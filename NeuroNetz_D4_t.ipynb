{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94b0518e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T14:16:02.416332100Z",
     "start_time": "2024-03-06T14:15:58.047971400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense , Dropout\n",
    "from scikeras.wrappers import KerasRegressor \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ff61b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T14:16:08.761519600Z",
     "start_time": "2024-03-06T14:16:08.728171800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n0            0.0000      -0.00200        100   7000   9000      400.35\n1            0.0000      -0.00192        100   7000   9000      416.89\n2            0.0000      -0.00184        100   7000   9000      432.05\n3            0.0000      -0.00176        100   7000   9000      445.87\n4            0.0000      -0.00168        100   7000   9000      458.33\n...             ...           ...        ...    ...    ...         ...\n43906        0.0024       0.00168        500   7000   9000      775.40\n43907        0.0024       0.00176        500   7000   9000      715.43\n43908        0.0024       0.00184        500   7000   9000      645.85\n43909        0.0024       0.00192        500   7000   9000      585.87\n43910        0.0024       0.00200        500   7000   9000      574.64\n\n[43911 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>100</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>400.35</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0000</td>\n      <td>-0.00192</td>\n      <td>100</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>416.89</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0000</td>\n      <td>-0.00184</td>\n      <td>100</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>432.05</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0000</td>\n      <td>-0.00176</td>\n      <td>100</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>445.87</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0000</td>\n      <td>-0.00168</td>\n      <td>100</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>458.33</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43906</th>\n      <td>0.0024</td>\n      <td>0.00168</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>775.40</td>\n    </tr>\n    <tr>\n      <th>43907</th>\n      <td>0.0024</td>\n      <td>0.00176</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>715.43</td>\n    </tr>\n    <tr>\n      <th>43908</th>\n      <td>0.0024</td>\n      <td>0.00184</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>645.85</td>\n    </tr>\n    <tr>\n      <th>43909</th>\n      <td>0.0024</td>\n      <td>0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>585.87</td>\n    </tr>\n    <tr>\n      <th>43910</th>\n      <td>0.0024</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>574.64</td>\n    </tr>\n  </tbody>\n</table>\n<p>43911 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/TPath_300_finish_data.pkl')\n",
    "data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish_D4_t_I7000_F9000/D4_t.pkl')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "966e3c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T14:16:15.376429800Z",
     "start_time": "2024-03-06T14:16:15.336734800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       X-Koordinate  Y-Koordinate  Zeitpunkt  Temperatur\n0            0.0000      -0.00200        100      400.35\n1            0.0000      -0.00192        100      416.89\n2            0.0000      -0.00184        100      432.05\n3            0.0000      -0.00176        100      445.87\n4            0.0000      -0.00168        100      458.33\n...             ...           ...        ...         ...\n43906        0.0024       0.00168        500      775.40\n43907        0.0024       0.00176        500      715.43\n43908        0.0024       0.00184        500      645.85\n43909        0.0024       0.00192        500      585.87\n43910        0.0024       0.00200        500      574.64\n\n[43911 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>100</td>\n      <td>400.35</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0000</td>\n      <td>-0.00192</td>\n      <td>100</td>\n      <td>416.89</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0000</td>\n      <td>-0.00184</td>\n      <td>100</td>\n      <td>432.05</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0000</td>\n      <td>-0.00176</td>\n      <td>100</td>\n      <td>445.87</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0000</td>\n      <td>-0.00168</td>\n      <td>100</td>\n      <td>458.33</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43906</th>\n      <td>0.0024</td>\n      <td>0.00168</td>\n      <td>500</td>\n      <td>775.40</td>\n    </tr>\n    <tr>\n      <th>43907</th>\n      <td>0.0024</td>\n      <td>0.00176</td>\n      <td>500</td>\n      <td>715.43</td>\n    </tr>\n    <tr>\n      <th>43908</th>\n      <td>0.0024</td>\n      <td>0.00184</td>\n      <td>500</td>\n      <td>645.85</td>\n    </tr>\n    <tr>\n      <th>43909</th>\n      <td>0.0024</td>\n      <td>0.00192</td>\n      <td>500</td>\n      <td>585.87</td>\n    </tr>\n    <tr>\n      <th>43910</th>\n      <td>0.0024</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>574.64</td>\n    </tr>\n  </tbody>\n</table>\n<p>43911 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.drop(data.columns[3:5], axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8783d1d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T14:16:40.909530800Z",
     "start_time": "2024-03-06T14:16:40.881128200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       X-Koordinate  Y-Koordinate  Zeitpunkt  Temperatur\n",
      "38620       0.00012      -0.00096        460     1229.80\n",
      "14428       0.00108       0.00168        230      542.76\n",
      "14359       0.00096       0.00024        230      777.04\n",
      "21104       0.00168       0.00128        290      720.23\n",
      "28698       0.00192       0.00088        360      886.28\n",
      "...             ...           ...        ...         ...\n",
      "6265        0.00204       0.00144        150      539.86\n",
      "11284       0.00132      -0.00096        200      690.53\n",
      "38158       0.00156      -0.00120        450     1049.80\n",
      "860         0.00192       0.00152        100      464.69\n",
      "15795       0.00180       0.00088        240      715.22\n",
      "\n",
      "[43911 rows x 4 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": "       X-Koordinate  Y-Koordinate  Zeitpunkt  Temperatur\n0           0.00012      -0.00096        460     1229.80\n1           0.00108       0.00168        230      542.76\n2           0.00096       0.00024        230      777.04\n3           0.00168       0.00128        290      720.23\n4           0.00192       0.00088        360      886.28\n...             ...           ...        ...         ...\n43906       0.00204       0.00144        150      539.86\n43907       0.00132      -0.00096        200      690.53\n43908       0.00156      -0.00120        450     1049.80\n43909       0.00192       0.00152        100      464.69\n43910       0.00180       0.00088        240      715.22\n\n[43911 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00012</td>\n      <td>-0.00096</td>\n      <td>460</td>\n      <td>1229.80</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00108</td>\n      <td>0.00168</td>\n      <td>230</td>\n      <td>542.76</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00096</td>\n      <td>0.00024</td>\n      <td>230</td>\n      <td>777.04</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00168</td>\n      <td>0.00128</td>\n      <td>290</td>\n      <td>720.23</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00192</td>\n      <td>0.00088</td>\n      <td>360</td>\n      <td>886.28</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43906</th>\n      <td>0.00204</td>\n      <td>0.00144</td>\n      <td>150</td>\n      <td>539.86</td>\n    </tr>\n    <tr>\n      <th>43907</th>\n      <td>0.00132</td>\n      <td>-0.00096</td>\n      <td>200</td>\n      <td>690.53</td>\n    </tr>\n    <tr>\n      <th>43908</th>\n      <td>0.00156</td>\n      <td>-0.00120</td>\n      <td>450</td>\n      <td>1049.80</td>\n    </tr>\n    <tr>\n      <th>43909</th>\n      <td>0.00192</td>\n      <td>0.00152</td>\n      <td>100</td>\n      <td>464.69</td>\n    </tr>\n    <tr>\n      <th>43910</th>\n      <td>0.00180</td>\n      <td>0.00088</td>\n      <td>240</td>\n      <td>715.22</td>\n    </tr>\n  </tbody>\n</table>\n<p>43911 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.sample(frac=1, random_state=42)  # Hier wird 42 als Random State verwendet, um die Ergebnisse reproduzierbar zu machen\n",
    "\n",
    "print(df1)\n",
    "df_reset = df1.reset_index(drop=True)\n",
    "df_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4e72a16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T14:16:45.604557400Z",
     "start_time": "2024-03-06T14:16:45.561569100Z"
    }
   },
   "outputs": [],
   "source": [
    "label = df_reset[\"Temperatur\"]\n",
    "# Korrektur: Verwenden Sie den Spaltennamen direkt, ohne Indexierung der columns-Eigenschaft\n",
    "df1 = df_reset.drop(\"Temperatur\", axis=1)\n",
    "X = df1\n",
    "y = label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7fa289a50d87423"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e694a236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T14:16:46.910591Z",
     "start_time": "2024-03-06T14:16:46.877622100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       X-Koordinate  Y-Koordinate  Zeitpunkt\n0           0.00012      -0.00096        460\n1           0.00108       0.00168        230\n2           0.00096       0.00024        230\n3           0.00168       0.00128        290\n4           0.00192       0.00088        360\n...             ...           ...        ...\n43906       0.00204       0.00144        150\n43907       0.00132      -0.00096        200\n43908       0.00156      -0.00120        450\n43909       0.00192       0.00152        100\n43910       0.00180       0.00088        240\n\n[43911 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00012</td>\n      <td>-0.00096</td>\n      <td>460</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00108</td>\n      <td>0.00168</td>\n      <td>230</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00096</td>\n      <td>0.00024</td>\n      <td>230</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00168</td>\n      <td>0.00128</td>\n      <td>290</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00192</td>\n      <td>0.00088</td>\n      <td>360</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43906</th>\n      <td>0.00204</td>\n      <td>0.00144</td>\n      <td>150</td>\n    </tr>\n    <tr>\n      <th>43907</th>\n      <td>0.00132</td>\n      <td>-0.00096</td>\n      <td>200</td>\n    </tr>\n    <tr>\n      <th>43908</th>\n      <td>0.00156</td>\n      <td>-0.00120</td>\n      <td>450</td>\n    </tr>\n    <tr>\n      <th>43909</th>\n      <td>0.00192</td>\n      <td>0.00152</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>43910</th>\n      <td>0.00180</td>\n      <td>0.00088</td>\n      <td>240</td>\n    </tr>\n  </tbody>\n</table>\n<p>43911 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f3303b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T14:16:50.520858400Z",
     "start_time": "2024-03-06T14:16:50.515915400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0        1229.80\n1         542.76\n2         777.04\n3         720.23\n4         886.28\n          ...   \n43906     539.86\n43907     690.53\n43908    1049.80\n43909     464.69\n43910     715.22\nName: Temperatur, Length: 43911, dtype: float64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3ad8da0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T14:16:51.970819600Z",
     "start_time": "2024-03-06T14:16:51.960078200Z"
    }
   },
   "outputs": [],
   "source": [
    " # train_df enthält 80% der Daten, test_df enthält 20% der Daten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c705edb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T14:16:56.485708700Z",
     "start_time": "2024-03-06T14:16:56.457363900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialisiere einen MinMaxScaler für die Features\n",
    "scaler_features = MinMaxScaler()\n",
    "scaler_features2 = MinMaxScaler()\n",
    "# Skaliere X_train und X_test\n",
    "X_train_scaled = scaler_features.fit_transform(X_train)\n",
    "X_test_scaled = scaler_features.transform(X_test)  # Nutze unterschiedliche Skalierungsparameter\n",
    "\n",
    "# Initialisiere einen SEPARATEN MinMaxScaler für das Ziel, wenn nötig\n",
    "scaler_target = MinMaxScaler()\n",
    "\n",
    "\n",
    "# Skaliere y_train und y_test. Beachte, dass y_train.reshape(-1, 1) verwendet wird, da MinMaxScaler \n",
    "# erwartet, dass die Eingaben als 2D-Arrays kommen, und Ziele normalerweise als 1D-Arrays vorliegen.\n",
    "y_train_scaled = scaler_target.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test_scaled = scaler_target.transform(y_test.values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbefe631e495b483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T14:16:58.077309200Z",
     "start_time": "2024-03-06T14:16:58.071791500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.05 , 0.66 , 0.275],\n       [0.8  , 0.02 , 0.525],\n       [0.6  , 0.2  , 0.525],\n       ...,\n       [0.45 , 0.92 , 0.975],\n       [0.3  , 0.7  , 0.875],\n       [0.75 , 1.   , 0.275]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9999999999999999"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_scaled.max()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T14:17:00.484293700Z",
     "start_time": "2024-03-06T14:17:00.477620500Z"
    }
   },
   "id": "ce04ce43aac2242f"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "375/375 [==============================] - 2s 2ms/step - loss: 0.0657 - mae: 0.0700 - val_loss: 0.0465 - val_mae: 0.0349\n",
      "Epoch 2/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0418 - mae: 0.0243 - val_loss: 0.0378 - val_mae: 0.0179\n",
      "Epoch 3/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0348 - mae: 0.0170 - val_loss: 0.0319 - val_mae: 0.0132\n",
      "Epoch 4/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0295 - mae: 0.0142 - val_loss: 0.0271 - val_mae: 0.0119\n",
      "Epoch 5/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0251 - mae: 0.0123 - val_loss: 0.0231 - val_mae: 0.0107\n",
      "Epoch 6/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0214 - mae: 0.0122 - val_loss: 0.0196 - val_mae: 0.0115\n",
      "Epoch 7/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0180 - mae: 0.0106 - val_loss: 0.0165 - val_mae: 0.0100\n",
      "Epoch 8/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0151 - mae: 0.0109 - val_loss: 0.0138 - val_mae: 0.0109\n",
      "Epoch 9/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0125 - mae: 0.0100 - val_loss: 0.0114 - val_mae: 0.0101\n",
      "Epoch 10/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0103 - mae: 0.0099 - val_loss: 0.0093 - val_mae: 0.0118\n",
      "Epoch 11/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0084 - mae: 0.0095 - val_loss: 0.0075 - val_mae: 0.0084\n",
      "Epoch 12/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0068 - mae: 0.0094 - val_loss: 0.0061 - val_mae: 0.0108\n",
      "Epoch 13/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0054 - mae: 0.0089 - val_loss: 0.0048 - val_mae: 0.0096\n",
      "Epoch 14/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0044 - mae: 0.0097 - val_loss: 0.0039 - val_mae: 0.0090\n",
      "Epoch 15/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0084 - val_loss: 0.0031 - val_mae: 0.0078\n",
      "Epoch 16/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0028 - mae: 0.0086 - val_loss: 0.0025 - val_mae: 0.0086\n",
      "Epoch 17/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0090 - val_loss: 0.0021 - val_mae: 0.0089\n",
      "Epoch 18/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0086 - val_loss: 0.0018 - val_mae: 0.0082\n",
      "Epoch 19/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0017 - mae: 0.0087 - val_loss: 0.0016 - val_mae: 0.0070\n",
      "Epoch 20/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0083 - val_loss: 0.0014 - val_mae: 0.0077\n",
      "Epoch 21/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0083 - val_loss: 0.0013 - val_mae: 0.0074\n",
      "Epoch 22/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0087 - val_loss: 0.0011 - val_mae: 0.0066\n",
      "Epoch 23/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0079 - val_loss: 0.0011 - val_mae: 0.0069\n",
      "Epoch 24/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0082 - val_loss: 0.0014 - val_mae: 0.0178\n",
      "Epoch 25/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0088 - val_loss: 0.0010 - val_mae: 0.0088\n",
      "Epoch 26/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 9.7480e-04 - mae: 0.0082 - val_loss: 9.5621e-04 - val_mae: 0.0083\n",
      "Epoch 27/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 9.3572e-04 - mae: 0.0081 - val_loss: 8.8043e-04 - val_mae: 0.0064\n",
      "Epoch 28/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 9.0725e-04 - mae: 0.0082 - val_loss: 9.0063e-04 - val_mae: 0.0083\n",
      "Epoch 29/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 8.7820e-04 - mae: 0.0081 - val_loss: 8.3832e-04 - val_mae: 0.0072\n",
      "Epoch 30/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 8.5208e-04 - mae: 0.0081 - val_loss: 9.4982e-04 - val_mae: 0.0121\n",
      "Epoch 31/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 8.2224e-04 - mae: 0.0078 - val_loss: 8.1879e-04 - val_mae: 0.0081\n",
      "Epoch 32/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 8.1454e-04 - mae: 0.0082 - val_loss: 7.6818e-04 - val_mae: 0.0068\n",
      "Epoch 33/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 7.8830e-04 - mae: 0.0079 - val_loss: 9.1685e-04 - val_mae: 0.0135\n",
      "Epoch 34/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 7.6535e-04 - mae: 0.0078 - val_loss: 7.5058e-04 - val_mae: 0.0076\n",
      "Epoch 35/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 7.5031e-04 - mae: 0.0077 - val_loss: 7.1970e-04 - val_mae: 0.0069\n",
      "Epoch 36/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 7.4217e-04 - mae: 0.0079 - val_loss: 6.8985e-04 - val_mae: 0.0059\n",
      "Epoch 37/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 7.2613e-04 - mae: 0.0079 - val_loss: 7.0106e-04 - val_mae: 0.0076\n",
      "Epoch 38/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 7.1538e-04 - mae: 0.0080 - val_loss: 6.7337e-04 - val_mae: 0.0069\n",
      "Epoch 39/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 7.0133e-04 - mae: 0.0079 - val_loss: 6.6293e-04 - val_mae: 0.0067\n",
      "Epoch 40/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 6.9003e-04 - mae: 0.0078 - val_loss: 8.0086e-04 - val_mae: 0.0112\n",
      "Epoch 41/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 6.8112e-04 - mae: 0.0079 - val_loss: 6.8050e-04 - val_mae: 0.0078\n",
      "Epoch 42/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 6.7881e-04 - mae: 0.0081 - val_loss: 6.2284e-04 - val_mae: 0.0061\n",
      "Epoch 43/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 6.3959e-04 - mae: 0.0070 - val_loss: 6.1499e-04 - val_mae: 0.0063\n",
      "Epoch 44/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 6.5198e-04 - mae: 0.0079 - val_loss: 6.5926e-04 - val_mae: 0.0076\n",
      "Epoch 45/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 6.3323e-04 - mae: 0.0075 - val_loss: 5.9540e-04 - val_mae: 0.0061\n",
      "Epoch 46/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 6.2926e-04 - mae: 0.0077 - val_loss: 5.8609e-04 - val_mae: 0.0062\n",
      "Epoch 47/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 6.1352e-04 - mae: 0.0074 - val_loss: 6.7549e-04 - val_mae: 0.0095\n",
      "Epoch 48/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 6.0439e-04 - mae: 0.0073 - val_loss: 5.8501e-04 - val_mae: 0.0067\n",
      "Epoch 49/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 5.9132e-04 - mae: 0.0071 - val_loss: 5.8815e-04 - val_mae: 0.0068\n",
      "Epoch 50/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 5.9493e-04 - mae: 0.0074 - val_loss: 6.2553e-04 - val_mae: 0.0090\n",
      "Epoch 51/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 5.9853e-04 - mae: 0.0078 - val_loss: 5.7588e-04 - val_mae: 0.0069\n",
      "Epoch 52/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 5.7560e-04 - mae: 0.0072 - val_loss: 5.4579e-04 - val_mae: 0.0061\n",
      "Epoch 53/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 5.7958e-04 - mae: 0.0076 - val_loss: 5.7431e-04 - val_mae: 0.0079\n",
      "Epoch 54/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 5.6547e-04 - mae: 0.0072 - val_loss: 5.2918e-04 - val_mae: 0.0056\n",
      "Epoch 55/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 5.5077e-04 - mae: 0.0068 - val_loss: 5.6424e-04 - val_mae: 0.0081\n",
      "Epoch 56/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 5.5269e-04 - mae: 0.0072 - val_loss: 5.4975e-04 - val_mae: 0.0069\n",
      "Epoch 57/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 5.5261e-04 - mae: 0.0074 - val_loss: 5.5712e-04 - val_mae: 0.0073\n",
      "Epoch 58/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 5.3754e-04 - mae: 0.0069 - val_loss: 5.6699e-04 - val_mae: 0.0082\n",
      "Epoch 59/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 5.5219e-04 - mae: 0.0077 - val_loss: 5.4259e-04 - val_mae: 0.0074\n",
      "Epoch 60/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 5.3405e-04 - mae: 0.0071 - val_loss: 5.7117e-04 - val_mae: 0.0078\n",
      "Epoch 61/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 5.2426e-04 - mae: 0.0069 - val_loss: 5.5397e-04 - val_mae: 0.0087\n",
      "Epoch 62/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 5.2642e-04 - mae: 0.0072 - val_loss: 4.9490e-04 - val_mae: 0.0058\n",
      "Epoch 63/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 5.1124e-04 - mae: 0.0067 - val_loss: 5.3706e-04 - val_mae: 0.0082\n",
      "Epoch 64/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 5.2159e-04 - mae: 0.0072 - val_loss: 5.1381e-04 - val_mae: 0.0077\n",
      "Epoch 65/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 5.1833e-04 - mae: 0.0073 - val_loss: 4.8281e-04 - val_mae: 0.0058\n",
      "Epoch 66/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 5.0068e-04 - mae: 0.0067 - val_loss: 4.8255e-04 - val_mae: 0.0059\n",
      "Epoch 67/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 5.0826e-04 - mae: 0.0073 - val_loss: 4.7216e-04 - val_mae: 0.0055\n",
      "Epoch 68/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.8987e-04 - mae: 0.0065 - val_loss: 4.8492e-04 - val_mae: 0.0062\n",
      "Epoch 69/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.9704e-04 - mae: 0.0070 - val_loss: 5.1637e-04 - val_mae: 0.0080\n",
      "Epoch 70/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.8684e-04 - mae: 0.0067 - val_loss: 5.0029e-04 - val_mae: 0.0073\n",
      "Epoch 71/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.8987e-04 - mae: 0.0070 - val_loss: 4.7595e-04 - val_mae: 0.0068\n",
      "Epoch 72/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.8387e-04 - mae: 0.0069 - val_loss: 5.0570e-04 - val_mae: 0.0080\n",
      "Epoch 73/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.9300e-04 - mae: 0.0073 - val_loss: 4.5840e-04 - val_mae: 0.0060\n",
      "Epoch 74/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.7722e-04 - mae: 0.0069 - val_loss: 5.7563e-04 - val_mae: 0.0107\n",
      "Epoch 75/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.6527e-04 - mae: 0.0064 - val_loss: 4.5175e-04 - val_mae: 0.0060\n",
      "Epoch 76/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.6934e-04 - mae: 0.0067 - val_loss: 5.7763e-04 - val_mae: 0.0115\n",
      "Epoch 77/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.6454e-04 - mae: 0.0067 - val_loss: 4.4154e-04 - val_mae: 0.0056\n",
      "Epoch 78/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.6697e-04 - mae: 0.0069 - val_loss: 5.1521e-04 - val_mae: 0.0096\n",
      "Epoch 79/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.6000e-04 - mae: 0.0067 - val_loss: 4.7110e-04 - val_mae: 0.0073\n",
      "Epoch 80/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.7342e-04 - mae: 0.0074 - val_loss: 4.7036e-04 - val_mae: 0.0069\n",
      "Epoch 81/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.5214e-04 - mae: 0.0066 - val_loss: 4.3367e-04 - val_mae: 0.0056\n",
      "Epoch 82/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.5035e-04 - mae: 0.0066 - val_loss: 4.2550e-04 - val_mae: 0.0055\n",
      "Epoch 83/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.5325e-04 - mae: 0.0068 - val_loss: 4.3981e-04 - val_mae: 0.0063\n",
      "Epoch 84/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.4775e-04 - mae: 0.0067 - val_loss: 4.2095e-04 - val_mae: 0.0056\n",
      "Epoch 85/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.4390e-04 - mae: 0.0066 - val_loss: 4.4658e-04 - val_mae: 0.0071\n",
      "Epoch 86/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.4718e-04 - mae: 0.0068 - val_loss: 4.2370e-04 - val_mae: 0.0060\n",
      "Epoch 87/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.4525e-04 - mae: 0.0069 - val_loss: 4.4346e-04 - val_mae: 0.0067\n",
      "Epoch 88/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.3580e-04 - mae: 0.0065 - val_loss: 4.2017e-04 - val_mae: 0.0059\n",
      "Epoch 89/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.3677e-04 - mae: 0.0067 - val_loss: 4.5131e-04 - val_mae: 0.0077\n",
      "Epoch 90/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.3619e-04 - mae: 0.0068 - val_loss: 5.0987e-04 - val_mae: 0.0107\n",
      "Epoch 91/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.3395e-04 - mae: 0.0067 - val_loss: 4.9703e-04 - val_mae: 0.0099\n",
      "Epoch 92/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.3295e-04 - mae: 0.0068 - val_loss: 4.0894e-04 - val_mae: 0.0056\n",
      "Epoch 93/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.3253e-04 - mae: 0.0068 - val_loss: 4.1028e-04 - val_mae: 0.0060\n",
      "Epoch 94/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.2988e-04 - mae: 0.0068 - val_loss: 4.2256e-04 - val_mae: 0.0067\n",
      "Epoch 95/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.2305e-04 - mae: 0.0065 - val_loss: 4.3992e-04 - val_mae: 0.0076\n",
      "Epoch 96/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.1652e-04 - mae: 0.0063 - val_loss: 4.1432e-04 - val_mae: 0.0064\n",
      "Epoch 97/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.2800e-04 - mae: 0.0069 - val_loss: 4.0895e-04 - val_mae: 0.0063\n",
      "Epoch 98/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.2103e-04 - mae: 0.0067 - val_loss: 4.0735e-04 - val_mae: 0.0063\n",
      "Epoch 99/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.1667e-04 - mae: 0.0066 - val_loss: 3.9842e-04 - val_mae: 0.0056\n",
      "Epoch 100/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.2142e-04 - mae: 0.0068 - val_loss: 3.9518e-04 - val_mae: 0.0058\n",
      "Epoch 101/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.1641e-04 - mae: 0.0067 - val_loss: 4.1495e-04 - val_mae: 0.0069\n",
      "Epoch 102/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.1742e-04 - mae: 0.0068 - val_loss: 7.4891e-04 - val_mae: 0.0163\n",
      "Epoch 103/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.1463e-04 - mae: 0.0067 - val_loss: 4.9226e-04 - val_mae: 0.0106\n",
      "Epoch 104/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.0559e-04 - mae: 0.0065 - val_loss: 3.9637e-04 - val_mae: 0.0059\n",
      "Epoch 105/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.1565e-04 - mae: 0.0070 - val_loss: 4.4581e-04 - val_mae: 0.0085\n",
      "Epoch 106/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.0601e-04 - mae: 0.0066 - val_loss: 4.0424e-04 - val_mae: 0.0063\n",
      "Epoch 107/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 3.9782e-04 - mae: 0.0063 - val_loss: 3.7682e-04 - val_mae: 0.0054\n",
      "Epoch 108/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 3.9669e-04 - mae: 0.0063 - val_loss: 4.0075e-04 - val_mae: 0.0070\n",
      "Epoch 109/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 3.9825e-04 - mae: 0.0065 - val_loss: 3.7618e-04 - val_mae: 0.0056\n",
      "Epoch 110/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 3.9454e-04 - mae: 0.0064 - val_loss: 4.0266e-04 - val_mae: 0.0065\n",
      "Epoch 111/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.0471e-04 - mae: 0.0069 - val_loss: 3.7346e-04 - val_mae: 0.0055\n",
      "Epoch 112/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 3.9131e-04 - mae: 0.0064 - val_loss: 4.1628e-04 - val_mae: 0.0078\n",
      "Epoch 113/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 3.9709e-04 - mae: 0.0067 - val_loss: 3.7727e-04 - val_mae: 0.0059\n",
      "Epoch 114/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 3.8946e-04 - mae: 0.0064 - val_loss: 3.6599e-04 - val_mae: 0.0053\n",
      "Epoch 115/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 3.9538e-04 - mae: 0.0068 - val_loss: 3.6876e-04 - val_mae: 0.0058\n",
      "Epoch 116/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 3.9256e-04 - mae: 0.0067 - val_loss: 3.6152e-04 - val_mae: 0.0051\n",
      "Epoch 117/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 3.8300e-04 - mae: 0.0063 - val_loss: 3.7186e-04 - val_mae: 0.0056\n",
      "Epoch 118/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 3.8040e-04 - mae: 0.0063 - val_loss: 3.9732e-04 - val_mae: 0.0069\n",
      "Epoch 119/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 3.8149e-04 - mae: 0.0063 - val_loss: 3.9765e-04 - val_mae: 0.0070\n",
      "Epoch 120/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 3.8014e-04 - mae: 0.0064 - val_loss: 3.7419e-04 - val_mae: 0.0062\n",
      "Epoch 121/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 3.9011e-04 - mae: 0.0068 - val_loss: 3.9527e-04 - val_mae: 0.0074\n",
      "Epoch 122/1000\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 3.7970e-04 - mae: 0.0064 - val_loss: 3.5668e-04 - val_mae: 0.0055\n",
      "Epoch 123/1000\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 3.8376e-04 - mae: 0.0067 - val_loss: 3.9732e-04 - val_mae: 0.0078\n",
      "Epoch 124/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 3.8733e-04 - mae: 0.0069 - val_loss: 3.7897e-04 - val_mae: 0.0062\n",
      "Epoch 125/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 3.7269e-04 - mae: 0.0062 - val_loss: 3.5018e-04 - val_mae: 0.0053\n",
      "Epoch 126/1000\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 3.7636e-04 - mae: 0.0065 - val_loss: 3.6763e-04 - val_mae: 0.0061\n",
      "Epoch 127/1000\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 3.7898e-04 - mae: 0.0065 - val_loss: 3.9104e-04 - val_mae: 0.0073\n",
      "Epoch 128/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 3.7138e-04 - mae: 0.0064 - val_loss: 3.6206e-04 - val_mae: 0.0064\n",
      "Epoch 129/1000\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 3.7915e-04 - mae: 0.0067 - val_loss: 3.7028e-04 - val_mae: 0.0060\n",
      "Epoch 130/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.7523e-04 - mae: 0.0066 - val_loss: 3.5602e-04 - val_mae: 0.0058\n",
      "Epoch 131/1000\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 3.6189e-04 - mae: 0.0061 - val_loss: 3.7362e-04 - val_mae: 0.0067\n",
      "Epoch 132/1000\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 3.7212e-04 - mae: 0.0066 - val_loss: 3.4825e-04 - val_mae: 0.0055\n",
      "Epoch 133/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.6555e-04 - mae: 0.0063 - val_loss: 3.5064e-04 - val_mae: 0.0056\n",
      "Epoch 134/1000\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 3.6615e-04 - mae: 0.0064 - val_loss: 3.6917e-04 - val_mae: 0.0064\n",
      "Epoch 135/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.6472e-04 - mae: 0.0063 - val_loss: 3.7226e-04 - val_mae: 0.0067\n",
      "Epoch 136/1000\n",
      "355/375 [===========================>..] - ETA: 0s - loss: 3.7552e-04 - mae: 0.0069Restoring model weights from the end of the best epoch: 131.\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.7506e-04 - mae: 0.0069 - val_loss: 3.8463e-04 - val_mae: 0.0072\n",
      "Epoch 136: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Netzwerkarchitektur\n",
    "model = Sequential([\n",
    "\n",
    "    Dense(136, activation='relu', input_shape=(3,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "    Dense(168, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(24, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(1 , activation = 'linear')\n",
    "])\n",
    "\n",
    "# Optimierer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# Modell kompilieren (Verwendung von mean_squared_error als Verlustfunktion für Regression)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])  # Metriken für Regression: Mean Absolute Error und Mean Squared Error\n",
    "\n",
    "# Early Stopping Callback\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "# Trainingsparameter\n",
    "batch_size = 75\n",
    "epochs = 1000\n",
    "\n",
    "# Modell trainieren (Annahme: X_train, y_train, X_val, y_val sind vordefiniert)\n",
    "history = model.fit(X_train_scaled, y_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T14:18:15.905504500Z",
     "start_time": "2024-03-06T14:17:12.670663700Z"
    }
   },
   "id": "8b52e1a9a6ff3aeb"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 - 0s - loss: 3.7289e-04 - mae: 0.0067 - 207ms/epoch - 753us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.00037289230385795236, 0.00668415566906333]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test_scaled, y_test_scaled, verbose=2)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T14:18:38.195887400Z",
     "start_time": "2024-03-06T14:18:37.951035400Z"
    }
   },
   "id": "4b02697cbcecd185"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bsp. Predicted: [602.8588] Actual: [596.74] \n",
      "Durchschnittliche Abweichung (MAE): [7.67562313]\n"
     ]
    }
   ],
   "source": [
    "scaled_predicted_values = model.predict(X_test_scaled, verbose = 0)\n",
    "\n",
    "# Führen Sie die Rücktransformation der skalierten Werte durch\n",
    "original_predicted_values = scaler_target.inverse_transform(scaled_predicted_values)\n",
    "original_actual_values = scaler_target.inverse_transform(y_test_scaled)  # y_test sind die skalierten tatsächlichen Werte\n",
    "print(f' Bsp. Predicted: {original_predicted_values[100]} Actual: {original_actual_values[100]} ')\n",
    "\n",
    "def calculate_mae(list1, list2):\n",
    "    # Stelle sicher, dass beide Listen die gleiche Länge haben\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Listen müssen die gleiche Länge haben\")\n",
    "\n",
    "    # Berechne die absolute Differenz zwischen den Elementen der Listen\n",
    "    differences = [abs(x - y) for x, y in zip(list1, list2)]\n",
    "\n",
    "    # Berechne den Durchschnitt der absoluten Differenzen\n",
    "    mae = sum(differences) / len(differences)\n",
    "\n",
    "    return mae\n",
    "\n",
    "# Beispiel\n",
    "list1 = original_predicted_values\n",
    "list2 = original_actual_values\n",
    "\n",
    "mae = calculate_mae(list1, list2)\n",
    "print(f\"Durchschnittliche Abweichung (MAE): {mae}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T14:18:42.614150Z",
     "start_time": "2024-03-06T14:18:42.197481700Z"
    }
   },
   "id": "a402d28abbd82f60"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mae = history.history['loss']\n",
    "val_mae = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(mae) + 1)\n",
    "\n",
    "# MAE Diagramm\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, mae, 'r', label='Training MSE')\n",
    "plt.plot(epochs, val_mae, 'b', label='Validation MSE')\n",
    "plt.title('Training and Validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T14:18:59.775600600Z",
     "start_time": "2024-03-06T14:18:59.617625Z"
    }
   },
   "id": "3688dd7102e95baf"
  },
  {
   "cell_type": "markdown",
   "id": "553df6fa",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "# def build_model(learning_rate=0.001, activation='relu', regularization=0.0001, dropout_rate=0.0):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(448, activation=activation, input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(384, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(96, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(128, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(320, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(416, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "#     \n",
    "#     model.add(Dense(416, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "#     \n",
    "#     model.add(Dense(256, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))    \n",
    "#     \n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mae'])\n",
    "#     return model\n",
    "# \n",
    "# # Verwenden Sie eine Funktion, um das Modell zu instanziieren, für scikit-learn Wrapper\n",
    "# model = KerasRegressor(model=build_model, verbose=2)\n",
    "# \n",
    "# # Anpassung der Parameter im param_grid\n",
    "# param_grid = {\n",
    "#     'model__learning_rate': [0.01, 0.001, 0.0001],\n",
    "#     'model__regularization': [0.001, 0.0001],\n",
    "#     'fit__batch_size': [10, 25, 50, 75],\n",
    "#     'fit__epochs': [50],\n",
    "#     'model__dropout_rate' : [0.0, 0.1, 0.2]\n",
    "# }\n",
    "# \n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=2)\n",
    "# # Hinweis: Stellen Sie sicher, dass Ihre Daten (X_train_scaled, y_train_scaled) korrekt definiert sind\n",
    "# grid_result = grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "# # Beste Parameter und Score ausgeben\n",
    "# print(\"Beste Parameter:\", grid_search.best_params_)\n",
    "# print(\"Beste Genauigkeit:\", grid_search.best_score_)\n",
    "# \n",
    "# with open(\"Gridsearch_D4.txt\", \"w\") as f:\n",
    "#     f.write(f\"Beste Parameter: {grid_search.best_params_}\\n\")\n",
    "#     f.write(f\"Beste Genauigkeit: {grid_search.best_score_}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T10:45:57.898597800Z",
     "start_time": "2024-02-29T10:45:57.884758200Z"
    }
   },
   "id": "7464a951f44a07ee"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 27\u001B[0m\n\u001B[0;32m     17\u001B[0m tuner \u001B[38;5;241m=\u001B[39m RandomSearch(\n\u001B[0;32m     18\u001B[0m     build_model,\n\u001B[0;32m     19\u001B[0m     objective\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     23\u001B[0m     project_name\u001B[38;5;241m=\u001B[39mproject_name\n\u001B[0;32m     24\u001B[0m )\n\u001B[0;32m     26\u001B[0m \u001B[38;5;66;03m# Durchführung des Random Search\u001B[39;00m\n\u001B[1;32m---> 27\u001B[0m \u001B[43mtuner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msearch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_scaled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train_scaled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mEarlyStopping\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmonitor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mval_loss\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpatience\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;66;03m# Abrufen und Speichern des besten Modells\u001B[39;00m\n\u001B[0;32m     30\u001B[0m best_model \u001B[38;5;241m=\u001B[39m tuner\u001B[38;5;241m.\u001B[39mget_best_models(num_models\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:233\u001B[0m, in \u001B[0;36mBaseTuner.search\u001B[1;34m(self, *fit_args, **fit_kwargs)\u001B[0m\n\u001B[0;32m    230\u001B[0m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m    232\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_trial_begin(trial)\n\u001B[1;32m--> 233\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_try_run_and_update_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    234\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_trial_end(trial)\n\u001B[0;32m    235\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_search_end()\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:273\u001B[0m, in \u001B[0;36mBaseTuner._try_run_and_update_trial\u001B[1;34m(self, trial, *fit_args, **fit_kwargs)\u001B[0m\n\u001B[0;32m    271\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_try_run_and_update_trial\u001B[39m(\u001B[38;5;28mself\u001B[39m, trial, \u001B[38;5;241m*\u001B[39mfit_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_kwargs):\n\u001B[0;32m    272\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 273\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_and_update_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    274\u001B[0m         trial\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m trial_module\u001B[38;5;241m.\u001B[39mTrialStatus\u001B[38;5;241m.\u001B[39mCOMPLETED\n\u001B[0;32m    275\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:238\u001B[0m, in \u001B[0;36mBaseTuner._run_and_update_trial\u001B[1;34m(self, trial, *fit_args, **fit_kwargs)\u001B[0m\n\u001B[0;32m    237\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_and_update_trial\u001B[39m(\u001B[38;5;28mself\u001B[39m, trial, \u001B[38;5;241m*\u001B[39mfit_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_kwargs):\n\u001B[1;32m--> 238\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    239\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moracle\u001B[38;5;241m.\u001B[39mget_trial(trial\u001B[38;5;241m.\u001B[39mtrial_id)\u001B[38;5;241m.\u001B[39mmetrics\u001B[38;5;241m.\u001B[39mexists(\n\u001B[0;32m    240\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moracle\u001B[38;5;241m.\u001B[39mobjective\u001B[38;5;241m.\u001B[39mname\n\u001B[0;32m    241\u001B[0m     ):\n\u001B[0;32m    242\u001B[0m         \u001B[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001B[39;00m\n\u001B[0;32m    243\u001B[0m         \u001B[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001B[39;00m\n\u001B[0;32m    244\u001B[0m         \u001B[38;5;66;03m# use case. No further action needed in this case.\u001B[39;00m\n\u001B[0;32m    245\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    246\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe use case of calling \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    247\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    253\u001B[0m             stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[0;32m    254\u001B[0m         )\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:314\u001B[0m, in \u001B[0;36mTuner.run_trial\u001B[1;34m(self, trial, *args, **kwargs)\u001B[0m\n\u001B[0;32m    312\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(model_checkpoint)\n\u001B[0;32m    313\u001B[0m     copied_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcallbacks\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m callbacks\n\u001B[1;32m--> 314\u001B[0m     obj_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_and_fit_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcopied_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    316\u001B[0m     histories\u001B[38;5;241m.\u001B[39mappend(obj_value)\n\u001B[0;32m    317\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m histories\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:233\u001B[0m, in \u001B[0;36mTuner._build_and_fit_model\u001B[1;34m(self, trial, *args, **kwargs)\u001B[0m\n\u001B[0;32m    231\u001B[0m hp \u001B[38;5;241m=\u001B[39m trial\u001B[38;5;241m.\u001B[39mhyperparameters\n\u001B[0;32m    232\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_build(hp)\n\u001B[1;32m--> 233\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhypermodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    235\u001B[0m \u001B[38;5;66;03m# Save the build config for model loading later.\u001B[39;00m\n\u001B[0;32m    236\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m backend\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mmulti_backend():\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py:149\u001B[0m, in \u001B[0;36mHyperModel.fit\u001B[1;34m(self, hp, model, *args, **kwargs)\u001B[0m\n\u001B[0;32m    125\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, hp, model, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    126\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Train the model.\u001B[39;00m\n\u001B[0;32m    127\u001B[0m \n\u001B[0;32m    128\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    147\u001B[0m \u001B[38;5;124;03m        If return a float, it should be the `objective` value.\u001B[39;00m\n\u001B[0;32m    148\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 149\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:1807\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1799\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1800\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1801\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1804\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1805\u001B[0m ):\n\u001B[0;32m   1806\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1807\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1808\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1809\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    829\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    831\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 832\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    834\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    835\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:868\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    865\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    866\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    867\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 868\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    869\u001B[0m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_config\u001B[49m\n\u001B[0;32m    870\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    871\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    872\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    873\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    874\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[1;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[0;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[1;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[0;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[0;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[0;32m   1319\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1320\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1321\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1322\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1323\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1324\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1325\u001B[0m     args,\n\u001B[0;32m   1326\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1327\u001B[0m     executing_eagerly)\n\u001B[0;32m   1328\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[1;34m(self, args)\u001B[0m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[0;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[1;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[0;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[0;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[0;32m    261\u001B[0m     )\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001B[0m, in \u001B[0;36mContext.call_function\u001B[1;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[0;32m   1484\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[0;32m   1485\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1486\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1487\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1488\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1489\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1490\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1491\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1492\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1493\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1494\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m   1495\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1496\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1500\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[0;32m   1501\u001B[0m   )\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Funktion zum Erstellen des Modells\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hp.Int('input_units', min_value=16, max_value=656, step=32), input_shape=(3,), activation='relu'))\n",
    "    for i in range(hp.Int('n_layers', 1, 10)):\n",
    "        model.add(Dense(hp.Int(f'units_{i}', min_value=16, max_value=656, step=32), activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Durchführung der Random Search dreimal\n",
    "for run in range(1, 4):\n",
    "    # Anpassen des Verzeichnisses und des Projektnamens für jeden Durchlauf\n",
    "    directory = 'random_search'\n",
    "    project_name = f'random_search_D4_t_{run}'\n",
    "    \n",
    "    tuner = RandomSearch(\n",
    "        build_model,\n",
    "        objective='val_loss',\n",
    "        max_trials=100,\n",
    "        executions_per_trial=2,\n",
    "        directory=directory,\n",
    "        project_name=project_name\n",
    "    )\n",
    "    \n",
    "    # Durchführung des Random Search\n",
    "    tuner.search(X_train_scaled, y_train_scaled, epochs=50, verbose =0, batch_size=50, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "    \n",
    "    # Abrufen und Speichern des besten Modells\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "    model_path = os.path.join(directory, project_name, 'best_model.h5') \n",
    "    best_model.save(model_path)\n",
    "    \n",
    "\n",
    "    # Optional: Abrufen und Ausgeben der besten Hyperparameter\n",
    "    best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "    \n",
    "    # Konvertieren der Hyperparameter in ein DataFrame\n",
    "    df_hyperparameters = pd.DataFrame([best_hyperparameters.values])\n",
    "    # Speichern des DataFrame als CSV\n",
    "    df_hyperparameters.to_csv(f'random_search_D4_t_{run}.csv', index=False)\n",
    "    \n",
    "    print(f\"Beste Hyperparameter für Lauf {run}: {best_hyperparameters.values}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T14:34:29.309186700Z",
     "start_time": "2024-03-06T14:34:13.302606100Z"
    }
   },
   "id": "d0f02feb42b652f5"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T23:57:20.263814600Z",
     "start_time": "2024-02-28T23:57:20.260104600Z"
    }
   },
   "id": "3e35d5ebef369658"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
