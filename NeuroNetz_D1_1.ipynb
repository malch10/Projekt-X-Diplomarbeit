{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94b0518e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T15:35:25.187938500Z",
     "start_time": "2024-04-04T15:35:12.824008500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    " import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense , Dropout\n",
    "from scikeras.wrappers import KerasRegressor \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Einlesen der Pickle-Dateien und Vorverarbeitung des Inhaltes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42e897a1c7eeed"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4ff61b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T15:35:25.212903900Z",
     "start_time": "2024-04-04T15:35:25.188939100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n0             0.0000      -0.00200        500   7000   9000      669.05\n1             0.0000      -0.00199        500   7000   9000      675.83\n2             0.0000      -0.00198        500   7000   9000      682.81\n3             0.0000      -0.00197        500   7000   9000      689.82\n4             0.0000      -0.00196        500   7000   9000      696.80\n...              ...           ...        ...    ...    ...         ...\n100646        0.0025       0.00196        500   7000   9000      578.47\n100647        0.0025       0.00197        500   7000   9000      576.89\n100648        0.0025       0.00198        500   7000   9000      575.32\n100649        0.0025       0.00199        500   7000   9000      573.76\n100650        0.0025       0.00200        500   7000   9000      572.20\n\n[100651 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>669.05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0000</td>\n      <td>-0.00199</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>675.83</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0000</td>\n      <td>-0.00198</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>682.81</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0000</td>\n      <td>-0.00197</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>689.82</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0000</td>\n      <td>-0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>696.80</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>100646</th>\n      <td>0.0025</td>\n      <td>0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>578.47</td>\n    </tr>\n    <tr>\n      <th>100647</th>\n      <td>0.0025</td>\n      <td>0.00197</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>576.89</td>\n    </tr>\n    <tr>\n      <th>100648</th>\n      <td>0.0025</td>\n      <td>0.00198</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>575.32</td>\n    </tr>\n    <tr>\n      <th>100649</th>\n      <td>0.0025</td>\n      <td>0.00199</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>573.76</td>\n    </tr>\n    <tr>\n      <th>100650</th>\n      <td>0.0025</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>572.20</td>\n    </tr>\n  </tbody>\n</table>\n<p>100651 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_D1_I7000_F9000/TPath_500_finish_data_D1.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "966e3c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T15:35:25.236835900Z",
     "start_time": "2024-04-04T15:35:25.210905200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "count    100651.000000\nmean       1144.030064\nstd         264.135723\nmin         572.200000\n25%         937.330000\n50%        1201.100000\n75%        1368.700000\nmax        1520.000000\nName: Temperatur, dtype: float64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.drop(data.columns[2:5], axis = 1)\n",
    "df['Temperatur'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8783d1d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T15:35:25.290337200Z",
     "start_time": "2024-04-04T15:35:25.221240100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       X-Koordinate  Y-Koordinate  Temperatur\n",
      "83145       0.00207      -0.00062      1282.2\n",
      "66701       0.00166      -0.00065      1347.6\n",
      "91325       0.00227       0.00098      1094.6\n",
      "46593       0.00116      -0.00123      1175.7\n",
      "49518       0.00123      -0.00005      1459.2\n",
      "...             ...           ...         ...\n",
      "6265        0.00015       0.00050      1439.1\n",
      "54886       0.00136       0.00150       876.7\n",
      "76820       0.00191       0.00029      1335.8\n",
      "860         0.00002      -0.00142      1071.2\n",
      "15795       0.00039      -0.00044      1488.1\n",
      "\n",
      "[100651 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate  Temperatur\n0            0.00207      -0.00062      1282.2\n1            0.00166      -0.00065      1347.6\n2            0.00227       0.00098      1094.6\n3            0.00116      -0.00123      1175.7\n4            0.00123      -0.00005      1459.2\n...              ...           ...         ...\n100646       0.00015       0.00050      1439.1\n100647       0.00136       0.00150       876.7\n100648       0.00191       0.00029      1335.8\n100649       0.00002      -0.00142      1071.2\n100650       0.00039      -0.00044      1488.1\n\n[100651 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00207</td>\n      <td>-0.00062</td>\n      <td>1282.2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00166</td>\n      <td>-0.00065</td>\n      <td>1347.6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00227</td>\n      <td>0.00098</td>\n      <td>1094.6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00116</td>\n      <td>-0.00123</td>\n      <td>1175.7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00123</td>\n      <td>-0.00005</td>\n      <td>1459.2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>100646</th>\n      <td>0.00015</td>\n      <td>0.00050</td>\n      <td>1439.1</td>\n    </tr>\n    <tr>\n      <th>100647</th>\n      <td>0.00136</td>\n      <td>0.00150</td>\n      <td>876.7</td>\n    </tr>\n    <tr>\n      <th>100648</th>\n      <td>0.00191</td>\n      <td>0.00029</td>\n      <td>1335.8</td>\n    </tr>\n    <tr>\n      <th>100649</th>\n      <td>0.00002</td>\n      <td>-0.00142</td>\n      <td>1071.2</td>\n    </tr>\n    <tr>\n      <th>100650</th>\n      <td>0.00039</td>\n      <td>-0.00044</td>\n      <td>1488.1</td>\n    </tr>\n  </tbody>\n</table>\n<p>100651 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.sample(frac=1, random_state=42)  # Hier wird 42 als Random State verwendet, um die Ergebnisse reproduzierbar zu machen\n",
    "print(df1)\n",
    "df_reset = df1.reset_index(drop=True)\n",
    "df_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4e72a16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T15:35:25.293337300Z",
     "start_time": "2024-04-04T15:35:25.234725300Z"
    }
   },
   "outputs": [],
   "source": [
    "label = df_reset[\"Temperatur\"]\n",
    "# Korrektur: Verwenden Sie den Spaltennamen direkt, ohne Indexierung der columns-Eigenschaft\n",
    "df1 = df_reset.drop(\"Temperatur\", axis=1)\n",
    "X = df1\n",
    "y = label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7fa289a50d87423"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e694a236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T15:35:25.320336800Z",
     "start_time": "2024-04-04T15:35:25.238353600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate\ncount  100651.000000  1.006510e+05\nmean        0.001250  1.103042e-20\nstd         0.000725  1.157589e-03\nmin         0.000000 -2.000000e-03\n25%         0.000620 -1.000000e-03\n50%         0.001250  4.529900e-18\n75%         0.001880  1.000000e-03\nmax         0.002500  2.000000e-03",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>100651.000000</td>\n      <td>1.006510e+05</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.001250</td>\n      <td>1.103042e-20</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.000725</td>\n      <td>1.157589e-03</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-2.000000e-03</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000620</td>\n      <td>-1.000000e-03</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.001250</td>\n      <td>4.529900e-18</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.001880</td>\n      <td>1.000000e-03</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.002500</td>\n      <td>2.000000e-03</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f3303b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T15:35:25.320336800Z",
     "start_time": "2024-04-04T15:35:25.254917700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "count    100651.000000\nmean       1144.030064\nstd         264.135723\nmin         572.200000\n25%         937.330000\n50%        1201.100000\n75%        1368.700000\nmax        1520.000000\nName: Temperatur, dtype: float64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3ad8da0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T15:35:25.345336600Z",
     "start_time": "2024-04-04T15:35:25.262918100Z"
    }
   },
   "outputs": [],
   "source": [
    " # train_df enthÃ¤lt 80% der Daten, test_df enthÃ¤lt 20% der Daten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c705edb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T15:35:25.346336400Z",
     "start_time": "2024-04-04T15:35:25.271900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialisiere einen MinMaxScaler fÃ¼r die Features\n",
    "scaler_features = MinMaxScaler()\n",
    "scaler_features2 = MinMaxScaler()\n",
    "# Skaliere X_train und X_test\n",
    "X_train_scaled = scaler_features.fit_transform(X_train)\n",
    "X_test_scaled = scaler_features.transform(X_test)  # Nutze unterschiedliche Skalierungsparameter\n",
    "\n",
    "\n",
    "scaler_target = MinMaxScaler()\n",
    "\n",
    "y_train_scaled = scaler_target.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test_scaled = scaler_target.transform(y_test.values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbefe631e495b483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T15:35:25.346336400Z",
     "start_time": "2024-04-04T15:35:25.280447800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.416 , 0.5725],\n       [0.812 , 0.7325],\n       [0.628 , 0.5075],\n       ...,\n       [0.604 , 0.3875],\n       [0.748 , 0.65  ],\n       [0.028 , 0.6225]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ende der Datenvorverarbeitung"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbcdf8ff6114c7a6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Machine Learning Modell mit Konfiguration je nach Dateiname"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca42b21ba64183fa"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "Epoch 1/400\n",
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "645/645 [==============================] - 3s 3ms/step - loss: 0.1089 - mae: 0.1095 - val_loss: 0.0580 - val_mae: 0.0173\n",
      "Epoch 2/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0503 - mae: 0.0080 - val_loss: 0.0443 - val_mae: 0.0043\n",
      "Epoch 3/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0406 - mae: 0.0091 - val_loss: 0.0373 - val_mae: 0.0064\n",
      "Epoch 4/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0353 - mae: 0.0097 - val_loss: 0.0335 - val_mae: 0.0132\n",
      "Epoch 5/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0319 - mae: 0.0075 - val_loss: 0.0305 - val_mae: 0.0046\n",
      "Epoch 6/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0295 - mae: 0.0078 - val_loss: 0.0286 - val_mae: 0.0128\n",
      "Epoch 7/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0275 - mae: 0.0081 - val_loss: 0.0264 - val_mae: 0.0038\n",
      "Epoch 8/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0257 - mae: 0.0082 - val_loss: 0.0250 - val_mae: 0.0147\n",
      "Epoch 9/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0241 - mae: 0.0069 - val_loss: 0.0234 - val_mae: 0.0101\n",
      "Epoch 10/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0227 - mae: 0.0087 - val_loss: 0.0220 - val_mae: 0.0069\n",
      "Epoch 11/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0215 - mae: 0.0076 - val_loss: 0.0209 - val_mae: 0.0108\n",
      "Epoch 12/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0203 - mae: 0.0056 - val_loss: 0.0199 - val_mae: 0.0106\n",
      "Epoch 13/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0193 - mae: 0.0068 - val_loss: 0.0187 - val_mae: 0.0036\n",
      "Epoch 14/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0183 - mae: 0.0060 - val_loss: 0.0178 - val_mae: 0.0035\n",
      "Epoch 15/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0176 - mae: 0.0072 - val_loss: 0.0170 - val_mae: 0.0023\n",
      "Epoch 16/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0168 - mae: 0.0066 - val_loss: 0.0164 - val_mae: 0.0096\n",
      "Epoch 17/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0160 - mae: 0.0039 - val_loss: 0.0157 - val_mae: 0.0033\n",
      "Epoch 18/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0154 - mae: 0.0061 - val_loss: 0.0152 - val_mae: 0.0115\n",
      "Epoch 19/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0148 - mae: 0.0063 - val_loss: 0.0144 - val_mae: 0.0026\n",
      "Epoch 20/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0142 - mae: 0.0042 - val_loss: 0.0139 - val_mae: 0.0028\n",
      "Epoch 21/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0137 - mae: 0.0058 - val_loss: 0.0135 - val_mae: 0.0104\n",
      "Epoch 22/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0131 - mae: 0.0043 - val_loss: 0.0133 - val_mae: 0.0154\n",
      "Epoch 23/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0127 - mae: 0.0047 - val_loss: 0.0124 - val_mae: 0.0059\n",
      "Epoch 24/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0122 - mae: 0.0056 - val_loss: 0.0119 - val_mae: 0.0022\n",
      "Epoch 25/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0118 - mae: 0.0053 - val_loss: 0.0116 - val_mae: 0.0058\n",
      "Epoch 26/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0113 - mae: 0.0043 - val_loss: 0.0111 - val_mae: 0.0041\n",
      "Epoch 27/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0110 - mae: 0.0048 - val_loss: 0.0108 - val_mae: 0.0055\n",
      "Epoch 28/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0107 - mae: 0.0055 - val_loss: 0.0105 - val_mae: 0.0076\n",
      "Epoch 29/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0103 - mae: 0.0039 - val_loss: 0.0102 - val_mae: 0.0073\n",
      "Epoch 30/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0100 - mae: 0.0046 - val_loss: 0.0098 - val_mae: 0.0019\n",
      "Epoch 31/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0097 - mae: 0.0057 - val_loss: 0.0095 - val_mae: 0.0027\n",
      "Epoch 32/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0094 - mae: 0.0038 - val_loss: 0.0092 - val_mae: 0.0039\n",
      "Epoch 33/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0091 - mae: 0.0038 - val_loss: 0.0090 - val_mae: 0.0027\n",
      "Epoch 34/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0089 - mae: 0.0046 - val_loss: 0.0087 - val_mae: 0.0046\n",
      "Epoch 35/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0086 - mae: 0.0034 - val_loss: 0.0084 - val_mae: 0.0040\n",
      "Epoch 36/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0084 - mae: 0.0047 - val_loss: 0.0082 - val_mae: 0.0017\n",
      "Epoch 37/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0081 - mae: 0.0040 - val_loss: 0.0086 - val_mae: 0.0192\n",
      "Epoch 38/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0079 - mae: 0.0042 - val_loss: 0.0078 - val_mae: 0.0026\n",
      "Epoch 39/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0077 - mae: 0.0044 - val_loss: 0.0076 - val_mae: 0.0063\n",
      "Epoch 40/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0075 - mae: 0.0031 - val_loss: 0.0074 - val_mae: 0.0019\n",
      "Epoch 41/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0073 - mae: 0.0036 - val_loss: 0.0072 - val_mae: 0.0042\n",
      "Epoch 42/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0071 - mae: 0.0037 - val_loss: 0.0070 - val_mae: 0.0026\n",
      "Epoch 43/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0069 - mae: 0.0046 - val_loss: 0.0068 - val_mae: 0.0043\n",
      "Epoch 44/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0067 - mae: 0.0035 - val_loss: 0.0066 - val_mae: 0.0061\n",
      "Epoch 45/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0065 - mae: 0.0039 - val_loss: 0.0064 - val_mae: 0.0030\n",
      "Epoch 46/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0064 - mae: 0.0035 - val_loss: 0.0063 - val_mae: 0.0037\n",
      "Epoch 47/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0062 - mae: 0.0036 - val_loss: 0.0061 - val_mae: 0.0028\n",
      "Epoch 48/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0061 - mae: 0.0035 - val_loss: 0.0060 - val_mae: 0.0031\n",
      "Epoch 49/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0059 - mae: 0.0031 - val_loss: 0.0058 - val_mae: 0.0032\n",
      "Epoch 50/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0058 - mae: 0.0039 - val_loss: 0.0057 - val_mae: 0.0026\n",
      "Epoch 51/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0056 - mae: 0.0029 - val_loss: 0.0055 - val_mae: 0.0024\n",
      "Epoch 52/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0055 - mae: 0.0033 - val_loss: 0.0054 - val_mae: 0.0019\n",
      "Epoch 53/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0054 - mae: 0.0040 - val_loss: 0.0053 - val_mae: 0.0039\n",
      "Epoch 54/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0052 - mae: 0.0025 - val_loss: 0.0052 - val_mae: 0.0032\n",
      "Epoch 55/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0051 - mae: 0.0033 - val_loss: 0.0050 - val_mae: 0.0026\n",
      "Epoch 56/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0050 - mae: 0.0035 - val_loss: 0.0049 - val_mae: 0.0016\n",
      "Epoch 57/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0049 - mae: 0.0031 - val_loss: 0.0048 - val_mae: 0.0037\n",
      "Epoch 58/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0048 - mae: 0.0028 - val_loss: 0.0047 - val_mae: 0.0047\n",
      "Epoch 59/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0047 - mae: 0.0031 - val_loss: 0.0046 - val_mae: 0.0017\n",
      "Epoch 60/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0046 - mae: 0.0036 - val_loss: 0.0045 - val_mae: 0.0034\n",
      "Epoch 61/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0045 - mae: 0.0029 - val_loss: 0.0044 - val_mae: 0.0019\n",
      "Epoch 62/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0044 - mae: 0.0029 - val_loss: 0.0043 - val_mae: 0.0022\n",
      "Epoch 63/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0043 - mae: 0.0031 - val_loss: 0.0042 - val_mae: 0.0014\n",
      "Epoch 64/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0042 - mae: 0.0027 - val_loss: 0.0041 - val_mae: 0.0014\n",
      "Epoch 65/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0041 - mae: 0.0036 - val_loss: 0.0041 - val_mae: 0.0028\n",
      "Epoch 66/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0040 - mae: 0.0029 - val_loss: 0.0040 - val_mae: 0.0017\n",
      "Epoch 67/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0039 - mae: 0.0027 - val_loss: 0.0039 - val_mae: 0.0041\n",
      "Epoch 68/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0039 - mae: 0.0028 - val_loss: 0.0038 - val_mae: 0.0018\n",
      "Epoch 69/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0038 - mae: 0.0028 - val_loss: 0.0037 - val_mae: 0.0029\n",
      "Epoch 70/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0037 - mae: 0.0033 - val_loss: 0.0037 - val_mae: 0.0022\n",
      "Epoch 71/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0036 - mae: 0.0023 - val_loss: 0.0036 - val_mae: 0.0021\n",
      "Epoch 72/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0036 - mae: 0.0031 - val_loss: 0.0035 - val_mae: 0.0029\n",
      "Epoch 73/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0035 - mae: 0.0027 - val_loss: 0.0035 - val_mae: 0.0014\n",
      "Epoch 74/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0035 - mae: 0.0035 - val_loss: 0.0034 - val_mae: 0.0018\n",
      "Epoch 75/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0034 - mae: 0.0023 - val_loss: 0.0034 - val_mae: 0.0013\n",
      "Epoch 76/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0033 - mae: 0.0024 - val_loss: 0.0033 - val_mae: 0.0031\n",
      "Epoch 77/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0033 - mae: 0.0033 - val_loss: 0.0032 - val_mae: 0.0014\n",
      "Epoch 78/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0032 - mae: 0.0026 - val_loss: 0.0032 - val_mae: 0.0017\n",
      "Epoch 79/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0031 - mae: 0.0030 - val_loss: 0.0033 - val_mae: 0.0105\n",
      "Epoch 80/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0031 - mae: 0.0028 - val_loss: 0.0030 - val_mae: 0.0020\n",
      "Epoch 81/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0030 - mae: 0.0025 - val_loss: 0.0030 - val_mae: 0.0058\n",
      "Epoch 82/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0030 - mae: 0.0027 - val_loss: 0.0030 - val_mae: 0.0046\n",
      "Epoch 83/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0029 - mae: 0.0027 - val_loss: 0.0033 - val_mae: 0.0156\n",
      "Epoch 84/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0029 - mae: 0.0028 - val_loss: 0.0028 - val_mae: 0.0034\n",
      "Epoch 85/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0028 - mae: 0.0026 - val_loss: 0.0028 - val_mae: 0.0025\n",
      "Epoch 86/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0028 - mae: 0.0028 - val_loss: 0.0027 - val_mae: 0.0024\n",
      "Epoch 87/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0027 - mae: 0.0025 - val_loss: 0.0027 - val_mae: 0.0037\n",
      "Epoch 88/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0027 - mae: 0.0026 - val_loss: 0.0026 - val_mae: 0.0032\n",
      "Epoch 89/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0026 - mae: 0.0029 - val_loss: 0.0026 - val_mae: 0.0048\n",
      "Epoch 90/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0026 - mae: 0.0023 - val_loss: 0.0025 - val_mae: 0.0019\n",
      "Epoch 91/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0025 - mae: 0.0028 - val_loss: 0.0026 - val_mae: 0.0076\n",
      "Epoch 92/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0025 - mae: 0.0026 - val_loss: 0.0024 - val_mae: 0.0013\n",
      "Epoch 93/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0024 - mae: 0.0027 - val_loss: 0.0024 - val_mae: 0.0021\n",
      "Epoch 94/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0024 - mae: 0.0029 - val_loss: 0.0024 - val_mae: 0.0027\n",
      "Epoch 95/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0021 - val_loss: 0.0023 - val_mae: 0.0053\n",
      "Epoch 96/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0027 - val_loss: 0.0023 - val_mae: 0.0039\n",
      "Epoch 97/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0022 - val_loss: 0.0022 - val_mae: 0.0028\n",
      "Epoch 98/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0026 - val_loss: 0.0022 - val_mae: 0.0037\n",
      "Epoch 99/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0025 - val_loss: 0.0022 - val_mae: 0.0022\n",
      "Epoch 100/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0021 - mae: 0.0027 - val_loss: 0.0021 - val_mae: 0.0035\n",
      "Epoch 101/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0021 - mae: 0.0024 - val_loss: 0.0021 - val_mae: 0.0016\n",
      "Epoch 102/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0021 - mae: 0.0024 - val_loss: 0.0020 - val_mae: 0.0025\n",
      "Epoch 103/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0020 - mae: 0.0024 - val_loss: 0.0020 - val_mae: 0.0027\n",
      "Epoch 104/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0020 - mae: 0.0024 - val_loss: 0.0020 - val_mae: 0.0016\n",
      "Epoch 105/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0020 - mae: 0.0027 - val_loss: 0.0019 - val_mae: 0.0030\n",
      "Epoch 106/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0019 - mae: 0.0021 - val_loss: 0.0019 - val_mae: 0.0015\n",
      "Epoch 107/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0019 - mae: 0.0026 - val_loss: 0.0019 - val_mae: 0.0030\n",
      "Epoch 108/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0018 - mae: 0.0022 - val_loss: 0.0018 - val_mae: 0.0018\n",
      "Epoch 109/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0018 - mae: 0.0026 - val_loss: 0.0018 - val_mae: 0.0036\n",
      "Epoch 110/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0018 - mae: 0.0024 - val_loss: 0.0018 - val_mae: 0.0042\n",
      "Epoch 111/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0018 - mae: 0.0024 - val_loss: 0.0017 - val_mae: 0.0024\n",
      "Epoch 112/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0017 - mae: 0.0025 - val_loss: 0.0017 - val_mae: 0.0037\n",
      "Epoch 113/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0017 - mae: 0.0024 - val_loss: 0.0017 - val_mae: 0.0034\n",
      "Epoch 114/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0017 - mae: 0.0026 - val_loss: 0.0016 - val_mae: 0.0013\n",
      "Epoch 115/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0016 - mae: 0.0019 - val_loss: 0.0016 - val_mae: 0.0012\n",
      "Epoch 116/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0016 - mae: 0.0022 - val_loss: 0.0016 - val_mae: 0.0029\n",
      "Epoch 117/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0016 - mae: 0.0025 - val_loss: 0.0016 - val_mae: 0.0022\n",
      "Epoch 118/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0016 - mae: 0.0024 - val_loss: 0.0015 - val_mae: 0.0019\n",
      "Epoch 119/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0015 - mae: 0.0023 - val_loss: 0.0015 - val_mae: 0.0024\n",
      "Epoch 120/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0015 - mae: 0.0022 - val_loss: 0.0015 - val_mae: 0.0037\n",
      "Epoch 121/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0015 - mae: 0.0023 - val_loss: 0.0015 - val_mae: 0.0012\n",
      "Epoch 122/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0015 - mae: 0.0027 - val_loss: 0.0014 - val_mae: 0.0026\n",
      "Epoch 123/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0014 - mae: 0.0019 - val_loss: 0.0014 - val_mae: 0.0043\n",
      "Epoch 124/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0014 - mae: 0.0023 - val_loss: 0.0014 - val_mae: 0.0023\n",
      "Epoch 125/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0024 - val_loss: 0.0014 - val_mae: 0.0017\n",
      "Epoch 126/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0023 - val_loss: 0.0013 - val_mae: 0.0027\n",
      "Epoch 127/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0022 - val_loss: 0.0013 - val_mae: 0.0012\n",
      "Epoch 128/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0024 - val_loss: 0.0013 - val_mae: 0.0049\n",
      "Epoch 129/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0022 - val_loss: 0.0013 - val_mae: 0.0013\n",
      "Epoch 130/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0013 - mae: 0.0021 - val_loss: 0.0013 - val_mae: 0.0045\n",
      "Epoch 131/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0022 - val_loss: 0.0012 - val_mae: 0.0023\n",
      "Epoch 132/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0023 - val_loss: 0.0012 - val_mae: 0.0039\n",
      "Epoch 133/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0012 - mae: 0.0022 - val_loss: 0.0012 - val_mae: 0.0044\n",
      "Epoch 134/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0012 - mae: 0.0021 - val_loss: 0.0012 - val_mae: 0.0013\n",
      "Epoch 135/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0022 - val_loss: 0.0011 - val_mae: 0.0017\n",
      "Epoch 136/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0021 - val_loss: 0.0011 - val_mae: 0.0033\n",
      "Epoch 137/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0011 - mae: 0.0021 - val_loss: 0.0011 - val_mae: 0.0025\n",
      "Epoch 138/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0022 - val_loss: 0.0011 - val_mae: 0.0046\n",
      "Epoch 139/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0022 - val_loss: 0.0011 - val_mae: 0.0016\n",
      "Epoch 140/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0011 - mae: 0.0021 - val_loss: 0.0011 - val_mae: 0.0030\n",
      "Epoch 141/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0022 - val_loss: 0.0010 - val_mae: 0.0024\n",
      "Epoch 142/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0020 - val_loss: 0.0010 - val_mae: 0.0011\n",
      "Epoch 143/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0022 - val_loss: 0.0011 - val_mae: 0.0069\n",
      "Epoch 144/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 9.9946e-04 - mae: 0.0021 - val_loss: 9.9479e-04 - val_mae: 0.0026\n",
      "Epoch 145/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 9.8151e-04 - mae: 0.0019 - val_loss: 9.7961e-04 - val_mae: 0.0033\n",
      "Epoch 146/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 9.6795e-04 - mae: 0.0022 - val_loss: 9.5411e-04 - val_mae: 0.0014\n",
      "Epoch 147/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 9.4998e-04 - mae: 0.0019 - val_loss: 9.4649e-04 - val_mae: 0.0023\n",
      "Epoch 148/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 9.4060e-04 - mae: 0.0023 - val_loss: 9.2851e-04 - val_mae: 0.0018\n",
      "Epoch 149/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 9.2218e-04 - mae: 0.0019 - val_loss: 9.1113e-04 - val_mae: 0.0014\n",
      "Epoch 150/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 9.0943e-04 - mae: 0.0022 - val_loss: 8.9802e-04 - val_mae: 0.0016\n",
      "Epoch 151/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 8.9743e-04 - mae: 0.0022 - val_loss: 8.8578e-04 - val_mae: 0.0017\n",
      "Epoch 152/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 8.8165e-04 - mae: 0.0020 - val_loss: 8.7473e-04 - val_mae: 0.0022\n",
      "Epoch 153/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 8.6983e-04 - mae: 0.0021 - val_loss: 8.5711e-04 - val_mae: 0.0010\n",
      "Epoch 154/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 8.5653e-04 - mae: 0.0020 - val_loss: 8.4685e-04 - val_mae: 0.0019\n",
      "Epoch 155/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 8.4403e-04 - mae: 0.0020 - val_loss: 8.3911e-04 - val_mae: 0.0025\n",
      "Epoch 156/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 8.2965e-04 - mae: 0.0018 - val_loss: 8.2277e-04 - val_mae: 0.0020\n",
      "Epoch 157/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 8.1844e-04 - mae: 0.0020 - val_loss: 8.3005e-04 - val_mae: 0.0043\n",
      "Epoch 158/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 8.0751e-04 - mae: 0.0021 - val_loss: 7.9915e-04 - val_mae: 0.0022\n",
      "Epoch 159/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 7.9998e-04 - mae: 0.0021 - val_loss: 7.8437e-04 - val_mae: 0.0010\n",
      "Epoch 160/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 7.8196e-04 - mae: 0.0016 - val_loss: 8.5273e-04 - val_mae: 0.0077\n",
      "Epoch 161/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 7.7294e-04 - mae: 0.0020 - val_loss: 7.6463e-04 - val_mae: 0.0016\n",
      "Epoch 162/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 7.6398e-04 - mae: 0.0022 - val_loss: 7.5521e-04 - val_mae: 0.0021\n",
      "Epoch 163/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 7.4943e-04 - mae: 0.0017 - val_loss: 7.4279e-04 - val_mae: 0.0016\n",
      "Epoch 164/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 7.4017e-04 - mae: 0.0019 - val_loss: 7.3033e-04 - val_mae: 0.0012\n",
      "Epoch 165/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 7.3304e-04 - mae: 0.0022 - val_loss: 7.2029e-04 - val_mae: 9.8425e-04\n",
      "Epoch 166/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 7.2108e-04 - mae: 0.0020 - val_loss: 7.1314e-04 - val_mae: 0.0015\n",
      "Epoch 167/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 7.1105e-04 - mae: 0.0019 - val_loss: 7.0122e-04 - val_mae: 0.0010\n",
      "Epoch 168/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 7.0062e-04 - mae: 0.0019 - val_loss: 6.9808e-04 - val_mae: 0.0023\n",
      "Epoch 169/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 6.9130e-04 - mae: 0.0019 - val_loss: 6.8780e-04 - val_mae: 0.0026\n",
      "Epoch 170/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 6.8183e-04 - mae: 0.0020 - val_loss: 6.7405e-04 - val_mae: 0.0016\n",
      "Epoch 171/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 6.7284e-04 - mae: 0.0020 - val_loss: 6.6565e-04 - val_mae: 0.0019\n",
      "Epoch 172/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 6.6334e-04 - mae: 0.0020 - val_loss: 6.6893e-04 - val_mae: 0.0029\n",
      "Epoch 173/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 6.5572e-04 - mae: 0.0020 - val_loss: 6.4625e-04 - val_mae: 0.0013\n",
      "Epoch 174/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 6.4512e-04 - mae: 0.0018 - val_loss: 6.3703e-04 - val_mae: 0.0012\n",
      "Epoch 175/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 6.3821e-04 - mae: 0.0020 - val_loss: 6.2886e-04 - val_mae: 0.0012\n",
      "Epoch 176/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 6.2901e-04 - mae: 0.0019 - val_loss: 6.2474e-04 - val_mae: 0.0023\n",
      "Epoch 177/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 6.1942e-04 - mae: 0.0017 - val_loss: 6.4804e-04 - val_mae: 0.0046\n",
      "Epoch 178/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 6.1220e-04 - mae: 0.0019 - val_loss: 6.0656e-04 - val_mae: 0.0016\n",
      "Epoch 179/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 6.0533e-04 - mae: 0.0020 - val_loss: 5.9622e-04 - val_mae: 0.0011\n",
      "Epoch 180/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 5.9699e-04 - mae: 0.0019 - val_loss: 5.9123e-04 - val_mae: 0.0017\n",
      "Epoch 181/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 5.9106e-04 - mae: 0.0021 - val_loss: 6.0075e-04 - val_mae: 0.0039\n",
      "Epoch 182/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 5.8068e-04 - mae: 0.0017 - val_loss: 5.7553e-04 - val_mae: 0.0015\n",
      "Epoch 183/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 5.7405e-04 - mae: 0.0018 - val_loss: 5.8863e-04 - val_mae: 0.0034\n",
      "Epoch 184/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 5.6750e-04 - mae: 0.0019 - val_loss: 5.6009e-04 - val_mae: 0.0013\n",
      "Epoch 185/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 5.6075e-04 - mae: 0.0019 - val_loss: 5.8091e-04 - val_mae: 0.0048\n",
      "Epoch 186/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 5.5763e-04 - mae: 0.0022 - val_loss: 5.5925e-04 - val_mae: 0.0031\n",
      "Epoch 187/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 5.4653e-04 - mae: 0.0017 - val_loss: 5.4158e-04 - val_mae: 0.0015\n",
      "Epoch 188/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 5.4287e-04 - mae: 0.0020 - val_loss: 5.6189e-04 - val_mae: 0.0051\n",
      "Epoch 189/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 5.3436e-04 - mae: 0.0018 - val_loss: 5.2732e-04 - val_mae: 9.7625e-04\n",
      "Epoch 190/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 5.2780e-04 - mae: 0.0018 - val_loss: 5.3580e-04 - val_mae: 0.0028\n",
      "Epoch 191/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 5.2369e-04 - mae: 0.0020 - val_loss: 5.1799e-04 - val_mae: 0.0017\n",
      "Epoch 192/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 5.1807e-04 - mae: 0.0021 - val_loss: 5.1087e-04 - val_mae: 0.0016\n",
      "Epoch 193/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 5.1001e-04 - mae: 0.0018 - val_loss: 5.0400e-04 - val_mae: 0.0012\n",
      "Epoch 194/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 5.0672e-04 - mae: 0.0020 - val_loss: 4.9922e-04 - val_mae: 0.0017\n",
      "Epoch 195/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 4.9712e-04 - mae: 0.0016 - val_loss: 4.9357e-04 - val_mae: 0.0015\n",
      "Epoch 196/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 4.9380e-04 - mae: 0.0019 - val_loss: 4.8601e-04 - val_mae: 9.5055e-04\n",
      "Epoch 197/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 4.8780e-04 - mae: 0.0019 - val_loss: 4.8128e-04 - val_mae: 0.0013\n",
      "Epoch 198/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 4.8455e-04 - mae: 0.0020 - val_loss: 4.8105e-04 - val_mae: 0.0025\n",
      "Epoch 199/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 4.7732e-04 - mae: 0.0018 - val_loss: 4.7721e-04 - val_mae: 0.0023\n",
      "Epoch 200/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 4.7227e-04 - mae: 0.0019 - val_loss: 4.6628e-04 - val_mae: 0.0014\n",
      "Epoch 201/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 4.6775e-04 - mae: 0.0020 - val_loss: 4.7360e-04 - val_mae: 0.0027\n",
      "Epoch 202/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 4.6308e-04 - mae: 0.0019 - val_loss: 4.5630e-04 - val_mae: 0.0012\n",
      "Epoch 203/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 4.5719e-04 - mae: 0.0019 - val_loss: 4.5177e-04 - val_mae: 0.0014\n",
      "Epoch 204/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 4.5262e-04 - mae: 0.0019 - val_loss: 4.6364e-04 - val_mae: 0.0039\n",
      "Epoch 205/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 4.5116e-04 - mae: 0.0020 - val_loss: 4.4341e-04 - val_mae: 0.0015\n",
      "Epoch 206/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 4.4284e-04 - mae: 0.0017 - val_loss: 4.3822e-04 - val_mae: 0.0013\n",
      "Epoch 207/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 4.3912e-04 - mae: 0.0019 - val_loss: 4.3553e-04 - val_mae: 0.0018\n",
      "Epoch 208/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 4.3600e-04 - mae: 0.0020 - val_loss: 4.3060e-04 - val_mae: 0.0016\n",
      "Epoch 209/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 4.3068e-04 - mae: 0.0019 - val_loss: 4.6461e-04 - val_mae: 0.0053\n",
      "Epoch 210/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 4.2565e-04 - mae: 0.0018 - val_loss: 4.2799e-04 - val_mae: 0.0029\n",
      "Epoch 211/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 4.2055e-04 - mae: 0.0017 - val_loss: 4.1755e-04 - val_mae: 0.0018\n",
      "Epoch 212/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 4.1882e-04 - mae: 0.0021 - val_loss: 4.1871e-04 - val_mae: 0.0024\n",
      "Epoch 213/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 4.1257e-04 - mae: 0.0018 - val_loss: 4.2310e-04 - val_mae: 0.0037\n",
      "Epoch 214/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 4.0943e-04 - mae: 0.0019 - val_loss: 4.4510e-04 - val_mae: 0.0051\n",
      "Epoch 215/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 4.0586e-04 - mae: 0.0019 - val_loss: 4.0777e-04 - val_mae: 0.0025\n",
      "Epoch 216/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 4.0143e-04 - mae: 0.0018 - val_loss: 4.0027e-04 - val_mae: 0.0019\n",
      "Epoch 217/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 3.9698e-04 - mae: 0.0018 - val_loss: 3.9935e-04 - val_mae: 0.0028\n",
      "Epoch 218/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 3.9506e-04 - mae: 0.0021 - val_loss: 3.9064e-04 - val_mae: 0.0018\n",
      "Epoch 219/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 3.9234e-04 - mae: 0.0020 - val_loss: 3.8930e-04 - val_mae: 0.0020\n",
      "Epoch 220/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 3.8620e-04 - mae: 0.0017 - val_loss: 3.8764e-04 - val_mae: 0.0022\n",
      "Epoch 221/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 3.8302e-04 - mae: 0.0018 - val_loss: 4.0116e-04 - val_mae: 0.0042\n",
      "Epoch 222/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 3.8027e-04 - mae: 0.0019 - val_loss: 3.7602e-04 - val_mae: 0.0015\n",
      "Epoch 223/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 3.7677e-04 - mae: 0.0019 - val_loss: 3.7337e-04 - val_mae: 0.0018\n",
      "Epoch 224/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 3.7338e-04 - mae: 0.0019 - val_loss: 3.7626e-04 - val_mae: 0.0031\n",
      "Epoch 225/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 3.7040e-04 - mae: 0.0019 - val_loss: 3.7836e-04 - val_mae: 0.0031\n",
      "Epoch 226/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.6829e-04 - mae: 0.0020 - val_loss: 3.6511e-04 - val_mae: 0.0020\n",
      "Epoch 227/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 3.6350e-04 - mae: 0.0018 - val_loss: 3.5982e-04 - val_mae: 0.0017\n",
      "Epoch 228/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 3.6161e-04 - mae: 0.0019 - val_loss: 3.5605e-04 - val_mae: 0.0014\n",
      "Epoch 229/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 3.5861e-04 - mae: 0.0019 - val_loss: 3.7995e-04 - val_mae: 0.0051\n",
      "Epoch 230/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.5500e-04 - mae: 0.0018 - val_loss: 3.5606e-04 - val_mae: 0.0026\n",
      "Epoch 231/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 3.5170e-04 - mae: 0.0018 - val_loss: 3.5142e-04 - val_mae: 0.0022\n",
      "Epoch 232/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 3.4987e-04 - mae: 0.0019 - val_loss: 3.6482e-04 - val_mae: 0.0044\n",
      "Epoch 233/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 3.4845e-04 - mae: 0.0020 - val_loss: 3.4630e-04 - val_mae: 0.0024\n",
      "Epoch 234/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 3.4460e-04 - mae: 0.0019 - val_loss: 3.5000e-04 - val_mae: 0.0027\n",
      "Epoch 235/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 3.4109e-04 - mae: 0.0018 - val_loss: 3.4622e-04 - val_mae: 0.0029\n",
      "Epoch 236/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 3.3814e-04 - mae: 0.0018 - val_loss: 3.4595e-04 - val_mae: 0.0032\n",
      "Epoch 237/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 3.3768e-04 - mae: 0.0021 - val_loss: 3.3381e-04 - val_mae: 0.0019\n",
      "Epoch 238/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 3.3351e-04 - mae: 0.0019 - val_loss: 3.3788e-04 - val_mae: 0.0026\n",
      "Epoch 239/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 3.3162e-04 - mae: 0.0020 - val_loss: 3.2973e-04 - val_mae: 0.0018\n",
      "Epoch 240/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 3.2951e-04 - mae: 0.0020 - val_loss: 3.2532e-04 - val_mae: 0.0017\n",
      "Epoch 241/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 3.2659e-04 - mae: 0.0019 - val_loss: 3.4506e-04 - val_mae: 0.0042\n",
      "Epoch 242/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 3.2367e-04 - mae: 0.0018 - val_loss: 3.2024e-04 - val_mae: 0.0015\n",
      "Epoch 243/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 3.2339e-04 - mae: 0.0021 - val_loss: 3.1872e-04 - val_mae: 0.0015\n",
      "Epoch 244/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 3.2032e-04 - mae: 0.0019 - val_loss: 3.3714e-04 - val_mae: 0.0045\n",
      "Epoch 245/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 3.1726e-04 - mae: 0.0018 - val_loss: 3.1306e-04 - val_mae: 0.0013\n",
      "Epoch 246/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 3.1615e-04 - mae: 0.0019 - val_loss: 3.1043e-04 - val_mae: 0.0012\n",
      "Epoch 247/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 3.1104e-04 - mae: 0.0015 - val_loss: 3.1138e-04 - val_mae: 0.0016\n",
      "Epoch 248/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 3.1145e-04 - mae: 0.0019 - val_loss: 3.0839e-04 - val_mae: 0.0016\n",
      "Epoch 249/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 3.0865e-04 - mae: 0.0018 - val_loss: 3.0539e-04 - val_mae: 0.0014\n",
      "Epoch 250/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 3.0658e-04 - mae: 0.0018 - val_loss: 3.0358e-04 - val_mae: 0.0017\n",
      "Epoch 251/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 3.0460e-04 - mae: 0.0019 - val_loss: 3.0011e-04 - val_mae: 0.0013\n",
      "Epoch 252/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.0224e-04 - mae: 0.0018 - val_loss: 3.0167e-04 - val_mae: 0.0022\n",
      "Epoch 253/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 3.0022e-04 - mae: 0.0018 - val_loss: 3.4954e-04 - val_mae: 0.0069\n",
      "Epoch 254/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.9852e-04 - mae: 0.0019 - val_loss: 2.9323e-04 - val_mae: 9.8544e-04\n",
      "Epoch 255/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.9621e-04 - mae: 0.0018 - val_loss: 3.0542e-04 - val_mae: 0.0038\n",
      "Epoch 256/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.9312e-04 - mae: 0.0017 - val_loss: 2.9214e-04 - val_mae: 0.0016\n",
      "Epoch 257/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.9365e-04 - mae: 0.0020 - val_loss: 2.9612e-04 - val_mae: 0.0025\n",
      "Epoch 258/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.9119e-04 - mae: 0.0019 - val_loss: 2.9569e-04 - val_mae: 0.0028\n",
      "Epoch 259/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.8972e-04 - mae: 0.0020 - val_loss: 2.8823e-04 - val_mae: 0.0020\n",
      "Epoch 260/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.8762e-04 - mae: 0.0019 - val_loss: 2.8216e-04 - val_mae: 9.6622e-04\n",
      "Epoch 261/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.8432e-04 - mae: 0.0017 - val_loss: 2.8542e-04 - val_mae: 0.0021\n",
      "Epoch 262/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.8477e-04 - mae: 0.0019 - val_loss: 2.8088e-04 - val_mae: 0.0017\n",
      "Epoch 263/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.8166e-04 - mae: 0.0018 - val_loss: 2.7770e-04 - val_mae: 0.0012\n",
      "Epoch 264/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.8105e-04 - mae: 0.0019 - val_loss: 2.9517e-04 - val_mae: 0.0042\n",
      "Epoch 265/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.8064e-04 - mae: 0.0020 - val_loss: 2.7580e-04 - val_mae: 0.0014\n",
      "Epoch 266/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.7725e-04 - mae: 0.0018 - val_loss: 2.8115e-04 - val_mae: 0.0026\n",
      "Epoch 267/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.7723e-04 - mae: 0.0020 - val_loss: 2.7957e-04 - val_mae: 0.0027\n",
      "Epoch 268/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.7333e-04 - mae: 0.0017 - val_loss: 2.7396e-04 - val_mae: 0.0020\n",
      "Epoch 269/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.7242e-04 - mae: 0.0017 - val_loss: 2.6806e-04 - val_mae: 0.0010\n",
      "Epoch 270/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.7194e-04 - mae: 0.0019 - val_loss: 2.7496e-04 - val_mae: 0.0029\n",
      "Epoch 271/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.6929e-04 - mae: 0.0017 - val_loss: 2.7005e-04 - val_mae: 0.0024\n",
      "Epoch 272/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.6865e-04 - mae: 0.0019 - val_loss: 2.6402e-04 - val_mae: 0.0011\n",
      "Epoch 273/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.6639e-04 - mae: 0.0018 - val_loss: 2.8053e-04 - val_mae: 0.0038\n",
      "Epoch 274/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.6556e-04 - mae: 0.0019 - val_loss: 2.7843e-04 - val_mae: 0.0038\n",
      "Epoch 275/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.6511e-04 - mae: 0.0020 - val_loss: 2.6782e-04 - val_mae: 0.0023\n",
      "Epoch 276/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.6264e-04 - mae: 0.0018 - val_loss: 2.6727e-04 - val_mae: 0.0026\n",
      "Epoch 277/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.6025e-04 - mae: 0.0017 - val_loss: 2.5704e-04 - val_mae: 0.0013\n",
      "Epoch 278/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.6073e-04 - mae: 0.0018 - val_loss: 2.8035e-04 - val_mae: 0.0045\n",
      "Epoch 279/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.5875e-04 - mae: 0.0019 - val_loss: 2.5698e-04 - val_mae: 0.0017\n",
      "Epoch 280/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.5751e-04 - mae: 0.0019 - val_loss: 2.5334e-04 - val_mae: 0.0013\n",
      "Epoch 281/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.5613e-04 - mae: 0.0018 - val_loss: 2.5250e-04 - val_mae: 0.0013\n",
      "Epoch 282/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.5561e-04 - mae: 0.0020 - val_loss: 2.5178e-04 - val_mae: 0.0016\n",
      "Epoch 283/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.5305e-04 - mae: 0.0018 - val_loss: 2.6537e-04 - val_mae: 0.0039\n",
      "Epoch 284/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.5274e-04 - mae: 0.0019 - val_loss: 2.5811e-04 - val_mae: 0.0031\n",
      "Epoch 285/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.5154e-04 - mae: 0.0019 - val_loss: 2.5123e-04 - val_mae: 0.0023\n",
      "Epoch 286/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.5001e-04 - mae: 0.0018 - val_loss: 2.4789e-04 - val_mae: 0.0016\n",
      "Epoch 287/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.5009e-04 - mae: 0.0020 - val_loss: 2.4509e-04 - val_mae: 0.0013\n",
      "Epoch 288/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.4815e-04 - mae: 0.0019 - val_loss: 2.4458e-04 - val_mae: 0.0014\n",
      "Epoch 289/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.4592e-04 - mae: 0.0017 - val_loss: 2.4252e-04 - val_mae: 0.0013\n",
      "Epoch 290/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.4490e-04 - mae: 0.0017 - val_loss: 2.4160e-04 - val_mae: 0.0013\n",
      "Epoch 291/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.4498e-04 - mae: 0.0019 - val_loss: 2.4082e-04 - val_mae: 0.0012\n",
      "Epoch 292/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.4282e-04 - mae: 0.0018 - val_loss: 2.3892e-04 - val_mae: 0.0011\n",
      "Epoch 293/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.4278e-04 - mae: 0.0019 - val_loss: 2.4112e-04 - val_mae: 0.0020\n",
      "Epoch 294/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.4080e-04 - mae: 0.0018 - val_loss: 2.3927e-04 - val_mae: 0.0018\n",
      "Epoch 295/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.4055e-04 - mae: 0.0019 - val_loss: 2.4295e-04 - val_mae: 0.0028\n",
      "Epoch 296/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.3869e-04 - mae: 0.0018 - val_loss: 2.3469e-04 - val_mae: 0.0011\n",
      "Epoch 297/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.3847e-04 - mae: 0.0019 - val_loss: 2.3406e-04 - val_mae: 0.0013\n",
      "Epoch 298/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.3714e-04 - mae: 0.0019 - val_loss: 2.3530e-04 - val_mae: 0.0018\n",
      "Epoch 299/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.3476e-04 - mae: 0.0017 - val_loss: 2.3332e-04 - val_mae: 0.0017\n",
      "Epoch 300/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.3594e-04 - mae: 0.0020 - val_loss: 2.3929e-04 - val_mae: 0.0028\n",
      "Epoch 301/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.3372e-04 - mae: 0.0018 - val_loss: 2.3618e-04 - val_mae: 0.0026\n",
      "Epoch 302/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.3245e-04 - mae: 0.0018 - val_loss: 2.5455e-04 - val_mae: 0.0045\n",
      "Epoch 303/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.3274e-04 - mae: 0.0019 - val_loss: 2.2861e-04 - val_mae: 0.0013\n",
      "Epoch 304/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.3113e-04 - mae: 0.0019 - val_loss: 2.6394e-04 - val_mae: 0.0054\n",
      "Epoch 305/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.3032e-04 - mae: 0.0018 - val_loss: 2.2576e-04 - val_mae: 0.0010\n",
      "Epoch 306/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.3052e-04 - mae: 0.0020 - val_loss: 2.3087e-04 - val_mae: 0.0023\n",
      "Epoch 307/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.2887e-04 - mae: 0.0018 - val_loss: 2.3900e-04 - val_mae: 0.0034\n",
      "Epoch 308/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.2766e-04 - mae: 0.0019 - val_loss: 2.2606e-04 - val_mae: 0.0016\n",
      "Epoch 309/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.2643e-04 - mae: 0.0018 - val_loss: 2.2269e-04 - val_mae: 0.0012\n",
      "Epoch 310/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.2485e-04 - mae: 0.0017 - val_loss: 2.2686e-04 - val_mae: 0.0023\n",
      "Epoch 311/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.2524e-04 - mae: 0.0019 - val_loss: 2.2267e-04 - val_mae: 0.0017\n",
      "Epoch 312/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.2368e-04 - mae: 0.0018 - val_loss: 2.2099e-04 - val_mae: 0.0015\n",
      "Epoch 313/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.2226e-04 - mae: 0.0018 - val_loss: 2.2346e-04 - val_mae: 0.0023\n",
      "Epoch 314/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.2212e-04 - mae: 0.0019 - val_loss: 2.1837e-04 - val_mae: 0.0014\n",
      "Epoch 315/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.2177e-04 - mae: 0.0019 - val_loss: 2.1702e-04 - val_mae: 0.0011\n",
      "Epoch 316/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.1919e-04 - mae: 0.0017 - val_loss: 2.1629e-04 - val_mae: 0.0013\n",
      "Epoch 317/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.1891e-04 - mae: 0.0018 - val_loss: 2.1571e-04 - val_mae: 0.0012\n",
      "Epoch 318/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.1821e-04 - mae: 0.0019 - val_loss: 2.2386e-04 - val_mae: 0.0031\n",
      "Epoch 319/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.1882e-04 - mae: 0.0020 - val_loss: 2.2192e-04 - val_mae: 0.0030\n",
      "Epoch 320/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.1636e-04 - mae: 0.0018 - val_loss: 2.1352e-04 - val_mae: 0.0014\n",
      "Epoch 321/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.1580e-04 - mae: 0.0018 - val_loss: 2.1379e-04 - val_mae: 0.0017\n",
      "Epoch 322/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.1519e-04 - mae: 0.0019 - val_loss: 2.6154e-04 - val_mae: 0.0057\n",
      "Epoch 323/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.1384e-04 - mae: 0.0018 - val_loss: 2.1052e-04 - val_mae: 0.0013\n",
      "Epoch 324/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.1254e-04 - mae: 0.0018 - val_loss: 2.1926e-04 - val_mae: 0.0028\n",
      "Epoch 325/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.1260e-04 - mae: 0.0019 - val_loss: 2.1469e-04 - val_mae: 0.0024\n",
      "Epoch 326/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.1129e-04 - mae: 0.0018 - val_loss: 2.0983e-04 - val_mae: 0.0019\n",
      "Epoch 327/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.1042e-04 - mae: 0.0019 - val_loss: 2.0649e-04 - val_mae: 0.0011\n",
      "Epoch 328/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.0968e-04 - mae: 0.0018 - val_loss: 2.0547e-04 - val_mae: 0.0011\n",
      "Epoch 329/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.0854e-04 - mae: 0.0018 - val_loss: 2.1798e-04 - val_mae: 0.0034\n",
      "Epoch 330/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.0828e-04 - mae: 0.0019 - val_loss: 2.0489e-04 - val_mae: 0.0016\n",
      "Epoch 331/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.0698e-04 - mae: 0.0019 - val_loss: 2.2544e-04 - val_mae: 0.0042\n",
      "Epoch 332/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.0666e-04 - mae: 0.0019 - val_loss: 2.2023e-04 - val_mae: 0.0042\n",
      "Epoch 333/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.0490e-04 - mae: 0.0018 - val_loss: 2.0194e-04 - val_mae: 0.0014\n",
      "Epoch 334/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.0432e-04 - mae: 0.0018 - val_loss: 2.0318e-04 - val_mae: 0.0018\n",
      "Epoch 335/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.0340e-04 - mae: 0.0018 - val_loss: 2.0587e-04 - val_mae: 0.0022\n",
      "Epoch 336/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.0511e-04 - mae: 0.0021 - val_loss: 2.9682e-04 - val_mae: 0.0094\n",
      "Epoch 337/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.0228e-04 - mae: 0.0018 - val_loss: 1.9811e-04 - val_mae: 0.0011\n",
      "Epoch 338/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.0126e-04 - mae: 0.0018 - val_loss: 2.0049e-04 - val_mae: 0.0020\n",
      "Epoch 339/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 2.0102e-04 - mae: 0.0019 - val_loss: 2.0457e-04 - val_mae: 0.0028\n",
      "Epoch 340/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.9977e-04 - mae: 0.0018 - val_loss: 1.9640e-04 - val_mae: 0.0012\n",
      "Epoch 341/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.9970e-04 - mae: 0.0019 - val_loss: 2.0222e-04 - val_mae: 0.0025\n",
      "Epoch 342/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.9856e-04 - mae: 0.0019 - val_loss: 1.9507e-04 - val_mae: 0.0013\n",
      "Epoch 343/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.9809e-04 - mae: 0.0019 - val_loss: 2.0196e-04 - val_mae: 0.0024\n",
      "Epoch 344/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.9775e-04 - mae: 0.0019 - val_loss: 2.1643e-04 - val_mae: 0.0040\n",
      "Epoch 345/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.9589e-04 - mae: 0.0018 - val_loss: 1.9370e-04 - val_mae: 0.0015\n",
      "Epoch 346/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.9583e-04 - mae: 0.0018 - val_loss: 1.9458e-04 - val_mae: 0.0017\n",
      "Epoch 347/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.9496e-04 - mae: 0.0018 - val_loss: 1.9689e-04 - val_mae: 0.0024\n",
      "Epoch 348/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.9528e-04 - mae: 0.0019 - val_loss: 1.9113e-04 - val_mae: 0.0013\n",
      "Epoch 349/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.9455e-04 - mae: 0.0020 - val_loss: 1.9027e-04 - val_mae: 0.0012\n",
      "Epoch 350/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.9277e-04 - mae: 0.0018 - val_loss: 1.8972e-04 - val_mae: 0.0013\n",
      "Epoch 351/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.9280e-04 - mae: 0.0019 - val_loss: 2.0287e-04 - val_mae: 0.0035\n",
      "Epoch 352/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.9204e-04 - mae: 0.0018 - val_loss: 1.9397e-04 - val_mae: 0.0024\n",
      "Epoch 353/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.9164e-04 - mae: 0.0019 - val_loss: 1.9398e-04 - val_mae: 0.0023\n",
      "Epoch 354/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.9136e-04 - mae: 0.0020 - val_loss: 2.1171e-04 - val_mae: 0.0044\n",
      "Epoch 355/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.9096e-04 - mae: 0.0020 - val_loss: 1.8835e-04 - val_mae: 0.0015\n",
      "Epoch 356/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.9007e-04 - mae: 0.0019 - val_loss: 2.1026e-04 - val_mae: 0.0047\n",
      "Epoch 357/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.8891e-04 - mae: 0.0018 - val_loss: 1.9555e-04 - val_mae: 0.0028\n",
      "Epoch 358/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.8830e-04 - mae: 0.0018 - val_loss: 1.8504e-04 - val_mae: 0.0013\n",
      "Epoch 359/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.8800e-04 - mae: 0.0018 - val_loss: 2.1506e-04 - val_mae: 0.0039\n",
      "Epoch 360/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.8768e-04 - mae: 0.0019 - val_loss: 1.8658e-04 - val_mae: 0.0017\n",
      "Epoch 361/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.8758e-04 - mae: 0.0020 - val_loss: 1.8449e-04 - val_mae: 0.0014\n",
      "Epoch 362/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.8779e-04 - mae: 0.0020 - val_loss: 1.8589e-04 - val_mae: 0.0021\n",
      "Epoch 363/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.8654e-04 - mae: 0.0019 - val_loss: 1.9056e-04 - val_mae: 0.0026\n",
      "Epoch 364/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.8559e-04 - mae: 0.0019 - val_loss: 1.8253e-04 - val_mae: 0.0013\n",
      "Epoch 365/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.8455e-04 - mae: 0.0018 - val_loss: 1.8781e-04 - val_mae: 0.0027\n",
      "Epoch 366/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.8468e-04 - mae: 0.0019 - val_loss: 1.8102e-04 - val_mae: 0.0014\n",
      "Epoch 367/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 1.8361e-04 - mae: 0.0019 - val_loss: 1.8082e-04 - val_mae: 0.0016\n",
      "Epoch 368/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 1.8272e-04 - mae: 0.0018 - val_loss: 1.7928e-04 - val_mae: 0.0012\n",
      "Epoch 369/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 1.8251e-04 - mae: 0.0018 - val_loss: 1.9147e-04 - val_mae: 0.0034\n",
      "Epoch 370/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 1.8208e-04 - mae: 0.0019 - val_loss: 1.7863e-04 - val_mae: 0.0013\n",
      "Epoch 371/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.8209e-04 - mae: 0.0019 - val_loss: 1.7925e-04 - val_mae: 0.0017\n",
      "Epoch 372/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 1.8086e-04 - mae: 0.0019 - val_loss: 1.8167e-04 - val_mae: 0.0023\n",
      "Epoch 373/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.8017e-04 - mae: 0.0018 - val_loss: 1.8475e-04 - val_mae: 0.0029\n",
      "Epoch 374/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.7999e-04 - mae: 0.0019 - val_loss: 1.7763e-04 - val_mae: 0.0016\n",
      "Epoch 375/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.8024e-04 - mae: 0.0019 - val_loss: 1.7915e-04 - val_mae: 0.0018\n",
      "Epoch 376/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.7839e-04 - mae: 0.0018 - val_loss: 1.7566e-04 - val_mae: 0.0013\n",
      "Epoch 377/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.7968e-04 - mae: 0.0020 - val_loss: 1.8874e-04 - val_mae: 0.0036\n",
      "Epoch 378/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 1.7801e-04 - mae: 0.0018 - val_loss: 1.8226e-04 - val_mae: 0.0023\n",
      "Epoch 379/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 1.7773e-04 - mae: 0.0019 - val_loss: 1.7430e-04 - val_mae: 0.0013\n",
      "Epoch 380/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 1.7761e-04 - mae: 0.0019 - val_loss: 1.7358e-04 - val_mae: 0.0011\n",
      "Epoch 381/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.7697e-04 - mae: 0.0019 - val_loss: 1.7415e-04 - val_mae: 0.0015\n",
      "Epoch 382/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.7690e-04 - mae: 0.0019 - val_loss: 1.7517e-04 - val_mae: 0.0017\n",
      "Epoch 383/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.7666e-04 - mae: 0.0019 - val_loss: 1.7404e-04 - val_mae: 0.0016\n",
      "Epoch 384/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 1.7643e-04 - mae: 0.0019 - val_loss: 1.7969e-04 - val_mae: 0.0030\n",
      "Epoch 385/400\n",
      "644/645 [============================>.] - ETA: 0s - loss: 1.7534e-04 - mae: 0.0019Restoring model weights from the end of the best epoch: 380.\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 1.7534e-04 - mae: 0.0019 - val_loss: 1.7699e-04 - val_mae: 0.0025\n",
      "Epoch 385: early stopping\n",
      "Die AusfÃ¼hrungszeit betrug 835.1740610599518 Sekunden.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Netzwerkarchitektur\n",
    "model = Sequential([\n",
    "    # Eingabeschicht\n",
    "\n",
    "    Dense(256, activation='relu', input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(128, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(160, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(224, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(112, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(320, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "    Dense(16, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(112, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(1 , activation = 'linear')\n",
    "    \n",
    "])\n",
    "\n",
    "# Optimierer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "# Modell kompilieren (Verwendung von mean_squared_error als Verlustfunktion fÃ¼r Regression)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])  # Metriken fÃ¼r Regression: Mean Absolute Error und Mean Squared Error\n",
    "\n",
    "# Early Stopping Callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=2, mode='min', restore_best_weights=True)#, min_delta = 0.00005)\n",
    "\n",
    "# Trainingsparameter\n",
    "batch_size = 100\n",
    "epochs = 400\n",
    "\n",
    "# Modell trainieren (Annahme: X_train, y_train, X_val, y_val sind vordefiniert)\n",
    "history = model.fit(X_train_scaled, y_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose = 1)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Berechne die Dauer\n",
    "duration = end_time - start_time\n",
    "\n",
    "print(f\"Die AusfÃ¼hrungszeit betrug {duration} Sekunden.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T14:02:42.031892300Z",
     "start_time": "2024-03-19T13:48:46.844727600Z"
    }
   },
   "id": "8b52e1a9a6ff3aeb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# k-Fold Crossvalidation \n",
    "FÃ¼r die Performancebestimmung der unterschiedlichen Netzarchitekturen"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7928df8ec1031de"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "Training fÃ¼r Fold 1...\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "645/645 [==============================] - 4s 3ms/step - loss: 0.2649 - mae: 0.1118 - val_loss: 0.1930 - val_mae: 0.0173\n",
      "Epoch 2/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.1722 - mae: 0.0103 - val_loss: 0.1561 - val_mae: 0.0194\n",
      "Epoch 3/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.1449 - mae: 0.0107 - val_loss: 0.1364 - val_mae: 0.0232\n",
      "Epoch 4/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.1292 - mae: 0.0106 - val_loss: 0.1234 - val_mae: 0.0161\n",
      "Epoch 5/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.1186 - mae: 0.0104 - val_loss: 0.1139 - val_mae: 0.0046\n",
      "Epoch 6/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.1101 - mae: 0.0079 - val_loss: 0.1063 - val_mae: 0.0118\n",
      "Epoch 7/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.1028 - mae: 0.0098 - val_loss: 0.0992 - val_mae: 0.0099\n",
      "Epoch 8/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0961 - mae: 0.0074 - val_loss: 0.0930 - val_mae: 0.0047\n",
      "Epoch 9/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0901 - mae: 0.0070 - val_loss: 0.0874 - val_mae: 0.0116\n",
      "Epoch 10/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0846 - mae: 0.0082 - val_loss: 0.0819 - val_mae: 0.0048\n",
      "Epoch 11/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0795 - mae: 0.0071 - val_loss: 0.0772 - val_mae: 0.0108\n",
      "Epoch 12/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0750 - mae: 0.0092 - val_loss: 0.0727 - val_mae: 0.0077\n",
      "Epoch 13/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0707 - mae: 0.0055 - val_loss: 0.0686 - val_mae: 0.0043\n",
      "Epoch 14/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0668 - mae: 0.0069 - val_loss: 0.0648 - val_mae: 0.0055\n",
      "Epoch 15/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0630 - mae: 0.0067 - val_loss: 0.0612 - val_mae: 0.0069\n",
      "Epoch 16/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0595 - mae: 0.0059 - val_loss: 0.0578 - val_mae: 0.0068\n",
      "Epoch 17/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0561 - mae: 0.0059 - val_loss: 0.0545 - val_mae: 0.0064\n",
      "Epoch 18/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0530 - mae: 0.0070 - val_loss: 0.0515 - val_mae: 0.0040\n",
      "Epoch 19/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0501 - mae: 0.0061 - val_loss: 0.0487 - val_mae: 0.0072\n",
      "Epoch 20/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0473 - mae: 0.0056 - val_loss: 0.0462 - val_mae: 0.0146\n",
      "Epoch 21/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0446 - mae: 0.0055 - val_loss: 0.0432 - val_mae: 0.0037\n",
      "Epoch 22/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0420 - mae: 0.0054 - val_loss: 0.0408 - val_mae: 0.0075\n",
      "Epoch 23/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0395 - mae: 0.0053 - val_loss: 0.0383 - val_mae: 0.0036\n",
      "Epoch 24/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0372 - mae: 0.0054 - val_loss: 0.0364 - val_mae: 0.0153\n",
      "Epoch 25/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0350 - mae: 0.0053 - val_loss: 0.0339 - val_mae: 0.0033\n",
      "Epoch 26/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0329 - mae: 0.0052 - val_loss: 0.0319 - val_mae: 0.0049\n",
      "Epoch 27/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0310 - mae: 0.0054 - val_loss: 0.0300 - val_mae: 0.0054\n",
      "Epoch 28/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0292 - mae: 0.0050 - val_loss: 0.0283 - val_mae: 0.0064\n",
      "Epoch 29/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0274 - mae: 0.0045 - val_loss: 0.0266 - val_mae: 0.0068\n",
      "Epoch 30/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0258 - mae: 0.0052 - val_loss: 0.0249 - val_mae: 0.0036\n",
      "Epoch 31/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0242 - mae: 0.0048 - val_loss: 0.0234 - val_mae: 0.0040\n",
      "Epoch 32/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0227 - mae: 0.0048 - val_loss: 0.0219 - val_mae: 0.0041\n",
      "Epoch 33/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0213 - mae: 0.0049 - val_loss: 0.0206 - val_mae: 0.0032\n",
      "Epoch 34/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0200 - mae: 0.0049 - val_loss: 0.0194 - val_mae: 0.0057\n",
      "Epoch 35/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0188 - mae: 0.0042 - val_loss: 0.0181 - val_mae: 0.0041\n",
      "Epoch 36/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0175 - mae: 0.0045 - val_loss: 0.0169 - val_mae: 0.0036\n",
      "Epoch 37/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0164 - mae: 0.0048 - val_loss: 0.0158 - val_mae: 0.0059\n",
      "Epoch 38/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0153 - mae: 0.0050 - val_loss: 0.0148 - val_mae: 0.0041\n",
      "Epoch 39/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0143 - mae: 0.0042 - val_loss: 0.0138 - val_mae: 0.0054\n",
      "Epoch 40/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0134 - mae: 0.0043 - val_loss: 0.0129 - val_mae: 0.0047\n",
      "Epoch 41/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0124 - mae: 0.0042 - val_loss: 0.0120 - val_mae: 0.0040\n",
      "Epoch 42/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0116 - mae: 0.0041 - val_loss: 0.0111 - val_mae: 0.0049\n",
      "Epoch 43/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0107 - mae: 0.0042 - val_loss: 0.0103 - val_mae: 0.0058\n",
      "Epoch 44/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0100 - mae: 0.0042 - val_loss: 0.0096 - val_mae: 0.0046\n",
      "Epoch 45/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0092 - mae: 0.0042 - val_loss: 0.0089 - val_mae: 0.0038\n",
      "Epoch 46/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0086 - mae: 0.0041 - val_loss: 0.0083 - val_mae: 0.0059\n",
      "Epoch 47/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0080 - mae: 0.0043 - val_loss: 0.0077 - val_mae: 0.0050\n",
      "Epoch 48/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0074 - mae: 0.0039 - val_loss: 0.0071 - val_mae: 0.0034\n",
      "Epoch 49/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0069 - mae: 0.0038 - val_loss: 0.0066 - val_mae: 0.0039\n",
      "Epoch 50/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0064 - mae: 0.0040 - val_loss: 0.0061 - val_mae: 0.0035\n",
      "Epoch 51/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0059 - mae: 0.0040 - val_loss: 0.0057 - val_mae: 0.0033\n",
      "Epoch 52/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0055 - mae: 0.0038 - val_loss: 0.0053 - val_mae: 0.0039\n",
      "Epoch 53/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0051 - mae: 0.0040 - val_loss: 0.0050 - val_mae: 0.0047\n",
      "Epoch 54/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0048 - mae: 0.0038 - val_loss: 0.0046 - val_mae: 0.0037\n",
      "Epoch 55/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0044 - mae: 0.0041 - val_loss: 0.0043 - val_mae: 0.0043\n",
      "Epoch 56/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0042 - mae: 0.0040 - val_loss: 0.0041 - val_mae: 0.0088\n",
      "Epoch 57/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0039 - mae: 0.0037 - val_loss: 0.0038 - val_mae: 0.0061\n",
      "Epoch 58/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0037 - mae: 0.0042 - val_loss: 0.0036 - val_mae: 0.0052\n",
      "Epoch 59/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0034 - mae: 0.0039 - val_loss: 0.0033 - val_mae: 0.0041\n",
      "Epoch 60/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0033 - mae: 0.0040 - val_loss: 0.0032 - val_mae: 0.0034\n",
      "Epoch 61/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0031 - mae: 0.0038 - val_loss: 0.0030 - val_mae: 0.0059\n",
      "Epoch 62/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0029 - mae: 0.0038 - val_loss: 0.0028 - val_mae: 0.0050\n",
      "Epoch 63/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0028 - mae: 0.0038 - val_loss: 0.0027 - val_mae: 0.0030\n",
      "Epoch 64/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0026 - mae: 0.0039 - val_loss: 0.0026 - val_mae: 0.0040\n",
      "Epoch 65/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0025 - mae: 0.0039 - val_loss: 0.0025 - val_mae: 0.0044\n",
      "Epoch 66/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0024 - mae: 0.0040 - val_loss: 0.0024 - val_mae: 0.0071\n",
      "Epoch 67/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0023 - mae: 0.0037 - val_loss: 0.0022 - val_mae: 0.0031\n",
      "Epoch 68/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0022 - mae: 0.0041 - val_loss: 0.0022 - val_mae: 0.0044\n",
      "Epoch 69/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0021 - mae: 0.0038 - val_loss: 0.0021 - val_mae: 0.0032\n",
      "Epoch 70/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0021 - mae: 0.0038 - val_loss: 0.0020 - val_mae: 0.0041\n",
      "Epoch 71/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0038 - val_loss: 0.0020 - val_mae: 0.0036\n",
      "Epoch 72/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0039 - val_loss: 0.0019 - val_mae: 0.0046\n",
      "Epoch 73/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0038 - val_loss: 0.0019 - val_mae: 0.0051\n",
      "Epoch 74/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0018 - mae: 0.0038 - val_loss: 0.0018 - val_mae: 0.0038\n",
      "Epoch 75/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0018 - mae: 0.0038 - val_loss: 0.0018 - val_mae: 0.0043\n",
      "Epoch 76/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0017 - mae: 0.0038 - val_loss: 0.0017 - val_mae: 0.0040\n",
      "Epoch 77/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0017 - mae: 0.0039 - val_loss: 0.0017 - val_mae: 0.0043\n",
      "Epoch 78/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0016 - mae: 0.0038 - val_loss: 0.0016 - val_mae: 0.0048\n",
      "Epoch 79/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0016 - mae: 0.0040 - val_loss: 0.0016 - val_mae: 0.0040\n",
      "Epoch 80/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0016 - mae: 0.0040 - val_loss: 0.0016 - val_mae: 0.0044\n",
      "Epoch 81/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0039 - val_loss: 0.0015 - val_mae: 0.0034\n",
      "Epoch 82/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0038 - val_loss: 0.0015 - val_mae: 0.0041\n",
      "Epoch 83/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0038 - val_loss: 0.0015 - val_mae: 0.0075\n",
      "Epoch 84/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0039 - val_loss: 0.0014 - val_mae: 0.0032\n",
      "Epoch 85/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0014 - mae: 0.0039 - val_loss: 0.0015 - val_mae: 0.0088\n",
      "Epoch 86/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0014 - mae: 0.0038 - val_loss: 0.0014 - val_mae: 0.0053\n",
      "Epoch 87/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0014 - mae: 0.0040 - val_loss: 0.0015 - val_mae: 0.0095\n",
      "Epoch 88/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0014 - mae: 0.0039 - val_loss: 0.0014 - val_mae: 0.0036\n",
      "Epoch 89/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0014 - mae: 0.0040 - val_loss: 0.0014 - val_mae: 0.0051\n",
      "Epoch 90/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0014 - mae: 0.0041 - val_loss: 0.0014 - val_mae: 0.0058\n",
      "Epoch 91/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0013 - mae: 0.0040 - val_loss: 0.0014 - val_mae: 0.0068\n",
      "Epoch 92/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0013 - mae: 0.0039 - val_loss: 0.0013 - val_mae: 0.0039\n",
      "Epoch 93/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0013 - mae: 0.0040 - val_loss: 0.0013 - val_mae: 0.0041\n",
      "Epoch 94/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0013 - mae: 0.0038 - val_loss: 0.0013 - val_mae: 0.0033\n",
      "Epoch 95/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0013 - mae: 0.0041 - val_loss: 0.0013 - val_mae: 0.0043\n",
      "Epoch 96/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0013 - mae: 0.0039 - val_loss: 0.0014 - val_mae: 0.0105\n",
      "Epoch 97/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0012 - val_mae: 0.0034\n",
      "Epoch 98/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0012 - mae: 0.0039 - val_loss: 0.0013 - val_mae: 0.0058\n",
      "Epoch 99/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0012 - mae: 0.0040 - val_loss: 0.0013 - val_mae: 0.0058\n",
      "Epoch 100/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0012 - mae: 0.0041 - val_loss: 0.0012 - val_mae: 0.0045\n",
      "Epoch 101/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0012 - mae: 0.0041 - val_loss: 0.0012 - val_mae: 0.0067\n",
      "Epoch 102/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0012 - mae: 0.0041 - val_loss: 0.0012 - val_mae: 0.0060\n",
      "Epoch 103/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0012 - mae: 0.0039 - val_loss: 0.0012 - val_mae: 0.0032\n",
      "Epoch 104/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0012 - mae: 0.0040 - val_loss: 0.0012 - val_mae: 0.0038\n",
      "Epoch 105/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0012 - mae: 0.0041 - val_loss: 0.0012 - val_mae: 0.0046\n",
      "Epoch 106/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0012 - mae: 0.0042 - val_loss: 0.0012 - val_mae: 0.0086\n",
      "Epoch 107/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0012 - mae: 0.0039 - val_loss: 0.0012 - val_mae: 0.0036\n",
      "Epoch 108/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0012 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0030\n",
      "Epoch 109/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0038 - val_loss: 0.0012 - val_mae: 0.0084\n",
      "Epoch 110/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0036\n",
      "Epoch 111/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0040 - val_loss: 0.0011 - val_mae: 0.0030\n",
      "Epoch 112/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0040 - val_loss: 0.0011 - val_mae: 0.0058\n",
      "Epoch 113/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0047\n",
      "Epoch 114/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0058\n",
      "Epoch 115/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0037\n",
      "Epoch 116/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0037\n",
      "Epoch 117/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0050\n",
      "Epoch 118/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0040 - val_loss: 0.0011 - val_mae: 0.0040\n",
      "Epoch 119/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0053\n",
      "Epoch 120/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 121/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0042\n",
      "Epoch 122/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 123/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0037\n",
      "Epoch 124/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0033\n",
      "Epoch 125/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0040 - val_loss: 0.0011 - val_mae: 0.0059\n",
      "Epoch 126/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0055\n",
      "Epoch 127/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0040 - val_loss: 0.0011 - val_mae: 0.0044\n",
      "Epoch 128/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0040 - val_loss: 0.0011 - val_mae: 0.0067\n",
      "Epoch 129/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0040 - val_loss: 0.0010 - val_mae: 0.0038\n",
      "Epoch 130/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0042\n",
      "Epoch 131/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0040 - val_loss: 0.0011 - val_mae: 0.0065\n",
      "Epoch 132/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0039 - val_loss: 0.0010 - val_mae: 0.0032\n",
      "Epoch 133/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0108\n",
      "Epoch 134/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0040 - val_loss: 0.0010 - val_mae: 0.0039\n",
      "Epoch 135/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0039 - val_loss: 0.0010 - val_mae: 0.0030\n",
      "Epoch 136/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0038 - val_loss: 0.0010 - val_mae: 0.0034\n",
      "Epoch 137/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0041 - val_loss: 0.0010 - val_mae: 0.0038\n",
      "Epoch 138/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0040 - val_loss: 0.0010 - val_mae: 0.0037\n",
      "Epoch 139/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0040 - val_loss: 0.0011 - val_mae: 0.0071\n",
      "Epoch 140/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0041 - val_loss: 0.0010 - val_mae: 0.0035\n",
      "Epoch 141/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0041 - val_loss: 0.0010 - val_mae: 0.0047\n",
      "Epoch 142/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0039 - val_loss: 0.0010 - val_mae: 0.0034\n",
      "Epoch 143/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0042 - val_loss: 0.0010 - val_mae: 0.0043\n",
      "Epoch 144/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0038 - val_loss: 0.0010 - val_mae: 0.0067\n",
      "Epoch 145/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0041 - val_loss: 0.0010 - val_mae: 0.0038\n",
      "Epoch 146/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0040 - val_loss: 0.0012 - val_mae: 0.0140\n",
      "Epoch 147/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0040 - val_loss: 0.0010 - val_mae: 0.0061\n",
      "Epoch 148/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.9715e-04 - mae: 0.0039 - val_loss: 9.9483e-04 - val_mae: 0.0038\n",
      "Epoch 149/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.9605e-04 - mae: 0.0040 - val_loss: 9.8674e-04 - val_mae: 0.0031\n",
      "Epoch 150/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.9362e-04 - mae: 0.0040 - val_loss: 0.0010 - val_mae: 0.0063\n",
      "Epoch 151/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.9051e-04 - mae: 0.0039 - val_loss: 9.8040e-04 - val_mae: 0.0030\n",
      "Epoch 152/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.8991e-04 - mae: 0.0041 - val_loss: 9.9955e-04 - val_mae: 0.0053\n",
      "Epoch 153/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.8856e-04 - mae: 0.0041 - val_loss: 9.9081e-04 - val_mae: 0.0045\n",
      "Epoch 154/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.8330e-04 - mae: 0.0039 - val_loss: 9.7586e-04 - val_mae: 0.0030\n",
      "Epoch 155/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.8430e-04 - mae: 0.0041 - val_loss: 0.0010 - val_mae: 0.0069\n",
      "Epoch 156/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.8023e-04 - mae: 0.0040 - val_loss: 9.7234e-04 - val_mae: 0.0032\n",
      "Epoch 157/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.7693e-04 - mae: 0.0039 - val_loss: 0.0010 - val_mae: 0.0080\n",
      "Epoch 158/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.7576e-04 - mae: 0.0039 - val_loss: 9.9581e-04 - val_mae: 0.0059\n",
      "Epoch 159/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.7461e-04 - mae: 0.0040 - val_loss: 9.7049e-04 - val_mae: 0.0038\n",
      "Epoch 160/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.7390e-04 - mae: 0.0041 - val_loss: 9.6508e-04 - val_mae: 0.0034\n",
      "Epoch 161/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.7099e-04 - mae: 0.0040 - val_loss: 0.0010 - val_mae: 0.0088\n",
      "Epoch 162/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.7021e-04 - mae: 0.0041 - val_loss: 9.8993e-04 - val_mae: 0.0058\n",
      "Epoch 163/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.6715e-04 - mae: 0.0040 - val_loss: 9.7554e-04 - val_mae: 0.0046\n",
      "Epoch 164/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.6648e-04 - mae: 0.0041 - val_loss: 9.5837e-04 - val_mae: 0.0035\n",
      "Epoch 165/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.6162e-04 - mae: 0.0038 - val_loss: 9.5637e-04 - val_mae: 0.0034\n",
      "Epoch 166/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.6237e-04 - mae: 0.0040 - val_loss: 0.0010 - val_mae: 0.0084\n",
      "Epoch 167/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.6115e-04 - mae: 0.0041 - val_loss: 9.5083e-04 - val_mae: 0.0031\n",
      "Epoch 168/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.5883e-04 - mae: 0.0040 - val_loss: 9.5904e-04 - val_mae: 0.0043\n",
      "Epoch 169/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.5458e-04 - mae: 0.0038 - val_loss: 9.4992e-04 - val_mae: 0.0035\n",
      "Epoch 170/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.5398e-04 - mae: 0.0039 - val_loss: 9.5159e-04 - val_mae: 0.0036\n",
      "Epoch 171/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.5400e-04 - mae: 0.0041 - val_loss: 9.4779e-04 - val_mae: 0.0037\n",
      "Epoch 172/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.4958e-04 - mae: 0.0039 - val_loss: 9.6066e-04 - val_mae: 0.0047\n",
      "Epoch 173/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.4908e-04 - mae: 0.0040 - val_loss: 9.3909e-04 - val_mae: 0.0031\n",
      "Epoch 174/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.4849e-04 - mae: 0.0040 - val_loss: 9.4186e-04 - val_mae: 0.0035\n",
      "Epoch 175/1000\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.4368e-04 - mae: 0.0038 - val_loss: 9.6504e-04 - val_mae: 0.0054\n",
      "Epoch 176/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.4491e-04 - mae: 0.0041 - val_loss: 9.4117e-04 - val_mae: 0.0038\n",
      "Epoch 177/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.4098e-04 - mae: 0.0038 - val_loss: 9.6387e-04 - val_mae: 0.0061\n",
      "Epoch 178/1000\n",
      "643/645 [============================>.] - ETA: 0s - loss: 9.4057e-04 - mae: 0.0039Restoring model weights from the end of the best epoch: 173.\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.4056e-04 - mae: 0.0039 - val_loss: 9.5462e-04 - val_mae: 0.0051\n",
      "Epoch 178: early stopping\n",
      "Training fÃ¼r Fold 2...\n",
      "Epoch 1/1000\n",
      "645/645 [==============================] - 3s 3ms/step - loss: 0.2667 - mae: 0.1190 - val_loss: 0.1932 - val_mae: 0.0157\n",
      "Epoch 2/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.1740 - mae: 0.0094 - val_loss: 0.1597 - val_mae: 0.0228\n",
      "Epoch 3/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.1494 - mae: 0.0085 - val_loss: 0.1414 - val_mae: 0.0091\n",
      "Epoch 4/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.1357 - mae: 0.0093 - val_loss: 0.1306 - val_mae: 0.0067\n",
      "Epoch 5/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.1266 - mae: 0.0119 - val_loss: 0.1236 - val_mae: 0.0254\n",
      "Epoch 6/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.1190 - mae: 0.0092 - val_loss: 0.1154 - val_mae: 0.0058\n",
      "Epoch 7/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.1122 - mae: 0.0075 - val_loss: 0.1088 - val_mae: 0.0039\n",
      "Epoch 8/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.1058 - mae: 0.0082 - val_loss: 0.1027 - val_mae: 0.0121\n",
      "Epoch 9/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0997 - mae: 0.0084 - val_loss: 0.0967 - val_mae: 0.0074\n",
      "Epoch 10/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0939 - mae: 0.0086 - val_loss: 0.0911 - val_mae: 0.0092\n",
      "Epoch 11/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0883 - mae: 0.0074 - val_loss: 0.0856 - val_mae: 0.0040\n",
      "Epoch 12/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0831 - mae: 0.0065 - val_loss: 0.0805 - val_mae: 0.0067\n",
      "Epoch 13/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0782 - mae: 0.0087 - val_loss: 0.0759 - val_mae: 0.0138\n",
      "Epoch 14/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0736 - mae: 0.0064 - val_loss: 0.0715 - val_mae: 0.0064\n",
      "Epoch 15/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0694 - mae: 0.0060 - val_loss: 0.0674 - val_mae: 0.0112\n",
      "Epoch 16/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0655 - mae: 0.0082 - val_loss: 0.0635 - val_mae: 0.0086\n",
      "Epoch 17/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0617 - mae: 0.0056 - val_loss: 0.0600 - val_mae: 0.0045\n",
      "Epoch 18/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0583 - mae: 0.0057 - val_loss: 0.0566 - val_mae: 0.0049\n",
      "Epoch 19/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0550 - mae: 0.0055 - val_loss: 0.0534 - val_mae: 0.0072\n",
      "Epoch 20/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0520 - mae: 0.0068 - val_loss: 0.0505 - val_mae: 0.0068\n",
      "Epoch 21/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0491 - mae: 0.0052 - val_loss: 0.0477 - val_mae: 0.0056\n",
      "Epoch 22/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0464 - mae: 0.0053 - val_loss: 0.0452 - val_mae: 0.0104\n",
      "Epoch 23/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0437 - mae: 0.0050 - val_loss: 0.0425 - val_mae: 0.0059\n",
      "Epoch 24/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0413 - mae: 0.0058 - val_loss: 0.0401 - val_mae: 0.0064\n",
      "Epoch 25/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0390 - mae: 0.0053 - val_loss: 0.0380 - val_mae: 0.0114\n",
      "Epoch 26/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0368 - mae: 0.0048 - val_loss: 0.0357 - val_mae: 0.0031\n",
      "Epoch 27/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0347 - mae: 0.0055 - val_loss: 0.0337 - val_mae: 0.0041\n",
      "Epoch 28/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0327 - mae: 0.0045 - val_loss: 0.0318 - val_mae: 0.0061\n",
      "Epoch 29/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0309 - mae: 0.0048 - val_loss: 0.0299 - val_mae: 0.0037\n",
      "Epoch 30/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0290 - mae: 0.0047 - val_loss: 0.0282 - val_mae: 0.0061\n",
      "Epoch 31/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0273 - mae: 0.0049 - val_loss: 0.0265 - val_mae: 0.0041\n",
      "Epoch 32/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0257 - mae: 0.0048 - val_loss: 0.0248 - val_mae: 0.0032\n",
      "Epoch 33/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0241 - mae: 0.0043 - val_loss: 0.0234 - val_mae: 0.0035\n",
      "Epoch 34/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0227 - mae: 0.0047 - val_loss: 0.0221 - val_mae: 0.0030\n",
      "Epoch 35/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0214 - mae: 0.0042 - val_loss: 0.0207 - val_mae: 0.0034\n",
      "Epoch 36/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0201 - mae: 0.0045 - val_loss: 0.0194 - val_mae: 0.0066\n",
      "Epoch 37/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0188 - mae: 0.0047 - val_loss: 0.0182 - val_mae: 0.0053\n",
      "Epoch 38/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0176 - mae: 0.0043 - val_loss: 0.0171 - val_mae: 0.0056\n",
      "Epoch 39/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0165 - mae: 0.0043 - val_loss: 0.0160 - val_mae: 0.0076\n",
      "Epoch 40/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0155 - mae: 0.0044 - val_loss: 0.0149 - val_mae: 0.0053\n",
      "Epoch 41/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0144 - mae: 0.0040 - val_loss: 0.0139 - val_mae: 0.0044\n",
      "Epoch 42/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0135 - mae: 0.0044 - val_loss: 0.0131 - val_mae: 0.0085\n",
      "Epoch 43/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0126 - mae: 0.0039 - val_loss: 0.0121 - val_mae: 0.0027\n",
      "Epoch 44/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0117 - mae: 0.0040 - val_loss: 0.0113 - val_mae: 0.0041\n",
      "Epoch 45/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0109 - mae: 0.0038 - val_loss: 0.0105 - val_mae: 0.0045\n",
      "Epoch 46/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0101 - mae: 0.0037 - val_loss: 0.0098 - val_mae: 0.0028\n",
      "Epoch 47/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0094 - mae: 0.0039 - val_loss: 0.0091 - val_mae: 0.0057\n",
      "Epoch 48/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0088 - mae: 0.0036 - val_loss: 0.0084 - val_mae: 0.0039\n",
      "Epoch 49/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0081 - mae: 0.0038 - val_loss: 0.0079 - val_mae: 0.0066\n",
      "Epoch 50/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0076 - mae: 0.0040 - val_loss: 0.0073 - val_mae: 0.0039\n",
      "Epoch 51/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0070 - mae: 0.0035 - val_loss: 0.0068 - val_mae: 0.0051\n",
      "Epoch 52/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0066 - mae: 0.0037 - val_loss: 0.0063 - val_mae: 0.0033\n",
      "Epoch 53/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0061 - mae: 0.0038 - val_loss: 0.0060 - val_mae: 0.0075\n",
      "Epoch 54/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0057 - mae: 0.0036 - val_loss: 0.0055 - val_mae: 0.0047\n",
      "Epoch 55/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0053 - mae: 0.0035 - val_loss: 0.0052 - val_mae: 0.0075\n",
      "Epoch 56/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0050 - mae: 0.0037 - val_loss: 0.0048 - val_mae: 0.0028\n",
      "Epoch 57/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0047 - mae: 0.0039 - val_loss: 0.0045 - val_mae: 0.0050\n",
      "Epoch 58/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0044 - mae: 0.0039 - val_loss: 0.0042 - val_mae: 0.0032\n",
      "Epoch 59/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0041 - mae: 0.0037 - val_loss: 0.0041 - val_mae: 0.0091\n",
      "Epoch 60/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0039 - mae: 0.0037 - val_loss: 0.0038 - val_mae: 0.0032\n",
      "Epoch 61/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0037 - mae: 0.0037 - val_loss: 0.0036 - val_mae: 0.0032\n",
      "Epoch 62/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0035 - mae: 0.0037 - val_loss: 0.0034 - val_mae: 0.0035\n",
      "Epoch 63/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0033 - mae: 0.0037 - val_loss: 0.0032 - val_mae: 0.0037\n",
      "Epoch 64/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0031 - mae: 0.0034 - val_loss: 0.0031 - val_mae: 0.0095\n",
      "Epoch 65/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0030 - mae: 0.0036 - val_loss: 0.0029 - val_mae: 0.0029\n",
      "Epoch 66/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0028 - mae: 0.0034 - val_loss: 0.0028 - val_mae: 0.0062\n",
      "Epoch 67/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0027 - mae: 0.0041 - val_loss: 0.0026 - val_mae: 0.0032\n",
      "Epoch 68/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0025 - mae: 0.0035 - val_loss: 0.0025 - val_mae: 0.0046\n",
      "Epoch 69/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0024 - mae: 0.0036 - val_loss: 0.0024 - val_mae: 0.0028\n",
      "Epoch 70/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0023 - mae: 0.0035 - val_loss: 0.0023 - val_mae: 0.0030\n",
      "Epoch 71/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0035 - val_loss: 0.0022 - val_mae: 0.0035\n",
      "Epoch 72/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0036 - val_loss: 0.0021 - val_mae: 0.0033\n",
      "Epoch 73/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0021 - mae: 0.0037 - val_loss: 0.0021 - val_mae: 0.0052\n",
      "Epoch 74/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0020 - mae: 0.0035 - val_loss: 0.0020 - val_mae: 0.0053\n",
      "Epoch 75/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0019 - mae: 0.0035 - val_loss: 0.0019 - val_mae: 0.0026\n",
      "Epoch 76/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0019 - mae: 0.0036 - val_loss: 0.0018 - val_mae: 0.0029\n",
      "Epoch 77/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0018 - mae: 0.0037 - val_loss: 0.0018 - val_mae: 0.0033\n",
      "Epoch 78/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0018 - mae: 0.0035 - val_loss: 0.0017 - val_mae: 0.0045\n",
      "Epoch 79/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0017 - mae: 0.0036 - val_loss: 0.0017 - val_mae: 0.0037\n",
      "Epoch 80/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0017 - mae: 0.0035 - val_loss: 0.0017 - val_mae: 0.0056\n",
      "Epoch 81/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0016 - mae: 0.0037 - val_loss: 0.0017 - val_mae: 0.0084\n",
      "Epoch 82/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0016 - mae: 0.0035 - val_loss: 0.0016 - val_mae: 0.0039\n",
      "Epoch 83/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0016 - mae: 0.0036 - val_loss: 0.0015 - val_mae: 0.0034\n",
      "Epoch 84/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0015 - mae: 0.0038 - val_loss: 0.0015 - val_mae: 0.0033\n",
      "Epoch 85/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0015 - mae: 0.0036 - val_loss: 0.0015 - val_mae: 0.0029\n",
      "Epoch 86/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0015 - mae: 0.0036 - val_loss: 0.0015 - val_mae: 0.0054\n",
      "Epoch 87/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0015 - mae: 0.0038 - val_loss: 0.0014 - val_mae: 0.0030\n",
      "Epoch 88/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0014 - mae: 0.0037 - val_loss: 0.0014 - val_mae: 0.0032\n",
      "Epoch 89/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0014 - mae: 0.0039 - val_loss: 0.0014 - val_mae: 0.0043\n",
      "Epoch 90/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0014 - mae: 0.0038 - val_loss: 0.0014 - val_mae: 0.0073\n",
      "Epoch 91/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0014 - mae: 0.0037 - val_loss: 0.0014 - val_mae: 0.0035\n",
      "Epoch 92/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0014 - mae: 0.0038 - val_loss: 0.0014 - val_mae: 0.0047\n",
      "Epoch 93/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0013 - mae: 0.0037 - val_loss: 0.0013 - val_mae: 0.0041\n",
      "Epoch 94/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0013 - mae: 0.0039 - val_loss: 0.0014 - val_mae: 0.0056\n",
      "Epoch 95/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0013 - mae: 0.0037 - val_loss: 0.0013 - val_mae: 0.0068\n",
      "Epoch 96/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0013 - mae: 0.0040 - val_loss: 0.0013 - val_mae: 0.0055\n",
      "Epoch 97/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0013 - mae: 0.0036 - val_loss: 0.0013 - val_mae: 0.0038\n",
      "Epoch 98/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0013 - mae: 0.0040 - val_loss: 0.0013 - val_mae: 0.0060\n",
      "Epoch 99/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0013 - mae: 0.0039 - val_loss: 0.0013 - val_mae: 0.0034\n",
      "Epoch 100/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0013 - mae: 0.0038 - val_loss: 0.0012 - val_mae: 0.0031\n",
      "Epoch 101/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0038 - val_loss: 0.0012 - val_mae: 0.0028\n",
      "Epoch 102/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0037 - val_loss: 0.0012 - val_mae: 0.0039\n",
      "Epoch 103/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0038 - val_loss: 0.0012 - val_mae: 0.0037\n",
      "Epoch 104/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0038 - val_loss: 0.0013 - val_mae: 0.0083\n",
      "Epoch 105/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0042 - val_loss: 0.0012 - val_mae: 0.0036\n",
      "Epoch 106/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0037 - val_loss: 0.0012 - val_mae: 0.0030\n",
      "Epoch 107/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0012 - mae: 0.0038 - val_loss: 0.0012 - val_mae: 0.0032\n",
      "Epoch 108/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0012 - mae: 0.0040 - val_loss: 0.0012 - val_mae: 0.0059\n",
      "Epoch 109/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0012 - mae: 0.0036 - val_loss: 0.0014 - val_mae: 0.0139\n",
      "Epoch 110/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0012 - mae: 0.0040 - val_loss: 0.0012 - val_mae: 0.0030\n",
      "Epoch 111/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0012 - mae: 0.0039 - val_loss: 0.0012 - val_mae: 0.0046\n",
      "Epoch 112/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0012 - mae: 0.0041 - val_loss: 0.0012 - val_mae: 0.0062\n",
      "Epoch 113/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0041\n",
      "Epoch 114/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0038 - val_loss: 0.0012 - val_mae: 0.0062\n",
      "Epoch 115/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0034\n",
      "Epoch 116/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0038 - val_loss: 0.0011 - val_mae: 0.0061\n",
      "Epoch 117/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0042\n",
      "Epoch 118/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0038 - val_loss: 0.0011 - val_mae: 0.0043\n",
      "Epoch 119/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0037\n",
      "Epoch 120/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0040 - val_loss: 0.0012 - val_mae: 0.0078\n",
      "Epoch 121/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 122/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0033\n",
      "Epoch 123/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0038 - val_loss: 0.0012 - val_mae: 0.0093\n",
      "Epoch 124/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0038 - val_loss: 0.0011 - val_mae: 0.0030\n",
      "Epoch 125/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0032\n",
      "Epoch 126/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0038 - val_loss: 0.0011 - val_mae: 0.0050\n",
      "Epoch 127/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0034\n",
      "Epoch 128/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0048\n",
      "Epoch 129/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0031\n",
      "Epoch 130/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0042\n",
      "Epoch 131/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0040 - val_loss: 0.0011 - val_mae: 0.0054\n",
      "Epoch 132/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0037 - val_loss: 0.0011 - val_mae: 0.0066\n",
      "Epoch 133/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0010 - mae: 0.0039 - val_loss: 0.0010 - val_mae: 0.0028\n",
      "Epoch 134/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0010 - mae: 0.0039 - val_loss: 0.0010 - val_mae: 0.0028\n",
      "Epoch 135/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0010 - mae: 0.0038 - val_loss: 0.0010 - val_mae: 0.0045\n",
      "Epoch 136/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0010 - mae: 0.0038 - val_loss: 0.0011 - val_mae: 0.0089\n",
      "Epoch 137/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0010 - mae: 0.0039 - val_loss: 0.0010 - val_mae: 0.0056\n",
      "Epoch 138/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0010 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0077\n",
      "Epoch 139/1000\n",
      "642/645 [============================>.] - ETA: 0s - loss: 0.0010 - mae: 0.0038Restoring model weights from the end of the best epoch: 134.\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0038 - val_loss: 0.0010 - val_mae: 0.0051\n",
      "Epoch 139: early stopping\n",
      "Training fÃ¼r Fold 3...\n",
      "Epoch 1/1000\n",
      "645/645 [==============================] - 3s 3ms/step - loss: 0.2435 - mae: 0.0718 - val_loss: 0.1905 - val_mae: 0.0082\n",
      "Epoch 2/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.1704 - mae: 0.0112 - val_loss: 0.1540 - val_mae: 0.0087\n",
      "Epoch 3/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.1435 - mae: 0.0100 - val_loss: 0.1351 - val_mae: 0.0196\n",
      "Epoch 4/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.1282 - mae: 0.0113 - val_loss: 0.1329 - val_mae: 0.0810\n",
      "Epoch 5/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.1178 - mae: 0.0089 - val_loss: 0.1133 - val_mae: 0.0082\n",
      "Epoch 6/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.1094 - mae: 0.0074 - val_loss: 0.1055 - val_mae: 0.0063\n",
      "Epoch 7/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.1020 - mae: 0.0080 - val_loss: 0.0986 - val_mae: 0.0100\n",
      "Epoch 8/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0959 - mae: 0.0123 - val_loss: 0.0932 - val_mae: 0.0165\n",
      "Epoch 9/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0902 - mae: 0.0052 - val_loss: 0.0877 - val_mae: 0.0060\n",
      "Epoch 10/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0852 - mae: 0.0068 - val_loss: 0.0827 - val_mae: 0.0047\n",
      "Epoch 11/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0803 - mae: 0.0062 - val_loss: 0.0779 - val_mae: 0.0049\n",
      "Epoch 12/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0756 - mae: 0.0068 - val_loss: 0.0734 - val_mae: 0.0082\n",
      "Epoch 13/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0712 - mae: 0.0067 - val_loss: 0.0691 - val_mae: 0.0073\n",
      "Epoch 14/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0670 - mae: 0.0058 - val_loss: 0.0650 - val_mae: 0.0052\n",
      "Epoch 15/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0631 - mae: 0.0060 - val_loss: 0.0611 - val_mae: 0.0066\n",
      "Epoch 16/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0593 - mae: 0.0073 - val_loss: 0.0575 - val_mae: 0.0042\n",
      "Epoch 17/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0558 - mae: 0.0048 - val_loss: 0.0546 - val_mae: 0.0169\n",
      "Epoch 18/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0525 - mae: 0.0052 - val_loss: 0.0508 - val_mae: 0.0052\n",
      "Epoch 19/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0492 - mae: 0.0051 - val_loss: 0.0476 - val_mae: 0.0069\n",
      "Epoch 20/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0462 - mae: 0.0062 - val_loss: 0.0447 - val_mae: 0.0040\n",
      "Epoch 21/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0433 - mae: 0.0043 - val_loss: 0.0419 - val_mae: 0.0065\n",
      "Epoch 22/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0406 - mae: 0.0052 - val_loss: 0.0392 - val_mae: 0.0033\n",
      "Epoch 23/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0380 - mae: 0.0046 - val_loss: 0.0366 - val_mae: 0.0028\n",
      "Epoch 24/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0354 - mae: 0.0047 - val_loss: 0.0342 - val_mae: 0.0053\n",
      "Epoch 25/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0331 - mae: 0.0049 - val_loss: 0.0320 - val_mae: 0.0051\n",
      "Epoch 26/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0308 - mae: 0.0040 - val_loss: 0.0297 - val_mae: 0.0040\n",
      "Epoch 27/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0286 - mae: 0.0045 - val_loss: 0.0275 - val_mae: 0.0032\n",
      "Epoch 28/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0265 - mae: 0.0039 - val_loss: 0.0255 - val_mae: 0.0039\n",
      "Epoch 29/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0246 - mae: 0.0044 - val_loss: 0.0237 - val_mae: 0.0055\n",
      "Epoch 30/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0228 - mae: 0.0046 - val_loss: 0.0220 - val_mae: 0.0070\n",
      "Epoch 31/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0212 - mae: 0.0040 - val_loss: 0.0204 - val_mae: 0.0029\n",
      "Epoch 32/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0197 - mae: 0.0041 - val_loss: 0.0190 - val_mae: 0.0040\n",
      "Epoch 33/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0183 - mae: 0.0045 - val_loss: 0.0176 - val_mae: 0.0041\n",
      "Epoch 34/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0170 - mae: 0.0037 - val_loss: 0.0164 - val_mae: 0.0047\n",
      "Epoch 35/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0157 - mae: 0.0039 - val_loss: 0.0152 - val_mae: 0.0057\n",
      "Epoch 36/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0146 - mae: 0.0040 - val_loss: 0.0140 - val_mae: 0.0043\n",
      "Epoch 37/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0135 - mae: 0.0039 - val_loss: 0.0130 - val_mae: 0.0032\n",
      "Epoch 38/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0125 - mae: 0.0038 - val_loss: 0.0121 - val_mae: 0.0077\n",
      "Epoch 39/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0116 - mae: 0.0040 - val_loss: 0.0112 - val_mae: 0.0055\n",
      "Epoch 40/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0107 - mae: 0.0036 - val_loss: 0.0103 - val_mae: 0.0040\n",
      "Epoch 41/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0100 - mae: 0.0037 - val_loss: 0.0096 - val_mae: 0.0030\n",
      "Epoch 42/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0092 - mae: 0.0039 - val_loss: 0.0089 - val_mae: 0.0035\n",
      "Epoch 43/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0085 - mae: 0.0036 - val_loss: 0.0082 - val_mae: 0.0026\n",
      "Epoch 44/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0079 - mae: 0.0036 - val_loss: 0.0076 - val_mae: 0.0028\n",
      "Epoch 45/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0073 - mae: 0.0035 - val_loss: 0.0070 - val_mae: 0.0028\n",
      "Epoch 46/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0067 - mae: 0.0039 - val_loss: 0.0065 - val_mae: 0.0027\n",
      "Epoch 47/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0062 - mae: 0.0038 - val_loss: 0.0060 - val_mae: 0.0037\n",
      "Epoch 48/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0058 - mae: 0.0037 - val_loss: 0.0056 - val_mae: 0.0026\n",
      "Epoch 49/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0054 - mae: 0.0038 - val_loss: 0.0052 - val_mae: 0.0032\n",
      "Epoch 50/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0050 - mae: 0.0036 - val_loss: 0.0048 - val_mae: 0.0042\n",
      "Epoch 51/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0047 - mae: 0.0038 - val_loss: 0.0045 - val_mae: 0.0050\n",
      "Epoch 52/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0043 - mae: 0.0036 - val_loss: 0.0042 - val_mae: 0.0028\n",
      "Epoch 53/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0041 - mae: 0.0036 - val_loss: 0.0039 - val_mae: 0.0030\n",
      "Epoch 54/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0038 - mae: 0.0035 - val_loss: 0.0037 - val_mae: 0.0057\n",
      "Epoch 55/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0036 - mae: 0.0035 - val_loss: 0.0034 - val_mae: 0.0029\n",
      "Epoch 56/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0033 - mae: 0.0035 - val_loss: 0.0032 - val_mae: 0.0026\n",
      "Epoch 57/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0031 - mae: 0.0032 - val_loss: 0.0030 - val_mae: 0.0038\n",
      "Epoch 58/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0029 - mae: 0.0035 - val_loss: 0.0028 - val_mae: 0.0024\n",
      "Epoch 59/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0028 - mae: 0.0034 - val_loss: 0.0027 - val_mae: 0.0048\n",
      "Epoch 60/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0026 - mae: 0.0036 - val_loss: 0.0026 - val_mae: 0.0047\n",
      "Epoch 61/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0025 - mae: 0.0034 - val_loss: 0.0024 - val_mae: 0.0057\n",
      "Epoch 62/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0024 - mae: 0.0034 - val_loss: 0.0023 - val_mae: 0.0031\n",
      "Epoch 63/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0022 - mae: 0.0033 - val_loss: 0.0022 - val_mae: 0.0030\n",
      "Epoch 64/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0021 - mae: 0.0035 - val_loss: 0.0021 - val_mae: 0.0051\n",
      "Epoch 65/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0021 - mae: 0.0034 - val_loss: 0.0020 - val_mae: 0.0027\n",
      "Epoch 66/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0020 - mae: 0.0035 - val_loss: 0.0019 - val_mae: 0.0046\n",
      "Epoch 67/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0019 - mae: 0.0033 - val_loss: 0.0019 - val_mae: 0.0037\n",
      "Epoch 68/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0018 - mae: 0.0033 - val_loss: 0.0018 - val_mae: 0.0034\n",
      "Epoch 69/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0018 - mae: 0.0035 - val_loss: 0.0017 - val_mae: 0.0024\n",
      "Epoch 70/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0017 - mae: 0.0033 - val_loss: 0.0017 - val_mae: 0.0038\n",
      "Epoch 71/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0017 - mae: 0.0034 - val_loss: 0.0016 - val_mae: 0.0045\n",
      "Epoch 72/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0016 - mae: 0.0034 - val_loss: 0.0016 - val_mae: 0.0038\n",
      "Epoch 73/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0016 - mae: 0.0033 - val_loss: 0.0016 - val_mae: 0.0054\n",
      "Epoch 74/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0015 - mae: 0.0034 - val_loss: 0.0015 - val_mae: 0.0053\n",
      "Epoch 75/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0015 - mae: 0.0034 - val_loss: 0.0015 - val_mae: 0.0040\n",
      "Epoch 76/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0015 - mae: 0.0034 - val_loss: 0.0014 - val_mae: 0.0033\n",
      "Epoch 77/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0014 - mae: 0.0032 - val_loss: 0.0014 - val_mae: 0.0045\n",
      "Epoch 78/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0014 - mae: 0.0037 - val_loss: 0.0014 - val_mae: 0.0037\n",
      "Epoch 79/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0014 - mae: 0.0033 - val_loss: 0.0014 - val_mae: 0.0061\n",
      "Epoch 80/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0014 - mae: 0.0035 - val_loss: 0.0013 - val_mae: 0.0032\n",
      "Epoch 81/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0013 - mae: 0.0034 - val_loss: 0.0013 - val_mae: 0.0038\n",
      "Epoch 82/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0013 - mae: 0.0036 - val_loss: 0.0013 - val_mae: 0.0028\n",
      "Epoch 83/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0013 - mae: 0.0034 - val_loss: 0.0013 - val_mae: 0.0039\n",
      "Epoch 84/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0013 - mae: 0.0034 - val_loss: 0.0013 - val_mae: 0.0050\n",
      "Epoch 85/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0013 - mae: 0.0035 - val_loss: 0.0013 - val_mae: 0.0049\n",
      "Epoch 86/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0012 - mae: 0.0036 - val_loss: 0.0013 - val_mae: 0.0056\n",
      "Epoch 87/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0012 - mae: 0.0036 - val_loss: 0.0012 - val_mae: 0.0030\n",
      "Epoch 88/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0012 - mae: 0.0035 - val_loss: 0.0013 - val_mae: 0.0081\n",
      "Epoch 89/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0012 - mae: 0.0035 - val_loss: 0.0012 - val_mae: 0.0028\n",
      "Epoch 90/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0039 - val_loss: 0.0012 - val_mae: 0.0034\n",
      "Epoch 91/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0012 - mae: 0.0034 - val_loss: 0.0012 - val_mae: 0.0032\n",
      "Epoch 92/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0035 - val_loss: 0.0012 - val_mae: 0.0037\n",
      "Epoch 93/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0035 - val_loss: 0.0012 - val_mae: 0.0030\n",
      "Epoch 94/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0036 - val_loss: 0.0011 - val_mae: 0.0033\n",
      "Epoch 95/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0036 - val_loss: 0.0011 - val_mae: 0.0033\n",
      "Epoch 96/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0036 - val_loss: 0.0012 - val_mae: 0.0059\n",
      "Epoch 97/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0037 - val_loss: 0.0011 - val_mae: 0.0037\n",
      "Epoch 98/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0034 - val_loss: 0.0011 - val_mae: 0.0050\n",
      "Epoch 99/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0036 - val_loss: 0.0011 - val_mae: 0.0045\n",
      "Epoch 100/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0036 - val_loss: 0.0012 - val_mae: 0.0111\n",
      "Epoch 101/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0034 - val_loss: 0.0011 - val_mae: 0.0029\n",
      "Epoch 102/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0036 - val_loss: 0.0011 - val_mae: 0.0034\n",
      "Epoch 103/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0036 - val_loss: 0.0011 - val_mae: 0.0033\n",
      "Epoch 104/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0037 - val_loss: 0.0011 - val_mae: 0.0072\n",
      "Epoch 105/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0035 - val_loss: 0.0011 - val_mae: 0.0027\n",
      "Epoch 106/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0036 - val_loss: 0.0011 - val_mae: 0.0049\n",
      "Epoch 107/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0036 - val_loss: 0.0011 - val_mae: 0.0028\n",
      "Epoch 108/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0035 - val_loss: 0.0011 - val_mae: 0.0036\n",
      "Epoch 109/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0036 - val_loss: 0.0011 - val_mae: 0.0060\n",
      "Epoch 110/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0036 - val_loss: 0.0010 - val_mae: 0.0037\n",
      "Epoch 111/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0036 - val_loss: 0.0010 - val_mae: 0.0032\n",
      "Epoch 112/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0035 - val_loss: 0.0010 - val_mae: 0.0037\n",
      "Epoch 113/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0036 - val_loss: 0.0010 - val_mae: 0.0040\n",
      "Epoch 114/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0037 - val_loss: 0.0010 - val_mae: 0.0030\n",
      "Epoch 115/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0034 - val_loss: 0.0010 - val_mae: 0.0034\n",
      "Epoch 116/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0036 - val_loss: 0.0010 - val_mae: 0.0025\n",
      "Epoch 117/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0010 - mae: 0.0036 - val_loss: 0.0010 - val_mae: 0.0025\n",
      "Epoch 118/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0010 - mae: 0.0037 - val_loss: 0.0010 - val_mae: 0.0046\n",
      "Epoch 119/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0010 - mae: 0.0035 - val_loss: 9.9678e-04 - val_mae: 0.0026\n",
      "Epoch 120/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0010 - mae: 0.0035 - val_loss: 0.0010 - val_mae: 0.0051\n",
      "Epoch 121/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.9975e-04 - mae: 0.0036 - val_loss: 0.0011 - val_mae: 0.0113\n",
      "Epoch 122/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.9610e-04 - mae: 0.0036 - val_loss: 9.9086e-04 - val_mae: 0.0033\n",
      "Epoch 123/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.9417e-04 - mae: 0.0038 - val_loss: 9.8940e-04 - val_mae: 0.0035\n",
      "Epoch 124/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.8869e-04 - mae: 0.0035 - val_loss: 0.0010 - val_mae: 0.0080\n",
      "Epoch 125/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.8734e-04 - mae: 0.0037 - val_loss: 9.7657e-04 - val_mae: 0.0027\n",
      "Epoch 126/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.8037e-04 - mae: 0.0034 - val_loss: 9.9914e-04 - val_mae: 0.0050\n",
      "Epoch 127/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.8076e-04 - mae: 0.0037 - val_loss: 9.8628e-04 - val_mae: 0.0044\n",
      "Epoch 128/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.7666e-04 - mae: 0.0036 - val_loss: 9.7198e-04 - val_mae: 0.0034\n",
      "Epoch 129/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.7137e-04 - mae: 0.0034 - val_loss: 9.7145e-04 - val_mae: 0.0038\n",
      "Epoch 130/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.6934e-04 - mae: 0.0035 - val_loss: 0.0010 - val_mae: 0.0061\n",
      "Epoch 131/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.6917e-04 - mae: 0.0038 - val_loss: 9.7681e-04 - val_mae: 0.0045\n",
      "Epoch 132/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.6390e-04 - mae: 0.0036 - val_loss: 9.5640e-04 - val_mae: 0.0028\n",
      "Epoch 133/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.6109e-04 - mae: 0.0035 - val_loss: 9.6518e-04 - val_mae: 0.0042\n",
      "Epoch 134/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.5864e-04 - mae: 0.0036 - val_loss: 9.6332e-04 - val_mae: 0.0044\n",
      "Epoch 135/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.5559e-04 - mae: 0.0035 - val_loss: 9.7129e-04 - val_mae: 0.0054\n",
      "Epoch 136/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.5402e-04 - mae: 0.0037 - val_loss: 9.5504e-04 - val_mae: 0.0041\n",
      "Epoch 137/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.4974e-04 - mae: 0.0035 - val_loss: 0.0010 - val_mae: 0.0100\n",
      "Epoch 138/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.4932e-04 - mae: 0.0037 - val_loss: 9.4090e-04 - val_mae: 0.0030\n",
      "Epoch 139/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.4576e-04 - mae: 0.0036 - val_loss: 9.5221e-04 - val_mae: 0.0040\n",
      "Epoch 140/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.4303e-04 - mae: 0.0036 - val_loss: 9.3724e-04 - val_mae: 0.0033\n",
      "Epoch 141/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.3965e-04 - mae: 0.0035 - val_loss: 9.3336e-04 - val_mae: 0.0030\n",
      "Epoch 142/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.3722e-04 - mae: 0.0035 - val_loss: 9.2928e-04 - val_mae: 0.0029\n",
      "Epoch 143/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.3542e-04 - mae: 0.0036 - val_loss: 9.3176e-04 - val_mae: 0.0033\n",
      "Epoch 144/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.3293e-04 - mae: 0.0036 - val_loss: 9.4096e-04 - val_mae: 0.0048\n",
      "Epoch 145/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.3103e-04 - mae: 0.0036 - val_loss: 9.3103e-04 - val_mae: 0.0039\n",
      "Epoch 146/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.2697e-04 - mae: 0.0035 - val_loss: 9.3269e-04 - val_mae: 0.0044\n",
      "Epoch 147/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.2548e-04 - mae: 0.0035 - val_loss: 9.1979e-04 - val_mae: 0.0033\n",
      "Epoch 148/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.2378e-04 - mae: 0.0036 - val_loss: 9.1354e-04 - val_mae: 0.0028\n",
      "Epoch 149/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.1964e-04 - mae: 0.0034 - val_loss: 9.2058e-04 - val_mae: 0.0036\n",
      "Epoch 150/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.1862e-04 - mae: 0.0036 - val_loss: 9.1854e-04 - val_mae: 0.0037\n",
      "Epoch 151/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.1745e-04 - mae: 0.0036 - val_loss: 9.5227e-04 - val_mae: 0.0064\n",
      "Epoch 152/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.1567e-04 - mae: 0.0037 - val_loss: 9.3016e-04 - val_mae: 0.0055\n",
      "Epoch 153/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.1004e-04 - mae: 0.0033 - val_loss: 9.0470e-04 - val_mae: 0.0028\n",
      "Epoch 154/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.1100e-04 - mae: 0.0036 - val_loss: 9.2133e-04 - val_mae: 0.0049\n",
      "Epoch 155/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.0985e-04 - mae: 0.0037 - val_loss: 9.2779e-04 - val_mae: 0.0056\n",
      "Epoch 156/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.0713e-04 - mae: 0.0037 - val_loss: 9.1142e-04 - val_mae: 0.0042\n",
      "Epoch 157/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.0178e-04 - mae: 0.0034 - val_loss: 9.0282e-04 - val_mae: 0.0037\n",
      "Epoch 158/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.0157e-04 - mae: 0.0035 - val_loss: 9.1994e-04 - val_mae: 0.0053\n",
      "Epoch 159/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 8.9942e-04 - mae: 0.0035 - val_loss: 9.0702e-04 - val_mae: 0.0046\n",
      "Epoch 160/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.0013e-04 - mae: 0.0038 - val_loss: 8.9852e-04 - val_mae: 0.0040\n",
      "Epoch 161/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 8.9349e-04 - mae: 0.0033 - val_loss: 9.0067e-04 - val_mae: 0.0044\n",
      "Epoch 162/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 8.9375e-04 - mae: 0.0035 - val_loss: 9.1947e-04 - val_mae: 0.0062\n",
      "Epoch 163/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 8.9150e-04 - mae: 0.0035 - val_loss: 9.4495e-04 - val_mae: 0.0080\n",
      "Epoch 164/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 8.8852e-04 - mae: 0.0034 - val_loss: 8.8030e-04 - val_mae: 0.0025\n",
      "Epoch 165/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 8.8701e-04 - mae: 0.0034 - val_loss: 8.8770e-04 - val_mae: 0.0037\n",
      "Epoch 166/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 8.8530e-04 - mae: 0.0034 - val_loss: 8.7987e-04 - val_mae: 0.0031\n",
      "Epoch 167/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 8.8376e-04 - mae: 0.0035 - val_loss: 9.0539e-04 - val_mae: 0.0051\n",
      "Epoch 168/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 8.8265e-04 - mae: 0.0036 - val_loss: 8.7563e-04 - val_mae: 0.0029\n",
      "Epoch 169/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 8.7999e-04 - mae: 0.0035 - val_loss: 8.7379e-04 - val_mae: 0.0029\n",
      "Epoch 170/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 8.7814e-04 - mae: 0.0035 - val_loss: 8.7233e-04 - val_mae: 0.0029\n",
      "Epoch 171/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 8.7679e-04 - mae: 0.0035 - val_loss: 8.7905e-04 - val_mae: 0.0042\n",
      "Epoch 172/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 8.7796e-04 - mae: 0.0037 - val_loss: 8.7822e-04 - val_mae: 0.0040\n",
      "Epoch 173/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 8.7292e-04 - mae: 0.0034 - val_loss: 8.6526e-04 - val_mae: 0.0027\n",
      "Epoch 174/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 8.7173e-04 - mae: 0.0035 - val_loss: 8.6264e-04 - val_mae: 0.0025\n",
      "Epoch 175/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 8.7079e-04 - mae: 0.0035 - val_loss: 8.6065e-04 - val_mae: 0.0025\n",
      "Epoch 176/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 8.6837e-04 - mae: 0.0035 - val_loss: 8.6723e-04 - val_mae: 0.0033\n",
      "Epoch 177/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 8.6675e-04 - mae: 0.0034 - val_loss: 8.6009e-04 - val_mae: 0.0030\n",
      "Epoch 178/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 8.6537e-04 - mae: 0.0035 - val_loss: 8.7227e-04 - val_mae: 0.0041\n",
      "Epoch 179/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 8.6272e-04 - mae: 0.0034 - val_loss: 8.6213e-04 - val_mae: 0.0036\n",
      "Epoch 180/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 8.6514e-04 - mae: 0.0037 - val_loss: 8.5664e-04 - val_mae: 0.0031\n",
      "Epoch 181/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 8.6045e-04 - mae: 0.0034 - val_loss: 8.5218e-04 - val_mae: 0.0026\n",
      "Epoch 182/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 8.5926e-04 - mae: 0.0035 - val_loss: 8.5158e-04 - val_mae: 0.0025\n",
      "Epoch 183/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 8.5799e-04 - mae: 0.0035 - val_loss: 8.6126e-04 - val_mae: 0.0041\n",
      "Epoch 184/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 8.5616e-04 - mae: 0.0034 - val_loss: 8.6385e-04 - val_mae: 0.0043\n",
      "Epoch 185/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 8.5796e-04 - mae: 0.0037 - val_loss: 8.5173e-04 - val_mae: 0.0036\n",
      "Epoch 186/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 8.5514e-04 - mae: 0.0036 - val_loss: 8.8000e-04 - val_mae: 0.0063\n",
      "Epoch 187/1000\n",
      "636/645 [============================>.] - ETA: 0s - loss: 8.5346e-04 - mae: 0.0036Restoring model weights from the end of the best epoch: 182.\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 8.5338e-04 - mae: 0.0036 - val_loss: 8.6354e-04 - val_mae: 0.0049\n",
      "Epoch 187: early stopping\n",
      "Training fÃ¼r Fold 4...\n",
      "Epoch 1/1000\n",
      "645/645 [==============================] - 3s 3ms/step - loss: 0.3462 - mae: 0.2410 - val_loss: 0.2007 - val_mae: 0.0585\n",
      "Epoch 2/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.1775 - mae: 0.0214 - val_loss: 0.1620 - val_mae: 0.0096\n",
      "Epoch 3/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.1528 - mae: 0.0117 - val_loss: 0.1457 - val_mae: 0.0226\n",
      "Epoch 4/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.1396 - mae: 0.0106 - val_loss: 0.1346 - val_mae: 0.0057\n",
      "Epoch 5/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.1308 - mae: 0.0109 - val_loss: 0.1271 - val_mae: 0.0155\n",
      "Epoch 6/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.1236 - mae: 0.0130 - val_loss: 0.1201 - val_mae: 0.0096\n",
      "Epoch 7/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.1170 - mae: 0.0089 - val_loss: 0.1138 - val_mae: 0.0086\n",
      "Epoch 8/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.1108 - mae: 0.0095 - val_loss: 0.1077 - val_mae: 0.0058\n",
      "Epoch 9/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.1050 - mae: 0.0101 - val_loss: 0.1019 - val_mae: 0.0043\n",
      "Epoch 10/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0995 - mae: 0.0110 - val_loss: 0.0966 - val_mae: 0.0068\n",
      "Epoch 11/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0941 - mae: 0.0073 - val_loss: 0.0919 - val_mae: 0.0178\n",
      "Epoch 12/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0891 - mae: 0.0096 - val_loss: 0.0865 - val_mae: 0.0069\n",
      "Epoch 13/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0842 - mae: 0.0066 - val_loss: 0.0819 - val_mae: 0.0091\n",
      "Epoch 14/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0796 - mae: 0.0077 - val_loss: 0.0773 - val_mae: 0.0054\n",
      "Epoch 15/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0754 - mae: 0.0093 - val_loss: 0.0733 - val_mae: 0.0085\n",
      "Epoch 16/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0713 - mae: 0.0068 - val_loss: 0.0697 - val_mae: 0.0153\n",
      "Epoch 17/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0675 - mae: 0.0068 - val_loss: 0.0656 - val_mae: 0.0062\n",
      "Epoch 18/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0639 - mae: 0.0074 - val_loss: 0.0620 - val_mae: 0.0042\n",
      "Epoch 19/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0604 - mae: 0.0067 - val_loss: 0.0587 - val_mae: 0.0041\n",
      "Epoch 20/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0572 - mae: 0.0058 - val_loss: 0.0555 - val_mae: 0.0049\n",
      "Epoch 21/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0541 - mae: 0.0066 - val_loss: 0.0525 - val_mae: 0.0051\n",
      "Epoch 22/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0511 - mae: 0.0062 - val_loss: 0.0496 - val_mae: 0.0065\n",
      "Epoch 23/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0482 - mae: 0.0057 - val_loss: 0.0480 - val_mae: 0.0269\n",
      "Epoch 24/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0456 - mae: 0.0059 - val_loss: 0.0444 - val_mae: 0.0075\n",
      "Epoch 25/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0431 - mae: 0.0056 - val_loss: 0.0418 - val_mae: 0.0052\n",
      "Epoch 26/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0407 - mae: 0.0061 - val_loss: 0.0395 - val_mae: 0.0071\n",
      "Epoch 27/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0383 - mae: 0.0053 - val_loss: 0.0372 - val_mae: 0.0047\n",
      "Epoch 28/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0361 - mae: 0.0056 - val_loss: 0.0350 - val_mae: 0.0049\n",
      "Epoch 29/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0340 - mae: 0.0059 - val_loss: 0.0329 - val_mae: 0.0039\n",
      "Epoch 30/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0319 - mae: 0.0053 - val_loss: 0.0309 - val_mae: 0.0077\n",
      "Epoch 31/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0298 - mae: 0.0053 - val_loss: 0.0288 - val_mae: 0.0042\n",
      "Epoch 32/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0278 - mae: 0.0051 - val_loss: 0.0269 - val_mae: 0.0059\n",
      "Epoch 33/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0260 - mae: 0.0052 - val_loss: 0.0251 - val_mae: 0.0074\n",
      "Epoch 34/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0242 - mae: 0.0050 - val_loss: 0.0233 - val_mae: 0.0050\n",
      "Epoch 35/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0225 - mae: 0.0049 - val_loss: 0.0216 - val_mae: 0.0044\n",
      "Epoch 36/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0209 - mae: 0.0050 - val_loss: 0.0202 - val_mae: 0.0102\n",
      "Epoch 37/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0194 - mae: 0.0047 - val_loss: 0.0186 - val_mae: 0.0039\n",
      "Epoch 38/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0180 - mae: 0.0047 - val_loss: 0.0173 - val_mae: 0.0049\n",
      "Epoch 39/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0166 - mae: 0.0048 - val_loss: 0.0160 - val_mae: 0.0047\n",
      "Epoch 40/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0154 - mae: 0.0046 - val_loss: 0.0148 - val_mae: 0.0042\n",
      "Epoch 41/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0142 - mae: 0.0044 - val_loss: 0.0136 - val_mae: 0.0043\n",
      "Epoch 42/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0131 - mae: 0.0043 - val_loss: 0.0125 - val_mae: 0.0048\n",
      "Epoch 43/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0120 - mae: 0.0042 - val_loss: 0.0115 - val_mae: 0.0050\n",
      "Epoch 44/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0110 - mae: 0.0042 - val_loss: 0.0106 - val_mae: 0.0038\n",
      "Epoch 45/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0102 - mae: 0.0039 - val_loss: 0.0097 - val_mae: 0.0055\n",
      "Epoch 46/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0093 - mae: 0.0042 - val_loss: 0.0089 - val_mae: 0.0041\n",
      "Epoch 47/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0085 - mae: 0.0042 - val_loss: 0.0082 - val_mae: 0.0031\n",
      "Epoch 48/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0078 - mae: 0.0039 - val_loss: 0.0075 - val_mae: 0.0041\n",
      "Epoch 49/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0072 - mae: 0.0041 - val_loss: 0.0069 - val_mae: 0.0041\n",
      "Epoch 50/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0066 - mae: 0.0040 - val_loss: 0.0063 - val_mae: 0.0033\n",
      "Epoch 51/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0061 - mae: 0.0042 - val_loss: 0.0059 - val_mae: 0.0042\n",
      "Epoch 52/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0056 - mae: 0.0039 - val_loss: 0.0054 - val_mae: 0.0038\n",
      "Epoch 53/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0052 - mae: 0.0041 - val_loss: 0.0050 - val_mae: 0.0049\n",
      "Epoch 54/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0049 - mae: 0.0040 - val_loss: 0.0047 - val_mae: 0.0054\n",
      "Epoch 55/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0046 - mae: 0.0042 - val_loss: 0.0044 - val_mae: 0.0043\n",
      "Epoch 56/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0043 - mae: 0.0038 - val_loss: 0.0041 - val_mae: 0.0035\n",
      "Epoch 57/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0040 - mae: 0.0040 - val_loss: 0.0039 - val_mae: 0.0040\n",
      "Epoch 58/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0038 - mae: 0.0040 - val_loss: 0.0037 - val_mae: 0.0053\n",
      "Epoch 59/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0035 - mae: 0.0041 - val_loss: 0.0035 - val_mae: 0.0066\n",
      "Epoch 60/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0034 - mae: 0.0040 - val_loss: 0.0033 - val_mae: 0.0062\n",
      "Epoch 61/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0032 - mae: 0.0039 - val_loss: 0.0031 - val_mae: 0.0041\n",
      "Epoch 62/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0030 - mae: 0.0039 - val_loss: 0.0029 - val_mae: 0.0036\n",
      "Epoch 63/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0029 - mae: 0.0040 - val_loss: 0.0028 - val_mae: 0.0040\n",
      "Epoch 64/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0028 - mae: 0.0041 - val_loss: 0.0028 - val_mae: 0.0092\n",
      "Epoch 65/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0026 - mae: 0.0041 - val_loss: 0.0026 - val_mae: 0.0032\n",
      "Epoch 66/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0025 - mae: 0.0039 - val_loss: 0.0025 - val_mae: 0.0044\n",
      "Epoch 67/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0024 - mae: 0.0041 - val_loss: 0.0024 - val_mae: 0.0062\n",
      "Epoch 68/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0024 - mae: 0.0041 - val_loss: 0.0023 - val_mae: 0.0034\n",
      "Epoch 69/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0023 - mae: 0.0040 - val_loss: 0.0023 - val_mae: 0.0082\n",
      "Epoch 70/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0042 - val_loss: 0.0022 - val_mae: 0.0036\n",
      "Epoch 71/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0021 - mae: 0.0041 - val_loss: 0.0021 - val_mae: 0.0030\n",
      "Epoch 72/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0021 - mae: 0.0040 - val_loss: 0.0021 - val_mae: 0.0039\n",
      "Epoch 73/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0020 - mae: 0.0039 - val_loss: 0.0021 - val_mae: 0.0067\n",
      "Epoch 74/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0020 - mae: 0.0042 - val_loss: 0.0020 - val_mae: 0.0042\n",
      "Epoch 75/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0019 - mae: 0.0042 - val_loss: 0.0019 - val_mae: 0.0064\n",
      "Epoch 76/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0019 - mae: 0.0042 - val_loss: 0.0019 - val_mae: 0.0050\n",
      "Epoch 77/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0019 - mae: 0.0040 - val_loss: 0.0018 - val_mae: 0.0032\n",
      "Epoch 78/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0018 - mae: 0.0041 - val_loss: 0.0018 - val_mae: 0.0055\n",
      "Epoch 79/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0018 - mae: 0.0040 - val_loss: 0.0018 - val_mae: 0.0037\n",
      "Epoch 80/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0018 - mae: 0.0043 - val_loss: 0.0018 - val_mae: 0.0057\n",
      "Epoch 81/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0017 - mae: 0.0042 - val_loss: 0.0017 - val_mae: 0.0046\n",
      "Epoch 82/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0017 - mae: 0.0039 - val_loss: 0.0017 - val_mae: 0.0040\n",
      "Epoch 83/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0017 - mae: 0.0043 - val_loss: 0.0017 - val_mae: 0.0031\n",
      "Epoch 84/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0017 - mae: 0.0039 - val_loss: 0.0016 - val_mae: 0.0033\n",
      "Epoch 85/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0016 - mae: 0.0043 - val_loss: 0.0016 - val_mae: 0.0047\n",
      "Epoch 86/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0016 - mae: 0.0040 - val_loss: 0.0016 - val_mae: 0.0034\n",
      "Epoch 87/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0016 - mae: 0.0040 - val_loss: 0.0016 - val_mae: 0.0069\n",
      "Epoch 88/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0016 - mae: 0.0041 - val_loss: 0.0016 - val_mae: 0.0045\n",
      "Epoch 89/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0015 - mae: 0.0039 - val_loss: 0.0015 - val_mae: 0.0047\n",
      "Epoch 90/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0015 - mae: 0.0041 - val_loss: 0.0015 - val_mae: 0.0036\n",
      "Epoch 91/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0051\n",
      "Epoch 92/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0040\n",
      "Epoch 93/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0015 - mae: 0.0041 - val_loss: 0.0015 - val_mae: 0.0047\n",
      "Epoch 94/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0015 - mae: 0.0039 - val_loss: 0.0015 - val_mae: 0.0040\n",
      "Epoch 95/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0014 - mae: 0.0040 - val_loss: 0.0014 - val_mae: 0.0033\n",
      "Epoch 96/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0014 - mae: 0.0041 - val_loss: 0.0014 - val_mae: 0.0060\n",
      "Epoch 97/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0014 - mae: 0.0041 - val_loss: 0.0014 - val_mae: 0.0053\n",
      "Epoch 98/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0014 - mae: 0.0041 - val_loss: 0.0014 - val_mae: 0.0037\n",
      "Epoch 99/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0053\n",
      "Epoch 100/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0014 - mae: 0.0038 - val_loss: 0.0014 - val_mae: 0.0039\n",
      "Epoch 101/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0014 - mae: 0.0040 - val_loss: 0.0014 - val_mae: 0.0046\n",
      "Epoch 102/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0014 - mae: 0.0041 - val_loss: 0.0013 - val_mae: 0.0034\n",
      "Epoch 103/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0013 - mae: 0.0040 - val_loss: 0.0013 - val_mae: 0.0044\n",
      "Epoch 104/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0013 - mae: 0.0040 - val_loss: 0.0013 - val_mae: 0.0029\n",
      "Epoch 105/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0041 - val_loss: 0.0013 - val_mae: 0.0036\n",
      "Epoch 106/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0048\n",
      "Epoch 107/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0032\n",
      "Epoch 108/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0031\n",
      "Epoch 109/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0040 - val_loss: 0.0013 - val_mae: 0.0028\n",
      "Epoch 110/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0041 - val_loss: 0.0013 - val_mae: 0.0053\n",
      "Epoch 111/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0033\n",
      "Epoch 112/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0013 - mae: 0.0040 - val_loss: 0.0013 - val_mae: 0.0057\n",
      "Epoch 113/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0054\n",
      "Epoch 114/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0012 - mae: 0.0041 - val_loss: 0.0012 - val_mae: 0.0046\n",
      "Epoch 115/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0012 - mae: 0.0042 - val_loss: 0.0012 - val_mae: 0.0031\n",
      "Epoch 116/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0032\n",
      "Epoch 117/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0064\n",
      "Epoch 118/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0012 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0115\n",
      "Epoch 119/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0046\n",
      "Epoch 120/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0012 - mae: 0.0039 - val_loss: 0.0012 - val_mae: 0.0030\n",
      "Epoch 121/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0012 - mae: 0.0042 - val_loss: 0.0012 - val_mae: 0.0037\n",
      "Epoch 122/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0012 - mae: 0.0042 - val_loss: 0.0012 - val_mae: 0.0032\n",
      "Epoch 123/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0012 - mae: 0.0042 - val_loss: 0.0012 - val_mae: 0.0040\n",
      "Epoch 124/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0036\n",
      "Epoch 125/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0012 - mae: 0.0040 - val_loss: 0.0012 - val_mae: 0.0032\n",
      "Epoch 126/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0042 - val_loss: 0.0012 - val_mae: 0.0046\n",
      "Epoch 127/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0041 - val_loss: 0.0012 - val_mae: 0.0074\n",
      "Epoch 128/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0042\n",
      "Epoch 129/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0012 - val_mae: 0.0053\n",
      "Epoch 130/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0070\n",
      "Epoch 131/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0090\n",
      "Epoch 132/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 133/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0051\n",
      "Epoch 134/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0013 - val_mae: 0.0110\n",
      "Epoch 135/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0061\n",
      "Epoch 136/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0066\n",
      "Epoch 137/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0044 - val_loss: 0.0011 - val_mae: 0.0029\n",
      "Epoch 138/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0053\n",
      "Epoch 139/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0050\n",
      "Epoch 140/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0036\n",
      "Epoch 141/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0033\n",
      "Epoch 142/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0041\n",
      "Epoch 143/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0044 - val_loss: 0.0011 - val_mae: 0.0044\n",
      "Epoch 144/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0041\n",
      "Epoch 145/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0074\n",
      "Epoch 146/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0033\n",
      "Epoch 147/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0053\n",
      "Epoch 148/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0037\n",
      "Epoch 149/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0056\n",
      "Epoch 150/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0044 - val_loss: 0.0011 - val_mae: 0.0053\n",
      "Epoch 151/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0010 - mae: 0.0042 - val_loss: 0.0012 - val_mae: 0.0107\n",
      "Epoch 152/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0010 - mae: 0.0042 - val_loss: 0.0010 - val_mae: 0.0034\n",
      "Epoch 153/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0010 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0082\n",
      "Epoch 154/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0010 - mae: 0.0043 - val_loss: 0.0010 - val_mae: 0.0029\n",
      "Epoch 155/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0010 - mae: 0.0044 - val_loss: 0.0010 - val_mae: 0.0048\n",
      "Epoch 156/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0010 - mae: 0.0042 - val_loss: 0.0012 - val_mae: 0.0122\n",
      "Epoch 157/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0010 - mae: 0.0042 - val_loss: 0.0010 - val_mae: 0.0034\n",
      "Epoch 158/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0010 - mae: 0.0043 - val_loss: 0.0010 - val_mae: 0.0049\n",
      "Epoch 159/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0010 - mae: 0.0043 - val_loss: 0.0010 - val_mae: 0.0061\n",
      "Epoch 160/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0010 - mae: 0.0045 - val_loss: 0.0010 - val_mae: 0.0054\n",
      "Epoch 161/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0010 - mae: 0.0041 - val_loss: 0.0010 - val_mae: 0.0034\n",
      "Epoch 162/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0010 - mae: 0.0041 - val_loss: 9.9831e-04 - val_mae: 0.0038\n",
      "Epoch 163/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0042 - val_loss: 9.9335e-04 - val_mae: 0.0033\n",
      "Epoch 164/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.9806e-04 - mae: 0.0040 - val_loss: 0.0010 - val_mae: 0.0044\n",
      "Epoch 165/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0046 - val_loss: 9.8592e-04 - val_mae: 0.0033\n",
      "Epoch 166/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.9379e-04 - mae: 0.0041 - val_loss: 9.9055e-04 - val_mae: 0.0040\n",
      "Epoch 167/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.9260e-04 - mae: 0.0043 - val_loss: 0.0010 - val_mae: 0.0070\n",
      "Epoch 168/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.9284e-04 - mae: 0.0045 - val_loss: 9.7703e-04 - val_mae: 0.0033\n",
      "Epoch 169/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.8780e-04 - mae: 0.0043 - val_loss: 9.7600e-04 - val_mae: 0.0035\n",
      "Epoch 170/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.8203e-04 - mae: 0.0041 - val_loss: 9.8514e-04 - val_mae: 0.0047\n",
      "Epoch 171/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.8123e-04 - mae: 0.0042 - val_loss: 9.8389e-04 - val_mae: 0.0047\n",
      "Epoch 172/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.7822e-04 - mae: 0.0043 - val_loss: 9.6734e-04 - val_mae: 0.0034\n",
      "Epoch 173/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.7737e-04 - mae: 0.0044 - val_loss: 9.6327e-04 - val_mae: 0.0032\n",
      "Epoch 174/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.7183e-04 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0110\n",
      "Epoch 175/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.7024e-04 - mae: 0.0042 - val_loss: 9.5584e-04 - val_mae: 0.0032\n",
      "Epoch 176/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.7119e-04 - mae: 0.0045 - val_loss: 0.0010 - val_mae: 0.0085\n",
      "Epoch 177/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.6307e-04 - mae: 0.0041 - val_loss: 9.5494e-04 - val_mae: 0.0035\n",
      "Epoch 178/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.6341e-04 - mae: 0.0042 - val_loss: 9.5717e-04 - val_mae: 0.0041\n",
      "Epoch 179/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.6081e-04 - mae: 0.0043 - val_loss: 9.5702e-04 - val_mae: 0.0044\n",
      "Epoch 180/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.5785e-04 - mae: 0.0042 - val_loss: 9.4436e-04 - val_mae: 0.0032\n",
      "Epoch 181/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.5611e-04 - mae: 0.0043 - val_loss: 9.6319e-04 - val_mae: 0.0051\n",
      "Epoch 182/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.5419e-04 - mae: 0.0043 - val_loss: 9.3936e-04 - val_mae: 0.0030\n",
      "Epoch 183/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.4991e-04 - mae: 0.0042 - val_loss: 9.4483e-04 - val_mae: 0.0043\n",
      "Epoch 184/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.5127e-04 - mae: 0.0044 - val_loss: 9.5032e-04 - val_mae: 0.0047\n",
      "Epoch 185/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.4268e-04 - mae: 0.0039 - val_loss: 9.3399e-04 - val_mae: 0.0033\n",
      "Epoch 186/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.4599e-04 - mae: 0.0044 - val_loss: 9.5367e-04 - val_mae: 0.0055\n",
      "Epoch 187/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.4010e-04 - mae: 0.0040 - val_loss: 9.5227e-04 - val_mae: 0.0053\n",
      "Epoch 188/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.3878e-04 - mae: 0.0042 - val_loss: 9.3045e-04 - val_mae: 0.0037\n",
      "Epoch 189/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.3790e-04 - mae: 0.0042 - val_loss: 9.4186e-04 - val_mae: 0.0048\n",
      "Epoch 190/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.3508e-04 - mae: 0.0042 - val_loss: 9.2543e-04 - val_mae: 0.0036\n",
      "Epoch 191/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.3480e-04 - mae: 0.0043 - val_loss: 9.2061e-04 - val_mae: 0.0031\n",
      "Epoch 192/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.2803e-04 - mae: 0.0039 - val_loss: 9.2615e-04 - val_mae: 0.0038\n",
      "Epoch 193/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.3213e-04 - mae: 0.0044 - val_loss: 9.2243e-04 - val_mae: 0.0039\n",
      "Epoch 194/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.2571e-04 - mae: 0.0040 - val_loss: 9.2380e-04 - val_mae: 0.0043\n",
      "Epoch 195/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.2800e-04 - mae: 0.0043 - val_loss: 9.1635e-04 - val_mae: 0.0035\n",
      "Epoch 196/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.2281e-04 - mae: 0.0041 - val_loss: 9.1476e-04 - val_mae: 0.0034\n",
      "Epoch 197/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.2423e-04 - mae: 0.0043 - val_loss: 0.0010 - val_mae: 0.0098\n",
      "Epoch 198/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.1929e-04 - mae: 0.0041 - val_loss: 9.2419e-04 - val_mae: 0.0045\n",
      "Epoch 199/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.1751e-04 - mae: 0.0040 - val_loss: 9.1900e-04 - val_mae: 0.0044\n",
      "Epoch 200/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.1825e-04 - mae: 0.0043 - val_loss: 9.4645e-04 - val_mae: 0.0070\n",
      "Epoch 201/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.1737e-04 - mae: 0.0043 - val_loss: 9.1011e-04 - val_mae: 0.0037\n",
      "Epoch 202/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.1810e-04 - mae: 0.0045 - val_loss: 9.8396e-04 - val_mae: 0.0084\n",
      "Epoch 203/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.1182e-04 - mae: 0.0041 - val_loss: 9.2706e-04 - val_mae: 0.0059\n",
      "Epoch 204/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.1145e-04 - mae: 0.0042 - val_loss: 9.1010e-04 - val_mae: 0.0042\n",
      "Epoch 205/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.1005e-04 - mae: 0.0042 - val_loss: 9.1690e-04 - val_mae: 0.0053\n",
      "Epoch 206/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.0954e-04 - mae: 0.0042 - val_loss: 8.9636e-04 - val_mae: 0.0031\n",
      "Epoch 207/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.0667e-04 - mae: 0.0041 - val_loss: 9.2885e-04 - val_mae: 0.0054\n",
      "Epoch 208/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.0655e-04 - mae: 0.0042 - val_loss: 9.2102e-04 - val_mae: 0.0060\n",
      "Epoch 209/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.0150e-04 - mae: 0.0040 - val_loss: 8.9316e-04 - val_mae: 0.0032\n",
      "Epoch 210/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.0442e-04 - mae: 0.0043 - val_loss: 8.9727e-04 - val_mae: 0.0041\n",
      "Epoch 211/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.0089e-04 - mae: 0.0041 - val_loss: 9.0597e-04 - val_mae: 0.0048\n",
      "Epoch 212/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.0032e-04 - mae: 0.0042 - val_loss: 8.9169e-04 - val_mae: 0.0036\n",
      "Epoch 213/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.0065e-04 - mae: 0.0043 - val_loss: 9.1713e-04 - val_mae: 0.0062\n",
      "Epoch 214/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 8.9904e-04 - mae: 0.0043 - val_loss: 8.8302e-04 - val_mae: 0.0028\n",
      "Epoch 215/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 8.9491e-04 - mae: 0.0040 - val_loss: 9.0344e-04 - val_mae: 0.0052\n",
      "Epoch 216/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 8.9438e-04 - mae: 0.0041 - val_loss: 9.0939e-04 - val_mae: 0.0053\n",
      "Epoch 217/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 8.9433e-04 - mae: 0.0042 - val_loss: 9.1883e-04 - val_mae: 0.0066\n",
      "Epoch 218/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 8.9438e-04 - mae: 0.0042 - val_loss: 9.0662e-04 - val_mae: 0.0056\n",
      "Epoch 219/1000\n",
      "632/645 [============================>.] - ETA: 0s - loss: 8.9195e-04 - mae: 0.0042Restoring model weights from the end of the best epoch: 214.\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 8.9191e-04 - mae: 0.0042 - val_loss: 8.8857e-04 - val_mae: 0.0043\n",
      "Epoch 219: early stopping\n",
      "Training fÃ¼r Fold 5...\n",
      "Epoch 1/1000\n",
      "645/645 [==============================] - 3s 3ms/step - loss: 0.2646 - mae: 0.1180 - val_loss: 0.1873 - val_mae: 0.0143\n",
      "Epoch 2/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.1661 - mae: 0.0079 - val_loss: 0.1497 - val_mae: 0.0131\n",
      "Epoch 3/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.1390 - mae: 0.0079 - val_loss: 0.1302 - val_mae: 0.0047\n",
      "Epoch 4/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.1242 - mae: 0.0084 - val_loss: 0.1191 - val_mae: 0.0178\n",
      "Epoch 5/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.1143 - mae: 0.0081 - val_loss: 0.1100 - val_mae: 0.0057\n",
      "Epoch 6/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.1063 - mae: 0.0072 - val_loss: 0.1026 - val_mae: 0.0059\n",
      "Epoch 7/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0994 - mae: 0.0081 - val_loss: 0.0961 - val_mae: 0.0094\n",
      "Epoch 8/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0929 - mae: 0.0061 - val_loss: 0.0898 - val_mae: 0.0030\n",
      "Epoch 9/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0870 - mae: 0.0076 - val_loss: 0.0841 - val_mae: 0.0034\n",
      "Epoch 10/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0817 - mae: 0.0082 - val_loss: 0.0792 - val_mae: 0.0088\n",
      "Epoch 11/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0768 - mae: 0.0057 - val_loss: 0.0744 - val_mae: 0.0067\n",
      "Epoch 12/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0722 - mae: 0.0063 - val_loss: 0.0699 - val_mae: 0.0052\n",
      "Epoch 13/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0679 - mae: 0.0066 - val_loss: 0.0658 - val_mae: 0.0056\n",
      "Epoch 14/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0638 - mae: 0.0056 - val_loss: 0.0621 - val_mae: 0.0133\n",
      "Epoch 15/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0601 - mae: 0.0060 - val_loss: 0.0583 - val_mae: 0.0076\n",
      "Epoch 16/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0565 - mae: 0.0054 - val_loss: 0.0548 - val_mae: 0.0036\n",
      "Epoch 17/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0532 - mae: 0.0060 - val_loss: 0.0516 - val_mae: 0.0042\n",
      "Epoch 18/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0502 - mae: 0.0058 - val_loss: 0.0487 - val_mae: 0.0062\n",
      "Epoch 19/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0473 - mae: 0.0053 - val_loss: 0.0460 - val_mae: 0.0063\n",
      "Epoch 20/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0447 - mae: 0.0055 - val_loss: 0.0434 - val_mae: 0.0043\n",
      "Epoch 21/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0422 - mae: 0.0051 - val_loss: 0.0410 - val_mae: 0.0037\n",
      "Epoch 22/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0398 - mae: 0.0055 - val_loss: 0.0386 - val_mae: 0.0030\n",
      "Epoch 23/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0375 - mae: 0.0045 - val_loss: 0.0364 - val_mae: 0.0058\n",
      "Epoch 24/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0354 - mae: 0.0051 - val_loss: 0.0345 - val_mae: 0.0119\n",
      "Epoch 25/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0333 - mae: 0.0053 - val_loss: 0.0323 - val_mae: 0.0054\n",
      "Epoch 26/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0314 - mae: 0.0047 - val_loss: 0.0304 - val_mae: 0.0032\n",
      "Epoch 27/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0296 - mae: 0.0050 - val_loss: 0.0287 - val_mae: 0.0055\n",
      "Epoch 28/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0278 - mae: 0.0047 - val_loss: 0.0269 - val_mae: 0.0057\n",
      "Epoch 29/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0261 - mae: 0.0043 - val_loss: 0.0253 - val_mae: 0.0045\n",
      "Epoch 30/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0245 - mae: 0.0047 - val_loss: 0.0237 - val_mae: 0.0033\n",
      "Epoch 31/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0229 - mae: 0.0041 - val_loss: 0.0222 - val_mae: 0.0072\n",
      "Epoch 32/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0215 - mae: 0.0048 - val_loss: 0.0208 - val_mae: 0.0032\n",
      "Epoch 33/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0201 - mae: 0.0048 - val_loss: 0.0195 - val_mae: 0.0072\n",
      "Epoch 34/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0189 - mae: 0.0040 - val_loss: 0.0183 - val_mae: 0.0035\n",
      "Epoch 35/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0177 - mae: 0.0041 - val_loss: 0.0171 - val_mae: 0.0030\n",
      "Epoch 36/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0165 - mae: 0.0043 - val_loss: 0.0160 - val_mae: 0.0042\n",
      "Epoch 37/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0154 - mae: 0.0043 - val_loss: 0.0149 - val_mae: 0.0057\n",
      "Epoch 38/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0144 - mae: 0.0043 - val_loss: 0.0140 - val_mae: 0.0029\n",
      "Epoch 39/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0135 - mae: 0.0041 - val_loss: 0.0131 - val_mae: 0.0053\n",
      "Epoch 40/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0126 - mae: 0.0043 - val_loss: 0.0122 - val_mae: 0.0039\n",
      "Epoch 41/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0118 - mae: 0.0037 - val_loss: 0.0115 - val_mae: 0.0123\n",
      "Epoch 42/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0110 - mae: 0.0039 - val_loss: 0.0106 - val_mae: 0.0034\n",
      "Epoch 43/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0102 - mae: 0.0039 - val_loss: 0.0098 - val_mae: 0.0034\n",
      "Epoch 44/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0095 - mae: 0.0040 - val_loss: 0.0091 - val_mae: 0.0028\n",
      "Epoch 45/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0088 - mae: 0.0037 - val_loss: 0.0085 - val_mae: 0.0030\n",
      "Epoch 46/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0082 - mae: 0.0039 - val_loss: 0.0079 - val_mae: 0.0060\n",
      "Epoch 47/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0076 - mae: 0.0037 - val_loss: 0.0073 - val_mae: 0.0028\n",
      "Epoch 48/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0071 - mae: 0.0037 - val_loss: 0.0068 - val_mae: 0.0027\n",
      "Epoch 49/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0066 - mae: 0.0038 - val_loss: 0.0064 - val_mae: 0.0029\n",
      "Epoch 50/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0062 - mae: 0.0037 - val_loss: 0.0060 - val_mae: 0.0066\n",
      "Epoch 51/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0058 - mae: 0.0035 - val_loss: 0.0055 - val_mae: 0.0032\n",
      "Epoch 52/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0054 - mae: 0.0040 - val_loss: 0.0052 - val_mae: 0.0054\n",
      "Epoch 53/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0050 - mae: 0.0036 - val_loss: 0.0049 - val_mae: 0.0030\n",
      "Epoch 54/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0047 - mae: 0.0035 - val_loss: 0.0046 - val_mae: 0.0025\n",
      "Epoch 55/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0044 - mae: 0.0034 - val_loss: 0.0044 - val_mae: 0.0094\n",
      "Epoch 56/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0041 - mae: 0.0035 - val_loss: 0.0041 - val_mae: 0.0072\n",
      "Epoch 57/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0039 - mae: 0.0036 - val_loss: 0.0038 - val_mae: 0.0048\n",
      "Epoch 58/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0037 - mae: 0.0036 - val_loss: 0.0036 - val_mae: 0.0061\n",
      "Epoch 59/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0035 - mae: 0.0036 - val_loss: 0.0034 - val_mae: 0.0030\n",
      "Epoch 60/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0033 - mae: 0.0036 - val_loss: 0.0032 - val_mae: 0.0031\n",
      "Epoch 61/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0031 - mae: 0.0033 - val_loss: 0.0031 - val_mae: 0.0063\n",
      "Epoch 62/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0029 - mae: 0.0037 - val_loss: 0.0029 - val_mae: 0.0032\n",
      "Epoch 63/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0028 - mae: 0.0034 - val_loss: 0.0027 - val_mae: 0.0049\n",
      "Epoch 64/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0027 - mae: 0.0036 - val_loss: 0.0026 - val_mae: 0.0039\n",
      "Epoch 65/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0025 - mae: 0.0034 - val_loss: 0.0025 - val_mae: 0.0025\n",
      "Epoch 66/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0024 - mae: 0.0033 - val_loss: 0.0024 - val_mae: 0.0049\n",
      "Epoch 67/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0037 - val_loss: 0.0023 - val_mae: 0.0049\n",
      "Epoch 68/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0036 - val_loss: 0.0022 - val_mae: 0.0044\n",
      "Epoch 69/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0036 - val_loss: 0.0021 - val_mae: 0.0040\n",
      "Epoch 70/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0021 - mae: 0.0035 - val_loss: 0.0021 - val_mae: 0.0031\n",
      "Epoch 71/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0020 - mae: 0.0037 - val_loss: 0.0020 - val_mae: 0.0047\n",
      "Epoch 72/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0020 - mae: 0.0036 - val_loss: 0.0019 - val_mae: 0.0047\n",
      "Epoch 73/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0019 - mae: 0.0034 - val_loss: 0.0019 - val_mae: 0.0039\n",
      "Epoch 74/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0018 - mae: 0.0036 - val_loss: 0.0018 - val_mae: 0.0026\n",
      "Epoch 75/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0018 - mae: 0.0037 - val_loss: 0.0018 - val_mae: 0.0026\n",
      "Epoch 76/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0018 - mae: 0.0037 - val_loss: 0.0017 - val_mae: 0.0029\n",
      "Epoch 77/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0017 - mae: 0.0034 - val_loss: 0.0017 - val_mae: 0.0025\n",
      "Epoch 78/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0017 - mae: 0.0036 - val_loss: 0.0017 - val_mae: 0.0059\n",
      "Epoch 79/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0016 - mae: 0.0038 - val_loss: 0.0016 - val_mae: 0.0027\n",
      "Epoch 80/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0016 - mae: 0.0036 - val_loss: 0.0016 - val_mae: 0.0034\n",
      "Epoch 81/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0016 - mae: 0.0037 - val_loss: 0.0016 - val_mae: 0.0045\n",
      "Epoch 82/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0015 - mae: 0.0035 - val_loss: 0.0015 - val_mae: 0.0035\n",
      "Epoch 83/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0015 - mae: 0.0038 - val_loss: 0.0015 - val_mae: 0.0049\n",
      "Epoch 84/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0015 - mae: 0.0039 - val_loss: 0.0015 - val_mae: 0.0029\n",
      "Epoch 85/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0015 - mae: 0.0037 - val_loss: 0.0014 - val_mae: 0.0032\n",
      "Epoch 86/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0014 - mae: 0.0038 - val_loss: 0.0014 - val_mae: 0.0056\n",
      "Epoch 87/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0014 - mae: 0.0039 - val_loss: 0.0015 - val_mae: 0.0077\n",
      "Epoch 88/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0014 - mae: 0.0035 - val_loss: 0.0014 - val_mae: 0.0078\n",
      "Epoch 89/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0014 - mae: 0.0037 - val_loss: 0.0014 - val_mae: 0.0039\n",
      "Epoch 90/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0037 - val_loss: 0.0013 - val_mae: 0.0037\n",
      "Epoch 91/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0038 - val_loss: 0.0013 - val_mae: 0.0032\n",
      "Epoch 92/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0037 - val_loss: 0.0013 - val_mae: 0.0027\n",
      "Epoch 93/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0038 - val_loss: 0.0013 - val_mae: 0.0040\n",
      "Epoch 94/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0039 - val_loss: 0.0013 - val_mae: 0.0028\n",
      "Epoch 95/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0013 - mae: 0.0038 - val_loss: 0.0013 - val_mae: 0.0028\n",
      "Epoch 96/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0037 - val_loss: 0.0013 - val_mae: 0.0056\n",
      "Epoch 97/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0036 - val_loss: 0.0012 - val_mae: 0.0038\n",
      "Epoch 98/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0036 - val_loss: 0.0013 - val_mae: 0.0056\n",
      "Epoch 99/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0039 - val_loss: 0.0012 - val_mae: 0.0049\n",
      "Epoch 100/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0038 - val_loss: 0.0012 - val_mae: 0.0066\n",
      "Epoch 101/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0038 - val_loss: 0.0012 - val_mae: 0.0041\n",
      "Epoch 102/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0038 - val_loss: 0.0012 - val_mae: 0.0029\n",
      "Epoch 103/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0035 - val_loss: 0.0012 - val_mae: 0.0033\n",
      "Epoch 104/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0037 - val_loss: 0.0012 - val_mae: 0.0037\n",
      "Epoch 105/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0040 - val_loss: 0.0012 - val_mae: 0.0054\n",
      "Epoch 106/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0038 - val_loss: 0.0012 - val_mae: 0.0038\n",
      "Epoch 107/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0036 - val_loss: 0.0012 - val_mae: 0.0086\n",
      "Epoch 108/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0038 - val_loss: 0.0011 - val_mae: 0.0045\n",
      "Epoch 109/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0045\n",
      "Epoch 110/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0052\n",
      "Epoch 111/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0037 - val_loss: 0.0011 - val_mae: 0.0050\n",
      "Epoch 112/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0012 - val_mae: 0.0078\n",
      "Epoch 113/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0037 - val_loss: 0.0011 - val_mae: 0.0032\n",
      "Epoch 114/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0037\n",
      "Epoch 115/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0038 - val_loss: 0.0011 - val_mae: 0.0030\n",
      "Epoch 116/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0038 - val_loss: 0.0011 - val_mae: 0.0034\n",
      "Epoch 117/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0038 - val_loss: 0.0011 - val_mae: 0.0044\n",
      "Epoch 118/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0038 - val_loss: 0.0011 - val_mae: 0.0031\n",
      "Epoch 119/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0038 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 120/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0038 - val_loss: 0.0011 - val_mae: 0.0066\n",
      "Epoch 121/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0037\n",
      "Epoch 122/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0038 - val_loss: 0.0011 - val_mae: 0.0061\n",
      "Epoch 123/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0037 - val_loss: 0.0011 - val_mae: 0.0050\n",
      "Epoch 124/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0038 - val_loss: 0.0011 - val_mae: 0.0043\n",
      "Epoch 125/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0010 - val_mae: 0.0037\n",
      "Epoch 126/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0038 - val_loss: 0.0010 - val_mae: 0.0042\n",
      "Epoch 127/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0041 - val_loss: 0.0010 - val_mae: 0.0034\n",
      "Epoch 128/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0038 - val_loss: 0.0010 - val_mae: 0.0041\n",
      "Epoch 129/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0040 - val_loss: 0.0010 - val_mae: 0.0029\n",
      "Epoch 130/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0010 - mae: 0.0038 - val_loss: 0.0010 - val_mae: 0.0029\n",
      "Epoch 131/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0010 - mae: 0.0039 - val_loss: 0.0010 - val_mae: 0.0029\n",
      "Epoch 132/1000\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0010 - mae: 0.0038 - val_loss: 0.0010 - val_mae: 0.0031\n",
      "Epoch 133/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0039 - val_loss: 0.0010 - val_mae: 0.0042\n",
      "Epoch 134/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0038 - val_loss: 0.0010 - val_mae: 0.0028\n",
      "Epoch 135/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0039 - val_loss: 0.0010 - val_mae: 0.0050\n",
      "Epoch 136/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0039 - val_loss: 0.0010 - val_mae: 0.0029\n",
      "Epoch 137/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0039 - val_loss: 0.0010 - val_mae: 0.0052\n",
      "Epoch 138/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0039 - val_loss: 9.9550e-04 - val_mae: 0.0028\n",
      "Epoch 139/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0040 - val_loss: 0.0010 - val_mae: 0.0052\n",
      "Epoch 140/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0038 - val_loss: 9.9626e-04 - val_mae: 0.0035\n",
      "Epoch 141/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.9737e-04 - mae: 0.0037 - val_loss: 9.8748e-04 - val_mae: 0.0027\n",
      "Epoch 142/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.9678e-04 - mae: 0.0039 - val_loss: 9.8788e-04 - val_mae: 0.0031\n",
      "Epoch 143/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.9270e-04 - mae: 0.0038 - val_loss: 0.0010 - val_mae: 0.0056\n",
      "Epoch 144/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.9271e-04 - mae: 0.0040 - val_loss: 9.8500e-04 - val_mae: 0.0033\n",
      "Epoch 145/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.8926e-04 - mae: 0.0039 - val_loss: 9.9724e-04 - val_mae: 0.0047\n",
      "Epoch 146/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.8556e-04 - mae: 0.0038 - val_loss: 9.7783e-04 - val_mae: 0.0031\n",
      "Epoch 147/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.8338e-04 - mae: 0.0038 - val_loss: 9.7817e-04 - val_mae: 0.0035\n",
      "Epoch 148/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.8136e-04 - mae: 0.0038 - val_loss: 0.0010 - val_mae: 0.0054\n",
      "Epoch 149/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.8153e-04 - mae: 0.0041 - val_loss: 9.9490e-04 - val_mae: 0.0056\n",
      "Epoch 150/1000\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.7653e-04 - mae: 0.0038 - val_loss: 9.8134e-04 - val_mae: 0.0045\n",
      "Epoch 151/1000\n",
      "638/645 [============================>.] - ETA: 0s - loss: 9.7538e-04 - mae: 0.0039Restoring model weights from the end of the best epoch: 146.\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.7557e-04 - mae: 0.0039 - val_loss: 9.9968e-04 - val_mae: 0.0062\n",
      "Epoch 151: early stopping\n",
      "Durchschnittlicher Validation Loss: 0.0009369292063638567\n",
      "Durchschnittlicher Validation MAE: 0.00265824836678803\n"
     ]
    }
   ],
   "source": [
    "# Initialisiere Listen, um Ergebnisse zu speichern\n",
    "val_loss_results = []\n",
    "val_mae_results = []\n",
    "\n",
    "# Funktion, um das Modell zu erstellen\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "            Dense(256, activation='relu', input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "            Dense(128, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "        \n",
    "            Dense(160, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "        \n",
    "            Dense(224, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "        \n",
    "            Dense(112, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "        \n",
    "            Dense(320, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "        \n",
    "            Dense(16, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "        \n",
    "            Dense(112, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "        \n",
    "            Dense(1 , activation = 'linear')\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# K-Fold Cross-Validation Konfiguration\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# LeistungsÃ¼berwachung\n",
    "fold_no = 1\n",
    "for train_index, val_index in kf.split(X_train_scaled):\n",
    "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_scaled[train_index], y_train_scaled[val_index]\n",
    "\n",
    "    model = create_model()\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "    print(f'Training fÃ¼r Fold {fold_no}...')\n",
    "    history = model.fit(X_train_fold, y_train_fold, batch_size=100, epochs=1000, validation_data=(X_val_fold, y_val_fold), callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "    # Speichere die Ergebnisse des aktuellen Folds\n",
    "    val_loss_results.append(min(history.history['val_loss']))\n",
    "    val_mae_results.append(min(history.history['val_mae']))\n",
    "\n",
    "    fold_no += 1\n",
    "\n",
    "# Berechne den Durchschnitt Ã¼ber alle Folds\n",
    "average_val_loss = np.mean(val_loss_results)\n",
    "average_val_mae = np.mean(val_mae_results)\n",
    "\n",
    "# Umwandeln der Listen in Pandas DataFrames\n",
    "val_loss_df = pd.DataFrame(val_loss_results, columns=['Validation Loss'])\n",
    "val_mae_df = pd.DataFrame(val_mae_results, columns=['Validation MAE'])\n",
    "\n",
    "# Speichern der DataFrames in CSV-Dateien\n",
    "val_loss_df.to_csv('val_loss_results_D4_1.csv', index=False)\n",
    "val_mae_df.to_csv('val_mae_results_D4_1.csv', index=False)\n",
    "\n",
    "# Gib die durchschnittlichen Ergebnisse aus\n",
    "print(f'Durchschnittlicher Validation Loss: {average_val_loss}')\n",
    "print(f'Durchschnittlicher Validation MAE: {average_val_mae}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T09:30:07.397487200Z",
     "start_time": "2024-03-18T09:06:30.480446Z"
    }
   },
   "id": "29c288dd786bd1cb"
  },
  {
   "cell_type": "markdown",
   "source": [
    " # Auswertung des NeuroNetz auf den Testdatensatz"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83d8d88143abaf36"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 - 1s - loss: 1.7373e-04 - mae: 0.0012 - 714ms/epoch - 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.00017373079026583582, 0.0011673958506435156]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test_scaled, y_test_scaled, verbose=2)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T14:04:42.706213200Z",
     "start_time": "2024-03-19T14:04:41.942244900Z"
    }
   },
   "id": "68d86893ad985b02"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f6f672a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:04:47.890440900Z",
     "start_time": "2024-03-19T14:04:46.732706100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bsp. Predicted: [1194.995] Actual: [1195.9] \n",
      "Durchschnittliche Abweichung (MAE): [1.10645499]\n"
     ]
    }
   ],
   "source": [
    "#RÃ¼ckrechnung des skalierten MAE zum unskalierten MAE fÃ¼r eines bessere EinschÃ¤tzung des Ergebnisses\n",
    "scaled_predicted_values = model.predict(X_test_scaled, verbose = 0)\n",
    "\n",
    "# FÃ¼hren Sie die RÃ¼cktransformation der skalierten Werte durch\n",
    "original_predicted_values = scaler_target.inverse_transform(scaled_predicted_values)\n",
    "original_actual_values = scaler_target.inverse_transform(y_test_scaled)  # y_test sind die skalierten tatsÃ¤chlichen Werte\n",
    "print(f' Bsp. Predicted: {original_predicted_values[1000]} Actual: {original_actual_values[1000]} ')\n",
    "\n",
    "def calculate_mae(list1, list2):\n",
    "    # Stelle sicher, dass beide Listen die gleiche LÃ¤nge haben\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Listen mÃ¼ssen die gleiche LÃ¤nge haben\")\n",
    "\n",
    "    # Berechne die absolute Differenz zwischen den Elementen der Listen\n",
    "    differences = [abs(x - y) for x, y in zip(list1, list2)]\n",
    "\n",
    "    # Berechne den Durchschnitt der absoluten Differenzen\n",
    "    mae = sum(differences) / len(differences)\n",
    "\n",
    "    return mae\n",
    "\n",
    "# Beispiel\n",
    "list1 = original_predicted_values\n",
    "list2 = original_actual_values\n",
    "\n",
    "mae = calculate_mae(list1, list2)\n",
    "print(f\"Durchschnittliche Abweichung (MAE): {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: [0.99995099]\n"
     ]
    }
   ],
   "source": [
    "#Berechnung der AuswertungsgrÃ¶ÃŸe R^2\n",
    "\n",
    "def calculate_r_squared(predicted, actual):\n",
    "    # Berechnung des Mittelwerts der tatsÃ¤chlichen Werte\n",
    "    mean_actual = sum(actual) / len(actual)\n",
    "    \n",
    "    # Berechnung der totalen Summe der Quadrate (SST)\n",
    "    sst = sum((x - mean_actual) ** 2 for x in actual)\n",
    "    \n",
    "    # Berechnung der Summe der Quadrate der Residuen (SSE)\n",
    "    sse = sum((actual[i] - predicted[i]) ** 2 for i in range(len(actual)))\n",
    "    \n",
    "    # Berechnung des R^2-Wertes\n",
    "    r_squared = 1 - (sse / sst)\n",
    "    \n",
    "    return r_squared\n",
    "\n",
    "# Berechnung von R^2 mit den bereitgestellten Listen\n",
    "r_squared = calculate_r_squared(list1, list2)\n",
    "\n",
    "print(f\"R^2: {r_squared}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T14:04:59.695541300Z",
     "start_time": "2024-03-19T14:04:59.559037700Z"
    }
   },
   "id": "48ac8cdcc05e55fd"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Werte die kleiner sind: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "             Echt  Vorhergesagt  X-Koordinate  Y-Koordinate  Differenz\n19281  790.107849        807.84         1.000        0.9125 -17.732151\n15566  754.444153        771.22         0.996        0.9250 -16.775847\n9896   775.477234        791.74         0.992        0.9175 -16.262766\n4160   789.651672        805.35         0.992        0.9125 -15.698328\n14143  817.084717        832.75         1.000        0.9025 -15.665283\n...           ...           ...           ...           ...        ...\n11939  603.741943        586.88         0.964        0.9775  16.861943\n1749   611.744202        594.73         0.980        0.9750  17.014202\n14839  617.464600        599.38         0.956        0.9725  18.084600\n13809  612.200317        593.15         0.988        0.9750  19.050317\n20012  612.656738        588.92         0.996        0.9750  23.736738\n\n[20131 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Echt</th>\n      <th>Vorhergesagt</th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Differenz</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>19281</th>\n      <td>790.107849</td>\n      <td>807.84</td>\n      <td>1.000</td>\n      <td>0.9125</td>\n      <td>-17.732151</td>\n    </tr>\n    <tr>\n      <th>15566</th>\n      <td>754.444153</td>\n      <td>771.22</td>\n      <td>0.996</td>\n      <td>0.9250</td>\n      <td>-16.775847</td>\n    </tr>\n    <tr>\n      <th>9896</th>\n      <td>775.477234</td>\n      <td>791.74</td>\n      <td>0.992</td>\n      <td>0.9175</td>\n      <td>-16.262766</td>\n    </tr>\n    <tr>\n      <th>4160</th>\n      <td>789.651672</td>\n      <td>805.35</td>\n      <td>0.992</td>\n      <td>0.9125</td>\n      <td>-15.698328</td>\n    </tr>\n    <tr>\n      <th>14143</th>\n      <td>817.084717</td>\n      <td>832.75</td>\n      <td>1.000</td>\n      <td>0.9025</td>\n      <td>-15.665283</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11939</th>\n      <td>603.741943</td>\n      <td>586.88</td>\n      <td>0.964</td>\n      <td>0.9775</td>\n      <td>16.861943</td>\n    </tr>\n    <tr>\n      <th>1749</th>\n      <td>611.744202</td>\n      <td>594.73</td>\n      <td>0.980</td>\n      <td>0.9750</td>\n      <td>17.014202</td>\n    </tr>\n    <tr>\n      <th>14839</th>\n      <td>617.464600</td>\n      <td>599.38</td>\n      <td>0.956</td>\n      <td>0.9725</td>\n      <td>18.084600</td>\n    </tr>\n    <tr>\n      <th>13809</th>\n      <td>612.200317</td>\n      <td>593.15</td>\n      <td>0.988</td>\n      <td>0.9750</td>\n      <td>19.050317</td>\n    </tr>\n    <tr>\n      <th>20012</th>\n      <td>612.656738</td>\n      <td>588.92</td>\n      <td>0.996</td>\n      <td>0.9750</td>\n      <td>23.736738</td>\n    </tr>\n  </tbody>\n</table>\n<p>20131 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ausgabe der hÃ¶chsten Abweichungen zwischen Echt und Vorhergesagt\n",
    "df_result = pd.DataFrame({'Echt': [val[0] for val in list1], 'Vorhergesagt': [val[0] for val in list2]})\n",
    "df_result['X-Koordinate'] = X_test_scaled[:, 0]\n",
    "df_result['Y-Koordinate'] = X_test_scaled[:, 1]\n",
    "\n",
    "df_result['Differenz'] = df_result['Echt'] - df_result['Vorhergesagt']\n",
    "df_result['Differenz'].sort_values()\n",
    "sorted_df = df_result.sort_values(by= 'Differenz')\n",
    "Anzahl_Punkte = (sorted_df['Differenz'] > 20).sum()\n",
    "print(\"Anzahl der Werte die kleiner sind:\", Anzahl_Punkte)\n",
    "\n",
    "sorted_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T14:05:04.057324900Z",
     "start_time": "2024-03-19T14:05:03.967852500Z"
    }
   },
   "id": "42bde60d3b4f2007"
  },
  {
   "cell_type": "markdown",
   "id": "553df6fa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mae = history.history['loss']\n",
    "val_mae = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(mae) + 1)\n",
    "# MAE Diagramm\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, mae, 'r', label='Training MSE')\n",
    "plt.plot(epochs, val_mae, 'b', label='Validation MSE')\n",
    "plt.title('Training and Validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.savefig('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Bilder Diplomarbeit/MSE_NeuroNetz/MSE_NeuroNetz_D1_2')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T14:05:08.892451400Z",
     "start_time": "2024-03-19T14:05:08.589737900Z"
    }
   },
   "id": "3688dd7102e95baf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# GridSearch\n",
    "Grid Search bietet die Vorteile der anpassbaren Rechenzeit sowie die MÃ¶glichkeit des EInsatzes von Verteilungen. So kÃ¶nnen theoretisch Hyperparamterkonfuigurationen gefunden wende, welche durch GridSearch nicht auffindbar wÃ¤ren. ZUdem ist das Ziel der Hyperparamteroptimierung eine Einstellung zu finden, welche auf Trainings und Testset gut angepasst ist. Die EInstellung muss nicht die bestmÃ¶glichste Einstellung sein, sondern eine Einstellung die das gewÃ¤hltre Problem gut wiederspiegelt. \n",
    "Bayesian Optimierung"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c177960cc729052"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3f17e2cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T10:00:01.423818100Z",
     "start_time": "2024-03-15T10:00:01.416947800Z"
    }
   },
   "outputs": [],
   "source": [
    "# def build_model(learning_rate=0.001, activation='relu', regularization=0.0001, dropout_rate=0.0):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(320, activation=activation, input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(176, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(288, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(192, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(208, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(224, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(80, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(304, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate)) \n",
    "# \n",
    "#     model.add(Dense(240, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))   \n",
    "# \n",
    "#     model.add(Dense(48, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mae'])\n",
    "#     return model\n",
    "# \n",
    "# # Verwenden Sie eine Funktion, um das Modell zu instanziieren, fÃ¼r scikit-learn Wrapper\n",
    "# model = KerasRegressor(model=build_model, verbose=2)\n",
    "# \n",
    "# # Anpassung der Parameter im param_grid\n",
    "# param_grid = {\n",
    "#     'model__learning_rate': [0.01, 0.001, 0.0001],\n",
    "#     'model__regularization': [0.001, 0.0001, 0.00001],\n",
    "#     'fit__batch_size': [100, 200, 400, 800],\n",
    "#     'fit__epochs': [50],\n",
    "#     'model__dropout_rate' : [0.0, 0.1, 0.2]\n",
    "# }\n",
    "# \n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=2)\n",
    "# # Hinweis: Stellen Sie sicher, dass Ihre Daten (X_train_scaled, y_train_scaled) korrekt definiert sind\n",
    "# grid_result = grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "# # Beste Parameter und Score ausgeben\n",
    "# print(\"Beste Parameter:\", grid_search.best_params_)\n",
    "# print(\"Beste Genauigkeit:\", grid_search.best_score_)\n",
    "# \n",
    "# with open(\"grid_search_D1_2.txt\", \"w\") as f:\n",
    "#     f.write(f\"Beste Parameter: {grid_search.best_params_}\\n\")\n",
    "#     f.write(f\"Beste Genauigkeit: {grid_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Search Architektur\n",
    "Tiefes Netz besser als breites Netz; Layer lernen auf unterschiedliche Weise"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75773dfef8260e5f"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "# # Funktion zum Erstellen des Modells\n",
    "# def build_model(hp):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(hp.Int('input_units', min_value=8, max_value=328, step=16), input_shape=(2,), activation='relu'))\n",
    "#     for i in range(hp.Int('n_layers', 1, 10)):\n",
    "#         model.add(Dense(hp.Int(f'units_{i}', min_value=8, max_value=328, step=16), activation='relu'))\n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     return model\n",
    "# \n",
    "# # DurchfÃ¼hrung der Random Search dreimal\n",
    "# for run in range(1, 4):\n",
    "#     # Anpassen des Verzeichnisses und des Projektnamens fÃ¼r jeden Durchlauf\n",
    "#     directory = 'random_search'\n",
    "#     project_name = f'random_search_D1_{run}'\n",
    "# \n",
    "#     tuner = RandomSearch(\n",
    "#         build_model,\n",
    "#         objective='val_loss',\n",
    "#         max_trials=100,\n",
    "#         executions_per_trial=1,\n",
    "#         directory=directory,\n",
    "#         project_name=project_name\n",
    "#     )\n",
    "# \n",
    "#     # DurchfÃ¼hrung des Random Search\n",
    "#     tuner.search(X_train_scaled, y_train_scaled, epochs=50, verbose =0, batch_size=500, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "# \n",
    "#     # Abrufen und Speichern des besten Modells\n",
    "#     best_model = tuner.get_best_models(num_models=1)[0]\n",
    "#     model_path = os.path.join(directory, project_name, 'best_model.h5') \n",
    "#     best_model.save(model_path)\n",
    "# \n",
    "# \n",
    "#     # Optional: Abrufen und Ausgeben der besten Hyperparameter\n",
    "#     best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "# \n",
    "#     # Konvertieren der Hyperparameter in ein DataFrame\n",
    "#     df_hyperparameters = pd.DataFrame([best_hyperparameters.values])\n",
    "#     # Speichern des DataFrame als CSV\n",
    "#     df_hyperparameters.to_csv(f'random_search_D1_{run}.csv', index=False)\n",
    "#     best_model.describe()\n",
    "#     print(f\"Beste Hyperparameter fÃ¼r Lauf {run}: {best_hyperparameters.values}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:00:01.435372800Z",
     "start_time": "2024-03-15T10:00:01.425559Z"
    }
   },
   "id": "158d81fabf560fc4"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:00:01.435372800Z",
     "start_time": "2024-03-15T10:00:01.432902600Z"
    }
   },
   "id": "6f86db4f21a8c913"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:00:01.435372800Z",
     "start_time": "2024-03-15T10:00:01.434846900Z"
    }
   },
   "id": "2a8e01cea48e945f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
