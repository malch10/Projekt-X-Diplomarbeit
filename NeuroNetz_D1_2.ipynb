{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94b0518e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T13:49:06.215602300Z",
     "start_time": "2024-03-19T13:48:57.831777300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense , Dropout\n",
    "from scikeras.wrappers import KerasRegressor \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Einlesen der Pickle-Dateien und Vorverarbeitung des Inhaltes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42e897a1c7eeed"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ff61b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T13:49:06.238861300Z",
     "start_time": "2024-03-19T13:49:06.215602300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n0             0.0000      -0.00200        500   7000   9000      669.05\n1             0.0000      -0.00199        500   7000   9000      675.83\n2             0.0000      -0.00198        500   7000   9000      682.81\n3             0.0000      -0.00197        500   7000   9000      689.82\n4             0.0000      -0.00196        500   7000   9000      696.80\n...              ...           ...        ...    ...    ...         ...\n100646        0.0025       0.00196        500   7000   9000      578.47\n100647        0.0025       0.00197        500   7000   9000      576.89\n100648        0.0025       0.00198        500   7000   9000      575.32\n100649        0.0025       0.00199        500   7000   9000      573.76\n100650        0.0025       0.00200        500   7000   9000      572.20\n\n[100651 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>669.05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0000</td>\n      <td>-0.00199</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>675.83</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0000</td>\n      <td>-0.00198</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>682.81</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0000</td>\n      <td>-0.00197</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>689.82</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0000</td>\n      <td>-0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>696.80</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>100646</th>\n      <td>0.0025</td>\n      <td>0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>578.47</td>\n    </tr>\n    <tr>\n      <th>100647</th>\n      <td>0.0025</td>\n      <td>0.00197</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>576.89</td>\n    </tr>\n    <tr>\n      <th>100648</th>\n      <td>0.0025</td>\n      <td>0.00198</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>575.32</td>\n    </tr>\n    <tr>\n      <th>100649</th>\n      <td>0.0025</td>\n      <td>0.00199</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>573.76</td>\n    </tr>\n    <tr>\n      <th>100650</th>\n      <td>0.0025</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>572.20</td>\n    </tr>\n  </tbody>\n</table>\n<p>100651 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_D1_I7000_F9000/TPath_500_finish_data_D1.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "966e3c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T13:49:06.251336800Z",
     "start_time": "2024-03-19T13:49:06.238861300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "count    100651.000000\nmean       1144.030064\nstd         264.135723\nmin         572.200000\n25%         937.330000\n50%        1201.100000\n75%        1368.700000\nmax        1520.000000\nName: Temperatur, dtype: float64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.drop(data.columns[2:5], axis = 1)\n",
    "df['Temperatur'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8783d1d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T13:49:06.340605600Z",
     "start_time": "2024-03-19T13:49:06.251336800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       X-Koordinate  Y-Koordinate  Temperatur\n",
      "83145       0.00207      -0.00062      1282.2\n",
      "66701       0.00166      -0.00065      1347.6\n",
      "91325       0.00227       0.00098      1094.6\n",
      "46593       0.00116      -0.00123      1175.7\n",
      "49518       0.00123      -0.00005      1459.2\n",
      "...             ...           ...         ...\n",
      "6265        0.00015       0.00050      1439.1\n",
      "54886       0.00136       0.00150       876.7\n",
      "76820       0.00191       0.00029      1335.8\n",
      "860         0.00002      -0.00142      1071.2\n",
      "15795       0.00039      -0.00044      1488.1\n",
      "\n",
      "[100651 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate  Temperatur\n0            0.00207      -0.00062      1282.2\n1            0.00166      -0.00065      1347.6\n2            0.00227       0.00098      1094.6\n3            0.00116      -0.00123      1175.7\n4            0.00123      -0.00005      1459.2\n...              ...           ...         ...\n100646       0.00015       0.00050      1439.1\n100647       0.00136       0.00150       876.7\n100648       0.00191       0.00029      1335.8\n100649       0.00002      -0.00142      1071.2\n100650       0.00039      -0.00044      1488.1\n\n[100651 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00207</td>\n      <td>-0.00062</td>\n      <td>1282.2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00166</td>\n      <td>-0.00065</td>\n      <td>1347.6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00227</td>\n      <td>0.00098</td>\n      <td>1094.6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00116</td>\n      <td>-0.00123</td>\n      <td>1175.7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00123</td>\n      <td>-0.00005</td>\n      <td>1459.2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>100646</th>\n      <td>0.00015</td>\n      <td>0.00050</td>\n      <td>1439.1</td>\n    </tr>\n    <tr>\n      <th>100647</th>\n      <td>0.00136</td>\n      <td>0.00150</td>\n      <td>876.7</td>\n    </tr>\n    <tr>\n      <th>100648</th>\n      <td>0.00191</td>\n      <td>0.00029</td>\n      <td>1335.8</td>\n    </tr>\n    <tr>\n      <th>100649</th>\n      <td>0.00002</td>\n      <td>-0.00142</td>\n      <td>1071.2</td>\n    </tr>\n    <tr>\n      <th>100650</th>\n      <td>0.00039</td>\n      <td>-0.00044</td>\n      <td>1488.1</td>\n    </tr>\n  </tbody>\n</table>\n<p>100651 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.sample(frac=1, random_state=42)  # Hier wird 42 als Random State verwendet, um die Ergebnisse reproduzierbar zu machen\n",
    "print(df1)\n",
    "df_reset = df1.reset_index(drop=True)\n",
    "df_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4e72a16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T13:49:06.340605600Z",
     "start_time": "2024-03-19T13:49:06.268091200Z"
    }
   },
   "outputs": [],
   "source": [
    "label = df_reset[\"Temperatur\"]\n",
    "# Korrektur: Verwenden Sie den Spaltennamen direkt, ohne Indexierung der columns-Eigenschaft\n",
    "df1 = df_reset.drop(\"Temperatur\", axis=1)\n",
    "X = df1\n",
    "y = label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7fa289a50d87423"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e694a236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T13:49:06.365114200Z",
     "start_time": "2024-03-19T13:49:06.274219700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate\ncount  100651.000000  1.006510e+05\nmean        0.001250  1.103042e-20\nstd         0.000725  1.157589e-03\nmin         0.000000 -2.000000e-03\n25%         0.000620 -1.000000e-03\n50%         0.001250  4.529900e-18\n75%         0.001880  1.000000e-03\nmax         0.002500  2.000000e-03",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>100651.000000</td>\n      <td>1.006510e+05</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.001250</td>\n      <td>1.103042e-20</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.000725</td>\n      <td>1.157589e-03</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-2.000000e-03</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000620</td>\n      <td>-1.000000e-03</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.001250</td>\n      <td>4.529900e-18</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.001880</td>\n      <td>1.000000e-03</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.002500</td>\n      <td>2.000000e-03</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f3303b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T13:49:06.365114200Z",
     "start_time": "2024-03-19T13:49:06.291008Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "count    100651.000000\nmean       1144.030064\nstd         264.135723\nmin         572.200000\n25%         937.330000\n50%        1201.100000\n75%        1368.700000\nmax        1520.000000\nName: Temperatur, dtype: float64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3ad8da0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T13:49:06.365114200Z",
     "start_time": "2024-03-19T13:49:06.300346100Z"
    }
   },
   "outputs": [],
   "source": [
    " # train_df enthÃ¤lt 80% der Daten, test_df enthÃ¤lt 20% der Daten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c705edb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T13:49:06.365114200Z",
     "start_time": "2024-03-19T13:49:06.310437600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialisiere einen MinMaxScaler fÃ¼r die Features\n",
    "scaler_features = MinMaxScaler()\n",
    "scaler_features2 = MinMaxScaler()\n",
    "# Skaliere X_train und X_test\n",
    "X_train_scaled = scaler_features.fit_transform(X_train)\n",
    "X_test_scaled = scaler_features.transform(X_test)  # Nutze unterschiedliche Skalierungsparameter\n",
    "\n",
    "\n",
    "scaler_target = MinMaxScaler()\n",
    "\n",
    "y_train_scaled = scaler_target.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test_scaled = scaler_target.transform(y_test.values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbefe631e495b483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T13:49:06.365114200Z",
     "start_time": "2024-03-19T13:49:06.320027100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.416 , 0.5725],\n       [0.812 , 0.7325],\n       [0.628 , 0.5075],\n       ...,\n       [0.604 , 0.3875],\n       [0.748 , 0.65  ],\n       [0.028 , 0.6225]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ende der Datenvorverarbeitung"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbcdf8ff6114c7a6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Machine Learning Modell mit Konfiguration je nach Dateiname"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca42b21ba64183fa"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "Epoch 1/400\n",
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "645/645 [==============================] - 7s 7ms/step - loss: 0.0594 - mae: 0.0854 - val_loss: 0.0266 - val_mae: 0.0087\n",
      "Epoch 2/400\n",
      "645/645 [==============================] - 4s 7ms/step - loss: 0.0244 - mae: 0.0151 - val_loss: 0.0221 - val_mae: 0.0142\n",
      "Epoch 3/400\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0213 - mae: 0.0159 - val_loss: 0.0221 - val_mae: 0.0373\n",
      "Epoch 4/400\n",
      "645/645 [==============================] - 4s 7ms/step - loss: 0.0195 - mae: 0.0108 - val_loss: 0.0218 - val_mae: 0.0399\n",
      "Epoch 5/400\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0190 - mae: 0.0128 - val_loss: 0.0185 - val_mae: 0.0136\n",
      "Epoch 6/400\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0181 - mae: 0.0117 - val_loss: 0.0176 - val_mae: 0.0083\n",
      "Epoch 7/400\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0178 - mae: 0.0128 - val_loss: 0.0170 - val_mae: 0.0045\n",
      "Epoch 8/400\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0169 - mae: 0.0089 - val_loss: 0.0165 - val_mae: 0.0070\n",
      "Epoch 9/400\n",
      "645/645 [==============================] - 4s 7ms/step - loss: 0.0165 - mae: 0.0096 - val_loss: 0.0160 - val_mae: 0.0074\n",
      "Epoch 10/400\n",
      "645/645 [==============================] - 4s 7ms/step - loss: 0.0160 - mae: 0.0099 - val_loss: 0.0155 - val_mae: 0.0073\n",
      "Epoch 11/400\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0154 - mae: 0.0091 - val_loss: 0.0149 - val_mae: 0.0041\n",
      "Epoch 12/400\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0149 - mae: 0.0104 - val_loss: 0.0146 - val_mae: 0.0093\n",
      "Epoch 13/400\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0143 - mae: 0.0079 - val_loss: 0.0140 - val_mae: 0.0074\n",
      "Epoch 14/400\n",
      "645/645 [==============================] - 4s 7ms/step - loss: 0.0140 - mae: 0.0089 - val_loss: 0.0136 - val_mae: 0.0088\n",
      "Epoch 15/400\n",
      "645/645 [==============================] - 4s 7ms/step - loss: 0.0134 - mae: 0.0059 - val_loss: 0.0133 - val_mae: 0.0124\n",
      "Epoch 16/400\n",
      "645/645 [==============================] - 4s 7ms/step - loss: 0.0131 - mae: 0.0082 - val_loss: 0.0128 - val_mae: 0.0082\n",
      "Epoch 17/400\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0128 - mae: 0.0078 - val_loss: 0.0123 - val_mae: 0.0063\n",
      "Epoch 18/400\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0122 - mae: 0.0044 - val_loss: 0.0120 - val_mae: 0.0024\n",
      "Epoch 19/400\n",
      "645/645 [==============================] - 4s 7ms/step - loss: 0.0119 - mae: 0.0061 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 20/400\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0116 - mae: 0.0075 - val_loss: 0.0114 - val_mae: 0.0080\n",
      "Epoch 21/400\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0112 - mae: 0.0049 - val_loss: 0.0110 - val_mae: 0.0061\n",
      "Epoch 22/400\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0109 - mae: 0.0053 - val_loss: 0.0107 - val_mae: 0.0023\n",
      "Epoch 23/400\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0107 - mae: 0.0066 - val_loss: 0.0104 - val_mae: 0.0027\n",
      "Epoch 24/400\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0103 - mae: 0.0039 - val_loss: 0.0102 - val_mae: 0.0066\n",
      "Epoch 25/400\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0100 - mae: 0.0040 - val_loss: 0.0098 - val_mae: 0.0025\n",
      "Epoch 26/400\n",
      "645/645 [==============================] - 4s 7ms/step - loss: 0.0098 - mae: 0.0056 - val_loss: 0.0097 - val_mae: 0.0067\n",
      "Epoch 27/400\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0095 - mae: 0.0053 - val_loss: 0.0093 - val_mae: 0.0034\n",
      "Epoch 28/400\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0092 - mae: 0.0037 - val_loss: 0.0091 - val_mae: 0.0034\n",
      "Epoch 29/400\n",
      "645/645 [==============================] - 4s 7ms/step - loss: 0.0090 - mae: 0.0057 - val_loss: 0.0092 - val_mae: 0.0193\n",
      "Epoch 30/400\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0087 - mae: 0.0046 - val_loss: 0.0087 - val_mae: 0.0094\n",
      "Epoch 31/400\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0085 - mae: 0.0045 - val_loss: 0.0083 - val_mae: 0.0033\n",
      "Epoch 32/400\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0083 - mae: 0.0049 - val_loss: 0.0081 - val_mae: 0.0027\n",
      "Epoch 33/400\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0080 - mae: 0.0033 - val_loss: 0.0079 - val_mae: 0.0034\n",
      "Epoch 34/400\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0078 - mae: 0.0043 - val_loss: 0.0077 - val_mae: 0.0064\n",
      "Epoch 35/400\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0076 - mae: 0.0042 - val_loss: 0.0075 - val_mae: 0.0055\n",
      "Epoch 36/400\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0074 - mae: 0.0042 - val_loss: 0.0074 - val_mae: 0.0099\n",
      "Epoch 37/400\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0072 - mae: 0.0046 - val_loss: 0.0071 - val_mae: 0.0021\n",
      "Epoch 38/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0070 - mae: 0.0036 - val_loss: 0.0069 - val_mae: 0.0034\n",
      "Epoch 39/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0069 - mae: 0.0051 - val_loss: 0.0068 - val_mae: 0.0043\n",
      "Epoch 40/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0067 - mae: 0.0021 - val_loss: 0.0066 - val_mae: 0.0029\n",
      "Epoch 41/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0065 - mae: 0.0035 - val_loss: 0.0064 - val_mae: 0.0025\n",
      "Epoch 42/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0064 - mae: 0.0046 - val_loss: 0.0063 - val_mae: 0.0056\n",
      "Epoch 43/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0062 - mae: 0.0034 - val_loss: 0.0061 - val_mae: 0.0015\n",
      "Epoch 44/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0060 - mae: 0.0031 - val_loss: 0.0060 - val_mae: 0.0059\n",
      "Epoch 45/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0059 - mae: 0.0044 - val_loss: 0.0059 - val_mae: 0.0091\n",
      "Epoch 46/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0057 - mae: 0.0024 - val_loss: 0.0056 - val_mae: 0.0039\n",
      "Epoch 47/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0056 - mae: 0.0034 - val_loss: 0.0055 - val_mae: 0.0049\n",
      "Epoch 48/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0054 - mae: 0.0036 - val_loss: 0.0053 - val_mae: 0.0045\n",
      "Epoch 49/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0053 - mae: 0.0035 - val_loss: 0.0052 - val_mae: 0.0022\n",
      "Epoch 50/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0052 - mae: 0.0034 - val_loss: 0.0057 - val_mae: 0.0174\n",
      "Epoch 51/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0050 - mae: 0.0030 - val_loss: 0.0050 - val_mae: 0.0046\n",
      "Epoch 52/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0049 - mae: 0.0030 - val_loss: 0.0048 - val_mae: 0.0020\n",
      "Epoch 53/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0048 - mae: 0.0040 - val_loss: 0.0047 - val_mae: 0.0023\n",
      "Epoch 54/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0047 - mae: 0.0031 - val_loss: 0.0046 - val_mae: 0.0024\n",
      "Epoch 55/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0045 - mae: 0.0034 - val_loss: 0.0046 - val_mae: 0.0070\n",
      "Epoch 56/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0044 - mae: 0.0027 - val_loss: 0.0044 - val_mae: 0.0022\n",
      "Epoch 57/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0043 - mae: 0.0036 - val_loss: 0.0043 - val_mae: 0.0023\n",
      "Epoch 58/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0042 - mae: 0.0031 - val_loss: 0.0042 - val_mae: 0.0024\n",
      "Epoch 59/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0041 - mae: 0.0028 - val_loss: 0.0041 - val_mae: 0.0080\n",
      "Epoch 60/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0040 - mae: 0.0032 - val_loss: 0.0040 - val_mae: 0.0037\n",
      "Epoch 61/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0039 - mae: 0.0033 - val_loss: 0.0039 - val_mae: 0.0042\n",
      "Epoch 62/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0038 - mae: 0.0027 - val_loss: 0.0038 - val_mae: 0.0031\n",
      "Epoch 63/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0037 - mae: 0.0031 - val_loss: 0.0037 - val_mae: 0.0031\n",
      "Epoch 64/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0036 - mae: 0.0031 - val_loss: 0.0036 - val_mae: 0.0028\n",
      "Epoch 65/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0036 - mae: 0.0031 - val_loss: 0.0035 - val_mae: 0.0013\n",
      "Epoch 66/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0035 - mae: 0.0034 - val_loss: 0.0035 - val_mae: 0.0053\n",
      "Epoch 67/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0034 - mae: 0.0029 - val_loss: 0.0033 - val_mae: 0.0019\n",
      "Epoch 68/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0033 - mae: 0.0032 - val_loss: 0.0033 - val_mae: 0.0045\n",
      "Epoch 69/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0032 - mae: 0.0026 - val_loss: 0.0033 - val_mae: 0.0082\n",
      "Epoch 70/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0032 - mae: 0.0033 - val_loss: 0.0031 - val_mae: 0.0025\n",
      "Epoch 71/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0031 - mae: 0.0028 - val_loss: 0.0031 - val_mae: 0.0036\n",
      "Epoch 72/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0030 - mae: 0.0027 - val_loss: 0.0030 - val_mae: 0.0037\n",
      "Epoch 73/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0029 - mae: 0.0026 - val_loss: 0.0029 - val_mae: 0.0018\n",
      "Epoch 74/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0029 - mae: 0.0029 - val_loss: 0.0028 - val_mae: 0.0016\n",
      "Epoch 75/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0028 - mae: 0.0026 - val_loss: 0.0028 - val_mae: 0.0032\n",
      "Epoch 76/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0028 - mae: 0.0036 - val_loss: 0.0027 - val_mae: 0.0045\n",
      "Epoch 77/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0027 - mae: 0.0023 - val_loss: 0.0027 - val_mae: 0.0034\n",
      "Epoch 78/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0026 - mae: 0.0025 - val_loss: 0.0026 - val_mae: 0.0028\n",
      "Epoch 79/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0026 - mae: 0.0034 - val_loss: 0.0026 - val_mae: 0.0069\n",
      "Epoch 80/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0025 - mae: 0.0020 - val_loss: 0.0025 - val_mae: 0.0030\n",
      "Epoch 81/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0025 - mae: 0.0025 - val_loss: 0.0024 - val_mae: 0.0024\n",
      "Epoch 82/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0024 - mae: 0.0032 - val_loss: 0.0024 - val_mae: 0.0046\n",
      "Epoch 83/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0024 - mae: 0.0026 - val_loss: 0.0023 - val_mae: 0.0022\n",
      "Epoch 84/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0025 - val_loss: 0.0023 - val_mae: 0.0014\n",
      "Epoch 85/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0029 - val_loss: 0.0023 - val_mae: 0.0047\n",
      "Epoch 86/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0026 - val_loss: 0.0022 - val_mae: 0.0050\n",
      "Epoch 87/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0027 - val_loss: 0.0023 - val_mae: 0.0091\n",
      "Epoch 88/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0021 - mae: 0.0027 - val_loss: 0.0021 - val_mae: 0.0032\n",
      "Epoch 89/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0021 - mae: 0.0027 - val_loss: 0.0021 - val_mae: 0.0031\n",
      "Epoch 90/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0020 - mae: 0.0025 - val_loss: 0.0020 - val_mae: 0.0023\n",
      "Epoch 91/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0020 - mae: 0.0025 - val_loss: 0.0020 - val_mae: 0.0022\n",
      "Epoch 92/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0020 - mae: 0.0025 - val_loss: 0.0019 - val_mae: 0.0014\n",
      "Epoch 93/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0019 - mae: 0.0029 - val_loss: 0.0019 - val_mae: 0.0024\n",
      "Epoch 94/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0019 - mae: 0.0021 - val_loss: 0.0019 - val_mae: 0.0034\n",
      "Epoch 95/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0018 - mae: 0.0027 - val_loss: 0.0018 - val_mae: 0.0020\n",
      "Epoch 96/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0018 - mae: 0.0024 - val_loss: 0.0018 - val_mae: 0.0023\n",
      "Epoch 97/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0018 - mae: 0.0024 - val_loss: 0.0018 - val_mae: 0.0014\n",
      "Epoch 98/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0017 - mae: 0.0027 - val_loss: 0.0017 - val_mae: 0.0029\n",
      "Epoch 99/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0017 - mae: 0.0025 - val_loss: 0.0018 - val_mae: 0.0086\n",
      "Epoch 100/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0017 - mae: 0.0025 - val_loss: 0.0017 - val_mae: 0.0017\n",
      "Epoch 101/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0016 - mae: 0.0026 - val_loss: 0.0016 - val_mae: 0.0011\n",
      "Epoch 102/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0016 - mae: 0.0023 - val_loss: 0.0016 - val_mae: 0.0013\n",
      "Epoch 103/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0016 - mae: 0.0025 - val_loss: 0.0016 - val_mae: 0.0015\n",
      "Epoch 104/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0016 - mae: 0.0029 - val_loss: 0.0017 - val_mae: 0.0095\n",
      "Epoch 105/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0015 - mae: 0.0022 - val_loss: 0.0015 - val_mae: 0.0028\n",
      "Epoch 106/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0015 - mae: 0.0025 - val_loss: 0.0015 - val_mae: 0.0016\n",
      "Epoch 107/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0015 - mae: 0.0024 - val_loss: 0.0015 - val_mae: 0.0015\n",
      "Epoch 108/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0022 - val_loss: 0.0014 - val_mae: 0.0036\n",
      "Epoch 109/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0014 - mae: 0.0027 - val_loss: 0.0014 - val_mae: 0.0012\n",
      "Epoch 110/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0025 - val_loss: 0.0014 - val_mae: 0.0017\n",
      "Epoch 111/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0023 - val_loss: 0.0014 - val_mae: 0.0014\n",
      "Epoch 112/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0027 - val_loss: 0.0014 - val_mae: 0.0059\n",
      "Epoch 113/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0024 - val_loss: 0.0013 - val_mae: 0.0019\n",
      "Epoch 114/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0025 - val_loss: 0.0013 - val_mae: 0.0034\n",
      "Epoch 115/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0026 - val_loss: 0.0013 - val_mae: 0.0012\n",
      "Epoch 116/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0025 - val_loss: 0.0013 - val_mae: 0.0076\n",
      "Epoch 117/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0024 - val_loss: 0.0012 - val_mae: 0.0022\n",
      "Epoch 118/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0024 - val_loss: 0.0012 - val_mae: 0.0047\n",
      "Epoch 119/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0024 - val_loss: 0.0012 - val_mae: 0.0021\n",
      "Epoch 120/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0023 - val_loss: 0.0012 - val_mae: 0.0036\n",
      "Epoch 121/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0012 - mae: 0.0023 - val_loss: 0.0011 - val_mae: 0.0015\n",
      "Epoch 122/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0027 - val_loss: 0.0011 - val_mae: 0.0045\n",
      "Epoch 123/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0011 - mae: 0.0024 - val_loss: 0.0011 - val_mae: 0.0014\n",
      "Epoch 124/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0011 - mae: 0.0025 - val_loss: 0.0011 - val_mae: 0.0012\n",
      "Epoch 125/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0011 - mae: 0.0025 - val_loss: 0.0011 - val_mae: 0.0024\n",
      "Epoch 126/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0011 - mae: 0.0022 - val_loss: 0.0011 - val_mae: 0.0044\n",
      "Epoch 127/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0024 - val_loss: 0.0011 - val_mae: 0.0039\n",
      "Epoch 128/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0024 - val_loss: 0.0010 - val_mae: 0.0022\n",
      "Epoch 129/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0010 - mae: 0.0024 - val_loss: 0.0010 - val_mae: 0.0018\n",
      "Epoch 130/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0025 - val_loss: 9.8954e-04 - val_mae: 0.0014\n",
      "Epoch 131/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 9.8795e-04 - mae: 0.0023 - val_loss: 9.8067e-04 - val_mae: 0.0029\n",
      "Epoch 132/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 9.7422e-04 - mae: 0.0024 - val_loss: 9.6060e-04 - val_mae: 0.0015\n",
      "Epoch 133/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 9.6162e-04 - mae: 0.0024 - val_loss: 9.4658e-04 - val_mae: 0.0015\n",
      "Epoch 134/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 9.4309e-04 - mae: 0.0020 - val_loss: 0.0010 - val_mae: 0.0078\n",
      "Epoch 135/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 9.3384e-04 - mae: 0.0026 - val_loss: 9.1833e-04 - val_mae: 0.0014\n",
      "Epoch 136/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 9.1896e-04 - mae: 0.0025 - val_loss: 0.0010 - val_mae: 0.0076\n",
      "Epoch 137/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 9.0632e-04 - mae: 0.0023 - val_loss: 8.9844e-04 - val_mae: 0.0023\n",
      "Epoch 138/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 8.9278e-04 - mae: 0.0023 - val_loss: 8.8495e-04 - val_mae: 0.0020\n",
      "Epoch 139/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 8.7947e-04 - mae: 0.0023 - val_loss: 8.7092e-04 - val_mae: 0.0022\n",
      "Epoch 140/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 8.6792e-04 - mae: 0.0024 - val_loss: 8.6004e-04 - val_mae: 0.0025\n",
      "Epoch 141/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 8.5759e-04 - mae: 0.0026 - val_loss: 8.6711e-04 - val_mae: 0.0041\n",
      "Epoch 142/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 8.4294e-04 - mae: 0.0022 - val_loss: 8.3934e-04 - val_mae: 0.0022\n",
      "Epoch 143/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 8.3146e-04 - mae: 0.0022 - val_loss: 8.5656e-04 - val_mae: 0.0044\n",
      "Epoch 144/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 8.2262e-04 - mae: 0.0025 - val_loss: 8.2589e-04 - val_mae: 0.0040\n",
      "Epoch 145/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 8.1355e-04 - mae: 0.0026 - val_loss: 8.0354e-04 - val_mae: 0.0024\n",
      "Epoch 146/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 7.9936e-04 - mae: 0.0023 - val_loss: 8.2046e-04 - val_mae: 0.0045\n",
      "Epoch 147/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 7.8939e-04 - mae: 0.0023 - val_loss: 7.7923e-04 - val_mae: 0.0016\n",
      "Epoch 148/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 7.8011e-04 - mae: 0.0024 - val_loss: 7.6747e-04 - val_mae: 0.0013\n",
      "Epoch 149/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 7.7111e-04 - mae: 0.0025 - val_loss: 7.5767e-04 - val_mae: 0.0012\n",
      "Epoch 150/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 7.5968e-04 - mae: 0.0023 - val_loss: 7.6648e-04 - val_mae: 0.0039\n",
      "Epoch 151/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 7.5036e-04 - mae: 0.0024 - val_loss: 7.9901e-04 - val_mae: 0.0076\n",
      "Epoch 152/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 7.4102e-04 - mae: 0.0023 - val_loss: 7.3656e-04 - val_mae: 0.0026\n",
      "Epoch 153/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 7.2981e-04 - mae: 0.0022 - val_loss: 7.2017e-04 - val_mae: 0.0014\n",
      "Epoch 154/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 7.2183e-04 - mae: 0.0024 - val_loss: 7.1150e-04 - val_mae: 0.0018\n",
      "Epoch 155/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 7.1200e-04 - mae: 0.0022 - val_loss: 7.0584e-04 - val_mae: 0.0021\n",
      "Epoch 156/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 7.0145e-04 - mae: 0.0021 - val_loss: 6.9248e-04 - val_mae: 0.0014\n",
      "Epoch 157/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 6.9266e-04 - mae: 0.0021 - val_loss: 7.1209e-04 - val_mae: 0.0051\n",
      "Epoch 158/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 6.8532e-04 - mae: 0.0022 - val_loss: 6.7739e-04 - val_mae: 0.0019\n",
      "Epoch 159/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 6.7988e-04 - mae: 0.0024 - val_loss: 6.6629e-04 - val_mae: 0.0012\n",
      "Epoch 160/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 6.6747e-04 - mae: 0.0021 - val_loss: 6.6832e-04 - val_mae: 0.0029\n",
      "Epoch 161/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 6.5987e-04 - mae: 0.0021 - val_loss: 6.5658e-04 - val_mae: 0.0025\n",
      "Epoch 162/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 6.5219e-04 - mae: 0.0021 - val_loss: 6.4786e-04 - val_mae: 0.0023\n",
      "Epoch 163/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 6.4564e-04 - mae: 0.0023 - val_loss: 6.3743e-04 - val_mae: 0.0018\n",
      "Epoch 164/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 6.3545e-04 - mae: 0.0020 - val_loss: 6.3435e-04 - val_mae: 0.0024\n",
      "Epoch 165/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 6.2953e-04 - mae: 0.0022 - val_loss: 6.1989e-04 - val_mae: 0.0013\n",
      "Epoch 166/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 6.2024e-04 - mae: 0.0020 - val_loss: 6.1225e-04 - val_mae: 0.0013\n",
      "Epoch 167/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 6.1495e-04 - mae: 0.0022 - val_loss: 6.0551e-04 - val_mae: 0.0014\n",
      "Epoch 168/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 6.0894e-04 - mae: 0.0023 - val_loss: 5.9879e-04 - val_mae: 0.0013\n",
      "Epoch 169/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 5.9991e-04 - mae: 0.0021 - val_loss: 5.9795e-04 - val_mae: 0.0025\n",
      "Epoch 170/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 5.9412e-04 - mae: 0.0021 - val_loss: 5.8794e-04 - val_mae: 0.0019\n",
      "Epoch 171/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 5.8796e-04 - mae: 0.0021 - val_loss: 5.8601e-04 - val_mae: 0.0026\n",
      "Epoch 172/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 5.7964e-04 - mae: 0.0020 - val_loss: 7.2047e-04 - val_mae: 0.0118\n",
      "Epoch 173/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 5.7637e-04 - mae: 0.0021 - val_loss: 5.6688e-04 - val_mae: 0.0015\n",
      "Epoch 174/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 5.7047e-04 - mae: 0.0024 - val_loss: 5.7203e-04 - val_mae: 0.0032\n",
      "Epoch 175/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 5.6013e-04 - mae: 0.0018 - val_loss: 5.5666e-04 - val_mae: 0.0019\n",
      "Epoch 176/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 5.5614e-04 - mae: 0.0021 - val_loss: 5.4879e-04 - val_mae: 0.0015\n",
      "Epoch 177/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 5.4852e-04 - mae: 0.0019 - val_loss: 5.4304e-04 - val_mae: 0.0018\n",
      "Epoch 178/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 5.4469e-04 - mae: 0.0021 - val_loss: 5.5327e-04 - val_mae: 0.0034\n",
      "Epoch 179/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 5.4317e-04 - mae: 0.0021 - val_loss: 5.3947e-04 - val_mae: 0.0027\n",
      "Epoch 180/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 5.3080e-04 - mae: 0.0017 - val_loss: 5.2592e-04 - val_mae: 0.0013\n",
      "Epoch 181/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 5.2778e-04 - mae: 0.0020 - val_loss: 5.2985e-04 - val_mae: 0.0032\n",
      "Epoch 182/400\n",
      "645/645 [==============================] - 4s 5ms/step - loss: 5.2554e-04 - mae: 0.0023 - val_loss: 5.2316e-04 - val_mae: 0.0025\n",
      "Epoch 183/400\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 5.2060e-04 - mae: 0.0021 - val_loss: 5.2326e-04 - val_mae: 0.0028\n",
      "Epoch 184/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 5.1158e-04 - mae: 0.0019 - val_loss: 5.0846e-04 - val_mae: 0.0019\n",
      "Epoch 185/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 5.1222e-04 - mae: 0.0023 - val_loss: 5.0040e-04 - val_mae: 0.0010\n",
      "Epoch 186/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 5.0249e-04 - mae: 0.0019 - val_loss: 5.1979e-04 - val_mae: 0.0037\n",
      "Epoch 187/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 4.9931e-04 - mae: 0.0021 - val_loss: 4.9279e-04 - val_mae: 0.0016\n",
      "Epoch 188/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 4.9694e-04 - mae: 0.0023 - val_loss: 4.9457e-04 - val_mae: 0.0028\n",
      "Epoch 189/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 4.9111e-04 - mae: 0.0022 - val_loss: 5.0774e-04 - val_mae: 0.0038\n",
      "Epoch 190/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 4.8602e-04 - mae: 0.0021 - val_loss: 4.8107e-04 - val_mae: 0.0017\n",
      "Epoch 191/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 4.7986e-04 - mae: 0.0019 - val_loss: 4.8521e-04 - val_mae: 0.0033\n",
      "Epoch 192/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 4.7760e-04 - mae: 0.0021 - val_loss: 4.7093e-04 - val_mae: 0.0014\n",
      "Epoch 193/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 4.7324e-04 - mae: 0.0021 - val_loss: 4.8155e-04 - val_mae: 0.0037\n",
      "Epoch 194/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 4.6784e-04 - mae: 0.0020 - val_loss: 4.6108e-04 - val_mae: 0.0012\n",
      "Epoch 195/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 4.6512e-04 - mae: 0.0022 - val_loss: 4.8233e-04 - val_mae: 0.0042\n",
      "Epoch 196/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 4.6122e-04 - mae: 0.0021 - val_loss: 4.6048e-04 - val_mae: 0.0025\n",
      "Epoch 197/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 4.5559e-04 - mae: 0.0020 - val_loss: 4.5165e-04 - val_mae: 0.0020\n",
      "Epoch 198/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 4.5215e-04 - mae: 0.0021 - val_loss: 4.5384e-04 - val_mae: 0.0029\n",
      "Epoch 199/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 4.4873e-04 - mae: 0.0021 - val_loss: 4.4984e-04 - val_mae: 0.0026\n",
      "Epoch 200/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 4.4452e-04 - mae: 0.0021 - val_loss: 4.4008e-04 - val_mae: 0.0017\n",
      "Epoch 201/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 4.4199e-04 - mae: 0.0022 - val_loss: 4.3650e-04 - val_mae: 0.0018\n",
      "Epoch 202/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 4.3685e-04 - mae: 0.0020 - val_loss: 4.3974e-04 - val_mae: 0.0028\n",
      "Epoch 203/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 4.3259e-04 - mae: 0.0019 - val_loss: 4.3320e-04 - val_mae: 0.0023\n",
      "Epoch 204/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 4.3112e-04 - mae: 0.0022 - val_loss: 4.2310e-04 - val_mae: 0.0012\n",
      "Epoch 205/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 4.2670e-04 - mae: 0.0020 - val_loss: 4.5811e-04 - val_mae: 0.0052\n",
      "Epoch 206/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 4.2275e-04 - mae: 0.0020 - val_loss: 4.2962e-04 - val_mae: 0.0030\n",
      "Epoch 207/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 4.2032e-04 - mae: 0.0021 - val_loss: 4.3223e-04 - val_mae: 0.0036\n",
      "Epoch 208/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 4.1874e-04 - mae: 0.0023 - val_loss: 4.1200e-04 - val_mae: 0.0015\n",
      "Epoch 209/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 4.1527e-04 - mae: 0.0020 - val_loss: 4.1222e-04 - val_mae: 0.0022\n",
      "Epoch 210/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 4.1018e-04 - mae: 0.0020 - val_loss: 4.0578e-04 - val_mae: 0.0016\n",
      "Epoch 211/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 4.0813e-04 - mae: 0.0021 - val_loss: 4.0262e-04 - val_mae: 0.0015\n",
      "Epoch 212/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 4.0546e-04 - mae: 0.0021 - val_loss: 4.2824e-04 - val_mae: 0.0047\n",
      "Epoch 213/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 4.0146e-04 - mae: 0.0020 - val_loss: 3.9496e-04 - val_mae: 0.0010\n",
      "Epoch 214/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.9917e-04 - mae: 0.0020 - val_loss: 5.1727e-04 - val_mae: 0.0083\n",
      "Epoch 215/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 3.9873e-04 - mae: 0.0021 - val_loss: 3.9600e-04 - val_mae: 0.0024\n",
      "Epoch 216/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 4.0613e-04 - mae: 0.0026 - val_loss: 3.8879e-04 - val_mae: 0.0015\n",
      "Epoch 217/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.8817e-04 - mae: 0.0015 - val_loss: 4.0689e-04 - val_mae: 0.0039\n",
      "Epoch 218/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.8685e-04 - mae: 0.0017 - val_loss: 3.9368e-04 - val_mae: 0.0031\n",
      "Epoch 219/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.8738e-04 - mae: 0.0021 - val_loss: 3.8206e-04 - val_mae: 0.0018\n",
      "Epoch 220/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 3.8445e-04 - mae: 0.0021 - val_loss: 3.8039e-04 - val_mae: 0.0016\n",
      "Epoch 221/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 3.8136e-04 - mae: 0.0020 - val_loss: 3.7500e-04 - val_mae: 0.0011\n",
      "Epoch 222/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.7908e-04 - mae: 0.0020 - val_loss: 3.7371e-04 - val_mae: 0.0015\n",
      "Epoch 223/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.7611e-04 - mae: 0.0019 - val_loss: 3.7143e-04 - val_mae: 0.0016\n",
      "Epoch 224/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.7439e-04 - mae: 0.0021 - val_loss: 3.7935e-04 - val_mae: 0.0031\n",
      "Epoch 225/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.7249e-04 - mae: 0.0022 - val_loss: 3.6700e-04 - val_mae: 0.0018\n",
      "Epoch 226/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.7031e-04 - mae: 0.0021 - val_loss: 3.9408e-04 - val_mae: 0.0053\n",
      "Epoch 227/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.6655e-04 - mae: 0.0020 - val_loss: 3.6109e-04 - val_mae: 0.0014\n",
      "Epoch 228/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.6259e-04 - mae: 0.0018 - val_loss: 3.6569e-04 - val_mae: 0.0026\n",
      "Epoch 229/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 3.6336e-04 - mae: 0.0022 - val_loss: 3.6259e-04 - val_mae: 0.0026\n",
      "Epoch 230/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.6041e-04 - mae: 0.0021 - val_loss: 3.5549e-04 - val_mae: 0.0016\n",
      "Epoch 231/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.5746e-04 - mae: 0.0020 - val_loss: 3.5939e-04 - val_mae: 0.0025\n",
      "Epoch 232/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.5882e-04 - mae: 0.0022 - val_loss: 3.4923e-04 - val_mae: 0.0011\n",
      "Epoch 233/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.5192e-04 - mae: 0.0019 - val_loss: 3.4724e-04 - val_mae: 0.0011\n",
      "Epoch 234/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.5337e-04 - mae: 0.0023 - val_loss: 3.4560e-04 - val_mae: 0.0012\n",
      "Epoch 235/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.4773e-04 - mae: 0.0018 - val_loss: 3.5209e-04 - val_mae: 0.0028\n",
      "Epoch 236/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.4976e-04 - mae: 0.0023 - val_loss: 3.4274e-04 - val_mae: 0.0016\n",
      "Epoch 237/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.4577e-04 - mae: 0.0021 - val_loss: 3.4149e-04 - val_mae: 0.0018\n",
      "Epoch 238/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.4480e-04 - mae: 0.0022 - val_loss: 3.3942e-04 - val_mae: 0.0017\n",
      "Epoch 239/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.3931e-04 - mae: 0.0017 - val_loss: 3.3715e-04 - val_mae: 0.0016\n",
      "Epoch 240/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.4188e-04 - mae: 0.0023 - val_loss: 4.4541e-04 - val_mae: 0.0077\n",
      "Epoch 241/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.4017e-04 - mae: 0.0022 - val_loss: 3.4514e-04 - val_mae: 0.0032\n",
      "Epoch 242/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.3477e-04 - mae: 0.0019 - val_loss: 3.3151e-04 - val_mae: 0.0015\n",
      "Epoch 243/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 3.3518e-04 - mae: 0.0021 - val_loss: 3.3479e-04 - val_mae: 0.0026\n",
      "Epoch 244/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 3.3300e-04 - mae: 0.0021 - val_loss: 3.3603e-04 - val_mae: 0.0030\n",
      "Epoch 245/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.3118e-04 - mae: 0.0021 - val_loss: 3.2618e-04 - val_mae: 0.0017\n",
      "Epoch 246/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 3.2954e-04 - mae: 0.0022 - val_loss: 3.2603e-04 - val_mae: 0.0018\n",
      "Epoch 247/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.2691e-04 - mae: 0.0021 - val_loss: 3.2674e-04 - val_mae: 0.0023\n",
      "Epoch 248/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.2516e-04 - mae: 0.0021 - val_loss: 3.1950e-04 - val_mae: 0.0014\n",
      "Epoch 249/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.2304e-04 - mae: 0.0020 - val_loss: 3.2437e-04 - val_mae: 0.0027\n",
      "Epoch 250/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.2286e-04 - mae: 0.0022 - val_loss: 4.1958e-04 - val_mae: 0.0076\n",
      "Epoch 251/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.2101e-04 - mae: 0.0022 - val_loss: 3.2030e-04 - val_mae: 0.0026\n",
      "Epoch 252/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.1690e-04 - mae: 0.0019 - val_loss: 3.2409e-04 - val_mae: 0.0035\n",
      "Epoch 253/400\n",
      "640/645 [============================>.] - ETA: 0s - loss: 3.1877e-04 - mae: 0.0022Restoring model weights from the end of the best epoch: 248.\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 3.1889e-04 - mae: 0.0023 - val_loss: 4.0102e-04 - val_mae: 0.0073\n",
      "Epoch 253: early stopping\n",
      "Die AusfÃ¼hrungszeit betrug 786.036984205246 Sekunden.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Netzwerkarchitektur\n",
    "model = Sequential([\n",
    "    # Eingabeschicht\n",
    "\n",
    "    Dense(80, activation='relu', input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(208, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(320, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(240, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(224, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(160, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(128, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(240, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(256, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(32, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(1 , activation = 'linear')\n",
    "])\n",
    "\n",
    "# Optimierer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "# Modell kompilieren (Verwendung von mean_squared_error als Verlustfunktion fÃ¼r Regression)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])  # Metriken fÃ¼r Regression: Mean Absolute Error und Mean Squared Error\n",
    "\n",
    "# Early Stopping Callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=2, mode='min', restore_best_weights=True)#, min_delta = 0.00005)\n",
    "\n",
    "# Trainingsparameter\n",
    "batch_size = 100\n",
    "epochs = 400\n",
    "\n",
    "# Modell trainieren (Annahme: X_train, y_train, X_val, y_val sind vordefiniert)\n",
    "history = model.fit(X_train_scaled, y_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose = 1)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Berechne die Dauer\n",
    "duration = end_time - start_time\n",
    "\n",
    "print(f\"Die AusfÃ¼hrungszeit betrug {duration} Sekunden.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T14:05:16.231959Z",
     "start_time": "2024-03-19T13:52:10.177213Z"
    }
   },
   "id": "8b52e1a9a6ff3aeb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# k-Fold Crossvalidation \n",
    "FÃ¼r die Performancebestimmung der unterschiedlichen Netzarchitekturen"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7928df8ec1031de"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "Training fÃ¼r Fold 1...\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "645/645 [==============================] - 4s 5ms/step - loss: 0.3110 - mae: 0.0778 - val_loss: 0.2223 - val_mae: 0.0082\n",
      "Epoch 2/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.1886 - mae: 0.0160 - val_loss: 0.1632 - val_mae: 0.0094\n",
      "Epoch 3/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.1504 - mae: 0.0164 - val_loss: 0.1397 - val_mae: 0.0124\n",
      "Epoch 4/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.1333 - mae: 0.0111 - val_loss: 0.1338 - val_mae: 0.0668\n",
      "Epoch 5/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.1238 - mae: 0.0138 - val_loss: 0.1197 - val_mae: 0.0151\n",
      "Epoch 6/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.1162 - mae: 0.0123 - val_loss: 0.1126 - val_mae: 0.0060\n",
      "Epoch 7/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.1098 - mae: 0.0116 - val_loss: 0.1068 - val_mae: 0.0141\n",
      "Epoch 8/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.1038 - mae: 0.0102 - val_loss: 0.1012 - val_mae: 0.0168\n",
      "Epoch 9/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0986 - mae: 0.0140 - val_loss: 0.0956 - val_mae: 0.0052\n",
      "Epoch 10/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0932 - mae: 0.0066 - val_loss: 0.0907 - val_mae: 0.0067\n",
      "Epoch 11/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0887 - mae: 0.0095 - val_loss: 0.0861 - val_mae: 0.0047\n",
      "Epoch 12/1000\n",
      "645/645 [==============================] - 4s 5ms/step - loss: 0.0841 - mae: 0.0096 - val_loss: 0.0823 - val_mae: 0.0186\n",
      "Epoch 13/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0798 - mae: 0.0090 - val_loss: 0.0779 - val_mae: 0.0153\n",
      "Epoch 14/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0757 - mae: 0.0087 - val_loss: 0.0736 - val_mae: 0.0036\n",
      "Epoch 15/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0719 - mae: 0.0101 - val_loss: 0.0700 - val_mae: 0.0096\n",
      "Epoch 16/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0682 - mae: 0.0069 - val_loss: 0.0664 - val_mae: 0.0094\n",
      "Epoch 17/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0646 - mae: 0.0082 - val_loss: 0.0628 - val_mae: 0.0079\n",
      "Epoch 18/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0612 - mae: 0.0079 - val_loss: 0.0597 - val_mae: 0.0149\n",
      "Epoch 19/1000\n",
      "645/645 [==============================] - 4s 7ms/step - loss: 0.0579 - mae: 0.0076 - val_loss: 0.0562 - val_mae: 0.0042\n",
      "Epoch 20/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0546 - mae: 0.0062 - val_loss: 0.0530 - val_mae: 0.0042\n",
      "Epoch 21/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0516 - mae: 0.0080 - val_loss: 0.0501 - val_mae: 0.0047\n",
      "Epoch 22/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0487 - mae: 0.0074 - val_loss: 0.0473 - val_mae: 0.0052\n",
      "Epoch 23/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0459 - mae: 0.0062 - val_loss: 0.0450 - val_mae: 0.0198\n",
      "Epoch 24/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0433 - mae: 0.0066 - val_loss: 0.0424 - val_mae: 0.0172\n",
      "Epoch 25/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0408 - mae: 0.0067 - val_loss: 0.0395 - val_mae: 0.0035\n",
      "Epoch 26/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0383 - mae: 0.0064 - val_loss: 0.0371 - val_mae: 0.0061\n",
      "Epoch 27/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0360 - mae: 0.0070 - val_loss: 0.0348 - val_mae: 0.0039\n",
      "Epoch 28/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0338 - mae: 0.0068 - val_loss: 0.0328 - val_mae: 0.0061\n",
      "Epoch 29/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0319 - mae: 0.0065 - val_loss: 0.0309 - val_mae: 0.0038\n",
      "Epoch 30/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0300 - mae: 0.0055 - val_loss: 0.0293 - val_mae: 0.0142\n",
      "Epoch 31/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0282 - mae: 0.0061 - val_loss: 0.0273 - val_mae: 0.0046\n",
      "Epoch 32/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0265 - mae: 0.0054 - val_loss: 0.0256 - val_mae: 0.0062\n",
      "Epoch 33/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0248 - mae: 0.0054 - val_loss: 0.0241 - val_mae: 0.0120\n",
      "Epoch 34/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0232 - mae: 0.0054 - val_loss: 0.0224 - val_mae: 0.0048\n",
      "Epoch 35/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0217 - mae: 0.0053 - val_loss: 0.0209 - val_mae: 0.0039\n",
      "Epoch 36/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0203 - mae: 0.0050 - val_loss: 0.0195 - val_mae: 0.0036\n",
      "Epoch 37/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0189 - mae: 0.0053 - val_loss: 0.0183 - val_mae: 0.0062\n",
      "Epoch 38/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0177 - mae: 0.0055 - val_loss: 0.0171 - val_mae: 0.0030\n",
      "Epoch 39/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0165 - mae: 0.0048 - val_loss: 0.0160 - val_mae: 0.0048\n",
      "Epoch 40/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0154 - mae: 0.0049 - val_loss: 0.0149 - val_mae: 0.0040\n",
      "Epoch 41/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0144 - mae: 0.0046 - val_loss: 0.0140 - val_mae: 0.0102\n",
      "Epoch 42/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0134 - mae: 0.0048 - val_loss: 0.0129 - val_mae: 0.0046\n",
      "Epoch 43/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0124 - mae: 0.0048 - val_loss: 0.0120 - val_mae: 0.0044\n",
      "Epoch 44/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0115 - mae: 0.0046 - val_loss: 0.0111 - val_mae: 0.0035\n",
      "Epoch 45/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0107 - mae: 0.0046 - val_loss: 0.0104 - val_mae: 0.0060\n",
      "Epoch 46/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0100 - mae: 0.0050 - val_loss: 0.0097 - val_mae: 0.0078\n",
      "Epoch 47/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0093 - mae: 0.0042 - val_loss: 0.0090 - val_mae: 0.0040\n",
      "Epoch 48/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0087 - mae: 0.0045 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 49/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0081 - mae: 0.0047 - val_loss: 0.0078 - val_mae: 0.0056\n",
      "Epoch 50/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0075 - mae: 0.0043 - val_loss: 0.0073 - val_mae: 0.0063\n",
      "Epoch 51/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0070 - mae: 0.0046 - val_loss: 0.0068 - val_mae: 0.0038\n",
      "Epoch 52/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0066 - mae: 0.0044 - val_loss: 0.0063 - val_mae: 0.0045\n",
      "Epoch 53/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0061 - mae: 0.0046 - val_loss: 0.0059 - val_mae: 0.0035\n",
      "Epoch 54/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0058 - mae: 0.0044 - val_loss: 0.0056 - val_mae: 0.0043\n",
      "Epoch 55/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0054 - mae: 0.0043 - val_loss: 0.0052 - val_mae: 0.0035\n",
      "Epoch 56/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0051 - mae: 0.0045 - val_loss: 0.0049 - val_mae: 0.0039\n",
      "Epoch 57/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0048 - mae: 0.0044 - val_loss: 0.0047 - val_mae: 0.0047\n",
      "Epoch 58/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0046 - mae: 0.0042 - val_loss: 0.0045 - val_mae: 0.0060\n",
      "Epoch 59/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0043 - mae: 0.0045 - val_loss: 0.0042 - val_mae: 0.0069\n",
      "Epoch 60/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0041 - mae: 0.0043 - val_loss: 0.0040 - val_mae: 0.0056\n",
      "Epoch 61/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0039 - mae: 0.0044 - val_loss: 0.0038 - val_mae: 0.0038\n",
      "Epoch 62/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0037 - mae: 0.0047 - val_loss: 0.0036 - val_mae: 0.0054\n",
      "Epoch 63/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0036 - mae: 0.0041 - val_loss: 0.0035 - val_mae: 0.0066\n",
      "Epoch 64/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0034 - mae: 0.0044 - val_loss: 0.0034 - val_mae: 0.0088\n",
      "Epoch 65/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0033 - mae: 0.0044 - val_loss: 0.0032 - val_mae: 0.0031\n",
      "Epoch 66/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0031 - mae: 0.0040 - val_loss: 0.0031 - val_mae: 0.0038\n",
      "Epoch 67/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0030 - mae: 0.0042 - val_loss: 0.0030 - val_mae: 0.0036\n",
      "Epoch 68/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0029 - mae: 0.0042 - val_loss: 0.0028 - val_mae: 0.0036\n",
      "Epoch 69/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0028 - mae: 0.0042 - val_loss: 0.0027 - val_mae: 0.0031\n",
      "Epoch 70/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0027 - mae: 0.0043 - val_loss: 0.0027 - val_mae: 0.0047\n",
      "Epoch 71/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0026 - mae: 0.0040 - val_loss: 0.0026 - val_mae: 0.0090\n",
      "Epoch 72/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0025 - mae: 0.0041 - val_loss: 0.0025 - val_mae: 0.0033\n",
      "Epoch 73/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0025 - mae: 0.0045 - val_loss: 0.0024 - val_mae: 0.0041\n",
      "Epoch 74/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0024 - mae: 0.0041 - val_loss: 0.0024 - val_mae: 0.0032\n",
      "Epoch 75/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0023 - mae: 0.0041 - val_loss: 0.0023 - val_mae: 0.0046\n",
      "Epoch 76/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0023 - mae: 0.0042 - val_loss: 0.0023 - val_mae: 0.0066\n",
      "Epoch 77/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0022 - mae: 0.0043 - val_loss: 0.0022 - val_mae: 0.0082\n",
      "Epoch 78/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0022 - mae: 0.0043 - val_loss: 0.0021 - val_mae: 0.0039\n",
      "Epoch 79/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0021 - mae: 0.0046 - val_loss: 0.0021 - val_mae: 0.0030\n",
      "Epoch 80/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0021 - mae: 0.0041 - val_loss: 0.0021 - val_mae: 0.0056\n",
      "Epoch 81/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0020 - mae: 0.0041 - val_loss: 0.0020 - val_mae: 0.0044\n",
      "Epoch 82/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0020 - mae: 0.0043 - val_loss: 0.0020 - val_mae: 0.0056\n",
      "Epoch 83/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0020 - mae: 0.0044 - val_loss: 0.0020 - val_mae: 0.0090\n",
      "Epoch 84/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0019 - mae: 0.0042 - val_loss: 0.0019 - val_mae: 0.0033\n",
      "Epoch 85/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0019 - mae: 0.0043 - val_loss: 0.0020 - val_mae: 0.0108\n",
      "Epoch 86/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0019 - mae: 0.0042 - val_loss: 0.0018 - val_mae: 0.0031\n",
      "Epoch 87/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0018 - mae: 0.0042 - val_loss: 0.0018 - val_mae: 0.0033\n",
      "Epoch 88/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0018 - mae: 0.0043 - val_loss: 0.0018 - val_mae: 0.0062\n",
      "Epoch 89/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0018 - mae: 0.0041 - val_loss: 0.0018 - val_mae: 0.0033\n",
      "Epoch 90/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0018 - mae: 0.0044 - val_loss: 0.0018 - val_mae: 0.0044\n",
      "Epoch 91/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0018 - mae: 0.0041 - val_loss: 0.0017 - val_mae: 0.0030\n",
      "Epoch 92/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0017 - mae: 0.0043 - val_loss: 0.0017 - val_mae: 0.0035\n",
      "Epoch 93/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0017 - mae: 0.0040 - val_loss: 0.0018 - val_mae: 0.0108\n",
      "Epoch 94/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0017 - mae: 0.0042 - val_loss: 0.0017 - val_mae: 0.0031\n",
      "Epoch 95/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0017 - mae: 0.0043 - val_loss: 0.0017 - val_mae: 0.0044\n",
      "Epoch 96/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0017 - mae: 0.0042 - val_loss: 0.0017 - val_mae: 0.0054\n",
      "Epoch 97/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0016 - mae: 0.0041 - val_loss: 0.0016 - val_mae: 0.0048\n",
      "Epoch 98/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0016 - mae: 0.0043 - val_loss: 0.0016 - val_mae: 0.0047\n",
      "Epoch 99/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0016 - mae: 0.0042 - val_loss: 0.0016 - val_mae: 0.0035\n",
      "Epoch 100/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0016 - mae: 0.0040 - val_loss: 0.0016 - val_mae: 0.0033\n",
      "Epoch 101/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0052\n",
      "Epoch 102/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0016 - mae: 0.0042 - val_loss: 0.0016 - val_mae: 0.0042\n",
      "Epoch 103/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0044\n",
      "Epoch 104/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0016 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0031\n",
      "Epoch 105/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0017 - val_mae: 0.0127\n",
      "Epoch 106/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0030\n",
      "Epoch 107/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0015 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0040\n",
      "Epoch 108/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0015 - mae: 0.0040 - val_loss: 0.0015 - val_mae: 0.0060\n",
      "Epoch 109/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0015 - mae: 0.0040 - val_loss: 0.0015 - val_mae: 0.0042\n",
      "Epoch 110/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0015 - mae: 0.0048 - val_loss: 0.0015 - val_mae: 0.0048\n",
      "Epoch 111/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0029\n",
      "Epoch 112/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0038\n",
      "Epoch 113/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 0.0015 - val_mae: 0.0067\n",
      "Epoch 114/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0015 - mae: 0.0049 - val_loss: 0.0015 - val_mae: 0.0087\n",
      "Epoch 115/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0068\n",
      "Epoch 116/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0045\n",
      "Epoch 117/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0015 - mae: 0.0047 - val_loss: 0.0016 - val_mae: 0.0098\n",
      "Epoch 118/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0050\n",
      "Epoch 119/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0061\n",
      "Epoch 120/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0014 - mae: 0.0046 - val_loss: 0.0014 - val_mae: 0.0031\n",
      "Epoch 121/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0033\n",
      "Epoch 122/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0056\n",
      "Epoch 123/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0014 - mae: 0.0046 - val_loss: 0.0014 - val_mae: 0.0052\n",
      "Epoch 124/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0038\n",
      "Epoch 125/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0063\n",
      "Epoch 126/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0014 - mae: 0.0046 - val_loss: 0.0014 - val_mae: 0.0036\n",
      "Epoch 127/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0033\n",
      "Epoch 128/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0054\n",
      "Epoch 129/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0071\n",
      "Epoch 130/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0038\n",
      "Epoch 131/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0046\n",
      "Epoch 132/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0014 - mae: 0.0046 - val_loss: 0.0014 - val_mae: 0.0033\n",
      "Epoch 133/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0014 - mae: 0.0046 - val_loss: 0.0014 - val_mae: 0.0043\n",
      "Epoch 134/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0061\n",
      "Epoch 135/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0052\n",
      "Epoch 136/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0042\n",
      "Epoch 137/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0067\n",
      "Epoch 138/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0014 - mae: 0.0046 - val_loss: 0.0014 - val_mae: 0.0046\n",
      "Epoch 139/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0048\n",
      "Epoch 140/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0014 - mae: 0.0046 - val_loss: 0.0014 - val_mae: 0.0074\n",
      "Epoch 141/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0013 - mae: 0.0046 - val_loss: 0.0014 - val_mae: 0.0055\n",
      "Epoch 142/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0053\n",
      "Epoch 143/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0030\n",
      "Epoch 144/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0067\n",
      "Epoch 145/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0041\n",
      "Epoch 146/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0104\n",
      "Epoch 147/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0074\n",
      "Epoch 148/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0042\n",
      "Epoch 149/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0013 - mae: 0.0046 - val_loss: 0.0013 - val_mae: 0.0067\n",
      "Epoch 150/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0013 - mae: 0.0046 - val_loss: 0.0013 - val_mae: 0.0039\n",
      "Epoch 151/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0044\n",
      "Epoch 152/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0048\n",
      "Epoch 153/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0013 - mae: 0.0046 - val_loss: 0.0013 - val_mae: 0.0059\n",
      "Epoch 154/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0013 - mae: 0.0046 - val_loss: 0.0013 - val_mae: 0.0058\n",
      "Epoch 155/1000\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0046Restoring model weights from the end of the best epoch: 150.\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0013 - mae: 0.0046 - val_loss: 0.0014 - val_mae: 0.0079\n",
      "Epoch 155: early stopping\n",
      "Training fÃ¼r Fold 2...\n",
      "Epoch 1/1000\n",
      "645/645 [==============================] - 6s 6ms/step - loss: 0.3511 - mae: 0.1222 - val_loss: 0.2391 - val_mae: 0.0096\n",
      "Epoch 2/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.2092 - mae: 0.0171 - val_loss: 0.1912 - val_mae: 0.0518\n",
      "Epoch 3/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.1743 - mae: 0.0140 - val_loss: 0.1645 - val_mae: 0.0145\n",
      "Epoch 4/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.1582 - mae: 0.0111 - val_loss: 0.1528 - val_mae: 0.0161\n",
      "Epoch 5/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.1488 - mae: 0.0151 - val_loss: 0.1445 - val_mae: 0.0209\n",
      "Epoch 6/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.1403 - mae: 0.0112 - val_loss: 0.1363 - val_mae: 0.0088\n",
      "Epoch 7/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.1327 - mae: 0.0091 - val_loss: 0.1289 - val_mae: 0.0050\n",
      "Epoch 8/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.1258 - mae: 0.0131 - val_loss: 0.1218 - val_mae: 0.0048\n",
      "Epoch 9/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.1184 - mae: 0.0091 - val_loss: 0.1149 - val_mae: 0.0085\n",
      "Epoch 10/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.1118 - mae: 0.0120 - val_loss: 0.1081 - val_mae: 0.0085\n",
      "Epoch 11/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.1048 - mae: 0.0076 - val_loss: 0.1014 - val_mae: 0.0059\n",
      "Epoch 12/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0983 - mae: 0.0072 - val_loss: 0.0963 - val_mae: 0.0291\n",
      "Epoch 13/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0921 - mae: 0.0108 - val_loss: 0.0889 - val_mae: 0.0081\n",
      "Epoch 14/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0860 - mae: 0.0065 - val_loss: 0.0830 - val_mae: 0.0039\n",
      "Epoch 15/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0803 - mae: 0.0084 - val_loss: 0.0775 - val_mae: 0.0110\n",
      "Epoch 16/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0749 - mae: 0.0090 - val_loss: 0.0722 - val_mae: 0.0034\n",
      "Epoch 17/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0699 - mae: 0.0064 - val_loss: 0.0676 - val_mae: 0.0072\n",
      "Epoch 18/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0653 - mae: 0.0065 - val_loss: 0.0631 - val_mae: 0.0073\n",
      "Epoch 19/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0612 - mae: 0.0069 - val_loss: 0.0592 - val_mae: 0.0057\n",
      "Epoch 20/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0573 - mae: 0.0067 - val_loss: 0.0553 - val_mae: 0.0033\n",
      "Epoch 21/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0536 - mae: 0.0080 - val_loss: 0.0518 - val_mae: 0.0054\n",
      "Epoch 22/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0502 - mae: 0.0045 - val_loss: 0.0486 - val_mae: 0.0034\n",
      "Epoch 23/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0471 - mae: 0.0068 - val_loss: 0.0455 - val_mae: 0.0039\n",
      "Epoch 24/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0441 - mae: 0.0061 - val_loss: 0.0427 - val_mae: 0.0045\n",
      "Epoch 25/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0415 - mae: 0.0061 - val_loss: 0.0404 - val_mae: 0.0135\n",
      "Epoch 26/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0389 - mae: 0.0064 - val_loss: 0.0377 - val_mae: 0.0068\n",
      "Epoch 27/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0366 - mae: 0.0069 - val_loss: 0.0354 - val_mae: 0.0036\n",
      "Epoch 28/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0344 - mae: 0.0050 - val_loss: 0.0333 - val_mae: 0.0039\n",
      "Epoch 29/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0323 - mae: 0.0052 - val_loss: 0.0312 - val_mae: 0.0040\n",
      "Epoch 30/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0302 - mae: 0.0054 - val_loss: 0.0291 - val_mae: 0.0045\n",
      "Epoch 31/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0282 - mae: 0.0058 - val_loss: 0.0273 - val_mae: 0.0035\n",
      "Epoch 32/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0265 - mae: 0.0051 - val_loss: 0.0256 - val_mae: 0.0052\n",
      "Epoch 33/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0248 - mae: 0.0054 - val_loss: 0.0239 - val_mae: 0.0036\n",
      "Epoch 34/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0232 - mae: 0.0055 - val_loss: 0.0224 - val_mae: 0.0034\n",
      "Epoch 35/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0217 - mae: 0.0052 - val_loss: 0.0211 - val_mae: 0.0085\n",
      "Epoch 36/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0205 - mae: 0.0058 - val_loss: 0.0198 - val_mae: 0.0041\n",
      "Epoch 37/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0193 - mae: 0.0050 - val_loss: 0.0187 - val_mae: 0.0033\n",
      "Epoch 38/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0183 - mae: 0.0054 - val_loss: 0.0177 - val_mae: 0.0034\n",
      "Epoch 39/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0173 - mae: 0.0048 - val_loss: 0.0168 - val_mae: 0.0052\n",
      "Epoch 40/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0164 - mae: 0.0062 - val_loss: 0.0160 - val_mae: 0.0061\n",
      "Epoch 41/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0156 - mae: 0.0042 - val_loss: 0.0152 - val_mae: 0.0059\n",
      "Epoch 42/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0147 - mae: 0.0046 - val_loss: 0.0143 - val_mae: 0.0041\n",
      "Epoch 43/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0139 - mae: 0.0052 - val_loss: 0.0135 - val_mae: 0.0044\n",
      "Epoch 44/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0132 - mae: 0.0048 - val_loss: 0.0128 - val_mae: 0.0035\n",
      "Epoch 45/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0125 - mae: 0.0051 - val_loss: 0.0121 - val_mae: 0.0041\n",
      "Epoch 46/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0118 - mae: 0.0050 - val_loss: 0.0115 - val_mae: 0.0073\n",
      "Epoch 47/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0112 - mae: 0.0050 - val_loss: 0.0109 - val_mae: 0.0049\n",
      "Epoch 48/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0106 - mae: 0.0051 - val_loss: 0.0103 - val_mae: 0.0056\n",
      "Epoch 49/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0100 - mae: 0.0047 - val_loss: 0.0097 - val_mae: 0.0074\n",
      "Epoch 50/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0094 - mae: 0.0050 - val_loss: 0.0092 - val_mae: 0.0065\n",
      "Epoch 51/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0089 - mae: 0.0043 - val_loss: 0.0087 - val_mae: 0.0032\n",
      "Epoch 52/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0084 - mae: 0.0044 - val_loss: 0.0082 - val_mae: 0.0034\n",
      "Epoch 53/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0079 - mae: 0.0046 - val_loss: 0.0077 - val_mae: 0.0040\n",
      "Epoch 54/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0075 - mae: 0.0045 - val_loss: 0.0073 - val_mae: 0.0090\n",
      "Epoch 55/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0071 - mae: 0.0041 - val_loss: 0.0069 - val_mae: 0.0032\n",
      "Epoch 56/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0067 - mae: 0.0045 - val_loss: 0.0065 - val_mae: 0.0042\n",
      "Epoch 57/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0063 - mae: 0.0041 - val_loss: 0.0061 - val_mae: 0.0032\n",
      "Epoch 58/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0060 - mae: 0.0043 - val_loss: 0.0058 - val_mae: 0.0031\n",
      "Epoch 59/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0056 - mae: 0.0044 - val_loss: 0.0055 - val_mae: 0.0067\n",
      "Epoch 60/1000\n",
      "645/645 [==============================] - 4s 5ms/step - loss: 0.0054 - mae: 0.0041 - val_loss: 0.0052 - val_mae: 0.0030\n",
      "Epoch 61/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0051 - mae: 0.0044 - val_loss: 0.0049 - val_mae: 0.0042\n",
      "Epoch 62/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0048 - mae: 0.0046 - val_loss: 0.0047 - val_mae: 0.0029\n",
      "Epoch 63/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0046 - mae: 0.0043 - val_loss: 0.0045 - val_mae: 0.0034\n",
      "Epoch 64/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0044 - mae: 0.0043 - val_loss: 0.0043 - val_mae: 0.0043\n",
      "Epoch 65/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0042 - mae: 0.0044 - val_loss: 0.0041 - val_mae: 0.0032\n",
      "Epoch 66/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0040 - mae: 0.0043 - val_loss: 0.0039 - val_mae: 0.0055\n",
      "Epoch 67/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0038 - mae: 0.0044 - val_loss: 0.0038 - val_mae: 0.0055\n",
      "Epoch 68/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0037 - mae: 0.0041 - val_loss: 0.0036 - val_mae: 0.0037\n",
      "Epoch 69/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0035 - mae: 0.0045 - val_loss: 0.0035 - val_mae: 0.0060\n",
      "Epoch 70/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0034 - mae: 0.0042 - val_loss: 0.0033 - val_mae: 0.0032\n",
      "Epoch 71/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0033 - mae: 0.0044 - val_loss: 0.0032 - val_mae: 0.0033\n",
      "Epoch 72/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0031 - mae: 0.0043 - val_loss: 0.0031 - val_mae: 0.0046\n",
      "Epoch 73/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0030 - mae: 0.0043 - val_loss: 0.0030 - val_mae: 0.0047\n",
      "Epoch 74/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0029 - mae: 0.0043 - val_loss: 0.0029 - val_mae: 0.0040\n",
      "Epoch 75/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0028 - mae: 0.0043 - val_loss: 0.0028 - val_mae: 0.0093\n",
      "Epoch 76/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0027 - mae: 0.0045 - val_loss: 0.0027 - val_mae: 0.0047\n",
      "Epoch 77/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0026 - mae: 0.0040 - val_loss: 0.0026 - val_mae: 0.0052\n",
      "Epoch 78/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0026 - mae: 0.0043 - val_loss: 0.0025 - val_mae: 0.0041\n",
      "Epoch 79/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0025 - mae: 0.0044 - val_loss: 0.0025 - val_mae: 0.0057\n",
      "Epoch 80/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0024 - mae: 0.0044 - val_loss: 0.0024 - val_mae: 0.0042\n",
      "Epoch 81/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0024 - mae: 0.0047 - val_loss: 0.0023 - val_mae: 0.0036\n",
      "Epoch 82/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0023 - mae: 0.0045 - val_loss: 0.0023 - val_mae: 0.0032\n",
      "Epoch 83/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0041 - val_loss: 0.0022 - val_mae: 0.0044\n",
      "Epoch 84/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0045 - val_loss: 0.0022 - val_mae: 0.0052\n",
      "Epoch 85/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0043 - val_loss: 0.0022 - val_mae: 0.0072\n",
      "Epoch 86/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0021 - mae: 0.0043 - val_loss: 0.0021 - val_mae: 0.0071\n",
      "Epoch 87/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0021 - mae: 0.0048 - val_loss: 0.0020 - val_mae: 0.0033\n",
      "Epoch 88/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0020 - mae: 0.0042 - val_loss: 0.0020 - val_mae: 0.0038\n",
      "Epoch 89/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0020 - mae: 0.0045 - val_loss: 0.0020 - val_mae: 0.0051\n",
      "Epoch 90/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0020 - mae: 0.0045 - val_loss: 0.0020 - val_mae: 0.0058\n",
      "Epoch 91/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0019 - mae: 0.0043 - val_loss: 0.0019 - val_mae: 0.0047\n",
      "Epoch 92/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0019 - mae: 0.0045 - val_loss: 0.0019 - val_mae: 0.0032\n",
      "Epoch 93/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0019 - mae: 0.0042 - val_loss: 0.0019 - val_mae: 0.0080\n",
      "Epoch 94/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0018 - mae: 0.0045 - val_loss: 0.0018 - val_mae: 0.0039\n",
      "Epoch 95/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0018 - mae: 0.0044 - val_loss: 0.0018 - val_mae: 0.0070\n",
      "Epoch 96/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0018 - mae: 0.0042 - val_loss: 0.0018 - val_mae: 0.0040\n",
      "Epoch 97/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0018 - mae: 0.0045 - val_loss: 0.0017 - val_mae: 0.0040\n",
      "Epoch 98/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0017 - mae: 0.0042 - val_loss: 0.0017 - val_mae: 0.0049\n",
      "Epoch 99/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0017 - mae: 0.0042 - val_loss: 0.0017 - val_mae: 0.0035\n",
      "Epoch 100/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0017 - mae: 0.0044 - val_loss: 0.0018 - val_mae: 0.0097\n",
      "Epoch 101/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0017 - mae: 0.0042 - val_loss: 0.0017 - val_mae: 0.0042\n",
      "Epoch 102/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0017 - mae: 0.0042 - val_loss: 0.0017 - val_mae: 0.0084\n",
      "Epoch 103/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0017 - mae: 0.0043 - val_loss: 0.0016 - val_mae: 0.0037\n",
      "Epoch 104/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0016 - mae: 0.0041 - val_loss: 0.0016 - val_mae: 0.0032\n",
      "Epoch 105/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0016 - mae: 0.0043 - val_loss: 0.0016 - val_mae: 0.0031\n",
      "Epoch 106/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0016 - mae: 0.0041 - val_loss: 0.0016 - val_mae: 0.0038\n",
      "Epoch 107/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0079\n",
      "Epoch 108/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0054\n",
      "Epoch 109/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0016 - mae: 0.0042 - val_loss: 0.0016 - val_mae: 0.0075\n",
      "Epoch 110/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0016 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0037\n",
      "Epoch 111/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0046\n",
      "Epoch 112/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0015 - mae: 0.0041 - val_loss: 0.0015 - val_mae: 0.0052\n",
      "Epoch 113/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0031\n",
      "Epoch 114/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0015 - mae: 0.0041 - val_loss: 0.0015 - val_mae: 0.0032\n",
      "Epoch 115/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0033\n",
      "Epoch 116/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0049\n",
      "Epoch 117/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0017 - val_mae: 0.0137\n",
      "Epoch 118/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0048\n",
      "Epoch 119/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0015 - mae: 0.0041 - val_loss: 0.0015 - val_mae: 0.0040\n",
      "Epoch 120/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 0.0015 - val_mae: 0.0084\n",
      "Epoch 121/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0033\n",
      "Epoch 122/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0072\n",
      "Epoch 123/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0049\n",
      "Epoch 124/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0034\n",
      "Epoch 125/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0032\n",
      "Epoch 126/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0078\n",
      "Epoch 127/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0049 - val_loss: 0.0015 - val_mae: 0.0077\n",
      "Epoch 128/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0036\n",
      "Epoch 129/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0042\n",
      "Epoch 130/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0014 - mae: 0.0046 - val_loss: 0.0014 - val_mae: 0.0059\n",
      "Epoch 131/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0041 - val_loss: 0.0015 - val_mae: 0.0083\n",
      "Epoch 132/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0040\n",
      "Epoch 133/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0046 - val_loss: 0.0014 - val_mae: 0.0029\n",
      "Epoch 134/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0039 - val_loss: 0.0014 - val_mae: 0.0035\n",
      "Epoch 135/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0074\n",
      "Epoch 136/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0015 - val_mae: 0.0120\n",
      "Epoch 137/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0034\n",
      "Epoch 138/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0068\n",
      "Epoch 139/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0028\n",
      "Epoch 140/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0028\n",
      "Epoch 141/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0054\n",
      "Epoch 142/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0031\n",
      "Epoch 143/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0013 - mae: 0.0046 - val_loss: 0.0013 - val_mae: 0.0040\n",
      "Epoch 144/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0038\n",
      "Epoch 145/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0042\n",
      "Epoch 146/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0041\n",
      "Epoch 147/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0031\n",
      "Epoch 148/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0052\n",
      "Epoch 149/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0032\n",
      "Epoch 150/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0028\n",
      "Epoch 151/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0077\n",
      "Epoch 152/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0033\n",
      "Epoch 153/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0013 - mae: 0.0046 - val_loss: 0.0013 - val_mae: 0.0064\n",
      "Epoch 154/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0033\n",
      "Epoch 155/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0013 - mae: 0.0046 - val_loss: 0.0013 - val_mae: 0.0039\n",
      "Epoch 156/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0059\n",
      "Epoch 157/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0013 - mae: 0.0047 - val_loss: 0.0013 - val_mae: 0.0037\n",
      "Epoch 158/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0035\n",
      "Epoch 159/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0030\n",
      "Epoch 160/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0034\n",
      "Epoch 161/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0028\n",
      "Epoch 162/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0042\n",
      "Epoch 163/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0067\n",
      "Epoch 164/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0051\n",
      "Epoch 165/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0098\n",
      "Epoch 166/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0033\n",
      "Epoch 167/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0073\n",
      "Epoch 168/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0058\n",
      "Epoch 169/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0080\n",
      "Epoch 170/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0032\n",
      "Epoch 171/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0056\n",
      "Epoch 172/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0033\n",
      "Epoch 173/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0049\n",
      "Epoch 174/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0048\n",
      "Epoch 175/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0072\n",
      "Epoch 176/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0012 - val_mae: 0.0030\n",
      "Epoch 177/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0042 - val_loss: 0.0012 - val_mae: 0.0030\n",
      "Epoch 178/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0046 - val_loss: 0.0013 - val_mae: 0.0098\n",
      "Epoch 179/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0063\n",
      "Epoch 180/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0059\n",
      "Epoch 181/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0046 - val_loss: 0.0013 - val_mae: 0.0052\n",
      "Epoch 182/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0041 - val_loss: 0.0012 - val_mae: 0.0034\n",
      "Epoch 183/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0082\n",
      "Epoch 184/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0034\n",
      "Epoch 185/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0060\n",
      "Epoch 186/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0045 - val_loss: 0.0012 - val_mae: 0.0035\n",
      "Epoch 187/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0042 - val_loss: 0.0012 - val_mae: 0.0035\n",
      "Epoch 188/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0045 - val_loss: 0.0012 - val_mae: 0.0027\n",
      "Epoch 189/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0045 - val_loss: 0.0012 - val_mae: 0.0034\n",
      "Epoch 190/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0034\n",
      "Epoch 191/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0042 - val_loss: 0.0012 - val_mae: 0.0042\n",
      "Epoch 192/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0046 - val_loss: 0.0012 - val_mae: 0.0037\n",
      "Epoch 193/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0045 - val_loss: 0.0012 - val_mae: 0.0030\n",
      "Epoch 194/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0042 - val_loss: 0.0012 - val_mae: 0.0052\n",
      "Epoch 195/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0045 - val_loss: 0.0012 - val_mae: 0.0069\n",
      "Epoch 196/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0041 - val_loss: 0.0013 - val_mae: 0.0084\n",
      "Epoch 197/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0046 - val_loss: 0.0012 - val_mae: 0.0042\n",
      "Epoch 198/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0032\n",
      "Epoch 199/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0111\n",
      "Epoch 200/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0039\n",
      "Epoch 201/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0045 - val_loss: 0.0012 - val_mae: 0.0032\n",
      "Epoch 202/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0044 - val_loss: 0.0012 - val_mae: 0.0033\n",
      "Epoch 203/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0046 - val_loss: 0.0013 - val_mae: 0.0084\n",
      "Epoch 204/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0044 - val_loss: 0.0012 - val_mae: 0.0071\n",
      "Epoch 205/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0044 - val_loss: 0.0012 - val_mae: 0.0039\n",
      "Epoch 206/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0046 - val_loss: 0.0012 - val_mae: 0.0039\n",
      "Epoch 207/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0064\n",
      "Epoch 208/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0048\n",
      "Epoch 209/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0042 - val_loss: 0.0012 - val_mae: 0.0040\n",
      "Epoch 210/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0049 - val_loss: 0.0012 - val_mae: 0.0029\n",
      "Epoch 211/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0033\n",
      "Epoch 212/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0042 - val_loss: 0.0012 - val_mae: 0.0056\n",
      "Epoch 213/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0044 - val_loss: 0.0012 - val_mae: 0.0039\n",
      "Epoch 214/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0045 - val_loss: 0.0012 - val_mae: 0.0033\n",
      "Epoch 215/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0042 - val_loss: 0.0012 - val_mae: 0.0044\n",
      "Epoch 216/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0048 - val_loss: 0.0012 - val_mae: 0.0055\n",
      "Epoch 217/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0042 - val_loss: 0.0012 - val_mae: 0.0035\n",
      "Epoch 218/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0030\n",
      "Epoch 219/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0046 - val_loss: 0.0012 - val_mae: 0.0030\n",
      "Epoch 220/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0044 - val_loss: 0.0012 - val_mae: 0.0037\n",
      "Epoch 221/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0044 - val_loss: 0.0012 - val_mae: 0.0040\n",
      "Epoch 222/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0064\n",
      "Epoch 223/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0046 - val_loss: 0.0012 - val_mae: 0.0055\n",
      "Epoch 224/1000\n",
      "641/645 [============================>.] - ETA: 0s - loss: 0.0012 - mae: 0.0043Restoring model weights from the end of the best epoch: 219.\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0044 - val_loss: 0.0012 - val_mae: 0.0045\n",
      "Epoch 224: early stopping\n",
      "Training fÃ¼r Fold 3...\n",
      "Epoch 1/1000\n",
      "645/645 [==============================] - 5s 5ms/step - loss: 0.3283 - mae: 0.0908 - val_loss: 0.2370 - val_mae: 0.0107\n",
      "Epoch 2/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.2049 - mae: 0.0143 - val_loss: 0.1801 - val_mae: 0.0062\n",
      "Epoch 3/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.1666 - mae: 0.0150 - val_loss: 0.1552 - val_mae: 0.0111\n",
      "Epoch 4/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.1478 - mae: 0.0108 - val_loss: 0.1410 - val_mae: 0.0067\n",
      "Epoch 5/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.1366 - mae: 0.0118 - val_loss: 0.1311 - val_mae: 0.0052\n",
      "Epoch 6/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.1267 - mae: 0.0081 - val_loss: 0.1248 - val_mae: 0.0393\n",
      "Epoch 7/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.1182 - mae: 0.0101 - val_loss: 0.1139 - val_mae: 0.0075\n",
      "Epoch 8/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.1101 - mae: 0.0094 - val_loss: 0.1061 - val_mae: 0.0068\n",
      "Epoch 9/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.1027 - mae: 0.0091 - val_loss: 0.0989 - val_mae: 0.0038\n",
      "Epoch 10/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0957 - mae: 0.0077 - val_loss: 0.0945 - val_mae: 0.0348\n",
      "Epoch 11/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0893 - mae: 0.0083 - val_loss: 0.0862 - val_mae: 0.0089\n",
      "Epoch 12/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0833 - mae: 0.0071 - val_loss: 0.0806 - val_mae: 0.0153\n",
      "Epoch 13/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0777 - mae: 0.0087 - val_loss: 0.0748 - val_mae: 0.0034\n",
      "Epoch 14/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0725 - mae: 0.0065 - val_loss: 0.0700 - val_mae: 0.0061\n",
      "Epoch 15/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0678 - mae: 0.0067 - val_loss: 0.0655 - val_mae: 0.0074\n",
      "Epoch 16/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0633 - mae: 0.0062 - val_loss: 0.0610 - val_mae: 0.0041\n",
      "Epoch 17/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0590 - mae: 0.0064 - val_loss: 0.0570 - val_mae: 0.0067\n",
      "Epoch 18/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0550 - mae: 0.0065 - val_loss: 0.0532 - val_mae: 0.0124\n",
      "Epoch 19/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0515 - mae: 0.0075 - val_loss: 0.0498 - val_mae: 0.0049\n",
      "Epoch 20/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0482 - mae: 0.0055 - val_loss: 0.0464 - val_mae: 0.0046\n",
      "Epoch 21/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0450 - mae: 0.0062 - val_loss: 0.0434 - val_mae: 0.0052\n",
      "Epoch 22/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0419 - mae: 0.0050 - val_loss: 0.0404 - val_mae: 0.0079\n",
      "Epoch 23/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0389 - mae: 0.0056 - val_loss: 0.0374 - val_mae: 0.0047\n",
      "Epoch 24/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0361 - mae: 0.0058 - val_loss: 0.0347 - val_mae: 0.0033\n",
      "Epoch 25/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0334 - mae: 0.0051 - val_loss: 0.0322 - val_mae: 0.0053\n",
      "Epoch 26/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0311 - mae: 0.0056 - val_loss: 0.0300 - val_mae: 0.0069\n",
      "Epoch 27/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0289 - mae: 0.0056 - val_loss: 0.0278 - val_mae: 0.0045\n",
      "Epoch 28/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0268 - mae: 0.0055 - val_loss: 0.0258 - val_mae: 0.0040\n",
      "Epoch 29/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0249 - mae: 0.0050 - val_loss: 0.0241 - val_mae: 0.0090\n",
      "Epoch 30/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0231 - mae: 0.0050 - val_loss: 0.0222 - val_mae: 0.0031\n",
      "Epoch 31/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0214 - mae: 0.0049 - val_loss: 0.0206 - val_mae: 0.0036\n",
      "Epoch 32/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0199 - mae: 0.0052 - val_loss: 0.0191 - val_mae: 0.0036\n",
      "Epoch 33/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0185 - mae: 0.0048 - val_loss: 0.0179 - val_mae: 0.0130\n",
      "Epoch 34/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0171 - mae: 0.0051 - val_loss: 0.0164 - val_mae: 0.0041\n",
      "Epoch 35/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0158 - mae: 0.0042 - val_loss: 0.0152 - val_mae: 0.0032\n",
      "Epoch 36/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0147 - mae: 0.0050 - val_loss: 0.0141 - val_mae: 0.0047\n",
      "Epoch 37/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0136 - mae: 0.0049 - val_loss: 0.0131 - val_mae: 0.0046\n",
      "Epoch 38/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0126 - mae: 0.0042 - val_loss: 0.0121 - val_mae: 0.0035\n",
      "Epoch 39/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0117 - mae: 0.0043 - val_loss: 0.0112 - val_mae: 0.0039\n",
      "Epoch 40/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0108 - mae: 0.0040 - val_loss: 0.0104 - val_mae: 0.0079\n",
      "Epoch 41/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0099 - mae: 0.0043 - val_loss: 0.0095 - val_mae: 0.0045\n",
      "Epoch 42/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0091 - mae: 0.0041 - val_loss: 0.0088 - val_mae: 0.0031\n",
      "Epoch 43/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0084 - mae: 0.0040 - val_loss: 0.0081 - val_mae: 0.0030\n",
      "Epoch 44/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0078 - mae: 0.0039 - val_loss: 0.0075 - val_mae: 0.0045\n",
      "Epoch 45/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0072 - mae: 0.0042 - val_loss: 0.0070 - val_mae: 0.0074\n",
      "Epoch 46/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0067 - mae: 0.0039 - val_loss: 0.0064 - val_mae: 0.0069\n",
      "Epoch 47/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0062 - mae: 0.0041 - val_loss: 0.0059 - val_mae: 0.0032\n",
      "Epoch 48/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0057 - mae: 0.0038 - val_loss: 0.0055 - val_mae: 0.0039\n",
      "Epoch 49/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0053 - mae: 0.0042 - val_loss: 0.0052 - val_mae: 0.0031\n",
      "Epoch 50/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0050 - mae: 0.0040 - val_loss: 0.0048 - val_mae: 0.0030\n",
      "Epoch 51/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0047 - mae: 0.0038 - val_loss: 0.0045 - val_mae: 0.0036\n",
      "Epoch 52/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0044 - mae: 0.0041 - val_loss: 0.0043 - val_mae: 0.0029\n",
      "Epoch 53/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0041 - mae: 0.0037 - val_loss: 0.0040 - val_mae: 0.0032\n",
      "Epoch 54/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0039 - mae: 0.0039 - val_loss: 0.0038 - val_mae: 0.0033\n",
      "Epoch 55/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0037 - mae: 0.0040 - val_loss: 0.0036 - val_mae: 0.0047\n",
      "Epoch 56/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0035 - mae: 0.0038 - val_loss: 0.0034 - val_mae: 0.0027\n",
      "Epoch 57/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0034 - mae: 0.0040 - val_loss: 0.0033 - val_mae: 0.0034\n",
      "Epoch 58/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0032 - mae: 0.0038 - val_loss: 0.0032 - val_mae: 0.0037\n",
      "Epoch 59/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0031 - mae: 0.0036 - val_loss: 0.0031 - val_mae: 0.0054\n",
      "Epoch 60/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0030 - mae: 0.0041 - val_loss: 0.0029 - val_mae: 0.0040\n",
      "Epoch 61/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0029 - mae: 0.0041 - val_loss: 0.0028 - val_mae: 0.0025\n",
      "Epoch 62/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0028 - mae: 0.0038 - val_loss: 0.0027 - val_mae: 0.0033\n",
      "Epoch 63/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0027 - mae: 0.0039 - val_loss: 0.0026 - val_mae: 0.0024\n",
      "Epoch 64/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0026 - mae: 0.0038 - val_loss: 0.0026 - val_mae: 0.0034\n",
      "Epoch 65/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0025 - mae: 0.0037 - val_loss: 0.0025 - val_mae: 0.0049\n",
      "Epoch 66/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0025 - mae: 0.0040 - val_loss: 0.0024 - val_mae: 0.0032\n",
      "Epoch 67/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0024 - mae: 0.0039 - val_loss: 0.0024 - val_mae: 0.0037\n",
      "Epoch 68/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0024 - mae: 0.0040 - val_loss: 0.0024 - val_mae: 0.0076\n",
      "Epoch 69/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0038 - val_loss: 0.0023 - val_mae: 0.0046\n",
      "Epoch 70/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0042 - val_loss: 0.0023 - val_mae: 0.0095\n",
      "Epoch 71/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0041 - val_loss: 0.0022 - val_mae: 0.0028\n",
      "Epoch 72/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0043 - val_loss: 0.0021 - val_mae: 0.0038\n",
      "Epoch 73/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0021 - mae: 0.0039 - val_loss: 0.0021 - val_mae: 0.0039\n",
      "Epoch 74/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0021 - mae: 0.0044 - val_loss: 0.0021 - val_mae: 0.0032\n",
      "Epoch 75/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0021 - mae: 0.0040 - val_loss: 0.0020 - val_mae: 0.0049\n",
      "Epoch 76/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0020 - mae: 0.0043 - val_loss: 0.0020 - val_mae: 0.0044\n",
      "Epoch 77/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0020 - mae: 0.0044 - val_loss: 0.0020 - val_mae: 0.0040\n",
      "Epoch 78/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0020 - mae: 0.0041 - val_loss: 0.0019 - val_mae: 0.0033\n",
      "Epoch 79/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0019 - mae: 0.0041 - val_loss: 0.0019 - val_mae: 0.0050\n",
      "Epoch 80/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0019 - mae: 0.0041 - val_loss: 0.0019 - val_mae: 0.0080\n",
      "Epoch 81/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0019 - mae: 0.0040 - val_loss: 0.0019 - val_mae: 0.0037\n",
      "Epoch 82/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0019 - mae: 0.0041 - val_loss: 0.0019 - val_mae: 0.0042\n",
      "Epoch 83/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0018 - mae: 0.0041 - val_loss: 0.0019 - val_mae: 0.0067\n",
      "Epoch 84/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0018 - mae: 0.0041 - val_loss: 0.0019 - val_mae: 0.0065\n",
      "Epoch 85/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0018 - mae: 0.0041 - val_loss: 0.0018 - val_mae: 0.0082\n",
      "Epoch 86/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0018 - mae: 0.0042 - val_loss: 0.0018 - val_mae: 0.0035\n",
      "Epoch 87/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0018 - mae: 0.0040 - val_loss: 0.0018 - val_mae: 0.0051\n",
      "Epoch 88/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0018 - mae: 0.0042 - val_loss: 0.0018 - val_mae: 0.0076\n",
      "Epoch 89/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0017 - mae: 0.0042 - val_loss: 0.0017 - val_mae: 0.0054\n",
      "Epoch 90/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0017 - mae: 0.0041 - val_loss: 0.0017 - val_mae: 0.0033\n",
      "Epoch 91/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0017 - mae: 0.0041 - val_loss: 0.0017 - val_mae: 0.0060\n",
      "Epoch 92/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0017 - mae: 0.0043 - val_loss: 0.0017 - val_mae: 0.0082\n",
      "Epoch 93/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0017 - mae: 0.0041 - val_loss: 0.0017 - val_mae: 0.0045\n",
      "Epoch 94/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0017 - mae: 0.0042 - val_loss: 0.0016 - val_mae: 0.0030\n",
      "Epoch 95/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0017 - mae: 0.0042 - val_loss: 0.0016 - val_mae: 0.0036\n",
      "Epoch 96/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0016 - mae: 0.0042 - val_loss: 0.0016 - val_mae: 0.0037\n",
      "Epoch 97/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0033\n",
      "Epoch 98/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0016 - mae: 0.0043 - val_loss: 0.0016 - val_mae: 0.0038\n",
      "Epoch 99/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0041\n",
      "Epoch 100/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0016 - mae: 0.0043 - val_loss: 0.0016 - val_mae: 0.0033\n",
      "Epoch 101/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0016 - mae: 0.0043 - val_loss: 0.0016 - val_mae: 0.0034\n",
      "Epoch 102/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0016 - mae: 0.0046 - val_loss: 0.0016 - val_mae: 0.0045\n",
      "Epoch 103/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0016 - mae: 0.0041 - val_loss: 0.0016 - val_mae: 0.0029\n",
      "Epoch 104/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0016 - mae: 0.0046 - val_loss: 0.0016 - val_mae: 0.0062\n",
      "Epoch 105/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0016 - mae: 0.0042 - val_loss: 0.0016 - val_mae: 0.0052\n",
      "Epoch 106/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0032\n",
      "Epoch 107/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 0.0015 - val_mae: 0.0040\n",
      "Epoch 108/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0016 - val_mae: 0.0097\n",
      "Epoch 109/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0047 - val_loss: 0.0016 - val_mae: 0.0095\n",
      "Epoch 110/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0048\n",
      "Epoch 111/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 0.0015 - val_mae: 0.0039\n",
      "Epoch 112/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0037\n",
      "Epoch 113/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 0.0015 - val_mae: 0.0052\n",
      "Epoch 114/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 0.0015 - val_mae: 0.0034\n",
      "Epoch 115/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 0.0015 - val_mae: 0.0071\n",
      "Epoch 116/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0037\n",
      "Epoch 117/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0047 - val_loss: 0.0015 - val_mae: 0.0046\n",
      "Epoch 118/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0035\n",
      "Epoch 119/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0046\n",
      "Epoch 120/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0070\n",
      "Epoch 121/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0037\n",
      "Epoch 122/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0042\n",
      "Epoch 123/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0041 - val_loss: 0.0014 - val_mae: 0.0028\n",
      "Epoch 124/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0067\n",
      "Epoch 125/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0051\n",
      "Epoch 126/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0075\n",
      "Epoch 127/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0036\n",
      "Epoch 128/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0044\n",
      "Epoch 129/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0039\n",
      "Epoch 130/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0039 - val_loss: 0.0014 - val_mae: 0.0032\n",
      "Epoch 131/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0046 - val_loss: 0.0014 - val_mae: 0.0053\n",
      "Epoch 132/1000\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0040 - val_loss: 0.0014 - val_mae: 0.0036\n",
      "Epoch 133/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0067\n",
      "Epoch 134/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0040 - val_loss: 0.0014 - val_mae: 0.0034\n",
      "Epoch 135/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0049\n",
      "Epoch 136/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0061\n",
      "Epoch 137/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0034\n",
      "Epoch 138/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0032\n",
      "Epoch 139/1000\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0014 - mae: 0.0039 - val_loss: 0.0014 - val_mae: 0.0053\n",
      "Epoch 140/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0041\n",
      "Epoch 141/1000\n",
      "645/645 [==============================] - 4s 5ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0031\n",
      "Epoch 142/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0035\n",
      "Epoch 143/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0041 - val_loss: 0.0014 - val_mae: 0.0035\n",
      "Epoch 144/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0041 - val_loss: 0.0013 - val_mae: 0.0029\n",
      "Epoch 145/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0041 - val_loss: 0.0013 - val_mae: 0.0029\n",
      "Epoch 146/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0041 - val_loss: 0.0014 - val_mae: 0.0086\n",
      "Epoch 147/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0050\n",
      "Epoch 148/1000\n",
      "645/645 [==============================] - 4s 5ms/step - loss: 0.0014 - mae: 0.0041 - val_loss: 0.0014 - val_mae: 0.0045\n",
      "Epoch 149/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0036\n",
      "Epoch 150/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0078\n",
      "Epoch 151/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0030\n",
      "Epoch 152/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0028\n",
      "Epoch 153/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0040 - val_loss: 0.0013 - val_mae: 0.0044\n",
      "Epoch 154/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0013 - mae: 0.0040 - val_loss: 0.0014 - val_mae: 0.0092\n",
      "Epoch 155/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0013 - mae: 0.0040 - val_loss: 0.0013 - val_mae: 0.0030\n",
      "Epoch 156/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0013 - mae: 0.0047 - val_loss: 0.0014 - val_mae: 0.0064\n",
      "Epoch 157/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0044\n",
      "Epoch 158/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0013 - mae: 0.0041 - val_loss: 0.0014 - val_mae: 0.0080\n",
      "Epoch 159/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0013 - mae: 0.0041 - val_loss: 0.0014 - val_mae: 0.0068\n",
      "Epoch 160/1000\n",
      "639/645 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0042Restoring model weights from the end of the best epoch: 155.\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0072\n",
      "Epoch 160: early stopping\n",
      "Training fÃ¼r Fold 4...\n",
      "Epoch 1/1000\n",
      "645/645 [==============================] - 6s 6ms/step - loss: 0.3271 - mae: 0.0852 - val_loss: 0.2437 - val_mae: 0.0210\n",
      "Epoch 2/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.2131 - mae: 0.0151 - val_loss: 0.1897 - val_mae: 0.0070\n",
      "Epoch 3/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.1772 - mae: 0.0150 - val_loss: 0.1663 - val_mae: 0.0080\n",
      "Epoch 4/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.1597 - mae: 0.0144 - val_loss: 0.1532 - val_mae: 0.0115\n",
      "Epoch 5/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.1484 - mae: 0.0128 - val_loss: 0.1433 - val_mae: 0.0135\n",
      "Epoch 6/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.1389 - mae: 0.0105 - val_loss: 0.1342 - val_mae: 0.0039\n",
      "Epoch 7/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.1304 - mae: 0.0110 - val_loss: 0.1265 - val_mae: 0.0184\n",
      "Epoch 8/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.1224 - mae: 0.0094 - val_loss: 0.1182 - val_mae: 0.0042\n",
      "Epoch 9/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.1148 - mae: 0.0108 - val_loss: 0.1112 - val_mae: 0.0122\n",
      "Epoch 10/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.1075 - mae: 0.0079 - val_loss: 0.1039 - val_mae: 0.0075\n",
      "Epoch 11/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.1007 - mae: 0.0092 - val_loss: 0.0973 - val_mae: 0.0038\n",
      "Epoch 12/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0944 - mae: 0.0101 - val_loss: 0.0931 - val_mae: 0.0297\n",
      "Epoch 13/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0884 - mae: 0.0072 - val_loss: 0.0856 - val_mae: 0.0115\n",
      "Epoch 14/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0829 - mae: 0.0073 - val_loss: 0.0802 - val_mae: 0.0079\n",
      "Epoch 15/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0777 - mae: 0.0083 - val_loss: 0.0751 - val_mae: 0.0051\n",
      "Epoch 16/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0728 - mae: 0.0070 - val_loss: 0.0705 - val_mae: 0.0053\n",
      "Epoch 17/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0683 - mae: 0.0066 - val_loss: 0.0660 - val_mae: 0.0070\n",
      "Epoch 18/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0639 - mae: 0.0068 - val_loss: 0.0619 - val_mae: 0.0103\n",
      "Epoch 19/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0598 - mae: 0.0064 - val_loss: 0.0577 - val_mae: 0.0044\n",
      "Epoch 20/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0559 - mae: 0.0059 - val_loss: 0.0543 - val_mae: 0.0145\n",
      "Epoch 21/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0521 - mae: 0.0057 - val_loss: 0.0503 - val_mae: 0.0046\n",
      "Epoch 22/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0486 - mae: 0.0057 - val_loss: 0.0468 - val_mae: 0.0038\n",
      "Epoch 23/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0453 - mae: 0.0058 - val_loss: 0.0437 - val_mae: 0.0050\n",
      "Epoch 24/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0422 - mae: 0.0069 - val_loss: 0.0407 - val_mae: 0.0065\n",
      "Epoch 25/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0393 - mae: 0.0038 - val_loss: 0.0380 - val_mae: 0.0047\n",
      "Epoch 26/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0367 - mae: 0.0049 - val_loss: 0.0353 - val_mae: 0.0031\n",
      "Epoch 27/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0340 - mae: 0.0049 - val_loss: 0.0326 - val_mae: 0.0037\n",
      "Epoch 28/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0314 - mae: 0.0052 - val_loss: 0.0303 - val_mae: 0.0067\n",
      "Epoch 29/1000\n",
      "645/645 [==============================] - 4s 5ms/step - loss: 0.0291 - mae: 0.0053 - val_loss: 0.0280 - val_mae: 0.0041\n",
      "Epoch 30/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0270 - mae: 0.0050 - val_loss: 0.0260 - val_mae: 0.0030\n",
      "Epoch 31/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0252 - mae: 0.0054 - val_loss: 0.0244 - val_mae: 0.0101\n",
      "Epoch 32/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0235 - mae: 0.0050 - val_loss: 0.0227 - val_mae: 0.0049\n",
      "Epoch 33/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0219 - mae: 0.0046 - val_loss: 0.0215 - val_mae: 0.0175\n",
      "Epoch 34/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0204 - mae: 0.0049 - val_loss: 0.0197 - val_mae: 0.0066\n",
      "Epoch 35/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0190 - mae: 0.0049 - val_loss: 0.0184 - val_mae: 0.0039\n",
      "Epoch 36/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0178 - mae: 0.0050 - val_loss: 0.0171 - val_mae: 0.0033\n",
      "Epoch 37/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0166 - mae: 0.0050 - val_loss: 0.0160 - val_mae: 0.0052\n",
      "Epoch 38/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0155 - mae: 0.0050 - val_loss: 0.0150 - val_mae: 0.0065\n",
      "Epoch 39/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0145 - mae: 0.0045 - val_loss: 0.0140 - val_mae: 0.0041\n",
      "Epoch 40/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0136 - mae: 0.0053 - val_loss: 0.0132 - val_mae: 0.0034\n",
      "Epoch 41/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0128 - mae: 0.0041 - val_loss: 0.0124 - val_mae: 0.0074\n",
      "Epoch 42/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0120 - mae: 0.0048 - val_loss: 0.0116 - val_mae: 0.0034\n",
      "Epoch 43/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0112 - mae: 0.0046 - val_loss: 0.0108 - val_mae: 0.0032\n",
      "Epoch 44/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0105 - mae: 0.0046 - val_loss: 0.0102 - val_mae: 0.0047\n",
      "Epoch 45/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0099 - mae: 0.0044 - val_loss: 0.0095 - val_mae: 0.0031\n",
      "Epoch 46/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0092 - mae: 0.0047 - val_loss: 0.0090 - val_mae: 0.0055\n",
      "Epoch 47/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0087 - mae: 0.0047 - val_loss: 0.0085 - val_mae: 0.0087\n",
      "Epoch 48/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0082 - mae: 0.0040 - val_loss: 0.0080 - val_mae: 0.0078\n",
      "Epoch 49/1000\n",
      "645/645 [==============================] - 4s 5ms/step - loss: 0.0077 - mae: 0.0043 - val_loss: 0.0075 - val_mae: 0.0032\n",
      "Epoch 50/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0073 - mae: 0.0043 - val_loss: 0.0070 - val_mae: 0.0041\n",
      "Epoch 51/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0068 - mae: 0.0044 - val_loss: 0.0066 - val_mae: 0.0039\n",
      "Epoch 52/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0064 - mae: 0.0041 - val_loss: 0.0063 - val_mae: 0.0045\n",
      "Epoch 53/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0061 - mae: 0.0043 - val_loss: 0.0059 - val_mae: 0.0050\n",
      "Epoch 54/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0058 - mae: 0.0041 - val_loss: 0.0056 - val_mae: 0.0043\n",
      "Epoch 55/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0054 - mae: 0.0044 - val_loss: 0.0055 - val_mae: 0.0142\n",
      "Epoch 56/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0052 - mae: 0.0043 - val_loss: 0.0050 - val_mae: 0.0051\n",
      "Epoch 57/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0049 - mae: 0.0040 - val_loss: 0.0048 - val_mae: 0.0046\n",
      "Epoch 58/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0047 - mae: 0.0043 - val_loss: 0.0045 - val_mae: 0.0037\n",
      "Epoch 59/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0044 - mae: 0.0042 - val_loss: 0.0044 - val_mae: 0.0063\n",
      "Epoch 60/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0042 - mae: 0.0040 - val_loss: 0.0041 - val_mae: 0.0056\n",
      "Epoch 61/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0040 - mae: 0.0043 - val_loss: 0.0040 - val_mae: 0.0052\n",
      "Epoch 62/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0039 - mae: 0.0042 - val_loss: 0.0038 - val_mae: 0.0040\n",
      "Epoch 63/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0037 - mae: 0.0043 - val_loss: 0.0036 - val_mae: 0.0032\n",
      "Epoch 64/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0036 - mae: 0.0042 - val_loss: 0.0035 - val_mae: 0.0052\n",
      "Epoch 65/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0034 - mae: 0.0044 - val_loss: 0.0034 - val_mae: 0.0089\n",
      "Epoch 66/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0033 - mae: 0.0044 - val_loss: 0.0033 - val_mae: 0.0057\n",
      "Epoch 67/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0032 - mae: 0.0043 - val_loss: 0.0031 - val_mae: 0.0032\n",
      "Epoch 68/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0031 - mae: 0.0045 - val_loss: 0.0030 - val_mae: 0.0039\n",
      "Epoch 69/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0030 - mae: 0.0043 - val_loss: 0.0029 - val_mae: 0.0029\n",
      "Epoch 70/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0029 - mae: 0.0043 - val_loss: 0.0029 - val_mae: 0.0072\n",
      "Epoch 71/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0028 - mae: 0.0041 - val_loss: 0.0028 - val_mae: 0.0051\n",
      "Epoch 72/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0027 - mae: 0.0045 - val_loss: 0.0027 - val_mae: 0.0033\n",
      "Epoch 73/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0027 - mae: 0.0042 - val_loss: 0.0026 - val_mae: 0.0045\n",
      "Epoch 74/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0026 - mae: 0.0045 - val_loss: 0.0026 - val_mae: 0.0063\n",
      "Epoch 75/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0025 - mae: 0.0040 - val_loss: 0.0025 - val_mae: 0.0035\n",
      "Epoch 76/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0025 - mae: 0.0041 - val_loss: 0.0024 - val_mae: 0.0036\n",
      "Epoch 77/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0024 - mae: 0.0044 - val_loss: 0.0024 - val_mae: 0.0052\n",
      "Epoch 78/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0024 - mae: 0.0044 - val_loss: 0.0023 - val_mae: 0.0030\n",
      "Epoch 79/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0023 - mae: 0.0041 - val_loss: 0.0023 - val_mae: 0.0033\n",
      "Epoch 80/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0023 - mae: 0.0040 - val_loss: 0.0023 - val_mae: 0.0078\n",
      "Epoch 81/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0022 - mae: 0.0044 - val_loss: 0.0022 - val_mae: 0.0073\n",
      "Epoch 82/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0022 - mae: 0.0043 - val_loss: 0.0021 - val_mae: 0.0032\n",
      "Epoch 83/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0021 - mae: 0.0043 - val_loss: 0.0021 - val_mae: 0.0033\n",
      "Epoch 84/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0021 - mae: 0.0041 - val_loss: 0.0021 - val_mae: 0.0036\n",
      "Epoch 85/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0021 - mae: 0.0048 - val_loss: 0.0020 - val_mae: 0.0030\n",
      "Epoch 86/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0020 - mae: 0.0042 - val_loss: 0.0020 - val_mae: 0.0028\n",
      "Epoch 87/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0020 - mae: 0.0041 - val_loss: 0.0020 - val_mae: 0.0050\n",
      "Epoch 88/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0020 - mae: 0.0043 - val_loss: 0.0020 - val_mae: 0.0047\n",
      "Epoch 89/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0019 - mae: 0.0043 - val_loss: 0.0020 - val_mae: 0.0065\n",
      "Epoch 90/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0019 - mae: 0.0044 - val_loss: 0.0019 - val_mae: 0.0062\n",
      "Epoch 91/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0019 - mae: 0.0045 - val_loss: 0.0019 - val_mae: 0.0058\n",
      "Epoch 92/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0019 - mae: 0.0042 - val_loss: 0.0019 - val_mae: 0.0055\n",
      "Epoch 93/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0018 - mae: 0.0042 - val_loss: 0.0018 - val_mae: 0.0042\n",
      "Epoch 94/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0018 - mae: 0.0041 - val_loss: 0.0018 - val_mae: 0.0047\n",
      "Epoch 95/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0018 - mae: 0.0042 - val_loss: 0.0018 - val_mae: 0.0034\n",
      "Epoch 96/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0018 - mae: 0.0045 - val_loss: 0.0018 - val_mae: 0.0034\n",
      "Epoch 97/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0017 - mae: 0.0041 - val_loss: 0.0017 - val_mae: 0.0033\n",
      "Epoch 98/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0017 - mae: 0.0044 - val_loss: 0.0017 - val_mae: 0.0030\n",
      "Epoch 99/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0017 - mae: 0.0040 - val_loss: 0.0017 - val_mae: 0.0054\n",
      "Epoch 100/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0017 - mae: 0.0043 - val_loss: 0.0017 - val_mae: 0.0051\n",
      "Epoch 101/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0017 - mae: 0.0043 - val_loss: 0.0017 - val_mae: 0.0042\n",
      "Epoch 102/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0017 - mae: 0.0042 - val_loss: 0.0017 - val_mae: 0.0048\n",
      "Epoch 103/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0016 - mae: 0.0041 - val_loss: 0.0016 - val_mae: 0.0040\n",
      "Epoch 104/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0016 - mae: 0.0040 - val_loss: 0.0017 - val_mae: 0.0062\n",
      "Epoch 105/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0028\n",
      "Epoch 106/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0016 - mae: 0.0041 - val_loss: 0.0016 - val_mae: 0.0043\n",
      "Epoch 107/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0016 - mae: 0.0043 - val_loss: 0.0016 - val_mae: 0.0044\n",
      "Epoch 108/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0016 - mae: 0.0043 - val_loss: 0.0016 - val_mae: 0.0067\n",
      "Epoch 109/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0016 - mae: 0.0040 - val_loss: 0.0016 - val_mae: 0.0029\n",
      "Epoch 110/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0016 - mae: 0.0040 - val_loss: 0.0015 - val_mae: 0.0028\n",
      "Epoch 111/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0016 - mae: 0.0042 - val_loss: 0.0016 - val_mae: 0.0054\n",
      "Epoch 112/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0016 - mae: 0.0047 - val_loss: 0.0015 - val_mae: 0.0027\n",
      "Epoch 113/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0015 - mae: 0.0037 - val_loss: 0.0015 - val_mae: 0.0044\n",
      "Epoch 114/1000\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0033\n",
      "Epoch 115/1000\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0047\n",
      "Epoch 116/1000\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0051\n",
      "Epoch 117/1000\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.0015 - mae: 0.0041 - val_loss: 0.0015 - val_mae: 0.0036\n",
      "Epoch 118/1000\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.0015 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0058\n",
      "Epoch 119/1000\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.0015 - mae: 0.0041 - val_loss: 0.0015 - val_mae: 0.0034\n",
      "Epoch 120/1000\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.0015 - mae: 0.0041 - val_loss: 0.0015 - val_mae: 0.0035\n",
      "Epoch 121/1000\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.0015 - mae: 0.0041 - val_loss: 0.0015 - val_mae: 0.0043\n",
      "Epoch 122/1000\n",
      "645/645 [==============================] - 5s 7ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 0.0015 - val_mae: 0.0043\n",
      "Epoch 123/1000\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.0015 - mae: 0.0041 - val_loss: 0.0015 - val_mae: 0.0057\n",
      "Epoch 124/1000\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 0.0015 - val_mae: 0.0059\n",
      "Epoch 125/1000\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0030\n",
      "Epoch 126/1000\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0036\n",
      "Epoch 127/1000\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0072\n",
      "Epoch 128/1000\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.0014 - mae: 0.0041 - val_loss: 0.0014 - val_mae: 0.0028\n",
      "Epoch 129/1000\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.0014 - mae: 0.0046 - val_loss: 0.0014 - val_mae: 0.0036\n",
      "Epoch 130/1000\n",
      "645/645 [==============================] - 5s 8ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0031\n",
      "Epoch 131/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0014 - mae: 0.0041 - val_loss: 0.0014 - val_mae: 0.0030\n",
      "Epoch 132/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0054\n",
      "Epoch 133/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0056\n",
      "Epoch 134/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0038\n",
      "Epoch 135/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0035\n",
      "Epoch 136/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0040 - val_loss: 0.0014 - val_mae: 0.0060\n",
      "Epoch 137/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0052\n",
      "Epoch 138/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0066\n",
      "Epoch 139/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0047\n",
      "Epoch 140/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0032\n",
      "Epoch 141/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0054\n",
      "Epoch 142/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0070\n",
      "Epoch 143/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0039\n",
      "Epoch 144/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0041\n",
      "Epoch 145/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0041 - val_loss: 0.0013 - val_mae: 0.0035\n",
      "Epoch 146/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0041 - val_loss: 0.0013 - val_mae: 0.0038\n",
      "Epoch 147/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0034\n",
      "Epoch 148/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0041 - val_loss: 0.0013 - val_mae: 0.0039\n",
      "Epoch 149/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0030\n",
      "Epoch 150/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0041 - val_loss: 0.0013 - val_mae: 0.0043\n",
      "Epoch 151/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0033\n",
      "Epoch 152/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0039\n",
      "Epoch 153/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0042\n",
      "Epoch 154/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0015 - val_mae: 0.0125\n",
      "Epoch 155/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0034\n",
      "Epoch 156/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0040 - val_loss: 0.0013 - val_mae: 0.0032\n",
      "Epoch 157/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0043\n",
      "Epoch 158/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0051\n",
      "Epoch 159/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0042\n",
      "Epoch 160/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0056\n",
      "Epoch 161/1000\n",
      "642/645 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0043Restoring model weights from the end of the best epoch: 156.\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0096\n",
      "Epoch 161: early stopping\n",
      "Training fÃ¼r Fold 5...\n",
      "Epoch 1/1000\n",
      "645/645 [==============================] - 5s 5ms/step - loss: 0.3256 - mae: 0.0813 - val_loss: 0.2440 - val_mae: 0.0089\n",
      "Epoch 2/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.2137 - mae: 0.0127 - val_loss: 0.1907 - val_mae: 0.0183\n",
      "Epoch 3/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.1773 - mae: 0.0140 - val_loss: 0.1668 - val_mae: 0.0186\n",
      "Epoch 4/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.1591 - mae: 0.0125 - val_loss: 0.1525 - val_mae: 0.0159\n",
      "Epoch 5/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.1469 - mae: 0.0105 - val_loss: 0.1418 - val_mae: 0.0150\n",
      "Epoch 6/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.1369 - mae: 0.0106 - val_loss: 0.1334 - val_mae: 0.0314\n",
      "Epoch 7/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.1281 - mae: 0.0131 - val_loss: 0.1251 - val_mae: 0.0320\n",
      "Epoch 8/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.1198 - mae: 0.0086 - val_loss: 0.1161 - val_mae: 0.0151\n",
      "Epoch 9/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.1122 - mae: 0.0100 - val_loss: 0.1083 - val_mae: 0.0042\n",
      "Epoch 10/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.1048 - mae: 0.0092 - val_loss: 0.1012 - val_mae: 0.0080\n",
      "Epoch 11/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0979 - mae: 0.0089 - val_loss: 0.0949 - val_mae: 0.0150\n",
      "Epoch 12/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0914 - mae: 0.0074 - val_loss: 0.0884 - val_mae: 0.0125\n",
      "Epoch 13/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0855 - mae: 0.0084 - val_loss: 0.0825 - val_mae: 0.0046\n",
      "Epoch 14/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0798 - mae: 0.0089 - val_loss: 0.0775 - val_mae: 0.0178\n",
      "Epoch 15/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0746 - mae: 0.0066 - val_loss: 0.0720 - val_mae: 0.0052\n",
      "Epoch 16/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0696 - mae: 0.0078 - val_loss: 0.0671 - val_mae: 0.0061\n",
      "Epoch 17/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0649 - mae: 0.0072 - val_loss: 0.0626 - val_mae: 0.0043\n",
      "Epoch 18/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0605 - mae: 0.0052 - val_loss: 0.0584 - val_mae: 0.0062\n",
      "Epoch 19/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0564 - mae: 0.0066 - val_loss: 0.0543 - val_mae: 0.0036\n",
      "Epoch 20/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0525 - mae: 0.0074 - val_loss: 0.0506 - val_mae: 0.0043\n",
      "Epoch 21/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0489 - mae: 0.0058 - val_loss: 0.0472 - val_mae: 0.0081\n",
      "Epoch 22/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0455 - mae: 0.0058 - val_loss: 0.0439 - val_mae: 0.0085\n",
      "Epoch 23/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0423 - mae: 0.0063 - val_loss: 0.0407 - val_mae: 0.0067\n",
      "Epoch 24/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0392 - mae: 0.0062 - val_loss: 0.0378 - val_mae: 0.0042\n",
      "Epoch 25/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0365 - mae: 0.0057 - val_loss: 0.0351 - val_mae: 0.0034\n",
      "Epoch 26/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0339 - mae: 0.0059 - val_loss: 0.0326 - val_mae: 0.0038\n",
      "Epoch 27/1000\n",
      "645/645 [==============================] - 4s 5ms/step - loss: 0.0315 - mae: 0.0055 - val_loss: 0.0303 - val_mae: 0.0054\n",
      "Epoch 28/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0292 - mae: 0.0054 - val_loss: 0.0282 - val_mae: 0.0085\n",
      "Epoch 29/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0271 - mae: 0.0056 - val_loss: 0.0269 - val_mae: 0.0236\n",
      "Epoch 30/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0252 - mae: 0.0050 - val_loss: 0.0243 - val_mae: 0.0072\n",
      "Epoch 31/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0234 - mae: 0.0052 - val_loss: 0.0225 - val_mae: 0.0029\n",
      "Epoch 32/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0217 - mae: 0.0052 - val_loss: 0.0211 - val_mae: 0.0141\n",
      "Epoch 33/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0202 - mae: 0.0049 - val_loss: 0.0194 - val_mae: 0.0058\n",
      "Epoch 34/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0187 - mae: 0.0055 - val_loss: 0.0181 - val_mae: 0.0094\n",
      "Epoch 35/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0174 - mae: 0.0046 - val_loss: 0.0168 - val_mae: 0.0085\n",
      "Epoch 36/1000\n",
      "645/645 [==============================] - 4s 5ms/step - loss: 0.0161 - mae: 0.0047 - val_loss: 0.0154 - val_mae: 0.0029\n",
      "Epoch 37/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0149 - mae: 0.0049 - val_loss: 0.0144 - val_mae: 0.0122\n",
      "Epoch 38/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0138 - mae: 0.0045 - val_loss: 0.0132 - val_mae: 0.0043\n",
      "Epoch 39/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0128 - mae: 0.0047 - val_loss: 0.0122 - val_mae: 0.0033\n",
      "Epoch 40/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0118 - mae: 0.0045 - val_loss: 0.0114 - val_mae: 0.0061\n",
      "Epoch 41/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0109 - mae: 0.0044 - val_loss: 0.0105 - val_mae: 0.0029\n",
      "Epoch 42/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0101 - mae: 0.0046 - val_loss: 0.0099 - val_mae: 0.0122\n",
      "Epoch 43/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0094 - mae: 0.0043 - val_loss: 0.0091 - val_mae: 0.0063\n",
      "Epoch 44/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0087 - mae: 0.0045 - val_loss: 0.0084 - val_mae: 0.0064\n",
      "Epoch 45/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0081 - mae: 0.0040 - val_loss: 0.0078 - val_mae: 0.0044\n",
      "Epoch 46/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0075 - mae: 0.0042 - val_loss: 0.0072 - val_mae: 0.0032\n",
      "Epoch 47/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0070 - mae: 0.0043 - val_loss: 0.0067 - val_mae: 0.0049\n",
      "Epoch 48/1000\n",
      "645/645 [==============================] - 4s 5ms/step - loss: 0.0065 - mae: 0.0044 - val_loss: 0.0063 - val_mae: 0.0050\n",
      "Epoch 49/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0061 - mae: 0.0043 - val_loss: 0.0059 - val_mae: 0.0050\n",
      "Epoch 50/1000\n",
      "645/645 [==============================] - 4s 5ms/step - loss: 0.0057 - mae: 0.0041 - val_loss: 0.0055 - val_mae: 0.0059\n",
      "Epoch 51/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0053 - mae: 0.0040 - val_loss: 0.0055 - val_mae: 0.0156\n",
      "Epoch 52/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0050 - mae: 0.0043 - val_loss: 0.0048 - val_mae: 0.0034\n",
      "Epoch 53/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0047 - mae: 0.0041 - val_loss: 0.0045 - val_mae: 0.0051\n",
      "Epoch 54/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0044 - mae: 0.0041 - val_loss: 0.0043 - val_mae: 0.0037\n",
      "Epoch 55/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0042 - mae: 0.0045 - val_loss: 0.0040 - val_mae: 0.0027\n",
      "Epoch 56/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0039 - mae: 0.0038 - val_loss: 0.0039 - val_mae: 0.0055\n",
      "Epoch 57/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0037 - mae: 0.0044 - val_loss: 0.0037 - val_mae: 0.0062\n",
      "Epoch 58/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0035 - mae: 0.0040 - val_loss: 0.0035 - val_mae: 0.0049\n",
      "Epoch 59/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0034 - mae: 0.0041 - val_loss: 0.0033 - val_mae: 0.0031\n",
      "Epoch 60/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0032 - mae: 0.0041 - val_loss: 0.0032 - val_mae: 0.0058\n",
      "Epoch 61/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0031 - mae: 0.0041 - val_loss: 0.0030 - val_mae: 0.0041\n",
      "Epoch 62/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0030 - mae: 0.0043 - val_loss: 0.0029 - val_mae: 0.0036\n",
      "Epoch 63/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0029 - mae: 0.0038 - val_loss: 0.0028 - val_mae: 0.0036\n",
      "Epoch 64/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0028 - mae: 0.0045 - val_loss: 0.0027 - val_mae: 0.0042\n",
      "Epoch 65/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0027 - mae: 0.0040 - val_loss: 0.0026 - val_mae: 0.0044\n",
      "Epoch 66/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0026 - mae: 0.0041 - val_loss: 0.0025 - val_mae: 0.0045\n",
      "Epoch 67/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0025 - mae: 0.0043 - val_loss: 0.0025 - val_mae: 0.0037\n",
      "Epoch 68/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0024 - mae: 0.0042 - val_loss: 0.0024 - val_mae: 0.0039\n",
      "Epoch 69/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0024 - mae: 0.0041 - val_loss: 0.0023 - val_mae: 0.0039\n",
      "Epoch 70/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0041 - val_loss: 0.0023 - val_mae: 0.0029\n",
      "Epoch 71/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0042 - val_loss: 0.0022 - val_mae: 0.0058\n",
      "Epoch 72/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0039 - val_loss: 0.0022 - val_mae: 0.0044\n",
      "Epoch 73/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0041 - val_loss: 0.0021 - val_mae: 0.0046\n",
      "Epoch 74/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0021 - mae: 0.0044 - val_loss: 0.0021 - val_mae: 0.0075\n",
      "Epoch 75/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0021 - mae: 0.0043 - val_loss: 0.0020 - val_mae: 0.0034\n",
      "Epoch 76/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0020 - mae: 0.0040 - val_loss: 0.0020 - val_mae: 0.0043\n",
      "Epoch 77/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0020 - mae: 0.0041 - val_loss: 0.0020 - val_mae: 0.0031\n",
      "Epoch 78/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0020 - mae: 0.0041 - val_loss: 0.0019 - val_mae: 0.0030\n",
      "Epoch 79/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0019 - mae: 0.0041 - val_loss: 0.0019 - val_mae: 0.0038\n",
      "Epoch 80/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0019 - mae: 0.0041 - val_loss: 0.0019 - val_mae: 0.0042\n",
      "Epoch 81/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0019 - mae: 0.0041 - val_loss: 0.0019 - val_mae: 0.0041\n",
      "Epoch 82/1000\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.0018 - mae: 0.0042 - val_loss: 0.0019 - val_mae: 0.0093\n",
      "Epoch 83/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0018 - mae: 0.0042 - val_loss: 0.0018 - val_mae: 0.0052\n",
      "Epoch 84/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0018 - mae: 0.0041 - val_loss: 0.0018 - val_mae: 0.0040\n",
      "Epoch 85/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0018 - mae: 0.0042 - val_loss: 0.0019 - val_mae: 0.0109\n",
      "Epoch 86/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0018 - mae: 0.0043 - val_loss: 0.0018 - val_mae: 0.0074\n",
      "Epoch 87/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0017 - mae: 0.0039 - val_loss: 0.0017 - val_mae: 0.0059\n",
      "Epoch 88/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0017 - mae: 0.0041 - val_loss: 0.0017 - val_mae: 0.0028\n",
      "Epoch 89/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0017 - mae: 0.0041 - val_loss: 0.0017 - val_mae: 0.0031\n",
      "Epoch 90/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0017 - mae: 0.0039 - val_loss: 0.0017 - val_mae: 0.0057\n",
      "Epoch 91/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0017 - mae: 0.0043 - val_loss: 0.0016 - val_mae: 0.0036\n",
      "Epoch 92/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0016 - mae: 0.0040 - val_loss: 0.0016 - val_mae: 0.0048\n",
      "Epoch 93/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0016 - mae: 0.0041 - val_loss: 0.0016 - val_mae: 0.0044\n",
      "Epoch 94/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0016 - mae: 0.0039 - val_loss: 0.0016 - val_mae: 0.0032\n",
      "Epoch 95/1000\n",
      "645/645 [==============================] - 4s 5ms/step - loss: 0.0016 - mae: 0.0041 - val_loss: 0.0016 - val_mae: 0.0046\n",
      "Epoch 96/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0016 - mae: 0.0041 - val_loss: 0.0016 - val_mae: 0.0071\n",
      "Epoch 97/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0029\n",
      "Epoch 98/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0016 - mae: 0.0038 - val_loss: 0.0016 - val_mae: 0.0060\n",
      "Epoch 99/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0030\n",
      "Epoch 100/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0015 - mae: 0.0041 - val_loss: 0.0016 - val_mae: 0.0092\n",
      "Epoch 101/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0038\n",
      "Epoch 102/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0015 - mae: 0.0040 - val_loss: 0.0015 - val_mae: 0.0035\n",
      "Epoch 103/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0015 - mae: 0.0041 - val_loss: 0.0015 - val_mae: 0.0035\n",
      "Epoch 104/1000\n",
      "645/645 [==============================] - 4s 5ms/step - loss: 0.0015 - mae: 0.0041 - val_loss: 0.0015 - val_mae: 0.0030\n",
      "Epoch 105/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0015 - mae: 0.0040 - val_loss: 0.0015 - val_mae: 0.0052\n",
      "Epoch 106/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0088\n",
      "Epoch 107/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0015 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0057\n",
      "Epoch 108/1000\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0015 - mae: 0.0039 - val_loss: 0.0015 - val_mae: 0.0084\n",
      "Epoch 109/1000\n",
      "635/645 [============================>.] - ETA: 0s - loss: 0.0015 - mae: 0.0043Restoring model weights from the end of the best epoch: 104.\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0077\n",
      "Epoch 109: early stopping\n",
      "Durchschnittlicher Validation Loss: 0.0013216145569458603\n",
      "Durchschnittlicher Validation MAE: 0.0027098299004137518\n"
     ]
    }
   ],
   "source": [
    "# Initialisiere Listen, um Ergebnisse zu speichern\n",
    "val_loss_results = []\n",
    "val_mae_results = []\n",
    "\n",
    "# Funktion, um das Modell zu erstellen\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "            Dense(80, activation='relu', input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "            Dense(208, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "        \n",
    "            Dense(320, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "        \n",
    "            Dense(240, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "        \n",
    "            Dense(224, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "        \n",
    "            Dense(160, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "            \n",
    "            Dense(128, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "            \n",
    "            Dense(240, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "            \n",
    "            Dense(256, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "            \n",
    "            Dense(32, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "            \n",
    "            Dense(1 , activation = 'linear')\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# K-Fold Cross-Validation Konfiguration\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# LeistungsÃ¼berwachung\n",
    "fold_no = 1\n",
    "for train_index, val_index in kf.split(X_train_scaled):\n",
    "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_scaled[train_index], y_train_scaled[val_index]\n",
    "\n",
    "    model = create_model()\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "    print(f'Training fÃ¼r Fold {fold_no}...')\n",
    "    history = model.fit(X_train_fold, y_train_fold, batch_size=100, epochs=1000, validation_data=(X_val_fold, y_val_fold), callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "    # Speichere die Ergebnisse des aktuellen Folds\n",
    "    val_loss_results.append(min(history.history['val_loss']))\n",
    "    val_mae_results.append(min(history.history['val_mae']))\n",
    "\n",
    "    fold_no += 1\n",
    "\n",
    "# Berechne den Durchschnitt Ã¼ber alle Folds\n",
    "average_val_loss = np.mean(val_loss_results)\n",
    "average_val_mae = np.mean(val_mae_results)\n",
    "\n",
    "# Gib die durchschnittlichen Ergebnisse aus\n",
    "print(f'Durchschnittlicher Validation Loss: {average_val_loss}')\n",
    "print(f'Durchschnittlicher Validation MAE: {average_val_mae}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T10:17:12.780295600Z",
     "start_time": "2024-03-18T09:32:57.974605500Z"
    }
   },
   "id": "29c288dd786bd1cb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Auswertung des NeuroNetz auf den Testdatensatz"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83d8d88143abaf36"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 - 1s - loss: 3.1961e-04 - mae: 0.0014 - 926ms/epoch - 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.0003196065663360059, 0.0014413115568459034]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test_scaled, y_test_scaled, verbose=2)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T14:05:40.437250700Z",
     "start_time": "2024-03-19T14:05:39.464894200Z"
    }
   },
   "id": "68d86893ad985b02"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f6f672a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:05:42.370794600Z",
     "start_time": "2024-03-19T14:05:41.184454500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bsp. Predicted: [1195.1089] Actual: [1195.9] \n",
      "Durchschnittliche Abweichung (MAE): [1.3660558]\n"
     ]
    }
   ],
   "source": [
    "#RÃ¼ckrechnung des skalierten MAE zum unskalierten MAE fÃ¼r eines bessere EinschÃ¤tzung des Ergebnisses\n",
    "scaled_predicted_values = model.predict(X_test_scaled, verbose = 0)\n",
    "\n",
    "# FÃ¼hren Sie die RÃ¼cktransformation der skalierten Werte durch\n",
    "original_predicted_values = scaler_target.inverse_transform(scaled_predicted_values)\n",
    "original_actual_values = scaler_target.inverse_transform(y_test_scaled)  # y_test sind die skalierten tatsÃ¤chlichen Werte\n",
    "print(f' Bsp. Predicted: {original_predicted_values[1000]} Actual: {original_actual_values[1000]} ')\n",
    "\n",
    "def calculate_mae(list1, list2):\n",
    "    # Stelle sicher, dass beide Listen die gleiche LÃ¤nge haben\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Listen mÃ¼ssen die gleiche LÃ¤nge haben\")\n",
    "\n",
    "    # Berechne die absolute Differenz zwischen den Elementen der Listen\n",
    "    differences = [abs(x - y) for x, y in zip(list1, list2)]\n",
    "\n",
    "    # Berechne den Durchschnitt der absoluten Differenzen\n",
    "    mae = sum(differences) / len(differences)\n",
    "\n",
    "    return mae\n",
    "\n",
    "# Beispiel\n",
    "list1 = original_predicted_values\n",
    "list2 = original_actual_values\n",
    "\n",
    "mae = calculate_mae(list1, list2)\n",
    "print(f\"Durchschnittliche Abweichung (MAE): {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: [0.99995256]\n"
     ]
    }
   ],
   "source": [
    "#Berechnung der AuswertungsgrÃ¶ÃŸe R^2\n",
    "\n",
    "def calculate_r_squared(predicted, actual):\n",
    "    # Berechnung des Mittelwerts der tatsÃ¤chlichen Werte\n",
    "    mean_actual = sum(actual) / len(actual)\n",
    "    \n",
    "    # Berechnung der totalen Summe der Quadrate (SST)\n",
    "    sst = sum((x - mean_actual) ** 2 for x in actual)\n",
    "    \n",
    "    # Berechnung der Summe der Quadrate der Residuen (SSE)\n",
    "    sse = sum((actual[i] - predicted[i]) ** 2 for i in range(len(actual)))\n",
    "    \n",
    "    # Berechnung des R^2-Wertes\n",
    "    r_squared = 1 - (sse / sst)\n",
    "    \n",
    "    return r_squared\n",
    "\n",
    "# Berechnung von R^2 mit den bereitgestellten Listen\n",
    "r_squared = calculate_r_squared(list1, list2)\n",
    "\n",
    "print(f\"R^2: {r_squared}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T14:05:43.478399600Z",
     "start_time": "2024-03-19T14:05:43.368387600Z"
    }
   },
   "id": "48ac8cdcc05e55fd"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Werte die kleiner sind: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "             Echt  Vorhergesagt  X-Koordinate  Y-Koordinate  Differenz\n19281  792.499634        807.84         1.000        0.9125 -15.340366\n15566  755.980469        771.22         0.996        0.9250 -15.239531\n9896   777.671448        791.74         0.992        0.9175 -14.068552\n11539  719.390686        733.08         0.996        0.9375 -13.689314\n4131   755.465942        768.74         0.988        0.9250 -13.274058\n...           ...           ...           ...           ...        ...\n1409   681.299133        666.57         0.936        0.0000  14.729133\n7694   682.386292        667.48         0.944        0.0000  14.906292\n14839  614.367920        599.38         0.956        0.9725  14.987920\n13809  609.107422        593.15         0.988        0.9750  15.957422\n20012  609.621704        588.92         0.996        0.9750  20.701704\n\n[20131 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Echt</th>\n      <th>Vorhergesagt</th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Differenz</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>19281</th>\n      <td>792.499634</td>\n      <td>807.84</td>\n      <td>1.000</td>\n      <td>0.9125</td>\n      <td>-15.340366</td>\n    </tr>\n    <tr>\n      <th>15566</th>\n      <td>755.980469</td>\n      <td>771.22</td>\n      <td>0.996</td>\n      <td>0.9250</td>\n      <td>-15.239531</td>\n    </tr>\n    <tr>\n      <th>9896</th>\n      <td>777.671448</td>\n      <td>791.74</td>\n      <td>0.992</td>\n      <td>0.9175</td>\n      <td>-14.068552</td>\n    </tr>\n    <tr>\n      <th>11539</th>\n      <td>719.390686</td>\n      <td>733.08</td>\n      <td>0.996</td>\n      <td>0.9375</td>\n      <td>-13.689314</td>\n    </tr>\n    <tr>\n      <th>4131</th>\n      <td>755.465942</td>\n      <td>768.74</td>\n      <td>0.988</td>\n      <td>0.9250</td>\n      <td>-13.274058</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1409</th>\n      <td>681.299133</td>\n      <td>666.57</td>\n      <td>0.936</td>\n      <td>0.0000</td>\n      <td>14.729133</td>\n    </tr>\n    <tr>\n      <th>7694</th>\n      <td>682.386292</td>\n      <td>667.48</td>\n      <td>0.944</td>\n      <td>0.0000</td>\n      <td>14.906292</td>\n    </tr>\n    <tr>\n      <th>14839</th>\n      <td>614.367920</td>\n      <td>599.38</td>\n      <td>0.956</td>\n      <td>0.9725</td>\n      <td>14.987920</td>\n    </tr>\n    <tr>\n      <th>13809</th>\n      <td>609.107422</td>\n      <td>593.15</td>\n      <td>0.988</td>\n      <td>0.9750</td>\n      <td>15.957422</td>\n    </tr>\n    <tr>\n      <th>20012</th>\n      <td>609.621704</td>\n      <td>588.92</td>\n      <td>0.996</td>\n      <td>0.9750</td>\n      <td>20.701704</td>\n    </tr>\n  </tbody>\n</table>\n<p>20131 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ausgabe der hÃ¶chsten Abweichungen zwischen Echt und Vorhergesagt\n",
    "df_result = pd.DataFrame({'Echt': [val[0] for val in list1], 'Vorhergesagt': [val[0] for val in list2]})\n",
    "df_result['X-Koordinate'] = X_test_scaled[:, 0]\n",
    "df_result['Y-Koordinate'] = X_test_scaled[:, 1]\n",
    "\n",
    "df_result['Differenz'] = df_result['Echt'] - df_result['Vorhergesagt']\n",
    "df_result['Differenz'].sort_values()\n",
    "sorted_df = df_result.sort_values(by= 'Differenz')\n",
    "Anzahl_Punkte = (sorted_df['Differenz'] > 20).sum()\n",
    "print(\"Anzahl der Werte die kleiner sind:\", Anzahl_Punkte)\n",
    "\n",
    "sorted_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T14:05:48.124575Z",
     "start_time": "2024-03-19T14:05:48.091947500Z"
    }
   },
   "id": "42bde60d3b4f2007"
  },
  {
   "cell_type": "markdown",
   "id": "553df6fa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mae = history.history['loss']\n",
    "val_mae = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(mae) + 1)\n",
    "# MAE Diagramm\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, mae, 'r', label='Training MSE')\n",
    "plt.plot(epochs, val_mae, 'b', label='Validation MSE')\n",
    "plt.title('Training and Validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.savefig('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Bilder Diplomarbeit/MSE_NeuroNetz/MSE_NeuroNetz_D1_2')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T14:05:52.915937800Z",
     "start_time": "2024-03-19T14:05:52.704855600Z"
    }
   },
   "id": "3688dd7102e95baf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# GridSearch\n",
    "Grid Search bietet die Vorteile der anpassbaren Rechenzeit sowie die MÃ¶glichkeit des EInsatzes von Verteilungen. So kÃ¶nnen theoretisch Hyperparamterkonfuigurationen gefunden wende, welche durch GridSearch nicht auffindbar wÃ¤ren. ZUdem ist das Ziel der Hyperparamteroptimierung eine Einstellung zu finden, welche auf Trainings und Testset gut angepasst ist. Die EInstellung muss nicht die bestmÃ¶glichste Einstellung sein, sondern eine Einstellung die das gewÃ¤hltre Problem gut wiederspiegelt. \n",
    "Bayesian Optimierung"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c177960cc729052"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3f17e2cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T10:00:01.423818100Z",
     "start_time": "2024-03-15T10:00:01.416947800Z"
    }
   },
   "outputs": [],
   "source": [
    "# def build_model(learning_rate=0.001, activation='relu', regularization=0.0001, dropout_rate=0.0):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(320, activation=activation, input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(176, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(288, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(192, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(208, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(224, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(80, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(304, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate)) \n",
    "# \n",
    "#     model.add(Dense(240, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))   \n",
    "# \n",
    "#     model.add(Dense(48, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mae'])\n",
    "#     return model\n",
    "# \n",
    "# # Verwenden Sie eine Funktion, um das Modell zu instanziieren, fÃ¼r scikit-learn Wrapper\n",
    "# model = KerasRegressor(model=build_model, verbose=2)\n",
    "# \n",
    "# # Anpassung der Parameter im param_grid\n",
    "# param_grid = {\n",
    "#     'model__learning_rate': [0.01, 0.001, 0.0001],\n",
    "#     'model__regularization': [0.001, 0.0001, 0.00001],\n",
    "#     'fit__batch_size': [100, 200, 400, 800],\n",
    "#     'fit__epochs': [50],\n",
    "#     'model__dropout_rate' : [0.0, 0.1, 0.2]\n",
    "# }\n",
    "# \n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=2)\n",
    "# # Hinweis: Stellen Sie sicher, dass Ihre Daten (X_train_scaled, y_train_scaled) korrekt definiert sind\n",
    "# grid_result = grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "# # Beste Parameter und Score ausgeben\n",
    "# print(\"Beste Parameter:\", grid_search.best_params_)\n",
    "# print(\"Beste Genauigkeit:\", grid_search.best_score_)\n",
    "# \n",
    "# with open(\"grid_search_D1_2.txt\", \"w\") as f:\n",
    "#     f.write(f\"Beste Parameter: {grid_search.best_params_}\\n\")\n",
    "#     f.write(f\"Beste Genauigkeit: {grid_search.best_score_}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
