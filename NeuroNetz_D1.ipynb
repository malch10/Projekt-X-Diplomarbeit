{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94b0518e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T09:50:38.590991400Z",
     "start_time": "2024-02-22T09:50:25.501335900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense , Dropout\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasRegressor \n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import time\n",
    "from keras_tuner import HyperModel\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_tuner import RandomSearch\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4ff61b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T09:50:38.639619400Z",
     "start_time": "2024-02-22T09:50:38.591992300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n0             0.0000      -0.00200        500   7000   9000      669.05\n1             0.0000      -0.00199        500   7000   9000      675.83\n2             0.0000      -0.00198        500   7000   9000      682.81\n3             0.0000      -0.00197        500   7000   9000      689.82\n4             0.0000      -0.00196        500   7000   9000      696.80\n...              ...           ...        ...    ...    ...         ...\n100646        0.0025       0.00196        500   7000   9000      578.47\n100647        0.0025       0.00197        500   7000   9000      576.89\n100648        0.0025       0.00198        500   7000   9000      575.32\n100649        0.0025       0.00199        500   7000   9000      573.76\n100650        0.0025       0.00200        500   7000   9000      572.20\n\n[100651 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>669.05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0000</td>\n      <td>-0.00199</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>675.83</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0000</td>\n      <td>-0.00198</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>682.81</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0000</td>\n      <td>-0.00197</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>689.82</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0000</td>\n      <td>-0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>696.80</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>100646</th>\n      <td>0.0025</td>\n      <td>0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>578.47</td>\n    </tr>\n    <tr>\n      <th>100647</th>\n      <td>0.0025</td>\n      <td>0.00197</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>576.89</td>\n    </tr>\n    <tr>\n      <th>100648</th>\n      <td>0.0025</td>\n      <td>0.00198</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>575.32</td>\n    </tr>\n    <tr>\n      <th>100649</th>\n      <td>0.0025</td>\n      <td>0.00199</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>573.76</td>\n    </tr>\n    <tr>\n      <th>100650</th>\n      <td>0.0025</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>572.20</td>\n    </tr>\n  </tbody>\n</table>\n<p>100651 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/TPath_300_finish_data.pkl')\n",
    "data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish_D1_I7000_F9000/TPath_500_finish_data_D1.pkl')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "966e3c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T09:50:38.639619400Z",
     "start_time": "2024-02-22T09:50:38.619745300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate  Temperatur\n0             0.0000      -0.00200      669.05\n1             0.0000      -0.00199      675.83\n2             0.0000      -0.00198      682.81\n3             0.0000      -0.00197      689.82\n4             0.0000      -0.00196      696.80\n...              ...           ...         ...\n100646        0.0025       0.00196      578.47\n100647        0.0025       0.00197      576.89\n100648        0.0025       0.00198      575.32\n100649        0.0025       0.00199      573.76\n100650        0.0025       0.00200      572.20\n\n[100651 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>669.05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0000</td>\n      <td>-0.00199</td>\n      <td>675.83</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0000</td>\n      <td>-0.00198</td>\n      <td>682.81</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0000</td>\n      <td>-0.00197</td>\n      <td>689.82</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0000</td>\n      <td>-0.00196</td>\n      <td>696.80</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>100646</th>\n      <td>0.0025</td>\n      <td>0.00196</td>\n      <td>578.47</td>\n    </tr>\n    <tr>\n      <th>100647</th>\n      <td>0.0025</td>\n      <td>0.00197</td>\n      <td>576.89</td>\n    </tr>\n    <tr>\n      <th>100648</th>\n      <td>0.0025</td>\n      <td>0.00198</td>\n      <td>575.32</td>\n    </tr>\n    <tr>\n      <th>100649</th>\n      <td>0.0025</td>\n      <td>0.00199</td>\n      <td>573.76</td>\n    </tr>\n    <tr>\n      <th>100650</th>\n      <td>0.0025</td>\n      <td>0.00200</td>\n      <td>572.20</td>\n    </tr>\n  </tbody>\n</table>\n<p>100651 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.drop(data.columns[2:5], axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8783d1d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T09:50:38.659060400Z",
     "start_time": "2024-02-22T09:50:38.631619700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       X-Koordinate  Y-Koordinate  Temperatur\n",
      "83145       0.00207      -0.00062      1282.2\n",
      "66701       0.00166      -0.00065      1347.6\n",
      "91325       0.00227       0.00098      1094.6\n",
      "46593       0.00116      -0.00123      1175.7\n",
      "49518       0.00123      -0.00005      1459.2\n",
      "...             ...           ...         ...\n",
      "6265        0.00015       0.00050      1439.1\n",
      "54886       0.00136       0.00150       876.7\n",
      "76820       0.00191       0.00029      1335.8\n",
      "860         0.00002      -0.00142      1071.2\n",
      "15795       0.00039      -0.00044      1488.1\n",
      "\n",
      "[100651 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate  Temperatur\n0            0.00207      -0.00062      1282.2\n1            0.00166      -0.00065      1347.6\n2            0.00227       0.00098      1094.6\n3            0.00116      -0.00123      1175.7\n4            0.00123      -0.00005      1459.2\n...              ...           ...         ...\n100646       0.00015       0.00050      1439.1\n100647       0.00136       0.00150       876.7\n100648       0.00191       0.00029      1335.8\n100649       0.00002      -0.00142      1071.2\n100650       0.00039      -0.00044      1488.1\n\n[100651 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00207</td>\n      <td>-0.00062</td>\n      <td>1282.2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00166</td>\n      <td>-0.00065</td>\n      <td>1347.6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00227</td>\n      <td>0.00098</td>\n      <td>1094.6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00116</td>\n      <td>-0.00123</td>\n      <td>1175.7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00123</td>\n      <td>-0.00005</td>\n      <td>1459.2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>100646</th>\n      <td>0.00015</td>\n      <td>0.00050</td>\n      <td>1439.1</td>\n    </tr>\n    <tr>\n      <th>100647</th>\n      <td>0.00136</td>\n      <td>0.00150</td>\n      <td>876.7</td>\n    </tr>\n    <tr>\n      <th>100648</th>\n      <td>0.00191</td>\n      <td>0.00029</td>\n      <td>1335.8</td>\n    </tr>\n    <tr>\n      <th>100649</th>\n      <td>0.00002</td>\n      <td>-0.00142</td>\n      <td>1071.2</td>\n    </tr>\n    <tr>\n      <th>100650</th>\n      <td>0.00039</td>\n      <td>-0.00044</td>\n      <td>1488.1</td>\n    </tr>\n  </tbody>\n</table>\n<p>100651 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.sample(frac=1, random_state=42)  # Hier wird 42 als Random State verwendet, um die Ergebnisse reproduzierbar zu machen\n",
    "\n",
    "print(df1)\n",
    "df_reset = df1.reset_index(drop=True)\n",
    "df_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4e72a16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T09:50:38.659060400Z",
     "start_time": "2024-02-22T09:50:38.647420500Z"
    }
   },
   "outputs": [],
   "source": [
    "label = df_reset[\"Temperatur\"]\n",
    "# Korrektur: Verwenden Sie den Spaltennamen direkt, ohne Indexierung der columns-Eigenschaft\n",
    "df1 = df_reset.drop(\"Temperatur\", axis=1)\n",
    "X = df1\n",
    "y = label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7fa289a50d87423"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e694a236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T09:50:38.709846Z",
     "start_time": "2024-02-22T09:50:38.653061100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate\ncount  100651.000000  1.006510e+05\nmean        0.001250  1.103042e-20\nstd         0.000725  1.157589e-03\nmin         0.000000 -2.000000e-03\n25%         0.000620 -1.000000e-03\n50%         0.001250  4.529900e-18\n75%         0.001880  1.000000e-03\nmax         0.002500  2.000000e-03",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>100651.000000</td>\n      <td>1.006510e+05</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.001250</td>\n      <td>1.103042e-20</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.000725</td>\n      <td>1.157589e-03</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-2.000000e-03</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000620</td>\n      <td>-1.000000e-03</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.001250</td>\n      <td>4.529900e-18</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.001880</td>\n      <td>1.000000e-03</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.002500</td>\n      <td>2.000000e-03</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f3303b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T09:50:38.799377500Z",
     "start_time": "2024-02-22T09:50:38.670890300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "count    100651.000000\nmean       1144.030064\nstd         264.135723\nmin         572.200000\n25%         937.330000\n50%        1201.100000\n75%        1368.700000\nmax        1520.000000\nName: Temperatur, dtype: float64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3ad8da0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T09:50:38.833562200Z",
     "start_time": "2024-02-22T09:50:38.680996600Z"
    }
   },
   "outputs": [],
   "source": [
    " # train_df enthält 80% der Daten, test_df enthält 20% der Daten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c705edb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T09:50:38.859633900Z",
     "start_time": "2024-02-22T09:50:38.689697100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialisiere einen MinMaxScaler für die Features\n",
    "scaler_features = MinMaxScaler()\n",
    "scaler_features2 = MinMaxScaler()\n",
    "# Skaliere X_train und X_test\n",
    "X_train_scaled = scaler_features.fit_transform(X_train)\n",
    "X_test_scaled = scaler_features.transform(X_test)  # Nutze unterschiedliche Skalierungsparameter\n",
    "\n",
    "# Initialisiere einen SEPARATEN MinMaxScaler für das Ziel, wenn nötig\n",
    "scaler_target = MinMaxScaler()\n",
    "\n",
    "\n",
    "# Skaliere y_train und y_test. Beachte, dass y_train.reshape(-1, 1) verwendet wird, da MinMaxScaler \n",
    "# erwartet, dass die Eingaben als 2D-Arrays kommen, und Ziele normalerweise als 1D-Arrays vorliegen.\n",
    "y_train_scaled = scaler_target.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test_scaled = scaler_target.transform(y_test.values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbefe631e495b483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T09:50:38.860633100Z",
     "start_time": "2024-02-22T09:50:38.699530500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.416 , 0.5725],\n       [0.812 , 0.7325],\n       [0.628 , 0.5075],\n       ...,\n       [0.604 , 0.3875],\n       [0.748 , 0.65  ],\n       [0.028 , 0.6225]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "323/323 [==============================] - 2s 3ms/step - loss: 0.1719 - mae: 0.0765 - val_loss: 0.1117 - val_mae: 0.0109\n",
      "Epoch 2/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.1030 - mae: 0.0131 - val_loss: 0.0951 - val_mae: 0.0107\n",
      "Epoch 3/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0892 - mae: 0.0130 - val_loss: 0.0833 - val_mae: 0.0114\n",
      "Epoch 4/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0784 - mae: 0.0087 - val_loss: 0.0736 - val_mae: 0.0054\n",
      "Epoch 5/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0696 - mae: 0.0092 - val_loss: 0.0655 - val_mae: 0.0045\n",
      "Epoch 6/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0620 - mae: 0.0081 - val_loss: 0.0588 - val_mae: 0.0141\n",
      "Epoch 7/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0554 - mae: 0.0084 - val_loss: 0.0528 - val_mae: 0.0187\n",
      "Epoch 8/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0495 - mae: 0.0079 - val_loss: 0.0468 - val_mae: 0.0100\n",
      "Epoch 9/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0441 - mae: 0.0071 - val_loss: 0.0417 - val_mae: 0.0106\n",
      "Epoch 10/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0392 - mae: 0.0072 - val_loss: 0.0368 - val_mae: 0.0048\n",
      "Epoch 11/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0346 - mae: 0.0064 - val_loss: 0.0324 - val_mae: 0.0035\n",
      "Epoch 12/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0304 - mae: 0.0066 - val_loss: 0.0284 - val_mae: 0.0072\n",
      "Epoch 13/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0265 - mae: 0.0058 - val_loss: 0.0247 - val_mae: 0.0067\n",
      "Epoch 14/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0230 - mae: 0.0063 - val_loss: 0.0213 - val_mae: 0.0038\n",
      "Epoch 15/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0198 - mae: 0.0067 - val_loss: 0.0182 - val_mae: 0.0041\n",
      "Epoch 16/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0170 - mae: 0.0068 - val_loss: 0.0156 - val_mae: 0.0067\n",
      "Epoch 17/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0144 - mae: 0.0066 - val_loss: 0.0139 - val_mae: 0.0237\n",
      "Epoch 18/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0123 - mae: 0.0069 - val_loss: 0.0112 - val_mae: 0.0053\n",
      "Epoch 19/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0103 - mae: 0.0056 - val_loss: 0.0095 - val_mae: 0.0070\n",
      "Epoch 20/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0087 - mae: 0.0070 - val_loss: 0.0081 - val_mae: 0.0117\n",
      "Epoch 21/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0074 - mae: 0.0081 - val_loss: 0.0068 - val_mae: 0.0113\n",
      "Epoch 22/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0062 - mae: 0.0061 - val_loss: 0.0061 - val_mae: 0.0183\n",
      "Epoch 23/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0052 - mae: 0.0065 - val_loss: 0.0051 - val_mae: 0.0175\n",
      "Epoch 24/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0044 - mae: 0.0069 - val_loss: 0.0041 - val_mae: 0.0068\n",
      "Epoch 25/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0038 - mae: 0.0078 - val_loss: 0.0035 - val_mae: 0.0062\n",
      "Epoch 26/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0065 - val_loss: 0.0037 - val_mae: 0.0193\n",
      "Epoch 27/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0029 - mae: 0.0069 - val_loss: 0.0028 - val_mae: 0.0132\n",
      "Epoch 28/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0070 - val_loss: 0.0025 - val_mae: 0.0121\n",
      "Epoch 29/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0078 - val_loss: 0.0022 - val_mae: 0.0098\n",
      "Epoch 30/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0062 - val_loss: 0.0019 - val_mae: 0.0040\n",
      "Epoch 31/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0070 - val_loss: 0.0020 - val_mae: 0.0144\n",
      "Epoch 32/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0018 - mae: 0.0081 - val_loss: 0.0017 - val_mae: 0.0070\n",
      "Epoch 33/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0068 - val_loss: 0.0017 - val_mae: 0.0124\n",
      "Epoch 34/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0067 - val_loss: 0.0015 - val_mae: 0.0062\n",
      "Epoch 35/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0069 - val_loss: 0.0017 - val_mae: 0.0159\n",
      "Epoch 36/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0080 - val_loss: 0.0014 - val_mae: 0.0072\n",
      "Epoch 37/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0066 - val_loss: 0.0013 - val_mae: 0.0061\n",
      "Epoch 38/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0060 - val_loss: 0.0013 - val_mae: 0.0057\n",
      "Epoch 39/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0075 - val_loss: 0.0012 - val_mae: 0.0069\n",
      "Epoch 40/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0065 - val_loss: 0.0012 - val_mae: 0.0044\n",
      "Epoch 41/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0083 - val_loss: 0.0012 - val_mae: 0.0058\n",
      "Epoch 42/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0064 - val_loss: 0.0011 - val_mae: 0.0044\n",
      "Epoch 43/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0070 - val_loss: 0.0011 - val_mae: 0.0049\n",
      "Epoch 44/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0071 - val_loss: 0.0011 - val_mae: 0.0045\n",
      "Epoch 45/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0064 - val_loss: 0.0016 - val_mae: 0.0214\n",
      "Epoch 46/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0070 - val_loss: 0.0011 - val_mae: 0.0079\n",
      "Epoch 47/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0076 - val_loss: 0.0010 - val_mae: 0.0048\n",
      "Epoch 48/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0064 - val_loss: 0.0013 - val_mae: 0.0122\n",
      "Epoch 49/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0066 - val_loss: 0.0011 - val_mae: 0.0078\n",
      "Epoch 50/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0080 - val_loss: 0.0012 - val_mae: 0.0112\n",
      "Epoch 51/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0060 - val_loss: 0.0010 - val_mae: 0.0045\n",
      "Epoch 52/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0069 - val_loss: 9.7742e-04 - val_mae: 0.0035\n",
      "Epoch 53/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0063 - val_loss: 0.0014 - val_mae: 0.0190\n",
      "Epoch 54/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0073 - val_loss: 0.0010 - val_mae: 0.0077\n",
      "Epoch 55/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0066 - val_loss: 0.0011 - val_mae: 0.0094\n",
      "Epoch 56/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0066 - val_loss: 9.8488e-04 - val_mae: 0.0068\n",
      "Epoch 57/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 9.8786e-04 - mae: 0.0065 - val_loss: 0.0013 - val_mae: 0.0159\n",
      "Epoch 58/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0071 - val_loss: 9.4238e-04 - val_mae: 0.0047\n",
      "Epoch 59/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 9.9349e-04 - mae: 0.0068 - val_loss: 0.0012 - val_mae: 0.0159\n",
      "Epoch 60/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 9.8327e-04 - mae: 0.0068 - val_loss: 0.0011 - val_mae: 0.0099\n",
      "Epoch 61/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 9.4145e-04 - mae: 0.0055 - val_loss: 0.0014 - val_mae: 0.0201\n",
      "Epoch 62/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 9.7258e-04 - mae: 0.0069 - val_loss: 9.2434e-04 - val_mae: 0.0050\n",
      "Epoch 63/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 9.6057e-04 - mae: 0.0068 - val_loss: 9.8226e-04 - val_mae: 0.0084\n",
      "Epoch 64/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 9.5330e-04 - mae: 0.0069 - val_loss: 9.1904e-04 - val_mae: 0.0058\n",
      "Epoch 65/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 9.9323e-04 - mae: 0.0073 - val_loss: 9.3616e-04 - val_mae: 0.0065\n",
      "Epoch 66/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 9.1243e-04 - mae: 0.0055 - val_loss: 0.0017 - val_mae: 0.0245\n",
      "Epoch 67/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 9.4994e-04 - mae: 0.0068 - val_loss: 0.0010 - val_mae: 0.0107\n",
      "Epoch 68/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 9.3289e-04 - mae: 0.0067 - val_loss: 0.0011 - val_mae: 0.0149\n",
      "Epoch 69/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 9.4663e-04 - mae: 0.0071 - val_loss: 0.0012 - val_mae: 0.0149\n",
      "Epoch 70/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 9.2651e-04 - mae: 0.0067 - val_loss: 0.0011 - val_mae: 0.0132\n",
      "Epoch 71/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.9658e-04 - mae: 0.0058 - val_loss: 8.7438e-04 - val_mae: 0.0048\n",
      "Epoch 72/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 9.2082e-04 - mae: 0.0071 - val_loss: 9.0775e-04 - val_mae: 0.0077\n",
      "Epoch 73/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 9.1825e-04 - mae: 0.0070 - val_loss: 8.6034e-04 - val_mae: 0.0046\n",
      "Epoch 74/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.8345e-04 - mae: 0.0058 - val_loss: 9.4279e-04 - val_mae: 0.0096\n",
      "Epoch 75/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 9.5705e-04 - mae: 0.0078 - val_loss: 8.7337e-04 - val_mae: 0.0059\n",
      "Epoch 76/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 9.0061e-04 - mae: 0.0063 - val_loss: 8.6943e-04 - val_mae: 0.0061\n",
      "Epoch 77/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.7716e-04 - mae: 0.0059 - val_loss: 8.9667e-04 - val_mae: 0.0081\n",
      "Epoch 78/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 9.2570e-04 - mae: 0.0074 - val_loss: 8.8049e-04 - val_mae: 0.0068\n",
      "Epoch 79/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.7397e-04 - mae: 0.0062 - val_loss: 8.7301e-04 - val_mae: 0.0071\n",
      "Epoch 80/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.8481e-04 - mae: 0.0066 - val_loss: 9.1028e-04 - val_mae: 0.0090\n",
      "Epoch 81/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.5483e-04 - mae: 0.0056 - val_loss: 8.3139e-04 - val_mae: 0.0045\n",
      "Epoch 82/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 9.0646e-04 - mae: 0.0075 - val_loss: 9.2538e-04 - val_mae: 0.0094\n",
      "Epoch 83/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.6526e-04 - mae: 0.0064 - val_loss: 8.3967e-04 - val_mae: 0.0056\n",
      "Epoch 84/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.4046e-04 - mae: 0.0055 - val_loss: 8.2648e-04 - val_mae: 0.0046\n",
      "Epoch 85/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.6148e-04 - mae: 0.0065 - val_loss: 8.1385e-04 - val_mae: 0.0043\n",
      "Epoch 86/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.5684e-04 - mae: 0.0064 - val_loss: 8.1479e-04 - val_mae: 0.0048\n",
      "Epoch 87/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.6768e-04 - mae: 0.0068 - val_loss: 8.0015e-04 - val_mae: 0.0036\n",
      "Epoch 88/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.5291e-04 - mae: 0.0065 - val_loss: 8.2905e-04 - val_mae: 0.0058\n",
      "Epoch 89/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.4832e-04 - mae: 0.0067 - val_loss: 0.0010 - val_mae: 0.0128\n",
      "Epoch 90/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.9161e-04 - mae: 0.0078 - val_loss: 8.5365e-04 - val_mae: 0.0068\n",
      "Epoch 91/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.1499e-04 - mae: 0.0051 - val_loss: 0.0015 - val_mae: 0.0194\n",
      "Epoch 92/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.5104e-04 - mae: 0.0069 - val_loss: 9.1886e-04 - val_mae: 0.0108\n",
      "Epoch 93/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.4245e-04 - mae: 0.0065 - val_loss: 0.0011 - val_mae: 0.0121\n",
      "Epoch 94/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.2076e-04 - mae: 0.0059 - val_loss: 7.8350e-04 - val_mae: 0.0041\n",
      "Epoch 95/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.8125e-04 - mae: 0.0084 - val_loss: 0.0011 - val_mae: 0.0157\n",
      "Epoch 96/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.0844e-04 - mae: 0.0053 - val_loss: 8.0505e-04 - val_mae: 0.0060\n",
      "Epoch 97/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.2606e-04 - mae: 0.0063 - val_loss: 7.7843e-04 - val_mae: 0.0040\n",
      "Epoch 98/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.0525e-04 - mae: 0.0058 - val_loss: 8.6291e-04 - val_mae: 0.0092\n",
      "Epoch 99/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.4865e-04 - mae: 0.0075 - val_loss: 0.0011 - val_mae: 0.0128\n",
      "Epoch 100/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.2064e-04 - mae: 0.0064 - val_loss: 7.8598e-04 - val_mae: 0.0057\n",
      "Epoch 101/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.0925e-04 - mae: 0.0063 - val_loss: 0.0015 - val_mae: 0.0204\n",
      "Epoch 102/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.4501e-04 - mae: 0.0073 - val_loss: 0.0012 - val_mae: 0.0186\n",
      "Epoch 103/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.2271e-04 - mae: 0.0062 - val_loss: 7.6588e-04 - val_mae: 0.0040\n",
      "Epoch 104/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.9214e-04 - mae: 0.0058 - val_loss: 7.8590e-04 - val_mae: 0.0053\n",
      "Epoch 105/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.1676e-04 - mae: 0.0069 - val_loss: 7.4949e-04 - val_mae: 0.0030\n",
      "Epoch 106/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.0660e-04 - mae: 0.0066 - val_loss: 8.3150e-04 - val_mae: 0.0086\n",
      "Epoch 107/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.9179e-04 - mae: 0.0061 - val_loss: 7.5075e-04 - val_mae: 0.0040\n",
      "Epoch 108/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.0094e-04 - mae: 0.0066 - val_loss: 9.0380e-04 - val_mae: 0.0097\n",
      "Epoch 109/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.3270e-04 - mae: 0.0075 - val_loss: 0.0019 - val_mae: 0.0246\n",
      "Epoch 110/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.4016e-04 - mae: 0.0070 - val_loss: 7.6437e-04 - val_mae: 0.0052\n",
      "Epoch 111/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.7033e-04 - mae: 0.0053 - val_loss: 7.4931e-04 - val_mae: 0.0043\n",
      "Epoch 112/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.2474e-04 - mae: 0.0068 - val_loss: 7.4294e-04 - val_mae: 0.0035\n",
      "Epoch 113/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.6606e-04 - mae: 0.0053 - val_loss: 7.4318e-04 - val_mae: 0.0044\n",
      "Epoch 114/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.9591e-04 - mae: 0.0069 - val_loss: 8.2819e-04 - val_mae: 0.0093\n",
      "Epoch 115/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.9327e-04 - mae: 0.0064 - val_loss: 8.8498e-04 - val_mae: 0.0118\n",
      "Epoch 116/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.8046e-04 - mae: 0.0064 - val_loss: 7.3459e-04 - val_mae: 0.0036\n",
      "Epoch 117/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.7504e-04 - mae: 0.0062 - val_loss: 7.3996e-04 - val_mae: 0.0047\n",
      "Epoch 118/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.1097e-04 - mae: 0.0071 - val_loss: 7.9782e-04 - val_mae: 0.0084\n",
      "Epoch 119/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.8979e-04 - mae: 0.0064 - val_loss: 7.5627e-04 - val_mae: 0.0050\n",
      "Epoch 120/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.6640e-04 - mae: 0.0058 - val_loss: 9.1747e-04 - val_mae: 0.0120\n",
      "Epoch 121/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.9263e-04 - mae: 0.0072 - val_loss: 7.4604e-04 - val_mae: 0.0057\n",
      "Epoch 122/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.5067e-04 - mae: 0.0055 - val_loss: 7.1972e-04 - val_mae: 0.0033\n",
      "Epoch 123/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.7856e-04 - mae: 0.0066 - val_loss: 7.1706e-04 - val_mae: 0.0033\n",
      "Epoch 124/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.7995e-04 - mae: 0.0068 - val_loss: 8.1045e-04 - val_mae: 0.0086\n",
      "Epoch 125/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.6822e-04 - mae: 0.0062 - val_loss: 7.1383e-04 - val_mae: 0.0031\n",
      "Epoch 126/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.8087e-04 - mae: 0.0071 - val_loss: 7.5503e-04 - val_mae: 0.0069\n",
      "Epoch 127/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.5314e-04 - mae: 0.0060 - val_loss: 8.4279e-04 - val_mae: 0.0111\n",
      "Epoch 128/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.7727e-04 - mae: 0.0065 - val_loss: 8.2480e-04 - val_mae: 0.0104\n",
      "Epoch 129/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.7591e-04 - mae: 0.0072 - val_loss: 7.0526e-04 - val_mae: 0.0029\n",
      "Epoch 130/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.8623e-04 - mae: 0.0074 - val_loss: 8.0020e-04 - val_mae: 0.0075\n",
      "Epoch 131/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.6289e-04 - mae: 0.0063 - val_loss: 7.6619e-04 - val_mae: 0.0076\n",
      "Epoch 132/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 8.0013e-04 - mae: 0.0074 - val_loss: 0.0018 - val_mae: 0.0284\n",
      "Epoch 133/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.5235e-04 - mae: 0.0056 - val_loss: 7.0151e-04 - val_mae: 0.0032\n",
      "Epoch 134/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.5294e-04 - mae: 0.0061 - val_loss: 8.6443e-04 - val_mae: 0.0110\n",
      "Epoch 135/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.6583e-04 - mae: 0.0063 - val_loss: 7.0556e-04 - val_mae: 0.0040\n",
      "Epoch 136/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.5461e-04 - mae: 0.0064 - val_loss: 7.6379e-04 - val_mae: 0.0069\n",
      "Epoch 137/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.6284e-04 - mae: 0.0066 - val_loss: 7.5802e-04 - val_mae: 0.0082\n",
      "Epoch 138/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.4379e-04 - mae: 0.0062 - val_loss: 7.0475e-04 - val_mae: 0.0041\n",
      "Epoch 139/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.5318e-04 - mae: 0.0064 - val_loss: 7.4717e-04 - val_mae: 0.0073\n",
      "Epoch 140/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.6585e-04 - mae: 0.0070 - val_loss: 7.3894e-04 - val_mae: 0.0060\n",
      "Epoch 141/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.5054e-04 - mae: 0.0065 - val_loss: 7.0156e-04 - val_mae: 0.0043\n",
      "Epoch 142/200\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.7628e-04 - mae: 0.0075 - val_loss: 8.5008e-04 - val_mae: 0.0113\n",
      "Epoch 143/200\n",
      "307/323 [===========================>..] - ETA: 0s - loss: 7.2114e-04 - mae: 0.0054Restoring model weights from the end of the best epoch: 133.\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 7.2315e-04 - mae: 0.0055 - val_loss: 7.4263e-04 - val_mae: 0.0070\n",
      "Epoch 143: early stopping\n",
      "Die Ausführungszeit betrug 127.74366974830627 Sekunden.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Netzwerkarchitektur\n",
    "model = Sequential([\n",
    "    # Eingabeschicht\n",
    "    Dense(224, activation='relu', input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    #Dropout(0.01),\n",
    "    # Versteckte Schicht\n",
    "    Dense(32, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    Dense(96, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    #Dropout(0.01),\n",
    "    # Ausgabeschicht für Regression (1 Einheit ohne Aktivierungsfunktion)\n",
    "    Dense(224, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    Dense(128, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    Dense(352, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(1 , activation = 'linear')\n",
    "])\n",
    "\n",
    "# Optimierer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# Modell kompilieren (Verwendung von mean_squared_error als Verlustfunktion für Regression)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])  # Metriken für Regression: Mean Absolute Error und Mean Squared Error\n",
    "\n",
    "# Early Stopping Callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=2, mode='min', restore_best_weights=True)#, min_delta = 0.00005)\n",
    "\n",
    "# Trainingsparameter\n",
    "batch_size = 200\n",
    "epochs = 200\n",
    "\n",
    "# Modell trainieren (Annahme: X_train, y_train, X_val, y_val sind vordefiniert)\n",
    "history = model.fit(X_train_scaled, y_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose = 1)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Berechne die Dauer\n",
    "duration = end_time - start_time\n",
    "\n",
    "print(f\"Die Ausführungszeit betrug {duration} Sekunden.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T10:37:30.871082900Z",
     "start_time": "2024-02-22T10:35:23.122700200Z"
    }
   },
   "id": "8b52e1a9a6ff3aeb"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f6f672a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T10:37:36.250778900Z",
     "start_time": "2024-02-22T10:37:35.180798500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bsp. Predicted: [1191.9076] Actual: [1195.9] \n",
      "Durchschnittliche Abweichung (MAE): [3.07670403]\n"
     ]
    }
   ],
   "source": [
    "scaled_predicted_values = model.predict(X_test_scaled, verbose = 0)\n",
    "\n",
    "# Führen Sie die Rücktransformation der skalierten Werte durch\n",
    "original_predicted_values = scaler_target.inverse_transform(scaled_predicted_values)\n",
    "original_actual_values = scaler_target.inverse_transform(y_test_scaled)  # y_test sind die skalierten tatsächlichen Werte\n",
    "print(f' Bsp. Predicted: {original_predicted_values[1000]} Actual: {original_actual_values[1000]} ')\n",
    "\n",
    "def calculate_mae(list1, list2):\n",
    "    # Stelle sicher, dass beide Listen die gleiche Länge haben\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Listen müssen die gleiche Länge haben\")\n",
    "    \n",
    "    # Berechne die absolute Differenz zwischen den Elementen der Listen\n",
    "    differences = [abs(x - y) for x, y in zip(list1, list2)]\n",
    "    \n",
    "    # Berechne den Durchschnitt der absoluten Differenzen\n",
    "    mae = sum(differences) / len(differences)\n",
    "    \n",
    "    return mae\n",
    "\n",
    "# Beispiel\n",
    "list1 = original_predicted_values\n",
    "list2 = original_actual_values\n",
    "\n",
    "mae = calculate_mae(list1, list2)\n",
    "print(f\"Durchschnittliche Abweichung (MAE): {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Werte die kleiner sind: 1327\n"
     ]
    },
    {
     "data": {
      "text/plain": "             Echt  Vorhergesagt  X-Koordinate  Y-Koordinate  Differenz\n4472   559.645264        589.58         0.580        1.0000 -29.934736\n17844  560.029968        589.93         0.568        1.0000 -29.900032\n14372  561.057007        590.84         0.536        1.0000 -29.782993\n16327  559.405151        589.10         0.596        1.0000 -29.694849\n7952   561.570374        591.26         0.520        1.0000 -29.689626\n...           ...           ...           ...           ...        ...\n14839  627.143005        599.38         0.956        0.9725  27.763005\n15061  615.466980        587.18         0.956        0.9775  28.286980\n11939  615.796448        586.88         0.964        0.9775  28.916448\n13809  622.623901        593.15         0.988        0.9750  29.473901\n20012  622.953430        588.92         0.996        0.9750  34.033430\n\n[20131 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Echt</th>\n      <th>Vorhergesagt</th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Differenz</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4472</th>\n      <td>559.645264</td>\n      <td>589.58</td>\n      <td>0.580</td>\n      <td>1.0000</td>\n      <td>-29.934736</td>\n    </tr>\n    <tr>\n      <th>17844</th>\n      <td>560.029968</td>\n      <td>589.93</td>\n      <td>0.568</td>\n      <td>1.0000</td>\n      <td>-29.900032</td>\n    </tr>\n    <tr>\n      <th>14372</th>\n      <td>561.057007</td>\n      <td>590.84</td>\n      <td>0.536</td>\n      <td>1.0000</td>\n      <td>-29.782993</td>\n    </tr>\n    <tr>\n      <th>16327</th>\n      <td>559.405151</td>\n      <td>589.10</td>\n      <td>0.596</td>\n      <td>1.0000</td>\n      <td>-29.694849</td>\n    </tr>\n    <tr>\n      <th>7952</th>\n      <td>561.570374</td>\n      <td>591.26</td>\n      <td>0.520</td>\n      <td>1.0000</td>\n      <td>-29.689626</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14839</th>\n      <td>627.143005</td>\n      <td>599.38</td>\n      <td>0.956</td>\n      <td>0.9725</td>\n      <td>27.763005</td>\n    </tr>\n    <tr>\n      <th>15061</th>\n      <td>615.466980</td>\n      <td>587.18</td>\n      <td>0.956</td>\n      <td>0.9775</td>\n      <td>28.286980</td>\n    </tr>\n    <tr>\n      <th>11939</th>\n      <td>615.796448</td>\n      <td>586.88</td>\n      <td>0.964</td>\n      <td>0.9775</td>\n      <td>28.916448</td>\n    </tr>\n    <tr>\n      <th>13809</th>\n      <td>622.623901</td>\n      <td>593.15</td>\n      <td>0.988</td>\n      <td>0.9750</td>\n      <td>29.473901</td>\n    </tr>\n    <tr>\n      <th>20012</th>\n      <td>622.953430</td>\n      <td>588.92</td>\n      <td>0.996</td>\n      <td>0.9750</td>\n      <td>34.033430</td>\n    </tr>\n  </tbody>\n</table>\n<p>20131 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame({'Echt': [val[0] for val in list1], 'Vorhergesagt': [val[0] for val in list2]})\n",
    "df_result['X-Koordinate'] = X_test_scaled[:, 0]\n",
    "df_result['Y-Koordinate'] = X_test_scaled[:, 1]\n",
    "\n",
    "df_result['Differenz'] = df_result['Echt'] - df_result['Vorhergesagt']\n",
    "df_result['Differenz'].sort_values()\n",
    "sorted_df = df_result.sort_values(by= 'Differenz')\n",
    "Anzahl_Punkte = (sorted_df['Differenz'] > 5).sum()\n",
    "print(\"Anzahl der Werte die kleiner sind:\", Anzahl_Punkte)\n",
    " \n",
    "sorted_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T10:38:23.694427500Z",
     "start_time": "2024-02-22T10:38:23.613245Z"
    }
   },
   "id": "42bde60d3b4f2007"
  },
  {
   "cell_type": "markdown",
   "id": "553df6fa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mae = history.history['loss']\n",
    "val_mae = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(mae) + 1)\n",
    "# MAE Diagramm\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, mae, 'r', label='Training MAE')\n",
    "plt.plot(epochs, val_mae, 'b', label='Validation MAE')\n",
    "plt.title('Training and Validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T12:01:17.919812200Z",
     "start_time": "2024-02-22T12:01:17.781771Z"
    }
   },
   "id": "3688dd7102e95baf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# GridSearch\n",
    "Grid Search bietet die Vorteile der anpassbaren Rechenzeit sowie die Möglichkeit des EInsatzes von Verteilungen. So können theoretisch Hyperparamterkonfuigurationen gefunden wende, welche durch GridSearch nicht auffindbar wären. ZUdem ist das Ziel der Hyperparamteroptimierung eine Einstellung zu finden, welche auf Trainings und Testset gut angepasst ist. Die EInstellung muss nicht die bestmöglichste Einstellung sein, sondern eine Einstellung die das gewähltre Problem gut wiederspiegelt. \n",
    "Bayesian Optimierung"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c177960cc729052"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3f17e2cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T15:59:48.819124300Z",
     "start_time": "2024-02-22T15:59:38.690236800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 36 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n36 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 890, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 760, in fit\n    self._fit(\n  File \"C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 928, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 524, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py\", line 275, in __init__\n    self._size = int(math.ceil(num_samples / batch_size))\n                               ~~~~~~~~~~~~^~~~~~~~~~~~\nTypeError: unsupported operand type(s) for /: 'int' and 'list'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[43], line 43\u001B[0m\n\u001B[0;32m     41\u001B[0m grid_search \u001B[38;5;241m=\u001B[39m GridSearchCV(estimator\u001B[38;5;241m=\u001B[39mmodel, param_grid\u001B[38;5;241m=\u001B[39mparam_grid, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m     42\u001B[0m \u001B[38;5;66;03m# Hinweis: Stellen Sie sicher, dass Ihre Daten (X_train_scaled, y_train_scaled) korrekt definiert sind\u001B[39;00m\n\u001B[1;32m---> 43\u001B[0m grid_result \u001B[38;5;241m=\u001B[39m \u001B[43mgrid_search\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_scaled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train_scaled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     44\u001B[0m \u001B[38;5;66;03m# Beste Parameter und Score ausgeben\u001B[39;00m\n\u001B[0;32m     45\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBeste Parameter:\u001B[39m\u001B[38;5;124m\"\u001B[39m, grid_search\u001B[38;5;241m.\u001B[39mbest_params_)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\base.py:1351\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1344\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1346\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1347\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1348\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1349\u001B[0m     )\n\u001B[0;32m   1350\u001B[0m ):\n\u001B[1;32m-> 1351\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, **params)\u001B[0m\n\u001B[0;32m    964\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m    965\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m    966\u001B[0m     )\n\u001B[0;32m    968\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m--> 970\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    972\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m    973\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m    974\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1525\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1526\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1527\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:947\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    940\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m!=\u001B[39m n_candidates \u001B[38;5;241m*\u001B[39m n_splits:\n\u001B[0;32m    941\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    942\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcv.split and cv.get_n_splits returned \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    943\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minconsistent results. Expected \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    944\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msplits, got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(n_splits, \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m n_candidates)\n\u001B[0;32m    945\u001B[0m     )\n\u001B[1;32m--> 947\u001B[0m \u001B[43m_warn_or_raise_about_fit_failures\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    949\u001B[0m \u001B[38;5;66;03m# For callable self.scoring, the return type is only know after\u001B[39;00m\n\u001B[0;32m    950\u001B[0m \u001B[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001B[39;00m\n\u001B[0;32m    951\u001B[0m \u001B[38;5;66;03m# can now be inserted with the correct key. The type checking\u001B[39;00m\n\u001B[0;32m    952\u001B[0m \u001B[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001B[39;00m\n\u001B[0;32m    953\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscoring):\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:531\u001B[0m, in \u001B[0;36m_warn_or_raise_about_fit_failures\u001B[1;34m(results, error_score)\u001B[0m\n\u001B[0;32m    524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_failed_fits \u001B[38;5;241m==\u001B[39m num_fits:\n\u001B[0;32m    525\u001B[0m     all_fits_failed_message \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    526\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mAll the \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fits failed.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    527\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIt is very likely that your model is misconfigured.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    528\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou can try to debug the error by setting error_score=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    529\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBelow are more details about the failures:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfit_errors_summary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    530\u001B[0m     )\n\u001B[1;32m--> 531\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(all_fits_failed_message)\n\u001B[0;32m    533\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    534\u001B[0m     some_fits_failed_message \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    535\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mnum_failed_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fits failed out of a total of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    536\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe score on these train-test partitions for these parameters\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    540\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBelow are more details about the failures:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfit_errors_summary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    541\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: \nAll the 36 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n36 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 890, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 760, in fit\n    self._fit(\n  File \"C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 928, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 524, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py\", line 275, in __init__\n    self._size = int(math.ceil(num_samples / batch_size))\n                               ~~~~~~~~~~~~^~~~~~~~~~~~\nTypeError: unsupported operand type(s) for /: 'int' and 'list'\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense ,Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def build_model(learning_rate=0.001, activation='relu', regularization=0.0001, dropout_rate=0.0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(224, activation=activation, input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(regularization))),\n",
    "    model.add(Dropout(dropout_rate)),\n",
    "    model.add(Dense(32, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization))),\n",
    "    model.add(Dropout(dropout_rate)),\n",
    "    model.add(Dense(96, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization))),\n",
    "    model.add(Dropout(dropout_rate)),\n",
    "    model.add(Dense(224, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization))),\n",
    "    model.add(Dropout(dropout_rate)),\n",
    "    model.add(Dense(128, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization))),\n",
    "    model.add(Dropout(dropout_rate)),\n",
    "    model.add(Dense(352, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization))),\n",
    "    model.add(Dropout(dropout_rate)),\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Verwenden Sie eine Funktion, um das Modell zu instanziieren, für scikit-learn Wrapper\n",
    "model = KerasRegressor(model=build_model, verbose=2, epochs=30, dropout_rate = 'dropout_rate', learning_rate = 'learning_rate', regularization = 'regularization')\n",
    "\n",
    "# Anpassung der Parameter im param_grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.001, 0.0001],\n",
    "    'regularization': [0.001, 0.0001],\n",
    "    'dropout_rate': [0.0, 0.2],\n",
    "    \n",
    "}\n",
    "\n",
    "fit_params = {\n",
    "    'batch_size': [50, 100, 200, 500],\n",
    "    'epochs': 30\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=2)\n",
    "# Hinweis: Stellen Sie sicher, dass Ihre Daten (X_train_scaled, y_train_scaled) korrekt definiert sind\n",
    "grid_result = grid_search.fit(X_train_scaled, y_train_scaled, **fit_params)\n",
    "# Beste Parameter und Score ausgeben\n",
    "print(\"Beste Parameter:\", grid_search.best_params_)\n",
    "print(\"Beste Genauigkeit:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter learning_rate for estimator KerasClassifier.\nThis issue can likely be resolved by setting this parameter in the KerasClassifier constructor:\n`KerasClassifier(learning_rate=0.001)`\nCheck the list of available parameters with `estimator.get_params().keys()`",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31m_RemoteTraceback\u001B[0m                          Traceback (most recent call last)",
      "\u001B[1;31m_RemoteTraceback\u001B[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\joblib\\parallel.py\", line 589, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\joblib\\parallel.py\", line 589, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 129, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 878, in _fit_and_score\n    estimator = estimator.set_params(**clone(parameters, safe=False))\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1165, in set_params\n    raise ValueError(\nValueError: Invalid parameter learning_rate for estimator KerasClassifier.\nThis issue can likely be resolved by setting this parameter in the KerasClassifier constructor:\n`KerasClassifier(learning_rate=0.001)`\nCheck the list of available parameters with `estimator.get_params().keys()`\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[48], line 34\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;66;03m# Erstelle und führe die Grid Search aus\u001B[39;00m\n\u001B[0;32m     33\u001B[0m grid \u001B[38;5;241m=\u001B[39m GridSearchCV(estimator\u001B[38;5;241m=\u001B[39mmodel, param_grid\u001B[38;5;241m=\u001B[39mparam_grid, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\n\u001B[1;32m---> 34\u001B[0m grid_result \u001B[38;5;241m=\u001B[39m \u001B[43mgrid\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_scaled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train_scaled\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;66;03m# Ergebnisse\u001B[39;00m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest: \u001B[39m\u001B[38;5;132;01m%f\u001B[39;00m\u001B[38;5;124m using \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (grid_result\u001B[38;5;241m.\u001B[39mbest_score_, grid_result\u001B[38;5;241m.\u001B[39mbest_params_))\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\base.py:1351\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1344\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1346\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1347\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1348\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1349\u001B[0m     )\n\u001B[0;32m   1350\u001B[0m ):\n\u001B[1;32m-> 1351\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, **params)\u001B[0m\n\u001B[0;32m    964\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m    965\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m    966\u001B[0m     )\n\u001B[0;32m    968\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m--> 970\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    972\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m    973\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m    974\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1525\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1526\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1527\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    908\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    909\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m    910\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    911\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    912\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[0;32m    913\u001B[0m         )\n\u001B[0;32m    914\u001B[0m     )\n\u001B[1;32m--> 916\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    917\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    918\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    919\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    920\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    921\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    922\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    923\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    924\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    925\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    926\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    927\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    928\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    929\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    930\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrouted_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplitter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    931\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    932\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    934\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    935\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    936\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    937\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    938\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    939\u001B[0m     )\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     62\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     63\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     64\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     66\u001B[0m )\n\u001B[1;32m---> 67\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\joblib\\parallel.py:1952\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1946\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[0;32m   1947\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[0;32m   1948\u001B[0m \u001B[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001B[39;00m\n\u001B[0;32m   1949\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[0;32m   1950\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 1952\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(output)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\joblib\\parallel.py:1595\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[1;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[0;32m   1592\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[0;32m   1594\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[1;32m-> 1595\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[0;32m   1597\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[0;32m   1598\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[0;32m   1599\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[0;32m   1600\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[0;32m   1601\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\joblib\\parallel.py:1699\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1692\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wait_retrieval():\n\u001B[0;32m   1693\u001B[0m \n\u001B[0;32m   1694\u001B[0m     \u001B[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001B[39;00m\n\u001B[0;32m   1695\u001B[0m     \u001B[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001B[39;00m\n\u001B[0;32m   1696\u001B[0m     \u001B[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001B[39;00m\n\u001B[0;32m   1697\u001B[0m     \u001B[38;5;66;03m# worker traceback.\u001B[39;00m\n\u001B[0;32m   1698\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_aborting:\n\u001B[1;32m-> 1699\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_error_fast\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1700\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m   1702\u001B[0m     \u001B[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001B[39;00m\n\u001B[0;32m   1703\u001B[0m     \u001B[38;5;66;03m# async callbacks to progress.\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\joblib\\parallel.py:1734\u001B[0m, in \u001B[0;36mParallel._raise_error_fast\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1730\u001B[0m \u001B[38;5;66;03m# If this error job exists, immediatly raise the error by\u001B[39;00m\n\u001B[0;32m   1731\u001B[0m \u001B[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001B[39;00m\n\u001B[0;32m   1732\u001B[0m \u001B[38;5;66;03m# called directly or if the generator is gc'ed.\u001B[39;00m\n\u001B[0;32m   1733\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m error_job \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1734\u001B[0m     \u001B[43merror_job\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_result\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\joblib\\parallel.py:736\u001B[0m, in \u001B[0;36mBatchCompletionCallBack.get_result\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    730\u001B[0m backend \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparallel\u001B[38;5;241m.\u001B[39m_backend\n\u001B[0;32m    732\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m backend\u001B[38;5;241m.\u001B[39msupports_retrieve_callback:\n\u001B[0;32m    733\u001B[0m     \u001B[38;5;66;03m# We assume that the result has already been retrieved by the\u001B[39;00m\n\u001B[0;32m    734\u001B[0m     \u001B[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001B[39;00m\n\u001B[0;32m    735\u001B[0m     \u001B[38;5;66;03m# be returned.\u001B[39;00m\n\u001B[1;32m--> 736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_return_or_raise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    738\u001B[0m \u001B[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001B[39;00m\n\u001B[0;32m    739\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\joblib\\parallel.py:754\u001B[0m, in \u001B[0;36mBatchCompletionCallBack._return_or_raise\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    752\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    753\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m==\u001B[39m TASK_ERROR:\n\u001B[1;32m--> 754\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result\n\u001B[0;32m    755\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result\n\u001B[0;32m    756\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "\u001B[1;31mValueError\u001B[0m: Invalid parameter learning_rate for estimator KerasClassifier.\nThis issue can likely be resolved by setting this parameter in the KerasClassifier constructor:\n`KerasClassifier(learning_rate=0.001)`\nCheck the list of available parameters with `estimator.get_params().keys()`"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Funktion, um das Keras-Modell zu erstellen\n",
    "def create_model(learning_rate=0.001,  regularization_rate=0.0001):\n",
    "    model = Sequential([\n",
    "        Dense(64, input_shape=(2,), activation='relu', \n",
    "              kernel_regularizer=tf.keras.regularizers.l2(regularization_rate)),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='MSE', metrics=['MAE'])\n",
    "    return model\n",
    "\n",
    "# Wrapper um das Modell für Grid Search\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0, lr=None, optimizer=None)\n",
    "\n",
    "# Definiere den Parameterraum für die Grid Search\n",
    "param_grid = {\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [10, 20],\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    #'dropout_rate': [0.0, 0.2, 0.5],\n",
    "    'regularization_rate': [0.01, 0.001, 0.0001]\n",
    "}\n",
    "\n",
    "# Erstelle und führe die Grid Search aus\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Ergebnisse\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "for params, mean_score, scores in grid_result.cv_results_['params'], grid_result.cv_results_['mean_test_score'], grid_result.cv_results_['std_test_score']:\n",
    "    print(\"%f (%f) with: %r\" % (mean_score, scores, params))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T16:08:53.249161500Z",
     "start_time": "2024-02-22T16:08:43.822287Z"
    }
   },
   "id": "6e3fbba3423056ad"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 46s]\n",
      "val_mae: 0.005825335392728448\n",
      "\n",
      "Best val_mae So Far: 0.0035446375841274858\n",
      "Total elapsed time: 00h 15m 04s\n",
      "Die besten Hyperparameter sind: {'units_input': 32, 'units_hidden1': 96, 'units_hidden2': 32, 'learning_rate': 0.001}\n"
     ]
    }
   ],
   "source": [
    "class RegressionHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(\n",
    "            units=hp.Int('units_input', min_value=16, max_value=124, step=16),\n",
    "            activation='relu',\n",
    "            input_shape=self.input_shape,\n",
    "            kernel_initializer='he_uniform',\n",
    "            kernel_regularizer=l2(0.0001)\n",
    "        ))\n",
    "        model.add(Dense(\n",
    "            units=hp.Int('units_hidden1', min_value=16, max_value=124, step=16),\n",
    "            activation='relu',\n",
    "            kernel_initializer='he_uniform',\n",
    "            kernel_regularizer=l2(0.0001)\n",
    "        ))\n",
    "        model.add(Dense(\n",
    "            units=hp.Int('units_hidden2', min_value=16, max_value=124, step=16),\n",
    "            activation='relu',\n",
    "            kernel_initializer='he_uniform',\n",
    "            kernel_regularizer=l2(0.0001) \n",
    "        ))\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "            loss='mean_squared_error',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "# Setzen Sie die richtige Eingabeform hier, z.B. (2,)\n",
    "hypermodel = RegressionHyperModel(input_shape=(2,))\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    hypermodel,\n",
    "    objective='val_mae',\n",
    "    max_trials=20,\n",
    "    executions_per_trial=2,\n",
    "    directory='my_dir',\n",
    "    project_name='keras_tuner_demo4'\n",
    ")\n",
    "\n",
    "# Beachten Sie, dass X_train_scaled, y_train_scaled durch Ihre tatsächlichen Trainingsdaten ersetzt werden müssen.\n",
    "tuner.search(X_train_scaled, y_train_scaled, epochs=10, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "\n",
    "# Die besten Hyperparameter bekommen\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Die besten Hyperparameter sind: {best_hps.values}\")\n",
    "\n",
    "# Das beste Modell mit den optimalen Hyperparametern trainieren\n",
    "#model = tuner.hypermodel.build(best_hps)\n",
    "# Hier müssen Sie die tatsächlichen Trainings- und Validierungsdaten einfügen\n",
    "#history = model.fit(X_train_scaled, y_train_scaled, epochs=100, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e4c339eeed37479"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6751193b14f574a1"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... | neuron... | neuron... | neuron... | neuron... | neuron... |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Epoch 17: early stopping\n",
      "| \u001B[0m1        \u001B[0m | \u001B[0m-0.000638\u001B[0m | \u001B[0m0.004229 \u001B[0m | \u001B[0m148.5    \u001B[0m | \u001B[0m16.02    \u001B[0m | \u001B[0m71.63    \u001B[0m | \u001B[0m43.0     \u001B[0m | \u001B[0m32.99    \u001B[0m |\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Epoch 19: early stopping\n",
      "| \u001B[95m2        \u001B[0m | \u001B[95m-0.000562\u001B[0m | \u001B[95m0.001944 \u001B[0m | \u001B[95m79.58    \u001B[0m | \u001B[95m89.01    \u001B[0m | \u001B[95m115.1    \u001B[0m | \u001B[95m93.13    \u001B[0m | \u001B[95m142.1    \u001B[0m |\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Epoch 18: early stopping\n",
      "| \u001B[0m3        \u001B[0m | \u001B[0m-0.000766\u001B[0m | \u001B[0m0.005658 \u001B[0m | \u001B[0m85.07    \u001B[0m | \u001B[0m104.1    \u001B[0m | \u001B[0m119.3    \u001B[0m | \u001B[0m41.35    \u001B[0m | \u001B[0m134.6    \u001B[0m |\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Epoch 16: early stopping\n",
      "| \u001B[0m4        \u001B[0m | \u001B[0m-0.000834\u001B[0m | \u001B[0m0.008647 \u001B[0m | \u001B[0m85.11    \u001B[0m | \u001B[0m86.15    \u001B[0m | \u001B[0m110.5    \u001B[0m | \u001B[0m103.4    \u001B[0m | \u001B[0m144.2    \u001B[0m |\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Epoch 20: early stopping\n",
      "| \u001B[0m5        \u001B[0m | \u001B[0m-0.000733\u001B[0m | \u001B[0m0.008982 \u001B[0m | \u001B[0m113.5    \u001B[0m | \u001B[0m26.86    \u001B[0m | \u001B[0m170.1    \u001B[0m | \u001B[0m57.75    \u001B[0m | \u001B[0m50.06    \u001B[0m |\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Epoch 12: early stopping\n",
      "| \u001B[0m6        \u001B[0m | \u001B[0m-0.000743\u001B[0m | \u001B[0m0.004154 \u001B[0m | \u001B[0m38.5     \u001B[0m | \u001B[0m150.3    \u001B[0m | \u001B[0m175.7    \u001B[0m | \u001B[0m138.0    \u001B[0m | \u001B[0m88.68    \u001B[0m |\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Epoch 21: early stopping\n",
      "| \u001B[0m7        \u001B[0m | \u001B[0m-0.000796\u001B[0m | \u001B[0m0.009176 \u001B[0m | \u001B[0m33.41    \u001B[0m | \u001B[0m197.5    \u001B[0m | \u001B[0m190.2    \u001B[0m | \u001B[0m18.45    \u001B[0m | \u001B[0m99.55    \u001B[0m |\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Epoch 17: early stopping\n",
      "| \u001B[0m8        \u001B[0m | \u001B[0m-0.000782\u001B[0m | \u001B[0m0.006971 \u001B[0m | \u001B[0m121.5    \u001B[0m | \u001B[0m76.55    \u001B[0m | \u001B[0m146.6    \u001B[0m | \u001B[0m162.7    \u001B[0m | \u001B[0m21.59    \u001B[0m |\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Epoch 22: early stopping\n",
      "| \u001B[95m9        \u001B[0m | \u001B[95m-0.000546\u001B[0m | \u001B[95m0.002098 \u001B[0m | \u001B[95m70.04    \u001B[0m | \u001B[95m45.3     \u001B[0m | \u001B[95m67.57    \u001B[0m | \u001B[95m165.3    \u001B[0m | \u001B[95m146.0    \u001B[0m |\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Epoch 39: early stopping\n",
      "| \u001B[0m10       \u001B[0m | \u001B[0m-0.000793\u001B[0m | \u001B[0m0.0001457\u001B[0m | \u001B[0m167.1    \u001B[0m | \u001B[0m110.3    \u001B[0m | \u001B[0m114.7    \u001B[0m | \u001B[0m151.9    \u001B[0m | \u001B[0m189.9    \u001B[0m |\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Epoch 25: early stopping\n",
      "| \u001B[0m11       \u001B[0m | \u001B[0m-0.000610\u001B[0m | \u001B[0m0.0004375\u001B[0m | \u001B[0m148.2    \u001B[0m | \u001B[0m174.9    \u001B[0m | \u001B[0m71.28    \u001B[0m | \u001B[0m171.8    \u001B[0m | \u001B[0m93.63    \u001B[0m |\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Epoch 22: early stopping\n",
      "| \u001B[0m12       \u001B[0m | \u001B[0m-0.000757\u001B[0m | \u001B[0m0.008991 \u001B[0m | \u001B[0m31.9     \u001B[0m | \u001B[0m119.0    \u001B[0m | \u001B[0m62.88    \u001B[0m | \u001B[0m155.0    \u001B[0m | \u001B[0m59.75    \u001B[0m |\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Epoch 15: early stopping\n",
      "| \u001B[0m13       \u001B[0m | \u001B[0m-0.000891\u001B[0m | \u001B[0m0.00989  \u001B[0m | \u001B[0m153.3    \u001B[0m | \u001B[0m75.35    \u001B[0m | \u001B[0m84.86    \u001B[0m | \u001B[0m76.01    \u001B[0m | \u001B[0m122.9    \u001B[0m |\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Epoch 17: early stopping\n",
      "| \u001B[0m14       \u001B[0m | \u001B[0m-0.000719\u001B[0m | \u001B[0m0.007607 \u001B[0m | \u001B[0m53.49    \u001B[0m | \u001B[0m58.95    \u001B[0m | \u001B[0m123.7    \u001B[0m | \u001B[0m157.1    \u001B[0m | \u001B[0m193.7    \u001B[0m |\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Epoch 19: early stopping\n",
      "| \u001B[0m15       \u001B[0m | \u001B[0m-0.000742\u001B[0m | \u001B[0m0.008752 \u001B[0m | \u001B[0m198.6    \u001B[0m | \u001B[0m87.49    \u001B[0m | \u001B[0m174.8    \u001B[0m | \u001B[0m161.6    \u001B[0m | \u001B[0m149.4    \u001B[0m |\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Epoch 30: early stopping\n",
      "| \u001B[0m16       \u001B[0m | \u001B[0m-0.000624\u001B[0m | \u001B[0m0.0002723\u001B[0m | \u001B[0m76.96    \u001B[0m | \u001B[0m101.7    \u001B[0m | \u001B[0m68.82    \u001B[0m | \u001B[0m133.2    \u001B[0m | \u001B[0m89.11    \u001B[0m |\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Epoch 24: early stopping\n",
      "| \u001B[0m17       \u001B[0m | \u001B[0m-0.000692\u001B[0m | \u001B[0m0.005645 \u001B[0m | \u001B[0m124.5    \u001B[0m | \u001B[0m149.4    \u001B[0m | \u001B[0m155.6    \u001B[0m | \u001B[0m96.35    \u001B[0m | \u001B[0m137.5    \u001B[0m |\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Epoch 31: early stopping\n",
      "| \u001B[95m18       \u001B[0m | \u001B[95m-0.000504\u001B[0m | \u001B[95m0.0008563\u001B[0m | \u001B[95m139.4    \u001B[0m | \u001B[95m143.1    \u001B[0m | \u001B[95m142.2    \u001B[0m | \u001B[95m67.5     \u001B[0m | \u001B[95m129.6    \u001B[0m |\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Epoch 12: early stopping\n",
      "| \u001B[0m19       \u001B[0m | \u001B[0m-0.000737\u001B[0m | \u001B[0m0.008334 \u001B[0m | \u001B[0m17.35    \u001B[0m | \u001B[0m23.21    \u001B[0m | \u001B[0m164.6    \u001B[0m | \u001B[0m32.63    \u001B[0m | \u001B[0m155.2    \u001B[0m |\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Epoch 19: early stopping\n",
      "| \u001B[0m20       \u001B[0m | \u001B[0m-0.000575\u001B[0m | \u001B[0m0.001016 \u001B[0m | \u001B[0m198.8    \u001B[0m | \u001B[0m101.1    \u001B[0m | \u001B[0m41.64    \u001B[0m | \u001B[0m70.41    \u001B[0m | \u001B[0m37.44    \u001B[0m |\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Epoch 20: early stopping\n",
      "| \u001B[0m21       \u001B[0m | \u001B[0m-0.000635\u001B[0m | \u001B[0m0.001644 \u001B[0m | \u001B[0m28.21    \u001B[0m | \u001B[0m184.1    \u001B[0m | \u001B[0m34.07    \u001B[0m | \u001B[0m73.35    \u001B[0m | \u001B[0m133.9    \u001B[0m |\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Epoch 19: early stopping\n",
      "| \u001B[0m22       \u001B[0m | \u001B[0m-0.000690\u001B[0m | \u001B[0m0.004116 \u001B[0m | \u001B[0m150.9    \u001B[0m | \u001B[0m173.6    \u001B[0m | \u001B[0m198.3    \u001B[0m | \u001B[0m173.2    \u001B[0m | \u001B[0m61.95    \u001B[0m |\n",
      "=================================================================================================\n",
      "{'target': -0.0005042816046625376, 'params': {'learning_rate': 0.0008562808887904138, 'neurons_layer_1': 139.37382512499065, 'neurons_layer_2': 143.13142125355472, 'neurons_layer_3': 142.17467953414652, 'neurons_layer_4': 67.50109625880788, 'neurons_layer_5': 129.5541186323257}}\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "\n",
    "# Angenommene Daten\n",
    "# X_train_scaled, y_train_scaled = # Deine skalierten Trainingsdaten\n",
    "\n",
    "def train_evaluate(neurons_layer_1, neurons_layer_2, neurons_layer_3, neurons_layer_4, neurons_layer_5, learning_rate):\n",
    "    model = Sequential([\n",
    "        Dense(int(neurons_layer_1), activation='relu', input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "        Dense(int(neurons_layer_2), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "        Dense(int(neurons_layer_3), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "        Dense(int(neurons_layer_4), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "        Dense(int(neurons_layer_5), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "        \n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='loss', patience=5, verbose=1, mode='min', restore_best_weights=True, min_delta=0.0001)\n",
    "\n",
    "    history = model.fit(X_train_scaled, y_train_scaled, batch_size=32, epochs=100, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "    # Hier wählen wir den negativen Mean Squared Error, da Bayesian Optimization maximiert\n",
    "    mse = np.min(history.history['val_loss'])\n",
    "    return -mse\n",
    "\n",
    "# Definieren des Bereichs der Hyperparameter\n",
    "pbounds = {\n",
    "    'neurons_layer_1': (16, 200),\n",
    "    'neurons_layer_2': (16, 200),\n",
    "    'neurons_layer_3': (16, 200),\n",
    "    'neurons_layer_4': (16, 200),\n",
    "    'neurons_layer_5': (16, 200),\n",
    "    'learning_rate': (0.0001, 0.01),\n",
    "}\n",
    "\n",
    "# Initialisieren des BayesianOptimization-Objekts\n",
    "optimizer = BayesianOptimization(\n",
    "    f=train_evaluate,\n",
    "    pbounds=pbounds,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "# Starten der Optimierung\n",
    "optimizer.maximize(init_points=2, n_iter=20)\n",
    "\n",
    "print(optimizer.max)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T15:22:26.910485500Z",
     "start_time": "2024-02-21T15:05:40.545629700Z"
    }
   },
   "id": "a5b6232547cdae67"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 00m 48s]\n",
      "val_loss: 1.355679523840081e-05\n",
      "\n",
      "Best val_loss So Far: 1.3108049188303994e-06\n",
      "Total elapsed time: 01h 41m 02s\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 224)               672       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                7200      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 96)                3168      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 224)               21728     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               28800     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 352)               45408     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 353       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 107329 (419.25 KB)\n",
      "Trainable params: 107329 (419.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "{'input_units': 224, 'n_layers': 5, 'units_0': 32, 'units_1': 96, 'units_2': 224, 'units_3': 128, 'units_4': 352, 'units_5': 448, 'units_6': 64, 'units_7': 448, 'units_8': 480, 'units_9': 480}\n"
     ]
    }
   ],
   "source": [
    "# Definieren der Funktion, die das Modell erstellt\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hp.Int('input_units', min_value=32, max_value=512, step=32), input_shape=(2,), activation='relu'))\n",
    "    # Hinzufügen von Schichten basierend auf dem Suchraum\n",
    "    for i in range(hp.Int('n_layers', 1, 10)):\n",
    "        model.add(Dense(hp.Int(f'units_{i}', min_value=32, max_value=512, step=32), activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Erstellen des RandomSearch Objekts\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=100,  # Anzahl der zu testenden Modellkonfigurationen\n",
    "    executions_per_trial=1,  # Anzahl der Male, die jede Modellkonfiguration trainiert wird\n",
    "    directory='random_search',  # Verzeichnis zur Speicherung der Suchlogs\n",
    "    project_name='neural_network_optimization'\n",
    ")\n",
    "\n",
    "# Durchführung des Random Search\n",
    "tuner.search(X_train_scaled, y_train_scaled, epochs=20, batch_size=50, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "\n",
    "# Abrufen des besten Modells\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Zusammenfassung des besten Modells\n",
    "best_model.summary()\n",
    "\n",
    "# Sie können auch die besten Hyperparameter direkt abrufen\n",
    "best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "print(best_hyperparameters.values) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bcbb2bbe83bfb6b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c6a6fa208c5d8a01"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
