{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94b0518e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T09:53:21.849458800Z",
     "start_time": "2024-03-15T09:53:21.774228700Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense , Dropout\n",
    "from scikeras.wrappers import KerasRegressor \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4ff61b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T09:53:21.894467Z",
     "start_time": "2024-03-15T09:53:21.775210200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n0             0.0000      -0.00200        500   7000   9000      669.05\n1             0.0000      -0.00199        500   7000   9000      675.83\n2             0.0000      -0.00198        500   7000   9000      682.81\n3             0.0000      -0.00197        500   7000   9000      689.82\n4             0.0000      -0.00196        500   7000   9000      696.80\n...              ...           ...        ...    ...    ...         ...\n100646        0.0025       0.00196        500   7000   9000      578.47\n100647        0.0025       0.00197        500   7000   9000      576.89\n100648        0.0025       0.00198        500   7000   9000      575.32\n100649        0.0025       0.00199        500   7000   9000      573.76\n100650        0.0025       0.00200        500   7000   9000      572.20\n\n[100651 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>669.05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0000</td>\n      <td>-0.00199</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>675.83</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0000</td>\n      <td>-0.00198</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>682.81</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0000</td>\n      <td>-0.00197</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>689.82</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0000</td>\n      <td>-0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>696.80</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>100646</th>\n      <td>0.0025</td>\n      <td>0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>578.47</td>\n    </tr>\n    <tr>\n      <th>100647</th>\n      <td>0.0025</td>\n      <td>0.00197</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>576.89</td>\n    </tr>\n    <tr>\n      <th>100648</th>\n      <td>0.0025</td>\n      <td>0.00198</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>575.32</td>\n    </tr>\n    <tr>\n      <th>100649</th>\n      <td>0.0025</td>\n      <td>0.00199</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>573.76</td>\n    </tr>\n    <tr>\n      <th>100650</th>\n      <td>0.0025</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>572.20</td>\n    </tr>\n  </tbody>\n</table>\n<p>100651 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/TPath_300_finish_data.pkl')\n",
    "data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_D1_I7000_F9000/TPath_500_finish_data_D1.pkl')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "966e3c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T09:53:21.994286Z",
     "start_time": "2024-03-15T09:53:21.785370700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "count    100651.000000\nmean       1144.030064\nstd         264.135723\nmin         572.200000\n25%         937.330000\n50%        1201.100000\n75%        1368.700000\nmax        1520.000000\nName: Temperatur, dtype: float64"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.drop(data.columns[2:5], axis = 1)\n",
    "df['Temperatur'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8783d1d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T09:53:21.994286Z",
     "start_time": "2024-03-15T09:53:21.794447100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       X-Koordinate  Y-Koordinate  Temperatur\n",
      "83145       0.00207      -0.00062      1282.2\n",
      "66701       0.00166      -0.00065      1347.6\n",
      "91325       0.00227       0.00098      1094.6\n",
      "46593       0.00116      -0.00123      1175.7\n",
      "49518       0.00123      -0.00005      1459.2\n",
      "...             ...           ...         ...\n",
      "6265        0.00015       0.00050      1439.1\n",
      "54886       0.00136       0.00150       876.7\n",
      "76820       0.00191       0.00029      1335.8\n",
      "860         0.00002      -0.00142      1071.2\n",
      "15795       0.00039      -0.00044      1488.1\n",
      "\n",
      "[100651 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate  Temperatur\n0            0.00207      -0.00062      1282.2\n1            0.00166      -0.00065      1347.6\n2            0.00227       0.00098      1094.6\n3            0.00116      -0.00123      1175.7\n4            0.00123      -0.00005      1459.2\n...              ...           ...         ...\n100646       0.00015       0.00050      1439.1\n100647       0.00136       0.00150       876.7\n100648       0.00191       0.00029      1335.8\n100649       0.00002      -0.00142      1071.2\n100650       0.00039      -0.00044      1488.1\n\n[100651 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00207</td>\n      <td>-0.00062</td>\n      <td>1282.2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00166</td>\n      <td>-0.00065</td>\n      <td>1347.6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00227</td>\n      <td>0.00098</td>\n      <td>1094.6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00116</td>\n      <td>-0.00123</td>\n      <td>1175.7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00123</td>\n      <td>-0.00005</td>\n      <td>1459.2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>100646</th>\n      <td>0.00015</td>\n      <td>0.00050</td>\n      <td>1439.1</td>\n    </tr>\n    <tr>\n      <th>100647</th>\n      <td>0.00136</td>\n      <td>0.00150</td>\n      <td>876.7</td>\n    </tr>\n    <tr>\n      <th>100648</th>\n      <td>0.00191</td>\n      <td>0.00029</td>\n      <td>1335.8</td>\n    </tr>\n    <tr>\n      <th>100649</th>\n      <td>0.00002</td>\n      <td>-0.00142</td>\n      <td>1071.2</td>\n    </tr>\n    <tr>\n      <th>100650</th>\n      <td>0.00039</td>\n      <td>-0.00044</td>\n      <td>1488.1</td>\n    </tr>\n  </tbody>\n</table>\n<p>100651 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.sample(frac=1, random_state=42)  # Hier wird 42 als Random State verwendet, um die Ergebnisse reproduzierbar zu machen\n",
    "\n",
    "print(df1)\n",
    "df_reset = df1.reset_index(drop=True)\n",
    "df_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a4e72a16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T09:53:22.014232800Z",
     "start_time": "2024-03-15T09:53:21.808006500Z"
    }
   },
   "outputs": [],
   "source": [
    "label = df_reset[\"Temperatur\"]\n",
    "# Korrektur: Verwenden Sie den Spaltennamen direkt, ohne Indexierung der columns-Eigenschaft\n",
    "df1 = df_reset.drop(\"Temperatur\", axis=1)\n",
    "X = df1\n",
    "y = label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7fa289a50d87423"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e694a236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T09:53:22.014232800Z",
     "start_time": "2024-03-15T09:53:21.814231300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate\ncount  100651.000000  1.006510e+05\nmean        0.001250  1.103042e-20\nstd         0.000725  1.157589e-03\nmin         0.000000 -2.000000e-03\n25%         0.000620 -1.000000e-03\n50%         0.001250  4.529900e-18\n75%         0.001880  1.000000e-03\nmax         0.002500  2.000000e-03",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>100651.000000</td>\n      <td>1.006510e+05</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.001250</td>\n      <td>1.103042e-20</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.000725</td>\n      <td>1.157589e-03</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-2.000000e-03</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000620</td>\n      <td>-1.000000e-03</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.001250</td>\n      <td>4.529900e-18</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.001880</td>\n      <td>1.000000e-03</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.002500</td>\n      <td>2.000000e-03</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f3303b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T09:53:22.014232800Z",
     "start_time": "2024-03-15T09:53:21.827487900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "count    100651.000000\nmean       1144.030064\nstd         264.135723\nmin         572.200000\n25%         937.330000\n50%        1201.100000\n75%        1368.700000\nmax        1520.000000\nName: Temperatur, dtype: float64"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e3ad8da0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T09:53:22.014232800Z",
     "start_time": "2024-03-15T09:53:21.835422100Z"
    }
   },
   "outputs": [],
   "source": [
    " # train_df enthält 80% der Daten, test_df enthält 20% der Daten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9c705edb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T09:53:22.034121300Z",
     "start_time": "2024-03-15T09:53:21.844452800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialisiere einen MinMaxScaler für die Features\n",
    "scaler_features = MinMaxScaler()\n",
    "scaler_features2 = MinMaxScaler()\n",
    "# Skaliere X_train und X_test\n",
    "X_train_scaled = scaler_features.fit_transform(X_train)\n",
    "X_test_scaled = scaler_features.transform(X_test)  # Nutze unterschiedliche Skalierungsparameter\n",
    "\n",
    "# Initialisiere einen SEPARATEN MinMaxScaler für das Ziel, wenn nötig\n",
    "scaler_target = MinMaxScaler()\n",
    "\n",
    "\n",
    "# Skaliere y_train und y_test. Beachte, dass y_train.reshape(-1, 1) verwendet wird, da MinMaxScaler \n",
    "# erwartet, dass die Eingaben als 2D-Arrays kommen, und Ziele normalerweise als 1D-Arrays vorliegen.\n",
    "y_train_scaled = scaler_target.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test_scaled = scaler_target.transform(y_test.values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bbefe631e495b483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T09:53:22.034121300Z",
     "start_time": "2024-03-15T09:53:21.852445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.416 , 0.5725],\n       [0.812 , 0.7325],\n       [0.628 , 0.5075],\n       ...,\n       [0.604 , 0.3875],\n       [0.748 , 0.65  ],\n       [0.028 , 0.6225]])"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "645/645 [==============================] - 4s 4ms/step - loss: 0.3200 - mae: 0.0764 - val_loss: 0.2368 - val_mae: 0.0107\n",
      "Epoch 2/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.2049 - mae: 0.0138 - val_loss: 0.1802 - val_mae: 0.0085\n",
      "Epoch 3/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.1663 - mae: 0.0118 - val_loss: 0.1550 - val_mae: 0.0150\n",
      "Epoch 4/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.1474 - mae: 0.0117 - val_loss: 0.1438 - val_mae: 0.0436\n",
      "Epoch 5/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.1350 - mae: 0.0119 - val_loss: 0.1294 - val_mae: 0.0049\n",
      "Epoch 6/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.1248 - mae: 0.0088 - val_loss: 0.1201 - val_mae: 0.0074\n",
      "Epoch 7/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.1162 - mae: 0.0116 - val_loss: 0.1118 - val_mae: 0.0043\n",
      "Epoch 8/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.1082 - mae: 0.0090 - val_loss: 0.1043 - val_mae: 0.0062\n",
      "Epoch 9/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.1008 - mae: 0.0086 - val_loss: 0.0997 - val_mae: 0.0387\n",
      "Epoch 10/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0941 - mae: 0.0101 - val_loss: 0.0907 - val_mae: 0.0045\n",
      "Epoch 11/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0877 - mae: 0.0084 - val_loss: 0.0849 - val_mae: 0.0140\n",
      "Epoch 12/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0819 - mae: 0.0081 - val_loss: 0.0790 - val_mae: 0.0047\n",
      "Epoch 13/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0764 - mae: 0.0085 - val_loss: 0.0754 - val_mae: 0.0312\n",
      "Epoch 14/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0714 - mae: 0.0073 - val_loss: 0.0690 - val_mae: 0.0046\n",
      "Epoch 15/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0668 - mae: 0.0082 - val_loss: 0.0646 - val_mae: 0.0091\n",
      "Epoch 16/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0625 - mae: 0.0059 - val_loss: 0.0606 - val_mae: 0.0141\n",
      "Epoch 17/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0584 - mae: 0.0075 - val_loss: 0.0565 - val_mae: 0.0133\n",
      "Epoch 18/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0544 - mae: 0.0057 - val_loss: 0.0525 - val_mae: 0.0083\n",
      "Epoch 19/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0508 - mae: 0.0066 - val_loss: 0.0491 - val_mae: 0.0053\n",
      "Epoch 20/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0475 - mae: 0.0065 - val_loss: 0.0458 - val_mae: 0.0035\n",
      "Epoch 21/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0443 - mae: 0.0052 - val_loss: 0.0427 - val_mae: 0.0037\n",
      "Epoch 22/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0411 - mae: 0.0059 - val_loss: 0.0396 - val_mae: 0.0076\n",
      "Epoch 23/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0382 - mae: 0.0058 - val_loss: 0.0368 - val_mae: 0.0049\n",
      "Epoch 24/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0355 - mae: 0.0061 - val_loss: 0.0342 - val_mae: 0.0042\n",
      "Epoch 25/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0330 - mae: 0.0059 - val_loss: 0.0318 - val_mae: 0.0044\n",
      "Epoch 26/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0306 - mae: 0.0050 - val_loss: 0.0295 - val_mae: 0.0064\n",
      "Epoch 27/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0285 - mae: 0.0058 - val_loss: 0.0276 - val_mae: 0.0107\n",
      "Epoch 28/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0265 - mae: 0.0054 - val_loss: 0.0256 - val_mae: 0.0039\n",
      "Epoch 29/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0248 - mae: 0.0057 - val_loss: 0.0240 - val_mae: 0.0042\n",
      "Epoch 30/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0232 - mae: 0.0047 - val_loss: 0.0225 - val_mae: 0.0038\n",
      "Epoch 31/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0217 - mae: 0.0057 - val_loss: 0.0211 - val_mae: 0.0071\n",
      "Epoch 32/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0203 - mae: 0.0048 - val_loss: 0.0196 - val_mae: 0.0046\n",
      "Epoch 33/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0190 - mae: 0.0052 - val_loss: 0.0187 - val_mae: 0.0152\n",
      "Epoch 34/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0178 - mae: 0.0050 - val_loss: 0.0172 - val_mae: 0.0049\n",
      "Epoch 35/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0166 - mae: 0.0052 - val_loss: 0.0160 - val_mae: 0.0031\n",
      "Epoch 36/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0155 - mae: 0.0051 - val_loss: 0.0150 - val_mae: 0.0045\n",
      "Epoch 37/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0145 - mae: 0.0049 - val_loss: 0.0140 - val_mae: 0.0042\n",
      "Epoch 38/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0136 - mae: 0.0047 - val_loss: 0.0131 - val_mae: 0.0042\n",
      "Epoch 39/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0127 - mae: 0.0048 - val_loss: 0.0122 - val_mae: 0.0032\n",
      "Epoch 40/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0118 - mae: 0.0045 - val_loss: 0.0114 - val_mae: 0.0039\n",
      "Epoch 41/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0110 - mae: 0.0047 - val_loss: 0.0107 - val_mae: 0.0054\n",
      "Epoch 42/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0103 - mae: 0.0046 - val_loss: 0.0100 - val_mae: 0.0077\n",
      "Epoch 43/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0097 - mae: 0.0048 - val_loss: 0.0094 - val_mae: 0.0046\n",
      "Epoch 44/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0091 - mae: 0.0041 - val_loss: 0.0088 - val_mae: 0.0081\n",
      "Epoch 45/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0085 - mae: 0.0046 - val_loss: 0.0082 - val_mae: 0.0035\n",
      "Epoch 46/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0079 - mae: 0.0041 - val_loss: 0.0078 - val_mae: 0.0098\n",
      "Epoch 47/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0074 - mae: 0.0044 - val_loss: 0.0072 - val_mae: 0.0043\n",
      "Epoch 48/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0070 - mae: 0.0039 - val_loss: 0.0068 - val_mae: 0.0062\n",
      "Epoch 49/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0065 - mae: 0.0040 - val_loss: 0.0063 - val_mae: 0.0055\n",
      "Epoch 50/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0061 - mae: 0.0042 - val_loss: 0.0060 - val_mae: 0.0060\n",
      "Epoch 51/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0058 - mae: 0.0042 - val_loss: 0.0056 - val_mae: 0.0043\n",
      "Epoch 52/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0054 - mae: 0.0043 - val_loss: 0.0053 - val_mae: 0.0057\n",
      "Epoch 53/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0051 - mae: 0.0040 - val_loss: 0.0050 - val_mae: 0.0034\n",
      "Epoch 54/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0048 - mae: 0.0043 - val_loss: 0.0047 - val_mae: 0.0035\n",
      "Epoch 55/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0046 - mae: 0.0042 - val_loss: 0.0044 - val_mae: 0.0026\n",
      "Epoch 56/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0043 - mae: 0.0039 - val_loss: 0.0042 - val_mae: 0.0029\n",
      "Epoch 57/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0041 - mae: 0.0042 - val_loss: 0.0040 - val_mae: 0.0042\n",
      "Epoch 58/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0039 - mae: 0.0040 - val_loss: 0.0038 - val_mae: 0.0030\n",
      "Epoch 59/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0038 - mae: 0.0038 - val_loss: 0.0037 - val_mae: 0.0030\n",
      "Epoch 60/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0036 - mae: 0.0041 - val_loss: 0.0035 - val_mae: 0.0047\n",
      "Epoch 61/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0035 - mae: 0.0042 - val_loss: 0.0035 - val_mae: 0.0091\n",
      "Epoch 62/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0033 - mae: 0.0040 - val_loss: 0.0034 - val_mae: 0.0098\n",
      "Epoch 63/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0032 - mae: 0.0043 - val_loss: 0.0032 - val_mae: 0.0063\n",
      "Epoch 64/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0031 - mae: 0.0042 - val_loss: 0.0030 - val_mae: 0.0040\n",
      "Epoch 65/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0030 - mae: 0.0040 - val_loss: 0.0030 - val_mae: 0.0060\n",
      "Epoch 66/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0029 - mae: 0.0043 - val_loss: 0.0028 - val_mae: 0.0033\n",
      "Epoch 67/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0028 - mae: 0.0041 - val_loss: 0.0027 - val_mae: 0.0039\n",
      "Epoch 68/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0027 - mae: 0.0044 - val_loss: 0.0027 - val_mae: 0.0048\n",
      "Epoch 69/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0026 - mae: 0.0037 - val_loss: 0.0026 - val_mae: 0.0037\n",
      "Epoch 70/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0026 - mae: 0.0042 - val_loss: 0.0026 - val_mae: 0.0071\n",
      "Epoch 71/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0025 - mae: 0.0041 - val_loss: 0.0024 - val_mae: 0.0039\n",
      "Epoch 72/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0024 - mae: 0.0042 - val_loss: 0.0024 - val_mae: 0.0028\n",
      "Epoch 73/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0024 - mae: 0.0041 - val_loss: 0.0023 - val_mae: 0.0045\n",
      "Epoch 74/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0043 - val_loss: 0.0023 - val_mae: 0.0043\n",
      "Epoch 75/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0043 - val_loss: 0.0022 - val_mae: 0.0048\n",
      "Epoch 76/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0043 - val_loss: 0.0022 - val_mae: 0.0049\n",
      "Epoch 77/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0041 - val_loss: 0.0021 - val_mae: 0.0030\n",
      "Epoch 78/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0021 - mae: 0.0041 - val_loss: 0.0022 - val_mae: 0.0090\n",
      "Epoch 79/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0021 - mae: 0.0043 - val_loss: 0.0021 - val_mae: 0.0067\n",
      "Epoch 80/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0021 - mae: 0.0045 - val_loss: 0.0020 - val_mae: 0.0040\n",
      "Epoch 81/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0020 - mae: 0.0042 - val_loss: 0.0020 - val_mae: 0.0028\n",
      "Epoch 82/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0020 - mae: 0.0043 - val_loss: 0.0021 - val_mae: 0.0097\n",
      "Epoch 83/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0020 - mae: 0.0043 - val_loss: 0.0019 - val_mae: 0.0032\n",
      "Epoch 84/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0019 - mae: 0.0043 - val_loss: 0.0019 - val_mae: 0.0054\n",
      "Epoch 85/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0019 - mae: 0.0042 - val_loss: 0.0019 - val_mae: 0.0042\n",
      "Epoch 86/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0019 - mae: 0.0040 - val_loss: 0.0019 - val_mae: 0.0091\n",
      "Epoch 87/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0019 - mae: 0.0047 - val_loss: 0.0019 - val_mae: 0.0090\n",
      "Epoch 88/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0018 - mae: 0.0040 - val_loss: 0.0018 - val_mae: 0.0040\n",
      "Epoch 89/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0018 - mae: 0.0046 - val_loss: 0.0020 - val_mae: 0.0142\n",
      "Epoch 90/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0018 - mae: 0.0044 - val_loss: 0.0018 - val_mae: 0.0051\n",
      "Epoch 91/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0018 - mae: 0.0046 - val_loss: 0.0018 - val_mae: 0.0101\n",
      "Epoch 92/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0017 - mae: 0.0040 - val_loss: 0.0017 - val_mae: 0.0031\n",
      "Epoch 93/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0017 - mae: 0.0042 - val_loss: 0.0017 - val_mae: 0.0044\n",
      "Epoch 94/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0017 - mae: 0.0044 - val_loss: 0.0017 - val_mae: 0.0033\n",
      "Epoch 95/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0017 - mae: 0.0040 - val_loss: 0.0017 - val_mae: 0.0034\n",
      "Epoch 96/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0017 - mae: 0.0045 - val_loss: 0.0017 - val_mae: 0.0073\n",
      "Epoch 97/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0017 - mae: 0.0041 - val_loss: 0.0017 - val_mae: 0.0039\n",
      "Epoch 98/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0017 - mae: 0.0042 - val_loss: 0.0016 - val_mae: 0.0040\n",
      "Epoch 99/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0032\n",
      "Epoch 100/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0016 - mae: 0.0043 - val_loss: 0.0016 - val_mae: 0.0039\n",
      "Epoch 101/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0031\n",
      "Epoch 102/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0016 - mae: 0.0043 - val_loss: 0.0018 - val_mae: 0.0119\n",
      "Epoch 103/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0016 - mae: 0.0045 - val_loss: 0.0018 - val_mae: 0.0125\n",
      "Epoch 104/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0034\n",
      "Epoch 105/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0016 - mae: 0.0043 - val_loss: 0.0016 - val_mae: 0.0039\n",
      "Epoch 106/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0016 - mae: 0.0043 - val_loss: 0.0016 - val_mae: 0.0057\n",
      "Epoch 107/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0017 - val_mae: 0.0100\n",
      "Epoch 108/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 0.0015 - val_mae: 0.0036\n",
      "Epoch 109/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0034\n",
      "Epoch 110/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 0.0015 - val_mae: 0.0032\n",
      "Epoch 111/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0047\n",
      "Epoch 112/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0097\n",
      "Epoch 113/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0047\n",
      "Epoch 114/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 0.0015 - val_mae: 0.0063\n",
      "Epoch 115/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0061\n",
      "Epoch 116/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0037\n",
      "Epoch 117/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0041 - val_loss: 0.0015 - val_mae: 0.0031\n",
      "Epoch 118/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0016 - val_mae: 0.0115\n",
      "Epoch 119/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0040 - val_loss: 0.0015 - val_mae: 0.0051\n",
      "Epoch 120/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0084\n",
      "Epoch 121/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0033\n",
      "Epoch 122/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 0.0015 - val_mae: 0.0052\n",
      "Epoch 123/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0036\n",
      "Epoch 124/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0041 - val_loss: 0.0014 - val_mae: 0.0028\n",
      "Epoch 125/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0034\n",
      "Epoch 126/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0038\n",
      "Epoch 127/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0070\n",
      "Epoch 128/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0055\n",
      "Epoch 129/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0053\n",
      "Epoch 130/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0031\n",
      "Epoch 131/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0047 - val_loss: 0.0014 - val_mae: 0.0043\n",
      "Epoch 132/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0041 - val_loss: 0.0014 - val_mae: 0.0043\n",
      "Epoch 133/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0057\n",
      "Epoch 134/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0032\n",
      "Epoch 135/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0087\n",
      "Epoch 136/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0050\n",
      "Epoch 137/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0034\n",
      "Epoch 138/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0083\n",
      "Epoch 139/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0039\n",
      "Epoch 140/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0065\n",
      "Epoch 141/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0014 - mae: 0.0047 - val_loss: 0.0014 - val_mae: 0.0045\n",
      "Epoch 142/400\n",
      "645/645 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0040\n",
      "Epoch 143/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0033\n",
      "Epoch 144/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0032\n",
      "Epoch 145/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0064\n",
      "Epoch 146/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0041\n",
      "Epoch 147/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0034\n",
      "Epoch 148/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0030\n",
      "Epoch 149/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0013 - mae: 0.0041 - val_loss: 0.0013 - val_mae: 0.0048\n",
      "Epoch 150/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0039\n",
      "Epoch 151/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0081\n",
      "Epoch 152/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0099\n",
      "Epoch 153/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0041\n",
      "Epoch 154/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0053\n",
      "Epoch 155/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0034\n",
      "Epoch 156/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0044\n",
      "Epoch 157/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0058\n",
      "Epoch 158/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0033\n",
      "Epoch 159/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0013 - mae: 0.0047 - val_loss: 0.0013 - val_mae: 0.0038\n",
      "Epoch 160/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0047\n",
      "Epoch 161/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0107\n",
      "Epoch 162/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0046\n",
      "Epoch 163/400\n",
      "640/645 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0045Restoring model weights from the end of the best epoch: 158.\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0077\n",
      "Epoch 163: early stopping\n",
      "Die Ausführungszeit betrug 397.3717601299286 Sekunden.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Netzwerkarchitektur\n",
    "model = Sequential([\n",
    "    # Eingabeschicht\n",
    "\n",
    "    Dense(80, activation='relu', input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "    Dense(208, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "    Dense(320, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "    Dense(240, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "    Dense(224, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "    Dense(160, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(128, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(240, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(256, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(32, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(1 , activation = 'linear')\n",
    "])\n",
    "\n",
    "# Optimierer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "# Modell kompilieren (Verwendung von mean_squared_error als Verlustfunktion für Regression)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])  # Metriken für Regression: Mean Absolute Error und Mean Squared Error\n",
    "\n",
    "# Early Stopping Callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=2, mode='min', restore_best_weights=True)#, min_delta = 0.00005)\n",
    "\n",
    "# Trainingsparameter\n",
    "batch_size = 100\n",
    "epochs = 400\n",
    "\n",
    "# Modell trainieren (Annahme: X_train, y_train, X_val, y_val sind vordefiniert)\n",
    "history = model.fit(X_train_scaled, y_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose = 1)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Berechne die Dauer\n",
    "duration = end_time - start_time\n",
    "\n",
    "print(f\"Die Ausführungszeit betrug {duration} Sekunden.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:59:59.232245600Z",
     "start_time": "2024-03-15T09:53:21.856355800Z"
    }
   },
   "id": "8b52e1a9a6ff3aeb"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 - 1s - loss: 0.0013 - mae: 0.0034 - 897ms/epoch - 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.0012983082560822368, 0.0033980649895966053]"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test_scaled, y_test_scaled, verbose=2)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:00:00.172308200Z",
     "start_time": "2024-03-15T09:59:59.231244500Z"
    }
   },
   "id": "68d86893ad985b02"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f6f672a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T10:00:01.043960Z",
     "start_time": "2024-03-15T10:00:00.167307800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bsp. Predicted: [1192.29] Actual: [1195.9] \n",
      "Durchschnittliche Abweichung (MAE): [3.22068681]\n"
     ]
    }
   ],
   "source": [
    "scaled_predicted_values = model.predict(X_test_scaled, verbose = 0)\n",
    "\n",
    "# Führen Sie die Rücktransformation der skalierten Werte durch\n",
    "original_predicted_values = scaler_target.inverse_transform(scaled_predicted_values)\n",
    "original_actual_values = scaler_target.inverse_transform(y_test_scaled)  # y_test sind die skalierten tatsächlichen Werte\n",
    "print(f' Bsp. Predicted: {original_predicted_values[1000]} Actual: {original_actual_values[1000]} ')\n",
    "\n",
    "def calculate_mae(list1, list2):\n",
    "    # Stelle sicher, dass beide Listen die gleiche Länge haben\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Listen müssen die gleiche Länge haben\")\n",
    "\n",
    "    # Berechne die absolute Differenz zwischen den Elementen der Listen\n",
    "    differences = [abs(x - y) for x, y in zip(list1, list2)]\n",
    "\n",
    "    # Berechne den Durchschnitt der absoluten Differenzen\n",
    "    mae = sum(differences) / len(differences)\n",
    "\n",
    "    return mae\n",
    "\n",
    "# Beispiel\n",
    "list1 = original_predicted_values\n",
    "list2 = original_actual_values\n",
    "\n",
    "mae = calculate_mae(list1, list2)\n",
    "print(f\"Durchschnittliche Abweichung (MAE): {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: [0.99971234]\n"
     ]
    }
   ],
   "source": [
    "def calculate_r_squared(predicted, actual):\n",
    "    # Berechnung des Mittelwerts der tatsächlichen Werte\n",
    "    mean_actual = sum(actual) / len(actual)\n",
    "    \n",
    "    # Berechnung der totalen Summe der Quadrate (SST)\n",
    "    sst = sum((x - mean_actual) ** 2 for x in actual)\n",
    "    \n",
    "    # Berechnung der Summe der Quadrate der Residuen (SSE)\n",
    "    sse = sum((actual[i] - predicted[i]) ** 2 for i in range(len(actual)))\n",
    "    \n",
    "    # Berechnung des R^2-Wertes\n",
    "    r_squared = 1 - (sse / sst)\n",
    "    \n",
    "    return r_squared\n",
    "\n",
    "# Berechnung von R^2 mit den bereitgestellten Listen\n",
    "r_squared = calculate_r_squared(list1, list2)\n",
    "\n",
    "print(f\"R^2: {r_squared}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:00:01.155892700Z",
     "start_time": "2024-03-15T10:00:01.040437200Z"
    }
   },
   "id": "48ac8cdcc05e55fd"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Werte die kleiner sind: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": "             Echt  Vorhergesagt  X-Koordinate  Y-Koordinate  Differenz\n14143  804.066650        832.75         1.000        0.9025 -28.683350\n19281  779.225708        807.84         1.000        0.9125 -28.614292\n16514  810.242615        838.63         1.000        0.9000 -28.387385\n4177   816.400452        844.45         1.000        0.8975 -28.049548\n16594  828.716064        855.66         1.000        0.8925 -26.943936\n...           ...           ...           ...           ...        ...\n321    613.249207        591.99         0.884        0.9750  21.259207\n4134   612.499695        591.24         0.840        0.9750  21.259695\n14839  621.075562        599.38         0.956        0.9725  21.695562\n13809  615.020813        593.15         0.988        0.9750  21.870813\n20012  615.157104        588.92         0.996        0.9750  26.237104\n\n[20131 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Echt</th>\n      <th>Vorhergesagt</th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Differenz</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14143</th>\n      <td>804.066650</td>\n      <td>832.75</td>\n      <td>1.000</td>\n      <td>0.9025</td>\n      <td>-28.683350</td>\n    </tr>\n    <tr>\n      <th>19281</th>\n      <td>779.225708</td>\n      <td>807.84</td>\n      <td>1.000</td>\n      <td>0.9125</td>\n      <td>-28.614292</td>\n    </tr>\n    <tr>\n      <th>16514</th>\n      <td>810.242615</td>\n      <td>838.63</td>\n      <td>1.000</td>\n      <td>0.9000</td>\n      <td>-28.387385</td>\n    </tr>\n    <tr>\n      <th>4177</th>\n      <td>816.400452</td>\n      <td>844.45</td>\n      <td>1.000</td>\n      <td>0.8975</td>\n      <td>-28.049548</td>\n    </tr>\n    <tr>\n      <th>16594</th>\n      <td>828.716064</td>\n      <td>855.66</td>\n      <td>1.000</td>\n      <td>0.8925</td>\n      <td>-26.943936</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>321</th>\n      <td>613.249207</td>\n      <td>591.99</td>\n      <td>0.884</td>\n      <td>0.9750</td>\n      <td>21.259207</td>\n    </tr>\n    <tr>\n      <th>4134</th>\n      <td>612.499695</td>\n      <td>591.24</td>\n      <td>0.840</td>\n      <td>0.9750</td>\n      <td>21.259695</td>\n    </tr>\n    <tr>\n      <th>14839</th>\n      <td>621.075562</td>\n      <td>599.38</td>\n      <td>0.956</td>\n      <td>0.9725</td>\n      <td>21.695562</td>\n    </tr>\n    <tr>\n      <th>13809</th>\n      <td>615.020813</td>\n      <td>593.15</td>\n      <td>0.988</td>\n      <td>0.9750</td>\n      <td>21.870813</td>\n    </tr>\n    <tr>\n      <th>20012</th>\n      <td>615.157104</td>\n      <td>588.92</td>\n      <td>0.996</td>\n      <td>0.9750</td>\n      <td>26.237104</td>\n    </tr>\n  </tbody>\n</table>\n<p>20131 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame({'Echt': [val[0] for val in list1], 'Vorhergesagt': [val[0] for val in list2]})\n",
    "df_result['X-Koordinate'] = X_test_scaled[:, 0]\n",
    "df_result['Y-Koordinate'] = X_test_scaled[:, 1]\n",
    "\n",
    "df_result['Differenz'] = df_result['Echt'] - df_result['Vorhergesagt']\n",
    "df_result['Differenz'].sort_values()\n",
    "sorted_df = df_result.sort_values(by= 'Differenz')\n",
    "Anzahl_Punkte = (sorted_df['Differenz'] > 20).sum()\n",
    "print(\"Anzahl der Werte die kleiner sind:\", Anzahl_Punkte)\n",
    "\n",
    "sorted_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:00:01.185004400Z",
     "start_time": "2024-03-15T10:00:01.155892700Z"
    }
   },
   "id": "42bde60d3b4f2007"
  },
  {
   "cell_type": "markdown",
   "id": "553df6fa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mae = history.history['loss']\n",
    "val_mae = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(mae) + 1)\n",
    "# MAE Diagramm\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, mae, 'r', label='Training MSE')\n",
    "plt.plot(epochs, val_mae, 'b', label='Validation MSE')\n",
    "plt.title('Training and Validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.savefig('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Bilder Diplomarbeit/MSE_NeuroNetz/MSE_NeuroNetz_D1_2')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:00:01.420781400Z",
     "start_time": "2024-03-15T10:00:01.185004400Z"
    }
   },
   "id": "3688dd7102e95baf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# GridSearch\n",
    "Grid Search bietet die Vorteile der anpassbaren Rechenzeit sowie die Möglichkeit des EInsatzes von Verteilungen. So können theoretisch Hyperparamterkonfuigurationen gefunden wende, welche durch GridSearch nicht auffindbar wären. ZUdem ist das Ziel der Hyperparamteroptimierung eine Einstellung zu finden, welche auf Trainings und Testset gut angepasst ist. Die EInstellung muss nicht die bestmöglichste Einstellung sein, sondern eine Einstellung die das gewähltre Problem gut wiederspiegelt. \n",
    "Bayesian Optimierung"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c177960cc729052"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3f17e2cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T10:00:01.423818100Z",
     "start_time": "2024-03-15T10:00:01.416947800Z"
    }
   },
   "outputs": [],
   "source": [
    "# def build_model(learning_rate=0.001, activation='relu', regularization=0.0001, dropout_rate=0.0):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(320, activation=activation, input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(176, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(288, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(192, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(208, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(224, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(80, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(304, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate)) \n",
    "# \n",
    "#     model.add(Dense(240, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))   \n",
    "# \n",
    "#     model.add(Dense(48, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mae'])\n",
    "#     return model\n",
    "# \n",
    "# # Verwenden Sie eine Funktion, um das Modell zu instanziieren, für scikit-learn Wrapper\n",
    "# model = KerasRegressor(model=build_model, verbose=2)\n",
    "# \n",
    "# # Anpassung der Parameter im param_grid\n",
    "# param_grid = {\n",
    "#     'model__learning_rate': [0.01, 0.001, 0.0001],\n",
    "#     'model__regularization': [0.001, 0.0001],\n",
    "#     'fit__batch_size': [100, 200, 400, 800],\n",
    "#     'fit__epochs': [50],\n",
    "#     'model__dropout_rate' : [0.0, 0.1, 0.2]\n",
    "# }\n",
    "# \n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=2)\n",
    "# # Hinweis: Stellen Sie sicher, dass Ihre Daten (X_train_scaled, y_train_scaled) korrekt definiert sind\n",
    "# grid_result = grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "# # Beste Parameter und Score ausgeben\n",
    "# print(\"Beste Parameter:\", grid_search.best_params_)\n",
    "# print(\"Beste Genauigkeit:\", grid_search.best_score_)\n",
    "# \n",
    "# with open(\"grid_search_D1_2.txt\", \"w\") as f:\n",
    "#     f.write(f\"Beste Parameter: {grid_search.best_params_}\\n\")\n",
    "#     f.write(f\"Beste Genauigkeit: {grid_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "  # Bayesian Optimization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bb41910a42cbdee"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "# from bayes_opt import BayesianOptimization\n",
    "# \n",
    "# \n",
    "# # Angenommene Daten\n",
    "# # X_train_scaled, y_train_scaled = # Deine skalierten Trainingsdaten\n",
    "# \n",
    "# def train_evaluate(neurons_layer_1, neurons_layer_2, neurons_layer_3, neurons_layer_4, neurons_layer_5, learning_rate):\n",
    "#     model = Sequential([\n",
    "#         Dense(int(neurons_layer_1), activation='relu', input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "#         Dense(int(neurons_layer_2), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "#         Dense(int(neurons_layer_3), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "#         Dense(int(neurons_layer_4), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "#         Dense(int(neurons_layer_5), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "#         \n",
    "#         Dense(1, activation='linear')\n",
    "#     ])\n",
    "# \n",
    "#     optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "#     model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "# \n",
    "#     early_stopping = EarlyStopping(monitor='loss', patience=5, verbose=1, mode='min', restore_best_weights=True, min_delta=0.0001)\n",
    "# \n",
    "#     history = model.fit(X_train_scaled, y_train_scaled, batch_size=32, epochs=100, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
    "# \n",
    "#     # Hier wählen wir den negativen Mean Squared Error, da Bayesian Optimization maximiert\n",
    "#     mse = np.min(history.history['val_loss'])\n",
    "#     return -mse\n",
    "# \n",
    "# # Definieren des Bereichs der Hyperparameter\n",
    "# pbounds = {\n",
    "#     'neurons_layer_1': (16, 200),\n",
    "#     'neurons_layer_2': (16, 200),\n",
    "#     'neurons_layer_3': (16, 200),\n",
    "#     'neurons_layer_4': (16, 200),\n",
    "#     'neurons_layer_5': (16, 200),\n",
    "#     'learning_rate': (0.0001, 0.01),\n",
    "# }\n",
    "# \n",
    "# # Initialisieren des BayesianOptimization-Objekts\n",
    "# optimizer = BayesianOptimization(\n",
    "#     f=train_evaluate,\n",
    "#     pbounds=pbounds,\n",
    "#     random_state=1,\n",
    "# )\n",
    "# \n",
    "# # Starten der Optimierung\n",
    "# optimizer.maximize(init_points=2, n_iter=20)\n",
    "# \n",
    "# print(optimizer.max)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:00:01.435372800Z",
     "start_time": "2024-03-15T10:00:01.421299100Z"
    }
   },
   "id": "a5b6232547cdae67"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Search Architektur\n",
    "Tiefes Netz besser als breites Netz; Layer lernen auf unterschiedliche Weise"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75773dfef8260e5f"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "# # Funktion zum Erstellen des Modells\n",
    "# def build_model(hp):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(hp.Int('input_units', min_value=16, max_value=328, step=16), input_shape=(2,), activation='relu'))\n",
    "#     for i in range(hp.Int('n_layers', 1, 10)):\n",
    "#         model.add(Dense(hp.Int(f'units_{i}', min_value=16, max_value=328, step=16), activation='relu'))\n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     return model\n",
    "# \n",
    "# # Durchführung der Random Search dreimal\n",
    "# for run in range(1, 4):\n",
    "#     # Anpassen des Verzeichnisses und des Projektnamens für jeden Durchlauf\n",
    "#     directory = 'random_search'\n",
    "#     project_name = f'random_search_D1_{run}'\n",
    "# \n",
    "#     tuner = RandomSearch(\n",
    "#         build_model,\n",
    "#         objective='val_loss',\n",
    "#         max_trials=100,\n",
    "#         executions_per_trial=1,\n",
    "#         directory=directory,\n",
    "#         project_name=project_name\n",
    "#     )\n",
    "# \n",
    "#     # Durchführung des Random Search\n",
    "#     tuner.search(X_train_scaled, y_train_scaled, epochs=50, verbose =0, batch_size=500, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "# \n",
    "#     # Abrufen und Speichern des besten Modells\n",
    "#     best_model = tuner.get_best_models(num_models=1)[0]\n",
    "#     model_path = os.path.join(directory, project_name, 'best_model.h5') \n",
    "#     best_model.save(model_path)\n",
    "# \n",
    "# \n",
    "#     # Optional: Abrufen und Ausgeben der besten Hyperparameter\n",
    "#     best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "# \n",
    "#     # Konvertieren der Hyperparameter in ein DataFrame\n",
    "#     df_hyperparameters = pd.DataFrame([best_hyperparameters.values])\n",
    "#     # Speichern des DataFrame als CSV\n",
    "#     df_hyperparameters.to_csv(f'random_search_D1_{run}.csv', index=False)\n",
    "#     best_model.describe()\n",
    "#     print(f\"Beste Hyperparameter für Lauf {run}: {best_hyperparameters.values}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:00:01.435372800Z",
     "start_time": "2024-03-15T10:00:01.425559Z"
    }
   },
   "id": "158d81fabf560fc4"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:00:01.435372800Z",
     "start_time": "2024-03-15T10:00:01.432902600Z"
    }
   },
   "id": "6f86db4f21a8c913"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:00:01.435372800Z",
     "start_time": "2024-03-15T10:00:01.434846900Z"
    }
   },
   "id": "2a8e01cea48e945f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
