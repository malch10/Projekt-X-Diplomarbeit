{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94b0518e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T16:02:17.762613400Z",
     "start_time": "2024-03-14T16:02:17.651516300Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense , Dropout\n",
    "from scikeras.wrappers import KerasRegressor \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4ff61b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T16:02:17.840612500Z",
     "start_time": "2024-03-14T16:02:17.654516100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n0             0.0000      -0.00200        500   7000   9000      669.05\n1             0.0000      -0.00199        500   7000   9000      675.83\n2             0.0000      -0.00198        500   7000   9000      682.81\n3             0.0000      -0.00197        500   7000   9000      689.82\n4             0.0000      -0.00196        500   7000   9000      696.80\n...              ...           ...        ...    ...    ...         ...\n100646        0.0025       0.00196        500   7000   9000      578.47\n100647        0.0025       0.00197        500   7000   9000      576.89\n100648        0.0025       0.00198        500   7000   9000      575.32\n100649        0.0025       0.00199        500   7000   9000      573.76\n100650        0.0025       0.00200        500   7000   9000      572.20\n\n[100651 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>669.05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0000</td>\n      <td>-0.00199</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>675.83</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0000</td>\n      <td>-0.00198</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>682.81</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0000</td>\n      <td>-0.00197</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>689.82</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0000</td>\n      <td>-0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>696.80</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>100646</th>\n      <td>0.0025</td>\n      <td>0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>578.47</td>\n    </tr>\n    <tr>\n      <th>100647</th>\n      <td>0.0025</td>\n      <td>0.00197</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>576.89</td>\n    </tr>\n    <tr>\n      <th>100648</th>\n      <td>0.0025</td>\n      <td>0.00198</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>575.32</td>\n    </tr>\n    <tr>\n      <th>100649</th>\n      <td>0.0025</td>\n      <td>0.00199</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>573.76</td>\n    </tr>\n    <tr>\n      <th>100650</th>\n      <td>0.0025</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>572.20</td>\n    </tr>\n  </tbody>\n</table>\n<p>100651 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/TPath_300_finish_data.pkl')\n",
    "data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_D1_I7000_F9000/TPath_500_finish_data_D1.pkl')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "966e3c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T16:02:17.856612700Z",
     "start_time": "2024-03-14T16:02:17.663785900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "count    100651.000000\nmean       1144.030064\nstd         264.135723\nmin         572.200000\n25%         937.330000\n50%        1201.100000\n75%        1368.700000\nmax        1520.000000\nName: Temperatur, dtype: float64"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.drop(data.columns[2:5], axis = 1)\n",
    "df['Temperatur'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8783d1d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T16:02:17.939613300Z",
     "start_time": "2024-03-14T16:02:17.671096600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       X-Koordinate  Y-Koordinate  Temperatur\n",
      "83145       0.00207      -0.00062      1282.2\n",
      "66701       0.00166      -0.00065      1347.6\n",
      "91325       0.00227       0.00098      1094.6\n",
      "46593       0.00116      -0.00123      1175.7\n",
      "49518       0.00123      -0.00005      1459.2\n",
      "...             ...           ...         ...\n",
      "6265        0.00015       0.00050      1439.1\n",
      "54886       0.00136       0.00150       876.7\n",
      "76820       0.00191       0.00029      1335.8\n",
      "860         0.00002      -0.00142      1071.2\n",
      "15795       0.00039      -0.00044      1488.1\n",
      "\n",
      "[100651 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate  Temperatur\n0            0.00207      -0.00062      1282.2\n1            0.00166      -0.00065      1347.6\n2            0.00227       0.00098      1094.6\n3            0.00116      -0.00123      1175.7\n4            0.00123      -0.00005      1459.2\n...              ...           ...         ...\n100646       0.00015       0.00050      1439.1\n100647       0.00136       0.00150       876.7\n100648       0.00191       0.00029      1335.8\n100649       0.00002      -0.00142      1071.2\n100650       0.00039      -0.00044      1488.1\n\n[100651 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00207</td>\n      <td>-0.00062</td>\n      <td>1282.2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00166</td>\n      <td>-0.00065</td>\n      <td>1347.6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00227</td>\n      <td>0.00098</td>\n      <td>1094.6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00116</td>\n      <td>-0.00123</td>\n      <td>1175.7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00123</td>\n      <td>-0.00005</td>\n      <td>1459.2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>100646</th>\n      <td>0.00015</td>\n      <td>0.00050</td>\n      <td>1439.1</td>\n    </tr>\n    <tr>\n      <th>100647</th>\n      <td>0.00136</td>\n      <td>0.00150</td>\n      <td>876.7</td>\n    </tr>\n    <tr>\n      <th>100648</th>\n      <td>0.00191</td>\n      <td>0.00029</td>\n      <td>1335.8</td>\n    </tr>\n    <tr>\n      <th>100649</th>\n      <td>0.00002</td>\n      <td>-0.00142</td>\n      <td>1071.2</td>\n    </tr>\n    <tr>\n      <th>100650</th>\n      <td>0.00039</td>\n      <td>-0.00044</td>\n      <td>1488.1</td>\n    </tr>\n  </tbody>\n</table>\n<p>100651 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.sample(frac=1, random_state=42)  # Hier wird 42 als Random State verwendet, um die Ergebnisse reproduzierbar zu machen\n",
    "\n",
    "print(df1)\n",
    "df_reset = df1.reset_index(drop=True)\n",
    "df_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4e72a16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T16:02:17.940613500Z",
     "start_time": "2024-03-14T16:02:17.686694400Z"
    }
   },
   "outputs": [],
   "source": [
    "label = df_reset[\"Temperatur\"]\n",
    "# Korrektur: Verwenden Sie den Spaltennamen direkt, ohne Indexierung der columns-Eigenschaft\n",
    "df1 = df_reset.drop(\"Temperatur\", axis=1)\n",
    "X = df1\n",
    "y = label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7fa289a50d87423"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e694a236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T16:02:17.943612800Z",
     "start_time": "2024-03-14T16:02:17.691694200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate\ncount  100651.000000  1.006510e+05\nmean        0.001250  1.103042e-20\nstd         0.000725  1.157589e-03\nmin         0.000000 -2.000000e-03\n25%         0.000620 -1.000000e-03\n50%         0.001250  4.529900e-18\n75%         0.001880  1.000000e-03\nmax         0.002500  2.000000e-03",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>100651.000000</td>\n      <td>1.006510e+05</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.001250</td>\n      <td>1.103042e-20</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.000725</td>\n      <td>1.157589e-03</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-2.000000e-03</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000620</td>\n      <td>-1.000000e-03</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.001250</td>\n      <td>4.529900e-18</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.001880</td>\n      <td>1.000000e-03</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.002500</td>\n      <td>2.000000e-03</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f3303b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T16:02:17.944612500Z",
     "start_time": "2024-03-14T16:02:17.705747800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "count    100651.000000\nmean       1144.030064\nstd         264.135723\nmin         572.200000\n25%         937.330000\n50%        1201.100000\n75%        1368.700000\nmax        1520.000000\nName: Temperatur, dtype: float64"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3ad8da0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T16:02:17.944612500Z",
     "start_time": "2024-03-14T16:02:17.715981Z"
    }
   },
   "outputs": [],
   "source": [
    " # train_df enthält 80% der Daten, test_df enthält 20% der Daten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c705edb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T16:02:17.944612500Z",
     "start_time": "2024-03-14T16:02:17.725949600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialisiere einen MinMaxScaler für die Features\n",
    "scaler_features = MinMaxScaler()\n",
    "scaler_features2 = MinMaxScaler()\n",
    "# Skaliere X_train und X_test\n",
    "X_train_scaled = scaler_features.fit_transform(X_train)\n",
    "X_test_scaled = scaler_features.transform(X_test)  # Nutze unterschiedliche Skalierungsparameter\n",
    "\n",
    "# Initialisiere einen SEPARATEN MinMaxScaler für das Ziel, wenn nötig\n",
    "scaler_target = MinMaxScaler()\n",
    "\n",
    "\n",
    "# Skaliere y_train und y_test. Beachte, dass y_train.reshape(-1, 1) verwendet wird, da MinMaxScaler \n",
    "# erwartet, dass die Eingaben als 2D-Arrays kommen, und Ziele normalerweise als 1D-Arrays vorliegen.\n",
    "y_train_scaled = scaler_target.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test_scaled = scaler_target.transform(y_test.values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bbefe631e495b483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T16:02:17.944612500Z",
     "start_time": "2024-03-14T16:02:17.733974200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.416 , 0.5725],\n       [0.812 , 0.7325],\n       [0.628 , 0.5075],\n       ...,\n       [0.604 , 0.3875],\n       [0.748 , 0.65  ],\n       [0.028 , 0.6225]])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "645/645 [==============================] - 3s 3ms/step - loss: 0.2869 - mae: 0.1414 - val_loss: 0.1944 - val_mae: 0.0165\n",
      "Epoch 2/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.1763 - mae: 0.0114 - val_loss: 0.1621 - val_mae: 0.0065\n",
      "Epoch 3/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.1535 - mae: 0.0109 - val_loss: 0.1462 - val_mae: 0.0077\n",
      "Epoch 4/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.1416 - mae: 0.0140 - val_loss: 0.1368 - val_mae: 0.0076\n",
      "Epoch 5/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.1335 - mae: 0.0120 - val_loss: 0.1300 - val_mae: 0.0092\n",
      "Epoch 6/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.1271 - mae: 0.0105 - val_loss: 0.1241 - val_mae: 0.0123\n",
      "Epoch 7/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.1212 - mae: 0.0099 - val_loss: 0.1182 - val_mae: 0.0078\n",
      "Epoch 8/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.1156 - mae: 0.0111 - val_loss: 0.1129 - val_mae: 0.0149\n",
      "Epoch 9/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.1102 - mae: 0.0102 - val_loss: 0.1075 - val_mae: 0.0118\n",
      "Epoch 10/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.1049 - mae: 0.0113 - val_loss: 0.1021 - val_mae: 0.0073\n",
      "Epoch 11/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0996 - mae: 0.0078 - val_loss: 0.0971 - val_mae: 0.0081\n",
      "Epoch 12/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0948 - mae: 0.0105 - val_loss: 0.0922 - val_mae: 0.0044\n",
      "Epoch 13/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0899 - mae: 0.0069 - val_loss: 0.0874 - val_mae: 0.0056\n",
      "Epoch 14/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0852 - mae: 0.0084 - val_loss: 0.0842 - val_mae: 0.0304\n",
      "Epoch 15/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0806 - mae: 0.0076 - val_loss: 0.0785 - val_mae: 0.0118\n",
      "Epoch 16/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 0.0762 - mae: 0.0075 - val_loss: 0.0746 - val_mae: 0.0190\n",
      "Epoch 17/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 0.0721 - mae: 0.0073 - val_loss: 0.0701 - val_mae: 0.0079\n",
      "Epoch 18/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0682 - mae: 0.0074 - val_loss: 0.0662 - val_mae: 0.0061\n",
      "Epoch 19/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0645 - mae: 0.0069 - val_loss: 0.0628 - val_mae: 0.0124\n",
      "Epoch 20/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0610 - mae: 0.0068 - val_loss: 0.0593 - val_mae: 0.0039\n",
      "Epoch 21/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0579 - mae: 0.0070 - val_loss: 0.0563 - val_mae: 0.0043\n",
      "Epoch 22/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0550 - mae: 0.0072 - val_loss: 0.0535 - val_mae: 0.0051\n",
      "Epoch 23/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0523 - mae: 0.0060 - val_loss: 0.0510 - val_mae: 0.0036\n",
      "Epoch 24/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0497 - mae: 0.0050 - val_loss: 0.0488 - val_mae: 0.0178\n",
      "Epoch 25/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0472 - mae: 0.0072 - val_loss: 0.0460 - val_mae: 0.0088\n",
      "Epoch 26/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0448 - mae: 0.0047 - val_loss: 0.0437 - val_mae: 0.0054\n",
      "Epoch 27/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0425 - mae: 0.0052 - val_loss: 0.0413 - val_mae: 0.0058\n",
      "Epoch 28/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0402 - mae: 0.0056 - val_loss: 0.0391 - val_mae: 0.0030\n",
      "Epoch 29/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0381 - mae: 0.0051 - val_loss: 0.0371 - val_mae: 0.0074\n",
      "Epoch 30/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0360 - mae: 0.0047 - val_loss: 0.0349 - val_mae: 0.0056\n",
      "Epoch 31/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0339 - mae: 0.0060 - val_loss: 0.0329 - val_mae: 0.0038\n",
      "Epoch 32/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0321 - mae: 0.0045 - val_loss: 0.0312 - val_mae: 0.0031\n",
      "Epoch 33/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0303 - mae: 0.0050 - val_loss: 0.0294 - val_mae: 0.0070\n",
      "Epoch 34/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0285 - mae: 0.0045 - val_loss: 0.0276 - val_mae: 0.0040\n",
      "Epoch 35/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0268 - mae: 0.0048 - val_loss: 0.0263 - val_mae: 0.0146\n",
      "Epoch 36/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0251 - mae: 0.0048 - val_loss: 0.0243 - val_mae: 0.0043\n",
      "Epoch 37/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0236 - mae: 0.0044 - val_loss: 0.0228 - val_mae: 0.0036\n",
      "Epoch 38/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0221 - mae: 0.0050 - val_loss: 0.0215 - val_mae: 0.0061\n",
      "Epoch 39/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0208 - mae: 0.0046 - val_loss: 0.0202 - val_mae: 0.0074\n",
      "Epoch 40/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0195 - mae: 0.0046 - val_loss: 0.0188 - val_mae: 0.0049\n",
      "Epoch 41/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0182 - mae: 0.0045 - val_loss: 0.0177 - val_mae: 0.0054\n",
      "Epoch 42/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0170 - mae: 0.0042 - val_loss: 0.0165 - val_mae: 0.0055\n",
      "Epoch 43/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0159 - mae: 0.0041 - val_loss: 0.0153 - val_mae: 0.0030\n",
      "Epoch 44/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0147 - mae: 0.0043 - val_loss: 0.0142 - val_mae: 0.0076\n",
      "Epoch 45/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0137 - mae: 0.0045 - val_loss: 0.0132 - val_mae: 0.0047\n",
      "Epoch 46/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0128 - mae: 0.0041 - val_loss: 0.0123 - val_mae: 0.0056\n",
      "Epoch 47/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0119 - mae: 0.0042 - val_loss: 0.0114 - val_mae: 0.0036\n",
      "Epoch 48/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0110 - mae: 0.0043 - val_loss: 0.0106 - val_mae: 0.0033\n",
      "Epoch 49/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0102 - mae: 0.0043 - val_loss: 0.0099 - val_mae: 0.0057\n",
      "Epoch 50/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0095 - mae: 0.0039 - val_loss: 0.0092 - val_mae: 0.0033\n",
      "Epoch 51/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0088 - mae: 0.0041 - val_loss: 0.0085 - val_mae: 0.0046\n",
      "Epoch 52/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0082 - mae: 0.0043 - val_loss: 0.0079 - val_mae: 0.0048\n",
      "Epoch 53/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0076 - mae: 0.0043 - val_loss: 0.0074 - val_mae: 0.0061\n",
      "Epoch 54/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0071 - mae: 0.0042 - val_loss: 0.0069 - val_mae: 0.0030\n",
      "Epoch 55/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0067 - mae: 0.0043 - val_loss: 0.0064 - val_mae: 0.0032\n",
      "Epoch 56/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0062 - mae: 0.0041 - val_loss: 0.0060 - val_mae: 0.0032\n",
      "Epoch 57/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0058 - mae: 0.0043 - val_loss: 0.0056 - val_mae: 0.0033\n",
      "Epoch 58/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0055 - mae: 0.0041 - val_loss: 0.0053 - val_mae: 0.0041\n",
      "Epoch 59/400\n",
      "645/645 [==============================] - 3s 4ms/step - loss: 0.0051 - mae: 0.0042 - val_loss: 0.0050 - val_mae: 0.0050\n",
      "Epoch 60/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0048 - mae: 0.0041 - val_loss: 0.0047 - val_mae: 0.0039\n",
      "Epoch 61/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0045 - mae: 0.0040 - val_loss: 0.0044 - val_mae: 0.0036\n",
      "Epoch 62/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0043 - mae: 0.0041 - val_loss: 0.0041 - val_mae: 0.0030\n",
      "Epoch 63/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0040 - mae: 0.0040 - val_loss: 0.0039 - val_mae: 0.0058\n",
      "Epoch 64/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0038 - mae: 0.0041 - val_loss: 0.0038 - val_mae: 0.0096\n",
      "Epoch 65/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0036 - mae: 0.0042 - val_loss: 0.0035 - val_mae: 0.0050\n",
      "Epoch 66/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0034 - mae: 0.0042 - val_loss: 0.0033 - val_mae: 0.0059\n",
      "Epoch 67/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0032 - mae: 0.0040 - val_loss: 0.0032 - val_mae: 0.0051\n",
      "Epoch 68/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0031 - mae: 0.0040 - val_loss: 0.0030 - val_mae: 0.0040\n",
      "Epoch 69/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0029 - mae: 0.0040 - val_loss: 0.0029 - val_mae: 0.0063\n",
      "Epoch 70/400\n",
      "645/645 [==============================] - 2s 4ms/step - loss: 0.0028 - mae: 0.0041 - val_loss: 0.0027 - val_mae: 0.0047\n",
      "Epoch 71/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0027 - mae: 0.0040 - val_loss: 0.0026 - val_mae: 0.0044\n",
      "Epoch 72/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0026 - mae: 0.0041 - val_loss: 0.0025 - val_mae: 0.0039\n",
      "Epoch 73/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0024 - mae: 0.0042 - val_loss: 0.0024 - val_mae: 0.0031\n",
      "Epoch 74/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0024 - mae: 0.0039 - val_loss: 0.0023 - val_mae: 0.0043\n",
      "Epoch 75/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0040 - val_loss: 0.0022 - val_mae: 0.0032\n",
      "Epoch 76/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0041 - val_loss: 0.0021 - val_mae: 0.0031\n",
      "Epoch 77/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0021 - mae: 0.0040 - val_loss: 0.0021 - val_mae: 0.0032\n",
      "Epoch 78/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0020 - mae: 0.0038 - val_loss: 0.0021 - val_mae: 0.0069\n",
      "Epoch 79/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0020 - mae: 0.0040 - val_loss: 0.0019 - val_mae: 0.0030\n",
      "Epoch 80/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0019 - mae: 0.0040 - val_loss: 0.0019 - val_mae: 0.0056\n",
      "Epoch 81/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0019 - mae: 0.0038 - val_loss: 0.0018 - val_mae: 0.0028\n",
      "Epoch 82/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0018 - mae: 0.0038 - val_loss: 0.0018 - val_mae: 0.0059\n",
      "Epoch 83/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0018 - mae: 0.0041 - val_loss: 0.0017 - val_mae: 0.0029\n",
      "Epoch 84/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0017 - mae: 0.0036 - val_loss: 0.0017 - val_mae: 0.0034\n",
      "Epoch 85/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0017 - mae: 0.0038 - val_loss: 0.0017 - val_mae: 0.0046\n",
      "Epoch 86/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0016 - mae: 0.0040 - val_loss: 0.0016 - val_mae: 0.0028\n",
      "Epoch 87/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0016 - mae: 0.0038 - val_loss: 0.0016 - val_mae: 0.0043\n",
      "Epoch 88/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0016 - mae: 0.0038 - val_loss: 0.0016 - val_mae: 0.0057\n",
      "Epoch 89/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0015 - mae: 0.0039 - val_loss: 0.0015 - val_mae: 0.0051\n",
      "Epoch 90/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0015 - mae: 0.0038 - val_loss: 0.0015 - val_mae: 0.0050\n",
      "Epoch 91/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0015 - mae: 0.0039 - val_loss: 0.0015 - val_mae: 0.0059\n",
      "Epoch 92/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0015 - mae: 0.0040 - val_loss: 0.0015 - val_mae: 0.0062\n",
      "Epoch 93/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0014 - mae: 0.0038 - val_loss: 0.0014 - val_mae: 0.0049\n",
      "Epoch 94/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0014 - mae: 0.0039 - val_loss: 0.0014 - val_mae: 0.0040\n",
      "Epoch 95/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0014 - mae: 0.0037 - val_loss: 0.0014 - val_mae: 0.0062\n",
      "Epoch 96/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0014 - mae: 0.0040 - val_loss: 0.0014 - val_mae: 0.0034\n",
      "Epoch 97/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0037 - val_loss: 0.0013 - val_mae: 0.0041\n",
      "Epoch 98/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0038 - val_loss: 0.0014 - val_mae: 0.0076\n",
      "Epoch 99/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0039 - val_loss: 0.0013 - val_mae: 0.0030\n",
      "Epoch 100/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0039 - val_loss: 0.0013 - val_mae: 0.0048\n",
      "Epoch 101/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0039 - val_loss: 0.0013 - val_mae: 0.0057\n",
      "Epoch 102/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0036 - val_loss: 0.0013 - val_mae: 0.0035\n",
      "Epoch 103/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0038 - val_loss: 0.0012 - val_mae: 0.0029\n",
      "Epoch 104/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0040 - val_loss: 0.0013 - val_mae: 0.0074\n",
      "Epoch 105/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0037 - val_loss: 0.0012 - val_mae: 0.0033\n",
      "Epoch 106/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0038 - val_loss: 0.0012 - val_mae: 0.0059\n",
      "Epoch 107/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0039 - val_loss: 0.0012 - val_mae: 0.0037\n",
      "Epoch 108/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0038 - val_loss: 0.0012 - val_mae: 0.0030\n",
      "Epoch 109/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0039 - val_loss: 0.0012 - val_mae: 0.0070\n",
      "Epoch 110/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0038 - val_loss: 0.0012 - val_mae: 0.0032\n",
      "Epoch 111/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0038 - val_loss: 0.0012 - val_mae: 0.0084\n",
      "Epoch 112/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0038 - val_loss: 0.0012 - val_mae: 0.0039\n",
      "Epoch 113/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 114/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0044\n",
      "Epoch 115/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0038 - val_loss: 0.0011 - val_mae: 0.0047\n",
      "Epoch 116/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0038 - val_loss: 0.0011 - val_mae: 0.0031\n",
      "Epoch 117/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0038 - val_loss: 0.0011 - val_mae: 0.0033\n",
      "Epoch 118/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0048\n",
      "Epoch 119/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0040 - val_loss: 0.0011 - val_mae: 0.0068\n",
      "Epoch 120/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0039\n",
      "Epoch 121/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0037 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 122/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0031\n",
      "Epoch 123/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0040 - val_loss: 0.0011 - val_mae: 0.0036\n",
      "Epoch 124/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0037 - val_loss: 0.0011 - val_mae: 0.0058\n",
      "Epoch 125/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0038 - val_loss: 0.0011 - val_mae: 0.0039\n",
      "Epoch 126/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0038 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 127/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0028\n",
      "Epoch 128/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0037 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 129/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0010 - val_mae: 0.0030\n",
      "Epoch 130/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0010 - val_mae: 0.0031\n",
      "Epoch 131/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0045\n",
      "Epoch 132/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0038 - val_loss: 0.0010 - val_mae: 0.0031\n",
      "Epoch 133/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0039 - val_loss: 0.0010 - val_mae: 0.0043\n",
      "Epoch 134/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0037 - val_loss: 0.0011 - val_mae: 0.0054\n",
      "Epoch 135/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0039 - val_loss: 0.0010 - val_mae: 0.0046\n",
      "Epoch 136/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0038 - val_loss: 0.0011 - val_mae: 0.0071\n",
      "Epoch 137/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0038 - val_loss: 0.0010 - val_mae: 0.0033\n",
      "Epoch 138/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0037 - val_loss: 0.0010 - val_mae: 0.0058\n",
      "Epoch 139/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0036 - val_loss: 0.0010 - val_mae: 0.0034\n",
      "Epoch 140/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0038 - val_loss: 0.0010 - val_mae: 0.0031\n",
      "Epoch 141/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0038 - val_loss: 0.0010 - val_mae: 0.0050\n",
      "Epoch 142/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0038 - val_loss: 9.9411e-04 - val_mae: 0.0027\n",
      "Epoch 143/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0037 - val_loss: 9.9328e-04 - val_mae: 0.0031\n",
      "Epoch 144/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.9810e-04 - mae: 0.0038 - val_loss: 0.0011 - val_mae: 0.0087\n",
      "Epoch 145/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.9596e-04 - mae: 0.0038 - val_loss: 0.0010 - val_mae: 0.0050\n",
      "Epoch 146/400\n",
      "645/645 [==============================] - 2s 3ms/step - loss: 9.9221e-04 - mae: 0.0038 - val_loss: 9.8358e-04 - val_mae: 0.0031\n",
      "Epoch 147/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.8872e-04 - mae: 0.0038 - val_loss: 9.9471e-04 - val_mae: 0.0048\n",
      "Epoch 148/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.8690e-04 - mae: 0.0039 - val_loss: 9.8245e-04 - val_mae: 0.0037\n",
      "Epoch 149/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.8401e-04 - mae: 0.0038 - val_loss: 9.9672e-04 - val_mae: 0.0049\n",
      "Epoch 150/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.8033e-04 - mae: 0.0038 - val_loss: 9.7778e-04 - val_mae: 0.0040\n",
      "Epoch 151/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.7815e-04 - mae: 0.0038 - val_loss: 9.8494e-04 - val_mae: 0.0048\n",
      "Epoch 152/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.7429e-04 - mae: 0.0037 - val_loss: 9.7258e-04 - val_mae: 0.0037\n",
      "Epoch 153/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.7129e-04 - mae: 0.0037 - val_loss: 9.8661e-04 - val_mae: 0.0055\n",
      "Epoch 154/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.6786e-04 - mae: 0.0036 - val_loss: 9.5856e-04 - val_mae: 0.0028\n",
      "Epoch 155/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.6459e-04 - mae: 0.0036 - val_loss: 9.7098e-04 - val_mae: 0.0045\n",
      "Epoch 156/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.6689e-04 - mae: 0.0040 - val_loss: 9.6207e-04 - val_mae: 0.0040\n",
      "Epoch 157/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.5954e-04 - mae: 0.0036 - val_loss: 9.4956e-04 - val_mae: 0.0026\n",
      "Epoch 158/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.6213e-04 - mae: 0.0039 - val_loss: 9.6913e-04 - val_mae: 0.0050\n",
      "Epoch 159/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.5613e-04 - mae: 0.0036 - val_loss: 9.4499e-04 - val_mae: 0.0025\n",
      "Epoch 160/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.5393e-04 - mae: 0.0037 - val_loss: 9.5718e-04 - val_mae: 0.0045\n",
      "Epoch 161/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.5001e-04 - mae: 0.0036 - val_loss: 9.5709e-04 - val_mae: 0.0047\n",
      "Epoch 162/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.5132e-04 - mae: 0.0039 - val_loss: 9.3777e-04 - val_mae: 0.0027\n",
      "Epoch 163/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.4763e-04 - mae: 0.0038 - val_loss: 0.0011 - val_mae: 0.0093\n",
      "Epoch 164/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.4716e-04 - mae: 0.0039 - val_loss: 9.3608e-04 - val_mae: 0.0030\n",
      "Epoch 165/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.4227e-04 - mae: 0.0036 - val_loss: 9.4769e-04 - val_mae: 0.0044\n",
      "Epoch 166/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.4026e-04 - mae: 0.0037 - val_loss: 9.5310e-04 - val_mae: 0.0052\n",
      "Epoch 167/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.3886e-04 - mae: 0.0037 - val_loss: 9.7626e-04 - val_mae: 0.0066\n",
      "Epoch 168/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.3948e-04 - mae: 0.0039 - val_loss: 9.5747e-04 - val_mae: 0.0056\n",
      "Epoch 169/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.3437e-04 - mae: 0.0036 - val_loss: 9.2650e-04 - val_mae: 0.0032\n",
      "Epoch 170/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.3222e-04 - mae: 0.0036 - val_loss: 9.3084e-04 - val_mae: 0.0037\n",
      "Epoch 171/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.2972e-04 - mae: 0.0036 - val_loss: 9.2543e-04 - val_mae: 0.0034\n",
      "Epoch 172/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.3065e-04 - mae: 0.0038 - val_loss: 9.3563e-04 - val_mae: 0.0046\n",
      "Epoch 173/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.2649e-04 - mae: 0.0036 - val_loss: 9.8822e-04 - val_mae: 0.0083\n",
      "Epoch 174/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.2592e-04 - mae: 0.0037 - val_loss: 9.3424e-04 - val_mae: 0.0047\n",
      "Epoch 175/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.2413e-04 - mae: 0.0038 - val_loss: 9.1234e-04 - val_mae: 0.0027\n",
      "Epoch 176/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.2247e-04 - mae: 0.0038 - val_loss: 9.1418e-04 - val_mae: 0.0031\n",
      "Epoch 177/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.2107e-04 - mae: 0.0038 - val_loss: 9.2371e-04 - val_mae: 0.0043\n",
      "Epoch 178/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.1625e-04 - mae: 0.0035 - val_loss: 9.1026e-04 - val_mae: 0.0029\n",
      "Epoch 179/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.1826e-04 - mae: 0.0038 - val_loss: 9.3930e-04 - val_mae: 0.0052\n",
      "Epoch 180/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.1423e-04 - mae: 0.0036 - val_loss: 9.4211e-04 - val_mae: 0.0061\n",
      "Epoch 181/400\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 9.1283e-04 - mae: 0.0036 - val_loss: 9.9951e-04 - val_mae: 0.0091\n",
      "Epoch 182/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.1128e-04 - mae: 0.0036 - val_loss: 9.0298e-04 - val_mae: 0.0028\n",
      "Epoch 183/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.1384e-04 - mae: 0.0040 - val_loss: 9.0859e-04 - val_mae: 0.0035\n",
      "Epoch 184/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.0628e-04 - mae: 0.0035 - val_loss: 8.9793e-04 - val_mae: 0.0027\n",
      "Epoch 185/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.0823e-04 - mae: 0.0038 - val_loss: 9.1072e-04 - val_mae: 0.0040\n",
      "Epoch 186/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.0547e-04 - mae: 0.0037 - val_loss: 9.0744e-04 - val_mae: 0.0040\n",
      "Epoch 187/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.0379e-04 - mae: 0.0037 - val_loss: 9.5096e-04 - val_mae: 0.0076\n",
      "Epoch 188/400\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.0737e-04 - mae: 0.0040 - val_loss: 9.6448e-04 - val_mae: 0.0086\n",
      "Epoch 189/400\n",
      "637/645 [============================>.] - ETA: 0s - loss: 9.0221e-04 - mae: 0.0037Restoring model weights from the end of the best epoch: 184.\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 9.0249e-04 - mae: 0.0037 - val_loss: 9.5694e-04 - val_mae: 0.0083\n",
      "Epoch 189: early stopping\n",
      "Die Ausführungszeit betrug 345.4478051662445 Sekunden.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Netzwerkarchitektur\n",
    "model = Sequential([\n",
    "    # Eingabeschicht\n",
    "\n",
    "    Dense(256, activation='relu', input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "    Dense(128, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "    Dense(160, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "    Dense(224, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "    Dense(112, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "    Dense(320, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(16, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(112, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    #Dense(240, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    #Dense(48, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(1 , activation = 'linear')\n",
    "])\n",
    "\n",
    "# Optimierer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "# Modell kompilieren (Verwendung von mean_squared_error als Verlustfunktion für Regression)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])  # Metriken für Regression: Mean Absolute Error und Mean Squared Error\n",
    "\n",
    "# Early Stopping Callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=2, mode='min', restore_best_weights=True)#, min_delta = 0.00005)\n",
    "\n",
    "# Trainingsparameter\n",
    "batch_size = 100\n",
    "epochs = 400\n",
    "\n",
    "# Modell trainieren (Annahme: X_train, y_train, X_val, y_val sind vordefiniert)\n",
    "history = model.fit(X_train_scaled, y_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose = 1)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Berechne die Dauer\n",
    "duration = end_time - start_time\n",
    "\n",
    "print(f\"Die Ausführungszeit betrug {duration} Sekunden.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T16:08:03.198726500Z",
     "start_time": "2024-03-14T16:02:17.736612900Z"
    }
   },
   "id": "8b52e1a9a6ff3aeb"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 - 1s - loss: 8.9852e-04 - mae: 0.0027 - 642ms/epoch - 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.0008985208696685731, 0.0027488218620419502]"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test_scaled, y_test_scaled, verbose=2)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T16:08:03.904209500Z",
     "start_time": "2024-03-14T16:08:03.198726500Z"
    }
   },
   "id": "68d86893ad985b02"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f6f672a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T16:08:04.688516600Z",
     "start_time": "2024-03-14T16:08:03.881209600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bsp. Predicted: [1193.7445] Actual: [1195.9] \n",
      "Durchschnittliche Abweichung (MAE): [2.60533657]\n"
     ]
    }
   ],
   "source": [
    "scaled_predicted_values = model.predict(X_test_scaled, verbose = 0)\n",
    "\n",
    "# Führen Sie die Rücktransformation der skalierten Werte durch\n",
    "original_predicted_values = scaler_target.inverse_transform(scaled_predicted_values)\n",
    "original_actual_values = scaler_target.inverse_transform(y_test_scaled)  # y_test sind die skalierten tatsächlichen Werte\n",
    "print(f' Bsp. Predicted: {original_predicted_values[1000]} Actual: {original_actual_values[1000]} ')\n",
    "\n",
    "def calculate_mae(list1, list2):\n",
    "    # Stelle sicher, dass beide Listen die gleiche Länge haben\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Listen müssen die gleiche Länge haben\")\n",
    "\n",
    "    # Berechne die absolute Differenz zwischen den Elementen der Listen\n",
    "    differences = [abs(x - y) for x, y in zip(list1, list2)]\n",
    "\n",
    "    # Berechne den Durchschnitt der absoluten Differenzen\n",
    "    mae = sum(differences) / len(differences)\n",
    "\n",
    "    return mae\n",
    "\n",
    "# Beispiel\n",
    "list1 = original_predicted_values\n",
    "list2 = original_actual_values\n",
    "\n",
    "mae = calculate_mae(list1, list2)\n",
    "print(f\"Durchschnittliche Abweichung (MAE): {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: [0.99978783]\n"
     ]
    }
   ],
   "source": [
    "def calculate_r_squared(predicted, actual):\n",
    "    # Berechnung des Mittelwerts der tatsächlichen Werte\n",
    "    mean_actual = sum(actual) / len(actual)\n",
    "    \n",
    "    # Berechnung der totalen Summe der Quadrate (SST)\n",
    "    sst = sum((x - mean_actual) ** 2 for x in actual)\n",
    "    \n",
    "    # Berechnung der Summe der Quadrate der Residuen (SSE)\n",
    "    sse = sum((actual[i] - predicted[i]) ** 2 for i in range(len(actual)))\n",
    "    \n",
    "    # Berechnung des R^2-Wertes\n",
    "    r_squared = 1 - (sse / sst)\n",
    "    \n",
    "    return r_squared\n",
    "\n",
    "# Berechnung von R^2 mit den bereitgestellten Listen\n",
    "r_squared = calculate_r_squared(list1, list2)\n",
    "\n",
    "print(f\"R^2: {r_squared}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T16:08:04.797830700Z",
     "start_time": "2024-03-14T16:08:04.690516400Z"
    }
   },
   "id": "48ac8cdcc05e55fd"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Werte die kleiner sind: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": "             Echt  Vorhergesagt  X-Koordinate  Y-Koordinate  Differenz\n19281  777.887451        807.84         1.000        0.9125 -29.952549\n14143  802.839111        832.75         1.000        0.9025 -29.910889\n16514  809.072205        838.63         1.000        0.9000 -29.557795\n4177   815.301086        844.45         1.000        0.8975 -29.148914\n16594  827.754272        855.66         1.000        0.8925 -27.905728\n...           ...           ...           ...           ...        ...\n15061  608.071289        587.18         0.956        0.9775  20.891289\n11939  608.316162        586.88         0.964        0.9775  21.436162\n14839  621.090210        599.38         0.956        0.9725  21.710210\n13809  615.559082        593.15         0.988        0.9750  22.409082\n20012  615.804016        588.92         0.996        0.9750  26.884016\n\n[20131 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Echt</th>\n      <th>Vorhergesagt</th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Differenz</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>19281</th>\n      <td>777.887451</td>\n      <td>807.84</td>\n      <td>1.000</td>\n      <td>0.9125</td>\n      <td>-29.952549</td>\n    </tr>\n    <tr>\n      <th>14143</th>\n      <td>802.839111</td>\n      <td>832.75</td>\n      <td>1.000</td>\n      <td>0.9025</td>\n      <td>-29.910889</td>\n    </tr>\n    <tr>\n      <th>16514</th>\n      <td>809.072205</td>\n      <td>838.63</td>\n      <td>1.000</td>\n      <td>0.9000</td>\n      <td>-29.557795</td>\n    </tr>\n    <tr>\n      <th>4177</th>\n      <td>815.301086</td>\n      <td>844.45</td>\n      <td>1.000</td>\n      <td>0.8975</td>\n      <td>-29.148914</td>\n    </tr>\n    <tr>\n      <th>16594</th>\n      <td>827.754272</td>\n      <td>855.66</td>\n      <td>1.000</td>\n      <td>0.8925</td>\n      <td>-27.905728</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15061</th>\n      <td>608.071289</td>\n      <td>587.18</td>\n      <td>0.956</td>\n      <td>0.9775</td>\n      <td>20.891289</td>\n    </tr>\n    <tr>\n      <th>11939</th>\n      <td>608.316162</td>\n      <td>586.88</td>\n      <td>0.964</td>\n      <td>0.9775</td>\n      <td>21.436162</td>\n    </tr>\n    <tr>\n      <th>14839</th>\n      <td>621.090210</td>\n      <td>599.38</td>\n      <td>0.956</td>\n      <td>0.9725</td>\n      <td>21.710210</td>\n    </tr>\n    <tr>\n      <th>13809</th>\n      <td>615.559082</td>\n      <td>593.15</td>\n      <td>0.988</td>\n      <td>0.9750</td>\n      <td>22.409082</td>\n    </tr>\n    <tr>\n      <th>20012</th>\n      <td>615.804016</td>\n      <td>588.92</td>\n      <td>0.996</td>\n      <td>0.9750</td>\n      <td>26.884016</td>\n    </tr>\n  </tbody>\n</table>\n<p>20131 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame({'Echt': [val[0] for val in list1], 'Vorhergesagt': [val[0] for val in list2]})\n",
    "df_result['X-Koordinate'] = X_test_scaled[:, 0]\n",
    "df_result['Y-Koordinate'] = X_test_scaled[:, 1]\n",
    "\n",
    "df_result['Differenz'] = df_result['Echt'] - df_result['Vorhergesagt']\n",
    "df_result['Differenz'].sort_values()\n",
    "sorted_df = df_result.sort_values(by= 'Differenz')\n",
    "Anzahl_Punkte = (sorted_df['Differenz'] > 20).sum()\n",
    "print(\"Anzahl der Werte die kleiner sind:\", Anzahl_Punkte)\n",
    "\n",
    "sorted_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T16:08:04.827234900Z",
     "start_time": "2024-03-14T16:08:04.796830700Z"
    }
   },
   "id": "42bde60d3b4f2007"
  },
  {
   "cell_type": "markdown",
   "id": "553df6fa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mae = history.history['loss']\n",
    "val_mae = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(mae) + 1)\n",
    "# MAE Diagramm\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, mae, 'r', label='Training MSE')\n",
    "plt.plot(epochs, val_mae, 'b', label='Validation MSE')\n",
    "plt.title('Training and Validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T16:08:04.956265300Z",
     "start_time": "2024-03-14T16:08:04.825234900Z"
    }
   },
   "id": "3688dd7102e95baf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# GridSearch\n",
    "Grid Search bietet die Vorteile der anpassbaren Rechenzeit sowie die Möglichkeit des EInsatzes von Verteilungen. So können theoretisch Hyperparamterkonfuigurationen gefunden wende, welche durch GridSearch nicht auffindbar wären. ZUdem ist das Ziel der Hyperparamteroptimierung eine Einstellung zu finden, welche auf Trainings und Testset gut angepasst ist. Die EInstellung muss nicht die bestmöglichste Einstellung sein, sondern eine Einstellung die das gewähltre Problem gut wiederspiegelt. \n",
    "Bayesian Optimierung"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c177960cc729052"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f17e2cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T16:08:04.960266400Z",
     "start_time": "2024-03-14T16:08:04.958265800Z"
    }
   },
   "outputs": [],
   "source": [
    "# def build_model(learning_rate=0.001, activation='relu', regularization=0.0001, dropout_rate=0.0):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(320, activation=activation, input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(176, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(288, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(192, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(208, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(224, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(80, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(304, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate)) \n",
    "# \n",
    "#     model.add(Dense(240, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))   \n",
    "# \n",
    "#     model.add(Dense(48, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mae'])\n",
    "#     return model\n",
    "# \n",
    "# # Verwenden Sie eine Funktion, um das Modell zu instanziieren, für scikit-learn Wrapper\n",
    "# model = KerasRegressor(model=build_model, verbose=2)\n",
    "# \n",
    "# # Anpassung der Parameter im param_grid\n",
    "# param_grid = {\n",
    "#     'model__learning_rate': [0.01, 0.001, 0.0001],\n",
    "#     'model__regularization': [0.001, 0.0001],\n",
    "#     'fit__batch_size': [100, 200, 400, 800],\n",
    "#     'fit__epochs': [50],\n",
    "#     'model__dropout_rate' : [0.0, 0.1, 0.2]\n",
    "# }\n",
    "# \n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=2)\n",
    "# # Hinweis: Stellen Sie sicher, dass Ihre Daten (X_train_scaled, y_train_scaled) korrekt definiert sind\n",
    "# grid_result = grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "# # Beste Parameter und Score ausgeben\n",
    "# print(\"Beste Parameter:\", grid_search.best_params_)\n",
    "# print(\"Beste Genauigkeit:\", grid_search.best_score_)\n",
    "# \n",
    "# with open(\"grid_search_D1_2.txt\", \"w\") as f:\n",
    "#     f.write(f\"Beste Parameter: {grid_search.best_params_}\\n\")\n",
    "#     f.write(f\"Beste Genauigkeit: {grid_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "  # Bayesian Optimization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bb41910a42cbdee"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# from bayes_opt import BayesianOptimization\n",
    "# \n",
    "# \n",
    "# # Angenommene Daten\n",
    "# # X_train_scaled, y_train_scaled = # Deine skalierten Trainingsdaten\n",
    "# \n",
    "# def train_evaluate(neurons_layer_1, neurons_layer_2, neurons_layer_3, neurons_layer_4, neurons_layer_5, learning_rate):\n",
    "#     model = Sequential([\n",
    "#         Dense(int(neurons_layer_1), activation='relu', input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "#         Dense(int(neurons_layer_2), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "#         Dense(int(neurons_layer_3), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "#         Dense(int(neurons_layer_4), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "#         Dense(int(neurons_layer_5), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "#         \n",
    "#         Dense(1, activation='linear')\n",
    "#     ])\n",
    "# \n",
    "#     optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "#     model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "# \n",
    "#     early_stopping = EarlyStopping(monitor='loss', patience=5, verbose=1, mode='min', restore_best_weights=True, min_delta=0.0001)\n",
    "# \n",
    "#     history = model.fit(X_train_scaled, y_train_scaled, batch_size=32, epochs=100, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
    "# \n",
    "#     # Hier wählen wir den negativen Mean Squared Error, da Bayesian Optimization maximiert\n",
    "#     mse = np.min(history.history['val_loss'])\n",
    "#     return -mse\n",
    "# \n",
    "# # Definieren des Bereichs der Hyperparameter\n",
    "# pbounds = {\n",
    "#     'neurons_layer_1': (16, 200),\n",
    "#     'neurons_layer_2': (16, 200),\n",
    "#     'neurons_layer_3': (16, 200),\n",
    "#     'neurons_layer_4': (16, 200),\n",
    "#     'neurons_layer_5': (16, 200),\n",
    "#     'learning_rate': (0.0001, 0.01),\n",
    "# }\n",
    "# \n",
    "# # Initialisieren des BayesianOptimization-Objekts\n",
    "# optimizer = BayesianOptimization(\n",
    "#     f=train_evaluate,\n",
    "#     pbounds=pbounds,\n",
    "#     random_state=1,\n",
    "# )\n",
    "# \n",
    "# # Starten der Optimierung\n",
    "# optimizer.maximize(init_points=2, n_iter=20)\n",
    "# \n",
    "# print(optimizer.max)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T16:08:04.964272300Z",
     "start_time": "2024-03-14T16:08:04.961265900Z"
    }
   },
   "id": "a5b6232547cdae67"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Search Architektur\n",
    "Tiefes Netz besser als breites Netz; Layer lernen auf unterschiedliche Weise"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75773dfef8260e5f"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# # Funktion zum Erstellen des Modells\n",
    "# def build_model(hp):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(hp.Int('input_units', min_value=16, max_value=328, step=16), input_shape=(2,), activation='relu'))\n",
    "#     for i in range(hp.Int('n_layers', 1, 10)):\n",
    "#         model.add(Dense(hp.Int(f'units_{i}', min_value=16, max_value=328, step=16), activation='relu'))\n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     return model\n",
    "# \n",
    "# # Durchführung der Random Search dreimal\n",
    "# for run in range(1, 4):\n",
    "#     # Anpassen des Verzeichnisses und des Projektnamens für jeden Durchlauf\n",
    "#     directory = 'random_search'\n",
    "#     project_name = f'random_search_D1_{run}'\n",
    "# \n",
    "#     tuner = RandomSearch(\n",
    "#         build_model,\n",
    "#         objective='val_loss',\n",
    "#         max_trials=100,\n",
    "#         executions_per_trial=1,\n",
    "#         directory=directory,\n",
    "#         project_name=project_name\n",
    "#     )\n",
    "# \n",
    "#     # Durchführung des Random Search\n",
    "#     tuner.search(X_train_scaled, y_train_scaled, epochs=50, verbose =0, batch_size=500, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "# \n",
    "#     # Abrufen und Speichern des besten Modells\n",
    "#     best_model = tuner.get_best_models(num_models=1)[0]\n",
    "#     model_path = os.path.join(directory, project_name, 'best_model.h5') \n",
    "#     best_model.save(model_path)\n",
    "# \n",
    "# \n",
    "#     # Optional: Abrufen und Ausgeben der besten Hyperparameter\n",
    "#     best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "# \n",
    "#     # Konvertieren der Hyperparameter in ein DataFrame\n",
    "#     df_hyperparameters = pd.DataFrame([best_hyperparameters.values])\n",
    "#     # Speichern des DataFrame als CSV\n",
    "#     df_hyperparameters.to_csv(f'random_search_D1_{run}.csv', index=False)\n",
    "#     best_model.describe()\n",
    "#     print(f\"Beste Hyperparameter für Lauf {run}: {best_hyperparameters.values}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T16:08:04.969305400Z",
     "start_time": "2024-03-14T16:08:04.965272900Z"
    }
   },
   "id": "158d81fabf560fc4"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T16:08:04.972392100Z",
     "start_time": "2024-03-14T16:08:04.970416500Z"
    }
   },
   "id": "6f86db4f21a8c913"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T16:08:04.973908800Z",
     "start_time": "2024-03-14T16:08:04.971415200Z"
    }
   },
   "id": "2a8e01cea48e945f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
