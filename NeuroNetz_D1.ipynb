{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94b0518e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T12:32:58.066098Z",
     "start_time": "2024-03-13T12:32:57.967015300Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense , Dropout\n",
    "from scikeras.wrappers import KerasRegressor \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4ff61b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T12:32:58.133097700Z",
     "start_time": "2024-03-13T12:32:57.971361100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n0             0.0000      -0.00200        500   7000   9000      669.05\n1             0.0000      -0.00199        500   7000   9000      675.83\n2             0.0000      -0.00198        500   7000   9000      682.81\n3             0.0000      -0.00197        500   7000   9000      689.82\n4             0.0000      -0.00196        500   7000   9000      696.80\n...              ...           ...        ...    ...    ...         ...\n100646        0.0025       0.00196        500   7000   9000      578.47\n100647        0.0025       0.00197        500   7000   9000      576.89\n100648        0.0025       0.00198        500   7000   9000      575.32\n100649        0.0025       0.00199        500   7000   9000      573.76\n100650        0.0025       0.00200        500   7000   9000      572.20\n\n[100651 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>669.05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0000</td>\n      <td>-0.00199</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>675.83</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0000</td>\n      <td>-0.00198</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>682.81</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0000</td>\n      <td>-0.00197</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>689.82</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0000</td>\n      <td>-0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>696.80</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>100646</th>\n      <td>0.0025</td>\n      <td>0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>578.47</td>\n    </tr>\n    <tr>\n      <th>100647</th>\n      <td>0.0025</td>\n      <td>0.00197</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>576.89</td>\n    </tr>\n    <tr>\n      <th>100648</th>\n      <td>0.0025</td>\n      <td>0.00198</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>575.32</td>\n    </tr>\n    <tr>\n      <th>100649</th>\n      <td>0.0025</td>\n      <td>0.00199</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>573.76</td>\n    </tr>\n    <tr>\n      <th>100650</th>\n      <td>0.0025</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>572.20</td>\n    </tr>\n  </tbody>\n</table>\n<p>100651 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/TPath_300_finish_data.pkl')\n",
    "data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_D1_I7000_F9000/TPath_500_finish_data_D1.pkl')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "966e3c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T12:32:58.154097400Z",
     "start_time": "2024-03-13T12:32:57.980308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "count    100651.000000\nmean       1144.030064\nstd         264.135723\nmin         572.200000\n25%         937.330000\n50%        1201.100000\n75%        1368.700000\nmax        1520.000000\nName: Temperatur, dtype: float64"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.drop(data.columns[2:5], axis = 1)\n",
    "df['Temperatur'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8783d1d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T12:32:58.225098100Z",
     "start_time": "2024-03-13T12:32:57.989833200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       X-Koordinate  Y-Koordinate  Temperatur\n",
      "83145       0.00207      -0.00062      1282.2\n",
      "66701       0.00166      -0.00065      1347.6\n",
      "91325       0.00227       0.00098      1094.6\n",
      "46593       0.00116      -0.00123      1175.7\n",
      "49518       0.00123      -0.00005      1459.2\n",
      "...             ...           ...         ...\n",
      "6265        0.00015       0.00050      1439.1\n",
      "54886       0.00136       0.00150       876.7\n",
      "76820       0.00191       0.00029      1335.8\n",
      "860         0.00002      -0.00142      1071.2\n",
      "15795       0.00039      -0.00044      1488.1\n",
      "\n",
      "[100651 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate  Temperatur\n0            0.00207      -0.00062      1282.2\n1            0.00166      -0.00065      1347.6\n2            0.00227       0.00098      1094.6\n3            0.00116      -0.00123      1175.7\n4            0.00123      -0.00005      1459.2\n...              ...           ...         ...\n100646       0.00015       0.00050      1439.1\n100647       0.00136       0.00150       876.7\n100648       0.00191       0.00029      1335.8\n100649       0.00002      -0.00142      1071.2\n100650       0.00039      -0.00044      1488.1\n\n[100651 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00207</td>\n      <td>-0.00062</td>\n      <td>1282.2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00166</td>\n      <td>-0.00065</td>\n      <td>1347.6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00227</td>\n      <td>0.00098</td>\n      <td>1094.6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00116</td>\n      <td>-0.00123</td>\n      <td>1175.7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00123</td>\n      <td>-0.00005</td>\n      <td>1459.2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>100646</th>\n      <td>0.00015</td>\n      <td>0.00050</td>\n      <td>1439.1</td>\n    </tr>\n    <tr>\n      <th>100647</th>\n      <td>0.00136</td>\n      <td>0.00150</td>\n      <td>876.7</td>\n    </tr>\n    <tr>\n      <th>100648</th>\n      <td>0.00191</td>\n      <td>0.00029</td>\n      <td>1335.8</td>\n    </tr>\n    <tr>\n      <th>100649</th>\n      <td>0.00002</td>\n      <td>-0.00142</td>\n      <td>1071.2</td>\n    </tr>\n    <tr>\n      <th>100650</th>\n      <td>0.00039</td>\n      <td>-0.00044</td>\n      <td>1488.1</td>\n    </tr>\n  </tbody>\n</table>\n<p>100651 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.sample(frac=1, random_state=42)  # Hier wird 42 als Random State verwendet, um die Ergebnisse reproduzierbar zu machen\n",
    "\n",
    "print(df1)\n",
    "df_reset = df1.reset_index(drop=True)\n",
    "df_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4e72a16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T12:32:58.228098200Z",
     "start_time": "2024-03-13T12:32:58.005747800Z"
    }
   },
   "outputs": [],
   "source": [
    "label = df_reset[\"Temperatur\"]\n",
    "# Korrektur: Verwenden Sie den Spaltennamen direkt, ohne Indexierung der columns-Eigenschaft\n",
    "df1 = df_reset.drop(\"Temperatur\", axis=1)\n",
    "X = df1\n",
    "y = label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7fa289a50d87423"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e694a236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T12:32:58.228098200Z",
     "start_time": "2024-03-13T12:32:58.010104800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate\ncount  100651.000000  1.006510e+05\nmean        0.001250  1.103042e-20\nstd         0.000725  1.157589e-03\nmin         0.000000 -2.000000e-03\n25%         0.000620 -1.000000e-03\n50%         0.001250  4.529900e-18\n75%         0.001880  1.000000e-03\nmax         0.002500  2.000000e-03",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>100651.000000</td>\n      <td>1.006510e+05</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.001250</td>\n      <td>1.103042e-20</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.000725</td>\n      <td>1.157589e-03</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-2.000000e-03</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000620</td>\n      <td>-1.000000e-03</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.001250</td>\n      <td>4.529900e-18</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.001880</td>\n      <td>1.000000e-03</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.002500</td>\n      <td>2.000000e-03</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f3303b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T12:32:58.228098200Z",
     "start_time": "2024-03-13T12:32:58.023985300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "count    100651.000000\nmean       1144.030064\nstd         264.135723\nmin         572.200000\n25%         937.330000\n50%        1201.100000\n75%        1368.700000\nmax        1520.000000\nName: Temperatur, dtype: float64"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3ad8da0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T12:32:58.228098200Z",
     "start_time": "2024-03-13T12:32:58.032587300Z"
    }
   },
   "outputs": [],
   "source": [
    " # train_df enthält 80% der Daten, test_df enthält 20% der Daten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c705edb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T12:32:58.228098200Z",
     "start_time": "2024-03-13T12:32:58.042296900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialisiere einen MinMaxScaler für die Features\n",
    "scaler_features = MinMaxScaler()\n",
    "scaler_features2 = MinMaxScaler()\n",
    "# Skaliere X_train und X_test\n",
    "X_train_scaled = scaler_features.fit_transform(X_train)\n",
    "X_test_scaled = scaler_features.transform(X_test)  # Nutze unterschiedliche Skalierungsparameter\n",
    "\n",
    "# Initialisiere einen SEPARATEN MinMaxScaler für das Ziel, wenn nötig\n",
    "scaler_target = MinMaxScaler()\n",
    "\n",
    "\n",
    "# Skaliere y_train und y_test. Beachte, dass y_train.reshape(-1, 1) verwendet wird, da MinMaxScaler \n",
    "# erwartet, dass die Eingaben als 2D-Arrays kommen, und Ziele normalerweise als 1D-Arrays vorliegen.\n",
    "y_train_scaled = scaler_target.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test_scaled = scaler_target.transform(y_test.values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbefe631e495b483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T12:32:58.229098200Z",
     "start_time": "2024-03-13T12:32:58.049988300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.416 , 0.5725],\n       [0.812 , 0.7325],\n       [0.628 , 0.5075],\n       ...,\n       [0.604 , 0.3875],\n       [0.748 , 0.65  ],\n       [0.028 , 0.6225]])"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "81/81 [==============================] - 2s 13ms/step - loss: 0.4404 - mae: 0.2371 - val_loss: 0.2823 - val_mae: 0.0896\n",
      "Epoch 2/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.2469 - mae: 0.0336 - val_loss: 0.2269 - val_mae: 0.0138\n",
      "Epoch 3/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.2184 - mae: 0.0229 - val_loss: 0.2103 - val_mae: 0.0243\n",
      "Epoch 4/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.2042 - mae: 0.0197 - val_loss: 0.1987 - val_mae: 0.0227\n",
      "Epoch 5/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.1937 - mae: 0.0154 - val_loss: 0.1888 - val_mae: 0.0097\n",
      "Epoch 6/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.1853 - mae: 0.0187 - val_loss: 0.1806 - val_mae: 0.0099\n",
      "Epoch 7/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.1773 - mae: 0.0162 - val_loss: 0.1730 - val_mae: 0.0076\n",
      "Epoch 8/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.1697 - mae: 0.0096 - val_loss: 0.1667 - val_mae: 0.0209\n",
      "Epoch 9/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.1632 - mae: 0.0136 - val_loss: 0.1596 - val_mae: 0.0074\n",
      "Epoch 10/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.1569 - mae: 0.0124 - val_loss: 0.1535 - val_mae: 0.0043\n",
      "Epoch 11/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.1513 - mae: 0.0135 - val_loss: 0.1478 - val_mae: 0.0033\n",
      "Epoch 12/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.1452 - mae: 0.0072 - val_loss: 0.1423 - val_mae: 0.0049\n",
      "Epoch 13/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.1400 - mae: 0.0110 - val_loss: 0.1376 - val_mae: 0.0170\n",
      "Epoch 14/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.1350 - mae: 0.0116 - val_loss: 0.1322 - val_mae: 0.0035\n",
      "Epoch 15/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.1301 - mae: 0.0109 - val_loss: 0.1276 - val_mae: 0.0069\n",
      "Epoch 16/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.1254 - mae: 0.0091 - val_loss: 0.1231 - val_mae: 0.0092\n",
      "Epoch 17/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.1211 - mae: 0.0104 - val_loss: 0.1188 - val_mae: 0.0096\n",
      "Epoch 18/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.1169 - mae: 0.0120 - val_loss: 0.1146 - val_mae: 0.0049\n",
      "Epoch 19/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.1127 - mae: 0.0096 - val_loss: 0.1106 - val_mae: 0.0033\n",
      "Epoch 20/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.1089 - mae: 0.0114 - val_loss: 0.1070 - val_mae: 0.0136\n",
      "Epoch 21/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.1050 - mae: 0.0085 - val_loss: 0.1031 - val_mae: 0.0091\n",
      "Epoch 22/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.1014 - mae: 0.0088 - val_loss: 0.0994 - val_mae: 0.0035\n",
      "Epoch 23/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0979 - mae: 0.0095 - val_loss: 0.0960 - val_mae: 0.0052\n",
      "Epoch 24/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0945 - mae: 0.0093 - val_loss: 0.0930 - val_mae: 0.0151\n",
      "Epoch 25/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0911 - mae: 0.0068 - val_loss: 0.0894 - val_mae: 0.0043\n",
      "Epoch 26/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0884 - mae: 0.0156 - val_loss: 0.0863 - val_mae: 0.0065\n",
      "Epoch 27/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0848 - mae: 0.0036 - val_loss: 0.0832 - val_mae: 0.0023\n",
      "Epoch 28/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0820 - mae: 0.0110 - val_loss: 0.0803 - val_mae: 0.0047\n",
      "Epoch 29/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0790 - mae: 0.0066 - val_loss: 0.0787 - val_mae: 0.0265\n",
      "Epoch 30/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0762 - mae: 0.0070 - val_loss: 0.0747 - val_mae: 0.0041\n",
      "Epoch 31/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0734 - mae: 0.0063 - val_loss: 0.0720 - val_mae: 0.0071\n",
      "Epoch 32/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0708 - mae: 0.0094 - val_loss: 0.0694 - val_mae: 0.0074\n",
      "Epoch 33/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0683 - mae: 0.0099 - val_loss: 0.0668 - val_mae: 0.0029\n",
      "Epoch 34/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0658 - mae: 0.0101 - val_loss: 0.0644 - val_mae: 0.0065\n",
      "Epoch 35/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0632 - mae: 0.0060 - val_loss: 0.0619 - val_mae: 0.0041\n",
      "Epoch 36/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0610 - mae: 0.0091 - val_loss: 0.0596 - val_mae: 0.0029\n",
      "Epoch 37/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0586 - mae: 0.0092 - val_loss: 0.0573 - val_mae: 0.0054\n",
      "Epoch 38/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0563 - mae: 0.0066 - val_loss: 0.0556 - val_mae: 0.0201\n",
      "Epoch 39/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0542 - mae: 0.0103 - val_loss: 0.0530 - val_mae: 0.0066\n",
      "Epoch 40/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0522 - mae: 0.0107 - val_loss: 0.0509 - val_mae: 0.0064\n",
      "Epoch 41/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0499 - mae: 0.0051 - val_loss: 0.0489 - val_mae: 0.0025\n",
      "Epoch 42/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0483 - mae: 0.0121 - val_loss: 0.0470 - val_mae: 0.0075\n",
      "Epoch 43/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0461 - mae: 0.0056 - val_loss: 0.0450 - val_mae: 0.0024\n",
      "Epoch 44/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0442 - mae: 0.0064 - val_loss: 0.0434 - val_mae: 0.0144\n",
      "Epoch 45/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0425 - mae: 0.0104 - val_loss: 0.0415 - val_mae: 0.0058\n",
      "Epoch 46/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0407 - mae: 0.0073 - val_loss: 0.0398 - val_mae: 0.0109\n",
      "Epoch 47/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0391 - mae: 0.0112 - val_loss: 0.0381 - val_mae: 0.0083\n",
      "Epoch 48/400\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0374 - mae: 0.0088 - val_loss: 0.0366 - val_mae: 0.0118\n",
      "Epoch 49/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0360 - mae: 0.0115 - val_loss: 0.0349 - val_mae: 0.0045\n",
      "Epoch 50/400\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0342 - mae: 0.0059 - val_loss: 0.0334 - val_mae: 0.0045\n",
      "Epoch 51/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0328 - mae: 0.0094 - val_loss: 0.0321 - val_mae: 0.0106\n",
      "Epoch 52/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0313 - mae: 0.0078 - val_loss: 0.0307 - val_mae: 0.0110\n",
      "Epoch 53/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0304 - mae: 0.0137 - val_loss: 0.0304 - val_mae: 0.0301\n",
      "Epoch 54/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0287 - mae: 0.0063 - val_loss: 0.0279 - val_mae: 0.0043\n",
      "Epoch 55/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0273 - mae: 0.0044 - val_loss: 0.0272 - val_mae: 0.0222\n",
      "Epoch 56/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0261 - mae: 0.0073 - val_loss: 0.0259 - val_mae: 0.0190\n",
      "Epoch 57/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0250 - mae: 0.0103 - val_loss: 0.0246 - val_mae: 0.0156\n",
      "Epoch 58/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0239 - mae: 0.0096 - val_loss: 0.0236 - val_mae: 0.0154\n",
      "Epoch 59/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0227 - mae: 0.0067 - val_loss: 0.0221 - val_mae: 0.0064\n",
      "Epoch 60/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0218 - mae: 0.0094 - val_loss: 0.0211 - val_mae: 0.0044\n",
      "Epoch 61/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0207 - mae: 0.0082 - val_loss: 0.0211 - val_mae: 0.0290\n",
      "Epoch 62/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0198 - mae: 0.0093 - val_loss: 0.0191 - val_mae: 0.0039\n",
      "Epoch 63/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0188 - mae: 0.0066 - val_loss: 0.0182 - val_mae: 0.0036\n",
      "Epoch 64/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0182 - mae: 0.0118 - val_loss: 0.0174 - val_mae: 0.0030\n",
      "Epoch 65/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0170 - mae: 0.0056 - val_loss: 0.0165 - val_mae: 0.0052\n",
      "Epoch 66/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0162 - mae: 0.0076 - val_loss: 0.0157 - val_mae: 0.0046\n",
      "Epoch 67/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0155 - mae: 0.0080 - val_loss: 0.0150 - val_mae: 0.0047\n",
      "Epoch 68/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0149 - mae: 0.0105 - val_loss: 0.0143 - val_mae: 0.0039\n",
      "Epoch 69/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0139 - mae: 0.0043 - val_loss: 0.0136 - val_mae: 0.0090\n",
      "Epoch 70/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0133 - mae: 0.0082 - val_loss: 0.0129 - val_mae: 0.0030\n",
      "Epoch 71/400\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0127 - mae: 0.0096 - val_loss: 0.0123 - val_mae: 0.0087\n",
      "Epoch 72/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0120 - mae: 0.0076 - val_loss: 0.0117 - val_mae: 0.0059\n",
      "Epoch 73/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0115 - mae: 0.0085 - val_loss: 0.0111 - val_mae: 0.0033\n",
      "Epoch 74/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0109 - mae: 0.0085 - val_loss: 0.0107 - val_mae: 0.0116\n",
      "Epoch 75/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0105 - mae: 0.0098 - val_loss: 0.0104 - val_mae: 0.0170\n",
      "Epoch 76/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0099 - mae: 0.0079 - val_loss: 0.0099 - val_mae: 0.0165\n",
      "Epoch 77/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0094 - mae: 0.0080 - val_loss: 0.0091 - val_mae: 0.0053\n",
      "Epoch 78/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0089 - mae: 0.0073 - val_loss: 0.0087 - val_mae: 0.0070\n",
      "Epoch 79/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0085 - mae: 0.0095 - val_loss: 0.0082 - val_mae: 0.0035\n",
      "Epoch 80/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0081 - mae: 0.0089 - val_loss: 0.0086 - val_mae: 0.0272\n",
      "Epoch 81/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0078 - mae: 0.0096 - val_loss: 0.0078 - val_mae: 0.0165\n",
      "Epoch 82/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0074 - mae: 0.0080 - val_loss: 0.0071 - val_mae: 0.0035\n",
      "Epoch 83/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0072 - mae: 0.0118 - val_loss: 0.0068 - val_mae: 0.0058\n",
      "Epoch 84/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0066 - mae: 0.0041 - val_loss: 0.0065 - val_mae: 0.0047\n",
      "Epoch 85/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0065 - mae: 0.0108 - val_loss: 0.0062 - val_mae: 0.0041\n",
      "Epoch 86/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0060 - mae: 0.0050 - val_loss: 0.0059 - val_mae: 0.0062\n",
      "Epoch 87/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0059 - mae: 0.0087 - val_loss: 0.0057 - val_mae: 0.0057\n",
      "Epoch 88/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0056 - mae: 0.0069 - val_loss: 0.0054 - val_mae: 0.0045\n",
      "Epoch 89/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0053 - mae: 0.0078 - val_loss: 0.0054 - val_mae: 0.0141\n",
      "Epoch 90/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0053 - mae: 0.0104 - val_loss: 0.0049 - val_mae: 0.0033\n",
      "Epoch 91/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0049 - mae: 0.0058 - val_loss: 0.0047 - val_mae: 0.0030\n",
      "Epoch 92/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0048 - mae: 0.0095 - val_loss: 0.0045 - val_mae: 0.0032\n",
      "Epoch 93/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0046 - mae: 0.0089 - val_loss: 0.0048 - val_mae: 0.0198\n",
      "Epoch 94/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0044 - mae: 0.0075 - val_loss: 0.0042 - val_mae: 0.0035\n",
      "Epoch 95/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0043 - mae: 0.0105 - val_loss: 0.0040 - val_mae: 0.0038\n",
      "Epoch 96/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0043 - mae: 0.0104 - val_loss: 0.0040 - val_mae: 0.0085\n",
      "Epoch 97/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0040 - mae: 0.0079 - val_loss: 0.0038 - val_mae: 0.0035\n",
      "Epoch 98/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0037 - mae: 0.0053 - val_loss: 0.0037 - val_mae: 0.0088\n",
      "Epoch 99/400\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0037 - mae: 0.0079 - val_loss: 0.0035 - val_mae: 0.0051\n",
      "Epoch 100/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0036 - mae: 0.0084 - val_loss: 0.0035 - val_mae: 0.0075\n",
      "Epoch 101/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0035 - mae: 0.0091 - val_loss: 0.0041 - val_mae: 0.0247\n",
      "Epoch 102/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0034 - mae: 0.0071 - val_loss: 0.0032 - val_mae: 0.0039\n",
      "Epoch 103/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0033 - mae: 0.0086 - val_loss: 0.0033 - val_mae: 0.0120\n",
      "Epoch 104/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0032 - mae: 0.0090 - val_loss: 0.0030 - val_mae: 0.0044\n",
      "Epoch 105/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0031 - mae: 0.0089 - val_loss: 0.0036 - val_mae: 0.0253\n",
      "Epoch 106/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0030 - mae: 0.0082 - val_loss: 0.0029 - val_mae: 0.0061\n",
      "Epoch 107/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0030 - mae: 0.0102 - val_loss: 0.0029 - val_mae: 0.0078\n",
      "Epoch 108/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0029 - mae: 0.0084 - val_loss: 0.0030 - val_mae: 0.0114\n",
      "Epoch 109/400\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0028 - mae: 0.0078 - val_loss: 0.0027 - val_mae: 0.0037\n",
      "Epoch 110/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0028 - mae: 0.0082 - val_loss: 0.0033 - val_mae: 0.0208\n",
      "Epoch 111/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0028 - mae: 0.0095 - val_loss: 0.0026 - val_mae: 0.0057\n",
      "Epoch 112/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0027 - mae: 0.0081 - val_loss: 0.0026 - val_mae: 0.0099\n",
      "Epoch 113/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0026 - mae: 0.0087 - val_loss: 0.0026 - val_mae: 0.0096\n",
      "Epoch 114/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0026 - mae: 0.0089 - val_loss: 0.0026 - val_mae: 0.0112\n",
      "Epoch 115/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0026 - mae: 0.0097 - val_loss: 0.0026 - val_mae: 0.0117\n",
      "Epoch 116/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0025 - mae: 0.0071 - val_loss: 0.0025 - val_mae: 0.0087\n",
      "Epoch 117/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0025 - mae: 0.0085 - val_loss: 0.0024 - val_mae: 0.0074\n",
      "Epoch 118/400\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0025 - mae: 0.0105 - val_loss: 0.0024 - val_mae: 0.0067\n",
      "Epoch 119/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0024 - mae: 0.0071 - val_loss: 0.0023 - val_mae: 0.0055\n",
      "Epoch 120/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0024 - mae: 0.0107 - val_loss: 0.0023 - val_mae: 0.0057\n",
      "Epoch 121/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0023 - mae: 0.0074 - val_loss: 0.0024 - val_mae: 0.0137\n",
      "Epoch 122/400\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0023 - mae: 0.0060 - val_loss: 0.0022 - val_mae: 0.0058\n",
      "Epoch 123/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0024 - mae: 0.0105 - val_loss: 0.0022 - val_mae: 0.0039\n",
      "Epoch 124/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0023 - mae: 0.0102 - val_loss: 0.0025 - val_mae: 0.0184\n",
      "Epoch 125/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0022 - mae: 0.0075 - val_loss: 0.0028 - val_mae: 0.0223\n",
      "Epoch 126/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0022 - mae: 0.0083 - val_loss: 0.0021 - val_mae: 0.0036\n",
      "Epoch 127/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0022 - mae: 0.0084 - val_loss: 0.0022 - val_mae: 0.0071\n",
      "Epoch 128/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0022 - mae: 0.0095 - val_loss: 0.0022 - val_mae: 0.0084\n",
      "Epoch 129/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0022 - mae: 0.0075 - val_loss: 0.0023 - val_mae: 0.0123\n",
      "Epoch 130/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0021 - mae: 0.0076 - val_loss: 0.0021 - val_mae: 0.0072\n",
      "Epoch 131/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0021 - mae: 0.0064 - val_loss: 0.0020 - val_mae: 0.0034\n",
      "Epoch 132/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0023 - mae: 0.0111 - val_loss: 0.0020 - val_mae: 0.0042\n",
      "Epoch 133/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0020 - mae: 0.0040 - val_loss: 0.0020 - val_mae: 0.0064\n",
      "Epoch 134/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0021 - mae: 0.0092 - val_loss: 0.0022 - val_mae: 0.0134\n",
      "Epoch 135/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0021 - mae: 0.0075 - val_loss: 0.0020 - val_mae: 0.0045\n",
      "Epoch 136/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0021 - mae: 0.0100 - val_loss: 0.0020 - val_mae: 0.0052\n",
      "Epoch 137/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0021 - mae: 0.0084 - val_loss: 0.0020 - val_mae: 0.0068\n",
      "Epoch 138/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0020 - mae: 0.0072 - val_loss: 0.0021 - val_mae: 0.0108\n",
      "Epoch 139/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0020 - mae: 0.0082 - val_loss: 0.0023 - val_mae: 0.0187\n",
      "Epoch 140/400\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0021 - mae: 0.0108 - val_loss: 0.0021 - val_mae: 0.0129\n",
      "Epoch 141/400\n",
      "79/81 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0052Restoring model weights from the end of the best epoch: 136.\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.0020 - mae: 0.0057 - val_loss: 0.0041 - val_mae: 0.0383\n",
      "Epoch 141: early stopping\n",
      "Die Ausführungszeit betrug 117.42955136299133 Sekunden.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Netzwerkarchitektur\n",
    "model = Sequential([\n",
    "    # Eingabeschicht\n",
    "\n",
    "    Dense(320, activation='relu', input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "    Dense(178, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "    Dense(288, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "    Dense(192, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "    Dense(208, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "    Dense(224, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(80, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(304, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(240, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(48, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(1 , activation = 'linear')\n",
    "])\n",
    "\n",
    "# Optimierer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# Modell kompilieren (Verwendung von mean_squared_error als Verlustfunktion für Regression)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])  # Metriken für Regression: Mean Absolute Error und Mean Squared Error\n",
    "\n",
    "# Early Stopping Callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=2, mode='min', restore_best_weights=True)#, min_delta = 0.00005)\n",
    "\n",
    "# Trainingsparameter\n",
    "batch_size = 800\n",
    "epochs = 400\n",
    "\n",
    "# Modell trainieren (Annahme: X_train, y_train, X_val, y_val sind vordefiniert)\n",
    "history = model.fit(X_train_scaled, y_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose = 1)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Berechne die Dauer\n",
    "duration = end_time - start_time\n",
    "\n",
    "print(f\"Die Ausführungszeit betrug {duration} Sekunden.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T12:34:55.508859600Z",
     "start_time": "2024-03-13T12:32:58.054097700Z"
    }
   },
   "id": "8b52e1a9a6ff3aeb"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 - 1s - loss: 0.0020 - mae: 0.0052 - 668ms/epoch - 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.001982138492166996, 0.005222695879638195]"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test_scaled, y_test_scaled, verbose=2)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T12:34:56.199259900Z",
     "start_time": "2024-03-13T12:34:55.490859200Z"
    }
   },
   "id": "68d86893ad985b02"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f6f672a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T12:34:57.102681100Z",
     "start_time": "2024-03-13T12:34:56.196260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bsp. Predicted: [1203.6246] Actual: [1195.9] \n",
      "Durchschnittliche Abweichung (MAE): [4.95006348]\n"
     ]
    }
   ],
   "source": [
    "scaled_predicted_values = model.predict(X_test_scaled, verbose = 0)\n",
    "\n",
    "# Führen Sie die Rücktransformation der skalierten Werte durch\n",
    "original_predicted_values = scaler_target.inverse_transform(scaled_predicted_values)\n",
    "original_actual_values = scaler_target.inverse_transform(y_test_scaled)  # y_test sind die skalierten tatsächlichen Werte\n",
    "print(f' Bsp. Predicted: {original_predicted_values[1000]} Actual: {original_actual_values[1000]} ')\n",
    "\n",
    "def calculate_mae(list1, list2):\n",
    "    # Stelle sicher, dass beide Listen die gleiche Länge haben\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Listen müssen die gleiche Länge haben\")\n",
    "\n",
    "    # Berechne die absolute Differenz zwischen den Elementen der Listen\n",
    "    differences = [abs(x - y) for x, y in zip(list1, list2)]\n",
    "\n",
    "    # Berechne den Durchschnitt der absoluten Differenzen\n",
    "    mae = sum(differences) / len(differences)\n",
    "\n",
    "    return mae\n",
    "\n",
    "# Beispiel\n",
    "list1 = original_predicted_values\n",
    "list2 = original_actual_values\n",
    "\n",
    "mae = calculate_mae(list1, list2)\n",
    "print(f\"Durchschnittliche Abweichung (MAE): {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: [0.99939672]\n"
     ]
    }
   ],
   "source": [
    "def calculate_r_squared(predicted, actual):\n",
    "    # Berechnung des Mittelwerts der tatsächlichen Werte\n",
    "    mean_actual = sum(actual) / len(actual)\n",
    "    \n",
    "    # Berechnung der totalen Summe der Quadrate (SST)\n",
    "    sst = sum((x - mean_actual) ** 2 for x in actual)\n",
    "    \n",
    "    # Berechnung der Summe der Quadrate der Residuen (SSE)\n",
    "    sse = sum((actual[i] - predicted[i]) ** 2 for i in range(len(actual)))\n",
    "    \n",
    "    # Berechnung des R^2-Wertes\n",
    "    r_squared = 1 - (sse / sst)\n",
    "    \n",
    "    return r_squared\n",
    "\n",
    "# Berechnung von R^2 mit den bereitgestellten Listen\n",
    "r_squared = calculate_r_squared(list1, list2)\n",
    "\n",
    "print(f\"R^2: {r_squared}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T12:34:57.209544Z",
     "start_time": "2024-03-13T12:34:57.104680400Z"
    }
   },
   "id": "48ac8cdcc05e55fd"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Werte die kleiner sind: 178\n"
     ]
    },
    {
     "data": {
      "text/plain": "             Echt  Vorhergesagt  X-Koordinate  Y-Koordinate  Differenz\n19281  775.801147        807.84         1.000        0.9125 -32.038853\n14143  801.546997        832.75         1.000        0.9025 -31.203003\n16514  807.827332        838.63         1.000        0.9000 -30.802668\n4177   813.922668        844.45         1.000        0.8975 -30.527332\n16594  825.956482        855.66         1.000        0.8925 -29.703518\n...           ...           ...           ...           ...        ...\n9782   698.054810        665.99         0.920        0.0000  32.064810\n18290  693.773560        661.65         0.860        0.0000  32.123560\n7694   699.847046        667.48         0.944        0.0000  32.367046\n11547  697.761780        665.34         0.916        0.0000  32.421780\n1409   699.203247        666.57         0.936        0.0000  32.633247\n\n[20131 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Echt</th>\n      <th>Vorhergesagt</th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Differenz</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>19281</th>\n      <td>775.801147</td>\n      <td>807.84</td>\n      <td>1.000</td>\n      <td>0.9125</td>\n      <td>-32.038853</td>\n    </tr>\n    <tr>\n      <th>14143</th>\n      <td>801.546997</td>\n      <td>832.75</td>\n      <td>1.000</td>\n      <td>0.9025</td>\n      <td>-31.203003</td>\n    </tr>\n    <tr>\n      <th>16514</th>\n      <td>807.827332</td>\n      <td>838.63</td>\n      <td>1.000</td>\n      <td>0.9000</td>\n      <td>-30.802668</td>\n    </tr>\n    <tr>\n      <th>4177</th>\n      <td>813.922668</td>\n      <td>844.45</td>\n      <td>1.000</td>\n      <td>0.8975</td>\n      <td>-30.527332</td>\n    </tr>\n    <tr>\n      <th>16594</th>\n      <td>825.956482</td>\n      <td>855.66</td>\n      <td>1.000</td>\n      <td>0.8925</td>\n      <td>-29.703518</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9782</th>\n      <td>698.054810</td>\n      <td>665.99</td>\n      <td>0.920</td>\n      <td>0.0000</td>\n      <td>32.064810</td>\n    </tr>\n    <tr>\n      <th>18290</th>\n      <td>693.773560</td>\n      <td>661.65</td>\n      <td>0.860</td>\n      <td>0.0000</td>\n      <td>32.123560</td>\n    </tr>\n    <tr>\n      <th>7694</th>\n      <td>699.847046</td>\n      <td>667.48</td>\n      <td>0.944</td>\n      <td>0.0000</td>\n      <td>32.367046</td>\n    </tr>\n    <tr>\n      <th>11547</th>\n      <td>697.761780</td>\n      <td>665.34</td>\n      <td>0.916</td>\n      <td>0.0000</td>\n      <td>32.421780</td>\n    </tr>\n    <tr>\n      <th>1409</th>\n      <td>699.203247</td>\n      <td>666.57</td>\n      <td>0.936</td>\n      <td>0.0000</td>\n      <td>32.633247</td>\n    </tr>\n  </tbody>\n</table>\n<p>20131 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame({'Echt': [val[0] for val in list1], 'Vorhergesagt': [val[0] for val in list2]})\n",
    "df_result['X-Koordinate'] = X_test_scaled[:, 0]\n",
    "df_result['Y-Koordinate'] = X_test_scaled[:, 1]\n",
    "\n",
    "df_result['Differenz'] = df_result['Echt'] - df_result['Vorhergesagt']\n",
    "df_result['Differenz'].sort_values()\n",
    "sorted_df = df_result.sort_values(by= 'Differenz')\n",
    "Anzahl_Punkte = (sorted_df['Differenz'] > 20).sum()\n",
    "print(\"Anzahl der Werte die kleiner sind:\", Anzahl_Punkte)\n",
    "\n",
    "sorted_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T12:34:57.267409300Z",
     "start_time": "2024-03-13T12:34:57.209544Z"
    }
   },
   "id": "42bde60d3b4f2007"
  },
  {
   "cell_type": "markdown",
   "id": "553df6fa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mae = history.history['loss']\n",
    "val_mae = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(mae) + 1)\n",
    "# MAE Diagramm\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, mae, 'r', label='Training MSE')\n",
    "plt.plot(epochs, val_mae, 'b', label='Validation MSE')\n",
    "plt.title('Training and Validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T12:34:57.423000300Z",
     "start_time": "2024-03-13T12:34:57.236409Z"
    }
   },
   "id": "3688dd7102e95baf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# GridSearch\n",
    "Grid Search bietet die Vorteile der anpassbaren Rechenzeit sowie die Möglichkeit des EInsatzes von Verteilungen. So können theoretisch Hyperparamterkonfuigurationen gefunden wende, welche durch GridSearch nicht auffindbar wären. ZUdem ist das Ziel der Hyperparamteroptimierung eine Einstellung zu finden, welche auf Trainings und Testset gut angepasst ist. Die EInstellung muss nicht die bestmöglichste Einstellung sein, sondern eine Einstellung die das gewähltre Problem gut wiederspiegelt. \n",
    "Bayesian Optimierung"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c177960cc729052"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f17e2cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T12:34:57.433068700Z",
     "start_time": "2024-03-13T12:34:57.422000100Z"
    }
   },
   "outputs": [],
   "source": [
    "# def build_model(learning_rate=0.001, activation='relu', regularization=0.0001, dropout_rate=0.0):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(320, activation=activation, input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(176, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(288, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(192, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(208, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(224, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(80, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(304, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate)) \n",
    "# \n",
    "#     model.add(Dense(240, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))   \n",
    "# \n",
    "#     model.add(Dense(48, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mae'])\n",
    "#     return model\n",
    "# \n",
    "# # Verwenden Sie eine Funktion, um das Modell zu instanziieren, für scikit-learn Wrapper\n",
    "# model = KerasRegressor(model=build_model, verbose=2)\n",
    "# \n",
    "# # Anpassung der Parameter im param_grid\n",
    "# param_grid = {\n",
    "#     'model__learning_rate': [0.01, 0.001, 0.0001],\n",
    "#     'model__regularization': [0.001, 0.0001],\n",
    "#     'fit__batch_size': [100, 200, 400, 800],\n",
    "#     'fit__epochs': [50],\n",
    "#     'model__dropout_rate' : [0.0, 0.1, 0.2]\n",
    "# }\n",
    "# \n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=2)\n",
    "# # Hinweis: Stellen Sie sicher, dass Ihre Daten (X_train_scaled, y_train_scaled) korrekt definiert sind\n",
    "# grid_result = grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "# # Beste Parameter und Score ausgeben\n",
    "# print(\"Beste Parameter:\", grid_search.best_params_)\n",
    "# print(\"Beste Genauigkeit:\", grid_search.best_score_)\n",
    "# \n",
    "# with open(\"grid_search_D1_2.txt\", \"w\") as f:\n",
    "#     f.write(f\"Beste Parameter: {grid_search.best_params_}\\n\")\n",
    "#     f.write(f\"Beste Genauigkeit: {grid_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "  # Bayesian Optimization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bb41910a42cbdee"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# from bayes_opt import BayesianOptimization\n",
    "# \n",
    "# \n",
    "# # Angenommene Daten\n",
    "# # X_train_scaled, y_train_scaled = # Deine skalierten Trainingsdaten\n",
    "# \n",
    "# def train_evaluate(neurons_layer_1, neurons_layer_2, neurons_layer_3, neurons_layer_4, neurons_layer_5, learning_rate):\n",
    "#     model = Sequential([\n",
    "#         Dense(int(neurons_layer_1), activation='relu', input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "#         Dense(int(neurons_layer_2), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "#         Dense(int(neurons_layer_3), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "#         Dense(int(neurons_layer_4), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "#         Dense(int(neurons_layer_5), activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "#         \n",
    "#         Dense(1, activation='linear')\n",
    "#     ])\n",
    "# \n",
    "#     optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "#     model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "# \n",
    "#     early_stopping = EarlyStopping(monitor='loss', patience=5, verbose=1, mode='min', restore_best_weights=True, min_delta=0.0001)\n",
    "# \n",
    "#     history = model.fit(X_train_scaled, y_train_scaled, batch_size=32, epochs=100, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
    "# \n",
    "#     # Hier wählen wir den negativen Mean Squared Error, da Bayesian Optimization maximiert\n",
    "#     mse = np.min(history.history['val_loss'])\n",
    "#     return -mse\n",
    "# \n",
    "# # Definieren des Bereichs der Hyperparameter\n",
    "# pbounds = {\n",
    "#     'neurons_layer_1': (16, 200),\n",
    "#     'neurons_layer_2': (16, 200),\n",
    "#     'neurons_layer_3': (16, 200),\n",
    "#     'neurons_layer_4': (16, 200),\n",
    "#     'neurons_layer_5': (16, 200),\n",
    "#     'learning_rate': (0.0001, 0.01),\n",
    "# }\n",
    "# \n",
    "# # Initialisieren des BayesianOptimization-Objekts\n",
    "# optimizer = BayesianOptimization(\n",
    "#     f=train_evaluate,\n",
    "#     pbounds=pbounds,\n",
    "#     random_state=1,\n",
    "# )\n",
    "# \n",
    "# # Starten der Optimierung\n",
    "# optimizer.maximize(init_points=2, n_iter=20)\n",
    "# \n",
    "# print(optimizer.max)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T12:34:57.433068700Z",
     "start_time": "2024-03-13T12:34:57.427452400Z"
    }
   },
   "id": "a5b6232547cdae67"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Search Architektur\n",
    "Tiefes Netz besser als breites Netz; Layer lernen auf unterschiedliche Weise"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75773dfef8260e5f"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# # Funktion zum Erstellen des Modells\n",
    "# def build_model(hp):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(hp.Int('input_units', min_value=16, max_value=328, step=16), input_shape=(2,), activation='relu'))\n",
    "#     for i in range(hp.Int('n_layers', 1, 10)):\n",
    "#         model.add(Dense(hp.Int(f'units_{i}', min_value=16, max_value=328, step=16), activation='relu'))\n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     return model\n",
    "# \n",
    "# # Durchführung der Random Search dreimal\n",
    "# for run in range(1, 4):\n",
    "#     # Anpassen des Verzeichnisses und des Projektnamens für jeden Durchlauf\n",
    "#     directory = 'random_search'\n",
    "#     project_name = f'random_search_D1_{run}'\n",
    "# \n",
    "#     tuner = RandomSearch(\n",
    "#         build_model,\n",
    "#         objective='val_loss',\n",
    "#         max_trials=100,\n",
    "#         executions_per_trial=1,\n",
    "#         directory=directory,\n",
    "#         project_name=project_name\n",
    "#     )\n",
    "# \n",
    "#     # Durchführung des Random Search\n",
    "#     tuner.search(X_train_scaled, y_train_scaled, epochs=50, verbose =0, batch_size=500, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "# \n",
    "#     # Abrufen und Speichern des besten Modells\n",
    "#     best_model = tuner.get_best_models(num_models=1)[0]\n",
    "#     model_path = os.path.join(directory, project_name, 'best_model.h5') \n",
    "#     best_model.save(model_path)\n",
    "# \n",
    "# \n",
    "#     # Optional: Abrufen und Ausgeben der besten Hyperparameter\n",
    "#     best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "# \n",
    "#     # Konvertieren der Hyperparameter in ein DataFrame\n",
    "#     df_hyperparameters = pd.DataFrame([best_hyperparameters.values])\n",
    "#     # Speichern des DataFrame als CSV\n",
    "#     df_hyperparameters.to_csv(f'random_search_D1_{run}.csv', index=False)\n",
    "#     best_model.describe()\n",
    "#     print(f\"Beste Hyperparameter für Lauf {run}: {best_hyperparameters.values}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T12:34:57.436034400Z",
     "start_time": "2024-03-13T12:34:57.431427600Z"
    }
   },
   "id": "158d81fabf560fc4"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T12:34:57.438477600Z",
     "start_time": "2024-03-13T12:34:57.435529300Z"
    }
   },
   "id": "6f86db4f21a8c913"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T12:34:57.444488800Z",
     "start_time": "2024-03-13T12:34:57.437046400Z"
    }
   },
   "id": "2a8e01cea48e945f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
