{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94b0518e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-29T23:21:40.505372500Z",
     "start_time": "2024-03-29T23:21:35.837169100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense , Dropout\n",
    "from scikeras.wrappers import KerasRegressor \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4ff61b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-29T23:21:40.524898100Z",
     "start_time": "2024-03-29T23:21:40.506372100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n0             0.0000      -0.00200        100   6000   5000      449.80\n1             0.0000      -0.00192        100   6000   5000      479.76\n2             0.0000      -0.00184        100   6000   5000      506.60\n3             0.0000      -0.00176        100   6000   5000      530.80\n4             0.0000      -0.00168        100   6000   5000      552.15\n...              ...           ...        ...    ...    ...         ...\n351283        0.0024       0.00168        500   9000   5000     1365.50\n351284        0.0024       0.00176        500   9000   5000     1247.20\n351285        0.0024       0.00184        500   9000   5000     1114.10\n351286        0.0024       0.00192        500   9000   5000      983.97\n351287        0.0024       0.00200        500   9000   5000      942.84\n\n[351288 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>449.80</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0000</td>\n      <td>-0.00192</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>479.76</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0000</td>\n      <td>-0.00184</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>506.60</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0000</td>\n      <td>-0.00176</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>530.80</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0000</td>\n      <td>-0.00168</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>552.15</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>351283</th>\n      <td>0.0024</td>\n      <td>0.00168</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1365.50</td>\n    </tr>\n    <tr>\n      <th>351284</th>\n      <td>0.0024</td>\n      <td>0.00176</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1247.20</td>\n    </tr>\n    <tr>\n      <th>351285</th>\n      <td>0.0024</td>\n      <td>0.00184</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1114.10</td>\n    </tr>\n    <tr>\n      <th>351286</th>\n      <td>0.0024</td>\n      <td>0.00192</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>983.97</td>\n    </tr>\n    <tr>\n      <th>351287</th>\n      <td>0.0024</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>942.84</td>\n    </tr>\n  </tbody>\n</table>\n<p>351288 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/TPath_300_finish_data.pkl')\n",
    "data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_ALL_D4_t_I_F_PKL.pkl')\n",
    "\n",
    "data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "966e3c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-29T23:21:40.632287Z",
     "start_time": "2024-03-29T23:21:40.523898Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate      Zeitpunkt          Strom  \\\ncount  351288.000000  3.512880e+05  351288.000000  351288.000000   \nmean        0.001200  8.187503e-20     300.000000    7250.000000   \nstd         0.000727  1.177570e-03     118.321764     968.247215   \nmin         0.000000 -2.000000e-03     100.000000    6000.000000   \n25%         0.000600 -1.040000e-03     200.000000    6750.000000   \n50%         0.001200  4.529900e-18     300.000000    7000.000000   \n75%         0.001800  1.040000e-03     400.000000    8000.000000   \nmax         0.002400  2.000000e-03     500.000000    9000.000000   \n\n               Kraft     Temperatur  \ncount  351288.000000  351288.000000  \nmean     6125.000000    1223.062798  \nstd      1268.613251     481.699573  \nmin      5000.000000     359.280000  \n25%      5000.000000     815.900000  \n50%      6000.000000    1136.800000  \n75%      6250.000000    1617.400000  \nmax      9000.000000    2577.200000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>351288.000000</td>\n      <td>3.512880e+05</td>\n      <td>351288.000000</td>\n      <td>351288.000000</td>\n      <td>351288.000000</td>\n      <td>351288.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.001200</td>\n      <td>8.187503e-20</td>\n      <td>300.000000</td>\n      <td>7250.000000</td>\n      <td>6125.000000</td>\n      <td>1223.062798</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.000727</td>\n      <td>1.177570e-03</td>\n      <td>118.321764</td>\n      <td>968.247215</td>\n      <td>1268.613251</td>\n      <td>481.699573</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-2.000000e-03</td>\n      <td>100.000000</td>\n      <td>6000.000000</td>\n      <td>5000.000000</td>\n      <td>359.280000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000600</td>\n      <td>-1.040000e-03</td>\n      <td>200.000000</td>\n      <td>6750.000000</td>\n      <td>5000.000000</td>\n      <td>815.900000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.001200</td>\n      <td>4.529900e-18</td>\n      <td>300.000000</td>\n      <td>7000.000000</td>\n      <td>6000.000000</td>\n      <td>1136.800000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.001800</td>\n      <td>1.040000e-03</td>\n      <td>400.000000</td>\n      <td>8000.000000</td>\n      <td>6250.000000</td>\n      <td>1617.400000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.002400</td>\n      <td>2.000000e-03</td>\n      <td>500.000000</td>\n      <td>9000.000000</td>\n      <td>9000.000000</td>\n      <td>2577.200000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n131733        0.0000      -0.00200        100   7000   6000      478.13\n131734        0.0000      -0.00192        100   7000   6000      511.16\n131735        0.0000      -0.00184        100   7000   6000      541.43\n131736        0.0000      -0.00176        100   7000   6000      569.14\n131737        0.0000      -0.00168        100   7000   6000      594.14\n...              ...           ...        ...    ...    ...         ...\n175639        0.0024       0.00168        500   7000   6000      942.96\n175640        0.0024       0.00176        500   7000   6000      865.10\n175641        0.0024       0.00184        500   7000   6000      786.99\n175642        0.0024       0.00192        500   7000   6000      708.11\n175643        0.0024       0.00200        500   7000   6000      690.48\n\n[43911 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>131733</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>100</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>478.13</td>\n    </tr>\n    <tr>\n      <th>131734</th>\n      <td>0.0000</td>\n      <td>-0.00192</td>\n      <td>100</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>511.16</td>\n    </tr>\n    <tr>\n      <th>131735</th>\n      <td>0.0000</td>\n      <td>-0.00184</td>\n      <td>100</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>541.43</td>\n    </tr>\n    <tr>\n      <th>131736</th>\n      <td>0.0000</td>\n      <td>-0.00176</td>\n      <td>100</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>569.14</td>\n    </tr>\n    <tr>\n      <th>131737</th>\n      <td>0.0000</td>\n      <td>-0.00168</td>\n      <td>100</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>594.14</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>175639</th>\n      <td>0.0024</td>\n      <td>0.00168</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>942.96</td>\n    </tr>\n    <tr>\n      <th>175640</th>\n      <td>0.0024</td>\n      <td>0.00176</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>865.10</td>\n    </tr>\n    <tr>\n      <th>175641</th>\n      <td>0.0024</td>\n      <td>0.00184</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>786.99</td>\n    </tr>\n    <tr>\n      <th>175642</th>\n      <td>0.0024</td>\n      <td>0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>708.11</td>\n    </tr>\n    <tr>\n      <th>175643</th>\n      <td>0.0024</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>690.48</td>\n    </tr>\n  </tbody>\n</table>\n<p>43911 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedingung1 = (data['Kraft'] == 6000) & (data['Strom'] == 7000)\n",
    "neues_df1 = data[bedingung1].copy()\n",
    "neues_df1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T23:21:40.633286600Z",
     "start_time": "2024-03-29T23:21:40.596045800Z"
    }
   },
   "id": "46ac10701e8c04c9"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n174573        0.0000      -0.00200        500   7000   6000      811.76\n174574        0.0000      -0.00192        500   7000   6000      897.57\n174575        0.0000      -0.00184        500   7000   6000      986.34\n174576        0.0000      -0.00176        500   7000   6000     1077.80\n174577        0.0000      -0.00168        500   7000   6000     1176.80\n...              ...           ...        ...    ...    ...         ...\n175639        0.0024       0.00168        500   7000   6000      942.96\n175640        0.0024       0.00176        500   7000   6000      865.10\n175641        0.0024       0.00184        500   7000   6000      786.99\n175642        0.0024       0.00192        500   7000   6000      708.11\n175643        0.0024       0.00200        500   7000   6000      690.48\n\n[1071 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>174573</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>811.76</td>\n    </tr>\n    <tr>\n      <th>174574</th>\n      <td>0.0000</td>\n      <td>-0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>897.57</td>\n    </tr>\n    <tr>\n      <th>174575</th>\n      <td>0.0000</td>\n      <td>-0.00184</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>986.34</td>\n    </tr>\n    <tr>\n      <th>174576</th>\n      <td>0.0000</td>\n      <td>-0.00176</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>1077.80</td>\n    </tr>\n    <tr>\n      <th>174577</th>\n      <td>0.0000</td>\n      <td>-0.00168</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>1176.80</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>175639</th>\n      <td>0.0024</td>\n      <td>0.00168</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>942.96</td>\n    </tr>\n    <tr>\n      <th>175640</th>\n      <td>0.0024</td>\n      <td>0.00176</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>865.10</td>\n    </tr>\n    <tr>\n      <th>175641</th>\n      <td>0.0024</td>\n      <td>0.00184</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>786.99</td>\n    </tr>\n    <tr>\n      <th>175642</th>\n      <td>0.0024</td>\n      <td>0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>708.11</td>\n    </tr>\n    <tr>\n      <th>175643</th>\n      <td>0.0024</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>690.48</td>\n    </tr>\n  </tbody>\n</table>\n<p>1071 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedingung = (data['Kraft'] == 6000) & (data['Strom'] == 7000) & (data['Zeitpunkt'] == 500)\n",
    "neues_df = data[bedingung].copy()\n",
    "neues_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T23:21:40.633286600Z",
     "start_time": "2024-03-29T23:21:40.607427100Z"
    }
   },
   "id": "7514abd38f1a0b4a"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8783d1d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-29T23:21:49.469294900Z",
     "start_time": "2024-03-29T23:21:49.412475900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n0            0.00072       0.00016        370   9000   5000     2452.80\n1            0.00084       0.00096        100   7000   5000      823.28\n2            0.00000      -0.00024        210   6000   5000      990.64\n3            0.00108       0.00080        150   7000   9000      606.30\n4            0.00024      -0.00096        270   8000   7000     1666.60\n...              ...           ...        ...    ...    ...         ...\n307372       0.00228       0.00032        390   7000   5000     1712.30\n307373       0.00240       0.00176        460   8000   7000      929.04\n307374       0.00036       0.00168        100   7000   9000      427.59\n307375       0.00024       0.00104        240   7000   9000      724.15\n307376       0.00216      -0.00064        410   7000   5000     1718.30\n\n[307377 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00072</td>\n      <td>0.00016</td>\n      <td>370</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>2452.80</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00084</td>\n      <td>0.00096</td>\n      <td>100</td>\n      <td>7000</td>\n      <td>5000</td>\n      <td>823.28</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00000</td>\n      <td>-0.00024</td>\n      <td>210</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>990.64</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00108</td>\n      <td>0.00080</td>\n      <td>150</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>606.30</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00024</td>\n      <td>-0.00096</td>\n      <td>270</td>\n      <td>8000</td>\n      <td>7000</td>\n      <td>1666.60</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>307372</th>\n      <td>0.00228</td>\n      <td>0.00032</td>\n      <td>390</td>\n      <td>7000</td>\n      <td>5000</td>\n      <td>1712.30</td>\n    </tr>\n    <tr>\n      <th>307373</th>\n      <td>0.00240</td>\n      <td>0.00176</td>\n      <td>460</td>\n      <td>8000</td>\n      <td>7000</td>\n      <td>929.04</td>\n    </tr>\n    <tr>\n      <th>307374</th>\n      <td>0.00036</td>\n      <td>0.00168</td>\n      <td>100</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>427.59</td>\n    </tr>\n    <tr>\n      <th>307375</th>\n      <td>0.00024</td>\n      <td>0.00104</td>\n      <td>240</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>724.15</td>\n    </tr>\n    <tr>\n      <th>307376</th>\n      <td>0.00216</td>\n      <td>-0.00064</td>\n      <td>410</td>\n      <td>7000</td>\n      <td>5000</td>\n      <td>1718.30</td>\n    </tr>\n  </tbody>\n</table>\n<p>307377 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reset = data.drop(neues_df1.index)\n",
    "\n",
    "df_reset= df_reset.sample(frac=1, random_state=42)\n",
    "df_reset = df_reset.reset_index(drop=True)\n",
    "\n",
    "df_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4e72a16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-29T23:21:49.861540700Z",
     "start_time": "2024-03-29T23:21:49.854188800Z"
    }
   },
   "outputs": [],
   "source": [
    "label = df_reset[\"Temperatur\"]\n",
    "# Korrektur: Verwenden Sie den Spaltennamen direkt, ohne Indexierung der columns-Eigenschaft\n",
    "df = df_reset.drop(\"Temperatur\", axis=1)\n",
    "X = df\n",
    "y = label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "y_2 = neues_df[\"Temperatur\"]\n",
    "# Korrektur: Verwenden Sie den Spaltennamen direkt, ohne Indexierung der columns-Eigenschaft\n",
    "X_2 = neues_df.drop(\"Temperatur\", axis=1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T23:22:03.119234100Z",
     "start_time": "2024-03-29T23:22:03.105814300Z"
    }
   },
   "id": "29463a17853bd669"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7fa289a50d87423"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e694a236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-29T23:22:05.281597600Z",
     "start_time": "2024-03-29T23:22:05.245326700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft\n0           0.0000      -0.00200        500   7000   6000\n1           0.0000      -0.00192        500   7000   6000\n2           0.0000      -0.00184        500   7000   6000\n3           0.0000      -0.00176        500   7000   6000\n4           0.0000      -0.00168        500   7000   6000\n...            ...           ...        ...    ...    ...\n1066        0.0024       0.00168        500   7000   6000\n1067        0.0024       0.00176        500   7000   6000\n1068        0.0024       0.00184        500   7000   6000\n1069        0.0024       0.00192        500   7000   6000\n1070        0.0024       0.00200        500   7000   6000\n\n[1071 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0000</td>\n      <td>-0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0000</td>\n      <td>-0.00184</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0000</td>\n      <td>-0.00176</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0000</td>\n      <td>-0.00168</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1066</th>\n      <td>0.0024</td>\n      <td>0.00168</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>1067</th>\n      <td>0.0024</td>\n      <td>0.00176</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>1068</th>\n      <td>0.0024</td>\n      <td>0.00184</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>1069</th>\n      <td>0.0024</td>\n      <td>0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>1070</th>\n      <td>0.0024</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n  </tbody>\n</table>\n<p>1071 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2 = X_2.reset_index(drop=True)\n",
    "X_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f3303b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-29T23:22:06.692929900Z",
     "start_time": "2024-03-29T23:22:06.686411Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0         2452.80\n1          823.28\n2          990.64\n3          606.30\n4         1666.60\n           ...   \n307372    1712.30\n307373     929.04\n307374     427.59\n307375     724.15\n307376    1718.30\nName: Temperatur, Length: 307377, dtype: float64"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3ad8da0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-29T23:22:07.283778800Z",
     "start_time": "2024-03-29T23:22:07.267766900Z"
    }
   },
   "outputs": [],
   "source": [
    " # train_df enthält 80% der Daten, test_df enthält 20% der Daten\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft\n0            0.00072       0.00016        370   9000   5000\n1            0.00084       0.00096        100   7000   5000\n2            0.00000      -0.00024        210   6000   5000\n3            0.00108       0.00080        150   7000   9000\n4            0.00024      -0.00096        270   8000   7000\n...              ...           ...        ...    ...    ...\n307372       0.00228       0.00032        390   7000   5000\n307373       0.00240       0.00176        460   8000   7000\n307374       0.00036       0.00168        100   7000   9000\n307375       0.00024       0.00104        240   7000   9000\n307376       0.00216      -0.00064        410   7000   5000\n\n[307377 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00072</td>\n      <td>0.00016</td>\n      <td>370</td>\n      <td>9000</td>\n      <td>5000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00084</td>\n      <td>0.00096</td>\n      <td>100</td>\n      <td>7000</td>\n      <td>5000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00000</td>\n      <td>-0.00024</td>\n      <td>210</td>\n      <td>6000</td>\n      <td>5000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00108</td>\n      <td>0.00080</td>\n      <td>150</td>\n      <td>7000</td>\n      <td>9000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00024</td>\n      <td>-0.00096</td>\n      <td>270</td>\n      <td>8000</td>\n      <td>7000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>307372</th>\n      <td>0.00228</td>\n      <td>0.00032</td>\n      <td>390</td>\n      <td>7000</td>\n      <td>5000</td>\n    </tr>\n    <tr>\n      <th>307373</th>\n      <td>0.00240</td>\n      <td>0.00176</td>\n      <td>460</td>\n      <td>8000</td>\n      <td>7000</td>\n    </tr>\n    <tr>\n      <th>307374</th>\n      <td>0.00036</td>\n      <td>0.00168</td>\n      <td>100</td>\n      <td>7000</td>\n      <td>9000</td>\n    </tr>\n    <tr>\n      <th>307375</th>\n      <td>0.00024</td>\n      <td>0.00104</td>\n      <td>240</td>\n      <td>7000</td>\n      <td>9000</td>\n    </tr>\n    <tr>\n      <th>307376</th>\n      <td>0.00216</td>\n      <td>-0.00064</td>\n      <td>410</td>\n      <td>7000</td>\n      <td>5000</td>\n    </tr>\n  </tbody>\n</table>\n<p>307377 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T23:22:07.761174300Z",
     "start_time": "2024-03-29T23:22:07.752656500Z"
    }
   },
   "id": "ecf768c7178a30f4"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c705edb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-29T23:22:09.073517600Z",
     "start_time": "2024-03-29T23:22:09.038056600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialisiere einen MinMaxScaler für die Features\n",
    "scaler_features = MinMaxScaler()\n",
    "# Skaliere X_train und X_test\n",
    "X_train_scaled = scaler_features.fit_transform(X)\n",
    "#X_test_scaled = scaler_features.transform(X_test)  # Nutze unterschiedliche Skalierungsparameter\n",
    "X_test_scaled_2 = scaler_features.transform(X_2)\n",
    "# Initialisiere einen SEPARATEN MinMaxScaler für das Ziel, wenn nötig\n",
    "scaler_target = MinMaxScaler()\n",
    "# Skaliere y_train und y_test. Beachte, dass y_train.reshape(-1, 1) verwendet wird, da MinMaxScaler \n",
    "# erwartet, dass die Eingaben als 2D-Arrays kommen, und Ziele normalerweise als 1D-Arrays vorliegen.\n",
    "y_train_scaled = scaler_target.fit_transform(y.values.reshape(-1, 1))\n",
    "#y_test_scaled = scaler_target.transform(y_test.values.reshape(-1, 1))\n",
    "y_test_scaled_2 = scaler_target.transform(y_2.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbefe631e495b483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-29T23:22:16.354340100Z",
     "start_time": "2024-03-29T23:22:16.346352500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.3       , 0.54      , 0.675     , 1.        , 0.        ],\n       [0.35      , 0.74      , 0.        , 0.33333333, 0.        ],\n       [0.        , 0.44      , 0.275     , 0.        , 0.        ],\n       ...,\n       [0.15      , 0.92      , 0.        , 0.33333333, 1.        ],\n       [0.1       , 0.76      , 0.35      , 0.33333333, 1.        ],\n       [0.9       , 0.34      , 0.775     , 0.33333333, 0.        ]])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.94391141],\n       [0.20920502],\n       [0.28466311],\n       ...,\n       [0.03079913],\n       [0.16450999],\n       [0.61274527]])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T23:22:17.226360500Z",
     "start_time": "2024-03-29T23:22:17.214490300Z"
    }
   },
   "id": "ce04ce43aac2242f"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "Epoch 1/2000\n",
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "1230/1230 [==============================] - 5s 3ms/step - loss: 0.0123 - mae: 0.0709 - val_loss: 0.0066 - val_mae: 0.0460\n",
      "Epoch 2/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0053 - mae: 0.0388 - val_loss: 0.0044 - val_mae: 0.0338\n",
      "Epoch 3/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0039 - mae: 0.0301 - val_loss: 0.0035 - val_mae: 0.0269\n",
      "Epoch 4/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0032 - mae: 0.0245 - val_loss: 0.0029 - val_mae: 0.0225\n",
      "Epoch 5/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0027 - mae: 0.0205 - val_loss: 0.0026 - val_mae: 0.0187\n",
      "Epoch 6/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0024 - mae: 0.0175 - val_loss: 0.0023 - val_mae: 0.0161\n",
      "Epoch 7/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0022 - mae: 0.0153 - val_loss: 0.0021 - val_mae: 0.0143\n",
      "Epoch 8/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0021 - mae: 0.0136 - val_loss: 0.0020 - val_mae: 0.0128\n",
      "Epoch 9/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0020 - mae: 0.0121 - val_loss: 0.0019 - val_mae: 0.0116\n",
      "Epoch 10/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0019 - mae: 0.0110 - val_loss: 0.0018 - val_mae: 0.0106\n",
      "Epoch 11/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0018 - mae: 0.0100 - val_loss: 0.0018 - val_mae: 0.0103\n",
      "Epoch 12/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0017 - mae: 0.0093 - val_loss: 0.0017 - val_mae: 0.0096\n",
      "Epoch 13/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0017 - mae: 0.0087 - val_loss: 0.0017 - val_mae: 0.0084\n",
      "Epoch 14/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0017 - mae: 0.0081 - val_loss: 0.0016 - val_mae: 0.0080\n",
      "Epoch 15/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0016 - mae: 0.0077 - val_loss: 0.0016 - val_mae: 0.0075\n",
      "Epoch 16/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0016 - mae: 0.0073 - val_loss: 0.0016 - val_mae: 0.0071\n",
      "Epoch 17/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0016 - mae: 0.0070 - val_loss: 0.0016 - val_mae: 0.0069\n",
      "Epoch 18/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0016 - mae: 0.0067 - val_loss: 0.0015 - val_mae: 0.0067\n",
      "Epoch 19/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0015 - mae: 0.0065 - val_loss: 0.0015 - val_mae: 0.0063\n",
      "Epoch 20/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0015 - mae: 0.0063 - val_loss: 0.0015 - val_mae: 0.0063\n",
      "Epoch 21/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0015 - mae: 0.0061 - val_loss: 0.0015 - val_mae: 0.0061\n",
      "Epoch 22/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0015 - mae: 0.0059 - val_loss: 0.0015 - val_mae: 0.0063\n",
      "Epoch 23/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0015 - mae: 0.0058 - val_loss: 0.0015 - val_mae: 0.0057\n",
      "Epoch 24/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0015 - mae: 0.0057 - val_loss: 0.0015 - val_mae: 0.0056\n",
      "Epoch 25/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0015 - mae: 0.0056 - val_loss: 0.0015 - val_mae: 0.0054\n",
      "Epoch 26/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0014 - mae: 0.0054 - val_loss: 0.0014 - val_mae: 0.0056\n",
      "Epoch 27/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0014 - mae: 0.0053 - val_loss: 0.0014 - val_mae: 0.0052\n",
      "Epoch 28/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0014 - mae: 0.0053 - val_loss: 0.0014 - val_mae: 0.0053\n",
      "Epoch 29/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 0.0014 - mae: 0.0052 - val_loss: 0.0014 - val_mae: 0.0052\n",
      "Epoch 30/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0014 - mae: 0.0051 - val_loss: 0.0014 - val_mae: 0.0050\n",
      "Epoch 31/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0014 - mae: 0.0050 - val_loss: 0.0014 - val_mae: 0.0051\n",
      "Epoch 32/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0014 - mae: 0.0049 - val_loss: 0.0014 - val_mae: 0.0049\n",
      "Epoch 33/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0014 - mae: 0.0049 - val_loss: 0.0014 - val_mae: 0.0049\n",
      "Epoch 34/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0014 - mae: 0.0048 - val_loss: 0.0014 - val_mae: 0.0047\n",
      "Epoch 35/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0014 - mae: 0.0048 - val_loss: 0.0014 - val_mae: 0.0046\n",
      "Epoch 36/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0014 - mae: 0.0047 - val_loss: 0.0014 - val_mae: 0.0052\n",
      "Epoch 37/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0013 - mae: 0.0046 - val_loss: 0.0013 - val_mae: 0.0047\n",
      "Epoch 38/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0013 - mae: 0.0046 - val_loss: 0.0013 - val_mae: 0.0045\n",
      "Epoch 39/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0044\n",
      "Epoch 40/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0045\n",
      "Epoch 41/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0043\n",
      "Epoch 42/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0043\n",
      "Epoch 43/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0044\n",
      "Epoch 44/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0044\n",
      "Epoch 45/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0043\n",
      "Epoch 46/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0042\n",
      "Epoch 47/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0042\n",
      "Epoch 48/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0042\n",
      "Epoch 49/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0013 - mae: 0.0041 - val_loss: 0.0013 - val_mae: 0.0041\n",
      "Epoch 50/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0013 - mae: 0.0041 - val_loss: 0.0013 - val_mae: 0.0040\n",
      "Epoch 51/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0013 - mae: 0.0040 - val_loss: 0.0013 - val_mae: 0.0043\n",
      "Epoch 52/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0012 - mae: 0.0040 - val_loss: 0.0012 - val_mae: 0.0040\n",
      "Epoch 53/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0012 - mae: 0.0040 - val_loss: 0.0012 - val_mae: 0.0042\n",
      "Epoch 54/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0012 - mae: 0.0040 - val_loss: 0.0012 - val_mae: 0.0040\n",
      "Epoch 55/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0012 - mae: 0.0039 - val_loss: 0.0012 - val_mae: 0.0040\n",
      "Epoch 56/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0012 - mae: 0.0040 - val_loss: 0.0012 - val_mae: 0.0041\n",
      "Epoch 57/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0012 - mae: 0.0039 - val_loss: 0.0012 - val_mae: 0.0040\n",
      "Epoch 58/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0012 - mae: 0.0039 - val_loss: 0.0012 - val_mae: 0.0040\n",
      "Epoch 59/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0012 - mae: 0.0038 - val_loss: 0.0012 - val_mae: 0.0038\n",
      "Epoch 60/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0012 - mae: 0.0038 - val_loss: 0.0012 - val_mae: 0.0038\n",
      "Epoch 61/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0012 - mae: 0.0038 - val_loss: 0.0012 - val_mae: 0.0037\n",
      "Epoch 62/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0012 - mae: 0.0038 - val_loss: 0.0012 - val_mae: 0.0043\n",
      "Epoch 63/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0012 - mae: 0.0037 - val_loss: 0.0012 - val_mae: 0.0038\n",
      "Epoch 64/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0012 - mae: 0.0037 - val_loss: 0.0012 - val_mae: 0.0037\n",
      "Epoch 65/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0012 - mae: 0.0037 - val_loss: 0.0012 - val_mae: 0.0040\n",
      "Epoch 66/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0012 - mae: 0.0037 - val_loss: 0.0012 - val_mae: 0.0039\n",
      "Epoch 67/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 0.0012 - mae: 0.0037 - val_loss: 0.0012 - val_mae: 0.0037\n",
      "Epoch 68/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0012 - mae: 0.0037 - val_loss: 0.0012 - val_mae: 0.0036\n",
      "Epoch 69/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0012 - mae: 0.0037 - val_loss: 0.0012 - val_mae: 0.0036\n",
      "Epoch 70/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0012 - mae: 0.0036 - val_loss: 0.0012 - val_mae: 0.0036\n",
      "Epoch 71/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 0.0011 - mae: 0.0036 - val_loss: 0.0011 - val_mae: 0.0038\n",
      "Epoch 72/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0011 - mae: 0.0036 - val_loss: 0.0011 - val_mae: 0.0037\n",
      "Epoch 73/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0011 - mae: 0.0036 - val_loss: 0.0011 - val_mae: 0.0037\n",
      "Epoch 74/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0011 - mae: 0.0036 - val_loss: 0.0011 - val_mae: 0.0038\n",
      "Epoch 75/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0011 - mae: 0.0035 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 76/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0011 - mae: 0.0035 - val_loss: 0.0011 - val_mae: 0.0036\n",
      "Epoch 77/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 0.0011 - mae: 0.0035 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 78/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 0.0011 - mae: 0.0035 - val_loss: 0.0011 - val_mae: 0.0037\n",
      "Epoch 79/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0011 - mae: 0.0035 - val_loss: 0.0011 - val_mae: 0.0036\n",
      "Epoch 80/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0011 - mae: 0.0035 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 81/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 0.0011 - mae: 0.0035 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 82/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0011 - mae: 0.0035 - val_loss: 0.0011 - val_mae: 0.0034\n",
      "Epoch 83/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0011 - mae: 0.0034 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 84/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0011 - mae: 0.0034 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 85/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0011 - mae: 0.0034 - val_loss: 0.0011 - val_mae: 0.0034\n",
      "Epoch 86/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 0.0011 - mae: 0.0034 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 87/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 0.0011 - mae: 0.0034 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 88/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0011 - mae: 0.0034 - val_loss: 0.0011 - val_mae: 0.0034\n",
      "Epoch 89/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0011 - mae: 0.0034 - val_loss: 0.0011 - val_mae: 0.0036\n",
      "Epoch 90/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0011 - mae: 0.0034 - val_loss: 0.0011 - val_mae: 0.0033\n",
      "Epoch 91/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0011 - mae: 0.0034 - val_loss: 0.0011 - val_mae: 0.0037\n",
      "Epoch 92/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0011 - mae: 0.0033 - val_loss: 0.0011 - val_mae: 0.0033\n",
      "Epoch 93/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0011 - mae: 0.0033 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 94/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 0.0011 - mae: 0.0033 - val_loss: 0.0011 - val_mae: 0.0041\n",
      "Epoch 95/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0010 - mae: 0.0033 - val_loss: 0.0010 - val_mae: 0.0032\n",
      "Epoch 96/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0010 - mae: 0.0033 - val_loss: 0.0010 - val_mae: 0.0032\n",
      "Epoch 97/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0010 - mae: 0.0033 - val_loss: 0.0010 - val_mae: 0.0038\n",
      "Epoch 98/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0010 - mae: 0.0033 - val_loss: 0.0010 - val_mae: 0.0036\n",
      "Epoch 99/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0010 - mae: 0.0033 - val_loss: 0.0010 - val_mae: 0.0036\n",
      "Epoch 100/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0010 - mae: 0.0033 - val_loss: 0.0010 - val_mae: 0.0032\n",
      "Epoch 101/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0010 - mae: 0.0033 - val_loss: 0.0010 - val_mae: 0.0032\n",
      "Epoch 102/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0010 - mae: 0.0032 - val_loss: 0.0010 - val_mae: 0.0033\n",
      "Epoch 103/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0010 - mae: 0.0032 - val_loss: 0.0010 - val_mae: 0.0032\n",
      "Epoch 104/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0010 - mae: 0.0032 - val_loss: 0.0010 - val_mae: 0.0036\n",
      "Epoch 105/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0010 - mae: 0.0032 - val_loss: 0.0010 - val_mae: 0.0032\n",
      "Epoch 106/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 0.0010 - mae: 0.0032 - val_loss: 0.0010 - val_mae: 0.0032\n",
      "Epoch 107/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0010 - mae: 0.0032 - val_loss: 0.0010 - val_mae: 0.0032\n",
      "Epoch 108/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 0.0010 - mae: 0.0032 - val_loss: 9.9911e-04 - val_mae: 0.0032\n",
      "Epoch 109/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 9.9817e-04 - mae: 0.0032 - val_loss: 9.9889e-04 - val_mae: 0.0035\n",
      "Epoch 110/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 9.9491e-04 - mae: 0.0032 - val_loss: 9.9203e-04 - val_mae: 0.0032\n",
      "Epoch 111/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 9.9153e-04 - mae: 0.0032 - val_loss: 9.9012e-04 - val_mae: 0.0033\n",
      "Epoch 112/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 9.8788e-04 - mae: 0.0031 - val_loss: 9.8782e-04 - val_mae: 0.0034\n",
      "Epoch 113/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 9.8480e-04 - mae: 0.0031 - val_loss: 9.8224e-04 - val_mae: 0.0031\n",
      "Epoch 114/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 9.8168e-04 - mae: 0.0032 - val_loss: 9.7906e-04 - val_mae: 0.0032\n",
      "Epoch 115/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 9.7829e-04 - mae: 0.0031 - val_loss: 9.8011e-04 - val_mae: 0.0036\n",
      "Epoch 116/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 9.7495e-04 - mae: 0.0031 - val_loss: 9.7255e-04 - val_mae: 0.0032\n",
      "Epoch 117/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 9.7169e-04 - mae: 0.0031 - val_loss: 9.6977e-04 - val_mae: 0.0032\n",
      "Epoch 118/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 9.6861e-04 - mae: 0.0031 - val_loss: 9.6877e-04 - val_mae: 0.0033\n",
      "Epoch 119/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 9.6535e-04 - mae: 0.0031 - val_loss: 9.6290e-04 - val_mae: 0.0031\n",
      "Epoch 120/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 9.6233e-04 - mae: 0.0031 - val_loss: 9.5898e-04 - val_mae: 0.0030\n",
      "Epoch 121/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 9.5912e-04 - mae: 0.0031 - val_loss: 9.5576e-04 - val_mae: 0.0030\n",
      "Epoch 122/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 9.5606e-04 - mae: 0.0031 - val_loss: 9.5427e-04 - val_mae: 0.0032\n",
      "Epoch 123/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 9.5280e-04 - mae: 0.0031 - val_loss: 9.5081e-04 - val_mae: 0.0031\n",
      "Epoch 124/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 9.4990e-04 - mae: 0.0031 - val_loss: 9.4724e-04 - val_mae: 0.0030\n",
      "Epoch 125/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 9.4666e-04 - mae: 0.0031 - val_loss: 9.4617e-04 - val_mae: 0.0033\n",
      "Epoch 126/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 9.4363e-04 - mae: 0.0030 - val_loss: 9.4089e-04 - val_mae: 0.0030\n",
      "Epoch 127/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 9.4072e-04 - mae: 0.0030 - val_loss: 9.4185e-04 - val_mae: 0.0034\n",
      "Epoch 128/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 9.3768e-04 - mae: 0.0030 - val_loss: 9.3456e-04 - val_mae: 0.0029\n",
      "Epoch 129/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 9.3471e-04 - mae: 0.0030 - val_loss: 9.3182e-04 - val_mae: 0.0030\n",
      "Epoch 130/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 9.3139e-04 - mae: 0.0030 - val_loss: 9.2839e-04 - val_mae: 0.0029\n",
      "Epoch 131/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 9.2871e-04 - mae: 0.0030 - val_loss: 9.2822e-04 - val_mae: 0.0032\n",
      "Epoch 132/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 9.2569e-04 - mae: 0.0030 - val_loss: 9.2282e-04 - val_mae: 0.0029\n",
      "Epoch 133/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 9.2294e-04 - mae: 0.0030 - val_loss: 9.2019e-04 - val_mae: 0.0029\n",
      "Epoch 134/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 9.1981e-04 - mae: 0.0030 - val_loss: 9.1864e-04 - val_mae: 0.0031\n",
      "Epoch 135/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 9.1698e-04 - mae: 0.0030 - val_loss: 9.1372e-04 - val_mae: 0.0029\n",
      "Epoch 136/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 9.1401e-04 - mae: 0.0030 - val_loss: 9.1167e-04 - val_mae: 0.0030\n",
      "Epoch 137/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 9.1130e-04 - mae: 0.0030 - val_loss: 9.1198e-04 - val_mae: 0.0033\n",
      "Epoch 138/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 9.0848e-04 - mae: 0.0030 - val_loss: 9.1519e-04 - val_mae: 0.0039\n",
      "Epoch 139/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 9.0569e-04 - mae: 0.0030 - val_loss: 9.0248e-04 - val_mae: 0.0029\n",
      "Epoch 140/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 9.0252e-04 - mae: 0.0029 - val_loss: 9.0195e-04 - val_mae: 0.0031\n",
      "Epoch 141/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 8.9997e-04 - mae: 0.0030 - val_loss: 8.9694e-04 - val_mae: 0.0028\n",
      "Epoch 142/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.9694e-04 - mae: 0.0029 - val_loss: 8.9543e-04 - val_mae: 0.0030\n",
      "Epoch 143/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.9453e-04 - mae: 0.0030 - val_loss: 8.9353e-04 - val_mae: 0.0030\n",
      "Epoch 144/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 8.9160e-04 - mae: 0.0030 - val_loss: 9.0025e-04 - val_mae: 0.0041\n",
      "Epoch 145/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.8916e-04 - mae: 0.0030 - val_loss: 8.8619e-04 - val_mae: 0.0029\n",
      "Epoch 146/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.8615e-04 - mae: 0.0029 - val_loss: 8.8341e-04 - val_mae: 0.0029\n",
      "Epoch 147/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.8367e-04 - mae: 0.0029 - val_loss: 8.8034e-04 - val_mae: 0.0028\n",
      "Epoch 148/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.8099e-04 - mae: 0.0029 - val_loss: 8.8107e-04 - val_mae: 0.0032\n",
      "Epoch 149/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.7815e-04 - mae: 0.0029 - val_loss: 8.7580e-04 - val_mae: 0.0029\n",
      "Epoch 150/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.7586e-04 - mae: 0.0029 - val_loss: 8.7460e-04 - val_mae: 0.0030\n",
      "Epoch 151/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.7297e-04 - mae: 0.0029 - val_loss: 8.7169e-04 - val_mae: 0.0030\n",
      "Epoch 152/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.7025e-04 - mae: 0.0029 - val_loss: 8.6733e-04 - val_mae: 0.0028\n",
      "Epoch 153/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.6797e-04 - mae: 0.0029 - val_loss: 8.6590e-04 - val_mae: 0.0029\n",
      "Epoch 154/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.6506e-04 - mae: 0.0029 - val_loss: 8.6335e-04 - val_mae: 0.0029\n",
      "Epoch 155/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.6258e-04 - mae: 0.0029 - val_loss: 8.6176e-04 - val_mae: 0.0030\n",
      "Epoch 156/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.5996e-04 - mae: 0.0029 - val_loss: 8.5994e-04 - val_mae: 0.0030\n",
      "Epoch 157/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 8.5752e-04 - mae: 0.0029 - val_loss: 8.5463e-04 - val_mae: 0.0028\n",
      "Epoch 158/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.5448e-04 - mae: 0.0028 - val_loss: 8.5631e-04 - val_mae: 0.0032\n",
      "Epoch 159/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.5248e-04 - mae: 0.0029 - val_loss: 8.5142e-04 - val_mae: 0.0030\n",
      "Epoch 160/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.4972e-04 - mae: 0.0028 - val_loss: 8.4950e-04 - val_mae: 0.0030\n",
      "Epoch 161/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.4736e-04 - mae: 0.0029 - val_loss: 8.5539e-04 - val_mae: 0.0039\n",
      "Epoch 162/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 8.4472e-04 - mae: 0.0028 - val_loss: 8.4304e-04 - val_mae: 0.0029\n",
      "Epoch 163/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.4210e-04 - mae: 0.0028 - val_loss: 8.4035e-04 - val_mae: 0.0028\n",
      "Epoch 164/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.3990e-04 - mae: 0.0028 - val_loss: 8.3664e-04 - val_mae: 0.0027\n",
      "Epoch 165/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.3727e-04 - mae: 0.0028 - val_loss: 8.3595e-04 - val_mae: 0.0029\n",
      "Epoch 166/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.3500e-04 - mae: 0.0028 - val_loss: 8.3705e-04 - val_mae: 0.0032\n",
      "Epoch 167/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.3248e-04 - mae: 0.0028 - val_loss: 8.2980e-04 - val_mae: 0.0027\n",
      "Epoch 168/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.2995e-04 - mae: 0.0028 - val_loss: 8.3178e-04 - val_mae: 0.0031\n",
      "Epoch 169/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.2764e-04 - mae: 0.0028 - val_loss: 8.2865e-04 - val_mae: 0.0032\n",
      "Epoch 170/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 8.2524e-04 - mae: 0.0028 - val_loss: 8.2694e-04 - val_mae: 0.0032\n",
      "Epoch 171/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.2282e-04 - mae: 0.0028 - val_loss: 8.2103e-04 - val_mae: 0.0028\n",
      "Epoch 172/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.2026e-04 - mae: 0.0028 - val_loss: 8.1786e-04 - val_mae: 0.0028\n",
      "Epoch 173/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.1808e-04 - mae: 0.0028 - val_loss: 8.1760e-04 - val_mae: 0.0030\n",
      "Epoch 174/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.1571e-04 - mae: 0.0028 - val_loss: 8.1552e-04 - val_mae: 0.0030\n",
      "Epoch 175/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 8.1322e-04 - mae: 0.0028 - val_loss: 8.1119e-04 - val_mae: 0.0027\n",
      "Epoch 176/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.1088e-04 - mae: 0.0028 - val_loss: 8.0914e-04 - val_mae: 0.0028\n",
      "Epoch 177/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.0870e-04 - mae: 0.0028 - val_loss: 8.0623e-04 - val_mae: 0.0027\n",
      "Epoch 178/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.0637e-04 - mae: 0.0028 - val_loss: 8.0323e-04 - val_mae: 0.0026\n",
      "Epoch 179/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.0400e-04 - mae: 0.0028 - val_loss: 8.0278e-04 - val_mae: 0.0028\n",
      "Epoch 180/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 8.0138e-04 - mae: 0.0027 - val_loss: 7.9920e-04 - val_mae: 0.0027\n",
      "Epoch 181/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 7.9943e-04 - mae: 0.0028 - val_loss: 7.9751e-04 - val_mae: 0.0027\n",
      "Epoch 182/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 7.9718e-04 - mae: 0.0028 - val_loss: 7.9470e-04 - val_mae: 0.0027\n",
      "Epoch 183/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 7.9500e-04 - mae: 0.0028 - val_loss: 7.9479e-04 - val_mae: 0.0030\n",
      "Epoch 184/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.9273e-04 - mae: 0.0027 - val_loss: 7.9171e-04 - val_mae: 0.0029\n",
      "Epoch 185/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.9018e-04 - mae: 0.0027 - val_loss: 7.8909e-04 - val_mae: 0.0027\n",
      "Epoch 186/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.8838e-04 - mae: 0.0027 - val_loss: 7.8732e-04 - val_mae: 0.0029\n",
      "Epoch 187/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.8597e-04 - mae: 0.0027 - val_loss: 7.8792e-04 - val_mae: 0.0032\n",
      "Epoch 188/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 7.8367e-04 - mae: 0.0027 - val_loss: 7.8331e-04 - val_mae: 0.0029\n",
      "Epoch 189/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.8181e-04 - mae: 0.0027 - val_loss: 7.7896e-04 - val_mae: 0.0027\n",
      "Epoch 190/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.7948e-04 - mae: 0.0027 - val_loss: 7.7664e-04 - val_mae: 0.0026\n",
      "Epoch 191/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.7720e-04 - mae: 0.0027 - val_loss: 7.7503e-04 - val_mae: 0.0027\n",
      "Epoch 192/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.7484e-04 - mae: 0.0027 - val_loss: 7.7629e-04 - val_mae: 0.0031\n",
      "Epoch 193/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.7306e-04 - mae: 0.0027 - val_loss: 7.7022e-04 - val_mae: 0.0026\n",
      "Epoch 194/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.7074e-04 - mae: 0.0027 - val_loss: 7.6919e-04 - val_mae: 0.0027\n",
      "Epoch 195/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 7.6855e-04 - mae: 0.0027 - val_loss: 7.6618e-04 - val_mae: 0.0026\n",
      "Epoch 196/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.6640e-04 - mae: 0.0027 - val_loss: 7.6471e-04 - val_mae: 0.0027\n",
      "Epoch 197/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.6418e-04 - mae: 0.0027 - val_loss: 7.6275e-04 - val_mae: 0.0027\n",
      "Epoch 198/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.6215e-04 - mae: 0.0027 - val_loss: 7.5936e-04 - val_mae: 0.0026\n",
      "Epoch 199/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.5989e-04 - mae: 0.0027 - val_loss: 7.5925e-04 - val_mae: 0.0028\n",
      "Epoch 200/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 7.5800e-04 - mae: 0.0027 - val_loss: 7.5486e-04 - val_mae: 0.0026\n",
      "Epoch 201/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 7.5559e-04 - mae: 0.0026 - val_loss: 7.5676e-04 - val_mae: 0.0030\n",
      "Epoch 202/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.5374e-04 - mae: 0.0027 - val_loss: 7.5217e-04 - val_mae: 0.0027\n",
      "Epoch 203/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.5179e-04 - mae: 0.0027 - val_loss: 7.4987e-04 - val_mae: 0.0027\n",
      "Epoch 204/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.4967e-04 - mae: 0.0027 - val_loss: 7.4843e-04 - val_mae: 0.0027\n",
      "Epoch 205/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.4753e-04 - mae: 0.0027 - val_loss: 7.4713e-04 - val_mae: 0.0028\n",
      "Epoch 206/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.4566e-04 - mae: 0.0027 - val_loss: 7.4644e-04 - val_mae: 0.0029\n",
      "Epoch 207/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 7.4328e-04 - mae: 0.0026 - val_loss: 7.5277e-04 - val_mae: 0.0037\n",
      "Epoch 208/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.4162e-04 - mae: 0.0027 - val_loss: 7.3871e-04 - val_mae: 0.0026\n",
      "Epoch 209/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.3919e-04 - mae: 0.0026 - val_loss: 7.3708e-04 - val_mae: 0.0026\n",
      "Epoch 210/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.3741e-04 - mae: 0.0026 - val_loss: 7.3533e-04 - val_mae: 0.0026\n",
      "Epoch 211/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.3545e-04 - mae: 0.0026 - val_loss: 7.3274e-04 - val_mae: 0.0025\n",
      "Epoch 212/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.3364e-04 - mae: 0.0027 - val_loss: 7.3176e-04 - val_mae: 0.0027\n",
      "Epoch 213/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.3131e-04 - mae: 0.0026 - val_loss: 7.2935e-04 - val_mae: 0.0026\n",
      "Epoch 214/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.2968e-04 - mae: 0.0027 - val_loss: 7.2706e-04 - val_mae: 0.0026\n",
      "Epoch 215/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.2769e-04 - mae: 0.0026 - val_loss: 7.2475e-04 - val_mae: 0.0025\n",
      "Epoch 216/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.2556e-04 - mae: 0.0026 - val_loss: 7.2389e-04 - val_mae: 0.0026\n",
      "Epoch 217/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.2362e-04 - mae: 0.0026 - val_loss: 7.2276e-04 - val_mae: 0.0027\n",
      "Epoch 218/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.2161e-04 - mae: 0.0026 - val_loss: 7.2030e-04 - val_mae: 0.0026\n",
      "Epoch 219/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 7.1984e-04 - mae: 0.0026 - val_loss: 7.1896e-04 - val_mae: 0.0027\n",
      "Epoch 220/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 7.1783e-04 - mae: 0.0026 - val_loss: 7.1594e-04 - val_mae: 0.0026\n",
      "Epoch 221/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 7.1582e-04 - mae: 0.0026 - val_loss: 7.1559e-04 - val_mae: 0.0027\n",
      "Epoch 222/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.1417e-04 - mae: 0.0026 - val_loss: 7.1154e-04 - val_mae: 0.0025\n",
      "Epoch 223/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 7.1210e-04 - mae: 0.0026 - val_loss: 7.0995e-04 - val_mae: 0.0025\n",
      "Epoch 224/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.1032e-04 - mae: 0.0026 - val_loss: 7.0842e-04 - val_mae: 0.0026\n",
      "Epoch 225/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.0839e-04 - mae: 0.0026 - val_loss: 7.0717e-04 - val_mae: 0.0026\n",
      "Epoch 226/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 7.0642e-04 - mae: 0.0026 - val_loss: 7.0447e-04 - val_mae: 0.0025\n",
      "Epoch 227/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.0464e-04 - mae: 0.0026 - val_loss: 7.0673e-04 - val_mae: 0.0031\n",
      "Epoch 228/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.0275e-04 - mae: 0.0026 - val_loss: 7.0640e-04 - val_mae: 0.0033\n",
      "Epoch 229/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 7.0073e-04 - mae: 0.0025 - val_loss: 6.9860e-04 - val_mae: 0.0025\n",
      "Epoch 230/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 6.9913e-04 - mae: 0.0026 - val_loss: 6.9766e-04 - val_mae: 0.0026\n",
      "Epoch 231/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 6.9733e-04 - mae: 0.0026 - val_loss: 6.9443e-04 - val_mae: 0.0024\n",
      "Epoch 232/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 6.9534e-04 - mae: 0.0026 - val_loss: 6.9380e-04 - val_mae: 0.0025\n",
      "Epoch 233/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 6.9363e-04 - mae: 0.0026 - val_loss: 6.9102e-04 - val_mae: 0.0025\n",
      "Epoch 234/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 6.9184e-04 - mae: 0.0026 - val_loss: 6.9131e-04 - val_mae: 0.0026\n",
      "Epoch 235/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 6.9010e-04 - mae: 0.0026 - val_loss: 6.8749e-04 - val_mae: 0.0025\n",
      "Epoch 236/2000\n",
      "1230/1230 [==============================] - 3s 3ms/step - loss: 6.8807e-04 - mae: 0.0025 - val_loss: 6.8684e-04 - val_mae: 0.0026\n",
      "Epoch 237/2000\n",
      "1230/1230 [==============================] - 4s 3ms/step - loss: 6.8651e-04 - mae: 0.0026 - val_loss: 6.8548e-04 - val_mae: 0.0027\n",
      "Epoch 238/2000\n",
      " 163/1230 [==>...........................] - ETA: 2s - loss: 6.8687e-04 - mae: 0.0027"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 33\u001B[0m\n\u001B[0;32m     30\u001B[0m epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2000\u001B[39m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;66;03m# Modell trainieren (Annahme: X_train, y_train, X_val, y_val sind vordefiniert)\u001B[39;00m\n\u001B[1;32m---> 33\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_scaled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train_scaled\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     34\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     35\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     36\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     37\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mearly_stopping\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:1807\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1799\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1800\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1801\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1804\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1805\u001B[0m ):\n\u001B[0;32m   1806\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1807\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1808\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1809\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    829\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    831\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 832\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    834\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    835\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:868\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    865\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    866\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    867\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 868\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    869\u001B[0m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_config\u001B[49m\n\u001B[0;32m    870\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    871\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    872\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    873\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    874\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[1;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[0;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[1;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[0;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[0;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[0;32m   1319\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1320\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1321\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1322\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1323\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1324\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1325\u001B[0m     args,\n\u001B[0;32m   1326\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1327\u001B[0m     executing_eagerly)\n\u001B[0;32m   1328\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[1;34m(self, args)\u001B[0m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[0;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[1;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[0;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[0;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[0;32m    261\u001B[0m     )\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001B[0m, in \u001B[0;36mContext.call_function\u001B[1;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[0;32m   1484\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[0;32m   1485\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1486\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1487\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1488\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1489\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1490\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1491\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1492\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1493\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1494\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m   1495\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1496\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1500\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[0;32m   1501\u001B[0m   )\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Netzwerkarchitektur\n",
    "model = Sequential([\n",
    "\n",
    "    Dense(248, activation='relu', input_shape=(5,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.000001)),\n",
    "    \n",
    "    Dense(184, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.000001)),\n",
    "    \n",
    "    Dense(248, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.000001)),\n",
    "    \n",
    "    Dense(264, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.000001)),\n",
    "    \n",
    "    Dense(8, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.000001)),\n",
    "    \n",
    "    Dense(1 , activation = 'linear')\n",
    "])\n",
    "\n",
    "# Optimierer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "\n",
    "# Modell kompilieren (Verwendung von mean_squared_error als Verlustfunktion für Regression)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])  # Metriken für Regression: Mean Absolute Error und Mean Squared Error\n",
    "\n",
    "# Early Stopping Callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "# Trainingsparameter\n",
    "batch_size = 200 #100\n",
    "epochs = 2000\n",
    "\n",
    "# Modell trainieren (Annahme: X_train, y_train, X_val, y_val sind vordefiniert)\n",
    "history = model.fit(X_train_scaled, y_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T23:36:00.042016300Z",
     "start_time": "2024-03-29T23:22:18.016311500Z"
    }
   },
   "id": "8b52e1a9a6ff3aeb"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "Training für Fold 1...\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "1757/1757 [==============================] - 3s 1ms/step - loss: 0.1269 - mae: 0.1721 - val_loss: 0.0220 - val_mae: 0.0781\n",
      "Epoch 2/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0202 - mae: 0.0701 - val_loss: 0.0183 - val_mae: 0.0633\n",
      "Epoch 3/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0173 - mae: 0.0597 - val_loss: 0.0162 - val_mae: 0.0569\n",
      "Epoch 4/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0155 - mae: 0.0533 - val_loss: 0.0149 - val_mae: 0.0516\n",
      "Epoch 5/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0144 - mae: 0.0490 - val_loss: 0.0139 - val_mae: 0.0480\n",
      "Epoch 6/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0135 - mae: 0.0452 - val_loss: 0.0131 - val_mae: 0.0421\n",
      "Epoch 7/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0128 - mae: 0.0417 - val_loss: 0.0125 - val_mae: 0.0415\n",
      "Epoch 8/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0122 - mae: 0.0387 - val_loss: 0.0118 - val_mae: 0.0365\n",
      "Epoch 9/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0117 - mae: 0.0359 - val_loss: 0.0115 - val_mae: 0.0376\n",
      "Epoch 10/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0112 - mae: 0.0336 - val_loss: 0.0111 - val_mae: 0.0318\n",
      "Epoch 11/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0108 - mae: 0.0312 - val_loss: 0.0108 - val_mae: 0.0322\n",
      "Epoch 12/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0105 - mae: 0.0290 - val_loss: 0.0104 - val_mae: 0.0293\n",
      "Epoch 13/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0102 - mae: 0.0269 - val_loss: 0.0101 - val_mae: 0.0272\n",
      "Epoch 14/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0099 - mae: 0.0244 - val_loss: 0.0098 - val_mae: 0.0231\n",
      "Epoch 15/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0096 - mae: 0.0222 - val_loss: 0.0095 - val_mae: 0.0209\n",
      "Epoch 16/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0094 - mae: 0.0201 - val_loss: 0.0093 - val_mae: 0.0200\n",
      "Epoch 17/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0092 - mae: 0.0183 - val_loss: 0.0091 - val_mae: 0.0164\n",
      "Epoch 18/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0090 - mae: 0.0164 - val_loss: 0.0089 - val_mae: 0.0152\n",
      "Epoch 19/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0089 - mae: 0.0149 - val_loss: 0.0088 - val_mae: 0.0134\n",
      "Epoch 20/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0088 - mae: 0.0136 - val_loss: 0.0087 - val_mae: 0.0122\n",
      "Epoch 21/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0086 - mae: 0.0124 - val_loss: 0.0086 - val_mae: 0.0118\n",
      "Epoch 22/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0085 - mae: 0.0115 - val_loss: 0.0086 - val_mae: 0.0134\n",
      "Epoch 23/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0084 - mae: 0.0108 - val_loss: 0.0084 - val_mae: 0.0103\n",
      "Epoch 24/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0083 - mae: 0.0102 - val_loss: 0.0083 - val_mae: 0.0090\n",
      "Epoch 25/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0083 - mae: 0.0096 - val_loss: 0.0082 - val_mae: 0.0092\n",
      "Epoch 26/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0082 - mae: 0.0091 - val_loss: 0.0081 - val_mae: 0.0082\n",
      "Epoch 27/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0081 - mae: 0.0088 - val_loss: 0.0080 - val_mae: 0.0079\n",
      "Epoch 28/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0080 - mae: 0.0084 - val_loss: 0.0080 - val_mae: 0.0075\n",
      "Epoch 29/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 30/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0079 - mae: 0.0077 - val_loss: 0.0078 - val_mae: 0.0071\n",
      "Epoch 31/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0078 - mae: 0.0073 - val_loss: 0.0078 - val_mae: 0.0076\n",
      "Epoch 32/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0077 - mae: 0.0073 - val_loss: 0.0077 - val_mae: 0.0084\n",
      "Epoch 33/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0077 - mae: 0.0070 - val_loss: 0.0077 - val_mae: 0.0091\n",
      "Epoch 34/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0076 - mae: 0.0069 - val_loss: 0.0076 - val_mae: 0.0067\n",
      "Epoch 35/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0076 - mae: 0.0068 - val_loss: 0.0075 - val_mae: 0.0074\n",
      "Epoch 36/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0075 - mae: 0.0065 - val_loss: 0.0075 - val_mae: 0.0070\n",
      "Epoch 37/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0074 - mae: 0.0065 - val_loss: 0.0074 - val_mae: 0.0060\n",
      "Epoch 38/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0074 - mae: 0.0064 - val_loss: 0.0074 - val_mae: 0.0063\n",
      "Epoch 39/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0073 - mae: 0.0063 - val_loss: 0.0073 - val_mae: 0.0057\n",
      "Epoch 40/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0073 - mae: 0.0062 - val_loss: 0.0072 - val_mae: 0.0061\n",
      "Epoch 41/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0072 - mae: 0.0062 - val_loss: 0.0072 - val_mae: 0.0055\n",
      "Epoch 42/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0072 - mae: 0.0063 - val_loss: 0.0071 - val_mae: 0.0058\n",
      "Epoch 43/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0071 - mae: 0.0060 - val_loss: 0.0071 - val_mae: 0.0069\n",
      "Epoch 44/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0071 - mae: 0.0060 - val_loss: 0.0071 - val_mae: 0.0069\n",
      "Epoch 45/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0070 - mae: 0.0059 - val_loss: 0.0070 - val_mae: 0.0055\n",
      "Epoch 46/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0070 - mae: 0.0058 - val_loss: 0.0069 - val_mae: 0.0058\n",
      "Epoch 47/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0069 - mae: 0.0058 - val_loss: 0.0069 - val_mae: 0.0061\n",
      "Epoch 48/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0069 - mae: 0.0057 - val_loss: 0.0069 - val_mae: 0.0057\n",
      "Epoch 49/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0068 - mae: 0.0057 - val_loss: 0.0068 - val_mae: 0.0054\n",
      "Epoch 50/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0068 - mae: 0.0056 - val_loss: 0.0068 - val_mae: 0.0078\n",
      "Epoch 51/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0067 - mae: 0.0056 - val_loss: 0.0067 - val_mae: 0.0053\n",
      "Epoch 52/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0067 - mae: 0.0056 - val_loss: 0.0067 - val_mae: 0.0050\n",
      "Epoch 53/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0066 - mae: 0.0055 - val_loss: 0.0066 - val_mae: 0.0049\n",
      "Epoch 54/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0066 - mae: 0.0056 - val_loss: 0.0066 - val_mae: 0.0060\n",
      "Epoch 55/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0066 - mae: 0.0054 - val_loss: 0.0066 - val_mae: 0.0068\n",
      "Epoch 56/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0065 - mae: 0.0054 - val_loss: 0.0065 - val_mae: 0.0049\n",
      "Epoch 57/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0065 - mae: 0.0055 - val_loss: 0.0065 - val_mae: 0.0050\n",
      "Epoch 58/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0064 - mae: 0.0053 - val_loss: 0.0064 - val_mae: 0.0058\n",
      "Epoch 59/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0064 - mae: 0.0054 - val_loss: 0.0064 - val_mae: 0.0053\n",
      "Epoch 60/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0064 - mae: 0.0053 - val_loss: 0.0063 - val_mae: 0.0055\n",
      "Epoch 61/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0063 - mae: 0.0053 - val_loss: 0.0063 - val_mae: 0.0051\n",
      "Epoch 62/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0063 - mae: 0.0052 - val_loss: 0.0063 - val_mae: 0.0063\n",
      "Epoch 63/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0062 - mae: 0.0052 - val_loss: 0.0062 - val_mae: 0.0052\n",
      "Epoch 64/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0062 - mae: 0.0052 - val_loss: 0.0062 - val_mae: 0.0053\n",
      "Epoch 65/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0062 - mae: 0.0052 - val_loss: 0.0062 - val_mae: 0.0047\n",
      "Epoch 66/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0061 - mae: 0.0052 - val_loss: 0.0061 - val_mae: 0.0053\n",
      "Epoch 67/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0061 - mae: 0.0050 - val_loss: 0.0061 - val_mae: 0.0045\n",
      "Epoch 68/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0061 - mae: 0.0051 - val_loss: 0.0061 - val_mae: 0.0058\n",
      "Epoch 69/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0060 - mae: 0.0051 - val_loss: 0.0060 - val_mae: 0.0045\n",
      "Epoch 70/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0060 - mae: 0.0051 - val_loss: 0.0060 - val_mae: 0.0048\n",
      "Epoch 71/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0060 - mae: 0.0050 - val_loss: 0.0059 - val_mae: 0.0044\n",
      "Epoch 72/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0059 - mae: 0.0050 - val_loss: 0.0059 - val_mae: 0.0049\n",
      "Epoch 73/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0059 - mae: 0.0050 - val_loss: 0.0059 - val_mae: 0.0046\n",
      "Epoch 74/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0059 - mae: 0.0050 - val_loss: 0.0059 - val_mae: 0.0047\n",
      "Epoch 75/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0058 - mae: 0.0049 - val_loss: 0.0058 - val_mae: 0.0044\n",
      "Epoch 76/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0058 - mae: 0.0049 - val_loss: 0.0058 - val_mae: 0.0044\n",
      "Epoch 77/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0058 - mae: 0.0049 - val_loss: 0.0058 - val_mae: 0.0044\n",
      "Epoch 78/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0057 - mae: 0.0049 - val_loss: 0.0057 - val_mae: 0.0045\n",
      "Epoch 79/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0057 - mae: 0.0049 - val_loss: 0.0057 - val_mae: 0.0045\n",
      "Epoch 80/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0057 - mae: 0.0048 - val_loss: 0.0057 - val_mae: 0.0062\n",
      "Epoch 81/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0057 - mae: 0.0049 - val_loss: 0.0056 - val_mae: 0.0041\n",
      "Epoch 82/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0056 - mae: 0.0048 - val_loss: 0.0056 - val_mae: 0.0043\n",
      "Epoch 83/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0056 - mae: 0.0047 - val_loss: 0.0056 - val_mae: 0.0044\n",
      "Epoch 84/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0056 - mae: 0.0047 - val_loss: 0.0055 - val_mae: 0.0042\n",
      "Epoch 85/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0055 - mae: 0.0047 - val_loss: 0.0055 - val_mae: 0.0042\n",
      "Epoch 86/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0055 - mae: 0.0047 - val_loss: 0.0055 - val_mae: 0.0044\n",
      "Epoch 87/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0055 - mae: 0.0047 - val_loss: 0.0055 - val_mae: 0.0059\n",
      "Epoch 88/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0054 - mae: 0.0046 - val_loss: 0.0054 - val_mae: 0.0043\n",
      "Epoch 89/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0054 - mae: 0.0047 - val_loss: 0.0054 - val_mae: 0.0046\n",
      "Epoch 90/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0054 - mae: 0.0047 - val_loss: 0.0054 - val_mae: 0.0040\n",
      "Epoch 91/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0054 - mae: 0.0046 - val_loss: 0.0053 - val_mae: 0.0042\n",
      "Epoch 92/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0053 - mae: 0.0045 - val_loss: 0.0053 - val_mae: 0.0043\n",
      "Epoch 93/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0053 - mae: 0.0046 - val_loss: 0.0053 - val_mae: 0.0042\n",
      "Epoch 94/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0053 - mae: 0.0045 - val_loss: 0.0053 - val_mae: 0.0044\n",
      "Epoch 95/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0053 - mae: 0.0046 - val_loss: 0.0052 - val_mae: 0.0043\n",
      "Epoch 96/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0052 - mae: 0.0045 - val_loss: 0.0052 - val_mae: 0.0048\n",
      "Epoch 97/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0052 - mae: 0.0046 - val_loss: 0.0052 - val_mae: 0.0039\n",
      "Epoch 98/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0052 - mae: 0.0044 - val_loss: 0.0052 - val_mae: 0.0047\n",
      "Epoch 99/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0051 - mae: 0.0045 - val_loss: 0.0051 - val_mae: 0.0040\n",
      "Epoch 100/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0051 - mae: 0.0044 - val_loss: 0.0051 - val_mae: 0.0041\n",
      "Epoch 101/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0051 - mae: 0.0045 - val_loss: 0.0051 - val_mae: 0.0046\n",
      "Epoch 102/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0051 - mae: 0.0044 - val_loss: 0.0051 - val_mae: 0.0043\n",
      "Epoch 103/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0050 - mae: 0.0045 - val_loss: 0.0050 - val_mae: 0.0041\n",
      "Epoch 104/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0050 - mae: 0.0044 - val_loss: 0.0050 - val_mae: 0.0045\n",
      "Epoch 105/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0050 - mae: 0.0044 - val_loss: 0.0050 - val_mae: 0.0041\n",
      "Epoch 106/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0050 - mae: 0.0044 - val_loss: 0.0050 - val_mae: 0.0039\n",
      "Epoch 107/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0049 - mae: 0.0044 - val_loss: 0.0049 - val_mae: 0.0043\n",
      "Epoch 108/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0049 - mae: 0.0044 - val_loss: 0.0049 - val_mae: 0.0050\n",
      "Epoch 109/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0049 - mae: 0.0044 - val_loss: 0.0049 - val_mae: 0.0045\n",
      "Epoch 110/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0049 - mae: 0.0044 - val_loss: 0.0049 - val_mae: 0.0054\n",
      "Epoch 111/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0048 - mae: 0.0043 - val_loss: 0.0048 - val_mae: 0.0041\n",
      "Epoch 112/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0048 - mae: 0.0043 - val_loss: 0.0048 - val_mae: 0.0048\n",
      "Epoch 113/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0048 - mae: 0.0044 - val_loss: 0.0048 - val_mae: 0.0040\n",
      "Epoch 114/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0048 - mae: 0.0043 - val_loss: 0.0048 - val_mae: 0.0037\n",
      "Epoch 115/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0048 - mae: 0.0043 - val_loss: 0.0047 - val_mae: 0.0043\n",
      "Epoch 116/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0047 - mae: 0.0043 - val_loss: 0.0047 - val_mae: 0.0052\n",
      "Epoch 117/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0047 - mae: 0.0043 - val_loss: 0.0047 - val_mae: 0.0042\n",
      "Epoch 118/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0047 - mae: 0.0043 - val_loss: 0.0047 - val_mae: 0.0061\n",
      "Epoch 119/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0047 - mae: 0.0043 - val_loss: 0.0046 - val_mae: 0.0045\n",
      "Epoch 120/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0046 - mae: 0.0042 - val_loss: 0.0046 - val_mae: 0.0037\n",
      "Epoch 121/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0046 - mae: 0.0042 - val_loss: 0.0046 - val_mae: 0.0040\n",
      "Epoch 122/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0046 - mae: 0.0042 - val_loss: 0.0046 - val_mae: 0.0039\n",
      "Epoch 123/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0046 - mae: 0.0042 - val_loss: 0.0046 - val_mae: 0.0040\n",
      "Epoch 124/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0045 - mae: 0.0042 - val_loss: 0.0045 - val_mae: 0.0041\n",
      "Epoch 125/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0045 - mae: 0.0042 - val_loss: 0.0045 - val_mae: 0.0037\n",
      "Epoch 126/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0045 - mae: 0.0041 - val_loss: 0.0045 - val_mae: 0.0063\n",
      "Epoch 127/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0045 - mae: 0.0041 - val_loss: 0.0045 - val_mae: 0.0049\n",
      "Epoch 128/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0045 - mae: 0.0041 - val_loss: 0.0044 - val_mae: 0.0038\n",
      "Epoch 129/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0044 - mae: 0.0041 - val_loss: 0.0044 - val_mae: 0.0055\n",
      "Epoch 130/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0044 - mae: 0.0041 - val_loss: 0.0044 - val_mae: 0.0037\n",
      "Epoch 131/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0044 - mae: 0.0041 - val_loss: 0.0044 - val_mae: 0.0056\n",
      "Epoch 132/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0044 - mae: 0.0041 - val_loss: 0.0044 - val_mae: 0.0037\n",
      "Epoch 133/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0043 - mae: 0.0040 - val_loss: 0.0043 - val_mae: 0.0037\n",
      "Epoch 134/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0043 - mae: 0.0040 - val_loss: 0.0043 - val_mae: 0.0049\n",
      "Epoch 135/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0043 - mae: 0.0041 - val_loss: 0.0043 - val_mae: 0.0042\n",
      "Epoch 136/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0043 - mae: 0.0040 - val_loss: 0.0043 - val_mae: 0.0038\n",
      "Epoch 137/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0043 - mae: 0.0040 - val_loss: 0.0043 - val_mae: 0.0040\n",
      "Epoch 138/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0042 - mae: 0.0040 - val_loss: 0.0042 - val_mae: 0.0037\n",
      "Epoch 139/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0042 - mae: 0.0039 - val_loss: 0.0042 - val_mae: 0.0036\n",
      "Epoch 140/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0042 - mae: 0.0041 - val_loss: 0.0042 - val_mae: 0.0038\n",
      "Epoch 141/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0042 - mae: 0.0040 - val_loss: 0.0042 - val_mae: 0.0037\n",
      "Epoch 142/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0042 - mae: 0.0040 - val_loss: 0.0041 - val_mae: 0.0036\n",
      "Epoch 143/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0041 - mae: 0.0039 - val_loss: 0.0041 - val_mae: 0.0036\n",
      "Epoch 144/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0041 - mae: 0.0039 - val_loss: 0.0041 - val_mae: 0.0036\n",
      "Epoch 145/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0041 - mae: 0.0039 - val_loss: 0.0041 - val_mae: 0.0049\n",
      "Epoch 146/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0041 - mae: 0.0040 - val_loss: 0.0041 - val_mae: 0.0038\n",
      "Epoch 147/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0041 - mae: 0.0039 - val_loss: 0.0040 - val_mae: 0.0033\n",
      "Epoch 148/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0040 - mae: 0.0039 - val_loss: 0.0040 - val_mae: 0.0037\n",
      "Epoch 149/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0040 - mae: 0.0039 - val_loss: 0.0040 - val_mae: 0.0039\n",
      "Epoch 150/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0040 - mae: 0.0040 - val_loss: 0.0040 - val_mae: 0.0044\n",
      "Epoch 151/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0040 - mae: 0.0039 - val_loss: 0.0040 - val_mae: 0.0038\n",
      "Epoch 152/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0040 - mae: 0.0039 - val_loss: 0.0039 - val_mae: 0.0037\n",
      "Epoch 153/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0039 - mae: 0.0039 - val_loss: 0.0039 - val_mae: 0.0048\n",
      "Epoch 154/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0039 - mae: 0.0039 - val_loss: 0.0039 - val_mae: 0.0034\n",
      "Epoch 155/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0039 - mae: 0.0039 - val_loss: 0.0039 - val_mae: 0.0037\n",
      "Epoch 156/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0039 - mae: 0.0039 - val_loss: 0.0039 - val_mae: 0.0034\n",
      "Epoch 157/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0039 - mae: 0.0038 - val_loss: 0.0038 - val_mae: 0.0035\n",
      "Epoch 158/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0038 - mae: 0.0039 - val_loss: 0.0038 - val_mae: 0.0036\n",
      "Epoch 159/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0038 - mae: 0.0038 - val_loss: 0.0038 - val_mae: 0.0045\n",
      "Epoch 160/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0038 - mae: 0.0038 - val_loss: 0.0038 - val_mae: 0.0035\n",
      "Epoch 161/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0038 - mae: 0.0037 - val_loss: 0.0038 - val_mae: 0.0037\n",
      "Epoch 162/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0038 - mae: 0.0038 - val_loss: 0.0038 - val_mae: 0.0034\n",
      "Epoch 163/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0037 - mae: 0.0037 - val_loss: 0.0038 - val_mae: 0.0058\n",
      "Epoch 164/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0037 - mae: 0.0038 - val_loss: 0.0037 - val_mae: 0.0039\n",
      "Epoch 165/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0037 - mae: 0.0038 - val_loss: 0.0037 - val_mae: 0.0033\n",
      "Epoch 166/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0037 - mae: 0.0038 - val_loss: 0.0037 - val_mae: 0.0034\n",
      "Epoch 167/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0037 - mae: 0.0038 - val_loss: 0.0037 - val_mae: 0.0043\n",
      "Epoch 168/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0037 - mae: 0.0038 - val_loss: 0.0037 - val_mae: 0.0055\n",
      "Epoch 169/1000\n",
      "1757/1757 [==============================] - 3s 1ms/step - loss: 0.0036 - mae: 0.0038 - val_loss: 0.0036 - val_mae: 0.0039\n",
      "Epoch 170/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0036 - mae: 0.0037 - val_loss: 0.0036 - val_mae: 0.0031\n",
      "Epoch 171/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0036 - mae: 0.0037 - val_loss: 0.0036 - val_mae: 0.0037\n",
      "Epoch 172/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0036 - mae: 0.0037 - val_loss: 0.0036 - val_mae: 0.0033\n",
      "Epoch 173/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0036 - mae: 0.0038 - val_loss: 0.0036 - val_mae: 0.0035\n",
      "Epoch 174/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0035 - mae: 0.0038 - val_loss: 0.0035 - val_mae: 0.0033\n",
      "Epoch 175/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0035 - mae: 0.0036 - val_loss: 0.0035 - val_mae: 0.0041\n",
      "Epoch 176/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0035 - mae: 0.0037 - val_loss: 0.0035 - val_mae: 0.0036\n",
      "Epoch 177/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0035 - mae: 0.0037 - val_loss: 0.0035 - val_mae: 0.0032\n",
      "Epoch 178/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0035 - mae: 0.0037 - val_loss: 0.0035 - val_mae: 0.0033\n",
      "Epoch 179/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0035 - mae: 0.0037 - val_loss: 0.0035 - val_mae: 0.0035\n",
      "Epoch 180/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0034 - mae: 0.0037 - val_loss: 0.0034 - val_mae: 0.0036\n",
      "Epoch 181/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0034 - mae: 0.0036 - val_loss: 0.0034 - val_mae: 0.0042\n",
      "Epoch 182/1000\n",
      "1695/1757 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0036"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 36\u001B[0m\n\u001B[0;32m     33\u001B[0m early_stopping \u001B[38;5;241m=\u001B[39m EarlyStopping(monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m, patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmin\u001B[39m\u001B[38;5;124m'\u001B[39m, restore_best_weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTraining für Fold \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfold_no\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m...\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 36\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_fold\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train_fold\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m16\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX_val_fold\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_val_fold\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mearly_stopping\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m# Speichere die Ergebnisse des aktuellen Folds\u001B[39;00m\n\u001B[0;32m     39\u001B[0m val_loss_results\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mmin\u001B[39m(history\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m]))\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:1856\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1840\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_eval_data_handler\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1841\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_eval_data_handler \u001B[38;5;241m=\u001B[39m data_adapter\u001B[38;5;241m.\u001B[39mget_data_handler(\n\u001B[0;32m   1842\u001B[0m         x\u001B[38;5;241m=\u001B[39mval_x,\n\u001B[0;32m   1843\u001B[0m         y\u001B[38;5;241m=\u001B[39mval_y,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1854\u001B[0m         pss_evaluation_shards\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pss_evaluation_shards,\n\u001B[0;32m   1855\u001B[0m     )\n\u001B[1;32m-> 1856\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1857\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_x\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1858\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_y\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1859\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_sample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1860\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1861\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1862\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1863\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1864\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1865\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1866\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1867\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_use_cached_eval_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1868\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1869\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m   1870\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval_\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name: val \u001B[38;5;28;01mfor\u001B[39;00m name, val \u001B[38;5;129;01min\u001B[39;00m val_logs\u001B[38;5;241m.\u001B[39mitems()\n\u001B[0;32m   1871\u001B[0m }\n\u001B[0;32m   1872\u001B[0m epoch_logs\u001B[38;5;241m.\u001B[39mupdate(val_logs)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:2296\u001B[0m, in \u001B[0;36mModel.evaluate\u001B[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001B[0m\n\u001B[0;32m   2292\u001B[0m             \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   2293\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m\"\u001B[39m, step_num\u001B[38;5;241m=\u001B[39mstep, _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   2294\u001B[0m             ):\n\u001B[0;32m   2295\u001B[0m                 callbacks\u001B[38;5;241m.\u001B[39mon_test_batch_begin(step)\n\u001B[1;32m-> 2296\u001B[0m                 logs \u001B[38;5;241m=\u001B[39m \u001B[43mtest_function_runner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_step\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2297\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mdataset_or_iterator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2298\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mdata_handler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2299\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2300\u001B[0m \u001B[43m                    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_pss_evaluation_shards\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2301\u001B[0m \u001B[43m                \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2303\u001B[0m logs \u001B[38;5;241m=\u001B[39m tf_utils\u001B[38;5;241m.\u001B[39msync_to_numpy_or_python_type(logs)\n\u001B[0;32m   2304\u001B[0m \u001B[38;5;66;03m# Override with model metrics instead of last step logs\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:4108\u001B[0m, in \u001B[0;36m_TestFunction.run_step\u001B[1;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001B[0m\n\u001B[0;32m   4107\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_step\u001B[39m(\u001B[38;5;28mself\u001B[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001B[1;32m-> 4108\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_or_iterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4109\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   4110\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    829\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    831\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 832\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    834\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    835\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:877\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    874\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    875\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[0;32m    876\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[1;32m--> 877\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    878\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[0;32m    879\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    880\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables:\n\u001B[0;32m    881\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    882\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[1;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[0;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[1;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[0;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[0;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[0;32m   1319\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1320\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1321\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1322\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1323\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1324\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1325\u001B[0m     args,\n\u001B[0;32m   1326\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1327\u001B[0m     executing_eagerly)\n\u001B[0;32m   1328\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[1;34m(self, args)\u001B[0m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[0;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[1;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[0;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[0;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[0;32m    261\u001B[0m     )\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001B[0m, in \u001B[0;36mContext.call_function\u001B[1;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[0;32m   1484\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[0;32m   1485\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1486\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1487\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1488\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1489\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1490\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1491\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1492\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1493\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1494\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m   1495\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1496\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1500\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[0;32m   1501\u001B[0m   )\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# # Initialisiere Listen, um Ergebnisse zu speichern\n",
    "# val_loss_results = []\n",
    "# val_mae_results = []\n",
    "# \n",
    "# # Funktion, um das Modell zu erstellen\n",
    "# def create_model():\n",
    "#     model = Sequential([\n",
    "#                 Dense(232, activation='relu', input_shape=(3,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "#                 \n",
    "#                 Dense(152, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "#                 \n",
    "#                 Dense(232, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "#                 \n",
    "#                 Dense(1 , activation = 'linear')\n",
    "# \n",
    "#     ])\n",
    "#     optimizer = Adam(learning_rate=0.00001)\n",
    "#     model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "#     return model\n",
    "# \n",
    "# # K-Fold Cross-Validation Konfiguration\n",
    "# n_splits = 5\n",
    "# kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "# \n",
    "# # Leistungsüberwachung\n",
    "# fold_no = 1\n",
    "# for train_index, val_index in kf.split(X_train_scaled):\n",
    "#     X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "#     y_train_fold, y_val_fold = y_train_scaled[train_index], y_train_scaled[val_index]\n",
    "# \n",
    "#     model = create_model()\n",
    "# \n",
    "#     early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "# \n",
    "#     print(f'Training für Fold {fold_no}...')\n",
    "#     history = model.fit(X_train_fold, y_train_fold, batch_size=16, epochs=1000, validation_data=(X_val_fold, y_val_fold), callbacks=[early_stopping], verbose=1)\n",
    "# \n",
    "#     # Speichere die Ergebnisse des aktuellen Folds\n",
    "#     val_loss_results.append(min(history.history['val_loss']))\n",
    "#     val_mae_results.append(min(history.history['val_mae']))\n",
    "# \n",
    "#     fold_no += 1\n",
    "# \n",
    "# # Berechne den Durchschnitt über alle Folds\n",
    "# average_val_loss = np.mean(val_loss_results)\n",
    "# average_val_mae = np.mean(val_mae_results)\n",
    "# \n",
    "# # Gib die durchschnittlichen Ergebnisse aus\n",
    "# print(f'Durchschnittlicher Validation Loss: {average_val_loss}')\n",
    "# print(f'Durchschnittlicher Validation MAE: {average_val_mae}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T13:07:25.049745600Z",
     "start_time": "2024-03-18T13:01:03.563514Z"
    }
   },
   "id": "929336b1a7ac475d"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 - 0s - loss: 0.0123 - mae: 0.0921 - 53ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.012280642054975033, 0.09208700805902481]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test_scaled_2, y_test_scaled_2, verbose=2)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T23:36:18.672883800Z",
     "start_time": "2024-03-29T23:36:18.584342500Z"
    }
   },
   "id": "4b02697cbcecd185"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bsp. Predicted: [729.07355] Actual: [754.68] \n",
      "Durchschnittliche Abweichung (MAE): [204.24159161]\n",
      "13.858617537521726\n"
     ]
    }
   ],
   "source": [
    "scaled_predicted_values = model.predict(X_test_scaled_2, verbose = 0)\n",
    "\n",
    "# Führen Sie die Rücktransformation der skalierten Werte durch\n",
    "original_predicted_values = scaler_target.inverse_transform(scaled_predicted_values)\n",
    "original_actual_values = scaler_target.inverse_transform(y_test_scaled_2)  # y_test sind die skalierten tatsächlichen Werte\n",
    "print(f' Bsp. Predicted: {original_predicted_values[100]} Actual: {original_actual_values[100]} ')\n",
    "\n",
    "def calculate_mae(list1, list2):\n",
    "    # Stelle sicher, dass beide Listen die gleiche Länge haben\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Listen müssen die gleiche Länge haben\")\n",
    "\n",
    "    # Berechne die absolute Differenz zwischen den Elementen der Listen\n",
    "    differences = [abs(x - y) for x, y in zip(list1, list2)]\n",
    "\n",
    "    # Berechne den Durchschnitt der absoluten Differenzen\n",
    "    mae = sum(differences) / len(differences)\n",
    "\n",
    "    return mae\n",
    "\n",
    "# Beispiel\n",
    "list1 = original_predicted_values\n",
    "list2 = original_actual_values\n",
    "\n",
    "mae = calculate_mae(list1, list2)\n",
    "print(f\"Durchschnittliche Abweichung (MAE): {mae}\")\n",
    "errors = np.abs((original_actual_values - original_predicted_values) / original_actual_values)\n",
    "mape = np.mean(errors) * 100\n",
    "print(mape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T23:36:23.730622900Z",
     "start_time": "2024-03-29T23:36:23.570416500Z"
    }
   },
   "id": "a402d28abbd82f60"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Werte die kleiner sind: 825\n"
     ]
    },
    {
     "data": {
      "text/plain": "            Echt  Vorhergesagt  X-Koordinate  Y-Koordinate  Zeitpunkt  \\\n754   982.962341        1441.2          0.70          0.80        1.0   \n805   971.618652        1429.5          0.75          0.80        1.0   \n856   962.316711        1416.5          0.80          0.80        1.0   \n755   925.077393        1378.8          0.70          0.82        1.0   \n753  1046.135986        1497.6          0.70          0.78        1.0   \n..           ...           ...           ...           ...        ...   \n564  1227.413940        1050.8          0.55          0.06        1.0   \n514  1326.276245        1149.4          0.50          0.08        1.0   \n513  1232.887451        1055.1          0.50          0.06        1.0   \n462  1237.175049        1059.0          0.45          0.06        1.0   \n463  1334.081909        1154.7          0.45          0.08        1.0   \n\n        Strom  Kraft   Differenz  \n754  0.333333   0.25 -458.237659  \n805  0.333333   0.25 -457.881348  \n856  0.333333   0.25 -454.183289  \n755  0.333333   0.25 -453.722607  \n753  0.333333   0.25 -451.464014  \n..        ...    ...         ...  \n564  0.333333   0.25  176.613940  \n514  0.333333   0.25  176.876245  \n513  0.333333   0.25  177.787451  \n462  0.333333   0.25  178.175049  \n463  0.333333   0.25  179.381909  \n\n[1071 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Echt</th>\n      <th>Vorhergesagt</th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Differenz</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>754</th>\n      <td>982.962341</td>\n      <td>1441.2</td>\n      <td>0.70</td>\n      <td>0.80</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.25</td>\n      <td>-458.237659</td>\n    </tr>\n    <tr>\n      <th>805</th>\n      <td>971.618652</td>\n      <td>1429.5</td>\n      <td>0.75</td>\n      <td>0.80</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.25</td>\n      <td>-457.881348</td>\n    </tr>\n    <tr>\n      <th>856</th>\n      <td>962.316711</td>\n      <td>1416.5</td>\n      <td>0.80</td>\n      <td>0.80</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.25</td>\n      <td>-454.183289</td>\n    </tr>\n    <tr>\n      <th>755</th>\n      <td>925.077393</td>\n      <td>1378.8</td>\n      <td>0.70</td>\n      <td>0.82</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.25</td>\n      <td>-453.722607</td>\n    </tr>\n    <tr>\n      <th>753</th>\n      <td>1046.135986</td>\n      <td>1497.6</td>\n      <td>0.70</td>\n      <td>0.78</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.25</td>\n      <td>-451.464014</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>564</th>\n      <td>1227.413940</td>\n      <td>1050.8</td>\n      <td>0.55</td>\n      <td>0.06</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.25</td>\n      <td>176.613940</td>\n    </tr>\n    <tr>\n      <th>514</th>\n      <td>1326.276245</td>\n      <td>1149.4</td>\n      <td>0.50</td>\n      <td>0.08</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.25</td>\n      <td>176.876245</td>\n    </tr>\n    <tr>\n      <th>513</th>\n      <td>1232.887451</td>\n      <td>1055.1</td>\n      <td>0.50</td>\n      <td>0.06</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.25</td>\n      <td>177.787451</td>\n    </tr>\n    <tr>\n      <th>462</th>\n      <td>1237.175049</td>\n      <td>1059.0</td>\n      <td>0.45</td>\n      <td>0.06</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.25</td>\n      <td>178.175049</td>\n    </tr>\n    <tr>\n      <th>463</th>\n      <td>1334.081909</td>\n      <td>1154.7</td>\n      <td>0.45</td>\n      <td>0.08</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.25</td>\n      <td>179.381909</td>\n    </tr>\n  </tbody>\n</table>\n<p>1071 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame({'Echt': [val[0] for val in list1], 'Vorhergesagt': [val[0] for val in list2]})\n",
    "df_result['X-Koordinate'] = X_test_scaled_2[:, 0]\n",
    "df_result['Y-Koordinate'] = X_test_scaled_2[:, 1]\n",
    "df_result['Zeitpunkt'] = X_test_scaled_2[:, 2]\n",
    "df_result['Strom'] = X_test_scaled_2[:, 3]\n",
    "df_result['Kraft'] = X_test_scaled_2[:, 4]\n",
    "\n",
    "df_result['Differenz'] = df_result['Echt'] - df_result['Vorhergesagt']\n",
    "df_result['Differenz'].sort_values()\n",
    "sorted_df = df_result.sort_values(by= 'Differenz')\n",
    "Anzahl_Punkte = (sorted_df['Differenz'] < 20).sum()\n",
    "print(\"Anzahl der Werte die kleiner sind:\", Anzahl_Punkte)\n",
    "\n",
    "sorted_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T23:36:28.428317300Z",
     "start_time": "2024-03-29T23:36:28.384184200Z"
    }
   },
   "id": "7ffe8ddf2200f429"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: [0.99989271]\n"
     ]
    }
   ],
   "source": [
    "#Berechnung der Auswertungsgröße R^2\n",
    "\n",
    "def calculate_r_squared(predicted, actual):\n",
    "    # Berechnung des Mittelwerts der tatsächlichen Werte\n",
    "    mean_actual = sum(actual) / len(actual)\n",
    "    \n",
    "    # Berechnung der totalen Summe der Quadrate (SST)\n",
    "    sst = sum((x - mean_actual) ** 2 for x in actual)\n",
    "    \n",
    "    # Berechnung der Summe der Quadrate der Residuen (SSE)\n",
    "    sse = sum((actual[i] - predicted[i]) ** 2 for i in range(len(actual)))\n",
    "    \n",
    "    # Berechnung des R^2-Wertes\n",
    "    r_squared = 1 - (sse / sst)\n",
    "    \n",
    "    return r_squared\n",
    "\n",
    "# Berechnung von R^2 mit den bereitgestellten Listen\n",
    "r_squared = calculate_r_squared(list1, list2)\n",
    "\n",
    "print(f\"R^2: {r_squared}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T13:59:02.256620900Z",
     "start_time": "2024-03-26T13:59:01.728316700Z"
    }
   },
   "id": "4c350477801f0961"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mae = history.history['loss']\n",
    "val_mae = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(mae) + 1)\n",
    "\n",
    "# MAE Diagramm\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, mae, 'r', label='Training MSE')\n",
    "plt.plot(epochs, val_mae, 'b', label='Validation MSE')\n",
    "plt.title('Training and Validation MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T12:29:07.617414Z",
     "start_time": "2024-03-25T12:29:07.401346700Z"
    }
   },
   "id": "3688dd7102e95baf"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mae = history.history['mae']\n",
    "val_mae = history.history['val_mae']\n",
    "\n",
    "epochs = range(1, len(mae) + 1)\n",
    "\n",
    "# MAE Diagramm\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, mae, 'r', label='Training MAE')\n",
    "plt.plot(epochs, val_mae, 'b', label='Validation MAE')\n",
    "plt.title('Training and Validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "#plt.ylim(0.00, 0.01)\n",
    "\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T12:29:10.425247700Z",
     "start_time": "2024-03-25T12:29:10.293470600Z"
    }
   },
   "id": "b8d71e5c44c48bef"
  },
  {
   "cell_type": "markdown",
   "id": "553df6fa",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x000001B625802E50>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 770, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 47\u001B[0m\n\u001B[0;32m     45\u001B[0m grid_search \u001B[38;5;241m=\u001B[39m GridSearchCV(estimator\u001B[38;5;241m=\u001B[39mmodel, param_grid\u001B[38;5;241m=\u001B[39mparam_grid, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m     46\u001B[0m \u001B[38;5;66;03m# Hinweis: Stellen Sie sicher, dass Ihre Daten (X_train_scaled, y_train_scaled) korrekt definiert sind\u001B[39;00m\n\u001B[1;32m---> 47\u001B[0m grid_result \u001B[38;5;241m=\u001B[39m \u001B[43mgrid_search\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_scaled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train_scaled\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;66;03m# Beste Parameter und Score ausgeben\u001B[39;00m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBeste Parameter:\u001B[39m\u001B[38;5;124m\"\u001B[39m, grid_search\u001B[38;5;241m.\u001B[39mbest_params_)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\base.py:1351\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1344\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1346\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1347\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1348\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1349\u001B[0m     )\n\u001B[0;32m   1350\u001B[0m ):\n\u001B[1;32m-> 1351\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, **params)\u001B[0m\n\u001B[0;32m    964\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m    965\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m    966\u001B[0m     )\n\u001B[0;32m    968\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m--> 970\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    972\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m    973\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m    974\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1525\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1526\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1527\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    908\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    909\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m    910\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    911\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    912\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[0;32m    913\u001B[0m         )\n\u001B[0;32m    914\u001B[0m     )\n\u001B[1;32m--> 916\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    917\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    918\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    919\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    920\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    921\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    922\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    923\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    924\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    925\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    926\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    927\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    928\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    929\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    930\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrouted_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplitter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    931\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    932\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    934\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    935\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    936\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    937\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    938\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    939\u001B[0m     )\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     62\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     63\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     64\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     66\u001B[0m )\n\u001B[1;32m---> 67\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\joblib\\parallel.py:1952\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1946\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[0;32m   1947\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[0;32m   1948\u001B[0m \u001B[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001B[39;00m\n\u001B[0;32m   1949\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[0;32m   1950\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 1952\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\joblib\\parallel.py:1595\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[1;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[0;32m   1592\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[0;32m   1594\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[1;32m-> 1595\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[0;32m   1597\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[0;32m   1598\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[0;32m   1599\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[0;32m   1600\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[0;32m   1601\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\joblib\\parallel.py:1707\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1702\u001B[0m \u001B[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001B[39;00m\n\u001B[0;32m   1703\u001B[0m \u001B[38;5;66;03m# async callbacks to progress.\u001B[39;00m\n\u001B[0;32m   1704\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ((\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m   1705\u001B[0m     (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mget_status(\n\u001B[0;32m   1706\u001B[0m         timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout) \u001B[38;5;241m==\u001B[39m TASK_PENDING)):\n\u001B[1;32m-> 1707\u001B[0m     time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m0.01\u001B[39m)\n\u001B[0;32m   1708\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m   1710\u001B[0m \u001B[38;5;66;03m# We need to be careful: the job list can be filling up as\u001B[39;00m\n\u001B[0;32m   1711\u001B[0m \u001B[38;5;66;03m# we empty it and Python list are not thread-safe by\u001B[39;00m\n\u001B[0;32m   1712\u001B[0m \u001B[38;5;66;03m# default hence the use of the lock\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def build_model(learning_rate=0.00001, activation='relu', regularization=0.00001, dropout_rate=0.0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(232, activation=activation, input_shape=(3,), kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(152, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(232, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Verwenden Sie eine Funktion, um das Modell zu instanziieren, für scikit-learn Wrapper\n",
    "model = KerasRegressor(model=build_model, verbose=2, callbacks=[early_stopping])\n",
    "\n",
    "# Anpassung der Parameter im param_grid\n",
    "param_grid = {\n",
    "    'model__learning_rate': [0.00001],\n",
    "    'model__regularization': [0.00001],\n",
    "    'fit__batch_size': [16, 32, 64, 100],\n",
    "    'fit__epochs': [100],\n",
    "    'model__dropout_rate' : [0.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=2)\n",
    "# Hinweis: Stellen Sie sicher, dass Ihre Daten (X_train_scaled, y_train_scaled) korrekt definiert sind\n",
    "grid_result = grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "# Beste Parameter und Score ausgeben\n",
    "print(\"Beste Parameter:\", grid_search.best_params_)\n",
    "print(\"Beste Genauigkeit:\", grid_search.best_score_)\n",
    "\n",
    "with open(\"Gridsearch_D4_t_1.txt\", \"w\") as f:\n",
    "    f.write(f\"Beste Parameter: {grid_search.best_params_}\\n\")\n",
    "    f.write(f\"Beste Genauigkeit: {grid_search.best_score_}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T12:15:54.960082300Z",
     "start_time": "2024-03-18T11:56:34.729533600Z"
    }
   },
   "id": "7464a951f44a07ee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Funktion zum Erstellen des Modells\n",
    "# def build_model(hp):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(hp.Int('input_units', min_value=8, max_value=328, step=16), input_shape=(3,), activation='relu'))\n",
    "#     for i in range(hp.Int('n_layers', 1, 10)):\n",
    "#         model.add(Dense(hp.Int(f'units_{i}', min_value=8, max_value=328, step=16), activation='relu'))\n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     return modeDer\n",
    "# \n",
    "# # Durchführung der Random Search dreimal\n",
    "# for run in range(1, 4):\n",
    "#     # Anpassen des Verzeichnisses und des Projektnamens für jeden Durchlauf\n",
    "#     directory = 'random_search'\n",
    "#     project_name = f'random_search_D4_t_1_{run}'\n",
    "# \n",
    "#     tuner = RandomSearch(\n",
    "#         build_model,\n",
    "#         objective='val_loss',\n",
    "#         max_trials=100,\n",
    "#         executions_per_trial=2,\n",
    "#         directory=directory,\n",
    "#         project_name=project_name\n",
    "#     )\n",
    "# \n",
    "#     # Durchführung des Random Search\n",
    "#     tuner.search(X_train_scaled, y_train_scaled, epochs=50, verbose =0, batch_size=50, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=5\n",
    "#     # Abrufen und Speichern des besten Modells\n",
    "#     best_model = tuner.get_best_models(num_models=1)[0]\n",
    "#     model_path = os.path.join(directory, project_name, 'best_model.h5') \n",
    "#     best_model.save(model_path)\n",
    "# \n",
    "# \n",
    "#     # Optional: Abrufen und Ausgeben der besten Hyperparameter\n",
    "#     best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "# \n",
    "#     # Konvertieren der Hyperparameter in ein DataFrame\n",
    "#     df_hyperparameters = pd.DataFrame([best_hyperparameters.values])\n",
    "#     # Speichern des DataFrame als CSV\n",
    "#     df_hyperparameters.to_csv(f'random_search_D4_t_1_{run}.csv', index=False)\n",
    "# \n",
    "#     print(f\"Beste Hyperparameter für Lauf {run}: {best_hyperparameters.values}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T10:03:46.649218900Z"
    }
   },
   "id": "d0f02feb42b652f5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T10:03:46.650224Z"
    }
   },
   "id": "3e35d5ebef369658"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
