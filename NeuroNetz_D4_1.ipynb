{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94b0518e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T10:16:02.651029400Z",
     "start_time": "2024-03-27T10:15:51.635748300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense , Dropout\n",
    "from scikeras.wrappers import KerasRegressor \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Datenvorverarbeitung"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eaee0c6f6eb883d"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ff61b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T10:16:02.672865300Z",
     "start_time": "2024-03-27T10:16:02.653029900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n0           0.0000      -0.00200        500   7000   9000      669.05\n1           0.0000      -0.00192        500   7000   9000      724.42\n2           0.0000      -0.00184        500   7000   9000      779.83\n3           0.0000      -0.00176        500   7000   9000      835.21\n4           0.0000      -0.00168        500   7000   9000      890.44\n...            ...           ...        ...    ...    ...         ...\n1066        0.0024       0.00168        500   7000   9000      775.40\n1067        0.0024       0.00176        500   7000   9000      715.43\n1068        0.0024       0.00184        500   7000   9000      645.85\n1069        0.0024       0.00192        500   7000   9000      585.87\n1070        0.0024       0.00200        500   7000   9000      574.64\n\n[1071 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>669.05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0000</td>\n      <td>-0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>724.42</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0000</td>\n      <td>-0.00184</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>779.83</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0000</td>\n      <td>-0.00176</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>835.21</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0000</td>\n      <td>-0.00168</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>890.44</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1066</th>\n      <td>0.0024</td>\n      <td>0.00168</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>775.40</td>\n    </tr>\n    <tr>\n      <th>1067</th>\n      <td>0.0024</td>\n      <td>0.00176</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>715.43</td>\n    </tr>\n    <tr>\n      <th>1068</th>\n      <td>0.0024</td>\n      <td>0.00184</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>645.85</td>\n    </tr>\n    <tr>\n      <th>1069</th>\n      <td>0.0024</td>\n      <td>0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>585.87</td>\n    </tr>\n    <tr>\n      <th>1070</th>\n      <td>0.0024</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>574.64</td>\n    </tr>\n  </tbody>\n</table>\n<p>1071 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_D4_I7000_F9000/TPath_500_finish_data_D4.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "966e3c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T10:16:02.691226Z",
     "start_time": "2024-03-27T10:16:02.672865300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      X-Koordinate  Y-Koordinate  Temperatur\n0           0.0000      -0.00200      669.05\n1           0.0000      -0.00192      724.42\n2           0.0000      -0.00184      779.83\n3           0.0000      -0.00176      835.21\n4           0.0000      -0.00168      890.44\n...            ...           ...         ...\n1066        0.0024       0.00168      775.40\n1067        0.0024       0.00176      715.43\n1068        0.0024       0.00184      645.85\n1069        0.0024       0.00192      585.87\n1070        0.0024       0.00200      574.64\n\n[1071 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>669.05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0000</td>\n      <td>-0.00192</td>\n      <td>724.42</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0000</td>\n      <td>-0.00184</td>\n      <td>779.83</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0000</td>\n      <td>-0.00176</td>\n      <td>835.21</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0000</td>\n      <td>-0.00168</td>\n      <td>890.44</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1066</th>\n      <td>0.0024</td>\n      <td>0.00168</td>\n      <td>775.40</td>\n    </tr>\n    <tr>\n      <th>1067</th>\n      <td>0.0024</td>\n      <td>0.00176</td>\n      <td>715.43</td>\n    </tr>\n    <tr>\n      <th>1068</th>\n      <td>0.0024</td>\n      <td>0.00184</td>\n      <td>645.85</td>\n    </tr>\n    <tr>\n      <th>1069</th>\n      <td>0.0024</td>\n      <td>0.00192</td>\n      <td>585.87</td>\n    </tr>\n    <tr>\n      <th>1070</th>\n      <td>0.0024</td>\n      <td>0.00200</td>\n      <td>574.64</td>\n    </tr>\n  </tbody>\n</table>\n<p>1071 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Droppen nicht benötigter Spalten\n",
    "df = data.drop(data.columns[2:5], axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "       X-Koordinate  Y-Koordinate   Temperatur\ncount   1071.000000  1.071000e+03  1071.000000\nmean       0.001200  8.422560e-20  1138.089346\nstd        0.000727  1.178118e-03   272.294437\nmin        0.000000 -2.000000e-03   574.640000\n25%        0.000600 -1.040000e-03   925.435000\n50%        0.001200  4.529900e-18  1200.300000\n75%        0.001800  1.040000e-03  1371.000000\nmax        0.002400  2.000000e-03  1519.900000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1071.000000</td>\n      <td>1.071000e+03</td>\n      <td>1071.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.001200</td>\n      <td>8.422560e-20</td>\n      <td>1138.089346</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.000727</td>\n      <td>1.178118e-03</td>\n      <td>272.294437</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-2.000000e-03</td>\n      <td>574.640000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000600</td>\n      <td>-1.040000e-03</td>\n      <td>925.435000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.001200</td>\n      <td>4.529900e-18</td>\n      <td>1200.300000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.001800</td>\n      <td>1.040000e-03</td>\n      <td>1371.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.002400</td>\n      <td>2.000000e-03</td>\n      <td>1519.900000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T10:16:02.749348700Z",
     "start_time": "2024-03-27T10:16:02.681038900Z"
    }
   },
   "id": "d955214c950ac934"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8783d1d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T10:16:02.788348500Z",
     "start_time": "2024-03-27T10:16:02.695237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      X-Koordinate  Y-Koordinate  Temperatur\n",
      "184        0.00036       0.00048     1441.10\n",
      "572        0.00132      -0.00112     1225.70\n",
      "309        0.00072      -0.00176      832.88\n",
      "930        0.00216      -0.00104     1158.00\n",
      "711        0.00156       0.00184      642.96\n",
      "...            ...           ...         ...\n",
      "330        0.00072      -0.00008     1500.20\n",
      "466        0.00108      -0.00144     1045.00\n",
      "121        0.00024      -0.00048     1484.90\n",
      "1044       0.00240      -0.00008     1259.10\n",
      "860        0.00192       0.00152      861.75\n",
      "\n",
      "[1071 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": "      X-Koordinate  Y-Koordinate  Temperatur\n0          0.00036       0.00048     1441.10\n1          0.00132      -0.00112     1225.70\n2          0.00072      -0.00176      832.88\n3          0.00216      -0.00104     1158.00\n4          0.00156       0.00184      642.96\n...            ...           ...         ...\n1066       0.00072      -0.00008     1500.20\n1067       0.00108      -0.00144     1045.00\n1068       0.00024      -0.00048     1484.90\n1069       0.00240      -0.00008     1259.10\n1070       0.00192       0.00152      861.75\n\n[1071 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00036</td>\n      <td>0.00048</td>\n      <td>1441.10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00132</td>\n      <td>-0.00112</td>\n      <td>1225.70</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00072</td>\n      <td>-0.00176</td>\n      <td>832.88</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00216</td>\n      <td>-0.00104</td>\n      <td>1158.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00156</td>\n      <td>0.00184</td>\n      <td>642.96</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1066</th>\n      <td>0.00072</td>\n      <td>-0.00008</td>\n      <td>1500.20</td>\n    </tr>\n    <tr>\n      <th>1067</th>\n      <td>0.00108</td>\n      <td>-0.00144</td>\n      <td>1045.00</td>\n    </tr>\n    <tr>\n      <th>1068</th>\n      <td>0.00024</td>\n      <td>-0.00048</td>\n      <td>1484.90</td>\n    </tr>\n    <tr>\n      <th>1069</th>\n      <td>0.00240</td>\n      <td>-0.00008</td>\n      <td>1259.10</td>\n    </tr>\n    <tr>\n      <th>1070</th>\n      <td>0.00192</td>\n      <td>0.00152</td>\n      <td>861.75</td>\n    </tr>\n  </tbody>\n</table>\n<p>1071 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomisieren der Anordnung\n",
    "df1 = df.sample(frac=1, random_state=42)  # Hier wird 42 als Random State verwendet, um die Ergebnisse reproduzierbar zu machen\n",
    "print(df1)\n",
    "df_reset = df1.reset_index(drop=True)\n",
    "df_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4e72a16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T10:16:02.817348800Z",
     "start_time": "2024-03-27T10:16:02.704972700Z"
    }
   },
   "outputs": [],
   "source": [
    "#Festlegen der Gesamtdaten\n",
    "label = df_reset[\"Temperatur\"]\n",
    "df1 = df_reset.drop(\"Temperatur\", axis=1)\n",
    "X = df1\n",
    "y = label"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7fa289a50d87423"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e694a236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T10:16:02.822348900Z",
     "start_time": "2024-03-27T10:16:02.710096500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      X-Koordinate  Y-Koordinate\n0          0.00036       0.00048\n1          0.00132      -0.00112\n2          0.00072      -0.00176\n3          0.00216      -0.00104\n4          0.00156       0.00184\n...            ...           ...\n1066       0.00072      -0.00008\n1067       0.00108      -0.00144\n1068       0.00024      -0.00048\n1069       0.00240      -0.00008\n1070       0.00192       0.00152\n\n[1071 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00036</td>\n      <td>0.00048</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00132</td>\n      <td>-0.00112</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00072</td>\n      <td>-0.00176</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00216</td>\n      <td>-0.00104</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00156</td>\n      <td>0.00184</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1066</th>\n      <td>0.00072</td>\n      <td>-0.00008</td>\n    </tr>\n    <tr>\n      <th>1067</th>\n      <td>0.00108</td>\n      <td>-0.00144</td>\n    </tr>\n    <tr>\n      <th>1068</th>\n      <td>0.00024</td>\n      <td>-0.00048</td>\n    </tr>\n    <tr>\n      <th>1069</th>\n      <td>0.00240</td>\n      <td>-0.00008</td>\n    </tr>\n    <tr>\n      <th>1070</th>\n      <td>0.00192</td>\n      <td>0.00152</td>\n    </tr>\n  </tbody>\n</table>\n<p>1071 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f3303b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T10:16:02.822348900Z",
     "start_time": "2024-03-27T10:16:02.714739Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0       1441.10\n1       1225.70\n2        832.88\n3       1158.00\n4        642.96\n         ...   \n1066    1500.20\n1067    1045.00\n1068    1484.90\n1069    1259.10\n1070     861.75\nName: Temperatur, Length: 1071, dtype: float64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3ad8da0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T10:16:02.882348300Z",
     "start_time": "2024-03-27T10:16:02.719911400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Festlegen der Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c705edb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T10:16:02.883348200Z",
     "start_time": "2024-03-27T10:16:02.725945900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialisiere einen MinMaxScaler für die Features\n",
    "scaler_features = MinMaxScaler()\n",
    "# Skaliere X_train und X_test\n",
    "X_train_scaled = scaler_features.fit_transform(X_train)\n",
    "X_test_scaled = scaler_features.transform(X_test)  # Nutze unterschiedliche Skalierungsparameter\n",
    "\n",
    "# Initialisiere einen SEPARATEN MinMaxScaler für das Ziel\n",
    "scaler_target = MinMaxScaler()\n",
    "y_train_scaled = scaler_target.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test_scaled = scaler_target.transform(y_test.values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbefe631e495b483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T10:16:02.883348200Z",
     "start_time": "2024-03-27T10:16:02.733957500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.35, 0.88],\n       [0.75, 0.88],\n       [0.85, 0.02],\n       ...,\n       [0.2 , 0.86],\n       [1.  , 0.52],\n       [0.8 , 0.04]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_scaled.max()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T10:16:02.883348200Z",
     "start_time": "2024-03-27T10:16:02.737894800Z"
    }
   },
   "id": "ce04ce43aac2242f"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "28/28 [==============================] - 1s 9ms/step - loss: 0.5232 - mae: 0.3658 - val_loss: 0.3679 - val_mae: 0.2404\n",
      "Epoch 2/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3919 - mae: 0.3070 - val_loss: 0.3266 - val_mae: 0.2339\n",
      "Epoch 3/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3197 - mae: 0.2504 - val_loss: 0.3015 - val_mae: 0.2141\n",
      "Epoch 4/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2852 - mae: 0.2353 - val_loss: 0.2392 - val_mae: 0.1608\n",
      "Epoch 5/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2406 - mae: 0.1733 - val_loss: 0.2444 - val_mae: 0.1711\n",
      "Epoch 6/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2191 - mae: 0.1346 - val_loss: 0.2043 - val_mae: 0.1105\n",
      "Epoch 7/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1928 - mae: 0.0742 - val_loss: 0.1887 - val_mae: 0.0624\n",
      "Epoch 8/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1822 - mae: 0.0539 - val_loss: 0.1795 - val_mae: 0.0559\n",
      "Epoch 9/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1866 - mae: 0.0790 - val_loss: 0.1734 - val_mae: 0.0290\n",
      "Epoch 10/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1726 - mae: 0.0357 - val_loss: 0.1694 - val_mae: 0.0216\n",
      "Epoch 11/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1685 - mae: 0.0234 - val_loss: 0.1669 - val_mae: 0.0240\n",
      "Epoch 12/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1652 - mae: 0.0155 - val_loss: 0.1640 - val_mae: 0.0200\n",
      "Epoch 13/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1628 - mae: 0.0171 - val_loss: 0.1618 - val_mae: 0.0214\n",
      "Epoch 14/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1607 - mae: 0.0203 - val_loss: 0.1596 - val_mae: 0.0246\n",
      "Epoch 15/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1579 - mae: 0.0133 - val_loss: 0.1567 - val_mae: 0.0121\n",
      "Epoch 16/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1573 - mae: 0.0272 - val_loss: 0.1620 - val_mae: 0.0616\n",
      "Epoch 17/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1561 - mae: 0.0339 - val_loss: 0.1544 - val_mae: 0.0335\n",
      "Epoch 18/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1541 - mae: 0.0375 - val_loss: 0.1512 - val_mae: 0.0229\n",
      "Epoch 19/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1500 - mae: 0.0213 - val_loss: 0.1487 - val_mae: 0.0188\n",
      "Epoch 20/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1477 - mae: 0.0163 - val_loss: 0.1471 - val_mae: 0.0243\n",
      "Epoch 21/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1459 - mae: 0.0177 - val_loss: 0.1446 - val_mae: 0.0114\n",
      "Epoch 22/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1448 - mae: 0.0239 - val_loss: 0.1464 - val_mae: 0.0423\n",
      "Epoch 23/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1447 - mae: 0.0379 - val_loss: 0.1430 - val_mae: 0.0385\n",
      "Epoch 24/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1417 - mae: 0.0309 - val_loss: 0.1398 - val_mae: 0.0210\n",
      "Epoch 25/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1387 - mae: 0.0186 - val_loss: 0.1375 - val_mae: 0.0143\n",
      "Epoch 26/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1369 - mae: 0.0150 - val_loss: 0.1367 - val_mae: 0.0270\n",
      "Epoch 27/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1353 - mae: 0.0178 - val_loss: 0.1345 - val_mae: 0.0183\n",
      "Epoch 28/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1336 - mae: 0.0162 - val_loss: 0.1333 - val_mae: 0.0301\n",
      "Epoch 29/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1318 - mae: 0.0126 - val_loss: 0.1308 - val_mae: 0.0096\n",
      "Epoch 30/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1303 - mae: 0.0144 - val_loss: 0.1292 - val_mae: 0.0106\n",
      "Epoch 31/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1286 - mae: 0.0124 - val_loss: 0.1279 - val_mae: 0.0131\n",
      "Epoch 32/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1277 - mae: 0.0188 - val_loss: 0.1274 - val_mae: 0.0260\n",
      "Epoch 33/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1279 - mae: 0.0347 - val_loss: 0.1255 - val_mae: 0.0257\n",
      "Epoch 34/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1250 - mae: 0.0264 - val_loss: 0.1245 - val_mae: 0.0345\n",
      "Epoch 35/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1230 - mae: 0.0194 - val_loss: 0.1220 - val_mae: 0.0165\n",
      "Epoch 36/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1231 - mae: 0.0314 - val_loss: 0.1236 - val_mae: 0.0429\n",
      "Epoch 37/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1240 - mae: 0.0476 - val_loss: 0.1255 - val_mae: 0.0601\n",
      "Epoch 38/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1212 - mae: 0.0393 - val_loss: 0.1184 - val_mae: 0.0245\n",
      "Epoch 39/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1178 - mae: 0.0236 - val_loss: 0.1166 - val_mae: 0.0172\n",
      "Epoch 40/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1158 - mae: 0.0123 - val_loss: 0.1155 - val_mae: 0.0204\n",
      "Epoch 41/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1144 - mae: 0.0126 - val_loss: 0.1137 - val_mae: 0.0121\n",
      "Epoch 42/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1129 - mae: 0.0080 - val_loss: 0.1123 - val_mae: 0.0093\n",
      "Epoch 43/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1118 - mae: 0.0103 - val_loss: 0.1121 - val_mae: 0.0259\n",
      "Epoch 44/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1106 - mae: 0.0120 - val_loss: 0.1098 - val_mae: 0.0086\n",
      "Epoch 45/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1091 - mae: 0.0064 - val_loss: 0.1085 - val_mae: 0.0078\n",
      "Epoch 46/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1079 - mae: 0.0058 - val_loss: 0.1072 - val_mae: 0.0075\n",
      "Epoch 47/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1067 - mae: 0.0067 - val_loss: 0.1060 - val_mae: 0.0054\n",
      "Epoch 48/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1054 - mae: 0.0057 - val_loss: 0.1048 - val_mae: 0.0060\n",
      "Epoch 49/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1043 - mae: 0.0081 - val_loss: 0.1036 - val_mae: 0.0070\n",
      "Epoch 50/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1031 - mae: 0.0058 - val_loss: 0.1025 - val_mae: 0.0071\n",
      "Epoch 51/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1019 - mae: 0.0074 - val_loss: 0.1013 - val_mae: 0.0070\n",
      "Epoch 52/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1008 - mae: 0.0062 - val_loss: 0.1002 - val_mae: 0.0085\n",
      "Epoch 53/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0997 - mae: 0.0078 - val_loss: 0.0990 - val_mae: 0.0062\n",
      "Epoch 54/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0986 - mae: 0.0082 - val_loss: 0.0979 - val_mae: 0.0056\n",
      "Epoch 55/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0975 - mae: 0.0080 - val_loss: 0.0972 - val_mae: 0.0137\n",
      "Epoch 56/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0965 - mae: 0.0121 - val_loss: 0.0960 - val_mae: 0.0155\n",
      "Epoch 57/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0957 - mae: 0.0174 - val_loss: 0.0947 - val_mae: 0.0094\n",
      "Epoch 58/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0955 - mae: 0.0256 - val_loss: 0.0959 - val_mae: 0.0388\n",
      "Epoch 59/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0967 - mae: 0.0443 - val_loss: 0.0954 - val_mae: 0.0423\n",
      "Epoch 60/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0932 - mae: 0.0254 - val_loss: 0.0918 - val_mae: 0.0142\n",
      "Epoch 61/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0918 - mae: 0.0213 - val_loss: 0.0915 - val_mae: 0.0273\n",
      "Epoch 62/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0926 - mae: 0.0350 - val_loss: 0.1015 - val_mae: 0.0752\n",
      "Epoch 63/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0916 - mae: 0.0340 - val_loss: 0.0896 - val_mae: 0.0254\n",
      "Epoch 64/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0885 - mae: 0.0183 - val_loss: 0.0877 - val_mae: 0.0117\n",
      "Epoch 65/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0872 - mae: 0.0110 - val_loss: 0.0871 - val_mae: 0.0182\n",
      "Epoch 66/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0862 - mae: 0.0083 - val_loss: 0.0857 - val_mae: 0.0075\n",
      "Epoch 67/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0853 - mae: 0.0101 - val_loss: 0.0850 - val_mae: 0.0163\n",
      "Epoch 68/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0848 - mae: 0.0181 - val_loss: 0.0846 - val_mae: 0.0257\n",
      "Epoch 69/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0839 - mae: 0.0187 - val_loss: 0.0835 - val_mae: 0.0211\n",
      "Epoch 70/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0827 - mae: 0.0142 - val_loss: 0.0819 - val_mae: 0.0092\n",
      "Epoch 71/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0818 - mae: 0.0158 - val_loss: 0.0814 - val_mae: 0.0185\n",
      "Epoch 72/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0809 - mae: 0.0157 - val_loss: 0.0802 - val_mae: 0.0116\n",
      "Epoch 73/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0800 - mae: 0.0156 - val_loss: 0.0803 - val_mae: 0.0279\n",
      "Epoch 74/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0789 - mae: 0.0107 - val_loss: 0.0782 - val_mae: 0.0052\n",
      "Epoch 75/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0778 - mae: 0.0053 - val_loss: 0.0774 - val_mae: 0.0060\n",
      "Epoch 76/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0769 - mae: 0.0062 - val_loss: 0.0766 - val_mae: 0.0100\n",
      "Epoch 77/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0761 - mae: 0.0058 - val_loss: 0.0756 - val_mae: 0.0046\n",
      "Epoch 78/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0752 - mae: 0.0067 - val_loss: 0.0750 - val_mae: 0.0127\n",
      "Epoch 79/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0744 - mae: 0.0088 - val_loss: 0.0741 - val_mae: 0.0107\n",
      "Epoch 80/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0735 - mae: 0.0076 - val_loss: 0.0734 - val_mae: 0.0144\n",
      "Epoch 81/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0728 - mae: 0.0117 - val_loss: 0.0726 - val_mae: 0.0158\n",
      "Epoch 82/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0722 - mae: 0.0159 - val_loss: 0.0722 - val_mae: 0.0214\n",
      "Epoch 83/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0712 - mae: 0.0124 - val_loss: 0.0706 - val_mae: 0.0100\n",
      "Epoch 84/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0703 - mae: 0.0114 - val_loss: 0.0700 - val_mae: 0.0128\n",
      "Epoch 85/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0695 - mae: 0.0096 - val_loss: 0.0693 - val_mae: 0.0190\n",
      "Epoch 86/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0694 - mae: 0.0239 - val_loss: 0.0707 - val_mae: 0.0435\n",
      "Epoch 87/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0693 - mae: 0.0305 - val_loss: 0.0688 - val_mae: 0.0296\n",
      "Epoch 88/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0681 - mae: 0.0254 - val_loss: 0.0679 - val_mae: 0.0331\n",
      "Epoch 89/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0665 - mae: 0.0142 - val_loss: 0.0659 - val_mae: 0.0120\n",
      "Epoch 90/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0655 - mae: 0.0107 - val_loss: 0.0651 - val_mae: 0.0097\n",
      "Epoch 91/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0647 - mae: 0.0074 - val_loss: 0.0643 - val_mae: 0.0115\n",
      "Epoch 92/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0639 - mae: 0.0083 - val_loss: 0.0635 - val_mae: 0.0084\n",
      "Epoch 93/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0632 - mae: 0.0084 - val_loss: 0.0630 - val_mae: 0.0165\n",
      "Epoch 94/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0625 - mae: 0.0099 - val_loss: 0.0620 - val_mae: 0.0087\n",
      "Epoch 95/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0617 - mae: 0.0085 - val_loss: 0.0613 - val_mae: 0.0076\n",
      "Epoch 96/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0609 - mae: 0.0059 - val_loss: 0.0605 - val_mae: 0.0072\n",
      "Epoch 97/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0601 - mae: 0.0064 - val_loss: 0.0598 - val_mae: 0.0083\n",
      "Epoch 98/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0594 - mae: 0.0071 - val_loss: 0.0590 - val_mae: 0.0064\n",
      "Epoch 99/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0587 - mae: 0.0060 - val_loss: 0.0583 - val_mae: 0.0061\n",
      "Epoch 100/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0580 - mae: 0.0087 - val_loss: 0.0577 - val_mae: 0.0120\n",
      "Epoch 101/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0575 - mae: 0.0124 - val_loss: 0.0569 - val_mae: 0.0070\n",
      "Epoch 102/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0566 - mae: 0.0058 - val_loss: 0.0562 - val_mae: 0.0080\n",
      "Epoch 103/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0559 - mae: 0.0078 - val_loss: 0.0556 - val_mae: 0.0110\n",
      "Epoch 104/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0558 - mae: 0.0203 - val_loss: 0.0551 - val_mae: 0.0141\n",
      "Epoch 105/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0547 - mae: 0.0129 - val_loss: 0.0543 - val_mae: 0.0116\n",
      "Epoch 106/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0539 - mae: 0.0101 - val_loss: 0.0534 - val_mae: 0.0059\n",
      "Epoch 107/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0534 - mae: 0.0130 - val_loss: 0.0528 - val_mae: 0.0078\n",
      "Epoch 108/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0525 - mae: 0.0088 - val_loss: 0.0523 - val_mae: 0.0122\n",
      "Epoch 109/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0519 - mae: 0.0086 - val_loss: 0.0514 - val_mae: 0.0055\n",
      "Epoch 110/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0513 - mae: 0.0100 - val_loss: 0.0520 - val_mae: 0.0295\n",
      "Epoch 111/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0520 - mae: 0.0312 - val_loss: 0.0514 - val_mae: 0.0290\n",
      "Epoch 112/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0503 - mae: 0.0165 - val_loss: 0.0499 - val_mae: 0.0146\n",
      "Epoch 113/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0494 - mae: 0.0117 - val_loss: 0.0491 - val_mae: 0.0124\n",
      "Epoch 114/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0488 - mae: 0.0118 - val_loss: 0.0489 - val_mae: 0.0208\n",
      "Epoch 115/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0490 - mae: 0.0233 - val_loss: 0.0510 - val_mae: 0.0470\n",
      "Epoch 116/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0482 - mae: 0.0230 - val_loss: 0.0474 - val_mae: 0.0183\n",
      "Epoch 117/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0469 - mae: 0.0110 - val_loss: 0.0465 - val_mae: 0.0099\n",
      "Epoch 118/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0462 - mae: 0.0074 - val_loss: 0.0465 - val_mae: 0.0204\n",
      "Epoch 119/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0458 - mae: 0.0130 - val_loss: 0.0458 - val_mae: 0.0184\n",
      "Epoch 120/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0452 - mae: 0.0120 - val_loss: 0.0457 - val_mae: 0.0238\n",
      "Epoch 121/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0448 - mae: 0.0154 - val_loss: 0.0458 - val_mae: 0.0311\n",
      "Epoch 122/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0464 - mae: 0.0360 - val_loss: 0.0455 - val_mae: 0.0384\n",
      "Epoch 123/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0442 - mae: 0.0244 - val_loss: 0.0430 - val_mae: 0.0087\n",
      "Epoch 124/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0430 - mae: 0.0156 - val_loss: 0.0433 - val_mae: 0.0254\n",
      "Epoch 125/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0424 - mae: 0.0156 - val_loss: 0.0418 - val_mae: 0.0065\n",
      "Epoch 126/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0418 - mae: 0.0131 - val_loss: 0.0415 - val_mae: 0.0117\n",
      "Epoch 127/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0414 - mae: 0.0174 - val_loss: 0.0409 - val_mae: 0.0120\n",
      "Epoch 128/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0405 - mae: 0.0086 - val_loss: 0.0401 - val_mae: 0.0065\n",
      "Epoch 129/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0402 - mae: 0.0113 - val_loss: 0.0398 - val_mae: 0.0125\n",
      "Epoch 130/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0423 - mae: 0.0354 - val_loss: 0.0407 - val_mae: 0.0268\n",
      "Epoch 131/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0427 - mae: 0.0496 - val_loss: 0.0472 - val_mae: 0.0722\n",
      "Epoch 132/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0404 - mae: 0.0341 - val_loss: 0.0392 - val_mae: 0.0315\n",
      "Epoch 133/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0385 - mae: 0.0213 - val_loss: 0.0378 - val_mae: 0.0117\n",
      "Epoch 134/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0377 - mae: 0.0154 - val_loss: 0.0377 - val_mae: 0.0197\n",
      "Epoch 135/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0371 - mae: 0.0139 - val_loss: 0.0367 - val_mae: 0.0085\n",
      "Epoch 136/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0370 - mae: 0.0195 - val_loss: 0.0380 - val_mae: 0.0397\n",
      "Epoch 137/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0365 - mae: 0.0205 - val_loss: 0.0359 - val_mae: 0.0165\n",
      "Epoch 138/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0356 - mae: 0.0108 - val_loss: 0.0353 - val_mae: 0.0111\n",
      "Epoch 139/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0350 - mae: 0.0077 - val_loss: 0.0347 - val_mae: 0.0075\n",
      "Epoch 140/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0345 - mae: 0.0072 - val_loss: 0.0343 - val_mae: 0.0096\n",
      "Epoch 141/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0341 - mae: 0.0088 - val_loss: 0.0351 - val_mae: 0.0265\n",
      "Epoch 142/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0338 - mae: 0.0133 - val_loss: 0.0335 - val_mae: 0.0153\n",
      "Epoch 143/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0333 - mae: 0.0128 - val_loss: 0.0330 - val_mae: 0.0096\n",
      "Epoch 144/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0328 - mae: 0.0118 - val_loss: 0.0326 - val_mae: 0.0151\n",
      "Epoch 145/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0324 - mae: 0.0133 - val_loss: 0.0321 - val_mae: 0.0119\n",
      "Epoch 146/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0321 - mae: 0.0160 - val_loss: 0.0315 - val_mae: 0.0106\n",
      "Epoch 147/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0316 - mae: 0.0153 - val_loss: 0.0312 - val_mae: 0.0108\n",
      "Epoch 148/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.0099 - val_loss: 0.0306 - val_mae: 0.0069\n",
      "Epoch 149/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.0106 - val_loss: 0.0302 - val_mae: 0.0065\n",
      "Epoch 150/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.0102 - val_loss: 0.0301 - val_mae: 0.0178\n",
      "Epoch 151/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.0114 - val_loss: 0.0295 - val_mae: 0.0105\n",
      "Epoch 152/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.0133 - val_loss: 0.0292 - val_mae: 0.0124\n",
      "Epoch 153/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.0107 - val_loss: 0.0285 - val_mae: 0.0077\n",
      "Epoch 154/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.0108 - val_loss: 0.0285 - val_mae: 0.0153\n",
      "Epoch 155/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.0186 - val_loss: 0.0280 - val_mae: 0.0177\n",
      "Epoch 156/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.0191 - val_loss: 0.0274 - val_mae: 0.0106\n",
      "Epoch 157/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.0084 - val_loss: 0.0269 - val_mae: 0.0062\n",
      "Epoch 158/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.0072 - val_loss: 0.0265 - val_mae: 0.0072\n",
      "Epoch 159/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.0056 - val_loss: 0.0262 - val_mae: 0.0116\n",
      "Epoch 160/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0260 - mae: 0.0092 - val_loss: 0.0257 - val_mae: 0.0058\n",
      "Epoch 161/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0258 - mae: 0.0131 - val_loss: 0.0265 - val_mae: 0.0273\n",
      "Epoch 162/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0257 - mae: 0.0188 - val_loss: 0.0271 - val_mae: 0.0338\n",
      "Epoch 163/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0260 - mae: 0.0248 - val_loss: 0.0252 - val_mae: 0.0206\n",
      "Epoch 164/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0252 - mae: 0.0201 - val_loss: 0.0272 - val_mae: 0.0409\n",
      "Epoch 165/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.0399 - val_loss: 0.0270 - val_mae: 0.0467\n",
      "Epoch 166/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0257 - mae: 0.0312 - val_loss: 0.0305 - val_mae: 0.0650\n",
      "Epoch 167/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.0377 - val_loss: 0.0270 - val_mae: 0.0440\n",
      "Epoch 168/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0240 - mae: 0.0213 - val_loss: 0.0230 - val_mae: 0.0099\n",
      "Epoch 169/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0229 - mae: 0.0118 - val_loss: 0.0226 - val_mae: 0.0071\n",
      "Epoch 170/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0225 - mae: 0.0088 - val_loss: 0.0223 - val_mae: 0.0072\n",
      "Epoch 171/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0221 - mae: 0.0078 - val_loss: 0.0219 - val_mae: 0.0081\n",
      "Epoch 172/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0218 - mae: 0.0092 - val_loss: 0.0216 - val_mae: 0.0075\n",
      "Epoch 173/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0215 - mae: 0.0078 - val_loss: 0.0214 - val_mae: 0.0121\n",
      "Epoch 174/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0212 - mae: 0.0083 - val_loss: 0.0210 - val_mae: 0.0092\n",
      "Epoch 175/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0209 - mae: 0.0108 - val_loss: 0.0211 - val_mae: 0.0178\n",
      "Epoch 176/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0207 - mae: 0.0121 - val_loss: 0.0204 - val_mae: 0.0116\n",
      "Epoch 177/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0203 - mae: 0.0085 - val_loss: 0.0203 - val_mae: 0.0119\n",
      "Epoch 178/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0199 - mae: 0.0071 - val_loss: 0.0197 - val_mae: 0.0055\n",
      "Epoch 179/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0197 - mae: 0.0087 - val_loss: 0.0200 - val_mae: 0.0215\n",
      "Epoch 180/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0196 - mae: 0.0156 - val_loss: 0.0197 - val_mae: 0.0203\n",
      "Epoch 181/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0195 - mae: 0.0172 - val_loss: 0.0192 - val_mae: 0.0163\n",
      "Epoch 182/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0189 - mae: 0.0135 - val_loss: 0.0189 - val_mae: 0.0154\n",
      "Epoch 183/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0187 - mae: 0.0123 - val_loss: 0.0183 - val_mae: 0.0050\n",
      "Epoch 184/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0182 - mae: 0.0093 - val_loss: 0.0182 - val_mae: 0.0143\n",
      "Epoch 185/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0181 - mae: 0.0122 - val_loss: 0.0197 - val_mae: 0.0383\n",
      "Epoch 186/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0210 - mae: 0.0451 - val_loss: 0.0188 - val_mae: 0.0301\n",
      "Epoch 187/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0180 - mae: 0.0192 - val_loss: 0.0180 - val_mae: 0.0230\n",
      "Epoch 188/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0176 - mae: 0.0169 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 189/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0170 - mae: 0.0108 - val_loss: 0.0170 - val_mae: 0.0154\n",
      "Epoch 190/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0168 - mae: 0.0116 - val_loss: 0.0180 - val_mae: 0.0325\n",
      "Epoch 191/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0174 - mae: 0.0248 - val_loss: 0.0173 - val_mae: 0.0275\n",
      "Epoch 192/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0171 - mae: 0.0252 - val_loss: 0.0170 - val_mae: 0.0231\n",
      "Epoch 193/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0167 - mae: 0.0237 - val_loss: 0.0166 - val_mae: 0.0253\n",
      "Epoch 194/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0159 - mae: 0.0136 - val_loss: 0.0157 - val_mae: 0.0113\n",
      "Epoch 195/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - mae: 0.0108 - val_loss: 0.0157 - val_mae: 0.0145\n",
      "Epoch 196/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0154 - mae: 0.0131 - val_loss: 0.0150 - val_mae: 0.0051\n",
      "Epoch 197/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0150 - mae: 0.0067 - val_loss: 0.0148 - val_mae: 0.0066\n",
      "Epoch 198/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0148 - mae: 0.0083 - val_loss: 0.0147 - val_mae: 0.0116\n",
      "Epoch 199/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0146 - mae: 0.0120 - val_loss: 0.0147 - val_mae: 0.0143\n",
      "Epoch 200/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0144 - mae: 0.0102 - val_loss: 0.0141 - val_mae: 0.0062\n",
      "Epoch 201/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0142 - mae: 0.0102 - val_loss: 0.0140 - val_mae: 0.0086\n",
      "Epoch 202/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0143 - mae: 0.0171 - val_loss: 0.0142 - val_mae: 0.0206\n",
      "Epoch 203/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0114 - val_loss: 0.0136 - val_mae: 0.0083\n",
      "Epoch 204/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0062 - val_loss: 0.0133 - val_mae: 0.0047\n",
      "Epoch 205/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0064 - val_loss: 0.0139 - val_mae: 0.0245\n",
      "Epoch 206/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0233 - val_loss: 0.0169 - val_mae: 0.0532\n",
      "Epoch 207/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0246 - val_loss: 0.0131 - val_mae: 0.0185\n",
      "Epoch 208/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0119 - val_loss: 0.0130 - val_mae: 0.0201\n",
      "Epoch 209/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0136 - val_loss: 0.0124 - val_mae: 0.0072\n",
      "Epoch 210/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0055 - val_loss: 0.0122 - val_mae: 0.0077\n",
      "Epoch 211/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0059 - val_loss: 0.0119 - val_mae: 0.0048\n",
      "Epoch 212/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0062 - val_loss: 0.0117 - val_mae: 0.0046\n",
      "Epoch 213/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0117 - mae: 0.0076 - val_loss: 0.0119 - val_mae: 0.0160\n",
      "Epoch 214/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0116 - mae: 0.0084 - val_loss: 0.0114 - val_mae: 0.0060\n",
      "Epoch 215/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0113 - mae: 0.0055 - val_loss: 0.0112 - val_mae: 0.0063\n",
      "Epoch 216/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - mae: 0.0067 - val_loss: 0.0111 - val_mae: 0.0080\n",
      "Epoch 217/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - mae: 0.0090 - val_loss: 0.0112 - val_mae: 0.0170\n",
      "Epoch 218/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0110 - mae: 0.0119 - val_loss: 0.0107 - val_mae: 0.0064\n",
      "Epoch 219/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0106 - mae: 0.0067 - val_loss: 0.0106 - val_mae: 0.0088\n",
      "Epoch 220/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0105 - mae: 0.0081 - val_loss: 0.0104 - val_mae: 0.0061\n",
      "Epoch 221/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0103 - mae: 0.0066 - val_loss: 0.0102 - val_mae: 0.0081\n",
      "Epoch 222/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0102 - mae: 0.0091 - val_loss: 0.0116 - val_mae: 0.0302\n",
      "Epoch 223/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0110 - mae: 0.0252 - val_loss: 0.0110 - val_mae: 0.0291\n",
      "Epoch 224/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0103 - mae: 0.0182 - val_loss: 0.0098 - val_mae: 0.0102\n",
      "Epoch 225/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0098 - mae: 0.0093 - val_loss: 0.0097 - val_mae: 0.0094\n",
      "Epoch 226/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0075 - val_loss: 0.0094 - val_mae: 0.0046\n",
      "Epoch 227/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0094 - mae: 0.0082 - val_loss: 0.0094 - val_mae: 0.0088\n",
      "Epoch 228/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0066 - val_loss: 0.0091 - val_mae: 0.0044\n",
      "Epoch 229/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0063 - val_loss: 0.0091 - val_mae: 0.0106\n",
      "Epoch 230/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0076 - val_loss: 0.0090 - val_mae: 0.0100\n",
      "Epoch 231/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0080 - val_loss: 0.0090 - val_mae: 0.0113\n",
      "Epoch 232/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0093 - val_loss: 0.0093 - val_mae: 0.0265\n",
      "Epoch 233/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0206 - val_loss: 0.0094 - val_mae: 0.0268\n",
      "Epoch 234/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0141 - val_loss: 0.0084 - val_mae: 0.0079\n",
      "Epoch 235/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0099 - val_loss: 0.0090 - val_mae: 0.0210\n",
      "Epoch 236/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0209 - val_loss: 0.0126 - val_mae: 0.0494\n",
      "Epoch 237/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0235 - val_loss: 0.0083 - val_mae: 0.0141\n",
      "Epoch 238/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0202 - val_loss: 0.0082 - val_mae: 0.0144\n",
      "Epoch 239/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0097 - val_loss: 0.0078 - val_mae: 0.0084\n",
      "Epoch 240/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0069 - val_loss: 0.0076 - val_mae: 0.0069\n",
      "Epoch 241/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0115 - val_loss: 0.0075 - val_mae: 0.0071\n",
      "Epoch 242/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0118 - val_loss: 0.0075 - val_mae: 0.0106\n",
      "Epoch 243/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - mae: 0.0102 - val_loss: 0.0072 - val_mae: 0.0045\n",
      "Epoch 244/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - mae: 0.0071 - val_loss: 0.0072 - val_mae: 0.0087\n",
      "Epoch 245/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - mae: 0.0078 - val_loss: 0.0073 - val_mae: 0.0134\n",
      "Epoch 246/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - mae: 0.0143 - val_loss: 0.0076 - val_mae: 0.0234\n",
      "Epoch 247/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - mae: 0.0115 - val_loss: 0.0069 - val_mae: 0.0064\n",
      "Epoch 248/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - mae: 0.0102 - val_loss: 0.0070 - val_mae: 0.0142\n",
      "Epoch 249/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - mae: 0.0178 - val_loss: 0.0070 - val_mae: 0.0162\n",
      "Epoch 250/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - mae: 0.0113 - val_loss: 0.0065 - val_mae: 0.0042\n",
      "Epoch 251/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - mae: 0.0139 - val_loss: 0.0070 - val_mae: 0.0179\n",
      "Epoch 252/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0065 - mae: 0.0099 - val_loss: 0.0068 - val_mae: 0.0204\n",
      "Epoch 253/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0065 - mae: 0.0116 - val_loss: 0.0065 - val_mae: 0.0159\n",
      "Epoch 254/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - mae: 0.0197 - val_loss: 0.0076 - val_mae: 0.0302\n",
      "Epoch 255/1000\n",
      "24/28 [========================>.....] - ETA: 0s - loss: 0.0075 - mae: 0.0304Restoring model weights from the end of the best epoch: 250.\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - mae: 0.0293 - val_loss: 0.0072 - val_mae: 0.0293\n",
      "Epoch 255: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Netzwerkarchitektur\n",
    "model = Sequential([\n",
    "\n",
    "    Dense(264, activation='relu', input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "    Dense(232, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(280, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(264, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(216, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(72, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(216, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(88, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(1 , activation = 'linear')\n",
    "])\n",
    "\n",
    "# Optimierer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# Modell kompilieren (Verwendung von mean_squared_error als Verlustfunktion für Regression)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])  # Metriken für Regression: Mean Absolute Error und Mean Squared Error\n",
    "\n",
    "# Early Stopping Callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "# Trainingsparameter\n",
    "batch_size = 25\n",
    "epochs = 1000\n",
    "\n",
    "# Modell trainieren (Annahme: X_train, y_train, X_val, y_val sind vordefiniert)\n",
    "history = model.fit(X_train_scaled, y_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T10:17:00.653533600Z",
     "start_time": "2024-03-27T10:16:35.789905400Z"
    }
   },
   "id": "8b52e1a9a6ff3aeb"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training für Fold 1...\n",
      "Epoch 1/1000\n",
      "28/28 [==============================] - 1s 8ms/step - loss: 0.5563 - mae: 0.3834 - val_loss: 0.4046 - val_mae: 0.2676\n",
      "Epoch 2/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3802 - mae: 0.2932 - val_loss: 0.3347 - val_mae: 0.2345\n",
      "Epoch 3/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3168 - mae: 0.2453 - val_loss: 0.2734 - val_mae: 0.1940\n",
      "Epoch 4/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2636 - mae: 0.1919 - val_loss: 0.2277 - val_mae: 0.1323\n",
      "Epoch 5/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2177 - mae: 0.1113 - val_loss: 0.2305 - val_mae: 0.1543\n",
      "Epoch 6/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2042 - mae: 0.0968 - val_loss: 0.1924 - val_mae: 0.0707\n",
      "Epoch 7/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1954 - mae: 0.0801 - val_loss: 0.1909 - val_mae: 0.0787\n",
      "Epoch 8/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1852 - mae: 0.0633 - val_loss: 0.1899 - val_mae: 0.0806\n",
      "Epoch 9/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1810 - mae: 0.0597 - val_loss: 0.1730 - val_mae: 0.0338\n",
      "Epoch 10/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1737 - mae: 0.0416 - val_loss: 0.1815 - val_mae: 0.0778\n",
      "Epoch 11/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1763 - mae: 0.0659 - val_loss: 0.1681 - val_mae: 0.0337\n",
      "Epoch 12/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1653 - mae: 0.0238 - val_loss: 0.1637 - val_mae: 0.0217\n",
      "Epoch 13/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1638 - mae: 0.0308 - val_loss: 0.1616 - val_mae: 0.0250\n",
      "Epoch 14/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1601 - mae: 0.0182 - val_loss: 0.1589 - val_mae: 0.0190\n",
      "Epoch 15/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1581 - mae: 0.0212 - val_loss: 0.1564 - val_mae: 0.0131\n",
      "Epoch 16/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1558 - mae: 0.0191 - val_loss: 0.1550 - val_mae: 0.0236\n",
      "Epoch 17/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1550 - mae: 0.0313 - val_loss: 0.1560 - val_mae: 0.0487\n",
      "Epoch 18/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1531 - mae: 0.0347 - val_loss: 0.1520 - val_mae: 0.0328\n",
      "Epoch 19/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1510 - mae: 0.0338 - val_loss: 0.1497 - val_mae: 0.0313\n",
      "Epoch 20/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1478 - mae: 0.0193 - val_loss: 0.1468 - val_mae: 0.0217\n",
      "Epoch 21/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1457 - mae: 0.0164 - val_loss: 0.1446 - val_mae: 0.0139\n",
      "Epoch 22/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1437 - mae: 0.0116 - val_loss: 0.1431 - val_mae: 0.0188\n",
      "Epoch 23/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1419 - mae: 0.0118 - val_loss: 0.1412 - val_mae: 0.0176\n",
      "Epoch 24/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1405 - mae: 0.0180 - val_loss: 0.1396 - val_mae: 0.0183\n",
      "Epoch 25/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1386 - mae: 0.0153 - val_loss: 0.1374 - val_mae: 0.0086\n",
      "Epoch 26/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1366 - mae: 0.0075 - val_loss: 0.1357 - val_mae: 0.0063\n",
      "Epoch 27/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1350 - mae: 0.0089 - val_loss: 0.1343 - val_mae: 0.0119\n",
      "Epoch 28/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1335 - mae: 0.0098 - val_loss: 0.1329 - val_mae: 0.0164\n",
      "Epoch 29/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1325 - mae: 0.0196 - val_loss: 0.1312 - val_mae: 0.0133\n",
      "Epoch 30/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1311 - mae: 0.0214 - val_loss: 0.1305 - val_mae: 0.0259\n",
      "Epoch 31/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1294 - mae: 0.0209 - val_loss: 0.1282 - val_mae: 0.0131\n",
      "Epoch 32/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1276 - mae: 0.0153 - val_loss: 0.1266 - val_mae: 0.0134\n",
      "Epoch 33/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1261 - mae: 0.0160 - val_loss: 0.1252 - val_mae: 0.0147\n",
      "Epoch 34/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1244 - mae: 0.0104 - val_loss: 0.1235 - val_mae: 0.0065\n",
      "Epoch 35/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1229 - mae: 0.0086 - val_loss: 0.1226 - val_mae: 0.0185\n",
      "Epoch 36/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1253 - mae: 0.0392 - val_loss: 0.1234 - val_mae: 0.0362\n",
      "Epoch 37/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1213 - mae: 0.0272 - val_loss: 0.1207 - val_mae: 0.0240\n",
      "Epoch 38/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1212 - mae: 0.0338 - val_loss: 0.1183 - val_mae: 0.0147\n",
      "Epoch 39/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1176 - mae: 0.0123 - val_loss: 0.1168 - val_mae: 0.0104\n",
      "Epoch 40/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1167 - mae: 0.0189 - val_loss: 0.1247 - val_mae: 0.0651\n",
      "Epoch 41/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1168 - mae: 0.0309 - val_loss: 0.1148 - val_mae: 0.0248\n",
      "Epoch 42/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1139 - mae: 0.0167 - val_loss: 0.1140 - val_mae: 0.0236\n",
      "Epoch 43/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1126 - mae: 0.0161 - val_loss: 0.1117 - val_mae: 0.0099\n",
      "Epoch 44/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1112 - mae: 0.0111 - val_loss: 0.1105 - val_mae: 0.0134\n",
      "Epoch 45/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1099 - mae: 0.0114 - val_loss: 0.1093 - val_mae: 0.0108\n",
      "Epoch 46/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1087 - mae: 0.0096 - val_loss: 0.1081 - val_mae: 0.0120\n",
      "Epoch 47/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1075 - mae: 0.0107 - val_loss: 0.1069 - val_mae: 0.0112\n",
      "Epoch 48/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1065 - mae: 0.0141 - val_loss: 0.1060 - val_mae: 0.0164\n",
      "Epoch 49/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1051 - mae: 0.0094 - val_loss: 0.1044 - val_mae: 0.0067\n",
      "Epoch 50/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1040 - mae: 0.0112 - val_loss: 0.1034 - val_mae: 0.0094\n",
      "Epoch 51/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1028 - mae: 0.0085 - val_loss: 0.1023 - val_mae: 0.0126\n",
      "Epoch 52/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1017 - mae: 0.0101 - val_loss: 0.1011 - val_mae: 0.0102\n",
      "Epoch 53/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1008 - mae: 0.0141 - val_loss: 0.1017 - val_mae: 0.0345\n",
      "Epoch 54/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0997 - mae: 0.0139 - val_loss: 0.0991 - val_mae: 0.0158\n",
      "Epoch 55/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0984 - mae: 0.0089 - val_loss: 0.0978 - val_mae: 0.0100\n",
      "Epoch 56/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0973 - mae: 0.0072 - val_loss: 0.0967 - val_mae: 0.0075\n",
      "Epoch 57/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0962 - mae: 0.0077 - val_loss: 0.0956 - val_mae: 0.0061\n",
      "Epoch 58/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0952 - mae: 0.0092 - val_loss: 0.0947 - val_mae: 0.0106\n",
      "Epoch 59/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0943 - mae: 0.0107 - val_loss: 0.0938 - val_mae: 0.0132\n",
      "Epoch 60/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0933 - mae: 0.0133 - val_loss: 0.0934 - val_mae: 0.0266\n",
      "Epoch 61/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0922 - mae: 0.0111 - val_loss: 0.0917 - val_mae: 0.0101\n",
      "Epoch 62/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0912 - mae: 0.0105 - val_loss: 0.0907 - val_mae: 0.0120\n",
      "Epoch 63/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0902 - mae: 0.0120 - val_loss: 0.0896 - val_mae: 0.0077\n",
      "Epoch 64/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0892 - mae: 0.0108 - val_loss: 0.0886 - val_mae: 0.0082\n",
      "Epoch 65/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0886 - mae: 0.0155 - val_loss: 0.0905 - val_mae: 0.0381\n",
      "Epoch 66/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0875 - mae: 0.0135 - val_loss: 0.0866 - val_mae: 0.0065\n",
      "Epoch 67/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0862 - mae: 0.0071 - val_loss: 0.0858 - val_mae: 0.0124\n",
      "Epoch 68/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0854 - mae: 0.0109 - val_loss: 0.0848 - val_mae: 0.0108\n",
      "Epoch 69/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0843 - mae: 0.0072 - val_loss: 0.0838 - val_mae: 0.0079\n",
      "Epoch 70/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0842 - mae: 0.0210 - val_loss: 0.0843 - val_mae: 0.0302\n",
      "Epoch 71/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0834 - mae: 0.0247 - val_loss: 0.0824 - val_mae: 0.0182\n",
      "Epoch 72/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0817 - mae: 0.0112 - val_loss: 0.0819 - val_mae: 0.0234\n",
      "Epoch 73/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0821 - mae: 0.0272 - val_loss: 0.0854 - val_mae: 0.0543\n",
      "Epoch 74/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0839 - mae: 0.0453 - val_loss: 0.0843 - val_mae: 0.0487\n",
      "Epoch 75/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0818 - mae: 0.0381 - val_loss: 0.0817 - val_mae: 0.0409\n",
      "Epoch 76/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0793 - mae: 0.0270 - val_loss: 0.0780 - val_mae: 0.0189\n",
      "Epoch 77/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.0175 - val_loss: 0.0768 - val_mae: 0.0108\n",
      "Epoch 78/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0764 - mae: 0.0086 - val_loss: 0.0760 - val_mae: 0.0104\n",
      "Epoch 79/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0756 - mae: 0.0117 - val_loss: 0.0761 - val_mae: 0.0291\n",
      "Epoch 80/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0754 - mae: 0.0225 - val_loss: 0.0780 - val_mae: 0.0554\n",
      "Epoch 81/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0747 - mae: 0.0222 - val_loss: 0.0735 - val_mae: 0.0132\n",
      "Epoch 82/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0744 - mae: 0.0285 - val_loss: 0.0800 - val_mae: 0.0635\n",
      "Epoch 83/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0764 - mae: 0.0460 - val_loss: 0.0724 - val_mae: 0.0209\n",
      "Epoch 84/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0719 - mae: 0.0191 - val_loss: 0.0715 - val_mae: 0.0203\n",
      "Epoch 85/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0708 - mae: 0.0128 - val_loss: 0.0703 - val_mae: 0.0104\n",
      "Epoch 86/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0699 - mae: 0.0105 - val_loss: 0.0695 - val_mae: 0.0083\n",
      "Epoch 87/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0691 - mae: 0.0084 - val_loss: 0.0688 - val_mae: 0.0131\n",
      "Epoch 88/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0683 - mae: 0.0091 - val_loss: 0.0679 - val_mae: 0.0104\n",
      "Epoch 89/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0675 - mae: 0.0089 - val_loss: 0.0671 - val_mae: 0.0076\n",
      "Epoch 90/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0667 - mae: 0.0083 - val_loss: 0.0668 - val_mae: 0.0192\n",
      "Epoch 91/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0665 - mae: 0.0191 - val_loss: 0.0668 - val_mae: 0.0246\n",
      "Epoch 92/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0656 - mae: 0.0161 - val_loss: 0.0648 - val_mae: 0.0078\n",
      "Epoch 93/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0646 - mae: 0.0107 - val_loss: 0.0641 - val_mae: 0.0079\n",
      "Epoch 94/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0637 - mae: 0.0072 - val_loss: 0.0634 - val_mae: 0.0103\n",
      "Epoch 95/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0630 - mae: 0.0081 - val_loss: 0.0626 - val_mae: 0.0086\n",
      "Epoch 96/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0623 - mae: 0.0094 - val_loss: 0.0618 - val_mae: 0.0061\n",
      "Epoch 97/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0615 - mae: 0.0062 - val_loss: 0.0611 - val_mae: 0.0058\n",
      "Epoch 98/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0608 - mae: 0.0064 - val_loss: 0.0606 - val_mae: 0.0123\n",
      "Epoch 99/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0601 - mae: 0.0088 - val_loss: 0.0603 - val_mae: 0.0191\n",
      "Epoch 100/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0595 - mae: 0.0104 - val_loss: 0.0590 - val_mae: 0.0071\n",
      "Epoch 101/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0587 - mae: 0.0076 - val_loss: 0.0585 - val_mae: 0.0138\n",
      "Epoch 102/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0581 - mae: 0.0113 - val_loss: 0.0577 - val_mae: 0.0095\n",
      "Epoch 103/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0576 - mae: 0.0150 - val_loss: 0.0574 - val_mae: 0.0169\n",
      "Epoch 104/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0569 - mae: 0.0136 - val_loss: 0.0564 - val_mae: 0.0113\n",
      "Epoch 105/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0560 - mae: 0.0095 - val_loss: 0.0556 - val_mae: 0.0083\n",
      "Epoch 106/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0554 - mae: 0.0102 - val_loss: 0.0549 - val_mae: 0.0078\n",
      "Epoch 107/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0548 - mae: 0.0112 - val_loss: 0.0548 - val_mae: 0.0187\n",
      "Epoch 108/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0543 - mae: 0.0140 - val_loss: 0.0536 - val_mae: 0.0076\n",
      "Epoch 109/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0533 - mae: 0.0080 - val_loss: 0.0531 - val_mae: 0.0124\n",
      "Epoch 110/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0527 - mae: 0.0095 - val_loss: 0.0525 - val_mae: 0.0142\n",
      "Epoch 111/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0521 - mae: 0.0114 - val_loss: 0.0519 - val_mae: 0.0167\n",
      "Epoch 112/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0519 - mae: 0.0195 - val_loss: 0.0511 - val_mae: 0.0105\n",
      "Epoch 113/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0508 - mae: 0.0105 - val_loss: 0.0504 - val_mae: 0.0099\n",
      "Epoch 114/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0502 - mae: 0.0124 - val_loss: 0.0499 - val_mae: 0.0149\n",
      "Epoch 115/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0495 - mae: 0.0105 - val_loss: 0.0492 - val_mae: 0.0089\n",
      "Epoch 116/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0492 - mae: 0.0152 - val_loss: 0.0500 - val_mae: 0.0342\n",
      "Epoch 117/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0488 - mae: 0.0197 - val_loss: 0.0484 - val_mae: 0.0204\n",
      "Epoch 118/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0478 - mae: 0.0129 - val_loss: 0.0472 - val_mae: 0.0053\n",
      "Epoch 119/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0471 - mae: 0.0095 - val_loss: 0.0467 - val_mae: 0.0070\n",
      "Epoch 120/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0471 - mae: 0.0184 - val_loss: 0.0483 - val_mae: 0.0353\n",
      "Epoch 121/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0465 - mae: 0.0192 - val_loss: 0.0456 - val_mae: 0.0104\n",
      "Epoch 122/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0471 - mae: 0.0300 - val_loss: 0.0467 - val_mae: 0.0318\n",
      "Epoch 123/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0475 - mae: 0.0409 - val_loss: 0.0457 - val_mae: 0.0299\n",
      "Epoch 124/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0451 - mae: 0.0247 - val_loss: 0.0449 - val_mae: 0.0247\n",
      "Epoch 125/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0443 - mae: 0.0236 - val_loss: 0.0443 - val_mae: 0.0271\n",
      "Epoch 126/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0448 - mae: 0.0335 - val_loss: 0.0446 - val_mae: 0.0338\n",
      "Epoch 127/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0445 - mae: 0.0318 - val_loss: 0.0553 - val_mae: 0.0812\n",
      "Epoch 128/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0467 - mae: 0.0471 - val_loss: 0.0421 - val_mae: 0.0172\n",
      "Epoch 129/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0419 - mae: 0.0165 - val_loss: 0.0412 - val_mae: 0.0091\n",
      "Epoch 130/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0409 - mae: 0.0077 - val_loss: 0.0406 - val_mae: 0.0057\n",
      "Epoch 131/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0403 - mae: 0.0064 - val_loss: 0.0401 - val_mae: 0.0092\n",
      "Epoch 132/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0398 - mae: 0.0069 - val_loss: 0.0396 - val_mae: 0.0104\n",
      "Epoch 133/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0393 - mae: 0.0067 - val_loss: 0.0391 - val_mae: 0.0102\n",
      "Epoch 134/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0389 - mae: 0.0093 - val_loss: 0.0388 - val_mae: 0.0149\n",
      "Epoch 135/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0383 - mae: 0.0076 - val_loss: 0.0380 - val_mae: 0.0083\n",
      "Epoch 136/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0378 - mae: 0.0076 - val_loss: 0.0376 - val_mae: 0.0111\n",
      "Epoch 137/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0373 - mae: 0.0093 - val_loss: 0.0370 - val_mae: 0.0076\n",
      "Epoch 138/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0369 - mae: 0.0091 - val_loss: 0.0365 - val_mae: 0.0046\n",
      "Epoch 139/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0363 - mae: 0.0063 - val_loss: 0.0360 - val_mae: 0.0038\n",
      "Epoch 140/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0358 - mae: 0.0051 - val_loss: 0.0356 - val_mae: 0.0076\n",
      "Epoch 141/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0354 - mae: 0.0090 - val_loss: 0.0351 - val_mae: 0.0088\n",
      "Epoch 142/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0349 - mae: 0.0101 - val_loss: 0.0348 - val_mae: 0.0130\n",
      "Epoch 143/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0344 - mae: 0.0064 - val_loss: 0.0342 - val_mae: 0.0099\n",
      "Epoch 144/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0340 - mae: 0.0106 - val_loss: 0.0339 - val_mae: 0.0142\n",
      "Epoch 145/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0335 - mae: 0.0095 - val_loss: 0.0333 - val_mae: 0.0094\n",
      "Epoch 146/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0331 - mae: 0.0100 - val_loss: 0.0328 - val_mae: 0.0073\n",
      "Epoch 147/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0327 - mae: 0.0106 - val_loss: 0.0327 - val_mae: 0.0144\n",
      "Epoch 148/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.0176 - val_loss: 0.0320 - val_mae: 0.0112\n",
      "Epoch 149/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.0091 - val_loss: 0.0319 - val_mae: 0.0203\n",
      "Epoch 150/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.0117 - val_loss: 0.0313 - val_mae: 0.0154\n",
      "Epoch 151/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.0110 - val_loss: 0.0305 - val_mae: 0.0055\n",
      "Epoch 152/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.0181 - val_loss: 0.0313 - val_mae: 0.0327\n",
      "Epoch 153/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0306 - mae: 0.0219 - val_loss: 0.0300 - val_mae: 0.0147\n",
      "Epoch 154/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0297 - mae: 0.0135 - val_loss: 0.0294 - val_mae: 0.0121\n",
      "Epoch 155/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0292 - mae: 0.0112 - val_loss: 0.0289 - val_mae: 0.0084\n",
      "Epoch 156/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0287 - mae: 0.0095 - val_loss: 0.0286 - val_mae: 0.0103\n",
      "Epoch 157/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0283 - mae: 0.0093 - val_loss: 0.0282 - val_mae: 0.0111\n",
      "Epoch 158/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0281 - mae: 0.0121 - val_loss: 0.0281 - val_mae: 0.0212\n",
      "Epoch 159/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0278 - mae: 0.0157 - val_loss: 0.0280 - val_mae: 0.0227\n",
      "Epoch 160/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0278 - mae: 0.0220 - val_loss: 0.0293 - val_mae: 0.0469\n",
      "Epoch 161/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.0189 - val_loss: 0.0267 - val_mae: 0.0145\n",
      "Epoch 162/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.0104 - val_loss: 0.0261 - val_mae: 0.0081\n",
      "Epoch 163/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0259 - mae: 0.0079 - val_loss: 0.0257 - val_mae: 0.0059\n",
      "Epoch 164/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0255 - mae: 0.0063 - val_loss: 0.0254 - val_mae: 0.0085\n",
      "Epoch 165/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0252 - mae: 0.0102 - val_loss: 0.0251 - val_mae: 0.0108\n",
      "Epoch 166/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0249 - mae: 0.0114 - val_loss: 0.0250 - val_mae: 0.0161\n",
      "Epoch 167/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0245 - mae: 0.0086 - val_loss: 0.0244 - val_mae: 0.0127\n",
      "Epoch 168/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0241 - mae: 0.0095 - val_loss: 0.0239 - val_mae: 0.0082\n",
      "Epoch 169/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0237 - mae: 0.0061 - val_loss: 0.0237 - val_mae: 0.0118\n",
      "Epoch 170/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0234 - mae: 0.0079 - val_loss: 0.0232 - val_mae: 0.0068\n",
      "Epoch 171/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0233 - mae: 0.0157 - val_loss: 0.0234 - val_mae: 0.0236\n",
      "Epoch 172/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0230 - mae: 0.0154 - val_loss: 0.0226 - val_mae: 0.0116\n",
      "Epoch 173/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0226 - mae: 0.0149 - val_loss: 0.0224 - val_mae: 0.0145\n",
      "Epoch 174/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0221 - mae: 0.0109 - val_loss: 0.0222 - val_mae: 0.0194\n",
      "Epoch 175/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0219 - mae: 0.0138 - val_loss: 0.0216 - val_mae: 0.0109\n",
      "Epoch 176/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0215 - mae: 0.0126 - val_loss: 0.0220 - val_mae: 0.0245\n",
      "Epoch 177/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0214 - mae: 0.0170 - val_loss: 0.0214 - val_mae: 0.0186\n",
      "Epoch 178/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0221 - mae: 0.0307 - val_loss: 0.0219 - val_mae: 0.0339\n",
      "Epoch 179/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0208 - mae: 0.0191 - val_loss: 0.0204 - val_mae: 0.0145\n",
      "Epoch 180/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0202 - mae: 0.0118 - val_loss: 0.0199 - val_mae: 0.0082\n",
      "Epoch 181/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0198 - mae: 0.0089 - val_loss: 0.0196 - val_mae: 0.0080\n",
      "Epoch 182/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0195 - mae: 0.0066 - val_loss: 0.0193 - val_mae: 0.0078\n",
      "Epoch 183/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0192 - mae: 0.0076 - val_loss: 0.0192 - val_mae: 0.0141\n",
      "Epoch 184/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0190 - mae: 0.0112 - val_loss: 0.0189 - val_mae: 0.0146\n",
      "Epoch 185/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0187 - mae: 0.0108 - val_loss: 0.0185 - val_mae: 0.0098\n",
      "Epoch 186/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0186 - mae: 0.0155 - val_loss: 0.0200 - val_mae: 0.0379\n",
      "Epoch 187/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0185 - mae: 0.0191 - val_loss: 0.0181 - val_mae: 0.0155\n",
      "Epoch 188/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0180 - mae: 0.0153 - val_loss: 0.0180 - val_mae: 0.0176\n",
      "Epoch 189/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0143 - val_loss: 0.0175 - val_mae: 0.0139\n",
      "Epoch 190/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0182 - mae: 0.0215 - val_loss: 0.0200 - val_mae: 0.0407\n",
      "Epoch 191/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0183 - mae: 0.0294 - val_loss: 0.0172 - val_mae: 0.0189\n",
      "Epoch 192/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0193 - val_loss: 0.0170 - val_mae: 0.0186\n",
      "Epoch 193/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0178 - val_loss: 0.0174 - val_mae: 0.0294\n",
      "Epoch 194/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0209 - val_loss: 0.0162 - val_mae: 0.0115\n",
      "Epoch 195/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0162 - val_loss: 0.0162 - val_mae: 0.0156\n",
      "Epoch 196/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0113 - val_loss: 0.0156 - val_mae: 0.0113\n",
      "Epoch 197/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0223 - val_loss: 0.0155 - val_mae: 0.0098\n",
      "Epoch 198/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0156 - mae: 0.0153 - val_loss: 0.0151 - val_mae: 0.0070\n",
      "Epoch 199/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0151 - mae: 0.0098 - val_loss: 0.0149 - val_mae: 0.0083\n",
      "Epoch 200/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0147 - mae: 0.0067 - val_loss: 0.0146 - val_mae: 0.0062\n",
      "Epoch 201/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0063 - val_loss: 0.0146 - val_mae: 0.0137\n",
      "Epoch 202/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0160 - mae: 0.0291 - val_loss: 0.0168 - val_mae: 0.0443\n",
      "Epoch 203/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0147 - mae: 0.0193 - val_loss: 0.0143 - val_mae: 0.0174\n",
      "Epoch 204/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0113 - val_loss: 0.0138 - val_mae: 0.0097\n",
      "Epoch 205/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0091 - val_loss: 0.0137 - val_mae: 0.0118\n",
      "Epoch 206/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0141 - val_loss: 0.0135 - val_mae: 0.0107\n",
      "Epoch 207/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0123 - val_loss: 0.0131 - val_mae: 0.0071\n",
      "Epoch 208/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0116 - val_loss: 0.0129 - val_mae: 0.0051\n",
      "Epoch 209/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0100 - val_loss: 0.0127 - val_mae: 0.0059\n",
      "Epoch 210/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - mae: 0.0113 - val_loss: 0.0126 - val_mae: 0.0091\n",
      "Epoch 211/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0076 - val_loss: 0.0124 - val_mae: 0.0105\n",
      "Epoch 212/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0099 - val_loss: 0.0124 - val_mae: 0.0140\n",
      "Epoch 213/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0136 - val_loss: 0.0120 - val_mae: 0.0080\n",
      "Epoch 214/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0133 - val_loss: 0.0122 - val_mae: 0.0167\n",
      "Epoch 215/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0117 - mae: 0.0076 - val_loss: 0.0116 - val_mae: 0.0059\n",
      "Epoch 216/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - mae: 0.0061 - val_loss: 0.0114 - val_mae: 0.0062\n",
      "Epoch 217/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0115 - mae: 0.0114 - val_loss: 0.0112 - val_mae: 0.0061\n",
      "Epoch 218/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0112 - mae: 0.0078 - val_loss: 0.0111 - val_mae: 0.0106\n",
      "Epoch 219/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0110 - mae: 0.0090 - val_loss: 0.0110 - val_mae: 0.0096\n",
      "Epoch 220/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0114 - val_mae: 0.0212\n",
      "Epoch 221/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0109 - mae: 0.0147 - val_loss: 0.0114 - val_mae: 0.0273\n",
      "Epoch 222/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0106 - mae: 0.0112 - val_loss: 0.0104 - val_mae: 0.0071\n",
      "Epoch 223/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0104 - mae: 0.0102 - val_loss: 0.0106 - val_mae: 0.0175\n",
      "Epoch 224/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0103 - mae: 0.0105 - val_loss: 0.0103 - val_mae: 0.0147\n",
      "Epoch 225/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0099 - val_mae: 0.0058\n",
      "Epoch 226/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0103 - val_mae: 0.0206\n",
      "Epoch 227/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0101 - mae: 0.0171 - val_loss: 0.0099 - val_mae: 0.0165\n",
      "Epoch 228/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0100 - mae: 0.0169 - val_loss: 0.0097 - val_mae: 0.0124\n",
      "Epoch 229/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0098 - mae: 0.0173 - val_loss: 0.0102 - val_mae: 0.0271\n",
      "Epoch 230/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0154 - val_loss: 0.0094 - val_mae: 0.0139\n",
      "Epoch 231/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0086 - val_loss: 0.0091 - val_mae: 0.0098\n",
      "Epoch 232/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0087 - val_loss: 0.0089 - val_mae: 0.0052\n",
      "Epoch 233/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0110 - val_loss: 0.0099 - val_mae: 0.0285\n",
      "Epoch 234/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0106 - mae: 0.0339 - val_loss: 0.0106 - val_mae: 0.0358\n",
      "Epoch 235/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0209 - val_loss: 0.0099 - val_mae: 0.0331\n",
      "Epoch 236/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0211 - val_loss: 0.0089 - val_mae: 0.0198\n",
      "Epoch 237/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0129 - val_loss: 0.0083 - val_mae: 0.0064\n",
      "Epoch 238/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0092 - val_loss: 0.0084 - val_mae: 0.0128\n",
      "Epoch 239/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0095 - val_loss: 0.0083 - val_mae: 0.0163\n",
      "Epoch 240/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0118 - val_loss: 0.0081 - val_mae: 0.0114\n",
      "Epoch 241/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0126 - val_loss: 0.0079 - val_mae: 0.0099\n",
      "Epoch 242/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0062 - val_loss: 0.0077 - val_mae: 0.0060\n",
      "Epoch 243/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0078 - val_loss: 0.0076 - val_mae: 0.0069\n",
      "Epoch 244/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - mae: 0.0074 - val_loss: 0.0075 - val_mae: 0.0063\n",
      "Epoch 245/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - mae: 0.0103 - val_loss: 0.0075 - val_mae: 0.0112\n",
      "Epoch 246/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - mae: 0.0111 - val_loss: 0.0074 - val_mae: 0.0135\n",
      "Epoch 247/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - mae: 0.0136 - val_loss: 0.0073 - val_mae: 0.0135\n",
      "Epoch 248/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - mae: 0.0074 - val_loss: 0.0070 - val_mae: 0.0062\n",
      "Epoch 249/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - mae: 0.0085 - val_loss: 0.0070 - val_mae: 0.0098\n",
      "Epoch 250/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - mae: 0.0085 - val_loss: 0.0068 - val_mae: 0.0047\n",
      "Epoch 251/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - mae: 0.0050 - val_loss: 0.0067 - val_mae: 0.0043\n",
      "Epoch 252/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - mae: 0.0084 - val_loss: 0.0067 - val_mae: 0.0097\n",
      "Epoch 253/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - mae: 0.0092 - val_loss: 0.0068 - val_mae: 0.0144\n",
      "Epoch 254/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - mae: 0.0124 - val_loss: 0.0067 - val_mae: 0.0142\n",
      "Epoch 255/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0065 - mae: 0.0094 - val_loss: 0.0064 - val_mae: 0.0076\n",
      "Epoch 256/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0064 - mae: 0.0108 - val_loss: 0.0065 - val_mae: 0.0138\n",
      "Epoch 257/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - mae: 0.0187 - val_loss: 0.0070 - val_mae: 0.0255\n",
      "Epoch 258/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - mae: 0.0221 - val_loss: 0.0068 - val_mae: 0.0211\n",
      "Epoch 259/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0062 - mae: 0.0117 - val_loss: 0.0061 - val_mae: 0.0105\n",
      "Epoch 260/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0061 - mae: 0.0103 - val_loss: 0.0060 - val_mae: 0.0095\n",
      "Epoch 261/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0059 - mae: 0.0077 - val_loss: 0.0062 - val_mae: 0.0161\n",
      "Epoch 262/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0059 - mae: 0.0099 - val_loss: 0.0058 - val_mae: 0.0064\n",
      "Epoch 263/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0058 - mae: 0.0072 - val_loss: 0.0057 - val_mae: 0.0046\n",
      "Epoch 264/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0057 - mae: 0.0059 - val_loss: 0.0056 - val_mae: 0.0054\n",
      "Epoch 265/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0056 - mae: 0.0065 - val_loss: 0.0055 - val_mae: 0.0059\n",
      "Epoch 266/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0058 - mae: 0.0146 - val_loss: 0.0062 - val_mae: 0.0261\n",
      "Epoch 267/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0058 - mae: 0.0157 - val_loss: 0.0065 - val_mae: 0.0284\n",
      "Epoch 268/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0060 - mae: 0.0192 - val_loss: 0.0054 - val_mae: 0.0075\n",
      "Epoch 269/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0054 - mae: 0.0087 - val_loss: 0.0052 - val_mae: 0.0054\n",
      "Epoch 270/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0052 - mae: 0.0072 - val_loss: 0.0051 - val_mae: 0.0033\n",
      "Epoch 271/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0052 - mae: 0.0070 - val_loss: 0.0057 - val_mae: 0.0197\n",
      "Epoch 272/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - mae: 0.0312 - val_loss: 0.0083 - val_mae: 0.0384\n",
      "Epoch 273/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0060 - mae: 0.0240 - val_loss: 0.0052 - val_mae: 0.0130\n",
      "Epoch 274/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0053 - mae: 0.0140 - val_loss: 0.0053 - val_mae: 0.0153\n",
      "Epoch 275/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0075 - val_loss: 0.0050 - val_mae: 0.0100\n",
      "Epoch 276/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0076 - val_loss: 0.0048 - val_mae: 0.0061\n",
      "Epoch 277/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0048 - mae: 0.0063 - val_loss: 0.0048 - val_mae: 0.0065\n",
      "Epoch 278/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0071 - val_loss: 0.0049 - val_mae: 0.0146\n",
      "Epoch 279/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0047 - mae: 0.0069 - val_loss: 0.0047 - val_mae: 0.0074\n",
      "Epoch 280/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - mae: 0.0078 - val_loss: 0.0047 - val_mae: 0.0103\n",
      "Epoch 281/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0050 - mae: 0.0156 - val_loss: 0.0050 - val_mae: 0.0148\n",
      "Epoch 282/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0048 - mae: 0.0153 - val_loss: 0.0049 - val_mae: 0.0183\n",
      "Epoch 283/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0046 - mae: 0.0104 - val_loss: 0.0044 - val_mae: 0.0053\n",
      "Epoch 284/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0061 - val_loss: 0.0044 - val_mae: 0.0068\n",
      "Epoch 285/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0059 - val_loss: 0.0044 - val_mae: 0.0107\n",
      "Epoch 286/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0078 - val_loss: 0.0043 - val_mae: 0.0093\n",
      "Epoch 287/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0043 - mae: 0.0080 - val_loss: 0.0042 - val_mae: 0.0056\n",
      "Epoch 288/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0064 - val_loss: 0.0042 - val_mae: 0.0083\n",
      "Epoch 289/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0071 - val_loss: 0.0041 - val_mae: 0.0074\n",
      "Epoch 290/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0046 - mae: 0.0185 - val_loss: 0.0043 - val_mae: 0.0138\n",
      "Epoch 291/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0056 - mae: 0.0303 - val_loss: 0.0047 - val_mae: 0.0216\n",
      "Epoch 292/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0045 - mae: 0.0173 - val_loss: 0.0040 - val_mae: 0.0079\n",
      "Epoch 293/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0074 - val_loss: 0.0040 - val_mae: 0.0092\n",
      "Epoch 294/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0087 - val_loss: 0.0043 - val_mae: 0.0190\n",
      "Epoch 295/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0129 - val_loss: 0.0039 - val_mae: 0.0098\n",
      "Epoch 296/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0119 - val_loss: 0.0039 - val_mae: 0.0072\n",
      "Epoch 297/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0041 - mae: 0.0137 - val_loss: 0.0042 - val_mae: 0.0174\n",
      "Epoch 298/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0104 - val_loss: 0.0039 - val_mae: 0.0128\n",
      "Epoch 299/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0144 - val_loss: 0.0045 - val_mae: 0.0216\n",
      "Epoch 300/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0158 - val_loss: 0.0039 - val_mae: 0.0124\n",
      "Epoch 301/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0038 - mae: 0.0115 - val_loss: 0.0037 - val_mae: 0.0105\n",
      "Epoch 302/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0037 - mae: 0.0101 - val_loss: 0.0039 - val_mae: 0.0122\n",
      "Epoch 303/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0127 - val_loss: 0.0041 - val_mae: 0.0158\n",
      "Epoch 304/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0142 - val_loss: 0.0035 - val_mae: 0.0061\n",
      "Epoch 305/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0109 - val_loss: 0.0037 - val_mae: 0.0129\n",
      "Epoch 306/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0143 - val_loss: 0.0045 - val_mae: 0.0313\n",
      "Epoch 307/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0232 - val_loss: 0.0037 - val_mae: 0.0157\n",
      "Epoch 308/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0099 - val_loss: 0.0034 - val_mae: 0.0052\n",
      "Epoch 309/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0068 - val_loss: 0.0034 - val_mae: 0.0071\n",
      "Epoch 310/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0088 - val_loss: 0.0034 - val_mae: 0.0102\n",
      "Epoch 311/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0079 - val_loss: 0.0033 - val_mae: 0.0069\n",
      "Epoch 312/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0063 - val_loss: 0.0033 - val_mae: 0.0087\n",
      "Epoch 313/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0058 - val_loss: 0.0032 - val_mae: 0.0045\n",
      "Epoch 314/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0087 - val_loss: 0.0034 - val_mae: 0.0130\n",
      "Epoch 315/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0147 - val_loss: 0.0032 - val_mae: 0.0093\n",
      "Epoch 316/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0131 - val_loss: 0.0032 - val_mae: 0.0071\n",
      "Epoch 317/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0060 - val_loss: 0.0031 - val_mae: 0.0059\n",
      "Epoch 318/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0071 - val_loss: 0.0031 - val_mae: 0.0075\n",
      "Epoch 319/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0055 - val_loss: 0.0031 - val_mae: 0.0112\n",
      "Epoch 320/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0072 - val_loss: 0.0030 - val_mae: 0.0045\n",
      "Epoch 321/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0080 - val_loss: 0.0032 - val_mae: 0.0119\n",
      "Epoch 322/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0090 - val_loss: 0.0031 - val_mae: 0.0124\n",
      "Epoch 323/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0125 - val_loss: 0.0038 - val_mae: 0.0258\n",
      "Epoch 324/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0206 - val_loss: 0.0035 - val_mae: 0.0184\n",
      "Epoch 325/1000\n",
      "23/28 [=======================>......] - ETA: 0s - loss: 0.0035 - mae: 0.0204Restoring model weights from the end of the best epoch: 320.\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0211 - val_loss: 0.0034 - val_mae: 0.0207\n",
      "Epoch 325: early stopping\n",
      "Training für Fold 2...\n",
      "Epoch 1/1000\n",
      "28/28 [==============================] - 2s 9ms/step - loss: 0.5101 - mae: 0.3493 - val_loss: 0.3900 - val_mae: 0.2800\n",
      "Epoch 2/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3517 - mae: 0.2502 - val_loss: 0.3379 - val_mae: 0.2723\n",
      "Epoch 3/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2937 - mae: 0.2011 - val_loss: 0.2601 - val_mae: 0.1635\n",
      "Epoch 4/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2377 - mae: 0.1268 - val_loss: 0.2169 - val_mae: 0.0847\n",
      "Epoch 5/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2155 - mae: 0.0872 - val_loss: 0.2063 - val_mae: 0.0700\n",
      "Epoch 6/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2003 - mae: 0.0573 - val_loss: 0.2087 - val_mae: 0.0921\n",
      "Epoch 7/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1974 - mae: 0.0672 - val_loss: 0.1995 - val_mae: 0.0963\n",
      "Epoch 8/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1954 - mae: 0.0742 - val_loss: 0.1921 - val_mae: 0.0696\n",
      "Epoch 9/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1924 - mae: 0.0772 - val_loss: 0.1816 - val_mae: 0.0407\n",
      "Epoch 10/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1833 - mae: 0.0561 - val_loss: 0.1770 - val_mae: 0.0304\n",
      "Epoch 11/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1820 - mae: 0.0618 - val_loss: 0.1841 - val_mae: 0.0856\n",
      "Epoch 12/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1739 - mae: 0.0340 - val_loss: 0.1730 - val_mae: 0.0446\n",
      "Epoch 13/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1700 - mae: 0.0253 - val_loss: 0.1682 - val_mae: 0.0215\n",
      "Epoch 14/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1699 - mae: 0.0419 - val_loss: 0.1700 - val_mae: 0.0567\n",
      "Epoch 15/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1659 - mae: 0.0324 - val_loss: 0.1673 - val_mae: 0.0494\n",
      "Epoch 16/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1633 - mae: 0.0297 - val_loss: 0.1623 - val_mae: 0.0361\n",
      "Epoch 17/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1611 - mae: 0.0306 - val_loss: 0.1610 - val_mae: 0.0402\n",
      "Epoch 18/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1610 - mae: 0.0428 - val_loss: 0.1571 - val_mae: 0.0259\n",
      "Epoch 19/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1555 - mae: 0.0169 - val_loss: 0.1542 - val_mae: 0.0137\n",
      "Epoch 20/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1531 - mae: 0.0112 - val_loss: 0.1522 - val_mae: 0.0138\n",
      "Epoch 21/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1512 - mae: 0.0120 - val_loss: 0.1504 - val_mae: 0.0200\n",
      "Epoch 22/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1495 - mae: 0.0171 - val_loss: 0.1482 - val_mae: 0.0137\n",
      "Epoch 23/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1472 - mae: 0.0118 - val_loss: 0.1468 - val_mae: 0.0220\n",
      "Epoch 24/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1455 - mae: 0.0140 - val_loss: 0.1451 - val_mae: 0.0225\n",
      "Epoch 25/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1436 - mae: 0.0141 - val_loss: 0.1428 - val_mae: 0.0177\n",
      "Epoch 26/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1417 - mae: 0.0101 - val_loss: 0.1407 - val_mae: 0.0073\n",
      "Epoch 27/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1400 - mae: 0.0114 - val_loss: 0.1390 - val_mae: 0.0095\n",
      "Epoch 28/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1416 - mae: 0.0375 - val_loss: 0.1449 - val_mae: 0.0661\n",
      "Epoch 29/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1449 - mae: 0.0610 - val_loss: 0.1414 - val_mae: 0.0557\n",
      "Epoch 30/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1370 - mae: 0.0342 - val_loss: 0.1345 - val_mae: 0.0221\n",
      "Epoch 31/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1338 - mae: 0.0199 - val_loss: 0.1327 - val_mae: 0.0148\n",
      "Epoch 32/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1325 - mae: 0.0248 - val_loss: 0.1308 - val_mae: 0.0110\n",
      "Epoch 33/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1303 - mae: 0.0143 - val_loss: 0.1292 - val_mae: 0.0101\n",
      "Epoch 34/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1286 - mae: 0.0122 - val_loss: 0.1278 - val_mae: 0.0114\n",
      "Epoch 35/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1269 - mae: 0.0073 - val_loss: 0.1261 - val_mae: 0.0075\n",
      "Epoch 36/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1254 - mae: 0.0078 - val_loss: 0.1247 - val_mae: 0.0100\n",
      "Epoch 37/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1241 - mae: 0.0105 - val_loss: 0.1233 - val_mae: 0.0103\n",
      "Epoch 38/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1226 - mae: 0.0112 - val_loss: 0.1219 - val_mae: 0.0128\n",
      "Epoch 39/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1212 - mae: 0.0100 - val_loss: 0.1206 - val_mae: 0.0178\n",
      "Epoch 40/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1200 - mae: 0.0143 - val_loss: 0.1191 - val_mae: 0.0135\n",
      "Epoch 41/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1185 - mae: 0.0128 - val_loss: 0.1180 - val_mae: 0.0166\n",
      "Epoch 42/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1172 - mae: 0.0135 - val_loss: 0.1170 - val_mae: 0.0248\n",
      "Epoch 43/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1162 - mae: 0.0195 - val_loss: 0.1174 - val_mae: 0.0368\n",
      "Epoch 44/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1165 - mae: 0.0319 - val_loss: 0.1137 - val_mae: 0.0118\n",
      "Epoch 45/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1131 - mae: 0.0101 - val_loss: 0.1123 - val_mae: 0.0070\n",
      "Epoch 46/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1118 - mae: 0.0103 - val_loss: 0.1115 - val_mae: 0.0170\n",
      "Epoch 47/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1113 - mae: 0.0225 - val_loss: 0.1105 - val_mae: 0.0238\n",
      "Epoch 48/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1094 - mae: 0.0130 - val_loss: 0.1085 - val_mae: 0.0071\n",
      "Epoch 49/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1080 - mae: 0.0097 - val_loss: 0.1075 - val_mae: 0.0121\n",
      "Epoch 50/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1069 - mae: 0.0114 - val_loss: 0.1075 - val_mae: 0.0311\n",
      "Epoch 51/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1065 - mae: 0.0230 - val_loss: 0.1057 - val_mae: 0.0247\n",
      "Epoch 52/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1051 - mae: 0.0216 - val_loss: 0.1075 - val_mae: 0.0514\n",
      "Epoch 53/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1044 - mae: 0.0284 - val_loss: 0.1053 - val_mae: 0.0389\n",
      "Epoch 54/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1038 - mae: 0.0329 - val_loss: 0.1122 - val_mae: 0.0769\n",
      "Epoch 55/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1033 - mae: 0.0337 - val_loss: 0.1007 - val_mae: 0.0181\n",
      "Epoch 56/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1005 - mae: 0.0214 - val_loss: 0.1008 - val_mae: 0.0333\n",
      "Epoch 57/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0990 - mae: 0.0163 - val_loss: 0.0981 - val_mae: 0.0103\n",
      "Epoch 58/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0984 - mae: 0.0210 - val_loss: 0.1006 - val_mae: 0.0475\n",
      "Epoch 59/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0985 - mae: 0.0329 - val_loss: 0.0972 - val_mae: 0.0281\n",
      "Epoch 60/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0959 - mae: 0.0186 - val_loss: 0.0948 - val_mae: 0.0083\n",
      "Epoch 61/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0944 - mae: 0.0105 - val_loss: 0.0937 - val_mae: 0.0069\n",
      "Epoch 62/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0933 - mae: 0.0083 - val_loss: 0.0928 - val_mae: 0.0102\n",
      "Epoch 63/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0922 - mae: 0.0070 - val_loss: 0.0917 - val_mae: 0.0093\n",
      "Epoch 64/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0912 - mae: 0.0074 - val_loss: 0.0906 - val_mae: 0.0060\n",
      "Epoch 65/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0901 - mae: 0.0076 - val_loss: 0.0896 - val_mae: 0.0081\n",
      "Epoch 66/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0891 - mae: 0.0078 - val_loss: 0.0886 - val_mae: 0.0086\n",
      "Epoch 67/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0881 - mae: 0.0081 - val_loss: 0.0877 - val_mae: 0.0107\n",
      "Epoch 68/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0871 - mae: 0.0065 - val_loss: 0.0866 - val_mae: 0.0055\n",
      "Epoch 69/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0861 - mae: 0.0054 - val_loss: 0.0856 - val_mae: 0.0084\n",
      "Epoch 70/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0851 - mae: 0.0065 - val_loss: 0.0846 - val_mae: 0.0066\n",
      "Epoch 71/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0842 - mae: 0.0076 - val_loss: 0.0838 - val_mae: 0.0088\n",
      "Epoch 72/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0836 - mae: 0.0142 - val_loss: 0.0828 - val_mae: 0.0088\n",
      "Epoch 73/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0823 - mae: 0.0075 - val_loss: 0.0818 - val_mae: 0.0062\n",
      "Epoch 74/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0813 - mae: 0.0055 - val_loss: 0.0809 - val_mae: 0.0070\n",
      "Epoch 75/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0804 - mae: 0.0070 - val_loss: 0.0803 - val_mae: 0.0146\n",
      "Epoch 76/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0797 - mae: 0.0132 - val_loss: 0.0793 - val_mae: 0.0150\n",
      "Epoch 77/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0787 - mae: 0.0102 - val_loss: 0.0782 - val_mae: 0.0121\n",
      "Epoch 78/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0781 - mae: 0.0148 - val_loss: 0.0786 - val_mae: 0.0258\n",
      "Epoch 79/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0774 - mae: 0.0178 - val_loss: 0.0765 - val_mae: 0.0124\n",
      "Epoch 80/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0761 - mae: 0.0122 - val_loss: 0.0756 - val_mae: 0.0128\n",
      "Epoch 81/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0754 - mae: 0.0149 - val_loss: 0.0748 - val_mae: 0.0111\n",
      "Epoch 82/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0747 - mae: 0.0195 - val_loss: 0.0744 - val_mae: 0.0183\n",
      "Epoch 83/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0740 - mae: 0.0178 - val_loss: 0.0733 - val_mae: 0.0171\n",
      "Epoch 84/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0740 - mae: 0.0270 - val_loss: 0.0746 - val_mae: 0.0379\n",
      "Epoch 85/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0736 - mae: 0.0310 - val_loss: 0.0715 - val_mae: 0.0147\n",
      "Epoch 86/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0712 - mae: 0.0160 - val_loss: 0.0704 - val_mae: 0.0084\n",
      "Epoch 87/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0701 - mae: 0.0095 - val_loss: 0.0696 - val_mae: 0.0104\n",
      "Epoch 88/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0694 - mae: 0.0150 - val_loss: 0.0690 - val_mae: 0.0148\n",
      "Epoch 89/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0685 - mae: 0.0121 - val_loss: 0.0686 - val_mae: 0.0231\n",
      "Epoch 90/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0679 - mae: 0.0156 - val_loss: 0.0674 - val_mae: 0.0148\n",
      "Epoch 91/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0672 - mae: 0.0169 - val_loss: 0.0667 - val_mae: 0.0161\n",
      "Epoch 92/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0661 - mae: 0.0115 - val_loss: 0.0656 - val_mae: 0.0078\n",
      "Epoch 93/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0653 - mae: 0.0107 - val_loss: 0.0649 - val_mae: 0.0113\n",
      "Epoch 94/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0645 - mae: 0.0106 - val_loss: 0.0640 - val_mae: 0.0084\n",
      "Epoch 95/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0637 - mae: 0.0078 - val_loss: 0.0633 - val_mae: 0.0095\n",
      "Epoch 96/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0629 - mae: 0.0089 - val_loss: 0.0624 - val_mae: 0.0060\n",
      "Epoch 97/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0621 - mae: 0.0060 - val_loss: 0.0618 - val_mae: 0.0093\n",
      "Epoch 98/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0614 - mae: 0.0091 - val_loss: 0.0618 - val_mae: 0.0243\n",
      "Epoch 99/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0607 - mae: 0.0095 - val_loss: 0.0604 - val_mae: 0.0122\n",
      "Epoch 100/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0600 - mae: 0.0106 - val_loss: 0.0597 - val_mae: 0.0124\n",
      "Epoch 101/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0595 - mae: 0.0157 - val_loss: 0.0599 - val_mae: 0.0291\n",
      "Epoch 102/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0592 - mae: 0.0215 - val_loss: 0.0581 - val_mae: 0.0075\n",
      "Epoch 103/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0580 - mae: 0.0153 - val_loss: 0.0577 - val_mae: 0.0183\n",
      "Epoch 104/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0572 - mae: 0.0133 - val_loss: 0.0569 - val_mae: 0.0159\n",
      "Epoch 105/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0565 - mae: 0.0129 - val_loss: 0.0561 - val_mae: 0.0132\n",
      "Epoch 106/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0556 - mae: 0.0065 - val_loss: 0.0552 - val_mae: 0.0068\n",
      "Epoch 107/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0550 - mae: 0.0099 - val_loss: 0.0546 - val_mae: 0.0086\n",
      "Epoch 108/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0542 - mae: 0.0066 - val_loss: 0.0538 - val_mae: 0.0068\n",
      "Epoch 109/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0535 - mae: 0.0071 - val_loss: 0.0532 - val_mae: 0.0096\n",
      "Epoch 110/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0529 - mae: 0.0086 - val_loss: 0.0526 - val_mae: 0.0132\n",
      "Epoch 111/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0525 - mae: 0.0142 - val_loss: 0.0521 - val_mae: 0.0141\n",
      "Epoch 112/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0534 - mae: 0.0305 - val_loss: 0.0698 - val_mae: 0.1080\n",
      "Epoch 113/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0559 - mae: 0.0504 - val_loss: 0.0547 - val_mae: 0.0548\n",
      "Epoch 114/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0513 - mae: 0.0254 - val_loss: 0.0503 - val_mae: 0.0158\n",
      "Epoch 115/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0506 - mae: 0.0236 - val_loss: 0.0521 - val_mae: 0.0396\n",
      "Epoch 116/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0494 - mae: 0.0155 - val_loss: 0.0489 - val_mae: 0.0153\n",
      "Epoch 117/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0485 - mae: 0.0104 - val_loss: 0.0482 - val_mae: 0.0119\n",
      "Epoch 118/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0479 - mae: 0.0115 - val_loss: 0.0474 - val_mae: 0.0066\n",
      "Epoch 119/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0474 - mae: 0.0142 - val_loss: 0.0474 - val_mae: 0.0218\n",
      "Epoch 120/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0468 - mae: 0.0150 - val_loss: 0.0473 - val_mae: 0.0284\n",
      "Epoch 121/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0468 - mae: 0.0229 - val_loss: 0.0459 - val_mae: 0.0159\n",
      "Epoch 122/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0456 - mae: 0.0145 - val_loss: 0.0451 - val_mae: 0.0118\n",
      "Epoch 123/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0448 - mae: 0.0095 - val_loss: 0.0446 - val_mae: 0.0125\n",
      "Epoch 124/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0442 - mae: 0.0105 - val_loss: 0.0440 - val_mae: 0.0138\n",
      "Epoch 125/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0436 - mae: 0.0080 - val_loss: 0.0432 - val_mae: 0.0069\n",
      "Epoch 126/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0430 - mae: 0.0067 - val_loss: 0.0428 - val_mae: 0.0136\n",
      "Epoch 127/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0425 - mae: 0.0102 - val_loss: 0.0422 - val_mae: 0.0098\n",
      "Epoch 128/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0419 - mae: 0.0092 - val_loss: 0.0418 - val_mae: 0.0150\n",
      "Epoch 129/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0431 - mae: 0.0341 - val_loss: 0.0442 - val_mae: 0.0454\n",
      "Epoch 130/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0448 - mae: 0.0472 - val_loss: 0.0416 - val_mae: 0.0238\n",
      "Epoch 131/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0423 - mae: 0.0356 - val_loss: 0.0412 - val_mae: 0.0255\n",
      "Epoch 132/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0401 - mae: 0.0155 - val_loss: 0.0395 - val_mae: 0.0081\n",
      "Epoch 133/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0394 - mae: 0.0114 - val_loss: 0.0390 - val_mae: 0.0098\n",
      "Epoch 134/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0388 - mae: 0.0115 - val_loss: 0.0385 - val_mae: 0.0100\n",
      "Epoch 135/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - mae: 0.0080 - val_loss: 0.0379 - val_mae: 0.0074\n",
      "Epoch 136/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0376 - mae: 0.0070 - val_loss: 0.0373 - val_mae: 0.0056\n",
      "Epoch 137/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0375 - mae: 0.0129 - val_loss: 0.0369 - val_mae: 0.0098\n",
      "Epoch 138/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0367 - mae: 0.0103 - val_loss: 0.0370 - val_mae: 0.0191\n",
      "Epoch 139/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0363 - mae: 0.0126 - val_loss: 0.0381 - val_mae: 0.0376\n",
      "Epoch 140/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0362 - mae: 0.0187 - val_loss: 0.0356 - val_mae: 0.0144\n",
      "Epoch 141/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0352 - mae: 0.0087 - val_loss: 0.0349 - val_mae: 0.0074\n",
      "Epoch 142/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0346 - mae: 0.0068 - val_loss: 0.0344 - val_mae: 0.0074\n",
      "Epoch 143/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0342 - mae: 0.0092 - val_loss: 0.0341 - val_mae: 0.0131\n",
      "Epoch 144/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0338 - mae: 0.0104 - val_loss: 0.0337 - val_mae: 0.0154\n",
      "Epoch 145/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0334 - mae: 0.0124 - val_loss: 0.0332 - val_mae: 0.0130\n",
      "Epoch 146/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0342 - mae: 0.0291 - val_loss: 0.0345 - val_mae: 0.0403\n",
      "Epoch 147/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0332 - mae: 0.0242 - val_loss: 0.0322 - val_mae: 0.0122\n",
      "Epoch 148/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.0092 - val_loss: 0.0317 - val_mae: 0.0088\n",
      "Epoch 149/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0315 - mae: 0.0090 - val_loss: 0.0313 - val_mae: 0.0100\n",
      "Epoch 150/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.0146 - val_loss: 0.0311 - val_mae: 0.0156\n",
      "Epoch 151/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.0176 - val_loss: 0.0305 - val_mae: 0.0132\n",
      "Epoch 152/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.0121 - val_loss: 0.0300 - val_mae: 0.0117\n",
      "Epoch 153/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.0092 - val_loss: 0.0295 - val_mae: 0.0075\n",
      "Epoch 154/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.0158 - val_loss: 0.0299 - val_mae: 0.0242\n",
      "Epoch 155/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.0141 - val_loss: 0.0289 - val_mae: 0.0162\n",
      "Epoch 156/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.0090 - val_loss: 0.0283 - val_mae: 0.0115\n",
      "Epoch 157/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.0165 - val_loss: 0.0280 - val_mae: 0.0150\n",
      "Epoch 158/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.0100 - val_loss: 0.0274 - val_mae: 0.0050\n",
      "Epoch 159/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.0075 - val_loss: 0.0271 - val_mae: 0.0109\n",
      "Epoch 160/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.0090 - val_loss: 0.0266 - val_mae: 0.0076\n",
      "Epoch 161/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.0136 - val_loss: 0.0268 - val_mae: 0.0198\n",
      "Epoch 162/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.0246 - val_loss: 0.0270 - val_mae: 0.0289\n",
      "Epoch 163/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.0202 - val_loss: 0.0259 - val_mae: 0.0148\n",
      "Epoch 164/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0254 - mae: 0.0099 - val_loss: 0.0252 - val_mae: 0.0100\n",
      "Epoch 165/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0249 - mae: 0.0082 - val_loss: 0.0247 - val_mae: 0.0075\n",
      "Epoch 166/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0251 - mae: 0.0167 - val_loss: 0.0277 - val_mae: 0.0455\n",
      "Epoch 167/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0261 - mae: 0.0312 - val_loss: 0.0253 - val_mae: 0.0275\n",
      "Epoch 168/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0242 - mae: 0.0143 - val_loss: 0.0244 - val_mae: 0.0205\n",
      "Epoch 169/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0236 - mae: 0.0109 - val_loss: 0.0235 - val_mae: 0.0127\n",
      "Epoch 170/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0233 - mae: 0.0121 - val_loss: 0.0242 - val_mae: 0.0298\n",
      "Epoch 171/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0235 - mae: 0.0213 - val_loss: 0.0236 - val_mae: 0.0270\n",
      "Epoch 172/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0241 - mae: 0.0299 - val_loss: 0.0245 - val_mae: 0.0402\n",
      "Epoch 173/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0233 - mae: 0.0276 - val_loss: 0.0263 - val_mae: 0.0518\n",
      "Epoch 174/1000\n",
      "26/28 [==========================>...] - ETA: 0s - loss: 0.0229 - mae: 0.0255Restoring model weights from the end of the best epoch: 169.\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0229 - mae: 0.0257 - val_loss: 0.0246 - val_mae: 0.0422\n",
      "Epoch 174: early stopping\n",
      "Training für Fold 3...\n",
      "Epoch 1/1000\n",
      "28/28 [==============================] - 1s 9ms/step - loss: 0.5751 - mae: 0.3995 - val_loss: 0.4130 - val_mae: 0.3067\n",
      "Epoch 2/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3926 - mae: 0.3031 - val_loss: 0.4187 - val_mae: 0.3697\n",
      "Epoch 3/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3372 - mae: 0.2672 - val_loss: 0.3132 - val_mae: 0.2587\n",
      "Epoch 4/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2733 - mae: 0.2059 - val_loss: 0.2502 - val_mae: 0.1779\n",
      "Epoch 5/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2404 - mae: 0.1617 - val_loss: 0.2443 - val_mae: 0.1922\n",
      "Epoch 6/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2245 - mae: 0.1464 - val_loss: 0.2348 - val_mae: 0.1643\n",
      "Epoch 7/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2035 - mae: 0.0948 - val_loss: 0.1870 - val_mae: 0.0557\n",
      "Epoch 8/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1836 - mae: 0.0427 - val_loss: 0.1989 - val_mae: 0.0981\n",
      "Epoch 9/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1871 - mae: 0.0679 - val_loss: 0.1782 - val_mae: 0.0373\n",
      "Epoch 10/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1782 - mae: 0.0421 - val_loss: 0.1848 - val_mae: 0.0784\n",
      "Epoch 11/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1773 - mae: 0.0515 - val_loss: 0.1734 - val_mae: 0.0404\n",
      "Epoch 12/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1702 - mae: 0.0260 - val_loss: 0.1685 - val_mae: 0.0229\n",
      "Epoch 13/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1674 - mae: 0.0213 - val_loss: 0.1663 - val_mae: 0.0209\n",
      "Epoch 14/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1649 - mae: 0.0178 - val_loss: 0.1636 - val_mae: 0.0167\n",
      "Epoch 15/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1653 - mae: 0.0372 - val_loss: 0.1657 - val_mae: 0.0572\n",
      "Epoch 16/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1619 - mae: 0.0295 - val_loss: 0.1597 - val_mae: 0.0214\n",
      "Epoch 17/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1587 - mae: 0.0191 - val_loss: 0.1588 - val_mae: 0.0315\n",
      "Epoch 18/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1567 - mae: 0.0184 - val_loss: 0.1558 - val_mae: 0.0211\n",
      "Epoch 19/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1544 - mae: 0.0134 - val_loss: 0.1538 - val_mae: 0.0187\n",
      "Epoch 20/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1525 - mae: 0.0124 - val_loss: 0.1516 - val_mae: 0.0120\n",
      "Epoch 21/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1506 - mae: 0.0120 - val_loss: 0.1500 - val_mae: 0.0177\n",
      "Epoch 22/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1489 - mae: 0.0130 - val_loss: 0.1480 - val_mae: 0.0134\n",
      "Epoch 23/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1472 - mae: 0.0130 - val_loss: 0.1462 - val_mae: 0.0104\n",
      "Epoch 24/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1453 - mae: 0.0075 - val_loss: 0.1445 - val_mae: 0.0110\n",
      "Epoch 25/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1436 - mae: 0.0074 - val_loss: 0.1428 - val_mae: 0.0090\n",
      "Epoch 26/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1419 - mae: 0.0069 - val_loss: 0.1433 - val_mae: 0.0349\n",
      "Epoch 27/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1421 - mae: 0.0312 - val_loss: 0.1428 - val_mae: 0.0411\n",
      "Epoch 28/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1410 - mae: 0.0343 - val_loss: 0.1399 - val_mae: 0.0351\n",
      "Epoch 29/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1380 - mae: 0.0218 - val_loss: 0.1367 - val_mae: 0.0178\n",
      "Epoch 30/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1358 - mae: 0.0129 - val_loss: 0.1349 - val_mae: 0.0082\n",
      "Epoch 31/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1341 - mae: 0.0088 - val_loss: 0.1334 - val_mae: 0.0094\n",
      "Epoch 32/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1328 - mae: 0.0124 - val_loss: 0.1321 - val_mae: 0.0139\n",
      "Epoch 33/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1312 - mae: 0.0100 - val_loss: 0.1305 - val_mae: 0.0081\n",
      "Epoch 34/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1297 - mae: 0.0077 - val_loss: 0.1291 - val_mae: 0.0085\n",
      "Epoch 35/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1283 - mae: 0.0068 - val_loss: 0.1276 - val_mae: 0.0073\n",
      "Epoch 36/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1269 - mae: 0.0067 - val_loss: 0.1264 - val_mae: 0.0144\n",
      "Epoch 37/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1256 - mae: 0.0088 - val_loss: 0.1250 - val_mae: 0.0119\n",
      "Epoch 38/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1242 - mae: 0.0090 - val_loss: 0.1235 - val_mae: 0.0065\n",
      "Epoch 39/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1229 - mae: 0.0100 - val_loss: 0.1223 - val_mae: 0.0115\n",
      "Epoch 40/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1217 - mae: 0.0112 - val_loss: 0.1221 - val_mae: 0.0273\n",
      "Epoch 41/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1241 - mae: 0.0410 - val_loss: 0.1299 - val_mae: 0.0782\n",
      "Epoch 42/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1219 - mae: 0.0406 - val_loss: 0.1188 - val_mae: 0.0178\n",
      "Epoch 43/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1201 - mae: 0.0375 - val_loss: 0.1181 - val_mae: 0.0252\n",
      "Epoch 44/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1174 - mae: 0.0255 - val_loss: 0.1164 - val_mae: 0.0200\n",
      "Epoch 45/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1159 - mae: 0.0208 - val_loss: 0.1153 - val_mae: 0.0190\n",
      "Epoch 46/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1148 - mae: 0.0243 - val_loss: 0.1149 - val_mae: 0.0306\n",
      "Epoch 47/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1134 - mae: 0.0212 - val_loss: 0.1123 - val_mae: 0.0134\n",
      "Epoch 48/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1117 - mae: 0.0108 - val_loss: 0.1111 - val_mae: 0.0121\n",
      "Epoch 49/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1105 - mae: 0.0115 - val_loss: 0.1099 - val_mae: 0.0087\n",
      "Epoch 50/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1094 - mae: 0.0111 - val_loss: 0.1087 - val_mae: 0.0091\n",
      "Epoch 51/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1081 - mae: 0.0066 - val_loss: 0.1076 - val_mae: 0.0095\n",
      "Epoch 52/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1069 - mae: 0.0070 - val_loss: 0.1064 - val_mae: 0.0095\n",
      "Epoch 53/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1059 - mae: 0.0088 - val_loss: 0.1054 - val_mae: 0.0093\n",
      "Epoch 54/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1047 - mae: 0.0077 - val_loss: 0.1042 - val_mae: 0.0093\n",
      "Epoch 55/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1036 - mae: 0.0073 - val_loss: 0.1030 - val_mae: 0.0062\n",
      "Epoch 56/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1025 - mae: 0.0079 - val_loss: 0.1023 - val_mae: 0.0164\n",
      "Epoch 57/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1015 - mae: 0.0085 - val_loss: 0.1010 - val_mae: 0.0103\n",
      "Epoch 58/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1004 - mae: 0.0083 - val_loss: 0.0998 - val_mae: 0.0063\n",
      "Epoch 59/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0994 - mae: 0.0117 - val_loss: 0.0990 - val_mae: 0.0125\n",
      "Epoch 60/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0984 - mae: 0.0126 - val_loss: 0.0978 - val_mae: 0.0112\n",
      "Epoch 61/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0972 - mae: 0.0085 - val_loss: 0.0967 - val_mae: 0.0077\n",
      "Epoch 62/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0962 - mae: 0.0085 - val_loss: 0.0957 - val_mae: 0.0083\n",
      "Epoch 63/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0951 - mae: 0.0077 - val_loss: 0.0947 - val_mae: 0.0100\n",
      "Epoch 64/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0941 - mae: 0.0060 - val_loss: 0.0936 - val_mae: 0.0066\n",
      "Epoch 65/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0932 - mae: 0.0097 - val_loss: 0.0927 - val_mae: 0.0092\n",
      "Epoch 66/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0922 - mae: 0.0093 - val_loss: 0.0916 - val_mae: 0.0087\n",
      "Epoch 67/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0913 - mae: 0.0117 - val_loss: 0.0908 - val_mae: 0.0109\n",
      "Epoch 68/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0901 - mae: 0.0067 - val_loss: 0.0897 - val_mae: 0.0092\n",
      "Epoch 69/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0892 - mae: 0.0075 - val_loss: 0.0887 - val_mae: 0.0061\n",
      "Epoch 70/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0886 - mae: 0.0148 - val_loss: 0.0880 - val_mae: 0.0141\n",
      "Epoch 71/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0881 - mae: 0.0234 - val_loss: 0.0896 - val_mae: 0.0425\n",
      "Epoch 72/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0877 - mae: 0.0288 - val_loss: 0.0863 - val_mae: 0.0181\n",
      "Epoch 73/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0869 - mae: 0.0299 - val_loss: 0.0963 - val_mae: 0.0875\n",
      "Epoch 74/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0915 - mae: 0.0601 - val_loss: 0.0862 - val_mae: 0.0382\n",
      "Epoch 75/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0858 - mae: 0.0373 - val_loss: 0.0917 - val_mae: 0.0749\n",
      "Epoch 76/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0851 - mae: 0.0348 - val_loss: 0.0828 - val_mae: 0.0190\n",
      "Epoch 77/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0822 - mae: 0.0169 - val_loss: 0.0817 - val_mae: 0.0158\n",
      "Epoch 78/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0810 - mae: 0.0100 - val_loss: 0.0806 - val_mae: 0.0100\n",
      "Epoch 79/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0801 - mae: 0.0076 - val_loss: 0.0796 - val_mae: 0.0069\n",
      "Epoch 80/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0793 - mae: 0.0093 - val_loss: 0.0804 - val_mae: 0.0316\n",
      "Epoch 81/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0787 - mae: 0.0152 - val_loss: 0.0779 - val_mae: 0.0077\n",
      "Epoch 82/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0777 - mae: 0.0147 - val_loss: 0.0784 - val_mae: 0.0300\n",
      "Epoch 83/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0768 - mae: 0.0140 - val_loss: 0.0763 - val_mae: 0.0099\n",
      "Epoch 84/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0757 - mae: 0.0074 - val_loss: 0.0753 - val_mae: 0.0058\n",
      "Epoch 85/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0749 - mae: 0.0068 - val_loss: 0.0746 - val_mae: 0.0096\n",
      "Epoch 86/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0741 - mae: 0.0095 - val_loss: 0.0738 - val_mae: 0.0119\n",
      "Epoch 87/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0734 - mae: 0.0125 - val_loss: 0.0736 - val_mae: 0.0216\n",
      "Epoch 88/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0726 - mae: 0.0122 - val_loss: 0.0720 - val_mae: 0.0084\n",
      "Epoch 89/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0717 - mae: 0.0108 - val_loss: 0.0717 - val_mae: 0.0181\n",
      "Epoch 90/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0731 - mae: 0.0337 - val_loss: 0.0792 - val_mae: 0.0636\n",
      "Epoch 91/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0751 - mae: 0.0536 - val_loss: 0.0710 - val_mae: 0.0284\n",
      "Epoch 92/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0702 - mae: 0.0229 - val_loss: 0.0692 - val_mae: 0.0151\n",
      "Epoch 93/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0686 - mae: 0.0113 - val_loss: 0.0684 - val_mae: 0.0131\n",
      "Epoch 94/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0679 - mae: 0.0120 - val_loss: 0.0676 - val_mae: 0.0166\n",
      "Epoch 95/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0669 - mae: 0.0083 - val_loss: 0.0665 - val_mae: 0.0052\n",
      "Epoch 96/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0661 - mae: 0.0068 - val_loss: 0.0658 - val_mae: 0.0075\n",
      "Epoch 97/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0654 - mae: 0.0076 - val_loss: 0.0654 - val_mae: 0.0166\n",
      "Epoch 98/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0647 - mae: 0.0109 - val_loss: 0.0643 - val_mae: 0.0100\n",
      "Epoch 99/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0639 - mae: 0.0089 - val_loss: 0.0637 - val_mae: 0.0133\n",
      "Epoch 100/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0635 - mae: 0.0151 - val_loss: 0.0652 - val_mae: 0.0365\n",
      "Epoch 101/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0641 - mae: 0.0293 - val_loss: 0.0635 - val_mae: 0.0303\n",
      "Epoch 102/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0633 - mae: 0.0306 - val_loss: 0.0659 - val_mae: 0.0509\n",
      "Epoch 103/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0619 - mae: 0.0242 - val_loss: 0.0607 - val_mae: 0.0102\n",
      "Epoch 104/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0604 - mae: 0.0122 - val_loss: 0.0599 - val_mae: 0.0081\n",
      "Epoch 105/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0595 - mae: 0.0078 - val_loss: 0.0591 - val_mae: 0.0059\n",
      "Epoch 106/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0587 - mae: 0.0051 - val_loss: 0.0585 - val_mae: 0.0072\n",
      "Epoch 107/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0580 - mae: 0.0056 - val_loss: 0.0577 - val_mae: 0.0051\n",
      "Epoch 108/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0575 - mae: 0.0105 - val_loss: 0.0572 - val_mae: 0.0112\n",
      "Epoch 109/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0567 - mae: 0.0078 - val_loss: 0.0566 - val_mae: 0.0152\n",
      "Epoch 110/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0561 - mae: 0.0100 - val_loss: 0.0571 - val_mae: 0.0292\n",
      "Epoch 111/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0561 - mae: 0.0209 - val_loss: 0.0554 - val_mae: 0.0154\n",
      "Epoch 112/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0547 - mae: 0.0095 - val_loss: 0.0543 - val_mae: 0.0068\n",
      "Epoch 113/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0541 - mae: 0.0110 - val_loss: 0.0538 - val_mae: 0.0137\n",
      "Epoch 114/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0533 - mae: 0.0077 - val_loss: 0.0530 - val_mae: 0.0055\n",
      "Epoch 115/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0526 - mae: 0.0082 - val_loss: 0.0526 - val_mae: 0.0173\n",
      "Epoch 116/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0521 - mae: 0.0103 - val_loss: 0.0519 - val_mae: 0.0130\n",
      "Epoch 117/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0516 - mae: 0.0141 - val_loss: 0.0512 - val_mae: 0.0110\n",
      "Epoch 118/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0509 - mae: 0.0136 - val_loss: 0.0505 - val_mae: 0.0131\n",
      "Epoch 119/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0501 - mae: 0.0084 - val_loss: 0.0498 - val_mae: 0.0078\n",
      "Epoch 120/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0495 - mae: 0.0100 - val_loss: 0.0492 - val_mae: 0.0117\n",
      "Epoch 121/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0490 - mae: 0.0121 - val_loss: 0.0495 - val_mae: 0.0265\n",
      "Epoch 122/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0483 - mae: 0.0104 - val_loss: 0.0479 - val_mae: 0.0100\n",
      "Epoch 123/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0476 - mae: 0.0105 - val_loss: 0.0474 - val_mae: 0.0123\n",
      "Epoch 124/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0469 - mae: 0.0084 - val_loss: 0.0466 - val_mae: 0.0099\n",
      "Epoch 125/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0465 - mae: 0.0118 - val_loss: 0.0492 - val_mae: 0.0465\n",
      "Epoch 126/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0469 - mae: 0.0267 - val_loss: 0.0462 - val_mae: 0.0212\n",
      "Epoch 127/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0458 - mae: 0.0207 - val_loss: 0.0451 - val_mae: 0.0142\n",
      "Epoch 128/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0446 - mae: 0.0081 - val_loss: 0.0443 - val_mae: 0.0091\n",
      "Epoch 129/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0439 - mae: 0.0079 - val_loss: 0.0436 - val_mae: 0.0061\n",
      "Epoch 130/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0434 - mae: 0.0086 - val_loss: 0.0435 - val_mae: 0.0173\n",
      "Epoch 131/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0429 - mae: 0.0116 - val_loss: 0.0427 - val_mae: 0.0133\n",
      "Epoch 132/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0423 - mae: 0.0100 - val_loss: 0.0420 - val_mae: 0.0093\n",
      "Epoch 133/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0420 - mae: 0.0151 - val_loss: 0.0415 - val_mae: 0.0108\n",
      "Epoch 134/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0410 - mae: 0.0073 - val_loss: 0.0408 - val_mae: 0.0059\n",
      "Epoch 135/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0406 - mae: 0.0095 - val_loss: 0.0402 - val_mae: 0.0056\n",
      "Epoch 136/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0407 - mae: 0.0200 - val_loss: 0.0398 - val_mae: 0.0128\n",
      "Epoch 137/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0396 - mae: 0.0126 - val_loss: 0.0392 - val_mae: 0.0071\n",
      "Epoch 138/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0390 - mae: 0.0105 - val_loss: 0.0387 - val_mae: 0.0104\n",
      "Epoch 139/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0385 - mae: 0.0135 - val_loss: 0.0382 - val_mae: 0.0098\n",
      "Epoch 140/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0380 - mae: 0.0111 - val_loss: 0.0375 - val_mae: 0.0074\n",
      "Epoch 141/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0373 - mae: 0.0093 - val_loss: 0.0371 - val_mae: 0.0117\n",
      "Epoch 142/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0369 - mae: 0.0114 - val_loss: 0.0376 - val_mae: 0.0292\n",
      "Epoch 143/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0366 - mae: 0.0162 - val_loss: 0.0360 - val_mae: 0.0078\n",
      "Epoch 144/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0358 - mae: 0.0087 - val_loss: 0.0355 - val_mae: 0.0076\n",
      "Epoch 145/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0357 - mae: 0.0163 - val_loss: 0.0397 - val_mae: 0.0531\n",
      "Epoch 146/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0403 - mae: 0.0508 - val_loss: 0.0631 - val_mae: 0.1123\n",
      "Epoch 147/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0416 - mae: 0.0656 - val_loss: 0.0417 - val_mae: 0.0711\n",
      "Epoch 148/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0381 - mae: 0.0442 - val_loss: 0.0384 - val_mae: 0.0541\n",
      "Epoch 149/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0346 - mae: 0.0260 - val_loss: 0.0334 - val_mae: 0.0132\n",
      "Epoch 150/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0333 - mae: 0.0150 - val_loss: 0.0328 - val_mae: 0.0105\n",
      "Epoch 151/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0325 - mae: 0.0100 - val_loss: 0.0326 - val_mae: 0.0166\n",
      "Epoch 152/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0322 - mae: 0.0121 - val_loss: 0.0320 - val_mae: 0.0139\n",
      "Epoch 153/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.0114 - val_loss: 0.0314 - val_mae: 0.0080\n",
      "Epoch 154/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.0082 - val_loss: 0.0311 - val_mae: 0.0139\n",
      "Epoch 155/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.0094 - val_loss: 0.0305 - val_mae: 0.0109\n",
      "Epoch 156/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.0129 - val_loss: 0.0302 - val_mae: 0.0133\n",
      "Epoch 157/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.0121 - val_loss: 0.0297 - val_mae: 0.0104\n",
      "Epoch 158/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.0080 - val_loss: 0.0292 - val_mae: 0.0098\n",
      "Epoch 159/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0290 - mae: 0.0092 - val_loss: 0.0288 - val_mae: 0.0094\n",
      "Epoch 160/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.0120 - val_loss: 0.0285 - val_mae: 0.0105\n",
      "Epoch 161/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.0114 - val_loss: 0.0282 - val_mae: 0.0146\n",
      "Epoch 162/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0278 - mae: 0.0115 - val_loss: 0.0280 - val_mae: 0.0195\n",
      "Epoch 163/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0274 - mae: 0.0094 - val_loss: 0.0273 - val_mae: 0.0139\n",
      "Epoch 164/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.0130 - val_loss: 0.0270 - val_mae: 0.0115\n",
      "Epoch 165/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.0211 - val_loss: 0.0266 - val_mae: 0.0147\n",
      "Epoch 166/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0262 - mae: 0.0105 - val_loss: 0.0260 - val_mae: 0.0107\n",
      "Epoch 167/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0257 - mae: 0.0070 - val_loss: 0.0256 - val_mae: 0.0092\n",
      "Epoch 168/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0254 - mae: 0.0079 - val_loss: 0.0252 - val_mae: 0.0081\n",
      "Epoch 169/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0250 - mae: 0.0093 - val_loss: 0.0250 - val_mae: 0.0140\n",
      "Epoch 170/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0248 - mae: 0.0125 - val_loss: 0.0249 - val_mae: 0.0210\n",
      "Epoch 171/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0243 - mae: 0.0114 - val_loss: 0.0242 - val_mae: 0.0122\n",
      "Epoch 172/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0243 - mae: 0.0171 - val_loss: 0.0240 - val_mae: 0.0166\n",
      "Epoch 173/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0236 - mae: 0.0100 - val_loss: 0.0234 - val_mae: 0.0108\n",
      "Epoch 174/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0231 - mae: 0.0073 - val_loss: 0.0230 - val_mae: 0.0080\n",
      "Epoch 175/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0228 - mae: 0.0094 - val_loss: 0.0229 - val_mae: 0.0145\n",
      "Epoch 176/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0225 - mae: 0.0087 - val_loss: 0.0226 - val_mae: 0.0158\n",
      "Epoch 177/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0222 - mae: 0.0092 - val_loss: 0.0219 - val_mae: 0.0082\n",
      "Epoch 178/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0218 - mae: 0.0074 - val_loss: 0.0217 - val_mae: 0.0091\n",
      "Epoch 179/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0215 - mae: 0.0106 - val_loss: 0.0214 - val_mae: 0.0112\n",
      "Epoch 180/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0212 - mae: 0.0102 - val_loss: 0.0212 - val_mae: 0.0136\n",
      "Epoch 181/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0209 - mae: 0.0121 - val_loss: 0.0214 - val_mae: 0.0245\n",
      "Epoch 182/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0206 - mae: 0.0135 - val_loss: 0.0203 - val_mae: 0.0078\n",
      "Epoch 183/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0202 - mae: 0.0100 - val_loss: 0.0204 - val_mae: 0.0161\n",
      "Epoch 184/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0201 - mae: 0.0143 - val_loss: 0.0199 - val_mae: 0.0159\n",
      "Epoch 185/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0196 - mae: 0.0114 - val_loss: 0.0196 - val_mae: 0.0143\n",
      "Epoch 186/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0194 - mae: 0.0137 - val_loss: 0.0195 - val_mae: 0.0192\n",
      "Epoch 187/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0192 - mae: 0.0160 - val_loss: 0.0193 - val_mae: 0.0215\n",
      "Epoch 188/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0188 - mae: 0.0139 - val_loss: 0.0190 - val_mae: 0.0195\n",
      "Epoch 189/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0186 - mae: 0.0152 - val_loss: 0.0186 - val_mae: 0.0183\n",
      "Epoch 190/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0182 - mae: 0.0141 - val_loss: 0.0180 - val_mae: 0.0125\n",
      "Epoch 191/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0180 - mae: 0.0136 - val_loss: 0.0176 - val_mae: 0.0071\n",
      "Epoch 192/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0147 - val_loss: 0.0175 - val_mae: 0.0145\n",
      "Epoch 193/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0169 - val_loss: 0.0174 - val_mae: 0.0154\n",
      "Epoch 194/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0123 - val_loss: 0.0168 - val_mae: 0.0071\n",
      "Epoch 195/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0071 - val_loss: 0.0165 - val_mae: 0.0082\n",
      "Epoch 196/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0068 - val_loss: 0.0162 - val_mae: 0.0069\n",
      "Epoch 197/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0060 - val_loss: 0.0161 - val_mae: 0.0115\n",
      "Epoch 198/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0114 - val_loss: 0.0162 - val_mae: 0.0190\n",
      "Epoch 199/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0089 - val_loss: 0.0156 - val_mae: 0.0111\n",
      "Epoch 200/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0155 - mae: 0.0126 - val_loss: 0.0167 - val_mae: 0.0340\n",
      "Epoch 201/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0221 - val_loss: 0.0151 - val_mae: 0.0104\n",
      "Epoch 202/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0149 - mae: 0.0107 - val_loss: 0.0150 - val_mae: 0.0136\n",
      "Epoch 203/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0146 - mae: 0.0097 - val_loss: 0.0146 - val_mae: 0.0120\n",
      "Epoch 204/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0148 - mae: 0.0183 - val_loss: 0.0147 - val_mae: 0.0211\n",
      "Epoch 205/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0146 - mae: 0.0180 - val_loss: 0.0158 - val_mae: 0.0351\n",
      "Epoch 206/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0146 - mae: 0.0216 - val_loss: 0.0139 - val_mae: 0.0091\n",
      "Epoch 207/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - mae: 0.0074 - val_loss: 0.0136 - val_mae: 0.0120\n",
      "Epoch 208/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - mae: 0.0069 - val_loss: 0.0135 - val_mae: 0.0123\n",
      "Epoch 209/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - mae: 0.0117 - val_loss: 0.0139 - val_mae: 0.0222\n",
      "Epoch 210/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - mae: 0.0091 - val_loss: 0.0133 - val_mae: 0.0183\n",
      "Epoch 211/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - mae: 0.0188 - val_loss: 0.0130 - val_mae: 0.0163\n",
      "Epoch 212/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0190 - val_loss: 0.0136 - val_mae: 0.0295\n",
      "Epoch 213/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0181 - val_loss: 0.0130 - val_mae: 0.0258\n",
      "Epoch 214/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0245 - val_loss: 0.0152 - val_mae: 0.0420\n",
      "Epoch 215/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0141 - mae: 0.0337 - val_loss: 0.0136 - val_mae: 0.0284\n",
      "Epoch 216/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0171 - val_loss: 0.0119 - val_mae: 0.0111\n",
      "Epoch 217/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0117 - mae: 0.0075 - val_loss: 0.0115 - val_mae: 0.0053\n",
      "Epoch 218/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0115 - mae: 0.0067 - val_loss: 0.0116 - val_mae: 0.0126\n",
      "Epoch 219/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0113 - mae: 0.0091 - val_loss: 0.0113 - val_mae: 0.0117\n",
      "Epoch 220/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - mae: 0.0083 - val_loss: 0.0110 - val_mae: 0.0062\n",
      "Epoch 221/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0109 - mae: 0.0082 - val_loss: 0.0108 - val_mae: 0.0079\n",
      "Epoch 222/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0108 - mae: 0.0072 - val_loss: 0.0107 - val_mae: 0.0087\n",
      "Epoch 223/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0106 - mae: 0.0087 - val_loss: 0.0105 - val_mae: 0.0068\n",
      "Epoch 224/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0104 - mae: 0.0075 - val_loss: 0.0105 - val_mae: 0.0130\n",
      "Epoch 225/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0103 - mae: 0.0099 - val_loss: 0.0102 - val_mae: 0.0084\n",
      "Epoch 226/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0101 - mae: 0.0100 - val_loss: 0.0101 - val_mae: 0.0120\n",
      "Epoch 227/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0103 - mae: 0.0162 - val_loss: 0.0104 - val_mae: 0.0179\n",
      "Epoch 228/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0106 - mae: 0.0245 - val_loss: 0.0103 - val_mae: 0.0214\n",
      "Epoch 229/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0113 - mae: 0.0319 - val_loss: 0.0104 - val_mae: 0.0257\n",
      "Epoch 230/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0106 - mae: 0.0266 - val_loss: 0.0101 - val_mae: 0.0213\n",
      "Epoch 231/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0100 - mae: 0.0207 - val_loss: 0.0099 - val_mae: 0.0234\n",
      "Epoch 232/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0176 - val_loss: 0.0098 - val_mae: 0.0217\n",
      "Epoch 233/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0136 - val_loss: 0.0091 - val_mae: 0.0118\n",
      "Epoch 234/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0095 - mae: 0.0181 - val_loss: 0.0089 - val_mae: 0.0091\n",
      "Epoch 235/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0137 - val_loss: 0.0088 - val_mae: 0.0100\n",
      "Epoch 236/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0086 - val_loss: 0.0086 - val_mae: 0.0072\n",
      "Epoch 237/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0067 - val_loss: 0.0085 - val_mae: 0.0076\n",
      "Epoch 238/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0087 - val_mae: 0.0167\n",
      "Epoch 239/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0125 - val_loss: 0.0082 - val_mae: 0.0099\n",
      "Epoch 240/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0092 - val_loss: 0.0081 - val_mae: 0.0063\n",
      "Epoch 241/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0081 - val_loss: 0.0085 - val_mae: 0.0179\n",
      "Epoch 242/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0108 - val_loss: 0.0079 - val_mae: 0.0092\n",
      "Epoch 243/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0069 - val_loss: 0.0079 - val_mae: 0.0138\n",
      "Epoch 244/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0129 - val_loss: 0.0105 - val_mae: 0.0425\n",
      "Epoch 245/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0261 - val_loss: 0.0088 - val_mae: 0.0280\n",
      "Epoch 246/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0196 - val_loss: 0.0082 - val_mae: 0.0265\n",
      "Epoch 247/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0157 - val_loss: 0.0074 - val_mae: 0.0131\n",
      "Epoch 248/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - mae: 0.0094 - val_loss: 0.0073 - val_mae: 0.0106\n",
      "Epoch 249/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - mae: 0.0136 - val_loss: 0.0075 - val_mae: 0.0185\n",
      "Epoch 250/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - mae: 0.0143 - val_loss: 0.0070 - val_mae: 0.0073\n",
      "Epoch 251/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - mae: 0.0056 - val_loss: 0.0069 - val_mae: 0.0082\n",
      "Epoch 252/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - mae: 0.0057 - val_loss: 0.0068 - val_mae: 0.0072\n",
      "Epoch 253/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - mae: 0.0052 - val_loss: 0.0066 - val_mae: 0.0051\n",
      "Epoch 254/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - mae: 0.0054 - val_loss: 0.0065 - val_mae: 0.0062\n",
      "Epoch 255/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0065 - mae: 0.0072 - val_loss: 0.0065 - val_mae: 0.0110\n",
      "Epoch 256/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0267 - val_loss: 0.0066 - val_mae: 0.0147\n",
      "Epoch 257/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - mae: 0.0226 - val_loss: 0.0070 - val_mae: 0.0187\n",
      "Epoch 258/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0065 - mae: 0.0137 - val_loss: 0.0063 - val_mae: 0.0117\n",
      "Epoch 259/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0065 - mae: 0.0155 - val_loss: 0.0065 - val_mae: 0.0161\n",
      "Epoch 260/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0063 - mae: 0.0136 - val_loss: 0.0062 - val_mae: 0.0108\n",
      "Epoch 261/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0061 - mae: 0.0098 - val_loss: 0.0060 - val_mae: 0.0099\n",
      "Epoch 262/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0060 - mae: 0.0100 - val_loss: 0.0059 - val_mae: 0.0068\n",
      "Epoch 263/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0059 - mae: 0.0098 - val_loss: 0.0061 - val_mae: 0.0158\n",
      "Epoch 264/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0059 - mae: 0.0115 - val_loss: 0.0061 - val_mae: 0.0146\n",
      "Epoch 265/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0059 - mae: 0.0130 - val_loss: 0.0057 - val_mae: 0.0098\n",
      "Epoch 266/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0057 - mae: 0.0098 - val_loss: 0.0062 - val_mae: 0.0241\n",
      "Epoch 267/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0058 - mae: 0.0162 - val_loss: 0.0056 - val_mae: 0.0103\n",
      "Epoch 268/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0055 - mae: 0.0088 - val_loss: 0.0055 - val_mae: 0.0108\n",
      "Epoch 269/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0054 - mae: 0.0078 - val_loss: 0.0054 - val_mae: 0.0102\n",
      "Epoch 270/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0053 - mae: 0.0057 - val_loss: 0.0052 - val_mae: 0.0041\n",
      "Epoch 271/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0054 - mae: 0.0116 - val_loss: 0.0053 - val_mae: 0.0100\n",
      "Epoch 272/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0052 - mae: 0.0085 - val_loss: 0.0052 - val_mae: 0.0087\n",
      "Epoch 273/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0053 - mae: 0.0130 - val_loss: 0.0051 - val_mae: 0.0067\n",
      "Epoch 274/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0050 - mae: 0.0057 - val_loss: 0.0050 - val_mae: 0.0066\n",
      "Epoch 275/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0085 - val_loss: 0.0053 - val_mae: 0.0150\n",
      "Epoch 276/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0110 - val_loss: 0.0049 - val_mae: 0.0095\n",
      "Epoch 277/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0085 - val_loss: 0.0048 - val_mae: 0.0067\n",
      "Epoch 278/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0047 - mae: 0.0062 - val_loss: 0.0049 - val_mae: 0.0160\n",
      "Epoch 279/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0048 - mae: 0.0097 - val_loss: 0.0046 - val_mae: 0.0053\n",
      "Epoch 280/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - mae: 0.0064 - val_loss: 0.0047 - val_mae: 0.0102\n",
      "Epoch 281/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - mae: 0.0079 - val_loss: 0.0045 - val_mae: 0.0070\n",
      "Epoch 282/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0046 - mae: 0.0090 - val_loss: 0.0045 - val_mae: 0.0094\n",
      "Epoch 283/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0053 - mae: 0.0214 - val_loss: 0.0114 - val_mae: 0.0669\n",
      "Epoch 284/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - mae: 0.0455 - val_loss: 0.0071 - val_mae: 0.0426\n",
      "Epoch 285/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0054 - mae: 0.0250 - val_loss: 0.0048 - val_mae: 0.0181\n",
      "Epoch 286/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0045 - mae: 0.0113 - val_loss: 0.0045 - val_mae: 0.0143\n",
      "Epoch 287/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0047 - mae: 0.0170 - val_loss: 0.0045 - val_mae: 0.0132\n",
      "Epoch 288/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0044 - mae: 0.0108 - val_loss: 0.0044 - val_mae: 0.0123\n",
      "Epoch 289/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0062 - val_loss: 0.0043 - val_mae: 0.0103\n",
      "Epoch 290/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0097 - val_loss: 0.0044 - val_mae: 0.0164\n",
      "Epoch 291/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0103 - val_loss: 0.0041 - val_mae: 0.0076\n",
      "Epoch 292/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0084 - val_loss: 0.0042 - val_mae: 0.0146\n",
      "Epoch 293/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0116 - val_loss: 0.0041 - val_mae: 0.0131\n",
      "Epoch 294/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0112 - val_loss: 0.0041 - val_mae: 0.0119\n",
      "Epoch 295/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0075 - val_loss: 0.0039 - val_mae: 0.0057\n",
      "Epoch 296/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0062 - val_loss: 0.0039 - val_mae: 0.0100\n",
      "Epoch 297/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0068 - val_loss: 0.0039 - val_mae: 0.0106\n",
      "Epoch 298/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0084 - val_loss: 0.0037 - val_mae: 0.0055\n",
      "Epoch 299/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0069 - val_loss: 0.0039 - val_mae: 0.0126\n",
      "Epoch 300/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0177 - val_loss: 0.0041 - val_mae: 0.0196\n",
      "Epoch 301/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0182 - val_loss: 0.0044 - val_mae: 0.0249\n",
      "Epoch 302/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0042 - mae: 0.0193 - val_loss: 0.0040 - val_mae: 0.0170\n",
      "Epoch 303/1000\n",
      "23/28 [=======================>......] - ETA: 0s - loss: 0.0040 - mae: 0.0162Restoring model weights from the end of the best epoch: 298.\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0040 - mae: 0.0170 - val_loss: 0.0042 - val_mae: 0.0215\n",
      "Epoch 303: early stopping\n",
      "Training für Fold 4...\n",
      "Epoch 1/1000\n",
      "28/28 [==============================] - 1s 9ms/step - loss: 0.5111 - mae: 0.3735 - val_loss: 0.4516 - val_mae: 0.3428\n",
      "Epoch 2/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3966 - mae: 0.3154 - val_loss: 0.3425 - val_mae: 0.2731\n",
      "Epoch 3/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3236 - mae: 0.2613 - val_loss: 0.3203 - val_mae: 0.2884\n",
      "Epoch 4/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2869 - mae: 0.2403 - val_loss: 0.2650 - val_mae: 0.2099\n",
      "Epoch 5/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2316 - mae: 0.1626 - val_loss: 0.2280 - val_mae: 0.1612\n",
      "Epoch 6/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2152 - mae: 0.1440 - val_loss: 0.1896 - val_mae: 0.0821\n",
      "Epoch 7/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1882 - mae: 0.0807 - val_loss: 0.2111 - val_mae: 0.1504\n",
      "Epoch 8/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1821 - mae: 0.0732 - val_loss: 0.1695 - val_mae: 0.0331\n",
      "Epoch 9/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1682 - mae: 0.0325 - val_loss: 0.1663 - val_mae: 0.0279\n",
      "Epoch 10/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1640 - mae: 0.0182 - val_loss: 0.1622 - val_mae: 0.0144\n",
      "Epoch 11/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1613 - mae: 0.0182 - val_loss: 0.1596 - val_mae: 0.0134\n",
      "Epoch 12/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1593 - mae: 0.0219 - val_loss: 0.1590 - val_mae: 0.0307\n",
      "Epoch 13/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1565 - mae: 0.0193 - val_loss: 0.1571 - val_mae: 0.0369\n",
      "Epoch 14/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1568 - mae: 0.0378 - val_loss: 0.1532 - val_mae: 0.0222\n",
      "Epoch 15/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1541 - mae: 0.0356 - val_loss: 0.1509 - val_mae: 0.0217\n",
      "Epoch 16/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1506 - mae: 0.0263 - val_loss: 0.1497 - val_mae: 0.0316\n",
      "Epoch 17/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1484 - mae: 0.0265 - val_loss: 0.1471 - val_mae: 0.0234\n",
      "Epoch 18/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1457 - mae: 0.0189 - val_loss: 0.1448 - val_mae: 0.0230\n",
      "Epoch 19/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1437 - mae: 0.0166 - val_loss: 0.1435 - val_mae: 0.0274\n",
      "Epoch 20/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1417 - mae: 0.0147 - val_loss: 0.1405 - val_mae: 0.0107\n",
      "Epoch 21/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1396 - mae: 0.0083 - val_loss: 0.1387 - val_mae: 0.0108\n",
      "Epoch 22/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1380 - mae: 0.0114 - val_loss: 0.1369 - val_mae: 0.0082\n",
      "Epoch 23/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1373 - mae: 0.0238 - val_loss: 0.1371 - val_mae: 0.0341\n",
      "Epoch 24/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1390 - mae: 0.0451 - val_loss: 0.1359 - val_mae: 0.0376\n",
      "Epoch 25/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1337 - mae: 0.0254 - val_loss: 0.1322 - val_mae: 0.0171\n",
      "Epoch 26/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1316 - mae: 0.0179 - val_loss: 0.1304 - val_mae: 0.0115\n",
      "Epoch 27/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1297 - mae: 0.0122 - val_loss: 0.1286 - val_mae: 0.0080\n",
      "Epoch 28/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1279 - mae: 0.0074 - val_loss: 0.1271 - val_mae: 0.0094\n",
      "Epoch 29/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1266 - mae: 0.0122 - val_loss: 0.1260 - val_mae: 0.0165\n",
      "Epoch 30/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1255 - mae: 0.0189 - val_loss: 0.1241 - val_mae: 0.0083\n",
      "Epoch 31/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1236 - mae: 0.0123 - val_loss: 0.1227 - val_mae: 0.0086\n",
      "Epoch 32/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1224 - mae: 0.0179 - val_loss: 0.1219 - val_mae: 0.0226\n",
      "Epoch 33/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1213 - mae: 0.0212 - val_loss: 0.1205 - val_mae: 0.0223\n",
      "Epoch 34/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1194 - mae: 0.0144 - val_loss: 0.1185 - val_mae: 0.0117\n",
      "Epoch 35/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1179 - mae: 0.0108 - val_loss: 0.1170 - val_mae: 0.0062\n",
      "Epoch 36/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1164 - mae: 0.0093 - val_loss: 0.1159 - val_mae: 0.0126\n",
      "Epoch 37/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1152 - mae: 0.0111 - val_loss: 0.1144 - val_mae: 0.0076\n",
      "Epoch 38/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1139 - mae: 0.0101 - val_loss: 0.1133 - val_mae: 0.0139\n",
      "Epoch 39/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1131 - mae: 0.0173 - val_loss: 0.1128 - val_mae: 0.0263\n",
      "Epoch 40/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1116 - mae: 0.0158 - val_loss: 0.1115 - val_mae: 0.0222\n",
      "Epoch 41/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1175 - mae: 0.0570 - val_loss: 0.1122 - val_mae: 0.0357\n",
      "Epoch 42/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1103 - mae: 0.0313 - val_loss: 0.1090 - val_mae: 0.0254\n",
      "Epoch 43/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1081 - mae: 0.0192 - val_loss: 0.1070 - val_mae: 0.0106\n",
      "Epoch 44/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1065 - mae: 0.0122 - val_loss: 0.1057 - val_mae: 0.0078\n",
      "Epoch 45/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1052 - mae: 0.0100 - val_loss: 0.1047 - val_mae: 0.0119\n",
      "Epoch 46/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1040 - mae: 0.0085 - val_loss: 0.1034 - val_mae: 0.0083\n",
      "Epoch 47/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1032 - mae: 0.0146 - val_loss: 0.1024 - val_mae: 0.0126\n",
      "Epoch 48/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1024 - mae: 0.0179 - val_loss: 0.1019 - val_mae: 0.0190\n",
      "Epoch 49/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1024 - mae: 0.0266 - val_loss: 0.1000 - val_mae: 0.0092\n",
      "Epoch 50/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0996 - mae: 0.0094 - val_loss: 0.0991 - val_mae: 0.0130\n",
      "Epoch 51/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0986 - mae: 0.0130 - val_loss: 0.0984 - val_mae: 0.0194\n",
      "Epoch 52/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0976 - mae: 0.0129 - val_loss: 0.0967 - val_mae: 0.0049\n",
      "Epoch 53/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0963 - mae: 0.0091 - val_loss: 0.0959 - val_mae: 0.0113\n",
      "Epoch 54/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0953 - mae: 0.0090 - val_loss: 0.0947 - val_mae: 0.0078\n",
      "Epoch 55/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0942 - mae: 0.0066 - val_loss: 0.0937 - val_mae: 0.0082\n",
      "Epoch 56/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0934 - mae: 0.0112 - val_loss: 0.0942 - val_mae: 0.0310\n",
      "Epoch 57/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0928 - mae: 0.0186 - val_loss: 0.0917 - val_mae: 0.0098\n",
      "Epoch 58/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0913 - mae: 0.0099 - val_loss: 0.0906 - val_mae: 0.0053\n",
      "Epoch 59/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0902 - mae: 0.0074 - val_loss: 0.0898 - val_mae: 0.0128\n",
      "Epoch 60/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0892 - mae: 0.0079 - val_loss: 0.0888 - val_mae: 0.0105\n",
      "Epoch 61/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0883 - mae: 0.0090 - val_loss: 0.0879 - val_mae: 0.0127\n",
      "Epoch 62/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0873 - mae: 0.0082 - val_loss: 0.0867 - val_mae: 0.0053\n",
      "Epoch 63/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0864 - mae: 0.0083 - val_loss: 0.0862 - val_mae: 0.0149\n",
      "Epoch 64/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0863 - mae: 0.0230 - val_loss: 0.0853 - val_mae: 0.0194\n",
      "Epoch 65/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0851 - mae: 0.0201 - val_loss: 0.0844 - val_mae: 0.0193\n",
      "Epoch 66/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0861 - mae: 0.0377 - val_loss: 0.0840 - val_mae: 0.0260\n",
      "Epoch 67/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0833 - mae: 0.0194 - val_loss: 0.0822 - val_mae: 0.0100\n",
      "Epoch 68/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0818 - mae: 0.0088 - val_loss: 0.0813 - val_mae: 0.0073\n",
      "Epoch 69/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0809 - mae: 0.0060 - val_loss: 0.0804 - val_mae: 0.0058\n",
      "Epoch 70/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0800 - mae: 0.0059 - val_loss: 0.0798 - val_mae: 0.0136\n",
      "Epoch 71/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0792 - mae: 0.0093 - val_loss: 0.0788 - val_mae: 0.0114\n",
      "Epoch 72/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0783 - mae: 0.0094 - val_loss: 0.0778 - val_mae: 0.0059\n",
      "Epoch 73/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0774 - mae: 0.0071 - val_loss: 0.0769 - val_mae: 0.0078\n",
      "Epoch 74/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0765 - mae: 0.0076 - val_loss: 0.0766 - val_mae: 0.0192\n",
      "Epoch 75/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0758 - mae: 0.0112 - val_loss: 0.0754 - val_mae: 0.0129\n",
      "Epoch 76/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0751 - mae: 0.0129 - val_loss: 0.0744 - val_mae: 0.0063\n",
      "Epoch 77/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0743 - mae: 0.0132 - val_loss: 0.0740 - val_mae: 0.0184\n",
      "Epoch 78/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0733 - mae: 0.0104 - val_loss: 0.0728 - val_mae: 0.0088\n",
      "Epoch 79/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0726 - mae: 0.0121 - val_loss: 0.0722 - val_mae: 0.0144\n",
      "Epoch 80/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0723 - mae: 0.0197 - val_loss: 0.0711 - val_mae: 0.0074\n",
      "Epoch 81/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0711 - mae: 0.0151 - val_loss: 0.0704 - val_mae: 0.0091\n",
      "Epoch 82/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0703 - mae: 0.0151 - val_loss: 0.0701 - val_mae: 0.0203\n",
      "Epoch 83/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0701 - mae: 0.0222 - val_loss: 0.0703 - val_mae: 0.0279\n",
      "Epoch 84/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0694 - mae: 0.0237 - val_loss: 0.0682 - val_mae: 0.0113\n",
      "Epoch 85/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0679 - mae: 0.0140 - val_loss: 0.0672 - val_mae: 0.0073\n",
      "Epoch 86/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0677 - mae: 0.0182 - val_loss: 0.0684 - val_mae: 0.0347\n",
      "Epoch 87/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0667 - mae: 0.0191 - val_loss: 0.0660 - val_mae: 0.0152\n",
      "Epoch 88/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0655 - mae: 0.0113 - val_loss: 0.0651 - val_mae: 0.0093\n",
      "Epoch 89/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0647 - mae: 0.0079 - val_loss: 0.0643 - val_mae: 0.0089\n",
      "Epoch 90/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0642 - mae: 0.0145 - val_loss: 0.0638 - val_mae: 0.0149\n",
      "Epoch 91/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0636 - mae: 0.0168 - val_loss: 0.0628 - val_mae: 0.0068\n",
      "Epoch 92/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0629 - mae: 0.0156 - val_loss: 0.0636 - val_mae: 0.0323\n",
      "Epoch 93/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0623 - mae: 0.0183 - val_loss: 0.0613 - val_mae: 0.0069\n",
      "Epoch 94/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0612 - mae: 0.0125 - val_loss: 0.0606 - val_mae: 0.0081\n",
      "Epoch 95/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0605 - mae: 0.0128 - val_loss: 0.0602 - val_mae: 0.0175\n",
      "Epoch 96/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0597 - mae: 0.0120 - val_loss: 0.0592 - val_mae: 0.0085\n",
      "Epoch 97/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0589 - mae: 0.0092 - val_loss: 0.0586 - val_mae: 0.0097\n",
      "Epoch 98/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0587 - mae: 0.0167 - val_loss: 0.0584 - val_mae: 0.0210\n",
      "Epoch 99/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0579 - mae: 0.0165 - val_loss: 0.0591 - val_mae: 0.0322\n",
      "Epoch 100/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0585 - mae: 0.0281 - val_loss: 0.0599 - val_mae: 0.0434\n",
      "Epoch 101/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0590 - mae: 0.0381 - val_loss: 0.0584 - val_mae: 0.0388\n",
      "Epoch 102/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0565 - mae: 0.0243 - val_loss: 0.0555 - val_mae: 0.0155\n",
      "Epoch 103/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0560 - mae: 0.0245 - val_loss: 0.0547 - val_mae: 0.0119\n",
      "Epoch 104/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0545 - mae: 0.0131 - val_loss: 0.0539 - val_mae: 0.0085\n",
      "Epoch 105/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0537 - mae: 0.0116 - val_loss: 0.0534 - val_mae: 0.0118\n",
      "Epoch 106/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0531 - mae: 0.0118 - val_loss: 0.0525 - val_mae: 0.0043\n",
      "Epoch 107/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0523 - mae: 0.0070 - val_loss: 0.0522 - val_mae: 0.0153\n",
      "Epoch 108/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0519 - mae: 0.0134 - val_loss: 0.0518 - val_mae: 0.0210\n",
      "Epoch 109/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0512 - mae: 0.0134 - val_loss: 0.0506 - val_mae: 0.0042\n",
      "Epoch 110/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0506 - mae: 0.0132 - val_loss: 0.0504 - val_mae: 0.0165\n",
      "Epoch 111/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0500 - mae: 0.0136 - val_loss: 0.0501 - val_mae: 0.0220\n",
      "Epoch 112/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0495 - mae: 0.0155 - val_loss: 0.0489 - val_mae: 0.0118\n",
      "Epoch 113/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0488 - mae: 0.0130 - val_loss: 0.0485 - val_mae: 0.0152\n",
      "Epoch 114/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0482 - mae: 0.0131 - val_loss: 0.0481 - val_mae: 0.0194\n",
      "Epoch 115/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0476 - mae: 0.0138 - val_loss: 0.0471 - val_mae: 0.0080\n",
      "Epoch 116/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0469 - mae: 0.0105 - val_loss: 0.0465 - val_mae: 0.0071\n",
      "Epoch 117/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0464 - mae: 0.0113 - val_loss: 0.0470 - val_mae: 0.0290\n",
      "Epoch 118/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0463 - mae: 0.0188 - val_loss: 0.0457 - val_mae: 0.0149\n",
      "Epoch 119/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0453 - mae: 0.0138 - val_loss: 0.0448 - val_mae: 0.0092\n",
      "Epoch 120/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0448 - mae: 0.0139 - val_loss: 0.0442 - val_mae: 0.0093\n",
      "Epoch 121/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0440 - mae: 0.0100 - val_loss: 0.0436 - val_mae: 0.0084\n",
      "Epoch 122/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0434 - mae: 0.0079 - val_loss: 0.0430 - val_mae: 0.0070\n",
      "Epoch 123/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0429 - mae: 0.0095 - val_loss: 0.0425 - val_mae: 0.0092\n",
      "Epoch 124/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0423 - mae: 0.0085 - val_loss: 0.0423 - val_mae: 0.0162\n",
      "Epoch 125/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0419 - mae: 0.0137 - val_loss: 0.0415 - val_mae: 0.0106\n",
      "Epoch 126/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0413 - mae: 0.0106 - val_loss: 0.0412 - val_mae: 0.0175\n",
      "Epoch 127/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0410 - mae: 0.0152 - val_loss: 0.0409 - val_mae: 0.0220\n",
      "Epoch 128/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0404 - mae: 0.0141 - val_loss: 0.0400 - val_mae: 0.0130\n",
      "Epoch 129/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0402 - mae: 0.0205 - val_loss: 0.0395 - val_mae: 0.0125\n",
      "Epoch 130/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0392 - mae: 0.0121 - val_loss: 0.0387 - val_mae: 0.0062\n",
      "Epoch 131/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0386 - mae: 0.0090 - val_loss: 0.0382 - val_mae: 0.0066\n",
      "Epoch 132/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0381 - mae: 0.0109 - val_loss: 0.0388 - val_mae: 0.0241\n",
      "Epoch 133/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0401 - mae: 0.0354 - val_loss: 0.0427 - val_mae: 0.0588\n",
      "Epoch 134/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0399 - mae: 0.0429 - val_loss: 0.0372 - val_mae: 0.0178\n",
      "Epoch 135/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0372 - mae: 0.0212 - val_loss: 0.0363 - val_mae: 0.0072\n",
      "Epoch 136/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0361 - mae: 0.0094 - val_loss: 0.0358 - val_mae: 0.0076\n",
      "Epoch 137/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0356 - mae: 0.0084 - val_loss: 0.0353 - val_mae: 0.0093\n",
      "Epoch 138/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0353 - mae: 0.0142 - val_loss: 0.0349 - val_mae: 0.0114\n",
      "Epoch 139/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0346 - mae: 0.0090 - val_loss: 0.0345 - val_mae: 0.0107\n",
      "Epoch 140/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0347 - mae: 0.0188 - val_loss: 0.0342 - val_mae: 0.0151\n",
      "Epoch 141/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0340 - mae: 0.0162 - val_loss: 0.0336 - val_mae: 0.0129\n",
      "Epoch 142/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0333 - mae: 0.0104 - val_loss: 0.0332 - val_mae: 0.0137\n",
      "Epoch 143/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0328 - mae: 0.0102 - val_loss: 0.0325 - val_mae: 0.0077\n",
      "Epoch 144/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0324 - mae: 0.0103 - val_loss: 0.0324 - val_mae: 0.0166\n",
      "Epoch 145/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0322 - mae: 0.0178 - val_loss: 0.0317 - val_mae: 0.0099\n",
      "Epoch 146/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0315 - mae: 0.0113 - val_loss: 0.0313 - val_mae: 0.0135\n",
      "Epoch 147/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0310 - mae: 0.0084 - val_loss: 0.0308 - val_mae: 0.0098\n",
      "Epoch 148/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0306 - mae: 0.0081 - val_loss: 0.0303 - val_mae: 0.0067\n",
      "Epoch 149/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0302 - mae: 0.0099 - val_loss: 0.0299 - val_mae: 0.0093\n",
      "Epoch 150/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.0116 - val_loss: 0.0297 - val_mae: 0.0121\n",
      "Epoch 151/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0293 - mae: 0.0088 - val_loss: 0.0290 - val_mae: 0.0049\n",
      "Epoch 152/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.0069 - val_loss: 0.0285 - val_mae: 0.0046\n",
      "Epoch 153/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0284 - mae: 0.0068 - val_loss: 0.0281 - val_mae: 0.0059\n",
      "Epoch 154/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.0107 - val_loss: 0.0279 - val_mae: 0.0119\n",
      "Epoch 155/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.0104 - val_loss: 0.0273 - val_mae: 0.0051\n",
      "Epoch 156/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.0113 - val_loss: 0.0275 - val_mae: 0.0196\n",
      "Epoch 157/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.0395 - val_loss: 0.0328 - val_mae: 0.0579\n",
      "Epoch 158/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0286 - mae: 0.0357 - val_loss: 0.0288 - val_mae: 0.0425\n",
      "Epoch 159/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.0268 - val_loss: 0.0275 - val_mae: 0.0276\n",
      "Epoch 160/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.0189 - val_loss: 0.0264 - val_mae: 0.0291\n",
      "Epoch 161/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0259 - mae: 0.0197 - val_loss: 0.0252 - val_mae: 0.0105\n",
      "Epoch 162/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0253 - mae: 0.0151 - val_loss: 0.0265 - val_mae: 0.0328\n",
      "Epoch 163/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0251 - mae: 0.0178 - val_loss: 0.0245 - val_mae: 0.0119\n",
      "Epoch 164/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0243 - mae: 0.0096 - val_loss: 0.0241 - val_mae: 0.0074\n",
      "Epoch 165/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0239 - mae: 0.0070 - val_loss: 0.0237 - val_mae: 0.0092\n",
      "Epoch 166/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0235 - mae: 0.0059 - val_loss: 0.0234 - val_mae: 0.0080\n",
      "Epoch 167/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0232 - mae: 0.0070 - val_loss: 0.0229 - val_mae: 0.0052\n",
      "Epoch 168/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0230 - mae: 0.0107 - val_loss: 0.0226 - val_mae: 0.0057\n",
      "Epoch 169/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0226 - mae: 0.0106 - val_loss: 0.0223 - val_mae: 0.0053\n",
      "Epoch 170/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0221 - mae: 0.0056 - val_loss: 0.0221 - val_mae: 0.0110\n",
      "Epoch 171/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0218 - mae: 0.0068 - val_loss: 0.0216 - val_mae: 0.0063\n",
      "Epoch 172/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0217 - mae: 0.0124 - val_loss: 0.0215 - val_mae: 0.0150\n",
      "Epoch 173/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0213 - mae: 0.0127 - val_loss: 0.0210 - val_mae: 0.0071\n",
      "Epoch 174/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0209 - mae: 0.0094 - val_loss: 0.0207 - val_mae: 0.0098\n",
      "Epoch 175/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0207 - mae: 0.0117 - val_loss: 0.0209 - val_mae: 0.0213\n",
      "Epoch 176/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0204 - mae: 0.0125 - val_loss: 0.0200 - val_mae: 0.0067\n",
      "Epoch 177/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0201 - mae: 0.0119 - val_loss: 0.0203 - val_mae: 0.0220\n",
      "Epoch 178/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0202 - mae: 0.0200 - val_loss: 0.0195 - val_mae: 0.0107\n",
      "Epoch 179/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0196 - mae: 0.0133 - val_loss: 0.0199 - val_mae: 0.0213\n",
      "Epoch 180/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0192 - mae: 0.0127 - val_loss: 0.0188 - val_mae: 0.0066\n",
      "Epoch 181/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0188 - mae: 0.0087 - val_loss: 0.0186 - val_mae: 0.0090\n",
      "Epoch 182/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0185 - mae: 0.0078 - val_loss: 0.0184 - val_mae: 0.0125\n",
      "Epoch 183/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0182 - mae: 0.0081 - val_loss: 0.0180 - val_mae: 0.0078\n",
      "Epoch 184/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0179 - mae: 0.0084 - val_loss: 0.0181 - val_mae: 0.0172\n",
      "Epoch 185/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0178 - mae: 0.0142 - val_loss: 0.0181 - val_mae: 0.0245\n",
      "Epoch 186/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0177 - mae: 0.0170 - val_loss: 0.0172 - val_mae: 0.0069\n",
      "Epoch 187/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0174 - mae: 0.0165 - val_loss: 0.0172 - val_mae: 0.0158\n",
      "Epoch 188/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0170 - mae: 0.0136 - val_loss: 0.0171 - val_mae: 0.0203\n",
      "Epoch 189/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0096 - val_loss: 0.0164 - val_mae: 0.0085\n",
      "Epoch 190/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0165 - mae: 0.0131 - val_loss: 0.0163 - val_mae: 0.0130\n",
      "Epoch 191/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0205 - val_loss: 0.0165 - val_mae: 0.0192\n",
      "Epoch 192/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0162 - mae: 0.0156 - val_loss: 0.0157 - val_mae: 0.0105\n",
      "Epoch 193/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0142 - val_loss: 0.0168 - val_mae: 0.0335\n",
      "Epoch 194/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0187 - mae: 0.0432 - val_loss: 0.0205 - val_mae: 0.0651\n",
      "Epoch 195/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0181 - mae: 0.0404 - val_loss: 0.0153 - val_mae: 0.0147\n",
      "Epoch 196/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0151 - mae: 0.0130 - val_loss: 0.0149 - val_mae: 0.0125\n",
      "Epoch 197/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0148 - mae: 0.0125 - val_loss: 0.0146 - val_mae: 0.0100\n",
      "Epoch 198/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0086 - val_loss: 0.0143 - val_mae: 0.0055\n",
      "Epoch 199/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0142 - mae: 0.0083 - val_loss: 0.0142 - val_mae: 0.0106\n",
      "Epoch 200/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0141 - mae: 0.0108 - val_loss: 0.0138 - val_mae: 0.0069\n",
      "Epoch 201/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0090 - val_loss: 0.0143 - val_mae: 0.0219\n",
      "Epoch 202/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0142 - mae: 0.0206 - val_loss: 0.0141 - val_mae: 0.0237\n",
      "Epoch 203/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0151 - val_loss: 0.0134 - val_mae: 0.0157\n",
      "Epoch 204/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0093 - val_loss: 0.0131 - val_mae: 0.0102\n",
      "Epoch 205/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0069 - val_loss: 0.0128 - val_mae: 0.0052\n",
      "Epoch 206/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0068 - val_loss: 0.0126 - val_mae: 0.0055\n",
      "Epoch 207/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - mae: 0.0085 - val_loss: 0.0124 - val_mae: 0.0069\n",
      "Epoch 208/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0067 - val_loss: 0.0122 - val_mae: 0.0066\n",
      "Epoch 209/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0121 - mae: 0.0072 - val_loss: 0.0120 - val_mae: 0.0049\n",
      "Epoch 210/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0119 - mae: 0.0062 - val_loss: 0.0118 - val_mae: 0.0075\n",
      "Epoch 211/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - mae: 0.0092 - val_loss: 0.0117 - val_mae: 0.0091\n",
      "Epoch 212/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0117 - mae: 0.0089 - val_loss: 0.0115 - val_mae: 0.0097\n",
      "Epoch 213/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0115 - mae: 0.0102 - val_loss: 0.0115 - val_mae: 0.0141\n",
      "Epoch 214/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - mae: 0.0167 - val_loss: 0.0118 - val_mae: 0.0223\n",
      "Epoch 215/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0113 - mae: 0.0135 - val_loss: 0.0113 - val_mae: 0.0197\n",
      "Epoch 216/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - mae: 0.0133 - val_loss: 0.0109 - val_mae: 0.0117\n",
      "Epoch 217/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0107 - mae: 0.0078 - val_loss: 0.0106 - val_mae: 0.0060\n",
      "Epoch 218/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0105 - mae: 0.0060 - val_loss: 0.0104 - val_mae: 0.0056\n",
      "Epoch 219/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0104 - mae: 0.0075 - val_loss: 0.0103 - val_mae: 0.0065\n",
      "Epoch 220/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0102 - mae: 0.0089 - val_loss: 0.0101 - val_mae: 0.0066\n",
      "Epoch 221/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0101 - mae: 0.0087 - val_loss: 0.0102 - val_mae: 0.0148\n",
      "Epoch 222/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0102 - mae: 0.0145 - val_loss: 0.0101 - val_mae: 0.0138\n",
      "Epoch 223/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0103 - mae: 0.0183 - val_loss: 0.0099 - val_mae: 0.0143\n",
      "Epoch 224/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0101 - mae: 0.0177 - val_loss: 0.0098 - val_mae: 0.0188\n",
      "Epoch 225/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0098 - mae: 0.0153 - val_loss: 0.0100 - val_mae: 0.0233\n",
      "Epoch 226/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0116 - val_loss: 0.0092 - val_mae: 0.0054\n",
      "Epoch 227/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0082 - val_loss: 0.0090 - val_mae: 0.0052\n",
      "Epoch 228/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0080 - val_loss: 0.0093 - val_mae: 0.0161\n",
      "Epoch 229/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0146 - val_loss: 0.0091 - val_mae: 0.0172\n",
      "Epoch 230/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0156 - val_loss: 0.0103 - val_mae: 0.0384\n",
      "Epoch 231/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0095 - mae: 0.0240 - val_loss: 0.0090 - val_mae: 0.0186\n",
      "Epoch 232/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0173 - val_loss: 0.0090 - val_mae: 0.0233\n",
      "Epoch 233/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0175 - val_loss: 0.0085 - val_mae: 0.0116\n",
      "Epoch 234/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0128 - val_loss: 0.0085 - val_mae: 0.0167\n",
      "Epoch 235/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0275 - val_loss: 0.0098 - val_mae: 0.0378\n",
      "Epoch 236/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0241 - val_loss: 0.0082 - val_mae: 0.0166\n",
      "Epoch 237/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0158 - val_loss: 0.0080 - val_mae: 0.0127\n",
      "Epoch 238/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0135 - val_loss: 0.0078 - val_mae: 0.0105\n",
      "Epoch 239/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0210 - val_loss: 0.0084 - val_mae: 0.0234\n",
      "Epoch 240/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0195 - val_loss: 0.0082 - val_mae: 0.0259\n",
      "Epoch 241/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0216 - val_loss: 0.0081 - val_mae: 0.0276\n",
      "Epoch 242/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0145 - val_loss: 0.0075 - val_mae: 0.0142\n",
      "Epoch 243/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - mae: 0.0129 - val_loss: 0.0073 - val_mae: 0.0102\n",
      "Epoch 244/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - mae: 0.0141 - val_loss: 0.0082 - val_mae: 0.0309\n",
      "Epoch 245/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0197 - val_loss: 0.0073 - val_mae: 0.0168\n",
      "Epoch 246/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - mae: 0.0106 - val_loss: 0.0069 - val_mae: 0.0072\n",
      "Epoch 247/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0071 - mae: 0.0133 - val_loss: 0.0068 - val_mae: 0.0067\n",
      "Epoch 248/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - mae: 0.0124 - val_loss: 0.0067 - val_mae: 0.0067\n",
      "Epoch 249/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - mae: 0.0066 - val_loss: 0.0066 - val_mae: 0.0064\n",
      "Epoch 250/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - mae: 0.0076 - val_loss: 0.0065 - val_mae: 0.0064\n",
      "Epoch 251/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0064 - mae: 0.0053 - val_loss: 0.0064 - val_mae: 0.0048\n",
      "Epoch 252/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0063 - mae: 0.0061 - val_loss: 0.0063 - val_mae: 0.0057\n",
      "Epoch 253/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0062 - mae: 0.0060 - val_loss: 0.0063 - val_mae: 0.0113\n",
      "Epoch 254/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0062 - mae: 0.0091 - val_loss: 0.0062 - val_mae: 0.0104\n",
      "Epoch 255/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0061 - mae: 0.0090 - val_loss: 0.0065 - val_mae: 0.0198\n",
      "Epoch 256/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - mae: 0.0209 - val_loss: 0.0094 - val_mae: 0.0478\n",
      "Epoch 257/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0098 - mae: 0.0463 - val_loss: 0.0087 - val_mae: 0.0424\n",
      "Epoch 258/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - mae: 0.0243 - val_loss: 0.0061 - val_mae: 0.0135\n",
      "Epoch 259/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0059 - mae: 0.0103 - val_loss: 0.0058 - val_mae: 0.0081\n",
      "Epoch 260/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0059 - mae: 0.0128 - val_loss: 0.0058 - val_mae: 0.0115\n",
      "Epoch 261/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0059 - mae: 0.0126 - val_loss: 0.0058 - val_mae: 0.0134\n",
      "Epoch 262/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0058 - mae: 0.0124 - val_loss: 0.0056 - val_mae: 0.0089\n",
      "Epoch 263/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0055 - mae: 0.0077 - val_loss: 0.0056 - val_mae: 0.0114\n",
      "Epoch 264/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0055 - mae: 0.0082 - val_loss: 0.0054 - val_mae: 0.0083\n",
      "Epoch 265/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0054 - mae: 0.0060 - val_loss: 0.0053 - val_mae: 0.0050\n",
      "Epoch 266/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0053 - mae: 0.0053 - val_loss: 0.0052 - val_mae: 0.0035\n",
      "Epoch 267/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0052 - mae: 0.0052 - val_loss: 0.0052 - val_mae: 0.0068\n",
      "Epoch 268/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0052 - mae: 0.0069 - val_loss: 0.0051 - val_mae: 0.0076\n",
      "Epoch 269/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0051 - mae: 0.0077 - val_loss: 0.0051 - val_mae: 0.0094\n",
      "Epoch 270/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0051 - mae: 0.0084 - val_loss: 0.0053 - val_mae: 0.0157\n",
      "Epoch 271/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0052 - mae: 0.0131 - val_loss: 0.0052 - val_mae: 0.0142\n",
      "Epoch 272/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0093 - val_loss: 0.0048 - val_mae: 0.0056\n",
      "Epoch 273/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0075 - val_loss: 0.0052 - val_mae: 0.0160\n",
      "Epoch 274/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0117 - val_loss: 0.0061 - val_mae: 0.0360\n",
      "Epoch 275/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0058 - mae: 0.0272 - val_loss: 0.0053 - val_mae: 0.0224\n",
      "Epoch 276/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0053 - mae: 0.0214 - val_loss: 0.0058 - val_mae: 0.0250\n",
      "Epoch 277/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0052 - mae: 0.0194 - val_loss: 0.0046 - val_mae: 0.0073\n",
      "Epoch 278/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0046 - mae: 0.0083 - val_loss: 0.0045 - val_mae: 0.0070\n",
      "Epoch 279/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0080 - val_loss: 0.0045 - val_mae: 0.0080\n",
      "Epoch 280/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0070 - val_loss: 0.0045 - val_mae: 0.0091\n",
      "Epoch 281/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0073 - val_loss: 0.0043 - val_mae: 0.0054\n",
      "Epoch 282/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0086 - val_loss: 0.0045 - val_mae: 0.0121\n",
      "Epoch 283/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0126 - val_loss: 0.0043 - val_mae: 0.0067\n",
      "Epoch 284/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0060 - mae: 0.0314 - val_loss: 0.0049 - val_mae: 0.0224\n",
      "Epoch 285/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0046 - mae: 0.0160 - val_loss: 0.0045 - val_mae: 0.0174\n",
      "Epoch 286/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0088 - val_loss: 0.0046 - val_mae: 0.0190\n",
      "Epoch 287/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0148 - val_loss: 0.0041 - val_mae: 0.0064\n",
      "Epoch 288/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0077 - val_loss: 0.0041 - val_mae: 0.0098\n",
      "Epoch 289/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0041 - mae: 0.0078 - val_loss: 0.0040 - val_mae: 0.0049\n",
      "Epoch 290/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0081 - val_loss: 0.0040 - val_mae: 0.0080\n",
      "Epoch 291/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0092 - val_loss: 0.0039 - val_mae: 0.0048\n",
      "Epoch 292/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0172 - val_loss: 0.0056 - val_mae: 0.0373\n",
      "Epoch 293/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0047 - mae: 0.0230 - val_loss: 0.0050 - val_mae: 0.0248\n",
      "Epoch 294/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0155 - val_loss: 0.0040 - val_mae: 0.0118\n",
      "Epoch 295/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0100 - val_loss: 0.0038 - val_mae: 0.0066\n",
      "Epoch 296/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0067 - val_loss: 0.0037 - val_mae: 0.0047\n",
      "Epoch 297/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0067 - val_loss: 0.0037 - val_mae: 0.0079\n",
      "Epoch 298/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0075 - val_loss: 0.0037 - val_mae: 0.0101\n",
      "Epoch 299/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0083 - val_loss: 0.0037 - val_mae: 0.0085\n",
      "Epoch 300/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0062 - val_loss: 0.0036 - val_mae: 0.0084\n",
      "Epoch 301/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0095 - val_loss: 0.0041 - val_mae: 0.0194\n",
      "Epoch 302/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0095 - val_loss: 0.0035 - val_mae: 0.0063\n",
      "Epoch 303/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0064 - val_loss: 0.0035 - val_mae: 0.0073\n",
      "Epoch 304/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0069 - val_loss: 0.0034 - val_mae: 0.0066\n",
      "Epoch 305/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0085 - val_loss: 0.0036 - val_mae: 0.0131\n",
      "Epoch 306/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0095 - val_loss: 0.0034 - val_mae: 0.0094\n",
      "Epoch 307/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0138 - val_loss: 0.0035 - val_mae: 0.0143\n",
      "Epoch 308/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0080 - val_loss: 0.0032 - val_mae: 0.0040\n",
      "Epoch 309/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0083 - val_loss: 0.0034 - val_mae: 0.0122\n",
      "Epoch 310/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0106 - val_loss: 0.0032 - val_mae: 0.0048\n",
      "Epoch 311/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0103 - val_loss: 0.0039 - val_mae: 0.0213\n",
      "Epoch 312/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0119 - val_loss: 0.0033 - val_mae: 0.0108\n",
      "Epoch 313/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0126 - val_loss: 0.0032 - val_mae: 0.0070\n",
      "Epoch 314/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0131 - val_loss: 0.0033 - val_mae: 0.0146\n",
      "Epoch 315/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0128 - val_loss: 0.0032 - val_mae: 0.0104\n",
      "Epoch 316/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0103 - val_loss: 0.0031 - val_mae: 0.0094\n",
      "Epoch 317/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0059 - val_loss: 0.0031 - val_mae: 0.0109\n",
      "Epoch 318/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0077 - val_loss: 0.0030 - val_mae: 0.0073\n",
      "Epoch 319/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0052 - val_loss: 0.0029 - val_mae: 0.0048\n",
      "Epoch 320/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0068 - val_loss: 0.0029 - val_mae: 0.0035\n",
      "Epoch 321/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0056 - val_loss: 0.0029 - val_mae: 0.0057\n",
      "Epoch 322/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0077 - val_loss: 0.0029 - val_mae: 0.0090\n",
      "Epoch 323/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0112 - val_loss: 0.0029 - val_mae: 0.0079\n",
      "Epoch 324/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0155 - val_loss: 0.0030 - val_mae: 0.0116\n",
      "Epoch 325/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0115 - val_loss: 0.0030 - val_mae: 0.0131\n",
      "Epoch 326/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0074 - val_loss: 0.0028 - val_mae: 0.0063\n",
      "Epoch 327/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0058 - val_loss: 0.0028 - val_mae: 0.0065\n",
      "Epoch 328/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0055 - val_loss: 0.0027 - val_mae: 0.0048\n",
      "Epoch 329/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0082 - val_loss: 0.0030 - val_mae: 0.0145\n",
      "Epoch 330/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0169 - val_loss: 0.0036 - val_mae: 0.0244\n",
      "Epoch 331/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0168 - val_loss: 0.0027 - val_mae: 0.0068\n",
      "Epoch 332/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0096 - val_loss: 0.0030 - val_mae: 0.0162\n",
      "Epoch 333/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0126 - val_loss: 0.0027 - val_mae: 0.0095\n",
      "Epoch 334/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0106 - val_loss: 0.0026 - val_mae: 0.0045\n",
      "Epoch 335/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0086 - val_loss: 0.0026 - val_mae: 0.0054\n",
      "Epoch 336/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0093 - val_loss: 0.0032 - val_mae: 0.0218\n",
      "Epoch 337/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0124 - val_loss: 0.0026 - val_mae: 0.0088\n",
      "Epoch 338/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0080 - val_loss: 0.0026 - val_mae: 0.0073\n",
      "Epoch 339/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0115 - val_loss: 0.0029 - val_mae: 0.0176\n",
      "Epoch 340/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0107 - val_loss: 0.0025 - val_mae: 0.0077\n",
      "Epoch 341/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0097 - val_loss: 0.0031 - val_mae: 0.0237\n",
      "Epoch 342/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0275 - val_loss: 0.0032 - val_mae: 0.0249\n",
      "Epoch 343/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0281 - val_loss: 0.0026 - val_mae: 0.0108\n",
      "Epoch 344/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0082 - val_loss: 0.0025 - val_mae: 0.0073\n",
      "Epoch 345/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0058 - val_loss: 0.0026 - val_mae: 0.0114\n",
      "Epoch 346/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0084 - val_loss: 0.0026 - val_mae: 0.0123\n",
      "Epoch 347/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0124 - val_loss: 0.0028 - val_mae: 0.0192\n",
      "Epoch 348/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0094 - val_loss: 0.0025 - val_mae: 0.0104\n",
      "Epoch 349/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0066 - val_loss: 0.0023 - val_mae: 0.0033\n",
      "Epoch 350/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0080 - val_loss: 0.0024 - val_mae: 0.0097\n",
      "Epoch 351/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0073 - val_loss: 0.0024 - val_mae: 0.0089\n",
      "Epoch 352/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0066 - val_loss: 0.0023 - val_mae: 0.0056\n",
      "Epoch 353/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0061 - val_loss: 0.0023 - val_mae: 0.0053\n",
      "Epoch 354/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0081 - val_loss: 0.0028 - val_mae: 0.0213\n",
      "Epoch 355/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0278 - val_loss: 0.0069 - val_mae: 0.0510\n",
      "Epoch 356/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0361 - val_loss: 0.0027 - val_mae: 0.0163\n",
      "Epoch 357/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0218 - val_loss: 0.0026 - val_mae: 0.0175\n",
      "Epoch 358/1000\n",
      "26/28 [==========================>...] - ETA: 0s - loss: 0.0027 - mae: 0.0160Restoring model weights from the end of the best epoch: 353.\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0156 - val_loss: 0.0024 - val_mae: 0.0108\n",
      "Epoch 358: early stopping\n",
      "Training für Fold 5...\n",
      "Epoch 1/1000\n",
      "28/28 [==============================] - 1s 9ms/step - loss: 0.5395 - mae: 0.3669 - val_loss: 0.3958 - val_mae: 0.2884\n",
      "Epoch 2/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3713 - mae: 0.2715 - val_loss: 0.3456 - val_mae: 0.2642\n",
      "Epoch 3/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3217 - mae: 0.2428 - val_loss: 0.2972 - val_mae: 0.2211\n",
      "Epoch 4/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2656 - mae: 0.1800 - val_loss: 0.2532 - val_mae: 0.1769\n",
      "Epoch 5/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2409 - mae: 0.1439 - val_loss: 0.2259 - val_mae: 0.1112\n",
      "Epoch 6/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2096 - mae: 0.0895 - val_loss: 0.1945 - val_mae: 0.0400\n",
      "Epoch 7/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2096 - mae: 0.1044 - val_loss: 0.1978 - val_mae: 0.0668\n",
      "Epoch 8/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1988 - mae: 0.0835 - val_loss: 0.1871 - val_mae: 0.0411\n",
      "Epoch 9/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1928 - mae: 0.0722 - val_loss: 0.1849 - val_mae: 0.0495\n",
      "Epoch 10/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1842 - mae: 0.0526 - val_loss: 0.1784 - val_mae: 0.0265\n",
      "Epoch 11/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1793 - mae: 0.0414 - val_loss: 0.1752 - val_mae: 0.0232\n",
      "Epoch 12/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1744 - mae: 0.0265 - val_loss: 0.1725 - val_mae: 0.0238\n",
      "Epoch 13/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1727 - mae: 0.0322 - val_loss: 0.1702 - val_mae: 0.0258\n",
      "Epoch 14/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1685 - mae: 0.0182 - val_loss: 0.1668 - val_mae: 0.0101\n",
      "Epoch 15/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1662 - mae: 0.0180 - val_loss: 0.1650 - val_mae: 0.0229\n",
      "Epoch 16/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1642 - mae: 0.0225 - val_loss: 0.1622 - val_mae: 0.0114\n",
      "Epoch 17/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1625 - mae: 0.0276 - val_loss: 0.1609 - val_mae: 0.0254\n",
      "Epoch 18/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1593 - mae: 0.0169 - val_loss: 0.1578 - val_mae: 0.0105\n",
      "Epoch 19/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1573 - mae: 0.0183 - val_loss: 0.1559 - val_mae: 0.0141\n",
      "Epoch 20/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1549 - mae: 0.0132 - val_loss: 0.1536 - val_mae: 0.0063\n",
      "Epoch 21/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1526 - mae: 0.0073 - val_loss: 0.1516 - val_mae: 0.0061\n",
      "Epoch 22/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1507 - mae: 0.0081 - val_loss: 0.1496 - val_mae: 0.0069\n",
      "Epoch 23/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1488 - mae: 0.0096 - val_loss: 0.1477 - val_mae: 0.0069\n",
      "Epoch 24/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1468 - mae: 0.0075 - val_loss: 0.1458 - val_mae: 0.0063\n",
      "Epoch 25/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1450 - mae: 0.0084 - val_loss: 0.1442 - val_mae: 0.0146\n",
      "Epoch 26/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1434 - mae: 0.0134 - val_loss: 0.1428 - val_mae: 0.0177\n",
      "Epoch 27/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1420 - mae: 0.0185 - val_loss: 0.1435 - val_mae: 0.0380\n",
      "Epoch 28/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1404 - mae: 0.0197 - val_loss: 0.1391 - val_mae: 0.0150\n",
      "Epoch 29/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1381 - mae: 0.0120 - val_loss: 0.1372 - val_mae: 0.0129\n",
      "Epoch 30/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1365 - mae: 0.0151 - val_loss: 0.1354 - val_mae: 0.0100\n",
      "Epoch 31/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1347 - mae: 0.0112 - val_loss: 0.1342 - val_mae: 0.0170\n",
      "Epoch 32/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1334 - mae: 0.0180 - val_loss: 0.1332 - val_mae: 0.0261\n",
      "Epoch 33/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1321 - mae: 0.0220 - val_loss: 0.1310 - val_mae: 0.0197\n",
      "Epoch 34/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1305 - mae: 0.0223 - val_loss: 0.1296 - val_mae: 0.0213\n",
      "Epoch 35/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1299 - mae: 0.0317 - val_loss: 0.1290 - val_mae: 0.0311\n",
      "Epoch 36/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1287 - mae: 0.0336 - val_loss: 0.1271 - val_mae: 0.0258\n",
      "Epoch 37/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1259 - mae: 0.0206 - val_loss: 0.1252 - val_mae: 0.0242\n",
      "Epoch 38/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1243 - mae: 0.0179 - val_loss: 0.1232 - val_mae: 0.0114\n",
      "Epoch 39/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1225 - mae: 0.0111 - val_loss: 0.1217 - val_mae: 0.0108\n",
      "Epoch 40/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1214 - mae: 0.0161 - val_loss: 0.1220 - val_mae: 0.0298\n",
      "Epoch 41/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1202 - mae: 0.0177 - val_loss: 0.1191 - val_mae: 0.0158\n",
      "Epoch 42/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1185 - mae: 0.0148 - val_loss: 0.1182 - val_mae: 0.0223\n",
      "Epoch 43/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1174 - mae: 0.0195 - val_loss: 0.1167 - val_mae: 0.0193\n",
      "Epoch 44/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1160 - mae: 0.0204 - val_loss: 0.1152 - val_mae: 0.0153\n",
      "Epoch 45/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1144 - mae: 0.0145 - val_loss: 0.1141 - val_mae: 0.0227\n",
      "Epoch 46/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1135 - mae: 0.0205 - val_loss: 0.1125 - val_mae: 0.0158\n",
      "Epoch 47/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1120 - mae: 0.0174 - val_loss: 0.1110 - val_mae: 0.0084\n",
      "Epoch 48/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1124 - mae: 0.0311 - val_loss: 0.1138 - val_mae: 0.0430\n",
      "Epoch 49/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1116 - mae: 0.0358 - val_loss: 0.1093 - val_mae: 0.0231\n",
      "Epoch 50/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1085 - mae: 0.0212 - val_loss: 0.1077 - val_mae: 0.0228\n",
      "Epoch 51/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1075 - mae: 0.0238 - val_loss: 0.1079 - val_mae: 0.0320\n",
      "Epoch 52/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1064 - mae: 0.0233 - val_loss: 0.1050 - val_mae: 0.0113\n",
      "Epoch 53/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1048 - mae: 0.0177 - val_loss: 0.1037 - val_mae: 0.0103\n",
      "Epoch 54/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1032 - mae: 0.0110 - val_loss: 0.1026 - val_mae: 0.0121\n",
      "Epoch 55/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1023 - mae: 0.0149 - val_loss: 0.1033 - val_mae: 0.0339\n",
      "Epoch 56/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1021 - mae: 0.0287 - val_loss: 0.1033 - val_mae: 0.0444\n",
      "Epoch 57/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1021 - mae: 0.0391 - val_loss: 0.0995 - val_mae: 0.0173\n",
      "Epoch 58/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0991 - mae: 0.0192 - val_loss: 0.0987 - val_mae: 0.0208\n",
      "Epoch 59/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0981 - mae: 0.0191 - val_loss: 0.0975 - val_mae: 0.0207\n",
      "Epoch 60/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0973 - mae: 0.0224 - val_loss: 0.0962 - val_mae: 0.0164\n",
      "Epoch 61/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0958 - mae: 0.0178 - val_loss: 0.0949 - val_mae: 0.0086\n",
      "Epoch 62/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0944 - mae: 0.0112 - val_loss: 0.0938 - val_mae: 0.0075\n",
      "Epoch 63/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0934 - mae: 0.0115 - val_loss: 0.0927 - val_mae: 0.0076\n",
      "Epoch 64/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0923 - mae: 0.0095 - val_loss: 0.0917 - val_mae: 0.0099\n",
      "Epoch 65/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0912 - mae: 0.0067 - val_loss: 0.0907 - val_mae: 0.0096\n",
      "Epoch 66/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0903 - mae: 0.0117 - val_loss: 0.0899 - val_mae: 0.0154\n",
      "Epoch 67/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0894 - mae: 0.0138 - val_loss: 0.0888 - val_mae: 0.0119\n",
      "Epoch 68/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0893 - mae: 0.0240 - val_loss: 0.0891 - val_mae: 0.0340\n",
      "Epoch 69/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0880 - mae: 0.0217 - val_loss: 0.0877 - val_mae: 0.0216\n",
      "Epoch 70/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0868 - mae: 0.0183 - val_loss: 0.0863 - val_mae: 0.0189\n",
      "Epoch 71/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0858 - mae: 0.0173 - val_loss: 0.0853 - val_mae: 0.0161\n",
      "Epoch 72/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0849 - mae: 0.0186 - val_loss: 0.0841 - val_mae: 0.0136\n",
      "Epoch 73/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0836 - mae: 0.0144 - val_loss: 0.0830 - val_mae: 0.0114\n",
      "Epoch 74/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0827 - mae: 0.0130 - val_loss: 0.0823 - val_mae: 0.0146\n",
      "Epoch 75/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0819 - mae: 0.0168 - val_loss: 0.0814 - val_mae: 0.0201\n",
      "Epoch 76/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0810 - mae: 0.0181 - val_loss: 0.0802 - val_mae: 0.0084\n",
      "Epoch 77/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0807 - mae: 0.0256 - val_loss: 0.0798 - val_mae: 0.0182\n",
      "Epoch 78/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0795 - mae: 0.0227 - val_loss: 0.0789 - val_mae: 0.0173\n",
      "Epoch 79/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0781 - mae: 0.0118 - val_loss: 0.0774 - val_mae: 0.0070\n",
      "Epoch 80/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0771 - mae: 0.0098 - val_loss: 0.0766 - val_mae: 0.0094\n",
      "Epoch 81/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0762 - mae: 0.0084 - val_loss: 0.0758 - val_mae: 0.0108\n",
      "Epoch 82/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0762 - mae: 0.0237 - val_loss: 0.0755 - val_mae: 0.0244\n",
      "Epoch 83/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0772 - mae: 0.0401 - val_loss: 0.0745 - val_mae: 0.0170\n",
      "Epoch 84/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0743 - mae: 0.0199 - val_loss: 0.0737 - val_mae: 0.0241\n",
      "Epoch 85/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0730 - mae: 0.0143 - val_loss: 0.0724 - val_mae: 0.0112\n",
      "Epoch 86/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0727 - mae: 0.0220 - val_loss: 0.0737 - val_mae: 0.0350\n",
      "Epoch 87/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0717 - mae: 0.0190 - val_loss: 0.0710 - val_mae: 0.0148\n",
      "Epoch 88/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0706 - mae: 0.0152 - val_loss: 0.0700 - val_mae: 0.0088\n",
      "Epoch 89/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0695 - mae: 0.0091 - val_loss: 0.0691 - val_mae: 0.0090\n",
      "Epoch 90/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0687 - mae: 0.0082 - val_loss: 0.0684 - val_mae: 0.0122\n",
      "Epoch 91/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0680 - mae: 0.0107 - val_loss: 0.0677 - val_mae: 0.0120\n",
      "Epoch 92/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0671 - mae: 0.0085 - val_loss: 0.0667 - val_mae: 0.0069\n",
      "Epoch 93/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0663 - mae: 0.0065 - val_loss: 0.0662 - val_mae: 0.0157\n",
      "Epoch 94/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0660 - mae: 0.0171 - val_loss: 0.0657 - val_mae: 0.0221\n",
      "Epoch 95/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0664 - mae: 0.0310 - val_loss: 0.0679 - val_mae: 0.0446\n",
      "Epoch 96/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0664 - mae: 0.0369 - val_loss: 0.0648 - val_mae: 0.0225\n",
      "Epoch 97/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0640 - mae: 0.0226 - val_loss: 0.0635 - val_mae: 0.0214\n",
      "Epoch 98/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0635 - mae: 0.0251 - val_loss: 0.0623 - val_mae: 0.0111\n",
      "Epoch 99/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0622 - mae: 0.0174 - val_loss: 0.0615 - val_mae: 0.0099\n",
      "Epoch 100/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0619 - mae: 0.0226 - val_loss: 0.0617 - val_mae: 0.0291\n",
      "Epoch 101/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0607 - mae: 0.0147 - val_loss: 0.0600 - val_mae: 0.0089\n",
      "Epoch 102/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0596 - mae: 0.0060 - val_loss: 0.0592 - val_mae: 0.0056\n",
      "Epoch 103/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0589 - mae: 0.0068 - val_loss: 0.0585 - val_mae: 0.0053\n",
      "Epoch 104/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0581 - mae: 0.0051 - val_loss: 0.0577 - val_mae: 0.0050\n",
      "Epoch 105/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0574 - mae: 0.0042 - val_loss: 0.0571 - val_mae: 0.0069\n",
      "Epoch 106/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0567 - mae: 0.0061 - val_loss: 0.0564 - val_mae: 0.0069\n",
      "Epoch 107/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0561 - mae: 0.0084 - val_loss: 0.0557 - val_mae: 0.0053\n",
      "Epoch 108/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0554 - mae: 0.0068 - val_loss: 0.0551 - val_mae: 0.0103\n",
      "Epoch 109/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0558 - mae: 0.0238 - val_loss: 0.0551 - val_mae: 0.0205\n",
      "Epoch 110/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0550 - mae: 0.0239 - val_loss: 0.0541 - val_mae: 0.0178\n",
      "Epoch 111/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0543 - mae: 0.0245 - val_loss: 0.0561 - val_mae: 0.0448\n",
      "Epoch 112/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0540 - mae: 0.0270 - val_loss: 0.0526 - val_mae: 0.0138\n",
      "Epoch 113/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0524 - mae: 0.0144 - val_loss: 0.0518 - val_mae: 0.0112\n",
      "Epoch 114/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0516 - mae: 0.0115 - val_loss: 0.0510 - val_mae: 0.0061\n",
      "Epoch 115/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0508 - mae: 0.0068 - val_loss: 0.0504 - val_mae: 0.0044\n",
      "Epoch 116/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0502 - mae: 0.0085 - val_loss: 0.0500 - val_mae: 0.0141\n",
      "Epoch 117/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0501 - mae: 0.0200 - val_loss: 0.0499 - val_mae: 0.0187\n",
      "Epoch 118/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0491 - mae: 0.0138 - val_loss: 0.0485 - val_mae: 0.0071\n",
      "Epoch 119/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0482 - mae: 0.0069 - val_loss: 0.0479 - val_mae: 0.0049\n",
      "Epoch 120/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0477 - mae: 0.0083 - val_loss: 0.0473 - val_mae: 0.0062\n",
      "Epoch 121/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0472 - mae: 0.0113 - val_loss: 0.0469 - val_mae: 0.0141\n",
      "Epoch 122/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0470 - mae: 0.0186 - val_loss: 0.0469 - val_mae: 0.0205\n",
      "Epoch 123/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0466 - mae: 0.0208 - val_loss: 0.0455 - val_mae: 0.0071\n",
      "Epoch 124/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0453 - mae: 0.0094 - val_loss: 0.0456 - val_mae: 0.0224\n",
      "Epoch 125/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0459 - mae: 0.0256 - val_loss: 0.0445 - val_mae: 0.0102\n",
      "Epoch 126/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0441 - mae: 0.0075 - val_loss: 0.0439 - val_mae: 0.0114\n",
      "Epoch 127/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0436 - mae: 0.0098 - val_loss: 0.0433 - val_mae: 0.0099\n",
      "Epoch 128/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0431 - mae: 0.0110 - val_loss: 0.0426 - val_mae: 0.0074\n",
      "Epoch 129/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0425 - mae: 0.0121 - val_loss: 0.0428 - val_mae: 0.0241\n",
      "Epoch 130/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0431 - mae: 0.0271 - val_loss: 0.0440 - val_mae: 0.0361\n",
      "Epoch 131/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0441 - mae: 0.0392 - val_loss: 0.0430 - val_mae: 0.0378\n",
      "Epoch 132/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0419 - mae: 0.0267 - val_loss: 0.0427 - val_mae: 0.0389\n",
      "Epoch 133/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0409 - mae: 0.0203 - val_loss: 0.0406 - val_mae: 0.0221\n",
      "Epoch 134/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0397 - mae: 0.0091 - val_loss: 0.0394 - val_mae: 0.0073\n",
      "Epoch 135/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0391 - mae: 0.0066 - val_loss: 0.0389 - val_mae: 0.0109\n",
      "Epoch 136/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0386 - mae: 0.0078 - val_loss: 0.0383 - val_mae: 0.0060\n",
      "Epoch 137/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0382 - mae: 0.0120 - val_loss: 0.0378 - val_mae: 0.0071\n",
      "Epoch 138/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0377 - mae: 0.0106 - val_loss: 0.0373 - val_mae: 0.0072\n",
      "Epoch 139/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0371 - mae: 0.0091 - val_loss: 0.0368 - val_mae: 0.0060\n",
      "Epoch 140/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0366 - mae: 0.0092 - val_loss: 0.0363 - val_mae: 0.0075\n",
      "Epoch 141/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0361 - mae: 0.0075 - val_loss: 0.0359 - val_mae: 0.0092\n",
      "Epoch 142/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0357 - mae: 0.0097 - val_loss: 0.0353 - val_mae: 0.0064\n",
      "Epoch 143/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0352 - mae: 0.0113 - val_loss: 0.0349 - val_mae: 0.0111\n",
      "Epoch 144/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0347 - mae: 0.0094 - val_loss: 0.0344 - val_mae: 0.0099\n",
      "Epoch 145/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0342 - mae: 0.0085 - val_loss: 0.0349 - val_mae: 0.0228\n",
      "Epoch 146/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0347 - mae: 0.0259 - val_loss: 0.0340 - val_mae: 0.0199\n",
      "Epoch 147/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0336 - mae: 0.0173 - val_loss: 0.0334 - val_mae: 0.0192\n",
      "Epoch 148/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0333 - mae: 0.0209 - val_loss: 0.0338 - val_mae: 0.0311\n",
      "Epoch 149/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0328 - mae: 0.0192 - val_loss: 0.0322 - val_mae: 0.0160\n",
      "Epoch 150/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.0107 - val_loss: 0.0315 - val_mae: 0.0063\n",
      "Epoch 151/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.0082 - val_loss: 0.0311 - val_mae: 0.0083\n",
      "Epoch 152/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.0064 - val_loss: 0.0307 - val_mae: 0.0073\n",
      "Epoch 153/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.0060 - val_loss: 0.0302 - val_mae: 0.0084\n",
      "Epoch 154/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0301 - mae: 0.0092 - val_loss: 0.0301 - val_mae: 0.0163\n",
      "Epoch 155/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.0124 - val_loss: 0.0298 - val_mae: 0.0210\n",
      "Epoch 156/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.0097 - val_loss: 0.0289 - val_mae: 0.0047\n",
      "Epoch 157/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.0062 - val_loss: 0.0286 - val_mae: 0.0093\n",
      "Epoch 158/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.0083 - val_loss: 0.0280 - val_mae: 0.0049\n",
      "Epoch 159/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.0049 - val_loss: 0.0277 - val_mae: 0.0068\n",
      "Epoch 160/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.0064 - val_loss: 0.0272 - val_mae: 0.0041\n",
      "Epoch 161/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.0068 - val_loss: 0.0269 - val_mae: 0.0089\n",
      "Epoch 162/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.0081 - val_loss: 0.0265 - val_mae: 0.0095\n",
      "Epoch 163/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.0199 - val_loss: 0.0271 - val_mae: 0.0256\n",
      "Epoch 164/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0273 - mae: 0.0304 - val_loss: 0.0267 - val_mae: 0.0246\n",
      "Epoch 165/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0263 - mae: 0.0196 - val_loss: 0.0257 - val_mae: 0.0159\n",
      "Epoch 166/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0256 - mae: 0.0166 - val_loss: 0.0251 - val_mae: 0.0113\n",
      "Epoch 167/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0251 - mae: 0.0155 - val_loss: 0.0246 - val_mae: 0.0094\n",
      "Epoch 168/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0246 - mae: 0.0128 - val_loss: 0.0243 - val_mae: 0.0098\n",
      "Epoch 169/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0242 - mae: 0.0126 - val_loss: 0.0239 - val_mae: 0.0080\n",
      "Epoch 170/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0239 - mae: 0.0138 - val_loss: 0.0235 - val_mae: 0.0082\n",
      "Epoch 171/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0241 - mae: 0.0214 - val_loss: 0.0245 - val_mae: 0.0338\n",
      "Epoch 172/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0243 - mae: 0.0290 - val_loss: 0.0238 - val_mae: 0.0208\n",
      "Epoch 173/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0241 - mae: 0.0309 - val_loss: 0.0229 - val_mae: 0.0183\n",
      "Epoch 174/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0228 - mae: 0.0188 - val_loss: 0.0222 - val_mae: 0.0100\n",
      "Epoch 175/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0222 - mae: 0.0149 - val_loss: 0.0218 - val_mae: 0.0089\n",
      "Epoch 176/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0222 - mae: 0.0174 - val_loss: 0.0249 - val_mae: 0.0430\n",
      "Epoch 177/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0235 - mae: 0.0306 - val_loss: 0.0213 - val_mae: 0.0113\n",
      "Epoch 178/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0212 - mae: 0.0124 - val_loss: 0.0212 - val_mae: 0.0172\n",
      "Epoch 179/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0208 - mae: 0.0113 - val_loss: 0.0205 - val_mae: 0.0080\n",
      "Epoch 180/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0205 - mae: 0.0123 - val_loss: 0.0204 - val_mae: 0.0132\n",
      "Epoch 181/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0201 - mae: 0.0084 - val_loss: 0.0199 - val_mae: 0.0049\n",
      "Epoch 182/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0198 - mae: 0.0066 - val_loss: 0.0197 - val_mae: 0.0098\n",
      "Epoch 183/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0195 - mae: 0.0068 - val_loss: 0.0193 - val_mae: 0.0045\n",
      "Epoch 184/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0192 - mae: 0.0075 - val_loss: 0.0190 - val_mae: 0.0070\n",
      "Epoch 185/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0189 - mae: 0.0064 - val_loss: 0.0187 - val_mae: 0.0081\n",
      "Epoch 186/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0185 - mae: 0.0054 - val_loss: 0.0184 - val_mae: 0.0062\n",
      "Epoch 187/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0183 - mae: 0.0080 - val_loss: 0.0181 - val_mae: 0.0071\n",
      "Epoch 188/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0180 - mae: 0.0063 - val_loss: 0.0178 - val_mae: 0.0063\n",
      "Epoch 189/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0177 - mae: 0.0054 - val_loss: 0.0175 - val_mae: 0.0040\n",
      "Epoch 190/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0174 - mae: 0.0065 - val_loss: 0.0173 - val_mae: 0.0063\n",
      "Epoch 191/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0173 - mae: 0.0103 - val_loss: 0.0180 - val_mae: 0.0258\n",
      "Epoch 192/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0173 - mae: 0.0172 - val_loss: 0.0169 - val_mae: 0.0112\n",
      "Epoch 193/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0167 - mae: 0.0091 - val_loss: 0.0167 - val_mae: 0.0122\n",
      "Epoch 194/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0164 - mae: 0.0076 - val_loss: 0.0163 - val_mae: 0.0071\n",
      "Epoch 195/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0162 - mae: 0.0086 - val_loss: 0.0162 - val_mae: 0.0150\n",
      "Epoch 196/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0160 - mae: 0.0104 - val_loss: 0.0157 - val_mae: 0.0055\n",
      "Epoch 197/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0157 - mae: 0.0108 - val_loss: 0.0158 - val_mae: 0.0169\n",
      "Epoch 198/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - mae: 0.0116 - val_loss: 0.0153 - val_mae: 0.0099\n",
      "Epoch 199/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0151 - mae: 0.0060 - val_loss: 0.0150 - val_mae: 0.0064\n",
      "Epoch 200/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0149 - mae: 0.0090 - val_loss: 0.0150 - val_mae: 0.0138\n",
      "Epoch 201/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0237 - mae: 0.0620 - val_loss: 0.0237 - val_mae: 0.0860\n",
      "Epoch 202/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0208 - mae: 0.0600 - val_loss: 0.0160 - val_mae: 0.0292\n",
      "Epoch 203/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0151 - mae: 0.0208 - val_loss: 0.0146 - val_mae: 0.0161\n",
      "Epoch 204/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0143 - mae: 0.0114 - val_loss: 0.0142 - val_mae: 0.0112\n",
      "Epoch 205/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0141 - mae: 0.0139 - val_loss: 0.0142 - val_mae: 0.0159\n",
      "Epoch 206/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0138 - mae: 0.0090 - val_loss: 0.0136 - val_mae: 0.0067\n",
      "Epoch 207/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - mae: 0.0064 - val_loss: 0.0133 - val_mae: 0.0054\n",
      "Epoch 208/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0054 - val_loss: 0.0132 - val_mae: 0.0067\n",
      "Epoch 209/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0061 - val_loss: 0.0130 - val_mae: 0.0078\n",
      "Epoch 210/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0072 - val_loss: 0.0129 - val_mae: 0.0130\n",
      "Epoch 211/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0079 - val_loss: 0.0126 - val_mae: 0.0080\n",
      "Epoch 212/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0066 - val_loss: 0.0123 - val_mae: 0.0051\n",
      "Epoch 213/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0059 - val_loss: 0.0122 - val_mae: 0.0075\n",
      "Epoch 214/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0084 - val_loss: 0.0121 - val_mae: 0.0093\n",
      "Epoch 215/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0094 - val_loss: 0.0118 - val_mae: 0.0063\n",
      "Epoch 216/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0114 - val_loss: 0.0118 - val_mae: 0.0111\n",
      "Epoch 217/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0117 - mae: 0.0116 - val_loss: 0.0115 - val_mae: 0.0074\n",
      "Epoch 218/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0114 - mae: 0.0066 - val_loss: 0.0112 - val_mae: 0.0049\n",
      "Epoch 219/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0112 - mae: 0.0063 - val_loss: 0.0113 - val_mae: 0.0138\n",
      "Epoch 220/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0113 - mae: 0.0138 - val_loss: 0.0110 - val_mae: 0.0103\n",
      "Epoch 221/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0109 - mae: 0.0062 - val_loss: 0.0108 - val_mae: 0.0051\n",
      "Epoch 222/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0107 - mae: 0.0066 - val_loss: 0.0106 - val_mae: 0.0064\n",
      "Epoch 223/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0106 - mae: 0.0092 - val_loss: 0.0105 - val_mae: 0.0094\n",
      "Epoch 224/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0105 - mae: 0.0098 - val_loss: 0.0104 - val_mae: 0.0094\n",
      "Epoch 225/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0102 - mae: 0.0078 - val_loss: 0.0102 - val_mae: 0.0079\n",
      "Epoch 226/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0101 - mae: 0.0068 - val_loss: 0.0099 - val_mae: 0.0046\n",
      "Epoch 227/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0066 - val_loss: 0.0099 - val_mae: 0.0083\n",
      "Epoch 228/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0059 - val_loss: 0.0097 - val_mae: 0.0071\n",
      "Epoch 229/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0062 - val_loss: 0.0096 - val_mae: 0.0102\n",
      "Epoch 230/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0095 - mae: 0.0080 - val_loss: 0.0094 - val_mae: 0.0090\n",
      "Epoch 231/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0072 - val_loss: 0.0092 - val_mae: 0.0067\n",
      "Epoch 232/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0085 - val_loss: 0.0093 - val_mae: 0.0147\n",
      "Epoch 233/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0121 - val_loss: 0.0092 - val_mae: 0.0124\n",
      "Epoch 234/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0094 - mae: 0.0188 - val_loss: 0.0090 - val_mae: 0.0129\n",
      "Epoch 235/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0153 - val_loss: 0.0089 - val_mae: 0.0128\n",
      "Epoch 236/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0147 - val_loss: 0.0111 - val_mae: 0.0470\n",
      "Epoch 237/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0256 - val_loss: 0.0085 - val_mae: 0.0100\n",
      "Epoch 238/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0119 - val_loss: 0.0083 - val_mae: 0.0066\n",
      "Epoch 239/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0069 - val_loss: 0.0082 - val_mae: 0.0061\n",
      "Epoch 240/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0076 - val_loss: 0.0080 - val_mae: 0.0052\n",
      "Epoch 241/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0079 - val_mae: 0.0070\n",
      "Epoch 242/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0073 - val_loss: 0.0078 - val_mae: 0.0097\n",
      "Epoch 243/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0102 - val_loss: 0.0078 - val_mae: 0.0099\n",
      "Epoch 244/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0158 - val_loss: 0.0078 - val_mae: 0.0146\n",
      "Epoch 245/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - mae: 0.0081 - val_loss: 0.0075 - val_mae: 0.0107\n",
      "Epoch 246/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - mae: 0.0075 - val_loss: 0.0073 - val_mae: 0.0064\n",
      "Epoch 247/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - mae: 0.0082 - val_loss: 0.0073 - val_mae: 0.0099\n",
      "Epoch 248/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - mae: 0.0191 - val_loss: 0.0101 - val_mae: 0.0493\n",
      "Epoch 249/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0301 - val_loss: 0.0079 - val_mae: 0.0229\n",
      "Epoch 250/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0215 - val_loss: 0.0072 - val_mae: 0.0137\n",
      "Epoch 251/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - mae: 0.0129 - val_loss: 0.0076 - val_mae: 0.0222\n",
      "Epoch 252/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - mae: 0.0167 - val_loss: 0.0069 - val_mae: 0.0122\n",
      "Epoch 253/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - mae: 0.0087 - val_loss: 0.0067 - val_mae: 0.0090\n",
      "Epoch 254/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - mae: 0.0079 - val_loss: 0.0066 - val_mae: 0.0070\n",
      "Epoch 255/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - mae: 0.0147 - val_loss: 0.0072 - val_mae: 0.0232\n",
      "Epoch 256/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0286 - val_loss: 0.0077 - val_mae: 0.0301\n",
      "Epoch 257/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0337 - val_loss: 0.0071 - val_mae: 0.0238\n",
      "Epoch 258/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - mae: 0.0186 - val_loss: 0.0063 - val_mae: 0.0090\n",
      "Epoch 259/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0063 - mae: 0.0097 - val_loss: 0.0061 - val_mae: 0.0045\n",
      "Epoch 260/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0061 - mae: 0.0064 - val_loss: 0.0060 - val_mae: 0.0056\n",
      "Epoch 261/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0060 - mae: 0.0071 - val_loss: 0.0059 - val_mae: 0.0039\n",
      "Epoch 262/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0059 - mae: 0.0059 - val_loss: 0.0059 - val_mae: 0.0043\n",
      "Epoch 263/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0058 - mae: 0.0048 - val_loss: 0.0058 - val_mae: 0.0051\n",
      "Epoch 264/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0058 - mae: 0.0063 - val_loss: 0.0057 - val_mae: 0.0058\n",
      "Epoch 265/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0057 - mae: 0.0065 - val_loss: 0.0056 - val_mae: 0.0053\n",
      "Epoch 266/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0056 - mae: 0.0065 - val_loss: 0.0055 - val_mae: 0.0035\n",
      "Epoch 267/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0055 - mae: 0.0060 - val_loss: 0.0055 - val_mae: 0.0074\n",
      "Epoch 268/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0054 - mae: 0.0050 - val_loss: 0.0054 - val_mae: 0.0054\n",
      "Epoch 269/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0054 - mae: 0.0059 - val_loss: 0.0054 - val_mae: 0.0074\n",
      "Epoch 270/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0053 - mae: 0.0069 - val_loss: 0.0053 - val_mae: 0.0064\n",
      "Epoch 271/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0053 - mae: 0.0082 - val_loss: 0.0054 - val_mae: 0.0132\n",
      "Epoch 272/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0052 - mae: 0.0086 - val_loss: 0.0052 - val_mae: 0.0074\n",
      "Epoch 273/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0052 - mae: 0.0081 - val_loss: 0.0051 - val_mae: 0.0081\n",
      "Epoch 274/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0052 - mae: 0.0112 - val_loss: 0.0051 - val_mae: 0.0104\n",
      "Epoch 275/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0058 - mae: 0.0220 - val_loss: 0.0055 - val_mae: 0.0215\n",
      "Epoch 276/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0059 - mae: 0.0254 - val_loss: 0.0052 - val_mae: 0.0147\n",
      "Epoch 277/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0052 - mae: 0.0148 - val_loss: 0.0050 - val_mae: 0.0125\n",
      "Epoch 278/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0106 - val_loss: 0.0051 - val_mae: 0.0151\n",
      "Epoch 279/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0118 - val_loss: 0.0048 - val_mae: 0.0078\n",
      "Epoch 280/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0049 - mae: 0.0129 - val_loss: 0.0051 - val_mae: 0.0197\n",
      "Epoch 281/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0052 - mae: 0.0196 - val_loss: 0.0048 - val_mae: 0.0131\n",
      "Epoch 282/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0135 - val_loss: 0.0047 - val_mae: 0.0124\n",
      "Epoch 283/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0047 - mae: 0.0105 - val_loss: 0.0046 - val_mae: 0.0106\n",
      "Epoch 284/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0078 - val_loss: 0.0045 - val_mae: 0.0053\n",
      "Epoch 285/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0077 - val_loss: 0.0044 - val_mae: 0.0079\n",
      "Epoch 286/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0079 - val_loss: 0.0044 - val_mae: 0.0061\n",
      "Epoch 287/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0067 - val_loss: 0.0044 - val_mae: 0.0099\n",
      "Epoch 288/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0043 - mae: 0.0087 - val_loss: 0.0043 - val_mae: 0.0071\n",
      "Epoch 289/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0105 - val_loss: 0.0044 - val_mae: 0.0135\n",
      "Epoch 290/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0044 - mae: 0.0122 - val_loss: 0.0046 - val_mae: 0.0180\n",
      "Epoch 291/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0042 - mae: 0.0094 - val_loss: 0.0042 - val_mae: 0.0107\n",
      "Epoch 292/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0041 - mae: 0.0070 - val_loss: 0.0040 - val_mae: 0.0046\n",
      "Epoch 293/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0058 - val_loss: 0.0043 - val_mae: 0.0145\n",
      "Epoch 294/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0125 - val_loss: 0.0041 - val_mae: 0.0118\n",
      "Epoch 295/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0041 - mae: 0.0116 - val_loss: 0.0039 - val_mae: 0.0064\n",
      "Epoch 296/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0088 - val_loss: 0.0041 - val_mae: 0.0129\n",
      "Epoch 297/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0250 - val_loss: 0.0041 - val_mae: 0.0135\n",
      "Epoch 298/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0039 - mae: 0.0090 - val_loss: 0.0039 - val_mae: 0.0072\n",
      "Epoch 299/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0124 - val_loss: 0.0041 - val_mae: 0.0152\n",
      "Epoch 300/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0043 - mae: 0.0192 - val_loss: 0.0041 - val_mae: 0.0164\n",
      "Epoch 301/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0044 - mae: 0.0201 - val_loss: 0.0038 - val_mae: 0.0110\n",
      "Epoch 302/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0172 - val_loss: 0.0044 - val_mae: 0.0237\n",
      "Epoch 303/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0051 - mae: 0.0314 - val_loss: 0.0046 - val_mae: 0.0217\n",
      "Epoch 304/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0233 - val_loss: 0.0041 - val_mae: 0.0194\n",
      "Epoch 305/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0038 - mae: 0.0111 - val_loss: 0.0036 - val_mae: 0.0068\n",
      "Epoch 306/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0063 - val_loss: 0.0035 - val_mae: 0.0044\n",
      "Epoch 307/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0066 - val_loss: 0.0035 - val_mae: 0.0047\n",
      "Epoch 308/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0053 - val_loss: 0.0035 - val_mae: 0.0052\n",
      "Epoch 309/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0069 - val_loss: 0.0035 - val_mae: 0.0085\n",
      "Epoch 310/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0088 - val_loss: 0.0035 - val_mae: 0.0097\n",
      "Epoch 311/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0059 - val_loss: 0.0034 - val_mae: 0.0056\n",
      "Epoch 312/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0053 - val_loss: 0.0034 - val_mae: 0.0079\n",
      "Epoch 313/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0034 - mae: 0.0077 - val_loss: 0.0035 - val_mae: 0.0091\n",
      "Epoch 314/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0094 - val_loss: 0.0033 - val_mae: 0.0063\n",
      "Epoch 315/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0079 - val_loss: 0.0033 - val_mae: 0.0063\n",
      "Epoch 316/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0080 - val_loss: 0.0033 - val_mae: 0.0085\n",
      "Epoch 317/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0140 - val_loss: 0.0037 - val_mae: 0.0199\n",
      "Epoch 318/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0103 - val_loss: 0.0033 - val_mae: 0.0089\n",
      "Epoch 319/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0066 - val_loss: 0.0039 - val_mae: 0.0253\n",
      "Epoch 320/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0130 - val_loss: 0.0037 - val_mae: 0.0190\n",
      "Epoch 321/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0047 - mae: 0.0299 - val_loss: 0.0057 - val_mae: 0.0438\n",
      "Epoch 322/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0043 - mae: 0.0284 - val_loss: 0.0045 - val_mae: 0.0297\n",
      "Epoch 323/1000\n",
      "23/28 [=======================>......] - ETA: 0s - loss: 0.0042 - mae: 0.0264Restoring model weights from the end of the best epoch: 318.\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0041 - mae: 0.0253 - val_loss: 0.0038 - val_mae: 0.0249\n",
      "Epoch 323: early stopping\n",
      "Durchschnittlicher Validation Loss: 0.00715961754322052\n",
      "Durchschnittlicher Validation MAE: 0.003827093029394746\n"
     ]
    }
   ],
   "source": [
    "# Initialisiere Listen, um Ergebnisse zu speichern\n",
    "val_loss_results = []\n",
    "val_mae_results = []\n",
    "\n",
    "# Funktion, um das Modell zu erstellen\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "                Dense(264, activation='relu', input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "                Dense(232, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "                Dense(280, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "                Dense(264, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "                Dense(216, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "                Dense(72, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "                Dense(216, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "                Dense(88, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "                Dense(1 , activation = 'linear')\n",
    "\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# K-Fold Cross-Validation Konfiguration\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Leistungsüberwachung\n",
    "fold_no = 1\n",
    "for train_index, val_index in kf.split(X_train_scaled):\n",
    "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_scaled[train_index], y_train_scaled[val_index]\n",
    "\n",
    "    model = create_model()\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "    print(f'Training für Fold {fold_no}...')\n",
    "    history = model.fit(X_train_fold, y_train_fold, batch_size=25, epochs=1000, validation_data=(X_val_fold, y_val_fold), callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "    # Speichere die Ergebnisse des aktuellen Folds\n",
    "    val_loss_results.append(min(history.history['val_loss']))\n",
    "    val_mae_results.append(min(history.history['val_mae']))\n",
    "\n",
    "    fold_no += 1\n",
    "\n",
    "# Berechne den Durchschnitt über alle Folds\n",
    "average_val_loss = np.mean(val_loss_results)\n",
    "average_val_mae = np.mean(val_mae_results)\n",
    "\n",
    "# Umwandeln der Listen in Pandas DataFrames\n",
    "val_loss_df = pd.DataFrame(val_loss_results, columns=['Validation Loss'])\n",
    "val_mae_df = pd.DataFrame(val_mae_results, columns=['Validation MAE'])\n",
    "\n",
    "# Speichern der DataFrames in CSV-Dateien\n",
    "val_loss_df.to_csv('val_loss_results_D4_1.csv', index=False)\n",
    "val_mae_df.to_csv('val_mae_results_D4_1.csv', index=False)\n",
    "\n",
    "# Gib die durchschnittlichen Ergebnisse aus\n",
    "print(f'Durchschnittlicher Validation Loss: {average_val_loss}')\n",
    "print(f'Durchschnittlicher Validation MAE: {average_val_mae}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T17:22:22.297813300Z",
     "start_time": "2024-03-26T17:19:49.878641200Z"
    }
   },
   "id": "72bddbbf84e85540"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 - 0s - loss: 0.0066 - mae: 0.0049 - 28ms/epoch - 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.006550399120897055, 0.004935364238917828]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modellevaluierung\n",
    "results = model.evaluate(X_test_scaled, y_test_scaled, verbose=2)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T10:17:13.431978800Z",
     "start_time": "2024-03-27T10:17:13.360927200Z"
    }
   },
   "id": "4b02697cbcecd185"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bsp. Predicted: [1147.8893] Actual: [1148.8] \n",
      "Durchschnittliche Abweichung (MAE): [4.6652046]\n",
      "0.49438164044155375\n"
     ]
    }
   ],
   "source": [
    "#Rückrechnung des skalierten MAE zum unskalierten MAE für eines bessere Einschätzung des Ergebnisses\n",
    "scaled_predicted_values = model.predict(X_test_scaled, verbose = 0)\n",
    "\n",
    "# Führen Sie die Rücktransformation der skalierten Werte durch\n",
    "original_predicted_values = scaler_target.inverse_transform(scaled_predicted_values)\n",
    "original_actual_values = scaler_target.inverse_transform(y_test_scaled)  # y_test sind die skalierten tatsächlichen Werte\n",
    "print(f' Bsp. Predicted: {original_predicted_values[100]} Actual: {original_actual_values[100]} ')\n",
    "\n",
    "def calculate_mae(list1, list2):\n",
    "    # Stelle sicher, dass beide Listen die gleiche Länge haben\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Listen müssen die gleiche Länge haben\")\n",
    "\n",
    "    # Berechne die absolute Differenz zwischen den Elementen der Listen\n",
    "    differences = [abs(x - y) for x, y in zip(list1, list2)]\n",
    "\n",
    "    # Berechne den Durchschnitt der absoluten Differenzen\n",
    "    mae = sum(differences) / len(differences)\n",
    "\n",
    "    return mae\n",
    "\n",
    "# Beispiel\n",
    "list1 = original_predicted_values\n",
    "list2 = original_actual_values\n",
    "\n",
    "mse = calculate_mae(list1, list2)\n",
    "print(f\"Durchschnittliche Abweichung (MAE): {mse}\")\n",
    "\n",
    "# Berechnung des MAPE\n",
    "errors = np.abs((original_actual_values - original_predicted_values) / original_actual_values)\n",
    "mape = np.mean(errors) * 100\n",
    "print(mape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T10:17:14.703152500Z",
     "start_time": "2024-03-27T10:17:14.536509800Z"
    }
   },
   "id": "a402d28abbd82f60"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: [0.99930726]\n"
     ]
    }
   ],
   "source": [
    "# Berechnung der Auswertungsgröße R^2\n",
    "def calculate_r_squared(predicted, actual):\n",
    "    # Berechnung des Mittelwerts der tatsächlichen Werte\n",
    "    mean_actual = sum(actual) / len(actual)\n",
    "    \n",
    "    # Berechnung der totalen Summe der Quadrate (SST)\n",
    "    sst = sum((x - mean_actual) ** 2 for x in actual)\n",
    "    \n",
    "    # Berechnung der Summe der Quadrate der Residuen (SSE)\n",
    "    sse = sum((actual[i] - predicted[i]) ** 2 for i in range(len(actual)))\n",
    "    \n",
    "    # Berechnung des R^2-Wertes\n",
    "    r_squared = 1 - (sse / sst)\n",
    "    \n",
    "    return r_squared\n",
    "\n",
    "# Berechnung von R^2 mit den bereitgestellten Listen\n",
    "r_squared = calculate_r_squared(list1, list2)\n",
    "\n",
    "print(f\"R^2: {r_squared}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T10:17:19.114418900Z",
     "start_time": "2024-03-27T10:17:19.111407300Z"
    }
   },
   "id": "2820df0b9f03b675"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plotting des Trainingsprozesses"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ace5b5c4d3c5033"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIjCAYAAAA0vUuxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB4SUlEQVR4nO3dd3wUdf7H8ffuJtkkpEJCEiAQei/SYuQAS5SiKFZElCKnJyKeh9wpFpr+xFNPOQVFEcGGIB5YAQUEVIiCIFVA6TWBUNKTTXbn90dkZU1IkSSzgdfz8ZhHdme+M/uZyYq8+X7nOxbDMAwBAAAAAM7JanYBAAAAAODtCE4AAAAAUAqCEwAAAACUguAEAAAAAKUgOAEAAABAKQhOAAAAAFAKghMAAAAAlILgBAAAAAClIDgBAAAAQCkITgDgpYYOHaq4uLg/te+ECRNksVgqtiAvs2/fPlksFs2ePbvKP9tisWjChAnu97Nnz5bFYtG+fftK3TcuLk5Dhw6t0HrO57sCACgbghMAlJPFYinTsnLlSrNLveg9+OCDslgs2rVr1znbPP7447JYLNq8eXMVVlZ+R44c0YQJE7Rx40azS3E7E14tFouefvrpYtsMGjRIFotFQUFBHutdLpfeeecdxcfHq2bNmgoODlazZs00ePBgff/99+52K1euLPG/s7lz51bqOQLAGT5mFwAA1c27777r8f6dd97R0qVLi6xv2bLleX3OjBkz5HK5/tS+TzzxhB599NHz+vwLwaBBg/TKK69ozpw5GjduXLFtPvjgA7Vt21bt2rX7059z11136fbbb5fdbv/TxyjNkSNHNHHiRMXFxalDhw4e287nu1IR/P399cEHH+iJJ57wWJ+VlaVPPvlE/v7+RfZ58MEHNW3aNN1www0aNGiQfHx8tHPnTi1evFiNGjXSpZdeWqR9ly5dihwnISGhYk8GAM6B4AQA5XTnnXd6vP/++++1dOnSIuv/KDs7W4GBgWX+HF9f3z9VnyT5+PjIx4c/4uPj49WkSRN98MEHxQanpKQk7d27V88+++x5fY7NZpPNZjuvY5yP8/muVIS+fftqwYIF2rRpk9q3b+9e/8knn8jhcKh37976+uuv3etTUlL06quv6p577tEbb7zhcawpU6bo+PHjRT6je/fuuuWWWyrvJACgFAzVA4BKcPnll6tNmzZav369evToocDAQD322GOSCv8yee2116pOnTqy2+1q3LixnnrqKTmdTo9j/PG+lTPDol544QW98cYbaty4sex2u7p06aJ169Z57FvcPU4Wi0UPPPCAPv74Y7Vp00Z2u12tW7fWkiVLitS/cuVKde7cWf7+/mrcuLFef/31Mt839e233+rWW29V/fr1ZbfbFRsbq3/84x/Kyckpcn5BQUE6fPiw+vfvr6CgIEVGRmrMmDFFrsXp06c1dOhQhYaGKiwsTEOGDNHp06dLrUUq7HXasWOHNmzYUGTbnDlzZLFYNHDgQDkcDo0bN06dOnVSaGioatSooe7du2vFihWlfkZx9zgZhqGnn35a9erVU2BgoK644gpt27atyL4nT57UmDFj1LZtWwUFBSkkJER9+vTRpk2b3G1Wrlzp7m0ZNmyYe5jamfu7irvHKSsrSw8//LBiY2Nlt9vVvHlzvfDCCzIMw6Ndeb4X55KQkKCGDRtqzpw5Huvff/999e7dWzVr1vRYv3fvXhmGoW7duhU5lsViUe3atcv82QBQVfjnSACoJCdOnFCfPn10++23684771RUVJSkwr9kBwUFafTo0QoKCtLXX3+tcePGKT09Xc8//3ypx50zZ44yMjL0t7/9TRaLRc8995xuuukm7dmzp9Seh++++04LFizQ/fffr+DgYL388su6+eabdeDAAdWqVUuS9NNPP6l3796KiYnRxIkT5XQ6NWnSJEVGRpbpvOfPn6/s7GyNGDFCtWrV0tq1a/XKK6/o0KFDmj9/vkdbp9OpXr16KT4+Xi+88IKWLVum//znP2rcuLFGjBghqTCA3HDDDfruu+903333qWXLllq4cKGGDBlSpnoGDRqkiRMnas6cOerYsaPHZ3/44Yfq3r276tevr9TUVL355psaOHCg7rnnHmVkZGjmzJnq1auX1q5dW2R4XGnGjRunp59+Wn379lXfvn21YcMGXXPNNXI4HB7t9uzZo48//li33nqrGjZsqJSUFL3++uvq2bOnfv75Z9WpU0ctW7bUpEmTNG7cON17773q3r27JOmyyy4r9rMNw9D111+vFStWaPjw4erQoYO+/PJL/fOf/9Thw4f10ksvebQvy/eiNAMHDtR7772nZ599VhaLRampqfrqq6/07rvvFglhDRo0kFT4Xbn11lvL1BObkZGh1NTUIutr1ap1wU+EAsBLGACA8zJy5Ejjj3+c9uzZ05BkTJ8+vUj77OzsIuv+9re/GYGBgUZubq573ZAhQ4wGDRq43+/du9eQZNSqVcs4efKke/0nn3xiSDI+++wz97rx48cXqUmS4efnZ+zatcu9btOmTYYk45VXXnGv69evnxEYGGgcPnzYve7XX381fHx8ihyzOMWd3+TJkw2LxWLs37/f4/wkGZMmTfJoe8kllxidOnVyv//4448NScZzzz3nXldQUGB0797dkGTMmjWr1Jq6dOli1KtXz3A6ne51S5YsMSQZr7/+uvuYeXl5HvudOnXKiIqKMu6++26P9ZKM8ePHu9/PmjXLkGTs3bvXMAzDOHbsmOHn52dce+21hsvlcrd77LHHDEnGkCFD3Otyc3M96jKMwt+13W73uDbr1q075/n+8bty5po9/fTTHu1uueUWw2KxeHwHyvq9KM6Z7+Tzzz9vbN261ZBkfPvtt4ZhGMa0adOMoKAgIysryxgyZIhRo0YNj30HDx5sSDLCw8ONG2+80XjhhReM7du3F/mMFStWGJLOuRw9erTEGgGgojBUDwAqid1u17Bhw4qsDwgIcL8+86/o3bt3V3Z2tnbs2FHqcQcMGKDw8HD3+zO9D3v27Cl138TERDVu3Nj9vl27dgoJCXHv63Q6tWzZMvXv31916tRxt2vSpIn69OlT6vElz/PLyspSamqqLrvsMhmGoZ9++qlI+/vuu8/jfffu3T3OZdGiRfLx8XH3QEmF9xSNGjWqTPVIhfelHTp0SN9884173Zw5c+Tn56dbb73VfUw/Pz9JhTO+nTx5UgUFBercuXOxw/xKsmzZMjkcDo0aNcqjN+Shhx4q0tZut8tqLfzfsdPp1IkTJxQUFKTmzZuX+3PPWLRokWw2mx588EGP9Q8//LAMw9DixYs91pf2vSiL1q1bq127dvrggw8kFV7fG2644Zy9SbNmzdLUqVPVsGFDLVy4UGPGjFHLli111VVX6fDhw0Xajxs3TkuXLi2y/HEYIABUFoITAFSSunXruv8ifrZt27bpxhtvVGhoqEJCQhQZGemeWCItLa3U49avX9/j/ZkQderUqXLve2b/M/seO3ZMOTk5atKkSZF2xa0rzoEDBzR06FDVrFnTfd9Sz549JRU9P39//yJDAM+uR5L279+vmJiYItNZN2/evEz1SNLtt98um83mvgcnNzdXCxcuVJ8+fTxC6Ntvv6127drJ399ftWrVUmRkpL744osy/V7Otn//fklS06ZNPdZHRkZ6fJ5UGNJeeuklNW3aVHa7XREREYqMjNTmzZvL/blnf36dOnUUHBzssf7MTI9n6jujtO9FWd1xxx2aP3++du3apTVr1uiOO+44Z1ur1aqRI0dq/fr1Sk1N1SeffKI+ffro66+/1u23316kfdu2bZWYmFhkKe6/MQCoDAQnAKgkZ/e8nHH69Gn17NlTmzZt0qRJk/TZZ59p6dKl+ve//y1JZZpS+lyztxl/uOm/ovctC6fTqauvvlpffPGFHnnkEX388cdaunSpexKDP55fVc1EV7t2bV199dX63//+p/z8fH322WfKyMjQoEGD3G3ee+89DR06VI0bN9bMmTO1ZMkSLV26VFdeeWWlTvX9zDPPaPTo0erRo4fee+89ffnll1q6dKlat25dZVOMV9T3YuDAgUpNTdU999yjWrVq6ZprrinTfrVq1dL111+vRYsWqWfPnvruu++KhDsAMBuTQwBAFVq5cqVOnDihBQsWqEePHu71e/fuNbGq39WuXVv+/v7FPjC2pIfInrFlyxb98ssvevvttzV48GD3+qVLl/7pmho0aKDly5crMzPTo9dp586d5TrOoEGDtGTJEi1evFhz5sxRSEiI+vXr597+0UcfqVGjRlqwYIHH8Lrx48f/qZol6ddff1WjRo3c648fP16kF+ejjz7SFVdcoZkzZ3qsP336tCIiItzvyzMBQoMGDbRs2TJlZGR49DqdGQp6pr6KVr9+fXXr1k0rV67UiBEj/tSU+J07d9aqVat09OjRSqsTAP4MepwAoAqd+Zf9s/8l3+Fw6NVXXzWrJA82m02JiYn6+OOPdeTIEff6Xbt2Fbkv5lz7S57nZxiG/vvf//7pmvr27auCggK99tpr7nVOp1OvvPJKuY7Tv39/BQYG6tVXX9XixYt10003eTyYtbjaf/jhByUlJZW75sTERPn6+uqVV17xON6UKVOKtLXZbEV6dubPn1/kPp8aNWpIUpmmYe/bt6+cTqemTp3qsf6ll16SxWIp8/1qf8bTTz+t8ePHl3gPWnJysn7++eci6x0Oh5YvXy6r1VrmoaEAUFXocQKAKnTZZZcpPDxcQ4YM0YMPPiiLxaJ33323wobKVYQJEyboq6++Urdu3TRixAj3X8DbtGmjjRs3lrhvixYt1LhxY40ZM0aHDx9WSEiI/ve//5X7Xpmz9evXT926ddOjjz6qffv2qVWrVlqwYEG57/8JCgpS//793fc5nT1MT5Kuu+46LViwQDfeeKOuvfZa7d27V9OnT1erVq2UmZlZrs868zyqyZMn67rrrlPfvn31008/afHixR69SGc+d9KkSRo2bJguu+wybdmyRe+//75HT5UkNW7cWGFhYZo+fbqCg4NVo0YNxcfHq2HDhkU+v1+/frriiiv0+OOPa9++fWrfvr2++uorffLJJ3rooYc8JoKoaD179nTf03Yuhw4dUteuXXXllVfqqquuUnR0tI4dO6YPPvhAmzZt0kMPPVTkOn377bfKzc0tcqx27dqpXbt2FXoOAFAcghMAVKFatWrp888/18MPP6wnnnhC4eHhuvPOO3XVVVepV69eZpcnSerUqZMWL16sMWPG6Mknn1RsbKwmTZqk7du3lzrrn6+vrz777DM9+OCDmjx5svz9/XXjjTfqgQceUPv27f9UPVarVZ9++qkeeughvffee7JYLLr++uv1n//8R5dcckm5jjVo0CDNmTNHMTExuvLKKz22DR06VMnJyXr99df15ZdfqlWrVnrvvfc0f/58rVy5stx1P/300/L399f06dO1YsUKxcfH66uvvtK1117r0e6xxx5TVlaW5syZo3nz5qljx4764osv9Oijj3q08/X11dtvv62xY8fqvvvuU0FBgWbNmlVscDpzzcaNG6d58+Zp1qxZiouL0/PPP6+HH3643OdS0Zo3b64pU6Zo0aJFevXVV5WSkiJ/f3+1adNGM2bM0PDhw4vs8/LLLxd7rPHjxxOcAFQJi+FN/8wJAPBa/fv317Zt2/Trr7+aXQoAAFWOe5wAAEXk5OR4vP/111+1aNEiXX755eYUBACAyehxAgAUERMTo6FDh6pRo0bav3+/XnvtNeXl5emnn34q8mwiAAAuBtzjBAAoonfv3vrggw+UnJwsu92uhIQEPfPMM4QmAMBFix4nAAAAACgF9zgBAAAAQCm8IjhNmzZNcXFx8vf3V3x8vNauXXvOtpdffrksFkuR5Y/TuwIAAABARTH9Hqd58+Zp9OjRmj59uuLj4zVlyhT16tVLO3fuVO3atYu0X7BggRwOh/v9iRMn1L59e916661l+jyXy6UjR44oODhYFoulws4DAAAAQPViGIYyMjJUp04dWa2l9CkZJuvatasxcuRI93un02nUqVPHmDx5cpn2f+mll4zg4GAjMzOzTO0PHjxoSGJhYWFhYWFhYWFhYTEkGQcPHiw1R5ja4+RwOLR+/XqNHTvWvc5qtSoxMVFJSUllOsbMmTN1++23q0aNGsVuz8vLU15envu98dtcGAcPHlRISMh5VA8AAACgOktPT1dsbKyCg4NLbWtqcEpNTZXT6VRUVJTH+qioKO3YsaPU/deuXautW7dq5syZ52wzefJkTZw4scj6kJAQghMAAACAMt3C4xWTQ/xZM2fOVNu2bdW1a9dzthk7dqzS0tLcy8GDB6uwQgAAAAAXAlN7nCIiImSz2ZSSkuKxPiUlRdHR0SXum5WVpblz52rSpEkltrPb7bLb7eddKwAAAICLl6k9Tn5+furUqZOWL1/uXudyubR8+XIlJCSUuO/8+fOVl5enO++8s7LLBAAAAHCRM3068tGjR2vIkCHq3LmzunbtqilTpigrK0vDhg2TJA0ePFh169bV5MmTPfabOXOm+vfvr1q1aplRNgAAACqY0+lUfn6+2WXgAuPr6yubzXbexzE9OA0YMEDHjx/XuHHjlJycrA4dOmjJkiXuCSMOHDhQZE71nTt36rvvvtNXX31lRskAAACoYJmZmTp06JB7BmSgolgsFtWrV09BQUHndxzjIvt2pqenKzQ0VGlpacyqBwAA4AWcTqd+/fVXBQYGKjIyskwznAFlYRiGjh8/ruzsbDVt2rRIz1N5soHpPU4AAAC4uOXn58swDEVGRiogIMDscnCBiYyM1L59+5Sfn39eQ/aq9XTkAAAAuHDQ04TKUFHfK4ITAAAAAJSC4AQAAAAApSA4AQAAAF4iLi5OU6ZMKXP7lStXymKx6PTp05VWEwoRnAAAAIByslgsJS4TJkz4U8ddt26d7r333jK3v+yyy3T06FGFhob+qc8rqzMBLTw8XLm5uR7b1q1b5z7vs82YMUPt27dXUFCQwsLCdMkll3g8m3XChAnFXrsWLVpU6rn8WcyqBwAAAJTT0aNH3a/nzZuncePGaefOne51Zz8zyDAMOZ1O+fiU/lfvyMjIctXh5+en6Ojocu1zPoKDg7Vw4UINHDjQvW7mzJmqX7++Dhw44F731ltv6aGHHtLLL7+snj17Ki8vT5s3b9bWrVs9jte6dWstW7bMY11ZrpMZ6HECAACAdzEMKSvLnKWMjziNjo52L6GhobJYLO73O3bsUHBwsBYvXqxOnTrJbrfru+++0+7du3XDDTcoKipKQUFB6tKlS5HQ8MehehaLRW+++aZuvPFGBQYGqmnTpvr000/d2/84VG/27NkKCwvTl19+qZYtWyooKEi9e/f2CHoFBQV68MEHFRYWplq1aumRRx7RkCFD1L9//1LPe8iQIXrrrbfc73NycjR37lwNGTLEo92nn36q2267TcOHD1eTJk3UunVrDRw4UP/3f//n0c7Hx8fjWkZHRysiIqLUOsxAcAIAAIB3yc6WgoLMWbKzK+w0Hn30UT377LPavn272rVrp8zMTPXt21fLly/XTz/9pN69e6tfv34ePTXFmThxom677TZt3rxZffv21aBBg3Ty5MkSLl+2XnjhBb377rv65ptvdODAAY0ZM8a9/d///rfef/99zZo1S6tXr1Z6ero+/vjjMp3TXXfdpW+//dZd8//+9z/FxcWpY8eOHu2io6P1/fffa//+/WU6bnVAcAIAAAAqwaRJk3T11VercePGqlmzptq3b6+//e1vatOmjZo2baqnnnpKjRs39uhBKs7QoUM1cOBANWnSRM8884wyMzO1du3ac7bPz8/X9OnT1blzZ3Xs2FEPPPCAli9f7t7+yiuvaOzYsbrxxhvVokULTZ06VWFhYWU6p9q1a6tPnz6aPXu2pMIheXfffXeRduPHj1dYWJji4uLUvHlzDR06VB9++KFcLpdHuy1btigoKMhjue+++8pUS1XzzgGEF4utW6WdO6WmTaV27cyuBgAAwDsEBkqZmeZ9dgXp3Lmzx/vMzExNmDBBX3zxhY4ePaqCggLl5OSU2uPU7qy/J9aoUUMhISE6duzYOdsHBgaqcePG7vcxMTHu9mlpaUpJSVHXrl3d2202mzp16lQk1JzL3Xffrb///e+68847lZSUpPnz5+vbb7/1aBMTE6OkpCRt3bpV33zzjdasWaMhQ4bozTff1JIlS2S1FvbfNG/evEhwDAkJKVMdVY3gZKa335ZeeEEaM0Z6/nmzqwEAAPAOFotUo4bZVZy3Gn84hzFjxmjp0qV64YUX1KRJEwUEBOiWW26Rw+Eo8Ti+vr4e7y0WS4khp7j2Rhnv3SqLPn366N5779Xw4cPVr18/1apV65xt27RpozZt2uj+++/Xfffdp+7du2vVqlW64oorJBVObtGkSZMKq60yMVTPTDZb4U+n09w6AAAAUOlWr16toUOH6sYbb1Tbtm0VHR2tffv2VWkNoaGhioqK0rp169zrnE6nNmzYUOZj+Pj4aPDgwVq5cmWxw/TOpVWrVpKkrKysshfsRehxMhPBCQAA4KLRtGlTLViwQP369ZPFYtGTTz5Z5uFxFWnUqFGaPHmymjRpohYtWuiVV17RqVOnijyHqSRPPfWU/vnPf56zt2nEiBGqU6eOrrzyStWrV09Hjx7V008/rcjISCUkJLjbFRQUKDk52WNfi8WiqKioP3dylYjgZCaCEwAAwEXjxRdf1N13363LLrtMEREReuSRR5Senl7ldTzyyCNKTk7W4MGDZbPZdO+996pXr16ynfm7aRn4+fmVOG14YmKi3nrrLb322ms6ceKEIiIilJCQoOXLl3uErW3btikmJsZjX7vdXuQhu97AYlTkgMdqID09XaGhoUpLSzP/xrMJE6SJE6URI6RXXzW3FgAAAJPk5uZq7969atiwofz9/c0u56LjcrnUsmVL3XbbbXrqqafMLqfClfT9Kk82oMfJTPQ4AQAAoIrt379fX331lXr27Km8vDxNnTpVe/fu1R133GF2aV6NySHMRHACAABAFbNarZo9e7a6dOmibt26acuWLVq2bJlatmxpdmlejR4nMxGcAAAAUMViY2O1evVqs8uoduhxMtOZ4GTCbCoAAAAAyo7gZKbfnphMjxMAAADg3QhOZmKoHgAAAFAtEJzMRHACAAAAqgWCk5kITgAAAEC1QHAyE5NDAAAAANUCwclMTA4BAABwUbv88sv10EMPud/HxcVpypQpJe5jsVj08ccfn/dnV9RxLhYEJzMxVA8AAKBa6tevn3r37l3stm+//VYWi0WbN28u93HXrVune++993zL8zBhwgR16NChyPqjR4+qT58+FfpZfzR79mxZLJZiH647f/58WSwWxcXFudc5nU49++yzatGihQICAlSzZk3Fx8frzTffdLcZOnSoLBZLkeVcv4+KwgNwzURwAgAAqJaGDx+um2++WYcOHVK9evU8ts2aNUudO3dWu3btyn3cyMjIiiqxVNHR0VXyOTVq1NCxY8eUlJSkhIQE9/qZM2eqfv36Hm0nTpyo119/XVOnTlXnzp2Vnp6uH3/8UadOnfJo17t3b82aNctjnd1ur7yTED1O5iI4AQAAFGEYUlaWOYthlK3G6667TpGRkZo9e7bH+szMTM2fP1/Dhw/XiRMnNHDgQNWtW1eBgYFq27atPvjggxKP+8eher/++qt69Oghf39/tWrVSkuXLi2yzyOPPKJmzZopMDBQjRo10pNPPqn8/HxJhT0+EydO1KZNm9w9M2dq/uNQvS1btujKK69UQECAatWqpXvvvVeZmZnu7UOHDlX//v31wgsvKCYmRrVq1dLIkSPdn3UuPj4+uuOOO/TWW2+51x06dEgrV67UHXfc4dH2008/1f33369bb71VDRs2VPv27TV8+HCNGTPGo53dbld0dLTHEh4eXmId54seJzOduceJySEAAADcsrOloCBzPjszU6pRo/R2Pj4+Gjx4sGbPnq3HH39cFotFUuHwM6fTqYEDByozM1OdOnXSI488opCQEH3xxRe666671LhxY3Xt2rXUz3C5XLrpppsUFRWlH374QWlpaR73Q50RHBys2bNnq06dOtqyZYvuueceBQcH61//+pcGDBigrVu3asmSJVq2bJkkKTQ0tMgxsrKy1KtXLyUkJGjdunU6duyY/vrXv+qBBx7wCIcrVqxQTEyMVqxYoV27dmnAgAHq0KGD7rnnnhLP5e6779bll1+u//73vwoMDNTs2bPVu3dvRUVFebSLjo7W119/rfvvv79Ke9/Kgh4nM9HjBAAAUG3dfffd2r17t1atWuVeN2vWLN18880KDQ1V3bp1NWbMGHXo0EGNGjXSqFGj1Lt3b3344YdlOv6yZcu0Y8cOvfPOO2rfvr169OihZ555pki7J554Qpdddpni4uLUr18/jRkzxv0ZAQEBCgoKko+Pj7tnJiAgoMgx5syZo9zcXL3zzjtq06aNrrzySk2dOlXvvvuuUlJS3O3Cw8M1depUtWjRQtddd52uvfZaLV++vNRzueSSS9SoUSN99NFHMgxDs2fP1t13312k3Ysvvqjjx48rOjpa7dq103333afFixcXaff5558rKCjIYynu2lQkepzMRHACAAAoIjCwsOfHrM8uqxYtWuiyyy7TW2+9pcsvv1y7du3St99+q0mTJkkqnOjgmWee0YcffqjDhw/L4XAoLy9PgWX8kO3btys2NlZ16tRxrzv7HqEz5s2bp5dfflm7d+9WZmamCgoKFBISUvYT+e2z2rdvrxpndbd169ZNLpdLO3fudPcMtW7dWrYzf4eVFBMToy1btpTpM+6++27NmjVL9evXV1ZWlvr27aupU6d6tGnVqpW2bt2q9evXa/Xq1frmm2/Ur18/DR061GOCiCuuuEKvvfaax741a9Ys1zmXF8HJTAQnAACAIiyWsg2X8wbDhw/XqFGjNG3aNM2aNUuNGzdWz549JUnPP/+8/vvf/2rKlClq27atatSooYceekgOh6PCPj8pKUmDBg3SxIkT1atXL4WGhmru3Ln6z3/+U2GfcTZfX1+P9xaLRa4y3nYyaNAg/etf/9KECRN01113ycen+ChitVrVpUsXdenSRQ899JDee+893XXXXXr88cfVsGFDSYUTTjRp0uT8TqacGKpnJh6ACwAAUK3ddtttslqtmjNnjt555x3dfffd7vudVq9erRtuuEF33nmn2rdvr0aNGumXX34p87FbtmypgwcP6ujRo+5133//vUebNWvWqEGDBnr88cfVuXNnNW3aVPv37/do4+fnJ2cp/1DfsmVLbdq0SVlZWe51q1evltVqVfPmzctcc0lq1qyp66+/XqtWrSp2mN65tGrVSpI8ajMDwclMPAAXAACgWgsKCtKAAQM0duxYHT16VEOHDnVva9q0qZYuXao1a9Zo+/bt+tvf/uZxv1BpEhMT1axZMw0ZMkSbNm3St99+q8cff9yjTdOmTXXgwAHNnTtXu3fv1ssvv6yFCxd6tImLi9PevXu1ceNGpaamKi8vr8hnDRo0SP7+/hoyZIi2bt2qFStWaNSoUbrrrruKTOBwPmbPnq3U1FS1aNGi2O233HKLXnrpJf3www/av3+/Vq5cqZEjR6pZs2Ye++Tl5Sk5OdljSU1NrbA6i0NwMhND9QAAAKq94cOH69SpU+rVq5fH/UhPPPGEOnbsqF69eunyyy9XdHS0+vfvX+bjWq1WLVy4UDk5Oeratav++te/6v/+7/882lx//fX6xz/+oQceeEAdOnTQmjVr9OSTT3q0ufnmm9W7d29dccUVioyMLHZK9MDAQH355Zc6efKkunTpoltuuUVXXXVVkXuQzteZqc7PpVevXvrss8/Ur18/d2hs0aKFvvrqK4+hfUuWLFFMTIzH8pe//KVCa/0ji2GUdbb6C0N6erpCQ0OVlpZW7pvmKtzSpdI110jt2kmbNplbCwAAgElyc3O1d+9eNWzYUP7+/maXgwtMSd+v8mQDepzMRI8TAAAAUC0QnMzEA3ABAACAaoHgZCZ6nAAAAIBqgeBkJoITAAAAUC0QnMxEcAIAAHC7yOYsQxWpqO8VwclMPAAXAABAtt/+TuRwOEyuBBeiM9+rM9+zP8un9CaoNDwAFwAAQD4+PgoMDNTx48fl6+srq5V/20fFcLlcOn78uAIDAz2eA/VnEJzMxFA9AAAAWSwWxcTEaO/evdq/f7/Z5eACY7VaVb9+fVkslvM6DsHJTAQnAAAASZKfn5+aNm3KcD1UOD8/vwrpxSQ4mYngBAAA4Ga1WuXv7292GUCxGEBqJiaHAAAAAKoFgpOZmBwCAAAAqBYITmZiqB4AAABQLRCczERwAgAAAKoFgpOZCE4AAABAtWB6cJo2bZri4uLk7++v+Ph4rV27tsT2p0+f1siRIxUTEyO73a5mzZpp0aJFVVRtBTtzjxOTQwAAAABezdTpyOfNm6fRo0dr+vTpio+P15QpU9SrVy/t3LlTtWvXLtLe4XDo6quvVu3atfXRRx+pbt262r9/v8LCwqq++Ipw9qx6hiGd50O5AAAAAFQOi2EYhlkfHh8fry5dumjq1KmSJJfLpdjYWI0aNUqPPvpokfbTp0/X888/rx07dsjX1/dPfWZ6erpCQ0OVlpamkJCQ86r/vJ04IUVEFL4uKPg9SAEAAACodOXJBqYN1XM4HFq/fr0SExN/L8ZqVWJiopKSkord59NPP1VCQoJGjhypqKgotWnTRs8884ycJdwjlJeXp/T0dI/Fa5wdlLjPCQAAAPBapgWn1NRUOZ1ORUVFeayPiopScnJysfvs2bNHH330kZxOpxYtWqQnn3xS//nPf/T000+f83MmT56s0NBQ9xIbG1uh53Fezg5O3OcEAAAAeC3TJ4coD5fLpdq1a+uNN95Qp06dNGDAAD3++OOaPn36OfcZO3as0tLS3MvBgwersOJSWM+6/PQ4AQAAAF7LtMkhIiIiZLPZlJKS4rE+JSVF0dHRxe4TExMjX19f2c7qqWnZsqWSk5PlcDjk5+dXZB+73S673V6xxVcUhuoBAAAA1YJpPU5+fn7q1KmTli9f7l7ncrm0fPlyJSQkFLtPt27dtGvXLrnOGtb2yy+/KCYmptjQ5PUITgAAAEC1YOpQvdGjR2vGjBl6++23tX37do0YMUJZWVkaNmyYJGnw4MEaO3asu/2IESN08uRJ/f3vf9cvv/yiL774Qs8884xGjhxp1imcH4ITAAAAUC2Y+hynAQMG6Pjx4xo3bpySk5PVoUMHLVmyxD1hxIEDB2Q96z6g2NhYffnll/rHP/6hdu3aqW7duvr73/+uRx55xKxTOD9n3+PE5BAAAACA1zL1OU5m8KrnOEmFvU4ul3TkiBQTY3Y1AAAAwEWjWjzHCb85M1yPoXoAAACA1yI4mY3gBAAAAHg9gpPZCE4AAACA1yM4me3MBBFMDgEAAAB4LYKT2ehxAgAAALwewclsBCcAAADA6xGczEZwAgAAALwewclsZ4IT9zgBAAAAXovgZLYzk0PQ4wQAAAB4LYKT2RiqBwAAAHg9gpPZCE4AAACA1yM4mY3gBAAAAHg9gpPZeAAuAAAA4PUITmajxwkAAADwegQnsxGcAAAAAK9HcDIbwQkAAADwegQns/EAXAAAAMDrEZzMxgNwAQAAAK9HcDIbQ/UAAAAAr0dwMhvBCQAAAPB6BCezEZwAAAAAr0dwMhuTQwAAAABej+BkNiaHAAAAALwewclsDNUDAAAAvB7ByWwEJwAAAMDrEZzMRnACAAAAvB7ByWxn7nFicggAAADAaxGczEaPEwAAAOD1CE5mIzgBAAAAXo/gZDaCEwAAAOD1CE5m4wG4AAAAgNcjOJmNB+ACAAAAXo/gZDaG6gEAAABej+BkNoITAAAA4PUITmYjOAEAAABej+BkNh6ACwAAAHg9gpPZ6HECAAAAvB7ByWwEJwAAAMDrEZzMRnACAAAAvB7ByWwEJwAAAMDrEZzMxuQQAAAAgNcjOJmNHicAAADA6xGczEZwAgAAALwewclsBCcAAADA6xGczHYmOHGPEwAAAOC1CE5mOzM5BD1OAAAAgNciOJmNoXoAAACA1yM4mY3gBAAAAHg9gpPZCE4AAACA1yM4mY0H4AIAAABej+BkNnqcAAAAAK9HcDIbwQkAAADwel4RnKZNm6a4uDj5+/srPj5ea9euPWfb2bNny2KxeCz+/v5VWG0FIzgBAAAAXs/04DRv3jyNHj1a48eP14YNG9S+fXv16tVLx44dO+c+ISEhOnr0qHvZv39/FVZcwXgALgAAAOD1TA9OL774ou655x4NGzZMrVq10vTp0xUYGKi33nrrnPtYLBZFR0e7l6ioqCqsuILxAFwAAADA65kanBwOh9avX6/ExET3OqvVqsTERCUlJZ1zv8zMTDVo0ECxsbG64YYbtG3btnO2zcvLU3p6usfiVRiqBwAAAHg9U4NTamqqnE5nkR6jqKgoJScnF7tP8+bN9dZbb+mTTz7Re++9J5fLpcsuu0yHDh0qtv3kyZMVGhrqXmJjYyv8PM4LwQkAAADweqYP1SuvhIQEDR48WB06dFDPnj21YMECRUZG6vXXXy+2/dixY5WWluZeDh48WMUVl4LgBAAAAHg9HzM/PCIiQjabTSkpKR7rU1JSFB0dXaZj+Pr66pJLLtGuXbuK3W6322W328+71krDA3ABAAAAr2dqj5Ofn586deqk5cuXu9e5XC4tX75cCQkJZTqG0+nUli1bFBMTU1llVi56nAAAAACvZ2qPkySNHj1aQ4YMUefOndW1a1dNmTJFWVlZGjZsmCRp8ODBqlu3riZPnixJmjRpki699FI1adJEp0+f1vPPP6/9+/frr3/9q5mn8ecRnAAAAACvZ3pwGjBggI4fP65x48YpOTlZHTp00JIlS9wTRhw4cEBW6+8dY6dOndI999yj5ORkhYeHq1OnTlqzZo1atWpl1imcH4ITAAAA4PUshmEYZhdRldLT0xUaGqq0tDSFhISYXY702WfS9ddLXbtKP/xgdjUAAADARaM82aDazap3wWFyCAAAAMDrEZzMxlA9AAAAwOsRnMxGcAIAAAC8HsHJbAQnAAAAwOsRnMx2JjhxjxMAAADgtQhOZjszOQQ9TgAAAIDXIjiZjaF6AAAAgNcjOJmN4AQAAAB4PYKT2QhOAAAAgNcjOJmNB+ACAAAAXo/gZDZ6nAAAAACvR3AyG8EJAAAA8HoEJ7MRnAAAAACvR3AyGw/ABQAAALwewclsPAAXAAAA8HoEJ7MxVA8AAADwegQnsxGcAAAAAK9HcDIbwQkAAADwegQns/EAXAAAAMDrEZzMdvaseoZhbi0AAAAAikVwMtuZ4CTR6wQAAAB4KYKT2c4OTtznBAAAAHglgpPZCE4AAACA1yM4mc161q+AoXoAAACAVyI4mY0eJwAAAMDrEZzMRnACAAAAvB7ByWwEJwAAAMDrEZzMxj1OAAAAgNcjOHmDM+GJHicAAADAKxGcvMGZ4XoEJwAAAMArEZy8AcEJAAAA8GoEJ29AcAIAAAC8GsHJG5y5x4nJIQAAAACvRHDyBvQ4AQAAAF6N4OQNCE4AAACAVyM4eQOCEwAAAODVCE7egOAEAAAAeDWCkzdgcggAAADAqxGcvAE9TgAAAIBXIzh5A4ITAAAA4NUITt6A4AQAAAB4NYKTN+AeJwAAAMCrEZy8AT1OAAAAgFcjOHkDghMAAADg1QhO3oDgBAAAAHg1gpM3IDgBAAAAXo3g5A2YHAIAAADwagQnb0CPEwAAAODVCE7egOAEAAAAeDWCkzcgOAEAAABejeDkDc4EJ+5xAgAAALwSwckbnJkcgh4nAAAAwCt5RXCaNm2a4uLi5O/vr/j4eK1du7ZM+82dO1cWi0X9+/ev3AIrG0P1AAAAAK9menCaN2+eRo8erfHjx2vDhg1q3769evXqpWPHjpW43759+zRmzBh17969iiqtRAQnAAAAwKuZHpxefPFF3XPPPRo2bJhatWql6dOnKzAwUG+99dY593E6nRo0aJAmTpyoRo0aVWG1lYTgBAAAAHg1U4OTw+HQ+vXrlZiY6F5ntVqVmJiopKSkc+43adIk1a5dW8OHDy/1M/Ly8pSenu6xeB0egAsAAAB4NVODU2pqqpxOp6KiojzWR0VFKTk5udh9vvvuO82cOVMzZswo02dMnjxZoaGh7iU2Nva8665w9DgBAAAAXs30oXrlkZGRobvuukszZsxQREREmfYZO3as0tLS3MvBgwcruco/geAEAAAAeDUfMz88IiJCNptNKSkpHutTUlIUHR1dpP3u3bu1b98+9evXz73O9dvwNh8fH+3cuVONGzf22Mdut8tut1dC9RWI4AQAAAB4NVN7nPz8/NSpUyctX77cvc7lcmn58uVKSEgo0r5FixbasmWLNm7c6F6uv/56XXHFFdq4caN3DsMrC4ITAAAA4NVM7XGSpNGjR2vIkCHq3LmzunbtqilTpigrK0vDhg2TJA0ePFh169bV5MmT5e/vrzZt2njsHxYWJklF1lcrTA4BAAAAeDXTg9OAAQN0/PhxjRs3TsnJyerQoYOWLFninjDiwIEDslqr1a1YZbZ5s7R1q9TidCN1lKSCArNLAgAAAFAMi2EYhtlFVKX09HSFhoYqLS1NISEhptYyerT00kvSv9p/qX9v6i1NmCCNH29qTQAAAMDFojzZ4MLsyqkmfhtlqDT99kvKzDStFgAAAADnRnAyUWho4c/TBcGFLwhOAAAAgFciOJnI3ePkrFH4IiPDtFoAAAAAnBvByUTuHqe8wMIX9DgBAAAAXongZCJ3j1Oef+ELepwAAAAAr0RwMpG7xynXXviCHicAAADAKxGcTHSmx+l0lm/hC4ITAAAA4JUITiY60+OUk2eTQ74M1QMAAAC8FMHJRGc/YytNofQ4AQAAAF6K4GQiHx8pKKjwdZpCC3ucDMPcogAAAAAUQXAymfs+J4VJBQWSw2FmOQAAAACKQXAy2Zn7nNL02wuG6wEAAABeh+BkMnePk2/twhdMEAEAAAB4HYKTydwPwbX/FpzocQIAAAC8DsHJZO6H4PoRnAAAAABvRXAymbvHyadW4QuG6gEAAABeh+BkMnePk61m4Qt6nAAAAACvQ3AymbvHyfLbC3qcAAAAAK9DcDKZu8fJCCt8QY8TAAAA4HUITiZzT0fuCil8QXACAAAAvA7ByWTuB+A6axS+YKgeAAAA4HUITiZz9zjl/xac6HECAAAAvE65gtNzzz2nnJwc9/vVq1crLy/P/T4jI0P3339/xVV3EXD3ODkCCl/Q4wQAAAB4nXIFp7FjxyrjrL/Y9+nTR4cPH3a/z87O1uuvv15x1V0E3LPq5dplSPQ4AQAAAF6oXMHJMIwS36P8zvQ4uQyrMhVEcAIAAAC8EPc4mSwgQPL1LXx9WmEM1QMAAAC8EMHJZBbLWfc5KZQeJwAAAMAL+ZR3hzfffFNBQUGSpIKCAs2ePVsRERGS5HH/E8ouLExKTT3T43TM7HIAAAAA/EG5glP9+vU1Y8YM9/vo6Gi9++67RdqgfDx7nPaYWwwAAACAIsoVnPbt21dJZVzc3M9yUhhD9QAAAAAvxD1OXqDIPU7MVggAAAB4lXIFp6SkJH3++ece69555x01bNhQtWvX1r333uvxQFyUTXR04c8dalEYmrKzzS0IAAAAgIdyBadJkyZp27Zt7vdbtmzR8OHDlZiYqEcffVSfffaZJk+eXOFFXugSEwt/LlJfHoILAAAAeKFyBaeNGzfqqquucr+fO3eu4uPjNWPGDI0ePVovv/yyPvzwwwov8kKXmFj4LKfdaqJf1ZRnOQEAAABeplzB6dSpU4qKinK/X7Vqlfr06eN+36VLFx08eLDiqrtIBAdLPXoUvv5C19LjBAAAAHiZcgWnqKgo7d27V5LkcDi0YcMGXXrppe7tGRkZ8vX1rdgKLxLXXlv4c5H60uMEAAAAeJlyBae+ffvq0Ucf1bfffquxY8cqMDBQ3bt3d2/fvHmzGjduXOFFXgz69i38uUo9lXEsx9xiAAAAAHgoV3B66qmn5OPjo549e2rGjBl644035Ofn597+1ltv6ZprrqnwIi8GzZpJjf0PKV9+Wrk20OxyAAAAAJylXA/AjYiI0DfffKO0tDQFBQXJZrN5bJ8/f76Cg4MrtMCLhcUitQk9qN259XT0qNnVAAAAADhbuYLT3XffXaZ2b7311p8q5mIX6F/44Nvs9HyTKwEAAABwtnIFp9mzZ6tBgwa65JJLZBhGZdV00QoMPBOcnCZXAgAAAOBs5QpOI0aM0AcffKC9e/dq2LBhuvPOO1WzZs3Kqu2iExhokSRlZxKcAAAAAG9Srskhpk2bpqNHj+pf//qXPvvsM8XGxuq2227Tl19+SQ9UBQgMLvx1ZGdyLQEAAABvUq7gJEl2u10DBw7U0qVL9fPPP6t169a6//77FRcXp0we3HpeAoMLOwCzs00uBAAAAICHcgcnj52tVlksFhmGIaeT4WXnKzDkt+CUazG5EgAAAABnK3dwysvL0wcffKCrr75azZo105YtWzR16lQdOHBAQUFBlVHjRSMwrPCZWNm555VnAQAAAFSwck0Ocf/992vu3LmKjY3V3XffrQ8++EARERGVVdtFJzDcLknKdpTr1wIAAACgkpXrb+jTp09X/fr11ahRI61atUqrVq0qtt2CBQsqpLiLTWBNf0lStsPX5EoAAAAAnK1cwWnw4MGyWLj/prIERgRKkrKdfpLLJVkZsgcAAAB4g3I/ABeVJzCyhiQpW4FSZqYUEmJyRQAAAACk85xVDxXLPTmEAqXTp80tBgAAAIAbwcmLBBaO1CM4AQAAAF7GK4LTtGnTFBcXJ39/f8XHx2vt2rXnbLtgwQJ17txZYWFhqlGjhjp06KB33323CqutPAEBhT+zFSilpZlbDAAAAAA304PTvHnzNHr0aI0fP14bNmxQ+/bt1atXLx07dqzY9jVr1tTjjz+upKQkbd68WcOGDdOwYcP05ZdfVnHlFe/sHifj1GlTawEAAADwO4thGIaZBcTHx6tLly6aOnWqJMnlcik2NlajRo3So48+WqZjdOzYUddee62eeuqpUtump6crNDRUaWlpCvGyyRdOnZJq1ix8nTdrjvyG3mFuQQAAAMAFrDzZwNQeJ4fDofXr1ysxMdG9zmq1KjExUUlJSaXubxiGli9frp07d6pHjx7FtsnLy1N6errH4q3O9DhJUvaxTPMKAQAAAODB1OCUmpoqp9OpqKgoj/VRUVFKTk4+535paWkKCgqSn5+frr32Wr3yyiu6+uqri207efJkhYaGupfY2NgKPYeK5OcnWS0uSVJ2arbJ1QAAAAA4w/R7nP6M4OBgbdy4UevWrdP//d//afTo0Vq5cmWxbceOHau0tDT3cvDgwaotthwsFinQxyFJyj6Za3I1AAAAAM4o1wNwK1pERIRsNptSUlI81qekpCg6Ovqc+1mtVjVp0kSS1KFDB23fvl2TJ0/W5ZdfXqSt3W6X3W6v0LorU6BfgTLzpZxTBCcAAADAW5ja4+Tn56dOnTpp+fLl7nUul0vLly9XQkJCmY/jcrmUl5dXGSVWuUD7b0P1Tl0Y5wMAAABcCEztcZKk0aNHa8iQIercubO6du2qKVOmKCsrS8OGDZMkDR48WHXr1tXkyZMlFd6z1LlzZzVu3Fh5eXlatGiR3n33Xb322mtmnkaFCQz4LTilF5hcCQAAAIAzTA9OAwYM0PHjxzVu3DglJyerQ4cOWrJkiXvCiAMHDshq/b1jLCsrS/fff78OHTqkgIAAtWjRQu+9954GDBhg1ilUqMAzD8ElOAEAAABew/TnOFU1b36OkyT17JCmbzaF6sPoB3Xr0ZfNLgcAAAC4YFWb5zihqMCgwl9JdtZFlWcBAAAAr0Zw8jKBITZJUjaPcQIAAAC8BsHJywSGFN52lu30k3KZkhwAAADwBgQnLxMY4itJylagdPq0ucUAAAAAkERw8jqBNSySCE4AAACANyE4eZnAwMKf2QqU0tLMLQYAAACAJIKT1/EITqdOmVsMAAAAAEkEJ6/jEZyOHjW3GAAAAACSCE5exyM4HTpkbjEAAAAAJBGcvA7BCQAAAPA+BCcvQ3ACAAAAvA/BycsEBBT+JDgBAAAA3oPg5GXocQIAAAC8D8HJy3gEp5MnpexscwsCAAAAQHDyNr8HpxqFLw4fNq8YAAAAAJIITl7HHZwsv70gOAEAAACmIzh5GXdwMgJlSNznBAAAAHgBgpOXOROcJClX/gQnAAAAwAsQnLzMmenIJWbWAwAAALwFwcnL+PoWLpKUowCCEwAAAOAFCE5eiGc5AQAAAN6F4OSFCE4AAACAdyE4eSGP4JSSIjkc5hYEAAAAXOQITl7IHZx8QgtfHDliXjEAAAAACE7eKPS3vHQyvHHhi6NHzSsGAAAAAMHJG0VHF/5M8W9Q+OLECfOKAQAAAEBw8kZRUYU/k33rFb5ITTWvGAAAAAAEJ290pscpWTGFL+hxAgAAAExFcPJC7uDkiix8QXACAAAATEVw8kLu4JQXXviC4AQAAACYiuDkhdyTQ+SEFL7gHicAAADAVAQnL+QOThmBcslCjxMAAABgMoKTF6pdu/BngdOqk6pJcAIAAABMRnDyQn5+Uq1aha+TFU1wAgAAAExGcPJSv09JHl14j5NhmFsQAAAAcBEjOHkpj+CUny9lZppbEAAAAHARIzh5KXdw8oktfMFwPQAAAMA0BCcv5Q5O/g0KXxCcAAAAANMQnLxUkR4nnuUEAAAAmIbg5KXcwcny2wt6nAAAAADTEJy8lDs4OSMLXxCcAAAAANMQnLzUmeCU4ggvfFFMcDpwQMrKqsKiAAAAgIsUwclLnQlOqbnBypdPkXucDhyQGjWSrr/ehOIAAACAiwzByUvVrCnZbIWvj6l2kR6nLVskp1PatMmE4gAAAICLDMHJS1mtv/c6HVRskeB09Gjhz5MnCwMUAAAAgMpDcPJiLVsW/tym1kWCU3Jy4U/DkE6dquLCAAAAgIsMwcmLtWtX+HOT2he5x+lMcJKk48ersCgAAADgIkRw8mJngtNmtTvnUD2JZ+MCAAAAlY3g5MXaty/8uVntZGRlSXl57m1n9zgRnAAAAIDKRXDyYi1bSjaboVOqqcOqK+3d697GUD0AAACg6hCcvJjdLrVoYZH0231Or78uqXBCCIbqAQAAAFWH4OTlzh6upzfflNLSlJEh5eT83obgBAAAAFQurwhO06ZNU1xcnPz9/RUfH6+1a9ees+2MGTPUvXt3hYeHKzw8XImJiSW2r+7cE0SEdNeRzGAlvzjHY5iexFA9AAAAoLKZHpzmzZun0aNHa/z48dqwYYPat2+vXr166dixY8W2X7lypQYOHKgVK1YoKSlJsbGxuuaaa3T48OEqrrxqnAlOi/OvUiPtUfunb9H+RVs92tDjBAAAAFQui2EYhpkFxMfHq0uXLpo6daokyeVyKTY2VqNGjdKjjz5a6v5Op1Ph4eGaOnWqBg8eXGr79PR0hYaGKi0tTSEhIeddf2U7ckSqW9dz3Ri9oBc0xv2+c2dp3boqLgwAAACo5sqTDUztcXI4HFq/fr0SExPd66xWqxITE5WUlFSmY2RnZys/P181a9YsdnteXp7S09M9luokJkZq1Ury95di67okSZ+qnySpQVThjU4M1QMAAAAql6nBKTU1VU6nU1FRUR7ro6KilPzHG3nO4ZFHHlGdOnU8wtfZJk+erNDQUPcSGxt73nVXJYtFWru2sOdp6N2Fv65f1FyS1Ca9MFwyVA8AAACoXKbf43Q+nn32Wc2dO1cLFy6Uv79/sW3Gjh2rtLQ093Lw4MEqrvL81aghhYdLXbp4rm+b84MkKSvLc5Y9AAAAABXLx8wPj4iIkM1mU0pKisf6lJQURUdHl7jvCy+8oGeffVbLli1TuzMzKBTDbrfLbrdXSL1m+2NwaqZf5CuH8uWn1FSpmnWmAQAAANWGqT1Ofn5+6tSpk5YvX+5e53K5tHz5ciUkJJxzv+eee05PPfWUlixZos6dO1dFqV4hOtozHNVpUkMRKhynx3A9AAAAoPKYPlRv9OjRmjFjht5++21t375dI0aMUFZWloYNGyZJGjx4sMaOHetu/+9//1tPPvmk3nrrLcXFxSk5OVnJycnKzMw06xSqVNeuv7+OHtr79+B0NN+kigAAAIALn+nBacCAAXrhhRc0btw4dejQQRs3btSSJUvcE0YcOHBAR48edbd/7bXX5HA4dMsttygmJsa9vPDCC2adQpU6e7he9OBrFOFXOEvg8S8u3IcAAwAAAGYz/TlOVa26Pcfpj1askK68UrJaJYdDuqPDNn24tbX+W/8/enD/w2aXBwAAAFQb1eY5Tii/hASpUydp4EDJZpMiujSUJKUeyJI2bDC5OgAAAODCRHCqZvz9pR9/lN57r/B9ZP1ASdJxRUqvv25iZQAAAMCFi+BUzUVEFP5MVYT0/vtSerq5BQEAAAAXIIJTNXcmOO20t5MrK1t6911zCwIAAAAuQASnaq5bNykgQNqS11zP6lHpueeknByzywIAAAAuKASnai42Vpo2rfD1OE3StwfqS1OmmFoTAAAAcKEhOF0Ahg6VBg2SnPLRjVqo7U//T0pJMbssAAAA4IJBcLoAWCzS9OlS166GTihC12Qv1IHbxki5uWaXBgAAAFwQCE4XiKAgadEii1o2zNEhxerqb57Q8WuHFj7bKTPT3W7ZMmnSJCkvz7xaAQAAgOqG4HQBqVVL+uqbANWPytUvaq7eX/9ThzpdL9WuLc2bpxMnpJtvdGr8eOn5f7vMLhcAAACoNghOF5h69aSl3/grMsyhDeqk+jqg3jkLtPOup/XMdauVnmmTJD0zKV/79zhNrhYAAACoHghOF6BmzaRlq/zUo4dkyKov1VuX5n+jqd93liQ10D7lOO0afcUGyUXPEwAAAFAagtMFql07adUq6ddfpYR4p04rXA7ZdWW9X/TZ8ztlU4EWHOiiFaM/NbtUAAAAwOsRnC5wTZpIX6+06Z67nWpc36GXvmimtmN66b7u2yRJ/3olVq5fd5tcJQAAAODdCE4XAX9/6Y2ZNu3a76d27QrXjfuwrYJs2frR1Unzr3vbY+a9M/LyCqc537GjigsGAAAAvAzB6SJVO9qqf44qnJP8kV/u1q5LbpV++cW93eWSBg+WRoyQ7rzTrCoBAAAA72AxDMMwu4iqlJ6ertDQUKWlpSkkJMTsckyVmSm1apKngyl2BSlDg3w+1Mk2PRTaqYkyMi2aN+/3tjt2SM2bm1crAAAAUNHKkw3ocbqIBQVJq9fZ1eNShzIVrNcLhmv+xqZ6c+bvoal+7RxJ8ghRAAAAwMWGHifI6ZRmzXRp9/82KnrVPJ3Iq6EdaqE+WiybnBqid9SiUZ5+3mWXxWJ2tQAAAEDFKE828KmimuDFbDbpr/dapXs7SpnNpO3bpZ07pVU+Sv/fCtlP5WrHHn9t/u8KtX/oCrPLBQAAAKocQ/XgKShI6tKlcEaIGTMUsi1J10b8IEl64R+H5XrzLZMLBAAAAKoewQkli4nR3975iyTpPd2pAfcEK3PYKOnQoVJ3fecdaebMyi4QAAAAqHwEJ5Tqmj42vfeuIV9rgT7SrYqdPUlj4uZr302jpe++K3afVaukIUOkv/5V2rKligsGAAAAKhjBCWUy6E6LvlruoyZ1c3Ra4fqP8x9qvPB53dj9uLZ2H+HxDKj8fGnkyN/3fYvRfQAAAKjmCE4os8svl3YeCNDnnxm6Jv60XLLpY92o9t9N1cgWy3QkcbBcHy3Q5Gdc2rZN8vVxSZLefdeQw2Fu7QAAAMD5IDihXKxW6drrLPry+zD9/LN0c68MuWTTq8b9arh8hpre2l7jJxR+raYV/E0xOqITJyz6bMhH0sU18z0AAAAuIAQn/GktW0ofLQnW119L3TpmyyG79qixQpSmJzVJw21va2jAh5KkN+fWYMweAAAAqi0egIsKYRjSmjXSwe2ZunbXfxWcdkgaM0a/OhqoeSubDFn0ru8w3fnjP6R27cwuFwAAAChXNiA4odI98bih/3vGIn/laFXNm9T1/b9LvXubXRYAAAAucuXJBgzVQ6WbOMmivokO5SpA8ScXq2Of2ronbqkmDfxZ23/KNbs8AAAAoFT0OKFKnD4t3THAqSVfWWScldd95dAjjT/SY+N8FTCwv+Tra1qNAAAAuLgwVK8EBCdzHTsmffXmfu3+YqeSNvjpy9zLJUm1laIHQ97Wg2P8FPzAECk83NxCAQAAcMEjOJWA4OQ9DJehhS8f1OgJIdqfFiZJqqPDetFvrG57pKEsj/xLqlHD3CIBAABwwSI4lYDg5H3y86UP38/X+EdytPtY4e+kkXZraPAC3XyHXS0fvFqWVi1NrhIAAAAXGoJTCQhO3is3V/r3s4b+81yBMnJ+v9epuXZoZN1PNOyvNgVdd7l0ySWSzWZeoQAAALggEJxKQHDyftnZ0v/mOjT3lVQt3xyhPJefJMlPeWqp7UoI2KiRt59Um8eul5o0MblaAAAAVFcEpxIQnKqXjAzp/dcz9dILBfolJcxjWy8t0cMdvlbivzrKctONkt1e5mP+8ovUqVMlFAwAAIBqg+c44YIRHCzdNyZIO46Gac8eaeH8At2ccFhWOfWleuuajc+p3R2tNbPWv5T198eknTtLPeadd0qdO0vz51fBCQAAAOCCQI8TqqU9e6T/PpWume/blZVf2NNklVOt9LP61tmk4ffa1Oz2jlLjxpKPj3u/X36RmjcvfN2hg7Rhg2SxmHACAAAAMB09TrjgNWok/XdWiA4ds+v5fzvVMCpLLtm0VW313JE71XzCQNVvEaC+9mVaeNVUGbt2S5JeffX3Y2zcKH39aaY5JwAAAIBqhR4nXDCOHJG+++yU3vnvSS3eHieXfp957yot1yOXrtKtm59QWrafOjRK08Y9oepjWaJFs49JgwebWDkAAADMwOQQJSA4XRxOn5Z+3urS528c0Yvv13bPzCdJTfSrFquPmmunXLJpiXqp13OJ0pgxjNsDAAC4iDBUDxe9sDDpsr9Y9cw79fTzr36659ZTCvBxSJJG215WE98DGtrmR0nSjVqoVf/6XOrdW9q/38SqAQAA4K3occJF4+TJwkn3Lu3ilMVZoDzZdeON0uLFhdtjdUA9bKs1/u5DavrscKlmTXMLBgAAQKViqF4JCE44W06ONHCg9Mknv6/zUb6G+7ytv/U7qkvG9Sucfg8AAAAXHIbqAWUUECB9/HFhb9SKrw317XxMBfLV6wV/VceFT6rTJU692ugFpb70rnTsmNnlAgAAwCT0OAF/sGqlodeeStXClWFyuHwlSRa51EnrdWODn3TnYKvq350oxcWZWygAAADOC0P1SkBwQlmdOCG992qaZr2aq03JUR7bLlWSbohZpxtu9lGLe7rL0rYNM/IBAABUMwSnEhCc8GccOSItfu+E3n8zWyt+jfXY1lS/6NrQ1br2aod6jGgtv54Jks12jiMBAADAWxCcSkBwwvk6ckT6dE6mPnn7tL7+Oco9nE+SgpShq31X6dpWe9Uz0VehPTso/PL28gkOMLFiAAAAFIfgVAKCEypSRob01ac5+mJmihYlhSklN6xIm1pK1YROn+u+cbXl0+dqyde36IEAAABQ5QhOJSA4obK4XNKGtQX6YmayvvjSR1sOhyvXZXdvb6Tdusl/sW64JlsJf20j29VXSv7+JlYMAABwcatW05FPmzZNcXFx8vf3V3x8vNauXXvOttu2bdPNN9+suLg4WSwWTZkypeoKBUphtUqdL/XR+Bn1tPZAtHKcdjnyDE0bs1c1/bO0R431Qu4D6v7pvxRzfWfdHvS5Xmo3S1vGzZexZat0nv+GkZ9/3ocAAADAOZganObNm6fRo0dr/Pjx2rBhg9q3b69evXrp2Dmel5Odna1GjRrp2WefVXR0dBVXC5Sfr59F9z/fUPuO1dC8OU7dccVRhfll67hqa57zFo3eMkztnrpVzdv5aWz4a/px2DQZSd9LBQXl+pxDh6TGjaVu3QhPAAAAlcHUoXrx8fHq0qWLpk6dKklyuVyKjY3VqFGj9Oijj5a4b1xcnB566CE99NBDJbbLy8tTXl6e+316erpiY2MZqgfT5OdL331raM1HR7RmWZaW745TnsvPvT1aR3W17ypd0z5FV98WrqhbuksNGxY5xuDB0r590owZ0oMPSitWFG5LSpIuvbQKTwgAAKCaKs9QPZ8qqqkIh8Oh9evXa+zYse51VqtViYmJSkpKqrDPmTx5siZOnFhhxwPOl6+vdMWVFl1xZV1JhRNMfLEgT/+bfkyL1kUq2Rmjd/Nv17s/SvpRav+vjbom7A1d0z1Hf7mjgfx7dNXYScGaOzdYktShgyGn8/dnSM2ZQ3ACAACoaKYN1UtNTZXT6VRUlOeDRaOiopScnFxhnzN27FilpaW5l4MHD1bYsYGKEBws3T7ErvlJsTqZ5a+vlzr16OAj6ljnqCRpkzro+dP36urP/q6aA69Rz7q/6j+vF4amttrsDk23aZ4kad6sLBXk5JtzMgAAABco0yeHqGx2u10hISEeC+Ct7HbpikSbJr9dR+sPxyglRXr/zWwNufKAYgLTlKNAfaOekqR/1p2j9Vf8U8/qEb2gh/We33DVUqqOZdbQ15c8LJ04cV61uFzSHXdIQ4dy3xQAAIBpQ/UiIiJks9mUkpLisT4lJYWJH4Df1K4t3TE8UHcMry/DkLZtk776LE8FuQUa/eQd8vG5Q48cPixlZUmNn9Nt1/yq176O0H92XquG8Xeq6ZdTC2eN+BO++Ub64IPC1w88IHXuXIEnBgAAUM2Y1uPk5+enTp06afny5e51LpdLy5cvV0JCglllAV7LYpHatJFGj7XrXxNryOfMP3vUrSs1aybZbLrr6RaSpK/US812L1aDJj66KeIbTenzpba9ukpGcsq5P+APzoQmSfrwwwo8EQAAgGrI1KF6o0eP1owZM/T2229r+/btGjFihLKysjRs2DBJ0uDBgz0mj3A4HNq4caM2btwoh8Ohw4cPa+PGjdq1a5dZpwB4lYQEacEC6ZruObJZnDqgBlp4oof+saSX2ozsqXoxBRpaY74W9XlFBZ98If30k3T0aJHjOBzSRx/9/n7+fIbrAQCAi5up05FL0tSpU/X8888rOTlZHTp00Msvv6z4+HhJ0uWXX664uDjNnj1bkrRv3z41/MO0zJLUs2dPrVy5skyfV54pB4HqLD1d2rDkmH54f5eWrwvWt8lNlWv4u7dH6pjaaota6WcN6bhVnf/RXbr+eikkRF98IV13nVS7Zr4y013KLrBrbbd/qMvyZwtvxAIAALgAlCcbmB6cqhrBCRer3Fxp9bIcfTrzmOYsqanU3GCP7W20RU0tu1WvjkvrnJfo++SGGqWXlaIofagB+qee03N375TefLNw3CAAAEA1R3AqAcEJKByK9+OP0q5d0lcfZ2n+p3Y5nEXnillt66GjCTfplu8eUrDS9ZSe1IiJMfJ78hHCEwAAqPYITiUgOAFFHTsmrVkjHV6frEMbUnRoX4GaRaXriXebK69WHV1xhfT994VtW+pnvdnjXV324UPSH57DBgAAUJ0QnEpAcALKr6BAmvWWoSceztaxzBqyyKU+WqLeLfbqsj5hantrC/l1aa/fp/oDAADwfgSnEhCcgD/v5ElpzLBUzfo0wmO9n/J0qXWdrozbo6uuNNR1QEP5desiBQSYVCkAAEDpCE4lIDgB52/bNumLt1O17OMM/bgvQqfyPSeaCFSWulnW6PLYPerZ3aUutzSQ3+WXSWFh5hQMAABQDIJTCQhOQMUyDOnXHU6tmHNEX3+Rq69/jlJqnud/WwHK1mVaox5Rvygh3qWuN9ZVaK9LpZgYk6oGAAAgOJWI4ARULpdL2rbV0Kr/pWrVokyt3BKh1DzPHimLXGqln3Vp8M+6tG2WLu0Vqpa3tZWteRNm6wMAAFWG4FQCghNQtQxD2r5dWvlJmlYvOq3vN9fQnvSIIu2Cla7Wvr+oSUy2Ejuf1i03OlWjd3cpomhbAACAikBwKgHBCTDfsWPSD8szlfRxsr7/3qK1h2KU5Qr0aBOkDHXTGnVplKrO8TZ1uTpcdfp3lcLDTaoaAABcaAhOJSA4Ad7H6ZR+3pCrnYt2a8s3p/T+uqbanVH0GVEdtV43x67T5Yk+6jiopfy7dZL8/Su2GIdD2rRJSksrfE5V27YVe3wAAOA1CE4lIDgB3s8wpPXrpXWfp+jHxcf1468h2nqqrlyyudv4KU8dLT8pIXqfLuvs0GU3RKrOdR3L/FDeZcukhx6SXnpJuvrq39dn9rlVq5ek66BiFWk9oRvWPSl17FjBZwgAALwBwakEBCegejp+XFo486QWzctQ0vZQHcsLK9KmvvbrsqDNSmhxWpclBqrDrU3l0761ZLN5tMvOllq0kA4elOLipB07JLtdMrZuU4+2J/WdurvbftPzSXVf+VQlnx0AADADwakEBCeg+jMMac9uQ0mfpGjNojSt2RSoLSfqePRISYXPk4q3rVe3BgeVcKnUpX9dRfbqqAkvhmjixN/bvfii9I9/SB9ePUMDlt0jf2ue6taVdh+06y69o3d2xEvNm1fxWQIAgMpGcCoBwQm4MGVkSGu/ztSa/x3VmjVS0v4YpRUEFWnXQPuUbIlRnmFX/0ab9PGe9gr3zdA3T32j68e20l6joSYM26/ef2ugSy+V/JWjo3f+S2HvvmLCWQEAgMpEcCoBwQm4OLhc0s+bC7T6o6NasyxLa7cHa0d6Xff2y7VCS3W1OmijtqmNe30d32P65WSkAmtY1K5JtrbuCdQ06yjd/7+rpP79TTgTAABQWQhOJSA4ARevtDRp/Zep+mXFYd1c7wdFZuzRz87mGvXhX7TqQEM55aN371utO1/rJkmaMqVwCF8bbdFXlt6KefGf0rBhUmiouScCAAAqBMGpBAQnAMVJ3X5cR348onZ3tf99XapUr56hvDyLrHLqL/pOPayr1eWSArW9tYXi7rhMlnp1JYtF+fmSr6+JJwAAAMqN4FQCghOA8vjqK2niRENr1liKbKutFHW3r9Ov9tbanN5QiR1SNXOWVfU71DShUgAAUF4EpxIQnAD8Gbt3S19/LX33xWlt+iFXO1LClWfYi7QLVrquCkxS47p5urSrSz1uilDtxHYSf94AAOB1CE4lIDgBqAgOh/TDqlytXpCi2Mztan5ijR5ccaOSci8p0ralflaPsM3q2iJDnXsEqtV1jeTTuYMUEFD1hQMAADeCUwkITgAqi9Mpff1ZlnZ+fUjb12Xpm58jtDW9fpF2AcrWJdqozhH71Ll1jrpcGaRmfZvK2r4tN0oBAFCFCE4lIDgBqEqpqdK3n5/Wms9O6scNVq0/VFsZBYFF2vkrR80sv6pFeIqaN3So66U29by1toLjW0n+/iZUDgDAhY/gVAKCEwAzuVzSLzsN/fjVSf249JTWbfTVT0ejlOMqGo58lK9W2q62oQfUNvSAWoccVGjHxgq+5lK1vamZbAF+JpwBAAAXDoJTCQhOALxNQYG0b6+hHSuOaue3x7RtU4G+2RWj3Tl1z7lPPR3UoNrL1O1Spy65qaHqXt1KlphoyVJ09j8AAFA8glMJCE4AqosD+w1tXJaqrd+e1Jbdgdp5IEBZJx06mhmkDHn++RWh4+rou1WX1EnRJW3ydUnPEDW5uqGsLZtL9qKz/wEAAIJTiQhOAKq73BxDn81K1efzsvTTVh/9fDJaTvkUaeenPDXQfrUOOqC/NDqsJi39VKNZXUV2jFW9hFjViiq6jyRp3z7pu++kW27h/ioAwAWN4FQCghOAC01OjrT1x1xtWJSsn9bkaMOOAG0+HlPsc6bO1tK+Rzc13aJmLW2KaF5LLS6PVvC+LXpvZJL25sVoeKdNar/sP1JYWNWcCAAAVYzgVAKCE4CLQUGBdPCAob3rUrV+6Umt+cGq5BSLMjOllJxQHVdkqcewqUAjwuZqxAip1b1/keLiKr9wAACqEMGpBAQnABc9l0tpm/fr87dPaMkKu1JSpJQ0u3bkNJBDdnWKOqg6zYL12bdh7l1aa6uurrlBES0itCGvtWrH2vXP0U41SoiSfM4x5A8AAC9HcCoBwQkAipef59KpFIdq1y+8r2nZ/FN6ecIJLdneQPlG0Qfz+sqh63y+VPsmmWrTOUCtE0LU5PJ68mnWiDAFAKgWCE4lIDgBQPmcPCkt+zhTX79/VJmHT6t9/notO9JKX+X2KNLWVw411h61CDqk5jHpimngp5hmwerWJ0R1uzeSQkNNOAMAAIpHcCoBwQkAKsYPa5xa/eFhbf3utLburaFtp+so2xVwzvbNtFO1fU8rIjRfXRqdUHxnp1p0q6U63RrKEltPslqrsHoAAAhOJSI4AUDlcLmkQwdc2rE6VTvXnNSvW/OUcrhAe47V0PqMZjJUfDCqoUw1s+xSs9AUNaubpWbNLWrWKVi12teTtVGcjp7y1+HDUkKCVK9e1Z7TO+9IL70kzZkjtWxZtZ8NAKh8BKcSEJwAoOqdOCFt+DZL6TuP6uDmU0r6ya4NByK0N6t2sc+gKk6AJUfj672lmxPTVOvmyxV6aUtZa4ZJFkul1Ox0SvXrS0eOSDf+5ZgWJL4m/fOfUmBgpXweAKDqEZxKQHACAO+Rny/t2ZmvX747pl/WntYv2/L1ywG7fjkRobT8ADllU20dU6CytUOeXT5WORVpSVX3sK26stkhRTYJVe3WkercL0aBLRtINtt51fbll1Lv3r+//1kt1fKRG6Rnnz2v4wIAvAfBqQQEJwCoJgxDSk2VTpyQkZGpdxcE6pl36unQMT9lFfifczdfOXSJZZOahyarSd1sNWlqVZMOQWoSX0s1O9SXoqLK1Et1x0BDH8y1yKYCOeWjoZqlWb5/k7Ztk5o2rcgzBQCYhOBUAoITAFR/ubnSqSM52vt9ir76JEdrf/JV+imn9qWF6XB+1Dn3s8opm5yqa0tWe/+d6hBzTO3j/dX40kjV7RwjV41gFWTlyT9pheo8fLtyDX9N1Ug9oGnysRRovdFR7a6tL332WaUNEQQAVB2CUwkITgBw4TIMac+vTm348rh2rz+tX7cXaNcBX+06WUtHHBFlPo6vHMqXn1pad2jb0x+r94p/6aulVoXplBbqRvW80keWV6dJzZtX4tkAACobwakEBCcAuDhlZ0tpqfnK339Ee37O1aatNm1c69CWX+3al15TJ5zhkiSLXO4ZAKc8nam/Px6kkyel66+XVq8uPFYtpaqNtqpN5DG17eSnNp391axLqCKahstSt47E/18AoFogOJWA4AQAKI7DUTifhOEy9MuvFh0/LnXv/vvjpXJypL/+VZo715DLVfwwvQBlq5ZOKNiapfqBJ9Q88oTsYQHK8qupnSmhOng6WB3qndBV8Zm6aUSUIjrWZ8gfAJiI4FQCghMA4Hzk5Eg7dkhbvkvT1i/2a+vPVm05VluH8mqX6zi+cugav1WKqZmriAiLWjQtUOOWdoU3CFFU8zDVahEpS2QEDwYGgEpEcCoBwQkAUBny8qTDh6VTh7KUtuu49mzK0C/bnXKlZciee1qNIzNUp1ae1v4Spk9+aakN2S1KPF6oTitYGUq3hCrG76SujNqmNnVPKTzKT+vSmumbPfXkPJ2ugIxjCvBzqUaIVVGBmYqrma47R4WpwV09z3tKdgC40BGcSkBwAgB4g03f52jVhylKP5Su5AMObTsQpAOnQ3TaEaiTzrDzOrZNBbre/pWaxWTIp2aI9ilOAbUCNXyYS/H9assSVKNiTgIAqjmCUwkITgAAb5eTI+3eka/c5NMKzk7Rjo25Wvm9v/Yf8VHqaR819TugawK/U2jresrp0kO5aXnKPHBSyaf8tGpTmJYfPPdsfw20T9GWY4r0Pa0In9OKDHMookGQImP9FVHXXvizYbAim4YppFGELAHnfmYWAFR3BKcSEJwAABe6DWty9eXbR5WyJ1uOk5lqkL9LO44E64MT1yhPZQ9CvnIownKiMGT5ZyqyRrYiQvIVVStf9WKciozxlS0sWIG1g1SnaQ3FtAhVUGw4QwQBVBsEpxIQnAAAF6uTJwxt35Cj1D3pOn60QMePS6l7M3R8f7ZST9l0PCtAqblBOp4fpizjzw3nC1a66lhTFGM/qcjATIXXyFdYiEvhYYbCw1W4RNsVXq+GwhuEKLxhmEIbhMkWHMgMgwCqXHmygU8V1QQAAExWs5ZF3a4OlBRYatucbKMwYO1KKwxXB3OVejRfx1NcSk616dCJQKVm+csocCrDYdeR/EhlKUgZCtFOV4h25kjKkXSibLXVUKYkyV+5auR7SJEBGcq0hsppsSnIkqX6QafUrcUJNW7tL9+4ugptEKbg2gFauSlc364PUNd2uRrU97Ts9aMkX98/fY0A4FzocQIAABUi42S+jmxP09FfMnRkd45OHHXo1PECnTrh0qnTFp3K8tWpbLtOZfvrlCNQpwqClW2UHuLKqrZS1Fh7ZA+wyu4vBQU41aBmpupF5skeapfhH6h0h798fC1qXidDdaKc8g0JUGiUv2rV9deMz6P1whshcqTnqpFjp/rXXq1RjwYpeOB1Uu3yTTcPoHpgqF4JCE4AAHgPR56h00eylXE0UxaLlHkqX7u25urU0RyFFJyU1VmgDFcN/bzHX2u2hepYmp8cDul0QZDSjFC10HZdqa/1qa7XIcVWeH3hOqmG2ivZ7aofnqkm0ZmqGepUSLChkFCLQsMsCgm3KaSWr0Jq+SogzC4jsIYCagYovE6ArME1pIAAhiECXorgVAKCEwAAFwanU7IZBVJ2thxWf333vY/S9p5U3v5k5Z3KUvpxh/Yd9tWRVD/l5xZI+QUKsWUpp8BXO7Pq6nheiApcVp1yhijPsKuuDmmSxqlTG4fWX/lP/fuDWP1yvOafrs9H+fKTQw75KVTpquuTLFmtylSQIv3SFBt4UmlGiI7lh8mZb8jH5VCTmifUvF626tQuUK1akj3ErjyfQB06FaSstAL5p6UowM+pgMZ15HRZlHXolOrXztWlPfy0NqWBFq2LVEQdX3XoalePrrmqE55TeGNZBQe3NWukd9+V7rtPat++Qg8NVCmCUwkITgAA4GyGIZ04UZgvbEaB5FN4C3hBgbR6tZSdnC7njl+1d1u29u63KC3TR+nZPkrL8VN6np/SHf5Kzw9UujNQOS67LDKULz+Tz6pQC21XpO2kAgKt8vdzKsDXKbuvS35+kp+fZLdLfnbJ7m+Vn79FNXzzFW5LV3a2lJLmr+BQqxo09VVQRIBsAX6yBdq1ZmuIJsysJ6fLKn+bQy91el9XXh+kgMvjlW0LVtaxLGVu3SefrDTVbxEoe71IpfpEK6R+mOrU9ylThks9kK1/XL9bX/5cT/+IX6OH/+Ujv15XFBYNVCCCUwkITgAAoLI5HNKxo07lp+fIJy9Lp1PydORAgax52Qo0spWSbOjgYavCbBmKDkiTb3iQcmxB2rk1X7v22pSS7q8Tmf5y5Es+Rr7q+aQoxJ6nnKAI5Th8lHMyRzaLSwGhftp2uq62ZMSprvWobrPMV47TV+vURRvUUYaslXaOjbRbe9S4XPtE66j8LAVKNmorxJalBn7JKrD4KM0ZJB9XvgKMLAX4OrU7t65OGL/39sXoiGpbTyg0TGoZdEj1Q07Lt2awfIL85WMz5JudJp9Tx+UT6CefetHyCQmUr90qH7+zFrvNvdj8bHK6LEo+4lJurtSooaHoWF8ZAYEyfP1kuAwVpGUpPzVN+Q5D+TZ/hUf6qF4Dm/zD/GX4B8jwD9CxdH+9PculpDWGru5wXEN67FVw8zoy6taTNcD+p3r6HA5p9ZeZ2vjFYf2lXbo6x9tkaduG0FhJql1wmjZtmp5//nklJyerffv2euWVV9S1a9dztp8/f76efPJJ7du3T02bNtW///1v9e3bt0yfRXACAAAXmqyswluprFYVPkE5PV0ncgK1botdmbtSlHPohHIyC5ST6VJ+rlN5OU45cg3l5brkyDOUl2dRXp6UVWDXKWewAvxcigrJVnq6RftP1FCOw0dOl+R0WeRnODSq+Zcact1JPb+lt6avbqOTGb7KcfopUNmqoSwF2fOVZ/HX4dxaKpCvwnRK6QqRS2V/xlcb3x0a2jtFzy29RMdyq8ff2axyypBFhqzyU54ClCN/S54CLHkKsOXJbs2XnyVfTvkoywiQzeJSoC1PgdY82W35OuqI0K7cuspx/f68tWbaqWjrMfkF+8vXx5CfzSk/m1O+Nqf8bC7JapHD8JXNKgXb87QvI0JrUxsqxDdHXSP2yiWLDmeHK9Seq3pBpxXk65Cfj+u3xSlfmyFZLUpzBOh0XqBO5wXIYpEa1kxTeGCesvL9VJBvyKcgVzarSz52H9nsPvLxt8nH37fwtQpkMwrk42PIsNp0LCNQJ9J8ZElPk19O4XFCa+TL5lsYWm1+Ntl8rbr2+csVEBlk4m+smgWnefPmafDgwZo+fbri4+M1ZcoUzZ8/Xzt37lTtYmawWbNmjXr06KHJkyfruuuu05w5c/Tvf/9bGzZsUJs2bUr9PIITAABAJXE6C3/+9hBkp7NwKKSPCpR1NF1bNuRLOTmKDspU2nGH9u83ZLfkK9Q/TwUBwcqxBSnnRLZ8XXm6anR7+YX4KyNDWr/OJcfGn3V8a4p+Tqml5BM+KkjPUUGeUwUuqwp8/FXgX0MFeU7lp+eqoMBQgdOqApdV+S6rnC6LClw2FRhWFbhschoWWWQoyveUfK1O7cmroxPOMFkMlyy/RR8fi1O+Vqd8LQXyUYFOOMOUaRT9S36C1ugaLdU82x3a4WxaIZextlLUIWCnvsntqlyj7A+trm6Objqm6HbmzlhZrYJTfHy8unTpoqlTp0qSXC6XYmNjNWrUKD366KNF2g8YMEBZWVn6/PPP3esuvfRSdejQQdOnTy/SPi8vT3l5ee736enpio2NJTgBAACgzAxDSk+X8vNVGLDycuXrzFVwpL/k7y/DYtWRI5LNasialaG89DzlpDmUk5GvnPQC5WbkKzfbKUee5GNxqoavQ64Cl7Kzpewci3LyrKodnK1GtbPU5NrmsjZppNOnpW+/MZSz67Dy9x6SI89Qfr4hh0PKd0j5BZKrwJDdmq+CAikj26aIGtm6NPaI0hwBWn8kWv62AtUJSldajp8OpwUpx2GTw2mVo8CmvHyr8p1WGYYU5pftXgoKpD3ptZTh8FcNW658fAw5feyFoTPfpYJ8o/BngaGCfMlpsalAPnIahceK9DmlCL8MWUKClGcP1akcf6Xn+spZIDldUkGBRU6X9OmPdRVeP9jU32u1eQCuw+HQ+vXrNXbsWPc6q9WqxMREJSUlFbtPUlKSRo8e7bGuV69e+vjjj4ttP3nyZE2cOLHCagYAAMDFx2KRQkPPvLOq8EHSvz+HzCKpbt0zryrmH+fDwqR+11sk1fttKZ+rK6QKnFF5dwyWQWpqqpxOp6KiojzWR0VFKTk5udh9kpOTy9V+7NixSktLcy8HDx6smOIBAAAAXDRM7XGqCna7XXa73ewyAAAAAFRjpvY4RUREyGazKSUlxWN9SkqKoqOji90nOjq6XO0BAAAA4HyZGpz8/PzUqVMnLV++3L3O5XJp+fLlSkhIKHafhIQEj/aStHTp0nO2BwAAAIDzZfpQvdGjR2vIkCHq3LmzunbtqilTpigrK0vDhg2TJA0ePFh169bV5MmTJUl///vf1bNnT/3nP//Rtddeq7lz5+rHH3/UG2+8YeZpAAAAALiAmR6cBgwYoOPHj2vcuHFKTk5Whw4dtGTJEvcEEAcOHJDV+nvH2GWXXaY5c+boiSee0GOPPaamTZvq448/LtMznAAAAADgzzD9OU5VjQfgAgAAAJDKlw1MvccJAAAAAKoDghMAAAAAlILgBAAAAAClIDgBAAAAQCkITgAAAABQCoITAAAAAJSC4AQAAAAApSA4AQAAAEApCE4AAAAAUAqCEwAAAACUguAEAAAAAKXwMbuAqmYYhiQpPT3d5EoAAAAAmOlMJjiTEUpy0QWnjIwMSVJsbKzJlQAAAADwBhkZGQoNDS2xjcUoS7y6gLhcLh05ckTBwcGyWCym1ZGenq7Y2FgdPHhQISEhptVxMeLam4vrby6uv3m49ubi+puL628urv+5GYahjIwM1alTR1ZryXcxXXQ9TlarVfXq1TO7DLeQkBC+wCbh2puL628urr95uPbm4vqbi+tvLq5/8UrraTqDySEAAAAAoBQEJwAAAAAoBcHJJHa7XePHj5fdbje7lIsO195cXH9zcf3Nw7U3F9ffXFx/c3H9K8ZFNzkEAAAAAJQXPU4AAAAAUAqCEwAAAACUguAEAAAAAKUgOAEAAABAKQhOJpg2bZri4uLk7++v+Ph4rV271uySLkgTJkyQxWLxWFq0aOHenpubq5EjR6pWrVoKCgrSzTffrJSUFBMrrr6++eYb9evXT3Xq1JHFYtHHH3/ssd0wDI0bN04xMTEKCAhQYmKifv31V482J0+e1KBBgxQSEqKwsDANHz5cmZmZVXgW1Vdp13/o0KFF/lvo3bu3Rxuu/58zefJkdenSRcHBwapdu7b69++vnTt3erQpy581Bw4c0LXXXqvAwEDVrl1b//znP1VQUFCVp1ItleX6X3755UW+//fdd59HG67/n/Paa6+pXbt27oeqJiQkaPHixe7tfPcrV2nXn+9+xSM4VbF58+Zp9OjRGj9+vDZs2KD27durV69eOnbsmNmlXZBat26to0ePupfvvvvOve0f//iHPvvsM82fP1+rVq3SkSNHdNNNN5lYbfWVlZWl9u3ba9q0acVuf+655/Tyyy9r+vTp+uGHH1SjRg316tVLubm57jaDBg3Stm3btHTpUn3++ef65ptvdO+991bVKVRrpV1/Serdu7fHfwsffPCBx3au/5+zatUqjRw5Ut9//72WLl2q/Px8XXPNNcrKynK3Ke3PGqfTqWuvvVYOh0Nr1qzR22+/rdmzZ2vcuHFmnFK1UpbrL0n33HOPx/f/ueeec2/j+v959erV07PPPqv169frxx9/1JVXXqkbbrhB27Ztk8R3v7KVdv0lvvsVzkCV6tq1qzFy5Ej3e6fTadSpU8eYPHmyiVVdmMaPH2+0b9++2G2nT582fH19jfnz57vXbd++3ZBkJCUlVVGFFyZJxsKFC93vXS6XER0dbTz//PPudadPnzbsdrvxwQcfGIZhGD///LMhyVi3bp27zeLFiw2LxWIcPny4ymq/EPzx+huGYQwZMsS44YYbzrkP17/iHDt2zJBkrFq1yjCMsv1Zs2jRIsNqtRrJycnuNq+99poREhJi5OXlVe0JVHN/vP6GYRg9e/Y0/v73v59zH65/xQoPDzfefPNNvvsmOXP9DYPvfmWgx6kKORwOrV+/XomJie51VqtViYmJSkpKMrGyC9evv/6qOnXqqFGjRho0aJAOHDggSVq/fr3y8/M9fhctWrRQ/fr1+V1UsL179yo5OdnjWoeGhio+Pt59rZOSkhQWFqbOnTu72yQmJspqteqHH36o8povRCtXrlTt2rXVvHlzjRgxQidOnHBv4/pXnLS0NElSzZo1JZXtz5qkpCS1bdtWUVFR7ja9evVSenq6x78co3R/vP5nvP/++4qIiFCbNm00duxYZWdnu7dx/SuG0+nU3LlzlZWVpYSEBL77VeyP1/8MvvsVy8fsAi4mqampcjqdHl9QSYqKitKOHTtMqurCFR8fr9mzZ6t58+Y6evSoJk6cqO7du2vr1q1KTk6Wn5+fwsLCPPaJiopScnKyOQVfoM5cz+K+92e2JScnq3bt2h7bfXx8VLNmTX4fFaB379666aab1LBhQ+3evVuPPfaY+vTpo6SkJNlsNq5/BXG5XHrooYfUrVs3tWnTRpLK9GdNcnJysf99nNmGsinu+kvSHXfcoQYNGqhOnTravHmzHnnkEe3cuVMLFiyQxPU/X1u2bFFCQoJyc3MVFBSkhQsXqlWrVtq4cSPf/Spwrusv8d2vDAQnXLD69Onjft2uXTvFx8erQYMG+vDDDxUQEGBiZUDVuv32292v27Ztq3bt2qlx48ZauXKlrrrqKhMru7CMHDlSW7du9biXElXnXNf/7Hv12rZtq5iYGF111VXavXu3GjduXNVlXnCaN2+ujRs3Ki0tTR999JGGDBmiVatWmV3WReNc179Vq1Z89ysBQ/WqUEREhGw2W5EZZVJSUhQdHW1SVRePsLAwNWvWTLt27VJ0dLQcDodOnz7t0YbfRcU7cz1L+t5HR0cXmSCloKBAJ0+e5PdRCRo1aqSIiAjt2rVLEte/IjzwwAP6/PPPtWLFCtWrV8+9vix/1kRHRxf738eZbSjdua5/ceLj4yXJ4/vP9f/z/Pz81KRJE3Xq1EmTJ09W+/bt9d///pfvfhU51/UvDt/980dwqkJ+fn7q1KmTli9f7l7ncrm0fPlyj/GoqByZmZnavXu3YmJi1KlTJ/n6+nr8Lnbu3KkDBw7wu6hgDRs2VHR0tMe1Tk9P1w8//OC+1gkJCTp9+rTWr1/vbvP111/L5XK5/6BHxTl06JBOnDihmJgYSVz/82EYhh544AEtXLhQX3/9tRo2bOixvSx/1iQkJGjLli0e4XXp0qUKCQlxD7lB8Uq7/sXZuHGjJHl8/7n+FcflcikvL4/vvknOXP/i8N2vAGbPTnGxmTt3rmG3243Zs2cbP//8s3HvvfcaYWFhHjOaoGI8/PDDxsqVK429e/caq1evNhITE42IiAjj2LFjhmEYxn333WfUr1/f+Prrr40ff/zRSEhIMBISEkyuunrKyMgwfvrpJ+Onn34yJBkvvvii8dNPPxn79+83DMMwnn32WSMsLMz45JNPjM2bNxs33HCD0bBhQyMnJ8d9jN69exuXXHKJ8cMPPxjfffed0bRpU2PgwIFmnVK1UtL1z8jIMMaMGWMkJSUZe/fuNZYtW2Z07NjRaNq0qZGbm+s+Btf/zxkxYoQRGhpqrFy50jh69Kh7yc7Odrcp7c+agoICo02bNsY111xjbNy40ViyZIkRGRlpjB071oxTqlZKu/67du0yJk2aZPz444/G3r17jU8++cRo1KiR0aNHD/cxuP5/3qOPPmqsWrXK2Lt3r7F582bj0UcfNSwWi/HVV18ZhsF3v7KVdP357lcOgpMJXnnlFaN+/fqGn5+f0bVrV+P77783u6QL0oABA4yYmBjDz8/PqFu3rjFgwABj165d7u05OTnG/fffb4SHhxuBgYHGjTfeaBw9etTEiquvFStWGJKKLEOGDDEMo3BK8ieffNKIiooy7Ha7cdVVVxk7d+70OMaJEyeMgQMHGkFBQUZISIgxbNgwIyMjw4SzqX5Kuv7Z2dnGNddcY0RGRhq+vr5GgwYNjHvuuafIP9Zw/f+c4q67JGPWrFnuNmX5s2bfvn1Gnz59jICAACMiIsJ4+OGHjfz8/Co+m+qntOt/4MABo0ePHkbNmjUNu91uNGnSxPjnP/9ppKWleRyH6//n3H333UaDBg0MPz8/IzIy0rjqqqvcockw+O5XtpKuP9/9ymExDMOouv4tAAAAAKh+uMcJAAAAAEpBcAIAAACAUhCcAAAAAKAUBCcAAAAAKAXBCQAAAABKQXACAAAAgFIQnAAAAACgFAQnAAAAACgFwQkAgBJYLBZ9/PHHZpcBADAZwQkA4LWGDh0qi8VSZOndu7fZpQEALjI+ZhcAAEBJevfurVmzZnmss9vtJlUDALhY0eMEAPBqdrtd0dHRHkt4eLikwmF0r732mvr06aOAgAA1atRIH330kcf+W7Zs0ZVXXqmAgADVqlVL9957rzIzMz3avPXWW2rdurXsdrtiYmL0wAMPeGxPTU3VjTfeqMDAQDVt2lSffvqpe9upU6c0aNAgRUZGKiAgQE2bNi0S9AAA1R/BCQBQrT355JO6+eabtWnTJg0aNEi33367tm/fLknKyspSr169FB4ernXr1mn+/PlatmyZRzB67bXXNHLkSN17773asmWLPv30UzVp0sTjMyZOnKjbbrtNmzdvVt++fTVo0CCdPHnS/fk///yzFi9erO3bt+u1115TRERE1V0AAECVsBiGYZhdBAAAxRk6dKjee+89+fv7e6x/7LHH9Nhjj8lisei+++7Ta6+95t526aWXqmPHjnr11Vc1Y8YMPfLIIzp48KBq1KghSVq0aJH69eunI0eOKCoqSnXr1tWwYcP09NNPF1uDxWLRE088oaeeekpSYRgLCgrS4sWL1bt3b11//fWKiIjQW2+9VUlXAQDgDbjHCQDg1a644gqPYCRJNWvWdL9OSEjw2JaQkKCNGzdKkrZv36727du7Q5MkdevWTS6XSzt37pTFYtGRI0d01VVXlVhDu3bt3K9r1KihkJAQHTt2TJI0YsQI3XzzzdqwYYOuueYa9e/fX5dddtmfOlcAgPciOAEAvFqNGjWKDJ2rKAEBAWVq5+vr6/HeYrHI5XJJkvr06aP9+/dr0aJFWrp0qa666iqNHDlSL7zwQoXXCwAwD/c4AQCqte+//77I+5YtW0qSWrZsqU2bNikrK8u9ffXq1bJarWrevLmCg4MVFxen5cuXn1cNkZGRGjJkiN577z1NmTJFb7zxxnkdDwDgfehxAgB4tby8PCUnJ3us8/HxcU/AMH/+fHXu3Fl/+ctf9P7772vt2rWaOXOmJGnQoEEaP368hgwZogkTJuj48eMaNWqU7rrrLkVFRUmSJkyYoPvuu0+1a9dWnz59lJGRodWrV2vUqFFlqm/cuHHq1KmTWrdurby8PH3++efu4AYAuHAQnAAAXm3JkiWKiYnxWNe8eXPt2LFDUuGMd3PnztX999+vmJgYffDBB2rVqpUkKTAwUF9++aX+/ve/q0uXLgoMDNTNN9+sF1980X2sIUOGKDc3Vy+99JLGjBmjiIgI3XLLLWWuz8/PT2PHjtW+ffsUEBCg7t27a+7cuRVw5gAAb8KsegCAastisWjhwoXq37+/2aUAAC5w3OMEAAAAAKUgOAEAAABAKbjHCQBQbTHaHABQVehxAgAAAIBSEJwAAAAAoBQEJwAAAAAoBcEJAAAAAEpBcAIAAACAUhCcAAAAAKAUBCcAAAAAKAXBCQAAAABK8f/K88swtW5ORQAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mse = history.history['loss']\n",
    "val_mse = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(mse) + 1)\n",
    "\n",
    "# MAE Diagramm\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, mse, 'r', label='Training MSE')\n",
    "plt.plot(epochs, val_mse, 'b', label='Validation MSE')\n",
    "plt.title('Training and Validation MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.savefig('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Bilder Diplomarbeit/MSE_NeuroNetz/MSE_NeuroNetz_D4_2')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T14:50:59.363295800Z",
     "start_time": "2024-03-19T14:50:59.153778200Z"
    }
   },
   "id": "3688dd7102e95baf"
  },
  {
   "cell_type": "markdown",
   "id": "553df6fa",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [],
   "source": [
    "def build_model(learning_rate=0.001, activation='relu', regularization=0.0001, dropout_rate=0.0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(264, activation=activation, input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(232, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(280, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(264, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(216, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(72, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(216, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(88, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))    \n",
    "\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Verwenden Sie eine Funktion, um das Modell zu instanziieren, für scikit-learn Wrapper\n",
    "model = KerasRegressor(model=build_model, verbose=2)\n",
    "\n",
    "# Anpassung der Parameter im param_grid\n",
    "param_grid = {\n",
    "    'model__learning_rate': [0.01, 0.001, 0.0001],\n",
    "    'model__regularization': [0.001, 0.0001, 0.00001],\n",
    "    'fit__batch_size': [10, 25, 50, 75],\n",
    "    'fit__epochs': [50],\n",
    "    'model__dropout_rate' : [0.0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=2)\n",
    "# Hinweis: Stellen Sie sicher, dass Ihre Daten (X_train_scaled, y_train_scaled) korrekt definiert sind\n",
    "grid_result = grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "# Beste Parameter und Score ausgeben\n",
    "print(\"Beste Parameter:\", grid_search.best_params_)\n",
    "print(\"Beste Genauigkeit:\", grid_search.best_score_)\n",
    "\n",
    "with open(\"Gridsearch_D4_1.txt\", \"w\") as f:\n",
    "    f.write(f\"Beste Parameter: {grid_search.best_params_}\\n\")\n",
    "    f.write(f\"Beste Genauigkeit: {grid_search.best_score_}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T11:10:51.270610300Z",
     "start_time": "2024-03-15T11:10:51.265221500Z"
    }
   },
   "id": "7464a951f44a07ee"
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [],
   "source": [
    "# Funktion zum Erstellen des Modells\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hp.Int('input_units', min_value=8, max_value=328, step=16), input_shape=(2,), activation='relu'))\n",
    "    for i in range(hp.Int('n_layers', 1, 10)):\n",
    "        model.add(Dense(hp.Int(f'units_{i}', min_value=8, max_value=328, step=16), activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Durchführung der Random Search dreimal\n",
    "for run in range(1, 4):\n",
    "    # Anpassen des Verzeichnisses und des Projektnamens für jeden Durchlauf\n",
    "    directory = 'random_search'\n",
    "    project_name = f'random_search_D4_{run}'\n",
    "\n",
    "    tuner = RandomSearch(\n",
    "        build_model,\n",
    "        objective='val_loss',\n",
    "        max_trials=100,\n",
    "        executions_per_trial=1,\n",
    "        directory=directory,\n",
    "        project_name=project_name\n",
    "    )\n",
    "\n",
    "    # Durchführung des Random Search\n",
    "    tuner.search(X_train_scaled, y_train_scaled, epochs=50, verbose =0, batch_size=20, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "\n",
    "    # Abrufen und Speichern des besten Modells\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "    model_path = os.path.join(directory, project_name, 'best_model.h5') \n",
    "    best_model.save(model_path)\n",
    "\n",
    "\n",
    "    # Optional: Abrufen und Ausgeben der besten Hyperparameter\n",
    "    best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "    # Konvertieren der Hyperparameter in ein DataFrame\n",
    "    df_hyperparameters = pd.DataFrame([best_hyperparameters.values])\n",
    "    # Speichern des DataFrame als CSV\n",
    "    df_hyperparameters.to_csv(f'random_search_D4_{run}.csv', index=False)\n",
    "\n",
    "    print(f\"Beste Hyperparameter für Lauf {run}: {best_hyperparameters.values}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T11:10:51.280272700Z",
     "start_time": "2024-03-15T11:10:51.271373100Z"
    }
   },
   "id": "d0f02feb42b652f5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
