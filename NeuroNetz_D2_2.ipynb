{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94b0518e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:21:54.125218600Z",
     "start_time": "2024-03-19T14:21:48.902106800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense , Dropout\n",
    "from scikeras.wrappers import KerasRegressor \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ff61b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:21:54.142361Z",
     "start_time": "2024-03-19T14:21:54.126218300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n0            0.0000      -0.00200        500   7000   9000      669.05\n1            0.0000      -0.00198        500   7000   9000      682.81\n2            0.0000      -0.00196        500   7000   9000      696.80\n3            0.0000      -0.00194        500   7000   9000      710.67\n4            0.0000      -0.00192        500   7000   9000      724.42\n...             ...           ...        ...    ...    ...         ...\n25321        0.0025       0.00192        500   7000   9000      584.84\n25322        0.0025       0.00194        500   7000   9000      581.64\n25323        0.0025       0.00196        500   7000   9000      578.47\n25324        0.0025       0.00198        500   7000   9000      575.32\n25325        0.0025       0.00200        500   7000   9000      572.20\n\n[25326 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>669.05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0000</td>\n      <td>-0.00198</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>682.81</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0000</td>\n      <td>-0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>696.80</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0000</td>\n      <td>-0.00194</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>710.67</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0000</td>\n      <td>-0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>724.42</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25321</th>\n      <td>0.0025</td>\n      <td>0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>584.84</td>\n    </tr>\n    <tr>\n      <th>25322</th>\n      <td>0.0025</td>\n      <td>0.00194</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>581.64</td>\n    </tr>\n    <tr>\n      <th>25323</th>\n      <td>0.0025</td>\n      <td>0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>578.47</td>\n    </tr>\n    <tr>\n      <th>25324</th>\n      <td>0.0025</td>\n      <td>0.00198</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>575.32</td>\n    </tr>\n    <tr>\n      <th>25325</th>\n      <td>0.0025</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>572.20</td>\n    </tr>\n  </tbody>\n</table>\n<p>25326 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/TPath_300_finish_data.pkl')\n",
    "data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_D2_I7000_F9000/TPath_500_finish_data_D2.pkl')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "966e3c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:21:54.156414600Z",
     "start_time": "2024-03-19T14:21:54.141361200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       X-Koordinate  Y-Koordinate  Temperatur\n0            0.0000      -0.00200      669.05\n1            0.0000      -0.00198      682.81\n2            0.0000      -0.00196      696.80\n3            0.0000      -0.00194      710.67\n4            0.0000      -0.00192      724.42\n...             ...           ...         ...\n25321        0.0025       0.00192      584.84\n25322        0.0025       0.00194      581.64\n25323        0.0025       0.00196      578.47\n25324        0.0025       0.00198      575.32\n25325        0.0025       0.00200      572.20\n\n[25326 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>669.05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0000</td>\n      <td>-0.00198</td>\n      <td>682.81</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0000</td>\n      <td>-0.00196</td>\n      <td>696.80</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0000</td>\n      <td>-0.00194</td>\n      <td>710.67</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0000</td>\n      <td>-0.00192</td>\n      <td>724.42</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25321</th>\n      <td>0.0025</td>\n      <td>0.00192</td>\n      <td>584.84</td>\n    </tr>\n    <tr>\n      <th>25322</th>\n      <td>0.0025</td>\n      <td>0.00194</td>\n      <td>581.64</td>\n    </tr>\n    <tr>\n      <th>25323</th>\n      <td>0.0025</td>\n      <td>0.00196</td>\n      <td>578.47</td>\n    </tr>\n    <tr>\n      <th>25324</th>\n      <td>0.0025</td>\n      <td>0.00198</td>\n      <td>575.32</td>\n    </tr>\n    <tr>\n      <th>25325</th>\n      <td>0.0025</td>\n      <td>0.00200</td>\n      <td>572.20</td>\n    </tr>\n  </tbody>\n</table>\n<p>25326 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.drop(data.columns[2:5], axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8783d1d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:21:54.185214800Z",
     "start_time": "2024-03-19T14:21:54.149414800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       X-Koordinate  Y-Koordinate  Temperatur\n",
      "5099        0.00050      -0.00052     1471.00\n",
      "12799       0.00126       0.00072     1319.30\n",
      "15071       0.00148       0.00194      595.19\n",
      "24620       0.00244      -0.00004     1249.00\n",
      "11071       0.00110      -0.00168      884.35\n",
      "...             ...           ...         ...\n",
      "21575       0.00214      -0.00064     1263.60\n",
      "5390        0.00052       0.00128     1035.40\n",
      "860         0.00008      -0.00088     1376.50\n",
      "15795       0.00156       0.00034     1383.80\n",
      "23654       0.00234       0.00074     1149.60\n",
      "\n",
      "[25326 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": "       X-Koordinate  Y-Koordinate  Temperatur\n0           0.00050      -0.00052     1471.00\n1           0.00126       0.00072     1319.30\n2           0.00148       0.00194      595.19\n3           0.00244      -0.00004     1249.00\n4           0.00110      -0.00168      884.35\n...             ...           ...         ...\n25321       0.00214      -0.00064     1263.60\n25322       0.00052       0.00128     1035.40\n25323       0.00008      -0.00088     1376.50\n25324       0.00156       0.00034     1383.80\n25325       0.00234       0.00074     1149.60\n\n[25326 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00050</td>\n      <td>-0.00052</td>\n      <td>1471.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00126</td>\n      <td>0.00072</td>\n      <td>1319.30</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00148</td>\n      <td>0.00194</td>\n      <td>595.19</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00244</td>\n      <td>-0.00004</td>\n      <td>1249.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00110</td>\n      <td>-0.00168</td>\n      <td>884.35</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25321</th>\n      <td>0.00214</td>\n      <td>-0.00064</td>\n      <td>1263.60</td>\n    </tr>\n    <tr>\n      <th>25322</th>\n      <td>0.00052</td>\n      <td>0.00128</td>\n      <td>1035.40</td>\n    </tr>\n    <tr>\n      <th>25323</th>\n      <td>0.00008</td>\n      <td>-0.00088</td>\n      <td>1376.50</td>\n    </tr>\n    <tr>\n      <th>25324</th>\n      <td>0.00156</td>\n      <td>0.00034</td>\n      <td>1383.80</td>\n    </tr>\n    <tr>\n      <th>25325</th>\n      <td>0.00234</td>\n      <td>0.00074</td>\n      <td>1149.60</td>\n    </tr>\n  </tbody>\n</table>\n<p>25326 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.sample(frac=1, random_state=42)  # Hier wird 42 als Random State verwendet, um die Ergebnisse reproduzierbar zu machen\n",
    "\n",
    "print(df1)\n",
    "df_reset = df1.reset_index(drop=True)\n",
    "df_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4e72a16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:21:54.188366900Z",
     "start_time": "2024-03-19T14:21:54.160116300Z"
    }
   },
   "outputs": [],
   "source": [
    "label = df_reset[\"Temperatur\"]\n",
    "# Korrektur: Verwenden Sie den Spaltennamen direkt, ohne Indexierung der columns-Eigenschaft\n",
    "df1 = df_reset.drop(\"Temperatur\", axis=1)\n",
    "X = df1\n",
    "y = label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7fa289a50d87423"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e694a236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:21:54.251674800Z",
     "start_time": "2024-03-19T14:21:54.165643300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       X-Koordinate  Y-Koordinate\n0           0.00050      -0.00052\n1           0.00126       0.00072\n2           0.00148       0.00194\n3           0.00244      -0.00004\n4           0.00110      -0.00168\n...             ...           ...\n25321       0.00214      -0.00064\n25322       0.00052       0.00128\n25323       0.00008      -0.00088\n25324       0.00156       0.00034\n25325       0.00234       0.00074\n\n[25326 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00050</td>\n      <td>-0.00052</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00126</td>\n      <td>0.00072</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00148</td>\n      <td>0.00194</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00244</td>\n      <td>-0.00004</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00110</td>\n      <td>-0.00168</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25321</th>\n      <td>0.00214</td>\n      <td>-0.00064</td>\n    </tr>\n    <tr>\n      <th>25322</th>\n      <td>0.00052</td>\n      <td>0.00128</td>\n    </tr>\n    <tr>\n      <th>25323</th>\n      <td>0.00008</td>\n      <td>-0.00088</td>\n    </tr>\n    <tr>\n      <th>25324</th>\n      <td>0.00156</td>\n      <td>0.00034</td>\n    </tr>\n    <tr>\n      <th>25325</th>\n      <td>0.00234</td>\n      <td>0.00074</td>\n    </tr>\n  </tbody>\n</table>\n<p>25326 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f3303b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:21:54.262675900Z",
     "start_time": "2024-03-19T14:21:54.171604100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0        1471.00\n1        1319.30\n2         595.19\n3        1249.00\n4         884.35\n          ...   \n25321    1263.60\n25322    1035.40\n25323    1376.50\n25324    1383.80\n25325    1149.60\nName: Temperatur, Length: 25326, dtype: float64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3ad8da0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:21:54.262675900Z",
     "start_time": "2024-03-19T14:21:54.176799900Z"
    }
   },
   "outputs": [],
   "source": [
    " # train_df enthält 80% der Daten, test_df enthält 20% der Daten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c705edb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:21:54.267675500Z",
     "start_time": "2024-03-19T14:21:54.182215100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialisiere einen MinMaxScaler für die Features\n",
    "scaler_features = MinMaxScaler()\n",
    "scaler_features2 = MinMaxScaler()\n",
    "# Skaliere X_train und X_test\n",
    "X_train_scaled = scaler_features.fit_transform(X_train)\n",
    "X_test_scaled = scaler_features.transform(X_test)  # Nutze unterschiedliche Skalierungsparameter\n",
    "\n",
    "# Initialisiere einen SEPARATEN MinMaxScaler für das Ziel, wenn nötig\n",
    "scaler_target = MinMaxScaler()\n",
    "\n",
    "\n",
    "# Skaliere y_train und y_test. Beachte, dass y_train.reshape(-1, 1) verwendet wird, da MinMaxScaler \n",
    "# erwartet, dass die Eingaben als 2D-Arrays kommen, und Ziele normalerweise als 1D-Arrays vorliegen.\n",
    "y_train_scaled = scaler_target.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test_scaled = scaler_target.transform(y_test.values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbefe631e495b483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:21:54.288675800Z",
     "start_time": "2024-03-19T14:21:54.188366900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.   , 0.15 ],\n       [0.984, 0.49 ],\n       [0.224, 0.905],\n       ...,\n       [0.04 , 0.585],\n       [0.976, 0.815],\n       [0.744, 0.785]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Netzwerkarchitektur"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d664797f8dcbd88c"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "163/163 [==============================] - 2s 3ms/step - loss: 0.2987 - mae: 0.3868 - val_loss: 0.1243 - val_mae: 0.2618\n",
      "Epoch 2/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0865 - mae: 0.2063 - val_loss: 0.0406 - val_mae: 0.1246\n",
      "Epoch 3/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0224 - mae: 0.0632 - val_loss: 0.0158 - val_mae: 0.0346\n",
      "Epoch 4/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0143 - mae: 0.0224 - val_loss: 0.0137 - val_mae: 0.0201\n",
      "Epoch 5/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0132 - mae: 0.0152 - val_loss: 0.0133 - val_mae: 0.0200\n",
      "Epoch 6/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0126 - mae: 0.0123 - val_loss: 0.0127 - val_mae: 0.0192\n",
      "Epoch 7/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0120 - mae: 0.0102 - val_loss: 0.0119 - val_mae: 0.0134\n",
      "Epoch 8/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0117 - mae: 0.0094 - val_loss: 0.0114 - val_mae: 0.0083\n",
      "Epoch 9/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0113 - mae: 0.0096 - val_loss: 0.0112 - val_mae: 0.0092\n",
      "Epoch 10/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0111 - mae: 0.0091 - val_loss: 0.0113 - val_mae: 0.0159\n",
      "Epoch 11/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0109 - mae: 0.0094 - val_loss: 0.0107 - val_mae: 0.0086\n",
      "Epoch 12/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0107 - mae: 0.0098 - val_loss: 0.0111 - val_mae: 0.0176\n",
      "Epoch 13/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0105 - mae: 0.0089 - val_loss: 0.0104 - val_mae: 0.0072\n",
      "Epoch 14/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0106 - mae: 0.0138 - val_loss: 0.0102 - val_mae: 0.0066\n",
      "Epoch 15/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0070 - val_loss: 0.0116 - val_mae: 0.0299\n",
      "Epoch 16/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0116 - val_loss: 0.0107 - val_mae: 0.0209\n",
      "Epoch 17/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0100 - val_loss: 0.0099 - val_mae: 0.0068\n",
      "Epoch 18/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0068 - val_loss: 0.0099 - val_mae: 0.0078\n",
      "Epoch 19/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0077 - val_loss: 0.0097 - val_mae: 0.0056\n",
      "Epoch 20/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0098 - val_loss: 0.0097 - val_mae: 0.0072\n",
      "Epoch 21/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0133 - val_loss: 0.0096 - val_mae: 0.0059\n",
      "Epoch 22/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0096 - mae: 0.0050 - val_loss: 0.0097 - val_mae: 0.0101\n",
      "Epoch 23/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0097 - mae: 0.0098 - val_loss: 0.0095 - val_mae: 0.0048\n",
      "Epoch 24/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0095 - mae: 0.0059 - val_loss: 0.0094 - val_mae: 0.0059\n",
      "Epoch 25/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0095 - mae: 0.0084 - val_loss: 0.0096 - val_mae: 0.0120\n",
      "Epoch 26/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0094 - mae: 0.0071 - val_loss: 0.0093 - val_mae: 0.0062\n",
      "Epoch 27/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0095 - mae: 0.0108 - val_loss: 0.0093 - val_mae: 0.0051\n",
      "Epoch 28/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0095 - mae: 0.0113 - val_loss: 0.0097 - val_mae: 0.0181\n",
      "Epoch 29/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0093 - mae: 0.0074 - val_loss: 0.0094 - val_mae: 0.0116\n",
      "Epoch 30/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0092 - mae: 0.0068 - val_loss: 0.0091 - val_mae: 0.0054\n",
      "Epoch 31/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0091 - mae: 0.0049 - val_loss: 0.0091 - val_mae: 0.0049\n",
      "Epoch 32/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0092 - mae: 0.0100 - val_loss: 0.0093 - val_mae: 0.0114\n",
      "Epoch 33/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0092 - mae: 0.0088 - val_loss: 0.0090 - val_mae: 0.0078\n",
      "Epoch 34/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0090 - mae: 0.0063 - val_loss: 0.0090 - val_mae: 0.0078\n",
      "Epoch 35/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0090 - mae: 0.0075 - val_loss: 0.0093 - val_mae: 0.0193\n",
      "Epoch 36/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0091 - mae: 0.0112 - val_loss: 0.0093 - val_mae: 0.0165\n",
      "Epoch 37/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0089 - mae: 0.0077 - val_loss: 0.0090 - val_mae: 0.0125\n",
      "Epoch 38/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0089 - mae: 0.0080 - val_loss: 0.0087 - val_mae: 0.0045\n",
      "Epoch 39/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0088 - mae: 0.0061 - val_loss: 0.0087 - val_mae: 0.0045\n",
      "Epoch 40/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0089 - mae: 0.0118 - val_loss: 0.0087 - val_mae: 0.0045\n",
      "Epoch 41/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0087 - mae: 0.0072 - val_loss: 0.0086 - val_mae: 0.0055\n",
      "Epoch 42/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0061 - val_loss: 0.0086 - val_mae: 0.0081\n",
      "Epoch 43/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0079 - val_loss: 0.0085 - val_mae: 0.0046\n",
      "Epoch 44/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0086 - mae: 0.0068 - val_loss: 0.0085 - val_mae: 0.0079\n",
      "Epoch 45/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0085 - mae: 0.0072 - val_loss: 0.0103 - val_mae: 0.0332\n",
      "Epoch 46/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0085 - mae: 0.0077 - val_loss: 0.0087 - val_mae: 0.0142\n",
      "Epoch 47/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0085 - mae: 0.0086 - val_loss: 0.0090 - val_mae: 0.0203\n",
      "Epoch 48/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0084 - mae: 0.0063 - val_loss: 0.0086 - val_mae: 0.0137\n",
      "Epoch 49/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0084 - mae: 0.0081 - val_loss: 0.0083 - val_mae: 0.0064\n",
      "Epoch 50/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0084 - mae: 0.0094 - val_loss: 0.0083 - val_mae: 0.0062\n",
      "Epoch 51/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0083 - mae: 0.0071 - val_loss: 0.0083 - val_mae: 0.0077\n",
      "Epoch 52/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0082 - mae: 0.0056 - val_loss: 0.0082 - val_mae: 0.0084\n",
      "Epoch 53/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0084 - mae: 0.0101 - val_loss: 0.0082 - val_mae: 0.0075\n",
      "Epoch 54/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0081 - mae: 0.0052 - val_loss: 0.0084 - val_mae: 0.0164\n",
      "Epoch 55/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0081 - mae: 0.0069 - val_loss: 0.0081 - val_mae: 0.0072\n",
      "Epoch 56/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0081 - mae: 0.0063 - val_loss: 0.0108 - val_mae: 0.0441\n",
      "Epoch 57/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0082 - mae: 0.0105 - val_loss: 0.0080 - val_mae: 0.0064\n",
      "Epoch 58/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0080 - mae: 0.0059 - val_loss: 0.0080 - val_mae: 0.0071\n",
      "Epoch 59/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0080 - mae: 0.0067 - val_loss: 0.0079 - val_mae: 0.0043\n",
      "Epoch 60/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0079 - mae: 0.0053 - val_loss: 0.0078 - val_mae: 0.0052\n",
      "Epoch 61/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0080 - mae: 0.0090 - val_loss: 0.0084 - val_mae: 0.0188\n",
      "Epoch 62/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0079 - mae: 0.0084 - val_loss: 0.0078 - val_mae: 0.0074\n",
      "Epoch 63/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0078 - mae: 0.0047 - val_loss: 0.0081 - val_mae: 0.0158\n",
      "Epoch 64/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0078 - mae: 0.0086 - val_loss: 0.0077 - val_mae: 0.0049\n",
      "Epoch 65/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0077 - mae: 0.0060 - val_loss: 0.0080 - val_mae: 0.0147\n",
      "Epoch 66/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0077 - mae: 0.0072 - val_loss: 0.0076 - val_mae: 0.0031\n",
      "Epoch 67/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0076 - mae: 0.0047 - val_loss: 0.0076 - val_mae: 0.0063\n",
      "Epoch 68/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0078 - mae: 0.0106 - val_loss: 0.0076 - val_mae: 0.0054\n",
      "Epoch 69/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0075 - mae: 0.0045 - val_loss: 0.0075 - val_mae: 0.0060\n",
      "Epoch 70/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0075 - mae: 0.0055 - val_loss: 0.0075 - val_mae: 0.0053\n",
      "Epoch 71/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0075 - mae: 0.0056 - val_loss: 0.0075 - val_mae: 0.0050\n",
      "Epoch 72/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0077 - mae: 0.0101 - val_loss: 0.0074 - val_mae: 0.0061\n",
      "Epoch 73/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0075 - mae: 0.0083 - val_loss: 0.0074 - val_mae: 0.0041\n",
      "Epoch 74/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0074 - mae: 0.0049 - val_loss: 0.0073 - val_mae: 0.0035\n",
      "Epoch 75/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0073 - mae: 0.0044 - val_loss: 0.0079 - val_mae: 0.0172\n",
      "Epoch 76/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0074 - mae: 0.0095 - val_loss: 0.0073 - val_mae: 0.0047\n",
      "Epoch 77/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0073 - mae: 0.0051 - val_loss: 0.0077 - val_mae: 0.0166\n",
      "Epoch 78/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0073 - mae: 0.0076 - val_loss: 0.0072 - val_mae: 0.0035\n",
      "Epoch 79/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0072 - mae: 0.0045 - val_loss: 0.0072 - val_mae: 0.0056\n",
      "Epoch 80/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0072 - mae: 0.0057 - val_loss: 0.0075 - val_mae: 0.0141\n",
      "Epoch 81/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0074 - mae: 0.0094 - val_loss: 0.0071 - val_mae: 0.0033\n",
      "Epoch 82/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0071 - mae: 0.0046 - val_loss: 0.0071 - val_mae: 0.0042\n",
      "Epoch 83/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0071 - mae: 0.0058 - val_loss: 0.0071 - val_mae: 0.0061\n",
      "Epoch 84/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0071 - mae: 0.0053 - val_loss: 0.0071 - val_mae: 0.0065\n",
      "Epoch 85/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0070 - mae: 0.0048 - val_loss: 0.0071 - val_mae: 0.0074\n",
      "Epoch 86/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0070 - mae: 0.0065 - val_loss: 0.0072 - val_mae: 0.0116\n",
      "Epoch 87/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0071 - mae: 0.0084 - val_loss: 0.0069 - val_mae: 0.0047\n",
      "Epoch 88/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0070 - mae: 0.0062 - val_loss: 0.0069 - val_mae: 0.0045\n",
      "Epoch 89/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0070 - mae: 0.0080 - val_loss: 0.0081 - val_mae: 0.0243\n",
      "Epoch 90/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0072 - mae: 0.0110 - val_loss: 0.0068 - val_mae: 0.0032\n",
      "Epoch 91/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0068 - mae: 0.0031 - val_loss: 0.0069 - val_mae: 0.0054\n",
      "Epoch 92/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0068 - mae: 0.0037 - val_loss: 0.0069 - val_mae: 0.0086\n",
      "Epoch 93/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0068 - mae: 0.0034 - val_loss: 0.0068 - val_mae: 0.0039\n",
      "Epoch 94/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0068 - mae: 0.0037 - val_loss: 0.0068 - val_mae: 0.0090\n",
      "Epoch 95/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0069 - mae: 0.0086 - val_loss: 0.0068 - val_mae: 0.0070\n",
      "Epoch 96/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0067 - mae: 0.0052 - val_loss: 0.0067 - val_mae: 0.0054\n",
      "Epoch 97/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0067 - mae: 0.0044 - val_loss: 0.0067 - val_mae: 0.0057\n",
      "Epoch 98/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0067 - mae: 0.0052 - val_loss: 0.0066 - val_mae: 0.0035\n",
      "Epoch 99/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0067 - mae: 0.0060 - val_loss: 0.0070 - val_mae: 0.0160\n",
      "Epoch 100/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0067 - mae: 0.0069 - val_loss: 0.0070 - val_mae: 0.0150\n",
      "Epoch 101/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0066 - mae: 0.0063 - val_loss: 0.0067 - val_mae: 0.0106\n",
      "Epoch 102/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0066 - mae: 0.0061 - val_loss: 0.0066 - val_mae: 0.0055\n",
      "Epoch 103/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0067 - mae: 0.0089 - val_loss: 0.0068 - val_mae: 0.0123\n",
      "Epoch 104/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0065 - mae: 0.0038 - val_loss: 0.0065 - val_mae: 0.0040\n",
      "Epoch 105/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0065 - mae: 0.0041 - val_loss: 0.0065 - val_mae: 0.0038\n",
      "Epoch 106/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0065 - mae: 0.0059 - val_loss: 0.0064 - val_mae: 0.0035\n",
      "Epoch 107/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0065 - mae: 0.0052 - val_loss: 0.0066 - val_mae: 0.0103\n",
      "Epoch 108/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0064 - mae: 0.0050 - val_loss: 0.0066 - val_mae: 0.0115\n",
      "Epoch 109/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0066 - mae: 0.0093 - val_loss: 0.0064 - val_mae: 0.0029\n",
      "Epoch 110/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0064 - mae: 0.0051 - val_loss: 0.0064 - val_mae: 0.0055\n",
      "Epoch 111/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0064 - mae: 0.0039 - val_loss: 0.0065 - val_mae: 0.0106\n",
      "Epoch 112/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0064 - mae: 0.0050 - val_loss: 0.0063 - val_mae: 0.0042\n",
      "Epoch 113/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0063 - mae: 0.0045 - val_loss: 0.0063 - val_mae: 0.0045\n",
      "Epoch 114/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0063 - mae: 0.0036 - val_loss: 0.0063 - val_mae: 0.0025\n",
      "Epoch 115/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0063 - mae: 0.0045 - val_loss: 0.0063 - val_mae: 0.0049\n",
      "Epoch 116/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0063 - mae: 0.0058 - val_loss: 0.0064 - val_mae: 0.0096\n",
      "Epoch 117/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0063 - mae: 0.0065 - val_loss: 0.0063 - val_mae: 0.0096\n",
      "Epoch 118/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0062 - mae: 0.0039 - val_loss: 0.0062 - val_mae: 0.0043\n",
      "Epoch 119/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0062 - mae: 0.0057 - val_loss: 0.0062 - val_mae: 0.0037\n",
      "Epoch 120/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0063 - mae: 0.0078 - val_loss: 0.0062 - val_mae: 0.0076\n",
      "Epoch 121/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0062 - mae: 0.0045 - val_loss: 0.0061 - val_mae: 0.0030\n",
      "Epoch 122/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0061 - mae: 0.0037 - val_loss: 0.0061 - val_mae: 0.0025\n",
      "Epoch 123/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0062 - mae: 0.0057 - val_loss: 0.0065 - val_mae: 0.0165\n",
      "Epoch 124/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0062 - mae: 0.0076 - val_loss: 0.0061 - val_mae: 0.0041\n",
      "Epoch 125/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0061 - mae: 0.0037 - val_loss: 0.0061 - val_mae: 0.0033\n",
      "Epoch 126/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0060 - mae: 0.0030 - val_loss: 0.0061 - val_mae: 0.0068\n",
      "Epoch 127/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0060 - mae: 0.0036 - val_loss: 0.0060 - val_mae: 0.0042\n",
      "Epoch 128/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0060 - mae: 0.0036 - val_loss: 0.0060 - val_mae: 0.0030\n",
      "Epoch 129/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0060 - mae: 0.0039 - val_loss: 0.0060 - val_mae: 0.0039\n",
      "Epoch 130/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0062 - mae: 0.0106 - val_loss: 0.0060 - val_mae: 0.0043\n",
      "Epoch 131/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0060 - mae: 0.0034 - val_loss: 0.0059 - val_mae: 0.0029\n",
      "Epoch 132/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0060 - mae: 0.0040 - val_loss: 0.0067 - val_mae: 0.0202\n",
      "Epoch 133/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0060 - mae: 0.0069 - val_loss: 0.0059 - val_mae: 0.0055\n",
      "Epoch 134/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0059 - mae: 0.0034 - val_loss: 0.0059 - val_mae: 0.0023\n",
      "Epoch 135/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0059 - mae: 0.0036 - val_loss: 0.0059 - val_mae: 0.0067\n",
      "Epoch 136/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0059 - mae: 0.0050 - val_loss: 0.0059 - val_mae: 0.0033\n",
      "Epoch 137/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0059 - mae: 0.0039 - val_loss: 0.0059 - val_mae: 0.0038\n",
      "Epoch 138/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0059 - mae: 0.0062 - val_loss: 0.0060 - val_mae: 0.0108\n",
      "Epoch 139/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0059 - mae: 0.0046 - val_loss: 0.0059 - val_mae: 0.0081\n",
      "Epoch 140/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0058 - mae: 0.0046 - val_loss: 0.0058 - val_mae: 0.0061\n",
      "Epoch 141/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0059 - mae: 0.0079 - val_loss: 0.0058 - val_mae: 0.0028\n",
      "Epoch 142/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0058 - mae: 0.0033 - val_loss: 0.0058 - val_mae: 0.0053\n",
      "Epoch 143/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0058 - mae: 0.0038 - val_loss: 0.0058 - val_mae: 0.0053\n",
      "Epoch 144/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0057 - mae: 0.0030 - val_loss: 0.0058 - val_mae: 0.0067\n",
      "Epoch 145/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0059 - mae: 0.0072 - val_loss: 0.0057 - val_mae: 0.0048\n",
      "Epoch 146/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0057 - mae: 0.0037 - val_loss: 0.0057 - val_mae: 0.0027\n",
      "Epoch 147/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0057 - mae: 0.0035 - val_loss: 0.0058 - val_mae: 0.0078\n",
      "Epoch 148/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0057 - mae: 0.0052 - val_loss: 0.0057 - val_mae: 0.0025\n",
      "Epoch 149/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0057 - mae: 0.0047 - val_loss: 0.0057 - val_mae: 0.0048\n",
      "Epoch 150/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0057 - mae: 0.0034 - val_loss: 0.0057 - val_mae: 0.0063\n",
      "Epoch 151/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0057 - mae: 0.0049 - val_loss: 0.0057 - val_mae: 0.0060\n",
      "Epoch 152/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0056 - mae: 0.0037 - val_loss: 0.0056 - val_mae: 0.0050\n",
      "Epoch 153/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0057 - mae: 0.0050 - val_loss: 0.0057 - val_mae: 0.0077\n",
      "Epoch 154/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0057 - mae: 0.0092 - val_loss: 0.0078 - val_mae: 0.0379\n",
      "Epoch 155/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0057 - mae: 0.0068 - val_loss: 0.0056 - val_mae: 0.0029\n",
      "Epoch 156/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0056 - mae: 0.0024 - val_loss: 0.0056 - val_mae: 0.0025\n",
      "Epoch 157/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0025 - val_loss: 0.0055 - val_mae: 0.0023\n",
      "Epoch 158/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0037 - val_loss: 0.0056 - val_mae: 0.0060\n",
      "Epoch 159/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0042 - val_loss: 0.0055 - val_mae: 0.0038\n",
      "Epoch 160/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0030 - val_loss: 0.0055 - val_mae: 0.0033\n",
      "Epoch 161/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0031 - val_loss: 0.0055 - val_mae: 0.0029\n",
      "Epoch 162/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0032 - val_loss: 0.0055 - val_mae: 0.0021\n",
      "Epoch 163/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0048 - val_loss: 0.0055 - val_mae: 0.0075\n",
      "Epoch 164/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0051 - val_loss: 0.0054 - val_mae: 0.0041\n",
      "Epoch 165/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0054 - mae: 0.0042 - val_loss: 0.0054 - val_mae: 0.0034\n",
      "Epoch 166/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0055 - val_loss: 0.0054 - val_mae: 0.0056\n",
      "Epoch 167/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0054 - mae: 0.0044 - val_loss: 0.0054 - val_mae: 0.0033\n",
      "Epoch 168/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0054 - mae: 0.0036 - val_loss: 0.0055 - val_mae: 0.0077\n",
      "Epoch 169/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0072 - val_loss: 0.0054 - val_mae: 0.0022\n",
      "Epoch 170/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0054 - mae: 0.0028 - val_loss: 0.0054 - val_mae: 0.0087\n",
      "Epoch 171/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0054 - mae: 0.0053 - val_loss: 0.0054 - val_mae: 0.0053\n",
      "Epoch 172/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0054 - mae: 0.0046 - val_loss: 0.0053 - val_mae: 0.0024\n",
      "Epoch 173/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0053 - mae: 0.0039 - val_loss: 0.0053 - val_mae: 0.0043\n",
      "Epoch 174/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0053 - mae: 0.0035 - val_loss: 0.0053 - val_mae: 0.0039\n",
      "Epoch 175/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0053 - mae: 0.0032 - val_loss: 0.0053 - val_mae: 0.0063\n",
      "Epoch 176/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0053 - mae: 0.0030 - val_loss: 0.0053 - val_mae: 0.0037\n",
      "Epoch 177/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0054 - mae: 0.0072 - val_loss: 0.0052 - val_mae: 0.0036\n",
      "Epoch 178/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0029 - val_loss: 0.0052 - val_mae: 0.0021\n",
      "Epoch 179/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0025 - val_loss: 0.0052 - val_mae: 0.0032\n",
      "Epoch 180/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0049 - val_loss: 0.0052 - val_mae: 0.0045\n",
      "Epoch 181/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0046 - val_loss: 0.0052 - val_mae: 0.0040\n",
      "Epoch 182/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0033 - val_loss: 0.0052 - val_mae: 0.0043\n",
      "Epoch 183/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0031 - val_loss: 0.0057 - val_mae: 0.0172\n",
      "Epoch 184/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0050 - val_loss: 0.0052 - val_mae: 0.0045\n",
      "Epoch 185/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0045 - val_loss: 0.0051 - val_mae: 0.0023\n",
      "Epoch 186/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0051 - mae: 0.0027 - val_loss: 0.0053 - val_mae: 0.0107\n",
      "Epoch 187/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0051 - mae: 0.0031 - val_loss: 0.0052 - val_mae: 0.0059\n",
      "Epoch 188/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0051 - mae: 0.0038 - val_loss: 0.0051 - val_mae: 0.0026\n",
      "Epoch 189/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0057 - val_loss: 0.0052 - val_mae: 0.0097\n",
      "Epoch 190/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0051 - mae: 0.0046 - val_loss: 0.0051 - val_mae: 0.0054\n",
      "Epoch 191/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0051 - mae: 0.0032 - val_loss: 0.0051 - val_mae: 0.0057\n",
      "Epoch 192/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0051 - mae: 0.0042 - val_loss: 0.0051 - val_mae: 0.0063\n",
      "Epoch 193/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0050 - mae: 0.0040 - val_loss: 0.0051 - val_mae: 0.0055\n",
      "Epoch 194/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0051 - mae: 0.0048 - val_loss: 0.0053 - val_mae: 0.0123\n",
      "Epoch 195/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0050 - mae: 0.0048 - val_loss: 0.0050 - val_mae: 0.0032\n",
      "Epoch 196/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0050 - mae: 0.0043 - val_loss: 0.0051 - val_mae: 0.0082\n",
      "Epoch 197/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0050 - mae: 0.0028 - val_loss: 0.0050 - val_mae: 0.0031\n",
      "Epoch 198/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0050 - mae: 0.0026 - val_loss: 0.0050 - val_mae: 0.0027\n",
      "Epoch 199/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0049 - mae: 0.0026 - val_loss: 0.0049 - val_mae: 0.0023\n",
      "Epoch 200/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0050 - mae: 0.0047 - val_loss: 0.0050 - val_mae: 0.0058\n",
      "Epoch 201/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0050 - mae: 0.0056 - val_loss: 0.0050 - val_mae: 0.0062\n",
      "Epoch 202/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0049 - mae: 0.0032 - val_loss: 0.0049 - val_mae: 0.0052\n",
      "Epoch 203/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0049 - mae: 0.0028 - val_loss: 0.0049 - val_mae: 0.0050\n",
      "Epoch 204/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0049 - mae: 0.0033 - val_loss: 0.0050 - val_mae: 0.0084\n",
      "Epoch 205/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0049 - mae: 0.0050 - val_loss: 0.0049 - val_mae: 0.0020\n",
      "Epoch 206/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0049 - mae: 0.0026 - val_loss: 0.0048 - val_mae: 0.0019\n",
      "Epoch 207/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0049 - mae: 0.0052 - val_loss: 0.0049 - val_mae: 0.0065\n",
      "Epoch 208/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0049 - mae: 0.0041 - val_loss: 0.0048 - val_mae: 0.0027\n",
      "Epoch 209/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0048 - mae: 0.0030 - val_loss: 0.0048 - val_mae: 0.0042\n",
      "Epoch 210/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0048 - mae: 0.0033 - val_loss: 0.0048 - val_mae: 0.0030\n",
      "Epoch 211/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0048 - mae: 0.0027 - val_loss: 0.0048 - val_mae: 0.0051\n",
      "Epoch 212/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0048 - mae: 0.0051 - val_loss: 0.0048 - val_mae: 0.0022\n",
      "Epoch 213/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0048 - mae: 0.0033 - val_loss: 0.0049 - val_mae: 0.0086\n",
      "Epoch 214/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0048 - mae: 0.0045 - val_loss: 0.0048 - val_mae: 0.0036\n",
      "Epoch 215/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0047 - mae: 0.0034 - val_loss: 0.0047 - val_mae: 0.0032\n",
      "Epoch 216/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0047 - mae: 0.0040 - val_loss: 0.0048 - val_mae: 0.0066\n",
      "Epoch 217/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0047 - mae: 0.0032 - val_loss: 0.0047 - val_mae: 0.0039\n",
      "Epoch 218/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0047 - mae: 0.0033 - val_loss: 0.0047 - val_mae: 0.0030\n",
      "Epoch 219/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0049 - mae: 0.0080 - val_loss: 0.0048 - val_mae: 0.0104\n",
      "Epoch 220/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0047 - mae: 0.0030 - val_loss: 0.0047 - val_mae: 0.0025\n",
      "Epoch 221/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0047 - mae: 0.0023 - val_loss: 0.0047 - val_mae: 0.0023\n",
      "Epoch 222/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0047 - mae: 0.0025 - val_loss: 0.0047 - val_mae: 0.0077\n",
      "Epoch 223/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0047 - mae: 0.0044 - val_loss: 0.0046 - val_mae: 0.0029\n",
      "Epoch 224/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0022 - val_loss: 0.0046 - val_mae: 0.0040\n",
      "Epoch 225/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0030 - val_loss: 0.0048 - val_mae: 0.0120\n",
      "Epoch 226/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0047 - mae: 0.0048 - val_loss: 0.0046 - val_mae: 0.0048\n",
      "Epoch 227/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0026 - val_loss: 0.0046 - val_mae: 0.0048\n",
      "Epoch 228/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0033 - val_loss: 0.0047 - val_mae: 0.0064\n",
      "Epoch 229/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0035 - val_loss: 0.0048 - val_mae: 0.0114\n",
      "Epoch 230/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0031 - val_loss: 0.0048 - val_mae: 0.0121\n",
      "Epoch 231/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0048 - val_loss: 0.0045 - val_mae: 0.0030\n",
      "Epoch 232/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0031 - val_loss: 0.0047 - val_mae: 0.0099\n",
      "Epoch 233/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0038 - val_loss: 0.0045 - val_mae: 0.0047\n",
      "Epoch 234/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0036 - val_loss: 0.0045 - val_mae: 0.0051\n",
      "Epoch 235/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0026 - val_loss: 0.0045 - val_mae: 0.0026\n",
      "Epoch 236/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0029 - val_loss: 0.0045 - val_mae: 0.0028\n",
      "Epoch 237/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0053 - val_loss: 0.0045 - val_mae: 0.0024\n",
      "Epoch 238/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0022 - val_loss: 0.0045 - val_mae: 0.0035\n",
      "Epoch 239/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0031 - val_loss: 0.0044 - val_mae: 0.0022\n",
      "Epoch 240/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0033 - val_loss: 0.0044 - val_mae: 0.0030\n",
      "Epoch 241/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0033 - val_loss: 0.0044 - val_mae: 0.0032\n",
      "Epoch 242/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0069 - val_loss: 0.0045 - val_mae: 0.0080\n",
      "Epoch 243/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0028 - val_loss: 0.0044 - val_mae: 0.0043\n",
      "Epoch 244/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0025 - val_loss: 0.0044 - val_mae: 0.0064\n",
      "Epoch 245/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0039 - val_loss: 0.0044 - val_mae: 0.0023\n",
      "Epoch 246/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0030 - val_loss: 0.0044 - val_mae: 0.0066\n",
      "Epoch 247/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0036 - val_loss: 0.0046 - val_mae: 0.0112\n",
      "Epoch 248/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0040 - val_loss: 0.0043 - val_mae: 0.0032\n",
      "Epoch 249/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0029 - val_loss: 0.0043 - val_mae: 0.0035\n",
      "Epoch 250/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0025 - val_loss: 0.0044 - val_mae: 0.0055\n",
      "Epoch 251/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0040 - val_loss: 0.0043 - val_mae: 0.0034\n",
      "Epoch 252/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0039 - val_loss: 0.0043 - val_mae: 0.0033\n",
      "Epoch 253/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0037 - val_loss: 0.0043 - val_mae: 0.0024\n",
      "Epoch 254/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0027 - val_loss: 0.0043 - val_mae: 0.0021\n",
      "Epoch 255/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0025 - val_loss: 0.0043 - val_mae: 0.0067\n",
      "Epoch 256/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0032 - val_loss: 0.0042 - val_mae: 0.0032\n",
      "Epoch 257/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0039 - val_loss: 0.0042 - val_mae: 0.0042\n",
      "Epoch 258/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0044 - val_loss: 0.0043 - val_mae: 0.0052\n",
      "Epoch 259/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0030 - val_loss: 0.0044 - val_mae: 0.0097\n",
      "Epoch 260/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0037 - val_loss: 0.0043 - val_mae: 0.0082\n",
      "Epoch 261/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0027 - val_loss: 0.0042 - val_mae: 0.0027\n",
      "Epoch 262/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0025 - val_loss: 0.0042 - val_mae: 0.0042\n",
      "Epoch 263/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0032 - val_loss: 0.0042 - val_mae: 0.0039\n",
      "Epoch 264/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0034 - val_loss: 0.0043 - val_mae: 0.0083\n",
      "Epoch 265/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0045 - val_loss: 0.0041 - val_mae: 0.0025\n",
      "Epoch 266/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0025 - val_loss: 0.0042 - val_mae: 0.0052\n",
      "Epoch 267/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0064 - val_loss: 0.0041 - val_mae: 0.0044\n",
      "Epoch 268/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0024 - val_loss: 0.0042 - val_mae: 0.0068\n",
      "Epoch 269/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0033 - val_loss: 0.0041 - val_mae: 0.0041\n",
      "Epoch 270/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0032 - val_loss: 0.0041 - val_mae: 0.0040\n",
      "Epoch 271/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0040 - val_loss: 0.0041 - val_mae: 0.0039\n",
      "Epoch 272/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0031 - val_loss: 0.0040 - val_mae: 0.0019\n",
      "Epoch 273/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0027 - val_loss: 0.0040 - val_mae: 0.0027\n",
      "Epoch 274/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0027 - val_loss: 0.0042 - val_mae: 0.0092\n",
      "Epoch 275/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0036 - val_loss: 0.0041 - val_mae: 0.0076\n",
      "Epoch 276/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0042 - val_loss: 0.0040 - val_mae: 0.0035\n",
      "Epoch 277/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0025 - val_loss: 0.0041 - val_mae: 0.0063\n",
      "Epoch 278/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0031 - val_loss: 0.0040 - val_mae: 0.0041\n",
      "Epoch 279/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0032 - val_loss: 0.0040 - val_mae: 0.0031\n",
      "Epoch 280/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0025 - val_loss: 0.0040 - val_mae: 0.0052\n",
      "Epoch 281/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0028 - val_loss: 0.0039 - val_mae: 0.0025\n",
      "Epoch 282/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0042 - val_loss: 0.0039 - val_mae: 0.0030\n",
      "Epoch 283/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0037 - val_loss: 0.0039 - val_mae: 0.0036\n",
      "Epoch 284/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0031 - val_loss: 0.0040 - val_mae: 0.0067\n",
      "Epoch 285/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0043 - val_loss: 0.0040 - val_mae: 0.0094\n",
      "Epoch 286/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0034 - val_loss: 0.0039 - val_mae: 0.0017\n",
      "Epoch 287/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0024 - val_loss: 0.0039 - val_mae: 0.0026\n",
      "Epoch 288/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0024 - val_loss: 0.0039 - val_mae: 0.0040\n",
      "Epoch 289/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0026 - val_loss: 0.0039 - val_mae: 0.0040\n",
      "Epoch 290/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0023 - val_loss: 0.0038 - val_mae: 0.0033\n",
      "Epoch 291/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0035 - val_loss: 0.0039 - val_mae: 0.0084\n",
      "Epoch 292/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0029 - val_loss: 0.0039 - val_mae: 0.0068\n",
      "Epoch 293/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0034 - val_loss: 0.0038 - val_mae: 0.0048\n",
      "Epoch 294/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0025 - val_loss: 0.0038 - val_mae: 0.0062\n",
      "Epoch 295/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0043 - val_loss: 0.0038 - val_mae: 0.0067\n",
      "Epoch 296/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0056 - val_loss: 0.0038 - val_mae: 0.0049\n",
      "Epoch 297/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0023 - val_loss: 0.0038 - val_mae: 0.0018\n",
      "Epoch 298/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0020 - val_loss: 0.0037 - val_mae: 0.0018\n",
      "Epoch 299/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0027 - val_loss: 0.0038 - val_mae: 0.0055\n",
      "Epoch 300/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0033 - val_loss: 0.0037 - val_mae: 0.0025\n",
      "Epoch 301/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0025 - val_loss: 0.0037 - val_mae: 0.0024\n",
      "Epoch 302/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0041 - val_loss: 0.0037 - val_mae: 0.0030\n",
      "Epoch 303/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0023 - val_loss: 0.0037 - val_mae: 0.0036\n",
      "Epoch 304/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0030 - val_loss: 0.0037 - val_mae: 0.0021\n",
      "Epoch 305/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0027 - val_loss: 0.0037 - val_mae: 0.0027\n",
      "Epoch 306/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0027 - val_loss: 0.0037 - val_mae: 0.0043\n",
      "Epoch 307/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0050 - val_loss: 0.0036 - val_mae: 0.0027\n",
      "Epoch 308/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0026 - val_loss: 0.0036 - val_mae: 0.0017\n",
      "Epoch 309/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0021 - val_loss: 0.0036 - val_mae: 0.0017\n",
      "Epoch 310/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0023 - val_loss: 0.0037 - val_mae: 0.0057\n",
      "Epoch 311/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0044 - val_loss: 0.0036 - val_mae: 0.0022\n",
      "Epoch 312/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0022 - val_loss: 0.0037 - val_mae: 0.0070\n",
      "Epoch 313/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0028 - val_loss: 0.0036 - val_mae: 0.0025\n",
      "Epoch 314/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0029 - val_loss: 0.0036 - val_mae: 0.0036\n",
      "Epoch 315/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0029 - val_loss: 0.0036 - val_mae: 0.0025\n",
      "Epoch 316/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0028 - val_loss: 0.0039 - val_mae: 0.0140\n",
      "Epoch 317/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0027 - val_loss: 0.0035 - val_mae: 0.0038\n",
      "Epoch 318/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0029 - val_loss: 0.0037 - val_mae: 0.0095\n",
      "Epoch 319/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0025 - val_loss: 0.0035 - val_mae: 0.0024\n",
      "Epoch 320/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0041 - val_loss: 0.0035 - val_mae: 0.0028\n",
      "Epoch 321/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0029 - val_loss: 0.0035 - val_mae: 0.0023\n",
      "Epoch 322/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0032 - val_loss: 0.0035 - val_mae: 0.0031\n",
      "Epoch 323/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0025 - val_loss: 0.0035 - val_mae: 0.0046\n",
      "Epoch 324/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0027 - val_loss: 0.0035 - val_mae: 0.0049\n",
      "Epoch 325/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0050 - val_loss: 0.0034 - val_mae: 0.0029\n",
      "Epoch 326/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0029 - val_loss: 0.0034 - val_mae: 0.0028\n",
      "Epoch 327/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0026 - val_loss: 0.0034 - val_mae: 0.0018\n",
      "Epoch 328/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0024 - val_loss: 0.0034 - val_mae: 0.0021\n",
      "Epoch 329/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0039 - val_loss: 0.0034 - val_mae: 0.0030\n",
      "Epoch 330/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0023 - val_loss: 0.0034 - val_mae: 0.0027\n",
      "Epoch 331/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0023 - val_loss: 0.0034 - val_mae: 0.0038\n",
      "Epoch 332/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0026 - val_loss: 0.0034 - val_mae: 0.0031\n",
      "Epoch 333/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0027 - val_loss: 0.0034 - val_mae: 0.0027\n",
      "Epoch 334/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0023 - val_loss: 0.0034 - val_mae: 0.0061\n",
      "Epoch 335/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0033 - val_loss: 0.0033 - val_mae: 0.0029\n",
      "Epoch 336/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0031 - val_loss: 0.0033 - val_mae: 0.0021\n",
      "Epoch 337/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0026 - val_loss: 0.0033 - val_mae: 0.0031\n",
      "Epoch 338/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0039 - val_loss: 0.0033 - val_mae: 0.0042\n",
      "Epoch 339/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0032 - val_loss: 0.0033 - val_mae: 0.0019\n",
      "Epoch 340/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0025 - val_loss: 0.0033 - val_mae: 0.0058\n",
      "Epoch 341/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0027 - val_loss: 0.0033 - val_mae: 0.0030\n",
      "Epoch 342/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0024 - val_loss: 0.0033 - val_mae: 0.0020\n",
      "Epoch 343/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0021 - val_loss: 0.0033 - val_mae: 0.0039\n",
      "Epoch 344/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0047 - val_loss: 0.0033 - val_mae: 0.0037\n",
      "Epoch 345/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0021 - val_loss: 0.0032 - val_mae: 0.0015\n",
      "Epoch 346/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0018 - val_loss: 0.0032 - val_mae: 0.0033\n",
      "Epoch 347/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0027 - val_loss: 0.0032 - val_mae: 0.0042\n",
      "Epoch 348/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0034 - val_loss: 0.0032 - val_mae: 0.0029\n",
      "Epoch 349/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0024 - val_loss: 0.0032 - val_mae: 0.0032\n",
      "Epoch 350/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0028 - val_loss: 0.0032 - val_mae: 0.0022\n",
      "Epoch 351/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0037 - val_loss: 0.0032 - val_mae: 0.0045\n",
      "Epoch 352/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0022 - val_loss: 0.0033 - val_mae: 0.0088\n",
      "Epoch 353/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0033 - val_loss: 0.0031 - val_mae: 0.0024\n",
      "Epoch 354/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0026 - val_loss: 0.0031 - val_mae: 0.0017\n",
      "Epoch 355/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0032 - val_loss: 0.0031 - val_mae: 0.0038\n",
      "Epoch 356/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0032 - val_loss: 0.0031 - val_mae: 0.0045\n",
      "Epoch 357/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0027 - val_loss: 0.0031 - val_mae: 0.0041\n",
      "Epoch 358/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0022 - val_loss: 0.0031 - val_mae: 0.0022\n",
      "Epoch 359/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0021 - val_loss: 0.0031 - val_mae: 0.0046\n",
      "Epoch 360/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0032 - val_loss: 0.0031 - val_mae: 0.0054\n",
      "Epoch 361/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0031 - val_loss: 0.0031 - val_mae: 0.0021\n",
      "Epoch 362/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0027 - val_loss: 0.0031 - val_mae: 0.0021\n",
      "Epoch 363/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0022 - val_loss: 0.0032 - val_mae: 0.0088\n",
      "Epoch 364/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0032 - val_loss: 0.0030 - val_mae: 0.0017\n",
      "Epoch 365/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0024 - val_loss: 0.0030 - val_mae: 0.0020\n",
      "Epoch 366/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0023 - val_loss: 0.0030 - val_mae: 0.0017\n",
      "Epoch 367/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0027 - val_loss: 0.0030 - val_mae: 0.0031\n",
      "Epoch 368/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0026 - val_loss: 0.0030 - val_mae: 0.0019\n",
      "Epoch 369/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0023 - val_loss: 0.0031 - val_mae: 0.0081\n",
      "Epoch 370/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0028 - val_loss: 0.0030 - val_mae: 0.0056\n",
      "Epoch 371/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0042 - val_loss: 0.0030 - val_mae: 0.0050\n",
      "Epoch 372/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0023 - val_loss: 0.0029 - val_mae: 0.0020\n",
      "Epoch 373/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0022 - val_loss: 0.0029 - val_mae: 0.0021\n",
      "Epoch 374/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0025 - val_loss: 0.0029 - val_mae: 0.0041\n",
      "Epoch 375/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0024 - val_loss: 0.0029 - val_mae: 0.0019\n",
      "Epoch 376/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0026 - val_loss: 0.0029 - val_mae: 0.0038\n",
      "Epoch 377/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0033 - val_loss: 0.0029 - val_mae: 0.0019\n",
      "Epoch 378/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0026 - val_loss: 0.0029 - val_mae: 0.0028\n",
      "Epoch 379/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0041 - val_loss: 0.0029 - val_mae: 0.0021\n",
      "Epoch 380/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0029 - mae: 0.0021 - val_loss: 0.0029 - val_mae: 0.0018\n",
      "Epoch 381/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0029 - mae: 0.0025 - val_loss: 0.0030 - val_mae: 0.0081\n",
      "Epoch 382/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0029 - val_loss: 0.0029 - val_mae: 0.0018\n",
      "Epoch 383/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0022 - val_loss: 0.0028 - val_mae: 0.0017\n",
      "Epoch 384/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0028 - val_loss: 0.0029 - val_mae: 0.0043\n",
      "Epoch 385/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0022 - val_loss: 0.0028 - val_mae: 0.0047\n",
      "Epoch 386/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0028 - mae: 0.0023 - val_loss: 0.0028 - val_mae: 0.0021\n",
      "Epoch 387/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0021 - val_loss: 0.0028 - val_mae: 0.0034\n",
      "Epoch 388/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0030 - val_loss: 0.0029 - val_mae: 0.0087\n",
      "Epoch 389/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0038 - val_loss: 0.0028 - val_mae: 0.0025\n",
      "Epoch 390/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0020 - val_loss: 0.0028 - val_mae: 0.0045\n",
      "Epoch 391/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0025 - val_loss: 0.0028 - val_mae: 0.0020\n",
      "Epoch 392/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0023 - val_loss: 0.0028 - val_mae: 0.0018\n",
      "Epoch 393/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0025 - val_loss: 0.0027 - val_mae: 0.0023\n",
      "Epoch 394/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0029 - val_loss: 0.0027 - val_mae: 0.0029\n",
      "Epoch 395/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0028 - val_loss: 0.0027 - val_mae: 0.0019\n",
      "Epoch 396/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0019 - val_loss: 0.0027 - val_mae: 0.0018\n",
      "Epoch 397/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0024 - val_loss: 0.0027 - val_mae: 0.0024\n",
      "Epoch 398/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0020 - val_loss: 0.0027 - val_mae: 0.0036\n",
      "Epoch 399/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0029 - val_loss: 0.0027 - val_mae: 0.0021\n",
      "Epoch 400/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0036 - val_loss: 0.0027 - val_mae: 0.0057\n",
      "Epoch 401/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0028 - val_loss: 0.0027 - val_mae: 0.0038\n",
      "Epoch 402/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0027 - mae: 0.0032 - val_loss: 0.0027 - val_mae: 0.0032\n",
      "Epoch 403/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0027 - mae: 0.0020 - val_loss: 0.0027 - val_mae: 0.0036\n",
      "Epoch 404/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0027 - mae: 0.0025 - val_loss: 0.0026 - val_mae: 0.0015\n",
      "Epoch 405/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0021 - val_loss: 0.0027 - val_mae: 0.0043\n",
      "Epoch 406/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0028 - val_loss: 0.0026 - val_mae: 0.0030\n",
      "Epoch 407/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0019 - val_loss: 0.0026 - val_mae: 0.0026\n",
      "Epoch 408/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0026 - val_loss: 0.0026 - val_mae: 0.0019\n",
      "Epoch 409/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0020 - val_loss: 0.0026 - val_mae: 0.0029\n",
      "Epoch 410/2000\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0026 - mae: 0.0030 - val_loss: 0.0027 - val_mae: 0.0068\n",
      "Epoch 411/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0023 - val_loss: 0.0026 - val_mae: 0.0033\n",
      "Epoch 412/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0025 - val_loss: 0.0026 - val_mae: 0.0037\n",
      "Epoch 413/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0024 - val_loss: 0.0026 - val_mae: 0.0021\n",
      "Epoch 414/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0024 - val_loss: 0.0026 - val_mae: 0.0028\n",
      "Epoch 415/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0040 - val_loss: 0.0029 - val_mae: 0.0137\n",
      "Epoch 416/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0028 - val_loss: 0.0025 - val_mae: 0.0023\n",
      "Epoch 417/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0016 - val_loss: 0.0025 - val_mae: 0.0019\n",
      "Epoch 418/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0017 - val_loss: 0.0025 - val_mae: 0.0019\n",
      "Epoch 419/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0017 - val_loss: 0.0025 - val_mae: 0.0019\n",
      "Epoch 420/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0019 - val_loss: 0.0025 - val_mae: 0.0020\n",
      "Epoch 421/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0020 - val_loss: 0.0025 - val_mae: 0.0066\n",
      "Epoch 422/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0026 - val_loss: 0.0025 - val_mae: 0.0053\n",
      "Epoch 423/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0033 - val_loss: 0.0025 - val_mae: 0.0020\n",
      "Epoch 424/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0019 - val_loss: 0.0025 - val_mae: 0.0048\n",
      "Epoch 425/2000\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0025 - mae: 0.0023 - val_loss: 0.0025 - val_mae: 0.0019\n",
      "Epoch 426/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0030 - val_loss: 0.0025 - val_mae: 0.0037\n",
      "Epoch 427/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0021 - val_loss: 0.0024 - val_mae: 0.0020\n",
      "Epoch 428/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0023 - val_loss: 0.0024 - val_mae: 0.0025\n",
      "Epoch 429/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0027 - val_loss: 0.0024 - val_mae: 0.0023\n",
      "Epoch 430/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0021 - val_loss: 0.0024 - val_mae: 0.0017\n",
      "Epoch 431/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0021 - val_loss: 0.0024 - val_mae: 0.0017\n",
      "Epoch 432/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0020 - val_loss: 0.0024 - val_mae: 0.0016\n",
      "Epoch 433/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0026 - val_loss: 0.0024 - val_mae: 0.0021\n",
      "Epoch 434/2000\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0024 - mae: 0.0024 - val_loss: 0.0024 - val_mae: 0.0050\n",
      "Epoch 435/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0026 - val_loss: 0.0024 - val_mae: 0.0015\n",
      "Epoch 436/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0023 - val_loss: 0.0024 - val_mae: 0.0029\n",
      "Epoch 437/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0019 - val_loss: 0.0024 - val_mae: 0.0051\n",
      "Epoch 438/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0031 - val_loss: 0.0024 - val_mae: 0.0054\n",
      "Epoch 439/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0026 - val_loss: 0.0024 - val_mae: 0.0045\n",
      "Epoch 440/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0023 - val_loss: 0.0023 - val_mae: 0.0048\n",
      "Epoch 441/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0028 - val_loss: 0.0023 - val_mae: 0.0020\n",
      "Epoch 442/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0019 - val_loss: 0.0023 - val_mae: 0.0018\n",
      "Epoch 443/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0026 - val_loss: 0.0023 - val_mae: 0.0018\n",
      "Epoch 444/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0018 - val_loss: 0.0023 - val_mae: 0.0029\n",
      "Epoch 445/2000\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0023 - mae: 0.0024 - val_loss: 0.0023 - val_mae: 0.0044\n",
      "Epoch 446/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0019 - val_loss: 0.0023 - val_mae: 0.0015\n",
      "Epoch 447/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0029 - val_loss: 0.0023 - val_mae: 0.0033\n",
      "Epoch 448/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0018 - val_loss: 0.0022 - val_mae: 0.0017\n",
      "Epoch 449/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0025 - val_loss: 0.0022 - val_mae: 0.0024\n",
      "Epoch 450/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0022 - val_loss: 0.0022 - val_mae: 0.0024\n",
      "Epoch 451/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0020 - val_loss: 0.0022 - val_mae: 0.0020\n",
      "Epoch 452/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0022 - val_loss: 0.0022 - val_mae: 0.0013\n",
      "Epoch 453/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0021 - val_loss: 0.0022 - val_mae: 0.0015\n",
      "Epoch 454/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0021 - val_loss: 0.0022 - val_mae: 0.0021\n",
      "Epoch 455/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0025 - val_loss: 0.0022 - val_mae: 0.0057\n",
      "Epoch 456/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0025 - val_loss: 0.0024 - val_mae: 0.0126\n",
      "Epoch 457/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0029 - val_loss: 0.0022 - val_mae: 0.0049\n",
      "Epoch 458/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0023 - val_loss: 0.0022 - val_mae: 0.0059\n",
      "Epoch 459/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0019 - val_loss: 0.0022 - val_mae: 0.0014\n",
      "Epoch 460/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0021 - val_loss: 0.0022 - val_mae: 0.0028\n",
      "Epoch 461/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0019 - val_loss: 0.0021 - val_mae: 0.0016\n",
      "Epoch 462/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0023 - val_loss: 0.0021 - val_mae: 0.0029\n",
      "Epoch 463/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0021 - val_loss: 0.0021 - val_mae: 0.0019\n",
      "Epoch 464/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0021 - val_loss: 0.0021 - val_mae: 0.0023\n",
      "Epoch 465/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0027 - val_loss: 0.0021 - val_mae: 0.0018\n",
      "Epoch 466/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0020 - val_loss: 0.0021 - val_mae: 0.0047\n",
      "Epoch 467/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0018 - val_loss: 0.0021 - val_mae: 0.0026\n",
      "Epoch 468/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0028 - val_loss: 0.0021 - val_mae: 0.0024\n",
      "Epoch 469/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0017 - val_loss: 0.0021 - val_mae: 0.0024\n",
      "Epoch 470/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0017 - val_loss: 0.0021 - val_mae: 0.0015\n",
      "Epoch 471/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0031 - val_loss: 0.0023 - val_mae: 0.0108\n",
      "Epoch 472/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0031 - val_loss: 0.0021 - val_mae: 0.0022\n",
      "Epoch 473/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0019 - val_loss: 0.0021 - val_mae: 0.0033\n",
      "Epoch 474/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0017 - val_loss: 0.0020 - val_mae: 0.0034\n",
      "Epoch 475/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0019 - val_loss: 0.0020 - val_mae: 0.0026\n",
      "Epoch 476/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0025 - val_loss: 0.0022 - val_mae: 0.0097\n",
      "Epoch 477/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0026 - val_loss: 0.0020 - val_mae: 0.0030\n",
      "Epoch 478/2000\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0026 - val_loss: 0.0020 - val_mae: 0.0020\n",
      "Epoch 479/2000\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0024 - val_loss: 0.0020 - val_mae: 0.0015\n",
      "Epoch 480/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0016 - val_loss: 0.0020 - val_mae: 0.0023\n",
      "Epoch 481/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0022 - val_loss: 0.0020 - val_mae: 0.0040\n",
      "Epoch 482/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0024 - val_loss: 0.0020 - val_mae: 0.0026\n",
      "Epoch 483/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0021 - val_loss: 0.0022 - val_mae: 0.0117\n",
      "Epoch 484/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0023 - val_loss: 0.0020 - val_mae: 0.0022\n",
      "Epoch 485/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0019 - val_loss: 0.0020 - val_mae: 0.0017\n",
      "Epoch 486/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0027 - val_loss: 0.0020 - val_mae: 0.0035\n",
      "Epoch 487/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0018 - val_loss: 0.0019 - val_mae: 0.0018\n",
      "Epoch 488/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0020 - val_loss: 0.0019 - val_mae: 0.0043\n",
      "Epoch 489/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0021 - val_loss: 0.0019 - val_mae: 0.0013\n",
      "Epoch 490/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0021 - val_loss: 0.0019 - val_mae: 0.0013\n",
      "Epoch 491/2000\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0021 - val_loss: 0.0020 - val_mae: 0.0064\n",
      "Epoch 492/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0031 - val_loss: 0.0019 - val_mae: 0.0027\n",
      "Epoch 493/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0019 - val_mae: 0.0032\n",
      "Epoch 494/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0023 - val_loss: 0.0019 - val_mae: 0.0015\n",
      "Epoch 495/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0016 - val_loss: 0.0019 - val_mae: 0.0053\n",
      "Epoch 496/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0023 - val_loss: 0.0019 - val_mae: 0.0013\n",
      "Epoch 497/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0019 - val_mae: 0.0036\n",
      "Epoch 498/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0021 - val_loss: 0.0019 - val_mae: 0.0026\n",
      "Epoch 499/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0022 - val_loss: 0.0019 - val_mae: 0.0030\n",
      "Epoch 500/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0019 - val_loss: 0.0018 - val_mae: 0.0021\n",
      "Epoch 501/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0023 - val_loss: 0.0018 - val_mae: 0.0027\n",
      "Epoch 502/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0021 - val_loss: 0.0018 - val_mae: 0.0026\n",
      "Epoch 503/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0019 - val_loss: 0.0018 - val_mae: 0.0028\n",
      "Epoch 504/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0022 - val_loss: 0.0018 - val_mae: 0.0024\n",
      "Epoch 505/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0023 - val_loss: 0.0019 - val_mae: 0.0091\n",
      "Epoch 506/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0018 - mae: 0.0027 - val_loss: 0.0019 - val_mae: 0.0055\n",
      "Epoch 507/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0022 - val_loss: 0.0018 - val_mae: 0.0034\n",
      "Epoch 508/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0022 - val_loss: 0.0018 - val_mae: 0.0021\n",
      "Epoch 509/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0017 - val_loss: 0.0018 - val_mae: 0.0032\n",
      "Epoch 510/2000\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0018 - mae: 0.0025 - val_loss: 0.0018 - val_mae: 0.0018\n",
      "Epoch 511/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0017 - val_loss: 0.0018 - val_mae: 0.0020\n",
      "Epoch 512/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0021 - val_loss: 0.0018 - val_mae: 0.0037\n",
      "Epoch 513/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0021 - val_loss: 0.0018 - val_mae: 0.0045\n",
      "Epoch 514/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0020 - val_loss: 0.0018 - val_mae: 0.0040\n",
      "Epoch 515/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0030 - val_loss: 0.0017 - val_mae: 0.0013\n",
      "Epoch 516/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0019 - val_loss: 0.0017 - val_mae: 0.0018\n",
      "Epoch 517/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0023 - val_loss: 0.0017 - val_mae: 0.0039\n",
      "Epoch 518/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0017 - val_loss: 0.0017 - val_mae: 0.0023\n",
      "Epoch 519/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0020 - val_loss: 0.0017 - val_mae: 0.0041\n",
      "Epoch 520/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0024 - val_loss: 0.0017 - val_mae: 0.0035\n",
      "Epoch 521/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0024 - val_loss: 0.0017 - val_mae: 0.0018\n",
      "Epoch 522/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0024 - val_loss: 0.0017 - val_mae: 0.0018\n",
      "Epoch 523/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0025 - val_loss: 0.0017 - val_mae: 0.0015\n",
      "Epoch 524/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0022 - val_loss: 0.0017 - val_mae: 0.0012\n",
      "Epoch 525/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0019 - val_loss: 0.0017 - val_mae: 0.0057\n",
      "Epoch 526/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0026 - val_loss: 0.0017 - val_mae: 0.0015\n",
      "Epoch 527/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0020 - val_loss: 0.0017 - val_mae: 0.0042\n",
      "Epoch 528/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0031 - val_loss: 0.0017 - val_mae: 0.0047\n",
      "Epoch 529/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0018 - val_loss: 0.0016 - val_mae: 0.0016\n",
      "Epoch 530/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0017 - val_loss: 0.0016 - val_mae: 0.0019\n",
      "Epoch 531/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0016 - val_loss: 0.0016 - val_mae: 0.0016\n",
      "Epoch 532/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0017 - val_loss: 0.0016 - val_mae: 0.0027\n",
      "Epoch 533/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0022 - val_loss: 0.0016 - val_mae: 0.0016\n",
      "Epoch 534/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0023 - val_loss: 0.0016 - val_mae: 0.0021\n",
      "Epoch 535/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0021 - val_loss: 0.0016 - val_mae: 0.0019\n",
      "Epoch 536/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0023 - val_loss: 0.0016 - val_mae: 0.0015\n",
      "Epoch 537/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0019 - val_loss: 0.0016 - val_mae: 0.0030\n",
      "Epoch 538/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0021 - val_loss: 0.0016 - val_mae: 0.0020\n",
      "Epoch 539/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0024 - val_loss: 0.0016 - val_mae: 0.0051\n",
      "Epoch 540/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0019 - val_loss: 0.0016 - val_mae: 0.0015\n",
      "Epoch 541/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0022 - val_loss: 0.0016 - val_mae: 0.0042\n",
      "Epoch 542/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0019 - val_loss: 0.0016 - val_mae: 0.0015\n",
      "Epoch 543/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0022 - val_loss: 0.0016 - val_mae: 0.0053\n",
      "Epoch 544/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0024 - val_loss: 0.0016 - val_mae: 0.0019\n",
      "Epoch 545/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0017 - val_loss: 0.0016 - val_mae: 0.0027\n",
      "Epoch 546/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0023 - val_loss: 0.0016 - val_mae: 0.0029\n",
      "Epoch 547/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0028 - val_loss: 0.0015 - val_mae: 0.0021\n",
      "Epoch 548/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0018 - val_loss: 0.0015 - val_mae: 0.0025\n",
      "Epoch 549/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0017 - val_loss: 0.0015 - val_mae: 0.0013\n",
      "Epoch 550/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0021 - val_loss: 0.0015 - val_mae: 0.0014\n",
      "Epoch 551/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0018 - val_loss: 0.0015 - val_mae: 0.0017\n",
      "Epoch 552/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0024 - val_loss: 0.0015 - val_mae: 0.0051\n",
      "Epoch 553/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0018 - val_loss: 0.0015 - val_mae: 0.0023\n",
      "Epoch 554/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0022 - val_loss: 0.0015 - val_mae: 0.0037\n",
      "Epoch 555/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0021 - val_loss: 0.0015 - val_mae: 0.0035\n",
      "Epoch 556/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0023 - val_loss: 0.0015 - val_mae: 0.0030\n",
      "Epoch 557/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0017 - val_loss: 0.0015 - val_mae: 0.0021\n",
      "Epoch 558/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0017 - val_loss: 0.0016 - val_mae: 0.0086\n",
      "Epoch 559/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0022 - val_loss: 0.0015 - val_mae: 0.0015\n",
      "Epoch 560/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0021 - val_loss: 0.0015 - val_mae: 0.0016\n",
      "Epoch 561/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0019 - val_loss: 0.0015 - val_mae: 0.0022\n",
      "Epoch 562/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0021 - val_loss: 0.0015 - val_mae: 0.0043\n",
      "Epoch 563/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0023 - val_loss: 0.0014 - val_mae: 0.0017\n",
      "Epoch 564/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0024 - val_loss: 0.0015 - val_mae: 0.0069\n",
      "Epoch 565/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0020 - val_loss: 0.0014 - val_mae: 0.0020\n",
      "Epoch 566/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0020 - val_loss: 0.0014 - val_mae: 0.0024\n",
      "Epoch 567/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0018 - val_loss: 0.0014 - val_mae: 0.0015\n",
      "Epoch 568/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0021 - val_loss: 0.0014 - val_mae: 0.0015\n",
      "Epoch 569/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0020 - val_loss: 0.0014 - val_mae: 0.0017\n",
      "Epoch 570/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0020 - val_loss: 0.0014 - val_mae: 0.0052\n",
      "Epoch 571/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0031 - val_loss: 0.0014 - val_mae: 0.0029\n",
      "Epoch 572/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0017 - val_loss: 0.0014 - val_mae: 0.0031\n",
      "Epoch 573/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0017 - val_loss: 0.0014 - val_mae: 0.0017\n",
      "Epoch 574/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0023 - val_loss: 0.0014 - val_mae: 0.0020\n",
      "Epoch 575/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0018 - val_loss: 0.0014 - val_mae: 0.0017\n",
      "Epoch 576/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0015 - val_loss: 0.0014 - val_mae: 0.0036\n",
      "Epoch 577/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0026 - val_loss: 0.0014 - val_mae: 0.0029\n",
      "Epoch 578/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0021 - val_loss: 0.0014 - val_mae: 0.0019\n",
      "Epoch 579/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0017 - val_loss: 0.0014 - val_mae: 0.0023\n",
      "Epoch 580/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0021 - val_loss: 0.0014 - val_mae: 0.0033\n",
      "Epoch 581/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0026 - val_loss: 0.0015 - val_mae: 0.0084\n",
      "Epoch 582/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0020 - val_loss: 0.0013 - val_mae: 0.0016\n",
      "Epoch 583/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0017 - val_loss: 0.0013 - val_mae: 0.0026\n",
      "Epoch 584/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0027 - val_loss: 0.0013 - val_mae: 0.0033\n",
      "Epoch 585/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0017 - val_loss: 0.0013 - val_mae: 0.0018\n",
      "Epoch 586/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0016 - val_loss: 0.0013 - val_mae: 0.0036\n",
      "Epoch 587/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0018 - val_loss: 0.0013 - val_mae: 0.0022\n",
      "Epoch 588/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0027 - val_loss: 0.0014 - val_mae: 0.0067\n",
      "Epoch 589/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0021 - val_loss: 0.0013 - val_mae: 0.0021\n",
      "Epoch 590/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0018 - val_loss: 0.0013 - val_mae: 0.0018\n",
      "Epoch 591/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0018 - val_loss: 0.0013 - val_mae: 0.0020\n",
      "Epoch 592/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0023 - val_loss: 0.0013 - val_mae: 0.0014\n",
      "Epoch 593/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0019 - val_loss: 0.0013 - val_mae: 0.0029\n",
      "Epoch 594/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0017 - val_loss: 0.0013 - val_mae: 0.0014\n",
      "Epoch 595/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0018 - val_loss: 0.0013 - val_mae: 0.0019\n",
      "Epoch 596/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0019 - val_loss: 0.0013 - val_mae: 0.0017\n",
      "Epoch 597/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0019 - val_loss: 0.0013 - val_mae: 0.0012\n",
      "Epoch 598/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0021 - val_loss: 0.0013 - val_mae: 0.0065\n",
      "Epoch 599/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0023 - val_loss: 0.0013 - val_mae: 0.0020\n",
      "Epoch 600/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0016 - val_loss: 0.0013 - val_mae: 0.0073\n",
      "Epoch 601/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0027 - val_loss: 0.0013 - val_mae: 0.0027\n",
      "Epoch 602/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0018 - val_loss: 0.0013 - val_mae: 0.0046\n",
      "Epoch 603/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0020 - val_loss: 0.0012 - val_mae: 0.0024\n",
      "Epoch 604/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0018 - val_loss: 0.0012 - val_mae: 0.0028\n",
      "Epoch 605/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0018 - val_loss: 0.0012 - val_mae: 0.0027\n",
      "Epoch 606/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0024 - val_loss: 0.0012 - val_mae: 0.0023\n",
      "Epoch 607/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0017 - val_loss: 0.0012 - val_mae: 0.0027\n",
      "Epoch 608/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0022 - val_loss: 0.0012 - val_mae: 0.0032\n",
      "Epoch 609/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0017 - val_loss: 0.0012 - val_mae: 0.0053\n",
      "Epoch 610/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0022 - val_loss: 0.0012 - val_mae: 0.0017\n",
      "Epoch 611/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0020 - val_loss: 0.0012 - val_mae: 0.0042\n",
      "Epoch 612/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0018 - val_loss: 0.0012 - val_mae: 0.0022\n",
      "Epoch 613/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0018 - val_loss: 0.0012 - val_mae: 0.0013\n",
      "Epoch 614/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0018 - val_loss: 0.0012 - val_mae: 0.0056\n",
      "Epoch 615/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0020 - val_loss: 0.0012 - val_mae: 0.0022\n",
      "Epoch 616/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0017 - val_loss: 0.0012 - val_mae: 0.0025\n",
      "Epoch 617/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0016 - val_loss: 0.0012 - val_mae: 0.0030\n",
      "Epoch 618/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0018 - val_loss: 0.0012 - val_mae: 0.0016\n",
      "Epoch 619/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0018 - val_loss: 0.0012 - val_mae: 0.0024\n",
      "Epoch 620/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0022 - val_loss: 0.0012 - val_mae: 0.0020\n",
      "Epoch 621/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0020 - val_loss: 0.0011 - val_mae: 0.0017\n",
      "Epoch 622/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0020 - val_loss: 0.0012 - val_mae: 0.0042\n",
      "Epoch 623/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0016 - val_loss: 0.0012 - val_mae: 0.0041\n",
      "Epoch 624/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0019 - val_loss: 0.0012 - val_mae: 0.0051\n",
      "Epoch 625/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0020 - val_loss: 0.0011 - val_mae: 0.0024\n",
      "Epoch 626/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0017 - val_loss: 0.0011 - val_mae: 0.0016\n",
      "Epoch 627/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0017 - val_loss: 0.0011 - val_mae: 0.0025\n",
      "Epoch 628/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0029 - val_loss: 0.0011 - val_mae: 0.0036\n",
      "Epoch 629/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0015 - val_loss: 0.0011 - val_mae: 0.0017\n",
      "Epoch 630/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0018 - val_loss: 0.0011 - val_mae: 0.0028\n",
      "Epoch 631/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0019 - val_loss: 0.0011 - val_mae: 0.0021\n",
      "Epoch 632/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0018 - val_loss: 0.0011 - val_mae: 0.0036\n",
      "Epoch 633/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0017 - val_loss: 0.0011 - val_mae: 0.0026\n",
      "Epoch 634/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0021 - val_loss: 0.0011 - val_mae: 0.0032\n",
      "Epoch 635/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0020 - val_loss: 0.0011 - val_mae: 0.0023\n",
      "Epoch 636/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0024 - val_loss: 0.0011 - val_mae: 0.0024\n",
      "Epoch 637/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0019 - val_loss: 0.0011 - val_mae: 0.0017\n",
      "Epoch 638/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0024 - val_loss: 0.0011 - val_mae: 0.0013\n",
      "Epoch 639/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0015 - val_loss: 0.0011 - val_mae: 0.0014\n",
      "Epoch 640/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0016 - val_loss: 0.0011 - val_mae: 0.0016\n",
      "Epoch 641/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0022 - val_loss: 0.0011 - val_mae: 0.0017\n",
      "Epoch 642/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0018 - val_loss: 0.0011 - val_mae: 0.0020\n",
      "Epoch 643/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0016 - val_loss: 0.0011 - val_mae: 0.0020\n",
      "Epoch 644/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0020 - val_loss: 0.0011 - val_mae: 0.0020\n",
      "Epoch 645/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0018 - val_loss: 0.0010 - val_mae: 0.0017\n",
      "Epoch 646/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0021 - val_loss: 0.0011 - val_mae: 0.0032\n",
      "Epoch 647/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0019 - val_loss: 0.0010 - val_mae: 0.0013\n",
      "Epoch 648/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0023 - val_loss: 0.0011 - val_mae: 0.0042\n",
      "Epoch 649/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0021 - val_loss: 0.0011 - val_mae: 0.0046\n",
      "Epoch 650/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0027 - val_loss: 0.0010 - val_mae: 0.0035\n",
      "Epoch 651/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0021 - val_loss: 0.0010 - val_mae: 0.0032\n",
      "Epoch 652/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0017 - val_loss: 0.0010 - val_mae: 0.0018\n",
      "Epoch 653/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0019 - val_loss: 0.0010 - val_mae: 0.0033\n",
      "Epoch 654/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0019 - val_loss: 0.0010 - val_mae: 0.0021\n",
      "Epoch 655/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0017 - val_loss: 0.0010 - val_mae: 0.0024\n",
      "Epoch 656/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0025 - val_loss: 0.0010 - val_mae: 0.0029\n",
      "Epoch 657/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0017 - val_loss: 0.0010 - val_mae: 0.0019\n",
      "Epoch 658/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 9.9851e-04 - mae: 0.0018 - val_loss: 0.0010 - val_mae: 0.0027\n",
      "Epoch 659/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 9.9668e-04 - mae: 0.0020 - val_loss: 9.9114e-04 - val_mae: 0.0015\n",
      "Epoch 660/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 9.8951e-04 - mae: 0.0015 - val_loss: 9.8881e-04 - val_mae: 0.0016\n",
      "Epoch 661/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 9.8888e-04 - mae: 0.0020 - val_loss: 9.8318e-04 - val_mae: 0.0013\n",
      "Epoch 662/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 9.8251e-04 - mae: 0.0017 - val_loss: 9.8358e-04 - val_mae: 0.0022\n",
      "Epoch 663/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 9.9057e-04 - mae: 0.0027 - val_loss: 9.8221e-04 - val_mae: 0.0022\n",
      "Epoch 664/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 9.7574e-04 - mae: 0.0018 - val_loss: 9.7318e-04 - val_mae: 0.0015\n",
      "Epoch 665/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 9.7213e-04 - mae: 0.0017 - val_loss: 9.7022e-04 - val_mae: 0.0016\n",
      "Epoch 666/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 9.6695e-04 - mae: 0.0014 - val_loss: 9.6697e-04 - val_mae: 0.0019\n",
      "Epoch 667/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 9.6471e-04 - mae: 0.0017 - val_loss: 0.0010 - val_mae: 0.0067\n",
      "Epoch 668/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 9.7011e-04 - mae: 0.0024 - val_loss: 9.6381e-04 - val_mae: 0.0024\n",
      "Epoch 669/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 9.5678e-04 - mae: 0.0015 - val_loss: 9.5980e-04 - val_mae: 0.0023\n",
      "Epoch 670/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 9.5571e-04 - mae: 0.0019 - val_loss: 9.5121e-04 - val_mae: 0.0013\n",
      "Epoch 671/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 9.4918e-04 - mae: 0.0014 - val_loss: 9.5239e-04 - val_mae: 0.0024\n",
      "Epoch 672/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 9.4811e-04 - mae: 0.0019 - val_loss: 9.4691e-04 - val_mae: 0.0018\n",
      "Epoch 673/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 9.4362e-04 - mae: 0.0018 - val_loss: 9.9283e-04 - val_mae: 0.0059\n",
      "Epoch 674/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 9.4401e-04 - mae: 0.0021 - val_loss: 9.4487e-04 - val_mae: 0.0030\n",
      "Epoch 675/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 9.3598e-04 - mae: 0.0017 - val_loss: 9.3650e-04 - val_mae: 0.0019\n",
      "Epoch 676/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 9.3094e-04 - mae: 0.0015 - val_loss: 9.3899e-04 - val_mae: 0.0026\n",
      "Epoch 677/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 9.3153e-04 - mae: 0.0021 - val_loss: 9.3802e-04 - val_mae: 0.0034\n",
      "Epoch 678/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 9.2626e-04 - mae: 0.0019 - val_loss: 9.2398e-04 - val_mae: 0.0017\n",
      "Epoch 679/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 9.2566e-04 - mae: 0.0023 - val_loss: 9.3207e-04 - val_mae: 0.0036\n",
      "Epoch 680/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 9.1940e-04 - mae: 0.0020 - val_loss: 9.1513e-04 - val_mae: 0.0014\n",
      "Epoch 681/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 9.1501e-04 - mae: 0.0018 - val_loss: 9.1129e-04 - val_mae: 0.0014\n",
      "Epoch 682/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 9.1380e-04 - mae: 0.0020 - val_loss: 9.1705e-04 - val_mae: 0.0029\n",
      "Epoch 683/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 9.0662e-04 - mae: 0.0016 - val_loss: 9.0443e-04 - val_mae: 0.0014\n",
      "Epoch 684/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 9.0571e-04 - mae: 0.0020 - val_loss: 9.0581e-04 - val_mae: 0.0025\n",
      "Epoch 685/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 9.0090e-04 - mae: 0.0018 - val_loss: 8.9690e-04 - val_mae: 0.0013\n",
      "Epoch 686/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 8.9664e-04 - mae: 0.0016 - val_loss: 8.9362e-04 - val_mae: 0.0013\n",
      "Epoch 687/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 8.9490e-04 - mae: 0.0019 - val_loss: 8.9966e-04 - val_mae: 0.0026\n",
      "Epoch 688/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 8.9000e-04 - mae: 0.0017 - val_loss: 8.9679e-04 - val_mae: 0.0028\n",
      "Epoch 689/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 8.8877e-04 - mae: 0.0020 - val_loss: 8.9129e-04 - val_mae: 0.0026\n",
      "Epoch 690/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 8.8609e-04 - mae: 0.0021 - val_loss: 8.8167e-04 - val_mae: 0.0018\n",
      "Epoch 691/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 8.8125e-04 - mae: 0.0019 - val_loss: 8.7677e-04 - val_mae: 0.0015\n",
      "Epoch 692/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 8.7583e-04 - mae: 0.0016 - val_loss: 8.7495e-04 - val_mae: 0.0018\n",
      "Epoch 693/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 8.7229e-04 - mae: 0.0016 - val_loss: 8.7655e-04 - val_mae: 0.0026\n",
      "Epoch 694/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.6945e-04 - mae: 0.0017 - val_loss: 8.6816e-04 - val_mae: 0.0018\n",
      "Epoch 695/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.6707e-04 - mae: 0.0019 - val_loss: 8.6332e-04 - val_mae: 0.0015\n",
      "Epoch 696/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 8.6179e-04 - mae: 0.0016 - val_loss: 8.6864e-04 - val_mae: 0.0029\n",
      "Epoch 697/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 8.6146e-04 - mae: 0.0020 - val_loss: 8.7237e-04 - val_mae: 0.0033\n",
      "Epoch 698/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 8.5811e-04 - mae: 0.0021 - val_loss: 8.5835e-04 - val_mae: 0.0027\n",
      "Epoch 699/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 8.5220e-04 - mae: 0.0017 - val_loss: 8.5126e-04 - val_mae: 0.0019\n",
      "Epoch 700/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 8.4953e-04 - mae: 0.0018 - val_loss: 8.4976e-04 - val_mae: 0.0020\n",
      "Epoch 701/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 8.4985e-04 - mae: 0.0022 - val_loss: 8.4264e-04 - val_mae: 0.0014\n",
      "Epoch 702/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 8.4716e-04 - mae: 0.0022 - val_loss: 8.6785e-04 - val_mae: 0.0049\n",
      "Epoch 703/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 8.4071e-04 - mae: 0.0018 - val_loss: 8.4770e-04 - val_mae: 0.0030\n",
      "Epoch 704/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 8.3854e-04 - mae: 0.0019 - val_loss: 8.3397e-04 - val_mae: 0.0013\n",
      "Epoch 705/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 8.3402e-04 - mae: 0.0018 - val_loss: 8.3149e-04 - val_mae: 0.0015\n",
      "Epoch 706/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.3151e-04 - mae: 0.0019 - val_loss: 8.2721e-04 - val_mae: 0.0012\n",
      "Epoch 707/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 8.2828e-04 - mae: 0.0018 - val_loss: 8.3089e-04 - val_mae: 0.0027\n",
      "Epoch 708/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 8.2446e-04 - mae: 0.0017 - val_loss: 8.2360e-04 - val_mae: 0.0018\n",
      "Epoch 709/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 8.2188e-04 - mae: 0.0017 - val_loss: 8.1987e-04 - val_mae: 0.0016\n",
      "Epoch 710/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 8.1803e-04 - mae: 0.0016 - val_loss: 8.1559e-04 - val_mae: 0.0012\n",
      "Epoch 711/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 8.1401e-04 - mae: 0.0015 - val_loss: 8.2548e-04 - val_mae: 0.0034\n",
      "Epoch 712/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 8.1344e-04 - mae: 0.0019 - val_loss: 8.2873e-04 - val_mae: 0.0036\n",
      "Epoch 713/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 8.1250e-04 - mae: 0.0022 - val_loss: 8.0605e-04 - val_mae: 0.0014\n",
      "Epoch 714/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 8.0802e-04 - mae: 0.0020 - val_loss: 8.0818e-04 - val_mae: 0.0023\n",
      "Epoch 715/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 8.0163e-04 - mae: 0.0015 - val_loss: 8.0928e-04 - val_mae: 0.0026\n",
      "Epoch 716/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 8.0094e-04 - mae: 0.0019 - val_loss: 7.9787e-04 - val_mae: 0.0016\n",
      "Epoch 717/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.9730e-04 - mae: 0.0018 - val_loss: 8.1248e-04 - val_mae: 0.0039\n",
      "Epoch 718/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.9997e-04 - mae: 0.0023 - val_loss: 7.9574e-04 - val_mae: 0.0023\n",
      "Epoch 719/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 7.9125e-04 - mae: 0.0018 - val_loss: 7.8822e-04 - val_mae: 0.0013\n",
      "Epoch 720/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 7.8930e-04 - mae: 0.0019 - val_loss: 7.8508e-04 - val_mae: 0.0013\n",
      "Epoch 721/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 7.8428e-04 - mae: 0.0016 - val_loss: 7.8955e-04 - val_mae: 0.0027\n",
      "Epoch 722/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 7.8820e-04 - mae: 0.0023 - val_loss: 7.7921e-04 - val_mae: 0.0012\n",
      "Epoch 723/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 7.7900e-04 - mae: 0.0016 - val_loss: 7.7829e-04 - val_mae: 0.0017\n",
      "Epoch 724/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 7.7693e-04 - mae: 0.0017 - val_loss: 8.3319e-04 - val_mae: 0.0058\n",
      "Epoch 725/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 7.8738e-04 - mae: 0.0027 - val_loss: 7.7340e-04 - val_mae: 0.0018\n",
      "Epoch 726/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 7.7052e-04 - mae: 0.0015 - val_loss: 7.6882e-04 - val_mae: 0.0013\n",
      "Epoch 727/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 7.7145e-04 - mae: 0.0020 - val_loss: 7.6796e-04 - val_mae: 0.0017\n",
      "Epoch 728/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 7.6559e-04 - mae: 0.0015 - val_loss: 7.6410e-04 - val_mae: 0.0013\n",
      "Epoch 729/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.6311e-04 - mae: 0.0015 - val_loss: 7.7696e-04 - val_mae: 0.0040\n",
      "Epoch 730/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.6115e-04 - mae: 0.0017 - val_loss: 7.6652e-04 - val_mae: 0.0027\n",
      "Epoch 731/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 7.5811e-04 - mae: 0.0016 - val_loss: 7.5521e-04 - val_mae: 0.0013\n",
      "Epoch 732/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 7.5507e-04 - mae: 0.0016 - val_loss: 7.6440e-04 - val_mae: 0.0033\n",
      "Epoch 733/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 7.5502e-04 - mae: 0.0020 - val_loss: 7.5013e-04 - val_mae: 0.0014\n",
      "Epoch 734/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.5022e-04 - mae: 0.0018 - val_loss: 7.4907e-04 - val_mae: 0.0016\n",
      "Epoch 735/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 7.4648e-04 - mae: 0.0016 - val_loss: 7.4370e-04 - val_mae: 0.0012\n",
      "Epoch 736/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 7.4727e-04 - mae: 0.0021 - val_loss: 7.4208e-04 - val_mae: 0.0014\n",
      "Epoch 737/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.4143e-04 - mae: 0.0017 - val_loss: 7.3884e-04 - val_mae: 0.0014\n",
      "Epoch 738/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.4194e-04 - mae: 0.0021 - val_loss: 7.4595e-04 - val_mae: 0.0027\n",
      "Epoch 739/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 7.3719e-04 - mae: 0.0019 - val_loss: 7.3327e-04 - val_mae: 0.0013\n",
      "Epoch 740/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 7.3777e-04 - mae: 0.0023 - val_loss: 7.3546e-04 - val_mae: 0.0024\n",
      "Epoch 741/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 7.3194e-04 - mae: 0.0019 - val_loss: 7.3026e-04 - val_mae: 0.0018\n",
      "Epoch 742/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 7.2767e-04 - mae: 0.0016 - val_loss: 7.2565e-04 - val_mae: 0.0014\n",
      "Epoch 743/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 7.2562e-04 - mae: 0.0017 - val_loss: 7.2538e-04 - val_mae: 0.0020\n",
      "Epoch 744/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 7.2240e-04 - mae: 0.0016 - val_loss: 7.1987e-04 - val_mae: 0.0012\n",
      "Epoch 745/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 7.2040e-04 - mae: 0.0017 - val_loss: 7.2274e-04 - val_mae: 0.0021\n",
      "Epoch 746/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 7.2006e-04 - mae: 0.0020 - val_loss: 7.1529e-04 - val_mae: 0.0015\n",
      "Epoch 747/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.1410e-04 - mae: 0.0015 - val_loss: 7.1249e-04 - val_mae: 0.0014\n",
      "Epoch 748/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 7.1252e-04 - mae: 0.0017 - val_loss: 7.1065e-04 - val_mae: 0.0016\n",
      "Epoch 749/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 7.0985e-04 - mae: 0.0017 - val_loss: 7.2750e-04 - val_mae: 0.0038\n",
      "Epoch 750/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 7.0992e-04 - mae: 0.0021 - val_loss: 7.2362e-04 - val_mae: 0.0038\n",
      "Epoch 751/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 7.0578e-04 - mae: 0.0019 - val_loss: 7.0352e-04 - val_mae: 0.0017\n",
      "Epoch 752/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 7.0419e-04 - mae: 0.0020 - val_loss: 7.0275e-04 - val_mae: 0.0019\n",
      "Epoch 753/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.9938e-04 - mae: 0.0017 - val_loss: 6.9906e-04 - val_mae: 0.0018\n",
      "Epoch 754/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.9641e-04 - mae: 0.0016 - val_loss: 6.9458e-04 - val_mae: 0.0014\n",
      "Epoch 755/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.9401e-04 - mae: 0.0016 - val_loss: 6.9218e-04 - val_mae: 0.0015\n",
      "Epoch 756/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.9192e-04 - mae: 0.0017 - val_loss: 7.9688e-04 - val_mae: 0.0085\n",
      "Epoch 757/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.9994e-04 - mae: 0.0025 - val_loss: 6.8766e-04 - val_mae: 0.0016\n",
      "Epoch 758/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.8599e-04 - mae: 0.0015 - val_loss: 6.8624e-04 - val_mae: 0.0017\n",
      "Epoch 759/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.8385e-04 - mae: 0.0015 - val_loss: 6.8255e-04 - val_mae: 0.0015\n",
      "Epoch 760/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.8287e-04 - mae: 0.0017 - val_loss: 6.8209e-04 - val_mae: 0.0020\n",
      "Epoch 761/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.8068e-04 - mae: 0.0018 - val_loss: 7.0138e-04 - val_mae: 0.0043\n",
      "Epoch 762/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.7972e-04 - mae: 0.0020 - val_loss: 6.7955e-04 - val_mae: 0.0022\n",
      "Epoch 763/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.8049e-04 - mae: 0.0023 - val_loss: 6.7226e-04 - val_mae: 0.0011\n",
      "Epoch 764/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.7244e-04 - mae: 0.0015 - val_loss: 6.7060e-04 - val_mae: 0.0014\n",
      "Epoch 765/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.6963e-04 - mae: 0.0015 - val_loss: 7.1588e-04 - val_mae: 0.0052\n",
      "Epoch 766/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.7090e-04 - mae: 0.0020 - val_loss: 6.6621e-04 - val_mae: 0.0013\n",
      "Epoch 767/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.6582e-04 - mae: 0.0016 - val_loss: 6.6958e-04 - val_mae: 0.0025\n",
      "Epoch 768/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.6345e-04 - mae: 0.0016 - val_loss: 6.6881e-04 - val_mae: 0.0026\n",
      "Epoch 769/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.6140e-04 - mae: 0.0017 - val_loss: 6.6180e-04 - val_mae: 0.0018\n",
      "Epoch 770/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.6542e-04 - mae: 0.0024 - val_loss: 6.5804e-04 - val_mae: 0.0016\n",
      "Epoch 771/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.5621e-04 - mae: 0.0016 - val_loss: 6.6366e-04 - val_mae: 0.0026\n",
      "Epoch 772/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.5394e-04 - mae: 0.0016 - val_loss: 6.5442e-04 - val_mae: 0.0018\n",
      "Epoch 773/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.5398e-04 - mae: 0.0020 - val_loss: 6.5010e-04 - val_mae: 0.0015\n",
      "Epoch 774/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.4951e-04 - mae: 0.0016 - val_loss: 6.5354e-04 - val_mae: 0.0025\n",
      "Epoch 775/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.4753e-04 - mae: 0.0017 - val_loss: 6.4550e-04 - val_mae: 0.0015\n",
      "Epoch 776/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.4581e-04 - mae: 0.0017 - val_loss: 6.4476e-04 - val_mae: 0.0018\n",
      "Epoch 777/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.4462e-04 - mae: 0.0019 - val_loss: 6.4171e-04 - val_mae: 0.0015\n",
      "Epoch 778/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.3997e-04 - mae: 0.0016 - val_loss: 6.3873e-04 - val_mae: 0.0015\n",
      "Epoch 779/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.4205e-04 - mae: 0.0022 - val_loss: 6.3998e-04 - val_mae: 0.0021\n",
      "Epoch 780/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.3793e-04 - mae: 0.0020 - val_loss: 6.3958e-04 - val_mae: 0.0023\n",
      "Epoch 781/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.3405e-04 - mae: 0.0017 - val_loss: 6.4233e-04 - val_mae: 0.0031\n",
      "Epoch 782/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.3359e-04 - mae: 0.0019 - val_loss: 6.3247e-04 - val_mae: 0.0019\n",
      "Epoch 783/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.2812e-04 - mae: 0.0014 - val_loss: 6.3182e-04 - val_mae: 0.0022\n",
      "Epoch 784/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.2988e-04 - mae: 0.0020 - val_loss: 6.3107e-04 - val_mae: 0.0023\n",
      "Epoch 785/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.2546e-04 - mae: 0.0017 - val_loss: 6.2434e-04 - val_mae: 0.0016\n",
      "Epoch 786/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.2639e-04 - mae: 0.0021 - val_loss: 6.3248e-04 - val_mae: 0.0031\n",
      "Epoch 787/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.2211e-04 - mae: 0.0019 - val_loss: 6.1936e-04 - val_mae: 0.0014\n",
      "Epoch 788/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.1917e-04 - mae: 0.0017 - val_loss: 6.1991e-04 - val_mae: 0.0021\n",
      "Epoch 789/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.1786e-04 - mae: 0.0018 - val_loss: 6.1849e-04 - val_mae: 0.0019\n",
      "Epoch 790/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.1463e-04 - mae: 0.0016 - val_loss: 6.2109e-04 - val_mae: 0.0026\n",
      "Epoch 791/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.1294e-04 - mae: 0.0017 - val_loss: 7.4739e-04 - val_mae: 0.0083\n",
      "Epoch 792/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.1576e-04 - mae: 0.0022 - val_loss: 6.1134e-04 - val_mae: 0.0020\n",
      "Epoch 793/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.0936e-04 - mae: 0.0018 - val_loss: 6.3837e-04 - val_mae: 0.0041\n",
      "Epoch 794/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.0715e-04 - mae: 0.0017 - val_loss: 6.1066e-04 - val_mae: 0.0023\n",
      "Epoch 795/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.0523e-04 - mae: 0.0018 - val_loss: 6.1215e-04 - val_mae: 0.0028\n",
      "Epoch 796/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.0529e-04 - mae: 0.0021 - val_loss: 6.2313e-04 - val_mae: 0.0036\n",
      "Epoch 797/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 6.0247e-04 - mae: 0.0020 - val_loss: 6.0052e-04 - val_mae: 0.0018\n",
      "Epoch 798/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.9870e-04 - mae: 0.0017 - val_loss: 6.0393e-04 - val_mae: 0.0029\n",
      "Epoch 799/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.9718e-04 - mae: 0.0017 - val_loss: 6.0305e-04 - val_mae: 0.0028\n",
      "Epoch 800/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 5.9393e-04 - mae: 0.0015 - val_loss: 5.9371e-04 - val_mae: 0.0015\n",
      "Epoch 801/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.9360e-04 - mae: 0.0018 - val_loss: 5.8996e-04 - val_mae: 0.0012\n",
      "Epoch 802/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.9020e-04 - mae: 0.0016 - val_loss: 6.0103e-04 - val_mae: 0.0028\n",
      "Epoch 803/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.8974e-04 - mae: 0.0018 - val_loss: 5.9111e-04 - val_mae: 0.0021\n",
      "Epoch 804/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.8697e-04 - mae: 0.0017 - val_loss: 5.9444e-04 - val_mae: 0.0024\n",
      "Epoch 805/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.8536e-04 - mae: 0.0018 - val_loss: 6.1775e-04 - val_mae: 0.0046\n",
      "Epoch 806/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.8482e-04 - mae: 0.0019 - val_loss: 5.8170e-04 - val_mae: 0.0017\n",
      "Epoch 807/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.8089e-04 - mae: 0.0017 - val_loss: 5.8341e-04 - val_mae: 0.0025\n",
      "Epoch 808/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.7933e-04 - mae: 0.0017 - val_loss: 6.1924e-04 - val_mae: 0.0054\n",
      "Epoch 809/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.7883e-04 - mae: 0.0019 - val_loss: 5.7523e-04 - val_mae: 0.0014\n",
      "Epoch 810/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.7603e-04 - mae: 0.0018 - val_loss: 6.2543e-04 - val_mae: 0.0055\n",
      "Epoch 811/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.7427e-04 - mae: 0.0018 - val_loss: 5.9808e-04 - val_mae: 0.0051\n",
      "Epoch 812/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.7209e-04 - mae: 0.0018 - val_loss: 5.7269e-04 - val_mae: 0.0019\n",
      "Epoch 813/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.7358e-04 - mae: 0.0023 - val_loss: 5.6695e-04 - val_mae: 0.0012\n",
      "Epoch 814/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.6643e-04 - mae: 0.0014 - val_loss: 5.6687e-04 - val_mae: 0.0017\n",
      "Epoch 815/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.6585e-04 - mae: 0.0016 - val_loss: 5.6615e-04 - val_mae: 0.0017\n",
      "Epoch 816/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.6386e-04 - mae: 0.0016 - val_loss: 5.6496e-04 - val_mae: 0.0018\n",
      "Epoch 817/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.6250e-04 - mae: 0.0017 - val_loss: 5.6436e-04 - val_mae: 0.0021\n",
      "Epoch 818/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.6247e-04 - mae: 0.0020 - val_loss: 5.6590e-04 - val_mae: 0.0024\n",
      "Epoch 819/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 5.6125e-04 - mae: 0.0020 - val_loss: 5.7715e-04 - val_mae: 0.0037\n",
      "Epoch 820/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 5.5908e-04 - mae: 0.0020 - val_loss: 5.6435e-04 - val_mae: 0.0029\n",
      "Epoch 821/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.5469e-04 - mae: 0.0016 - val_loss: 5.5885e-04 - val_mae: 0.0023\n",
      "Epoch 822/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.5512e-04 - mae: 0.0019 - val_loss: 5.5152e-04 - val_mae: 0.0014\n",
      "Epoch 823/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.5159e-04 - mae: 0.0016 - val_loss: 5.5182e-04 - val_mae: 0.0018\n",
      "Epoch 824/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.5083e-04 - mae: 0.0018 - val_loss: 6.0795e-04 - val_mae: 0.0062\n",
      "Epoch 825/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.5157e-04 - mae: 0.0019 - val_loss: 5.4825e-04 - val_mae: 0.0017\n",
      "Epoch 826/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.4623e-04 - mae: 0.0016 - val_loss: 5.4586e-04 - val_mae: 0.0017\n",
      "Epoch 827/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.4394e-04 - mae: 0.0015 - val_loss: 5.4709e-04 - val_mae: 0.0021\n",
      "Epoch 828/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.4411e-04 - mae: 0.0019 - val_loss: 5.4187e-04 - val_mae: 0.0016\n",
      "Epoch 829/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.4049e-04 - mae: 0.0015 - val_loss: 6.3935e-04 - val_mae: 0.0075\n",
      "Epoch 830/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.4286e-04 - mae: 0.0020 - val_loss: 5.4630e-04 - val_mae: 0.0027\n",
      "Epoch 831/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.4070e-04 - mae: 0.0020 - val_loss: 5.3588e-04 - val_mae: 0.0014\n",
      "Epoch 832/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.3487e-04 - mae: 0.0014 - val_loss: 5.3492e-04 - val_mae: 0.0015\n",
      "Epoch 833/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.3487e-04 - mae: 0.0017 - val_loss: 5.3364e-04 - val_mae: 0.0017\n",
      "Epoch 834/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.3165e-04 - mae: 0.0015 - val_loss: 5.4260e-04 - val_mae: 0.0035\n",
      "Epoch 835/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.3371e-04 - mae: 0.0021 - val_loss: 5.3379e-04 - val_mae: 0.0023\n",
      "Epoch 836/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.2896e-04 - mae: 0.0016 - val_loss: 5.3006e-04 - val_mae: 0.0020\n",
      "Epoch 837/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.2657e-04 - mae: 0.0015 - val_loss: 5.2787e-04 - val_mae: 0.0018\n",
      "Epoch 838/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.2580e-04 - mae: 0.0017 - val_loss: 5.3006e-04 - val_mae: 0.0028\n",
      "Epoch 839/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.2431e-04 - mae: 0.0017 - val_loss: 5.2253e-04 - val_mae: 0.0014\n",
      "Epoch 840/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.2252e-04 - mae: 0.0017 - val_loss: 5.2258e-04 - val_mae: 0.0019\n",
      "Epoch 841/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.2198e-04 - mae: 0.0019 - val_loss: 5.2142e-04 - val_mae: 0.0019\n",
      "Epoch 842/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.1834e-04 - mae: 0.0016 - val_loss: 5.2532e-04 - val_mae: 0.0029\n",
      "Epoch 843/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.1770e-04 - mae: 0.0017 - val_loss: 5.2894e-04 - val_mae: 0.0036\n",
      "Epoch 844/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 5.1770e-04 - mae: 0.0020 - val_loss: 5.1416e-04 - val_mae: 0.0015\n",
      "Epoch 845/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.1352e-04 - mae: 0.0016 - val_loss: 5.1598e-04 - val_mae: 0.0020\n",
      "Epoch 846/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.1238e-04 - mae: 0.0017 - val_loss: 5.1078e-04 - val_mae: 0.0015\n",
      "Epoch 847/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.0982e-04 - mae: 0.0016 - val_loss: 5.1175e-04 - val_mae: 0.0020\n",
      "Epoch 848/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 5.0873e-04 - mae: 0.0017 - val_loss: 5.1842e-04 - val_mae: 0.0029\n",
      "Epoch 849/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.0923e-04 - mae: 0.0020 - val_loss: 5.1031e-04 - val_mae: 0.0021\n",
      "Epoch 850/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.0742e-04 - mae: 0.0018 - val_loss: 5.0733e-04 - val_mae: 0.0022\n",
      "Epoch 851/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.0685e-04 - mae: 0.0020 - val_loss: 5.4529e-04 - val_mae: 0.0051\n",
      "Epoch 852/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.0333e-04 - mae: 0.0018 - val_loss: 5.0056e-04 - val_mae: 0.0014\n",
      "Epoch 853/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.0002e-04 - mae: 0.0015 - val_loss: 5.5574e-04 - val_mae: 0.0056\n",
      "Epoch 854/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 5.0068e-04 - mae: 0.0018 - val_loss: 4.9991e-04 - val_mae: 0.0019\n",
      "Epoch 855/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.9781e-04 - mae: 0.0017 - val_loss: 5.2440e-04 - val_mae: 0.0047\n",
      "Epoch 856/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.9659e-04 - mae: 0.0017 - val_loss: 4.9426e-04 - val_mae: 0.0013\n",
      "Epoch 857/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.9555e-04 - mae: 0.0018 - val_loss: 4.9301e-04 - val_mae: 0.0014\n",
      "Epoch 858/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.9364e-04 - mae: 0.0017 - val_loss: 4.9267e-04 - val_mae: 0.0016\n",
      "Epoch 859/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.9181e-04 - mae: 0.0017 - val_loss: 4.9479e-04 - val_mae: 0.0025\n",
      "Epoch 860/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.8968e-04 - mae: 0.0016 - val_loss: 4.8917e-04 - val_mae: 0.0016\n",
      "Epoch 861/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.8981e-04 - mae: 0.0019 - val_loss: 4.8774e-04 - val_mae: 0.0016\n",
      "Epoch 862/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.8672e-04 - mae: 0.0016 - val_loss: 4.8640e-04 - val_mae: 0.0015\n",
      "Epoch 863/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.8631e-04 - mae: 0.0018 - val_loss: 5.0525e-04 - val_mae: 0.0044\n",
      "Epoch 864/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.8681e-04 - mae: 0.0021 - val_loss: 5.1499e-04 - val_mae: 0.0057\n",
      "Epoch 865/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.8371e-04 - mae: 0.0019 - val_loss: 4.8101e-04 - val_mae: 0.0015\n",
      "Epoch 866/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.8279e-04 - mae: 0.0020 - val_loss: 4.8514e-04 - val_mae: 0.0022\n",
      "Epoch 867/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.7896e-04 - mae: 0.0015 - val_loss: 4.8637e-04 - val_mae: 0.0029\n",
      "Epoch 868/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.7795e-04 - mae: 0.0016 - val_loss: 4.8031e-04 - val_mae: 0.0021\n",
      "Epoch 869/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.7837e-04 - mae: 0.0019 - val_loss: 4.7565e-04 - val_mae: 0.0016\n",
      "Epoch 870/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.7462e-04 - mae: 0.0016 - val_loss: 4.7679e-04 - val_mae: 0.0020\n",
      "Epoch 871/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.7430e-04 - mae: 0.0018 - val_loss: 4.7944e-04 - val_mae: 0.0026\n",
      "Epoch 872/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.7320e-04 - mae: 0.0018 - val_loss: 4.7232e-04 - val_mae: 0.0016\n",
      "Epoch 873/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.6980e-04 - mae: 0.0015 - val_loss: 4.7168e-04 - val_mae: 0.0019\n",
      "Epoch 874/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.7382e-04 - mae: 0.0023 - val_loss: 4.6946e-04 - val_mae: 0.0017\n",
      "Epoch 875/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.6719e-04 - mae: 0.0015 - val_loss: 4.6756e-04 - val_mae: 0.0016\n",
      "Epoch 876/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.6609e-04 - mae: 0.0015 - val_loss: 5.0246e-04 - val_mae: 0.0046\n",
      "Epoch 877/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.6578e-04 - mae: 0.0017 - val_loss: 4.6298e-04 - val_mae: 0.0011\n",
      "Epoch 878/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.6377e-04 - mae: 0.0016 - val_loss: 4.8177e-04 - val_mae: 0.0038\n",
      "Epoch 879/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.6282e-04 - mae: 0.0017 - val_loss: 4.6193e-04 - val_mae: 0.0016\n",
      "Epoch 880/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.6187e-04 - mae: 0.0017 - val_loss: 4.6017e-04 - val_mae: 0.0016\n",
      "Epoch 881/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.5926e-04 - mae: 0.0016 - val_loss: 4.5728e-04 - val_mae: 0.0012\n",
      "Epoch 882/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.5775e-04 - mae: 0.0016 - val_loss: 4.5716e-04 - val_mae: 0.0016\n",
      "Epoch 883/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.5685e-04 - mae: 0.0016 - val_loss: 4.5566e-04 - val_mae: 0.0015\n",
      "Epoch 884/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.5616e-04 - mae: 0.0018 - val_loss: 4.5977e-04 - val_mae: 0.0023\n",
      "Epoch 885/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.5715e-04 - mae: 0.0021 - val_loss: 5.0805e-04 - val_mae: 0.0055\n",
      "Epoch 886/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.5376e-04 - mae: 0.0018 - val_loss: 4.6506e-04 - val_mae: 0.0034\n",
      "Epoch 887/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.5099e-04 - mae: 0.0016 - val_loss: 4.6651e-04 - val_mae: 0.0039\n",
      "Epoch 888/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.5091e-04 - mae: 0.0017 - val_loss: 4.5253e-04 - val_mae: 0.0021\n",
      "Epoch 889/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.4956e-04 - mae: 0.0018 - val_loss: 4.5393e-04 - val_mae: 0.0027\n",
      "Epoch 890/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.4785e-04 - mae: 0.0017 - val_loss: 4.5097e-04 - val_mae: 0.0024\n",
      "Epoch 891/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.4638e-04 - mae: 0.0017 - val_loss: 4.6791e-04 - val_mae: 0.0038\n",
      "Epoch 892/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.4516e-04 - mae: 0.0016 - val_loss: 4.6786e-04 - val_mae: 0.0045\n",
      "Epoch 893/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.4422e-04 - mae: 0.0018 - val_loss: 4.4863e-04 - val_mae: 0.0028\n",
      "Epoch 894/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.4313e-04 - mae: 0.0018 - val_loss: 4.5528e-04 - val_mae: 0.0037\n",
      "Epoch 895/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.4174e-04 - mae: 0.0018 - val_loss: 4.4128e-04 - val_mae: 0.0018\n",
      "Epoch 896/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.3939e-04 - mae: 0.0016 - val_loss: 4.3768e-04 - val_mae: 0.0013\n",
      "Epoch 897/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.3806e-04 - mae: 0.0016 - val_loss: 4.4421e-04 - val_mae: 0.0028\n",
      "Epoch 898/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.3849e-04 - mae: 0.0017 - val_loss: 4.3570e-04 - val_mae: 0.0012\n",
      "Epoch 899/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.3728e-04 - mae: 0.0019 - val_loss: 4.4641e-04 - val_mae: 0.0031\n",
      "Epoch 900/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.3428e-04 - mae: 0.0016 - val_loss: 4.3933e-04 - val_mae: 0.0027\n",
      "Epoch 901/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.3505e-04 - mae: 0.0019 - val_loss: 4.4025e-04 - val_mae: 0.0031\n",
      "Epoch 902/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.3851e-04 - mae: 0.0023 - val_loss: 5.1220e-04 - val_mae: 0.0075\n",
      "Epoch 903/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.3309e-04 - mae: 0.0018 - val_loss: 4.3181e-04 - val_mae: 0.0020\n",
      "Epoch 904/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.2907e-04 - mae: 0.0015 - val_loss: 4.2871e-04 - val_mae: 0.0014\n",
      "Epoch 905/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.2920e-04 - mae: 0.0017 - val_loss: 4.3672e-04 - val_mae: 0.0026\n",
      "Epoch 906/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.2763e-04 - mae: 0.0016 - val_loss: 4.3093e-04 - val_mae: 0.0020\n",
      "Epoch 907/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.2593e-04 - mae: 0.0015 - val_loss: 4.3589e-04 - val_mae: 0.0033\n",
      "Epoch 908/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.2643e-04 - mae: 0.0018 - val_loss: 4.2897e-04 - val_mae: 0.0023\n",
      "Epoch 909/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.2448e-04 - mae: 0.0017 - val_loss: 4.4273e-04 - val_mae: 0.0046\n",
      "Epoch 910/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.2277e-04 - mae: 0.0015 - val_loss: 4.2217e-04 - val_mae: 0.0014\n",
      "Epoch 911/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.2396e-04 - mae: 0.0019 - val_loss: 4.3770e-04 - val_mae: 0.0042\n",
      "Epoch 912/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.2147e-04 - mae: 0.0017 - val_loss: 4.2349e-04 - val_mae: 0.0022\n",
      "Epoch 913/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.1987e-04 - mae: 0.0016 - val_loss: 4.2203e-04 - val_mae: 0.0019\n",
      "Epoch 914/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.1842e-04 - mae: 0.0016 - val_loss: 4.3335e-04 - val_mae: 0.0035\n",
      "Epoch 915/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.1919e-04 - mae: 0.0019 - val_loss: 4.1743e-04 - val_mae: 0.0015\n",
      "Epoch 916/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.1726e-04 - mae: 0.0018 - val_loss: 4.1768e-04 - val_mae: 0.0020\n",
      "Epoch 917/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.1438e-04 - mae: 0.0015 - val_loss: 4.1780e-04 - val_mae: 0.0020\n",
      "Epoch 918/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.1422e-04 - mae: 0.0017 - val_loss: 4.1417e-04 - val_mae: 0.0018\n",
      "Epoch 919/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.1291e-04 - mae: 0.0016 - val_loss: 4.1414e-04 - val_mae: 0.0021\n",
      "Epoch 920/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.1150e-04 - mae: 0.0015 - val_loss: 4.1230e-04 - val_mae: 0.0017\n",
      "Epoch 921/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.1009e-04 - mae: 0.0015 - val_loss: 4.0818e-04 - val_mae: 0.0011\n",
      "Epoch 922/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.0910e-04 - mae: 0.0016 - val_loss: 4.0961e-04 - val_mae: 0.0016\n",
      "Epoch 923/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.0853e-04 - mae: 0.0017 - val_loss: 4.2287e-04 - val_mae: 0.0034\n",
      "Epoch 924/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.0917e-04 - mae: 0.0019 - val_loss: 4.0805e-04 - val_mae: 0.0018\n",
      "Epoch 925/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.0724e-04 - mae: 0.0018 - val_loss: 4.0847e-04 - val_mae: 0.0021\n",
      "Epoch 926/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.0392e-04 - mae: 0.0015 - val_loss: 4.0839e-04 - val_mae: 0.0022\n",
      "Epoch 927/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.0419e-04 - mae: 0.0017 - val_loss: 4.0330e-04 - val_mae: 0.0015\n",
      "Epoch 928/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.0247e-04 - mae: 0.0016 - val_loss: 4.0357e-04 - val_mae: 0.0018\n",
      "Epoch 929/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.0111e-04 - mae: 0.0015 - val_loss: 4.0005e-04 - val_mae: 0.0014\n",
      "Epoch 930/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 4.0092e-04 - mae: 0.0017 - val_loss: 4.0678e-04 - val_mae: 0.0028\n",
      "Epoch 931/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.9906e-04 - mae: 0.0016 - val_loss: 3.9699e-04 - val_mae: 0.0011\n",
      "Epoch 932/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.9942e-04 - mae: 0.0019 - val_loss: 4.0566e-04 - val_mae: 0.0026\n",
      "Epoch 933/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.9834e-04 - mae: 0.0018 - val_loss: 4.0023e-04 - val_mae: 0.0022\n",
      "Epoch 934/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.9582e-04 - mae: 0.0016 - val_loss: 3.9629e-04 - val_mae: 0.0018\n",
      "Epoch 935/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.9566e-04 - mae: 0.0017 - val_loss: 4.3236e-04 - val_mae: 0.0048\n",
      "Epoch 936/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.9561e-04 - mae: 0.0018 - val_loss: 3.9379e-04 - val_mae: 0.0016\n",
      "Epoch 937/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.9432e-04 - mae: 0.0018 - val_loss: 3.9440e-04 - val_mae: 0.0020\n",
      "Epoch 938/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.9250e-04 - mae: 0.0017 - val_loss: 3.9229e-04 - val_mae: 0.0017\n",
      "Epoch 939/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.9080e-04 - mae: 0.0016 - val_loss: 3.9613e-04 - val_mae: 0.0024\n",
      "Epoch 940/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.9049e-04 - mae: 0.0017 - val_loss: 3.8940e-04 - val_mae: 0.0015\n",
      "Epoch 941/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.8817e-04 - mae: 0.0015 - val_loss: 3.8742e-04 - val_mae: 0.0012\n",
      "Epoch 942/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.8822e-04 - mae: 0.0016 - val_loss: 3.9205e-04 - val_mae: 0.0022\n",
      "Epoch 943/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.8837e-04 - mae: 0.0019 - val_loss: 3.9248e-04 - val_mae: 0.0025\n",
      "Epoch 944/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.8574e-04 - mae: 0.0016 - val_loss: 3.8538e-04 - val_mae: 0.0016\n",
      "Epoch 945/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.8526e-04 - mae: 0.0017 - val_loss: 3.8316e-04 - val_mae: 0.0012\n",
      "Epoch 946/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.8348e-04 - mae: 0.0015 - val_loss: 3.8442e-04 - val_mae: 0.0017\n",
      "Epoch 947/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.8295e-04 - mae: 0.0016 - val_loss: 3.8371e-04 - val_mae: 0.0018\n",
      "Epoch 948/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.8647e-04 - mae: 0.0021 - val_loss: 3.9307e-04 - val_mae: 0.0029\n",
      "Epoch 949/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.8059e-04 - mae: 0.0015 - val_loss: 3.7898e-04 - val_mae: 0.0012\n",
      "Epoch 950/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.7976e-04 - mae: 0.0016 - val_loss: 3.7916e-04 - val_mae: 0.0014\n",
      "Epoch 951/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.7941e-04 - mae: 0.0016 - val_loss: 3.7902e-04 - val_mae: 0.0016\n",
      "Epoch 952/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.7870e-04 - mae: 0.0017 - val_loss: 3.7665e-04 - val_mae: 0.0012\n",
      "Epoch 953/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.7679e-04 - mae: 0.0015 - val_loss: 3.8479e-04 - val_mae: 0.0031\n",
      "Epoch 954/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.7599e-04 - mae: 0.0016 - val_loss: 3.7612e-04 - val_mae: 0.0016\n",
      "Epoch 955/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.7516e-04 - mae: 0.0016 - val_loss: 3.7379e-04 - val_mae: 0.0014\n",
      "Epoch 956/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.7618e-04 - mae: 0.0018 - val_loss: 3.7397e-04 - val_mae: 0.0016\n",
      "Epoch 957/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.7315e-04 - mae: 0.0016 - val_loss: 3.7111e-04 - val_mae: 0.0011\n",
      "Epoch 958/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.7178e-04 - mae: 0.0015 - val_loss: 3.7337e-04 - val_mae: 0.0019\n",
      "Epoch 959/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.7234e-04 - mae: 0.0018 - val_loss: 3.7485e-04 - val_mae: 0.0021\n",
      "Epoch 960/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.7000e-04 - mae: 0.0015 - val_loss: 4.2774e-04 - val_mae: 0.0056\n",
      "Epoch 961/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.7333e-04 - mae: 0.0021 - val_loss: 3.6748e-04 - val_mae: 0.0011\n",
      "Epoch 962/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.6789e-04 - mae: 0.0014 - val_loss: 3.7720e-04 - val_mae: 0.0029\n",
      "Epoch 963/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.6803e-04 - mae: 0.0016 - val_loss: 3.6625e-04 - val_mae: 0.0012\n",
      "Epoch 964/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.6594e-04 - mae: 0.0014 - val_loss: 3.7300e-04 - val_mae: 0.0030\n",
      "Epoch 965/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.6620e-04 - mae: 0.0017 - val_loss: 3.6527e-04 - val_mae: 0.0016\n",
      "Epoch 966/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.6657e-04 - mae: 0.0018 - val_loss: 3.6338e-04 - val_mae: 0.0012\n",
      "Epoch 967/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.6488e-04 - mae: 0.0016 - val_loss: 3.6249e-04 - val_mae: 0.0013\n",
      "Epoch 968/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.6390e-04 - mae: 0.0017 - val_loss: 3.7432e-04 - val_mae: 0.0035\n",
      "Epoch 969/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.6273e-04 - mae: 0.0017 - val_loss: 3.6324e-04 - val_mae: 0.0017\n",
      "Epoch 970/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.6301e-04 - mae: 0.0019 - val_loss: 3.7550e-04 - val_mae: 0.0033\n",
      "Epoch 971/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.6108e-04 - mae: 0.0016 - val_loss: 3.6028e-04 - val_mae: 0.0015\n",
      "Epoch 972/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.5891e-04 - mae: 0.0014 - val_loss: 3.5897e-04 - val_mae: 0.0012\n",
      "Epoch 973/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.6172e-04 - mae: 0.0019 - val_loss: 3.6115e-04 - val_mae: 0.0022\n",
      "Epoch 974/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.5889e-04 - mae: 0.0017 - val_loss: 3.6347e-04 - val_mae: 0.0027\n",
      "Epoch 975/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.5729e-04 - mae: 0.0016 - val_loss: 3.5924e-04 - val_mae: 0.0022\n",
      "Epoch 976/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.5621e-04 - mae: 0.0015 - val_loss: 3.5509e-04 - val_mae: 0.0012\n",
      "Epoch 977/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.5680e-04 - mae: 0.0018 - val_loss: 3.6613e-04 - val_mae: 0.0031\n",
      "Epoch 978/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.5733e-04 - mae: 0.0019 - val_loss: 3.5493e-04 - val_mae: 0.0017\n",
      "Epoch 979/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.5351e-04 - mae: 0.0015 - val_loss: 3.6353e-04 - val_mae: 0.0030\n",
      "Epoch 980/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.5264e-04 - mae: 0.0015 - val_loss: 3.5640e-04 - val_mae: 0.0022\n",
      "Epoch 981/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.5254e-04 - mae: 0.0016 - val_loss: 3.5247e-04 - val_mae: 0.0017\n",
      "Epoch 982/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.5232e-04 - mae: 0.0017 - val_loss: 4.0337e-04 - val_mae: 0.0054\n",
      "Epoch 983/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.5328e-04 - mae: 0.0018 - val_loss: 3.5657e-04 - val_mae: 0.0028\n",
      "Epoch 984/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.5085e-04 - mae: 0.0017 - val_loss: 3.6078e-04 - val_mae: 0.0034\n",
      "Epoch 985/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.4873e-04 - mae: 0.0015 - val_loss: 3.5019e-04 - val_mae: 0.0017\n",
      "Epoch 986/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.5043e-04 - mae: 0.0018 - val_loss: 3.8331e-04 - val_mae: 0.0058\n",
      "Epoch 987/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.5428e-04 - mae: 0.0022 - val_loss: 3.4586e-04 - val_mae: 0.0011\n",
      "Epoch 988/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.4628e-04 - mae: 0.0014 - val_loss: 3.4934e-04 - val_mae: 0.0020\n",
      "Epoch 989/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.4539e-04 - mae: 0.0014 - val_loss: 3.4978e-04 - val_mae: 0.0022\n",
      "Epoch 990/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.4570e-04 - mae: 0.0016 - val_loss: 3.5476e-04 - val_mae: 0.0032\n",
      "Epoch 991/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.4551e-04 - mae: 0.0017 - val_loss: 3.4721e-04 - val_mae: 0.0019\n",
      "Epoch 992/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.4463e-04 - mae: 0.0016 - val_loss: 3.4448e-04 - val_mae: 0.0016\n",
      "Epoch 993/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.4277e-04 - mae: 0.0014 - val_loss: 3.4516e-04 - val_mae: 0.0020\n",
      "Epoch 994/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.4223e-04 - mae: 0.0015 - val_loss: 3.7997e-04 - val_mae: 0.0047\n",
      "Epoch 995/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.4288e-04 - mae: 0.0017 - val_loss: 3.4116e-04 - val_mae: 0.0014\n",
      "Epoch 996/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.4067e-04 - mae: 0.0015 - val_loss: 3.4315e-04 - val_mae: 0.0022\n",
      "Epoch 997/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.4052e-04 - mae: 0.0016 - val_loss: 4.7656e-04 - val_mae: 0.0087\n",
      "Epoch 998/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.4836e-04 - mae: 0.0023 - val_loss: 3.3797e-04 - val_mae: 0.0012\n",
      "Epoch 999/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.3803e-04 - mae: 0.0014 - val_loss: 3.4141e-04 - val_mae: 0.0020\n",
      "Epoch 1000/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.3845e-04 - mae: 0.0015 - val_loss: 3.4024e-04 - val_mae: 0.0021\n",
      "Epoch 1001/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.3707e-04 - mae: 0.0015 - val_loss: 3.4413e-04 - val_mae: 0.0025\n",
      "Epoch 1002/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.3779e-04 - mae: 0.0017 - val_loss: 3.3604e-04 - val_mae: 0.0015\n",
      "Epoch 1003/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.3612e-04 - mae: 0.0016 - val_loss: 3.3813e-04 - val_mae: 0.0020\n",
      "Epoch 1004/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.3576e-04 - mae: 0.0016 - val_loss: 3.3426e-04 - val_mae: 0.0013\n",
      "Epoch 1005/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.3371e-04 - mae: 0.0014 - val_loss: 3.3941e-04 - val_mae: 0.0024\n",
      "Epoch 1006/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.3327e-04 - mae: 0.0014 - val_loss: 3.3787e-04 - val_mae: 0.0026\n",
      "Epoch 1007/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.3239e-04 - mae: 0.0014 - val_loss: 3.3392e-04 - val_mae: 0.0017\n",
      "Epoch 1008/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.3236e-04 - mae: 0.0016 - val_loss: 3.3103e-04 - val_mae: 0.0013\n",
      "Epoch 1009/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.3143e-04 - mae: 0.0016 - val_loss: 3.3411e-04 - val_mae: 0.0021\n",
      "Epoch 1010/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.3218e-04 - mae: 0.0018 - val_loss: 3.2996e-04 - val_mae: 0.0014\n",
      "Epoch 1011/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.2926e-04 - mae: 0.0014 - val_loss: 3.2943e-04 - val_mae: 0.0014\n",
      "Epoch 1012/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.3206e-04 - mae: 0.0020 - val_loss: 3.4187e-04 - val_mae: 0.0034\n",
      "Epoch 1013/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.2934e-04 - mae: 0.0017 - val_loss: 3.3841e-04 - val_mae: 0.0034\n",
      "Epoch 1014/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.2970e-04 - mae: 0.0019 - val_loss: 3.3874e-04 - val_mae: 0.0030\n",
      "Epoch 1015/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.2742e-04 - mae: 0.0016 - val_loss: 3.3501e-04 - val_mae: 0.0028\n",
      "Epoch 1016/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.2672e-04 - mae: 0.0016 - val_loss: 3.2505e-04 - val_mae: 0.0011\n",
      "Epoch 1017/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.2511e-04 - mae: 0.0014 - val_loss: 3.2894e-04 - val_mae: 0.0022\n",
      "Epoch 1018/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.2604e-04 - mae: 0.0017 - val_loss: 3.2639e-04 - val_mae: 0.0018\n",
      "Epoch 1019/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.2553e-04 - mae: 0.0018 - val_loss: 3.2929e-04 - val_mae: 0.0023\n",
      "Epoch 1020/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.2434e-04 - mae: 0.0016 - val_loss: 3.2317e-04 - val_mae: 0.0014\n",
      "Epoch 1021/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.2718e-04 - mae: 0.0021 - val_loss: 3.4640e-04 - val_mae: 0.0039\n",
      "Epoch 1022/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.2370e-04 - mae: 0.0017 - val_loss: 3.2224e-04 - val_mae: 0.0014\n",
      "Epoch 1023/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.2138e-04 - mae: 0.0015 - val_loss: 3.2443e-04 - val_mae: 0.0021\n",
      "Epoch 1024/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.2049e-04 - mae: 0.0014 - val_loss: 3.3571e-04 - val_mae: 0.0036\n",
      "Epoch 1025/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.2060e-04 - mae: 0.0015 - val_loss: 3.2814e-04 - val_mae: 0.0026\n",
      "Epoch 1026/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.1943e-04 - mae: 0.0014 - val_loss: 3.2072e-04 - val_mae: 0.0016\n",
      "Epoch 1027/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.1977e-04 - mae: 0.0016 - val_loss: 3.2250e-04 - val_mae: 0.0021\n",
      "Epoch 1028/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.1874e-04 - mae: 0.0016 - val_loss: 3.1797e-04 - val_mae: 0.0014\n",
      "Epoch 1029/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.1724e-04 - mae: 0.0014 - val_loss: 3.2107e-04 - val_mae: 0.0024\n",
      "Epoch 1030/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.1801e-04 - mae: 0.0017 - val_loss: 3.1560e-04 - val_mae: 0.0012\n",
      "Epoch 1031/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.1632e-04 - mae: 0.0015 - val_loss: 3.1698e-04 - val_mae: 0.0017\n",
      "Epoch 1032/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.1599e-04 - mae: 0.0016 - val_loss: 3.1675e-04 - val_mae: 0.0015\n",
      "Epoch 1033/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.1499e-04 - mae: 0.0015 - val_loss: 3.1377e-04 - val_mae: 0.0013\n",
      "Epoch 1034/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.1573e-04 - mae: 0.0018 - val_loss: 3.2968e-04 - val_mae: 0.0028\n",
      "Epoch 1035/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.1592e-04 - mae: 0.0019 - val_loss: 3.1312e-04 - val_mae: 0.0014\n",
      "Epoch 1036/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.1311e-04 - mae: 0.0015 - val_loss: 3.2017e-04 - val_mae: 0.0024\n",
      "Epoch 1037/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.1193e-04 - mae: 0.0014 - val_loss: 3.1428e-04 - val_mae: 0.0021\n",
      "Epoch 1038/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.1215e-04 - mae: 0.0016 - val_loss: 3.1537e-04 - val_mae: 0.0021\n",
      "Epoch 1039/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.1158e-04 - mae: 0.0016 - val_loss: 3.3334e-04 - val_mae: 0.0039\n",
      "Epoch 1040/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.1431e-04 - mae: 0.0021 - val_loss: 3.1175e-04 - val_mae: 0.0019\n",
      "Epoch 1041/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.0923e-04 - mae: 0.0014 - val_loss: 3.0912e-04 - val_mae: 0.0013\n",
      "Epoch 1042/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.0982e-04 - mae: 0.0016 - val_loss: 3.1560e-04 - val_mae: 0.0028\n",
      "Epoch 1043/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.0847e-04 - mae: 0.0015 - val_loss: 3.1108e-04 - val_mae: 0.0022\n",
      "Epoch 1044/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.1070e-04 - mae: 0.0020 - val_loss: 3.0963e-04 - val_mae: 0.0017\n",
      "Epoch 1045/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.0801e-04 - mae: 0.0016 - val_loss: 3.1432e-04 - val_mae: 0.0027\n",
      "Epoch 1046/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.0763e-04 - mae: 0.0016 - val_loss: 3.0711e-04 - val_mae: 0.0017\n",
      "Epoch 1047/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.0595e-04 - mae: 0.0014 - val_loss: 3.0520e-04 - val_mae: 0.0012\n",
      "Epoch 1048/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.0726e-04 - mae: 0.0018 - val_loss: 3.2710e-04 - val_mae: 0.0043\n",
      "Epoch 1049/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.0569e-04 - mae: 0.0015 - val_loss: 3.0517e-04 - val_mae: 0.0015\n",
      "Epoch 1050/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.0545e-04 - mae: 0.0017 - val_loss: 3.0606e-04 - val_mae: 0.0019\n",
      "Epoch 1051/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.0500e-04 - mae: 0.0017 - val_loss: 3.0434e-04 - val_mae: 0.0016\n",
      "Epoch 1052/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.0391e-04 - mae: 0.0016 - val_loss: 3.0516e-04 - val_mae: 0.0019\n",
      "Epoch 1053/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.0269e-04 - mae: 0.0014 - val_loss: 3.0585e-04 - val_mae: 0.0020\n",
      "Epoch 1054/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.0297e-04 - mae: 0.0016 - val_loss: 3.1707e-04 - val_mae: 0.0030\n",
      "Epoch 1055/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.0214e-04 - mae: 0.0016 - val_loss: 3.0071e-04 - val_mae: 0.0012\n",
      "Epoch 1056/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.0176e-04 - mae: 0.0016 - val_loss: 2.9984e-04 - val_mae: 0.0011\n",
      "Epoch 1057/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.0097e-04 - mae: 0.0016 - val_loss: 2.9946e-04 - val_mae: 0.0012\n",
      "Epoch 1058/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.0166e-04 - mae: 0.0018 - val_loss: 2.9925e-04 - val_mae: 0.0013\n",
      "Epoch 1059/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.9998e-04 - mae: 0.0016 - val_loss: 3.0602e-04 - val_mae: 0.0027\n",
      "Epoch 1060/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 3.0021e-04 - mae: 0.0017 - val_loss: 2.9808e-04 - val_mae: 0.0013\n",
      "Epoch 1061/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.9811e-04 - mae: 0.0014 - val_loss: 2.9787e-04 - val_mae: 0.0013\n",
      "Epoch 1062/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.9753e-04 - mae: 0.0014 - val_loss: 3.0559e-04 - val_mae: 0.0026\n",
      "Epoch 1063/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.9741e-04 - mae: 0.0015 - val_loss: 2.9734e-04 - val_mae: 0.0015\n",
      "Epoch 1064/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.9598e-04 - mae: 0.0014 - val_loss: 3.0371e-04 - val_mae: 0.0030\n",
      "Epoch 1065/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.9829e-04 - mae: 0.0019 - val_loss: 2.9535e-04 - val_mae: 0.0012\n",
      "Epoch 1066/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.9647e-04 - mae: 0.0017 - val_loss: 2.9821e-04 - val_mae: 0.0019\n",
      "Epoch 1067/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.9613e-04 - mae: 0.0017 - val_loss: 3.0198e-04 - val_mae: 0.0024\n",
      "Epoch 1068/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.9531e-04 - mae: 0.0016 - val_loss: 2.9506e-04 - val_mae: 0.0016\n",
      "Epoch 1069/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.9563e-04 - mae: 0.0018 - val_loss: 2.9333e-04 - val_mae: 0.0013\n",
      "Epoch 1070/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.9301e-04 - mae: 0.0014 - val_loss: 3.0903e-04 - val_mae: 0.0031\n",
      "Epoch 1071/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.9504e-04 - mae: 0.0019 - val_loss: 2.9139e-04 - val_mae: 0.0010\n",
      "Epoch 1072/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.9300e-04 - mae: 0.0016 - val_loss: 2.9382e-04 - val_mae: 0.0018\n",
      "Epoch 1073/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.9210e-04 - mae: 0.0015 - val_loss: 2.9449e-04 - val_mae: 0.0019\n",
      "Epoch 1074/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.9205e-04 - mae: 0.0016 - val_loss: 3.1442e-04 - val_mae: 0.0048\n",
      "Epoch 1075/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.9133e-04 - mae: 0.0016 - val_loss: 2.9833e-04 - val_mae: 0.0027\n",
      "Epoch 1076/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.9064e-04 - mae: 0.0015 - val_loss: 2.8901e-04 - val_mae: 0.0011\n",
      "Epoch 1077/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.9098e-04 - mae: 0.0016 - val_loss: 3.0015e-04 - val_mae: 0.0028\n",
      "Epoch 1078/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.9081e-04 - mae: 0.0018 - val_loss: 2.8976e-04 - val_mae: 0.0015\n",
      "Epoch 1079/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.8833e-04 - mae: 0.0014 - val_loss: 2.9391e-04 - val_mae: 0.0023\n",
      "Epoch 1080/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.8882e-04 - mae: 0.0016 - val_loss: 2.9481e-04 - val_mae: 0.0026\n",
      "Epoch 1081/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.8828e-04 - mae: 0.0016 - val_loss: 3.1473e-04 - val_mae: 0.0041\n",
      "Epoch 1082/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.8748e-04 - mae: 0.0015 - val_loss: 2.8922e-04 - val_mae: 0.0015\n",
      "Epoch 1083/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.8692e-04 - mae: 0.0015 - val_loss: 2.8977e-04 - val_mae: 0.0020\n",
      "Epoch 1084/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.8699e-04 - mae: 0.0016 - val_loss: 2.8841e-04 - val_mae: 0.0019\n",
      "Epoch 1085/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.8595e-04 - mae: 0.0015 - val_loss: 2.8677e-04 - val_mae: 0.0018\n",
      "Epoch 1086/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.8602e-04 - mae: 0.0016 - val_loss: 2.8720e-04 - val_mae: 0.0018\n",
      "Epoch 1087/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.8504e-04 - mae: 0.0015 - val_loss: 2.8433e-04 - val_mae: 0.0015\n",
      "Epoch 1088/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.8582e-04 - mae: 0.0018 - val_loss: 3.0367e-04 - val_mae: 0.0038\n",
      "Epoch 1089/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.8526e-04 - mae: 0.0017 - val_loss: 2.9029e-04 - val_mae: 0.0028\n",
      "Epoch 1090/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.8447e-04 - mae: 0.0017 - val_loss: 3.5105e-04 - val_mae: 0.0064\n",
      "Epoch 1091/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.8540e-04 - mae: 0.0017 - val_loss: 2.9764e-04 - val_mae: 0.0036\n",
      "Epoch 1092/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.8260e-04 - mae: 0.0015 - val_loss: 2.8092e-04 - val_mae: 9.9928e-04\n",
      "Epoch 1093/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.8201e-04 - mae: 0.0015 - val_loss: 3.0273e-04 - val_mae: 0.0039\n",
      "Epoch 1094/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.8165e-04 - mae: 0.0015 - val_loss: 2.8167e-04 - val_mae: 0.0015\n",
      "Epoch 1095/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.8280e-04 - mae: 0.0018 - val_loss: 2.8074e-04 - val_mae: 0.0014\n",
      "Epoch 1096/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.8004e-04 - mae: 0.0014 - val_loss: 2.8167e-04 - val_mae: 0.0018\n",
      "Epoch 1097/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.8132e-04 - mae: 0.0017 - val_loss: 2.8993e-04 - val_mae: 0.0033\n",
      "Epoch 1098/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.8069e-04 - mae: 0.0017 - val_loss: 2.7828e-04 - val_mae: 0.0011\n",
      "Epoch 1099/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.8000e-04 - mae: 0.0016 - val_loss: 2.7786e-04 - val_mae: 0.0011\n",
      "Epoch 1100/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.7940e-04 - mae: 0.0016 - val_loss: 2.7925e-04 - val_mae: 0.0017\n",
      "Epoch 1101/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.7977e-04 - mae: 0.0017 - val_loss: 2.7830e-04 - val_mae: 0.0015\n",
      "Epoch 1102/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.7794e-04 - mae: 0.0015 - val_loss: 2.7746e-04 - val_mae: 0.0013\n",
      "Epoch 1103/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.7833e-04 - mae: 0.0017 - val_loss: 2.7650e-04 - val_mae: 0.0012\n",
      "Epoch 1104/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.7739e-04 - mae: 0.0016 - val_loss: 2.7723e-04 - val_mae: 0.0015\n",
      "Epoch 1105/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.7644e-04 - mae: 0.0014 - val_loss: 2.7572e-04 - val_mae: 0.0013\n",
      "Epoch 1106/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.7591e-04 - mae: 0.0015 - val_loss: 2.7766e-04 - val_mae: 0.0018\n",
      "Epoch 1107/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.7654e-04 - mae: 0.0017 - val_loss: 2.7933e-04 - val_mae: 0.0021\n",
      "Epoch 1108/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.7664e-04 - mae: 0.0017 - val_loss: 2.8475e-04 - val_mae: 0.0032\n",
      "Epoch 1109/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.7563e-04 - mae: 0.0017 - val_loss: 2.7336e-04 - val_mae: 0.0011\n",
      "Epoch 1110/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.7377e-04 - mae: 0.0014 - val_loss: 2.7575e-04 - val_mae: 0.0017\n",
      "Epoch 1111/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.7577e-04 - mae: 0.0018 - val_loss: 2.7491e-04 - val_mae: 0.0017\n",
      "Epoch 1112/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.7633e-04 - mae: 0.0020 - val_loss: 2.7254e-04 - val_mae: 0.0013\n",
      "Epoch 1113/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.7387e-04 - mae: 0.0016 - val_loss: 2.7235e-04 - val_mae: 0.0012\n",
      "Epoch 1114/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.7232e-04 - mae: 0.0014 - val_loss: 2.7108e-04 - val_mae: 9.9538e-04\n",
      "Epoch 1115/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.7210e-04 - mae: 0.0015 - val_loss: 2.7712e-04 - val_mae: 0.0023\n",
      "Epoch 1116/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.7308e-04 - mae: 0.0017 - val_loss: 2.7841e-04 - val_mae: 0.0025\n",
      "Epoch 1117/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.7152e-04 - mae: 0.0015 - val_loss: 2.7110e-04 - val_mae: 0.0013\n",
      "Epoch 1118/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.7032e-04 - mae: 0.0013 - val_loss: 2.7384e-04 - val_mae: 0.0020\n",
      "Epoch 1119/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.7146e-04 - mae: 0.0017 - val_loss: 2.7118e-04 - val_mae: 0.0016\n",
      "Epoch 1120/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.7026e-04 - mae: 0.0015 - val_loss: 2.7993e-04 - val_mae: 0.0032\n",
      "Epoch 1121/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.7044e-04 - mae: 0.0017 - val_loss: 2.7446e-04 - val_mae: 0.0025\n",
      "Epoch 1122/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.6936e-04 - mae: 0.0015 - val_loss: 2.6868e-04 - val_mae: 0.0013\n",
      "Epoch 1123/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.6873e-04 - mae: 0.0015 - val_loss: 2.6887e-04 - val_mae: 0.0014\n",
      "Epoch 1124/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.6918e-04 - mae: 0.0016 - val_loss: 2.7172e-04 - val_mae: 0.0021\n",
      "Epoch 1125/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.6873e-04 - mae: 0.0016 - val_loss: 2.7020e-04 - val_mae: 0.0020\n",
      "Epoch 1126/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.6927e-04 - mae: 0.0018 - val_loss: 2.7061e-04 - val_mae: 0.0021\n",
      "Epoch 1127/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.6776e-04 - mae: 0.0016 - val_loss: 2.6726e-04 - val_mae: 0.0015\n",
      "Epoch 1128/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.6766e-04 - mae: 0.0016 - val_loss: 2.6667e-04 - val_mae: 0.0014\n",
      "Epoch 1129/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.6646e-04 - mae: 0.0015 - val_loss: 2.6506e-04 - val_mae: 0.0010\n",
      "Epoch 1130/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.6534e-04 - mae: 0.0014 - val_loss: 2.6523e-04 - val_mae: 0.0012\n",
      "Epoch 1131/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.6637e-04 - mae: 0.0016 - val_loss: 2.6526e-04 - val_mae: 0.0013\n",
      "Epoch 1132/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.6515e-04 - mae: 0.0015 - val_loss: 2.6902e-04 - val_mae: 0.0022\n",
      "Epoch 1133/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.6504e-04 - mae: 0.0015 - val_loss: 2.6441e-04 - val_mae: 0.0013\n",
      "Epoch 1134/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.6455e-04 - mae: 0.0015 - val_loss: 2.6810e-04 - val_mae: 0.0020\n",
      "Epoch 1135/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.6475e-04 - mae: 0.0016 - val_loss: 2.6871e-04 - val_mae: 0.0024\n",
      "Epoch 1136/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.6635e-04 - mae: 0.0020 - val_loss: 2.6320e-04 - val_mae: 0.0014\n",
      "Epoch 1137/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.6408e-04 - mae: 0.0017 - val_loss: 2.6894e-04 - val_mae: 0.0027\n",
      "Epoch 1138/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.6298e-04 - mae: 0.0015 - val_loss: 2.6526e-04 - val_mae: 0.0019\n",
      "Epoch 1139/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.6291e-04 - mae: 0.0016 - val_loss: 2.6370e-04 - val_mae: 0.0017\n",
      "Epoch 1140/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.6343e-04 - mae: 0.0017 - val_loss: 2.6637e-04 - val_mae: 0.0025\n",
      "Epoch 1141/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.6258e-04 - mae: 0.0016 - val_loss: 3.0853e-04 - val_mae: 0.0051\n",
      "Epoch 1142/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.6262e-04 - mae: 0.0017 - val_loss: 2.9411e-04 - val_mae: 0.0047\n",
      "Epoch 1143/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.6414e-04 - mae: 0.0019 - val_loss: 2.5980e-04 - val_mae: 0.0011\n",
      "Epoch 1144/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.6039e-04 - mae: 0.0014 - val_loss: 2.7491e-04 - val_mae: 0.0032\n",
      "Epoch 1145/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.6043e-04 - mae: 0.0015 - val_loss: 2.6251e-04 - val_mae: 0.0019\n",
      "Epoch 1146/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.6087e-04 - mae: 0.0017 - val_loss: 2.7253e-04 - val_mae: 0.0033\n",
      "Epoch 1147/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.6112e-04 - mae: 0.0017 - val_loss: 2.6178e-04 - val_mae: 0.0019\n",
      "Epoch 1148/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.6168e-04 - mae: 0.0019 - val_loss: 2.5957e-04 - val_mae: 0.0015\n",
      "Epoch 1149/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.6021e-04 - mae: 0.0017 - val_loss: 2.6244e-04 - val_mae: 0.0024\n",
      "Epoch 1150/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.5919e-04 - mae: 0.0016 - val_loss: 2.5943e-04 - val_mae: 0.0017\n",
      "Epoch 1151/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.5811e-04 - mae: 0.0015 - val_loss: 2.5922e-04 - val_mae: 0.0018\n",
      "Epoch 1152/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.5883e-04 - mae: 0.0017 - val_loss: 2.5897e-04 - val_mae: 0.0018\n",
      "Epoch 1153/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.5787e-04 - mae: 0.0015 - val_loss: 2.5682e-04 - val_mae: 0.0012\n",
      "Epoch 1154/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.5783e-04 - mae: 0.0016 - val_loss: 2.6737e-04 - val_mae: 0.0030\n",
      "Epoch 1155/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.5775e-04 - mae: 0.0016 - val_loss: 2.5690e-04 - val_mae: 0.0015\n",
      "Epoch 1156/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.5666e-04 - mae: 0.0015 - val_loss: 2.5659e-04 - val_mae: 0.0016\n",
      "Epoch 1157/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.5714e-04 - mae: 0.0017 - val_loss: 2.5679e-04 - val_mae: 0.0016\n",
      "Epoch 1158/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.5627e-04 - mae: 0.0015 - val_loss: 2.5735e-04 - val_mae: 0.0019\n",
      "Epoch 1159/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.5693e-04 - mae: 0.0018 - val_loss: 2.5781e-04 - val_mae: 0.0018\n",
      "Epoch 1160/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.5575e-04 - mae: 0.0016 - val_loss: 2.5909e-04 - val_mae: 0.0022\n",
      "Epoch 1161/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.5501e-04 - mae: 0.0015 - val_loss: 2.6029e-04 - val_mae: 0.0026\n",
      "Epoch 1162/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.5524e-04 - mae: 0.0016 - val_loss: 2.5303e-04 - val_mae: 0.0010\n",
      "Epoch 1163/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.5379e-04 - mae: 0.0014 - val_loss: 2.5681e-04 - val_mae: 0.0021\n",
      "Epoch 1164/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.5378e-04 - mae: 0.0014 - val_loss: 2.5649e-04 - val_mae: 0.0022\n",
      "Epoch 1165/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.5359e-04 - mae: 0.0015 - val_loss: 2.5272e-04 - val_mae: 0.0012\n",
      "Epoch 1166/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.5423e-04 - mae: 0.0017 - val_loss: 2.5339e-04 - val_mae: 0.0014\n",
      "Epoch 1167/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.5389e-04 - mae: 0.0017 - val_loss: 2.6034e-04 - val_mae: 0.0025\n",
      "Epoch 1168/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.5349e-04 - mae: 0.0017 - val_loss: 2.5188e-04 - val_mae: 0.0012\n",
      "Epoch 1169/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.5183e-04 - mae: 0.0015 - val_loss: 2.5441e-04 - val_mae: 0.0020\n",
      "Epoch 1170/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.5207e-04 - mae: 0.0016 - val_loss: 2.5102e-04 - val_mae: 0.0014\n",
      "Epoch 1171/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.5209e-04 - mae: 0.0016 - val_loss: 2.5243e-04 - val_mae: 0.0018\n",
      "Epoch 1172/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.5036e-04 - mae: 0.0014 - val_loss: 2.5236e-04 - val_mae: 0.0018\n",
      "Epoch 1173/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.5131e-04 - mae: 0.0016 - val_loss: 2.5110e-04 - val_mae: 0.0015\n",
      "Epoch 1174/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.5204e-04 - mae: 0.0018 - val_loss: 2.7731e-04 - val_mae: 0.0043\n",
      "Epoch 1175/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.5248e-04 - mae: 0.0019 - val_loss: 2.4914e-04 - val_mae: 0.0013\n",
      "Epoch 1176/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4922e-04 - mae: 0.0014 - val_loss: 2.6759e-04 - val_mae: 0.0036\n",
      "Epoch 1177/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.5098e-04 - mae: 0.0018 - val_loss: 2.5168e-04 - val_mae: 0.0020\n",
      "Epoch 1178/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4855e-04 - mae: 0.0014 - val_loss: 2.4900e-04 - val_mae: 0.0014\n",
      "Epoch 1179/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4904e-04 - mae: 0.0015 - val_loss: 2.5622e-04 - val_mae: 0.0027\n",
      "Epoch 1180/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.5055e-04 - mae: 0.0019 - val_loss: 2.4789e-04 - val_mae: 0.0013\n",
      "Epoch 1181/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4791e-04 - mae: 0.0014 - val_loss: 2.5092e-04 - val_mae: 0.0019\n",
      "Epoch 1182/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4815e-04 - mae: 0.0016 - val_loss: 2.4773e-04 - val_mae: 0.0015\n",
      "Epoch 1183/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4865e-04 - mae: 0.0017 - val_loss: 2.4858e-04 - val_mae: 0.0017\n",
      "Epoch 1184/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4761e-04 - mae: 0.0016 - val_loss: 2.6550e-04 - val_mae: 0.0039\n",
      "Epoch 1185/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4875e-04 - mae: 0.0018 - val_loss: 2.5559e-04 - val_mae: 0.0031\n",
      "Epoch 1186/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4715e-04 - mae: 0.0016 - val_loss: 2.5285e-04 - val_mae: 0.0026\n",
      "Epoch 1187/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4687e-04 - mae: 0.0016 - val_loss: 2.4635e-04 - val_mae: 0.0015\n",
      "Epoch 1188/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4603e-04 - mae: 0.0015 - val_loss: 2.4478e-04 - val_mae: 0.0011\n",
      "Epoch 1189/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4656e-04 - mae: 0.0017 - val_loss: 2.4584e-04 - val_mae: 0.0015\n",
      "Epoch 1190/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4595e-04 - mae: 0.0016 - val_loss: 2.4627e-04 - val_mae: 0.0016\n",
      "Epoch 1191/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4503e-04 - mae: 0.0015 - val_loss: 2.4519e-04 - val_mae: 0.0016\n",
      "Epoch 1192/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4501e-04 - mae: 0.0015 - val_loss: 2.4499e-04 - val_mae: 0.0016\n",
      "Epoch 1193/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4436e-04 - mae: 0.0015 - val_loss: 2.5099e-04 - val_mae: 0.0023\n",
      "Epoch 1194/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4482e-04 - mae: 0.0016 - val_loss: 2.5214e-04 - val_mae: 0.0030\n",
      "Epoch 1195/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4334e-04 - mae: 0.0014 - val_loss: 2.4588e-04 - val_mae: 0.0020\n",
      "Epoch 1196/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4355e-04 - mae: 0.0015 - val_loss: 2.4495e-04 - val_mae: 0.0018\n",
      "Epoch 1197/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4600e-04 - mae: 0.0020 - val_loss: 2.4549e-04 - val_mae: 0.0019\n",
      "Epoch 1198/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4348e-04 - mae: 0.0016 - val_loss: 2.4545e-04 - val_mae: 0.0020\n",
      "Epoch 1199/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4603e-04 - mae: 0.0020 - val_loss: 2.4255e-04 - val_mae: 0.0014\n",
      "Epoch 1200/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4261e-04 - mae: 0.0016 - val_loss: 2.4174e-04 - val_mae: 0.0012\n",
      "Epoch 1201/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4309e-04 - mae: 0.0016 - val_loss: 2.4443e-04 - val_mae: 0.0019\n",
      "Epoch 1202/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4113e-04 - mae: 0.0014 - val_loss: 2.4154e-04 - val_mae: 0.0014\n",
      "Epoch 1203/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4206e-04 - mae: 0.0016 - val_loss: 2.4405e-04 - val_mae: 0.0018\n",
      "Epoch 1204/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4267e-04 - mae: 0.0018 - val_loss: 2.4266e-04 - val_mae: 0.0017\n",
      "Epoch 1205/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4055e-04 - mae: 0.0014 - val_loss: 2.5140e-04 - val_mae: 0.0030\n",
      "Epoch 1206/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4088e-04 - mae: 0.0015 - val_loss: 2.4041e-04 - val_mae: 0.0013\n",
      "Epoch 1207/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4244e-04 - mae: 0.0018 - val_loss: 2.4239e-04 - val_mae: 0.0017\n",
      "Epoch 1208/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3973e-04 - mae: 0.0014 - val_loss: 2.4315e-04 - val_mae: 0.0023\n",
      "Epoch 1209/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3971e-04 - mae: 0.0014 - val_loss: 2.3845e-04 - val_mae: 0.0011\n",
      "Epoch 1210/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4127e-04 - mae: 0.0018 - val_loss: 2.5713e-04 - val_mae: 0.0036\n",
      "Epoch 1211/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4168e-04 - mae: 0.0019 - val_loss: 2.3846e-04 - val_mae: 0.0012\n",
      "Epoch 1212/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3879e-04 - mae: 0.0015 - val_loss: 3.0747e-04 - val_mae: 0.0062\n",
      "Epoch 1213/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.4119e-04 - mae: 0.0019 - val_loss: 2.3999e-04 - val_mae: 0.0016\n",
      "Epoch 1214/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3854e-04 - mae: 0.0015 - val_loss: 2.3963e-04 - val_mae: 0.0017\n",
      "Epoch 1215/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3908e-04 - mae: 0.0017 - val_loss: 2.3758e-04 - val_mae: 0.0013\n",
      "Epoch 1216/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3785e-04 - mae: 0.0015 - val_loss: 2.3832e-04 - val_mae: 0.0016\n",
      "Epoch 1217/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3737e-04 - mae: 0.0014 - val_loss: 2.3863e-04 - val_mae: 0.0017\n",
      "Epoch 1218/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3780e-04 - mae: 0.0016 - val_loss: 2.3631e-04 - val_mae: 0.0011\n",
      "Epoch 1219/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3952e-04 - mae: 0.0020 - val_loss: 2.3778e-04 - val_mae: 0.0017\n",
      "Epoch 1220/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3740e-04 - mae: 0.0016 - val_loss: 2.4047e-04 - val_mae: 0.0023\n",
      "Epoch 1221/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3710e-04 - mae: 0.0016 - val_loss: 2.3731e-04 - val_mae: 0.0016\n",
      "Epoch 1222/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3554e-04 - mae: 0.0013 - val_loss: 2.3724e-04 - val_mae: 0.0018\n",
      "Epoch 1223/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3606e-04 - mae: 0.0015 - val_loss: 2.3512e-04 - val_mae: 0.0012\n",
      "Epoch 1224/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3613e-04 - mae: 0.0016 - val_loss: 2.3576e-04 - val_mae: 0.0015\n",
      "Epoch 1225/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3585e-04 - mae: 0.0016 - val_loss: 2.5881e-04 - val_mae: 0.0044\n",
      "Epoch 1226/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3636e-04 - mae: 0.0017 - val_loss: 2.3560e-04 - val_mae: 0.0015\n",
      "Epoch 1227/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3524e-04 - mae: 0.0016 - val_loss: 2.3501e-04 - val_mae: 0.0015\n",
      "Epoch 1228/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3506e-04 - mae: 0.0015 - val_loss: 2.3612e-04 - val_mae: 0.0018\n",
      "Epoch 1229/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3469e-04 - mae: 0.0015 - val_loss: 2.3473e-04 - val_mae: 0.0015\n",
      "Epoch 1230/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3498e-04 - mae: 0.0016 - val_loss: 2.4354e-04 - val_mae: 0.0032\n",
      "Epoch 1231/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3532e-04 - mae: 0.0018 - val_loss: 2.4678e-04 - val_mae: 0.0037\n",
      "Epoch 1232/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3667e-04 - mae: 0.0020 - val_loss: 2.3303e-04 - val_mae: 0.0013\n",
      "Epoch 1233/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3323e-04 - mae: 0.0015 - val_loss: 2.3378e-04 - val_mae: 0.0016\n",
      "Epoch 1234/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3288e-04 - mae: 0.0014 - val_loss: 2.3535e-04 - val_mae: 0.0019\n",
      "Epoch 1235/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3310e-04 - mae: 0.0016 - val_loss: 2.3346e-04 - val_mae: 0.0016\n",
      "Epoch 1236/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3211e-04 - mae: 0.0014 - val_loss: 2.6186e-04 - val_mae: 0.0050\n",
      "Epoch 1237/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3445e-04 - mae: 0.0018 - val_loss: 2.4087e-04 - val_mae: 0.0028\n",
      "Epoch 1238/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3354e-04 - mae: 0.0017 - val_loss: 2.3198e-04 - val_mae: 0.0014\n",
      "Epoch 1239/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3154e-04 - mae: 0.0014 - val_loss: 2.3845e-04 - val_mae: 0.0029\n",
      "Epoch 1240/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3252e-04 - mae: 0.0017 - val_loss: 2.3193e-04 - val_mae: 0.0016\n",
      "Epoch 1241/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3134e-04 - mae: 0.0015 - val_loss: 2.3541e-04 - val_mae: 0.0022\n",
      "Epoch 1242/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3080e-04 - mae: 0.0014 - val_loss: 2.3271e-04 - val_mae: 0.0018\n",
      "Epoch 1243/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3336e-04 - mae: 0.0020 - val_loss: 2.3124e-04 - val_mae: 0.0015\n",
      "Epoch 1244/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3220e-04 - mae: 0.0018 - val_loss: 2.2963e-04 - val_mae: 0.0012\n",
      "Epoch 1245/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3123e-04 - mae: 0.0017 - val_loss: 2.3051e-04 - val_mae: 0.0015\n",
      "Epoch 1246/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3075e-04 - mae: 0.0016 - val_loss: 2.3362e-04 - val_mae: 0.0020\n",
      "Epoch 1247/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3201e-04 - mae: 0.0019 - val_loss: 2.3391e-04 - val_mae: 0.0022\n",
      "Epoch 1248/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3124e-04 - mae: 0.0018 - val_loss: 2.9753e-04 - val_mae: 0.0069\n",
      "Epoch 1249/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3459e-04 - mae: 0.0022 - val_loss: 2.2951e-04 - val_mae: 0.0015\n",
      "Epoch 1250/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2914e-04 - mae: 0.0015 - val_loss: 2.2902e-04 - val_mae: 0.0014\n",
      "Epoch 1251/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2824e-04 - mae: 0.0013 - val_loss: 2.3043e-04 - val_mae: 0.0019\n",
      "Epoch 1252/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2886e-04 - mae: 0.0015 - val_loss: 2.3007e-04 - val_mae: 0.0017\n",
      "Epoch 1253/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2914e-04 - mae: 0.0016 - val_loss: 2.3018e-04 - val_mae: 0.0019\n",
      "Epoch 1254/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2973e-04 - mae: 0.0017 - val_loss: 2.3128e-04 - val_mae: 0.0021\n",
      "Epoch 1255/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2807e-04 - mae: 0.0015 - val_loss: 2.2769e-04 - val_mae: 0.0014\n",
      "Epoch 1256/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2786e-04 - mae: 0.0015 - val_loss: 2.3033e-04 - val_mae: 0.0019\n",
      "Epoch 1257/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2760e-04 - mae: 0.0015 - val_loss: 2.2843e-04 - val_mae: 0.0017\n",
      "Epoch 1258/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2725e-04 - mae: 0.0014 - val_loss: 2.4369e-04 - val_mae: 0.0036\n",
      "Epoch 1259/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2838e-04 - mae: 0.0017 - val_loss: 2.3613e-04 - val_mae: 0.0027\n",
      "Epoch 1260/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2784e-04 - mae: 0.0017 - val_loss: 2.2797e-04 - val_mae: 0.0016\n",
      "Epoch 1261/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2817e-04 - mae: 0.0018 - val_loss: 2.2770e-04 - val_mae: 0.0016\n",
      "Epoch 1262/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.3007e-04 - mae: 0.0021 - val_loss: 2.2957e-04 - val_mae: 0.0022\n",
      "Epoch 1263/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2624e-04 - mae: 0.0015 - val_loss: 2.2558e-04 - val_mae: 0.0013\n",
      "Epoch 1264/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2515e-04 - mae: 0.0013 - val_loss: 2.2634e-04 - val_mae: 0.0016\n",
      "Epoch 1265/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2618e-04 - mae: 0.0016 - val_loss: 2.2521e-04 - val_mae: 0.0014\n",
      "Epoch 1266/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2757e-04 - mae: 0.0019 - val_loss: 2.3464e-04 - val_mae: 0.0030\n",
      "Epoch 1267/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2586e-04 - mae: 0.0016 - val_loss: 2.3008e-04 - val_mae: 0.0025\n",
      "Epoch 1268/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2536e-04 - mae: 0.0015 - val_loss: 2.2415e-04 - val_mae: 0.0012\n",
      "Epoch 1269/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2474e-04 - mae: 0.0015 - val_loss: 2.2387e-04 - val_mae: 0.0012\n",
      "Epoch 1270/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2468e-04 - mae: 0.0015 - val_loss: 2.2600e-04 - val_mae: 0.0017\n",
      "Epoch 1271/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2453e-04 - mae: 0.0015 - val_loss: 2.2817e-04 - val_mae: 0.0024\n",
      "Epoch 1272/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2532e-04 - mae: 0.0017 - val_loss: 2.4922e-04 - val_mae: 0.0041\n",
      "Epoch 1273/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2639e-04 - mae: 0.0019 - val_loss: 2.2932e-04 - val_mae: 0.0020\n",
      "Epoch 1274/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2375e-04 - mae: 0.0015 - val_loss: 2.3247e-04 - val_mae: 0.0028\n",
      "Epoch 1275/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2431e-04 - mae: 0.0017 - val_loss: 2.2799e-04 - val_mae: 0.0023\n",
      "Epoch 1276/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2297e-04 - mae: 0.0014 - val_loss: 2.2256e-04 - val_mae: 0.0013\n",
      "Epoch 1277/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2547e-04 - mae: 0.0019 - val_loss: 2.2527e-04 - val_mae: 0.0018\n",
      "Epoch 1278/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2355e-04 - mae: 0.0016 - val_loss: 2.2231e-04 - val_mae: 0.0012\n",
      "Epoch 1279/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2348e-04 - mae: 0.0017 - val_loss: 2.3324e-04 - val_mae: 0.0034\n",
      "Epoch 1280/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2383e-04 - mae: 0.0017 - val_loss: 2.2324e-04 - val_mae: 0.0017\n",
      "Epoch 1281/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2256e-04 - mae: 0.0015 - val_loss: 2.2279e-04 - val_mae: 0.0015\n",
      "Epoch 1282/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2253e-04 - mae: 0.0016 - val_loss: 2.2389e-04 - val_mae: 0.0020\n",
      "Epoch 1283/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2134e-04 - mae: 0.0014 - val_loss: 2.2765e-04 - val_mae: 0.0027\n",
      "Epoch 1284/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2217e-04 - mae: 0.0016 - val_loss: 2.2261e-04 - val_mae: 0.0017\n",
      "Epoch 1285/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2347e-04 - mae: 0.0018 - val_loss: 2.2026e-04 - val_mae: 0.0011\n",
      "Epoch 1286/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2166e-04 - mae: 0.0016 - val_loss: 2.2072e-04 - val_mae: 0.0013\n",
      "Epoch 1287/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2130e-04 - mae: 0.0016 - val_loss: 2.2080e-04 - val_mae: 0.0014\n",
      "Epoch 1288/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2141e-04 - mae: 0.0016 - val_loss: 2.2756e-04 - val_mae: 0.0028\n",
      "Epoch 1289/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2090e-04 - mae: 0.0015 - val_loss: 2.2056e-04 - val_mae: 0.0013\n",
      "Epoch 1290/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2080e-04 - mae: 0.0016 - val_loss: 2.2001e-04 - val_mae: 0.0014\n",
      "Epoch 1291/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2039e-04 - mae: 0.0015 - val_loss: 2.3028e-04 - val_mae: 0.0030\n",
      "Epoch 1292/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2105e-04 - mae: 0.0016 - val_loss: 2.2100e-04 - val_mae: 0.0016\n",
      "Epoch 1293/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2004e-04 - mae: 0.0016 - val_loss: 2.2443e-04 - val_mae: 0.0023\n",
      "Epoch 1294/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2113e-04 - mae: 0.0017 - val_loss: 2.3308e-04 - val_mae: 0.0033\n",
      "Epoch 1295/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.1946e-04 - mae: 0.0015 - val_loss: 2.1863e-04 - val_mae: 0.0012\n",
      "Epoch 1296/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.1865e-04 - mae: 0.0014 - val_loss: 2.1943e-04 - val_mae: 0.0016\n",
      "Epoch 1297/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.2219e-04 - mae: 0.0020 - val_loss: 2.2121e-04 - val_mae: 0.0020\n",
      "Epoch 1298/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.1969e-04 - mae: 0.0017 - val_loss: 2.1905e-04 - val_mae: 0.0016\n",
      "Epoch 1299/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.1879e-04 - mae: 0.0016 - val_loss: 2.2651e-04 - val_mae: 0.0027\n",
      "Epoch 1300/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.1901e-04 - mae: 0.0016 - val_loss: 2.1785e-04 - val_mae: 0.0014\n",
      "Epoch 1301/2000\n",
      "121/163 [=====================>........] - ETA: 0s - loss: 2.1934e-04 - mae: 0.0017Restoring model weights from the end of the best epoch: 1296.\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 2.1908e-04 - mae: 0.0017 - val_loss: 2.1952e-04 - val_mae: 0.0018\n",
      "Epoch 1301: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Netzwerkarchitektur\n",
    "model = Sequential([\n",
    "\n",
    "    Dense(216, activation='relu', input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(104, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(104, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(152, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(8, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(56, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(152, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(56, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(1 , activation = 'linear')\n",
    "])\n",
    "\n",
    "# Optimierer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "# Modell kompilieren (Verwendung von mean_squared_error als Verlustfunktion für Regression)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])  # Metriken für Regression: Mean Absolute Error und Mean Squared Error\n",
    "\n",
    "# Early Stopping Callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "# Trainingsparameter\n",
    "batch_size = 100\n",
    "epochs = 2000\n",
    "\n",
    "# Modell trainieren (Annahme: X_train, y_train, X_val, y_val sind vordefiniert)\n",
    "history = model.fit(X_train_scaled, y_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T14:42:03.011973900Z",
     "start_time": "2024-03-19T14:34:05.768731700Z"
    }
   },
   "id": "8b52e1a9a6ff3aeb"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "Training für Fold 1...\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "163/163 [==============================] - 3s 5ms/step - loss: 0.2044 - mae: 0.1635 - val_loss: 0.1150 - val_mae: 0.0219\n",
      "Epoch 2/1000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1081 - mae: 0.0315 - val_loss: 0.1020 - val_mae: 0.0416\n",
      "Epoch 3/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0946 - mae: 0.0172 - val_loss: 0.0918 - val_mae: 0.0373\n",
      "Epoch 4/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0876 - mae: 0.0292 - val_loss: 0.0823 - val_mae: 0.0113\n",
      "Epoch 5/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0791 - mae: 0.0082 - val_loss: 0.0761 - val_mae: 0.0106\n",
      "Epoch 6/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0734 - mae: 0.0077 - val_loss: 0.0709 - val_mae: 0.0135\n",
      "Epoch 7/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0684 - mae: 0.0082 - val_loss: 0.0664 - val_mae: 0.0149\n",
      "Epoch 8/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0643 - mae: 0.0129 - val_loss: 0.0622 - val_mae: 0.0152\n",
      "Epoch 9/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0616 - mae: 0.0195 - val_loss: 0.0626 - val_mae: 0.0579\n",
      "Epoch 10/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0573 - mae: 0.0159 - val_loss: 0.0550 - val_mae: 0.0074\n",
      "Epoch 11/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0535 - mae: 0.0062 - val_loss: 0.0523 - val_mae: 0.0153\n",
      "Epoch 12/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0505 - mae: 0.0065 - val_loss: 0.0491 - val_mae: 0.0076\n",
      "Epoch 13/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0478 - mae: 0.0061 - val_loss: 0.0464 - val_mae: 0.0046\n",
      "Epoch 14/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0452 - mae: 0.0070 - val_loss: 0.0439 - val_mae: 0.0075\n",
      "Epoch 15/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0427 - mae: 0.0067 - val_loss: 0.0416 - val_mae: 0.0111\n",
      "Epoch 16/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0404 - mae: 0.0100 - val_loss: 0.0396 - val_mae: 0.0189\n",
      "Epoch 17/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0384 - mae: 0.0142 - val_loss: 0.0369 - val_mae: 0.0045\n",
      "Epoch 18/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0359 - mae: 0.0050 - val_loss: 0.0350 - val_mae: 0.0131\n",
      "Epoch 19/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0341 - mae: 0.0121 - val_loss: 0.0328 - val_mae: 0.0036\n",
      "Epoch 20/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.0045 - val_loss: 0.0313 - val_mae: 0.0177\n",
      "Epoch 21/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.0072 - val_loss: 0.0291 - val_mae: 0.0041\n",
      "Epoch 22/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.0058 - val_loss: 0.0273 - val_mae: 0.0040\n",
      "Epoch 23/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0265 - mae: 0.0074 - val_loss: 0.0266 - val_mae: 0.0252\n",
      "Epoch 24/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0251 - mae: 0.0121 - val_loss: 0.0240 - val_mae: 0.0038\n",
      "Epoch 25/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0232 - mae: 0.0047 - val_loss: 0.0224 - val_mae: 0.0037\n",
      "Epoch 26/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0218 - mae: 0.0061 - val_loss: 0.0241 - val_mae: 0.0430\n",
      "Epoch 27/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0205 - mae: 0.0095 - val_loss: 0.0207 - val_mae: 0.0242\n",
      "Epoch 28/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0191 - mae: 0.0066 - val_loss: 0.0184 - val_mae: 0.0091\n",
      "Epoch 29/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0178 - mae: 0.0070 - val_loss: 0.0172 - val_mae: 0.0110\n",
      "Epoch 30/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0078 - val_loss: 0.0160 - val_mae: 0.0081\n",
      "Epoch 31/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0154 - mae: 0.0061 - val_loss: 0.0150 - val_mae: 0.0102\n",
      "Epoch 32/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0115 - val_loss: 0.0138 - val_mae: 0.0040\n",
      "Epoch 33/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0042 - val_loss: 0.0128 - val_mae: 0.0035\n",
      "Epoch 34/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0124 - mae: 0.0054 - val_loss: 0.0122 - val_mae: 0.0124\n",
      "Epoch 35/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0115 - mae: 0.0050 - val_loss: 0.0110 - val_mae: 0.0040\n",
      "Epoch 36/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0106 - mae: 0.0048 - val_loss: 0.0102 - val_mae: 0.0077\n",
      "Epoch 37/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0099 - mae: 0.0089 - val_loss: 0.0118 - val_mae: 0.0442\n",
      "Epoch 38/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0083 - val_loss: 0.0087 - val_mae: 0.0036\n",
      "Epoch 39/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0059 - val_loss: 0.0081 - val_mae: 0.0072\n",
      "Epoch 40/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0061 - val_loss: 0.0076 - val_mae: 0.0114\n",
      "Epoch 41/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0073 - mae: 0.0067 - val_loss: 0.0070 - val_mae: 0.0093\n",
      "Epoch 42/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0067 - mae: 0.0069 - val_loss: 0.0069 - val_mae: 0.0194\n",
      "Epoch 43/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0062 - mae: 0.0066 - val_loss: 0.0059 - val_mae: 0.0043\n",
      "Epoch 44/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0058 - mae: 0.0072 - val_loss: 0.0055 - val_mae: 0.0056\n",
      "Epoch 45/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0053 - mae: 0.0043 - val_loss: 0.0052 - val_mae: 0.0100\n",
      "Epoch 46/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0064 - val_loss: 0.0047 - val_mae: 0.0042\n",
      "Epoch 47/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0046 - mae: 0.0054 - val_loss: 0.0045 - val_mae: 0.0073\n",
      "Epoch 48/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0077 - val_loss: 0.0041 - val_mae: 0.0037\n",
      "Epoch 49/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0068 - val_loss: 0.0038 - val_mae: 0.0051\n",
      "Epoch 50/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0054 - val_loss: 0.0036 - val_mae: 0.0062\n",
      "Epoch 51/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0076 - val_loss: 0.0034 - val_mae: 0.0061\n",
      "Epoch 52/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0113 - val_loss: 0.0032 - val_mae: 0.0057\n",
      "Epoch 53/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0049 - val_loss: 0.0030 - val_mae: 0.0082\n",
      "Epoch 54/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0050 - val_loss: 0.0028 - val_mae: 0.0059\n",
      "Epoch 55/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0078 - val_loss: 0.0029 - val_mae: 0.0112\n",
      "Epoch 56/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0061 - val_loss: 0.0026 - val_mae: 0.0057\n",
      "Epoch 57/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0064 - val_loss: 0.0026 - val_mae: 0.0115\n",
      "Epoch 58/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0065 - val_loss: 0.0025 - val_mae: 0.0126\n",
      "Epoch 59/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0081 - val_loss: 0.0022 - val_mae: 0.0037\n",
      "Epoch 60/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0060 - val_loss: 0.0030 - val_mae: 0.0219\n",
      "Epoch 61/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0074 - val_loss: 0.0021 - val_mae: 0.0092\n",
      "Epoch 62/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0060 - val_loss: 0.0020 - val_mae: 0.0030\n",
      "Epoch 63/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0073 - val_loss: 0.0025 - val_mae: 0.0191\n",
      "Epoch 64/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0084 - val_loss: 0.0019 - val_mae: 0.0059\n",
      "Epoch 65/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0043 - val_loss: 0.0018 - val_mae: 0.0031\n",
      "Epoch 66/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0056 - val_loss: 0.0020 - val_mae: 0.0138\n",
      "Epoch 67/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0083 - val_loss: 0.0022 - val_mae: 0.0197\n",
      "Epoch 68/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0065 - val_loss: 0.0017 - val_mae: 0.0043\n",
      "Epoch 69/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0079 - val_loss: 0.0016 - val_mae: 0.0032\n",
      "Epoch 70/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0063 - val_loss: 0.0016 - val_mae: 0.0043\n",
      "Epoch 71/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0067 - val_loss: 0.0016 - val_mae: 0.0045\n",
      "Epoch 72/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0066 - val_loss: 0.0021 - val_mae: 0.0197\n",
      "Epoch 73/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0071 - val_loss: 0.0016 - val_mae: 0.0083\n",
      "Epoch 74/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0069 - val_loss: 0.0015 - val_mae: 0.0031\n",
      "Epoch 75/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0066 - val_loss: 0.0015 - val_mae: 0.0063\n",
      "Epoch 76/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0055 - val_loss: 0.0015 - val_mae: 0.0052\n",
      "Epoch 77/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0072 - val_loss: 0.0026 - val_mae: 0.0311\n",
      "Epoch 78/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0077 - val_loss: 0.0015 - val_mae: 0.0080\n",
      "Epoch 79/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0058 - val_loss: 0.0014 - val_mae: 0.0047\n",
      "Epoch 80/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0060 - val_loss: 0.0015 - val_mae: 0.0071\n",
      "Epoch 81/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0056 - val_loss: 0.0016 - val_mae: 0.0139\n",
      "Epoch 82/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0079 - val_loss: 0.0014 - val_mae: 0.0071\n",
      "Epoch 83/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0073 - val_loss: 0.0015 - val_mae: 0.0133\n",
      "Epoch 84/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0066 - val_loss: 0.0014 - val_mae: 0.0081\n",
      "Epoch 85/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0057 - val_loss: 0.0014 - val_mae: 0.0090\n",
      "Epoch 86/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0067 - val_loss: 0.0015 - val_mae: 0.0104\n",
      "Epoch 87/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0084 - val_loss: 0.0014 - val_mae: 0.0106\n",
      "Epoch 88/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0068 - val_loss: 0.0013 - val_mae: 0.0043\n",
      "Epoch 89/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0052 - val_loss: 0.0013 - val_mae: 0.0052\n",
      "Epoch 90/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0048 - val_loss: 0.0013 - val_mae: 0.0062\n",
      "Epoch 91/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0065 - val_loss: 0.0015 - val_mae: 0.0133\n",
      "Epoch 92/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0071 - val_loss: 0.0013 - val_mae: 0.0071\n",
      "Epoch 93/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0062 - val_loss: 0.0013 - val_mae: 0.0050\n",
      "Epoch 94/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0065 - val_loss: 0.0012 - val_mae: 0.0030\n",
      "Epoch 95/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0049 - val_loss: 0.0013 - val_mae: 0.0086\n",
      "Epoch 96/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0071 - val_loss: 0.0012 - val_mae: 0.0048\n",
      "Epoch 97/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0068 - val_loss: 0.0012 - val_mae: 0.0062\n",
      "Epoch 98/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0061 - val_loss: 0.0015 - val_mae: 0.0155\n",
      "Epoch 99/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0086 - val_loss: 0.0012 - val_mae: 0.0032\n",
      "Epoch 100/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0051 - val_loss: 0.0012 - val_mae: 0.0033\n",
      "Epoch 101/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0070 - val_loss: 0.0013 - val_mae: 0.0097\n",
      "Epoch 102/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0061 - val_loss: 0.0012 - val_mae: 0.0047\n",
      "Epoch 103/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0054 - val_loss: 0.0012 - val_mae: 0.0068\n",
      "Epoch 104/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0089 - val_loss: 0.0012 - val_mae: 0.0079\n",
      "Epoch 105/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0051 - val_loss: 0.0012 - val_mae: 0.0033\n",
      "Epoch 106/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0054 - val_loss: 0.0012 - val_mae: 0.0059\n",
      "Epoch 107/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0072 - val_loss: 0.0012 - val_mae: 0.0053\n",
      "Epoch 108/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0071 - val_loss: 0.0012 - val_mae: 0.0034\n",
      "Epoch 109/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0053 - val_loss: 0.0012 - val_mae: 0.0047\n",
      "Epoch 110/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0067 - val_loss: 0.0012 - val_mae: 0.0086\n",
      "Epoch 111/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0068 - val_loss: 0.0012 - val_mae: 0.0061\n",
      "Epoch 112/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0069 - val_loss: 0.0011 - val_mae: 0.0038\n",
      "Epoch 113/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0058 - val_loss: 0.0011 - val_mae: 0.0028\n",
      "Epoch 114/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0050 - val_loss: 0.0013 - val_mae: 0.0118\n",
      "Epoch 115/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0051 - val_loss: 0.0011 - val_mae: 0.0036\n",
      "Epoch 116/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0063 - val_loss: 0.0013 - val_mae: 0.0120\n",
      "Epoch 117/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0071 - val_loss: 0.0012 - val_mae: 0.0082\n",
      "Epoch 118/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0064 - val_loss: 0.0012 - val_mae: 0.0079\n",
      "Epoch 119/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0057 - val_loss: 0.0012 - val_mae: 0.0083\n",
      "Epoch 120/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0071 - val_loss: 0.0011 - val_mae: 0.0030\n",
      "Epoch 121/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0055 - val_loss: 0.0012 - val_mae: 0.0072\n",
      "Epoch 122/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0062 - val_loss: 0.0012 - val_mae: 0.0090\n",
      "Epoch 123/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0057 - val_loss: 0.0011 - val_mae: 0.0067\n",
      "Epoch 124/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0069 - val_loss: 0.0011 - val_mae: 0.0065\n",
      "Epoch 125/1000\n",
      "158/163 [============================>.] - ETA: 0s - loss: 0.0011 - mae: 0.0066Restoring model weights from the end of the best epoch: 120.\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0066 - val_loss: 0.0011 - val_mae: 0.0066\n",
      "Epoch 125: early stopping\n",
      "Training für Fold 2...\n",
      "Epoch 1/1000\n",
      "163/163 [==============================] - 2s 4ms/step - loss: 0.1607 - mae: 0.1118 - val_loss: 0.0981 - val_mae: 0.0124\n",
      "Epoch 2/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0903 - mae: 0.0301 - val_loss: 0.0812 - val_mae: 0.0110\n",
      "Epoch 3/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0780 - mae: 0.0247 - val_loss: 0.0729 - val_mae: 0.0188\n",
      "Epoch 4/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0692 - mae: 0.0077 - val_loss: 0.0662 - val_mae: 0.0101\n",
      "Epoch 5/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0637 - mae: 0.0122 - val_loss: 0.0652 - val_mae: 0.0499\n",
      "Epoch 6/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0592 - mae: 0.0133 - val_loss: 0.0565 - val_mae: 0.0052\n",
      "Epoch 7/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0548 - mae: 0.0098 - val_loss: 0.0622 - val_mae: 0.0724\n",
      "Epoch 8/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0522 - mae: 0.0192 - val_loss: 0.0497 - val_mae: 0.0132\n",
      "Epoch 9/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0482 - mae: 0.0112 - val_loss: 0.0468 - val_mae: 0.0161\n",
      "Epoch 10/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0454 - mae: 0.0111 - val_loss: 0.0439 - val_mae: 0.0085\n",
      "Epoch 11/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0427 - mae: 0.0066 - val_loss: 0.0414 - val_mae: 0.0042\n",
      "Epoch 12/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0405 - mae: 0.0125 - val_loss: 0.0413 - val_mae: 0.0362\n",
      "Epoch 13/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0384 - mae: 0.0127 - val_loss: 0.0370 - val_mae: 0.0058\n",
      "Epoch 14/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0360 - mae: 0.0058 - val_loss: 0.0349 - val_mae: 0.0042\n",
      "Epoch 15/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0341 - mae: 0.0079 - val_loss: 0.0333 - val_mae: 0.0124\n",
      "Epoch 16/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0323 - mae: 0.0095 - val_loss: 0.0315 - val_mae: 0.0133\n",
      "Epoch 17/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.0119 - val_loss: 0.0295 - val_mae: 0.0059\n",
      "Epoch 18/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.0060 - val_loss: 0.0279 - val_mae: 0.0077\n",
      "Epoch 19/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.0085 - val_loss: 0.0263 - val_mae: 0.0044\n",
      "Epoch 20/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0256 - mae: 0.0084 - val_loss: 0.0248 - val_mae: 0.0044\n",
      "Epoch 21/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0242 - mae: 0.0080 - val_loss: 0.0234 - val_mae: 0.0068\n",
      "Epoch 22/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0231 - mae: 0.0142 - val_loss: 0.0221 - val_mae: 0.0079\n",
      "Epoch 23/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0214 - mae: 0.0059 - val_loss: 0.0207 - val_mae: 0.0042\n",
      "Epoch 24/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0201 - mae: 0.0053 - val_loss: 0.0195 - val_mae: 0.0069\n",
      "Epoch 25/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0189 - mae: 0.0063 - val_loss: 0.0184 - val_mae: 0.0086\n",
      "Epoch 26/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0180 - mae: 0.0105 - val_loss: 0.0172 - val_mae: 0.0064\n",
      "Epoch 27/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0167 - mae: 0.0053 - val_loss: 0.0168 - val_mae: 0.0210\n",
      "Epoch 28/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0159 - mae: 0.0116 - val_loss: 0.0152 - val_mae: 0.0071\n",
      "Epoch 29/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0147 - mae: 0.0058 - val_loss: 0.0143 - val_mae: 0.0078\n",
      "Epoch 30/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0070 - val_loss: 0.0133 - val_mae: 0.0041\n",
      "Epoch 31/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0067 - val_loss: 0.0126 - val_mae: 0.0113\n",
      "Epoch 32/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0089 - val_loss: 0.0121 - val_mae: 0.0201\n",
      "Epoch 33/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0113 - mae: 0.0083 - val_loss: 0.0108 - val_mae: 0.0038\n",
      "Epoch 34/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0105 - mae: 0.0069 - val_loss: 0.0102 - val_mae: 0.0066\n",
      "Epoch 35/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0098 - mae: 0.0052 - val_loss: 0.0096 - val_mae: 0.0108\n",
      "Epoch 36/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0071 - val_loss: 0.0106 - val_mae: 0.0358\n",
      "Epoch 37/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0096 - val_loss: 0.0084 - val_mae: 0.0124\n",
      "Epoch 38/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0077 - val_mae: 0.0042\n",
      "Epoch 39/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0085 - val_loss: 0.0074 - val_mae: 0.0122\n",
      "Epoch 40/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0070 - mae: 0.0070 - val_loss: 0.0067 - val_mae: 0.0035\n",
      "Epoch 41/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0069 - mae: 0.0128 - val_loss: 0.0064 - val_mae: 0.0041\n",
      "Epoch 42/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0062 - mae: 0.0055 - val_loss: 0.0061 - val_mae: 0.0106\n",
      "Epoch 43/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0058 - mae: 0.0057 - val_loss: 0.0057 - val_mae: 0.0064\n",
      "Epoch 44/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0055 - mae: 0.0072 - val_loss: 0.0053 - val_mae: 0.0040\n",
      "Epoch 45/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0052 - mae: 0.0066 - val_loss: 0.0050 - val_mae: 0.0058\n",
      "Epoch 46/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0053 - val_loss: 0.0051 - val_mae: 0.0163\n",
      "Epoch 47/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0133 - val_loss: 0.0045 - val_mae: 0.0044\n",
      "Epoch 48/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0050 - val_loss: 0.0044 - val_mae: 0.0135\n",
      "Epoch 49/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0057 - val_loss: 0.0044 - val_mae: 0.0159\n",
      "Epoch 50/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0075 - val_loss: 0.0039 - val_mae: 0.0092\n",
      "Epoch 51/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0091 - val_loss: 0.0037 - val_mae: 0.0067\n",
      "Epoch 52/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0074 - val_loss: 0.0040 - val_mae: 0.0205\n",
      "Epoch 53/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0083 - val_loss: 0.0033 - val_mae: 0.0055\n",
      "Epoch 54/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0095 - val_loss: 0.0032 - val_mae: 0.0062\n",
      "Epoch 55/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0072 - val_loss: 0.0032 - val_mae: 0.0086\n",
      "Epoch 56/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0071 - val_loss: 0.0030 - val_mae: 0.0077\n",
      "Epoch 57/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0077 - val_loss: 0.0063 - val_mae: 0.0462\n",
      "Epoch 58/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0087 - val_loss: 0.0028 - val_mae: 0.0047\n",
      "Epoch 59/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0064 - val_loss: 0.0036 - val_mae: 0.0286\n",
      "Epoch 60/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0088 - val_loss: 0.0028 - val_mae: 0.0137\n",
      "Epoch 61/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0067 - val_loss: 0.0026 - val_mae: 0.0108\n",
      "Epoch 62/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0073 - val_loss: 0.0026 - val_mae: 0.0127\n",
      "Epoch 63/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0111 - val_loss: 0.0025 - val_mae: 0.0093\n",
      "Epoch 64/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0072 - val_loss: 0.0024 - val_mae: 0.0087\n",
      "Epoch 65/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0064 - val_loss: 0.0023 - val_mae: 0.0077\n",
      "Epoch 66/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0078 - val_loss: 0.0025 - val_mae: 0.0147\n",
      "Epoch 67/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0089 - val_loss: 0.0021 - val_mae: 0.0037\n",
      "Epoch 68/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0082 - val_loss: 0.0024 - val_mae: 0.0173\n",
      "Epoch 69/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0078 - val_loss: 0.0021 - val_mae: 0.0060\n",
      "Epoch 70/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0065 - val_loss: 0.0020 - val_mae: 0.0063\n",
      "Epoch 71/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0077 - val_loss: 0.0022 - val_mae: 0.0140\n",
      "Epoch 72/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0076 - val_loss: 0.0022 - val_mae: 0.0128\n",
      "Epoch 73/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0088 - val_loss: 0.0019 - val_mae: 0.0041\n",
      "Epoch 74/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0071 - val_loss: 0.0019 - val_mae: 0.0055\n",
      "Epoch 75/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0079 - val_loss: 0.0018 - val_mae: 0.0058\n",
      "Epoch 76/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0066 - val_loss: 0.0021 - val_mae: 0.0143\n",
      "Epoch 77/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0091 - val_loss: 0.0018 - val_mae: 0.0042\n",
      "Epoch 78/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0060 - val_loss: 0.0018 - val_mae: 0.0085\n",
      "Epoch 79/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0079 - val_loss: 0.0017 - val_mae: 0.0046\n",
      "Epoch 80/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0058 - val_loss: 0.0017 - val_mae: 0.0052\n",
      "Epoch 81/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0091 - val_loss: 0.0017 - val_mae: 0.0083\n",
      "Epoch 82/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0052 - val_loss: 0.0016 - val_mae: 0.0037\n",
      "Epoch 83/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0060 - val_loss: 0.0017 - val_mae: 0.0086\n",
      "Epoch 84/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0086 - val_loss: 0.0016 - val_mae: 0.0045\n",
      "Epoch 85/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0076 - val_loss: 0.0017 - val_mae: 0.0113\n",
      "Epoch 86/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0077 - val_loss: 0.0016 - val_mae: 0.0070\n",
      "Epoch 87/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0059 - val_loss: 0.0017 - val_mae: 0.0112\n",
      "Epoch 88/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0065 - val_loss: 0.0019 - val_mae: 0.0184\n",
      "Epoch 89/1000\n",
      "152/163 [==========================>...] - ETA: 0s - loss: 0.0015 - mae: 0.0061Restoring model weights from the end of the best epoch: 84.\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0060 - val_loss: 0.0025 - val_mae: 0.0260\n",
      "Epoch 89: early stopping\n",
      "Training für Fold 3...\n",
      "Epoch 1/1000\n",
      "163/163 [==============================] - 2s 4ms/step - loss: 0.1789 - mae: 0.1496 - val_loss: 0.1028 - val_mae: 0.0196\n",
      "Epoch 2/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0940 - mae: 0.0204 - val_loss: 0.0866 - val_mae: 0.0118\n",
      "Epoch 3/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0821 - mae: 0.0131 - val_loss: 0.0780 - val_mae: 0.0182\n",
      "Epoch 4/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0748 - mae: 0.0187 - val_loss: 0.0708 - val_mae: 0.0075\n",
      "Epoch 5/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0688 - mae: 0.0167 - val_loss: 0.0654 - val_mae: 0.0155\n",
      "Epoch 6/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0628 - mae: 0.0096 - val_loss: 0.0603 - val_mae: 0.0089\n",
      "Epoch 7/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0583 - mae: 0.0103 - val_loss: 0.0560 - val_mae: 0.0068\n",
      "Epoch 8/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0541 - mae: 0.0067 - val_loss: 0.0535 - val_mae: 0.0286\n",
      "Epoch 9/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0506 - mae: 0.0120 - val_loss: 0.0491 - val_mae: 0.0165\n",
      "Epoch 10/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0477 - mae: 0.0161 - val_loss: 0.0456 - val_mae: 0.0081\n",
      "Epoch 11/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0441 - mae: 0.0057 - val_loss: 0.0427 - val_mae: 0.0054\n",
      "Epoch 12/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0414 - mae: 0.0087 - val_loss: 0.0401 - val_mae: 0.0096\n",
      "Epoch 13/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0388 - mae: 0.0083 - val_loss: 0.0376 - val_mae: 0.0109\n",
      "Epoch 14/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0364 - mae: 0.0075 - val_loss: 0.0353 - val_mae: 0.0091\n",
      "Epoch 15/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0346 - mae: 0.0148 - val_loss: 0.0330 - val_mae: 0.0037\n",
      "Epoch 16/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0320 - mae: 0.0052 - val_loss: 0.0310 - val_mae: 0.0074\n",
      "Epoch 17/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.0049 - val_loss: 0.0290 - val_mae: 0.0039\n",
      "Epoch 18/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.0050 - val_loss: 0.0272 - val_mae: 0.0076\n",
      "Epoch 19/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.0091 - val_loss: 0.0255 - val_mae: 0.0092\n",
      "Epoch 20/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0248 - mae: 0.0095 - val_loss: 0.0383 - val_mae: 0.0913\n",
      "Epoch 21/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0238 - mae: 0.0134 - val_loss: 0.0223 - val_mae: 0.0043\n",
      "Epoch 22/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0216 - mae: 0.0046 - val_loss: 0.0209 - val_mae: 0.0049\n",
      "Epoch 23/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0202 - mae: 0.0042 - val_loss: 0.0195 - val_mae: 0.0034\n",
      "Epoch 24/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0190 - mae: 0.0066 - val_loss: 0.0183 - val_mae: 0.0038\n",
      "Epoch 25/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0177 - mae: 0.0062 - val_loss: 0.0171 - val_mae: 0.0057\n",
      "Epoch 26/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0165 - mae: 0.0044 - val_loss: 0.0159 - val_mae: 0.0076\n",
      "Epoch 27/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0153 - mae: 0.0044 - val_loss: 0.0148 - val_mae: 0.0040\n",
      "Epoch 28/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0143 - mae: 0.0067 - val_loss: 0.0137 - val_mae: 0.0047\n",
      "Epoch 29/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0051 - val_loss: 0.0128 - val_mae: 0.0083\n",
      "Epoch 30/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0123 - mae: 0.0065 - val_loss: 0.0118 - val_mae: 0.0063\n",
      "Epoch 31/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0115 - mae: 0.0077 - val_loss: 0.0110 - val_mae: 0.0042\n",
      "Epoch 32/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0106 - mae: 0.0071 - val_loss: 0.0101 - val_mae: 0.0034\n",
      "Epoch 33/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0099 - mae: 0.0085 - val_loss: 0.0095 - val_mae: 0.0072\n",
      "Epoch 34/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0062 - val_loss: 0.0087 - val_mae: 0.0033\n",
      "Epoch 35/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0059 - val_loss: 0.0083 - val_mae: 0.0114\n",
      "Epoch 36/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0070 - val_loss: 0.0075 - val_mae: 0.0044\n",
      "Epoch 37/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0073 - mae: 0.0053 - val_loss: 0.0071 - val_mae: 0.0081\n",
      "Epoch 38/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0069 - mae: 0.0086 - val_loss: 0.0066 - val_mae: 0.0079\n",
      "Epoch 39/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0063 - mae: 0.0058 - val_loss: 0.0061 - val_mae: 0.0049\n",
      "Epoch 40/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0059 - mae: 0.0054 - val_loss: 0.0056 - val_mae: 0.0036\n",
      "Epoch 41/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0055 - mae: 0.0066 - val_loss: 0.0052 - val_mae: 0.0052\n",
      "Epoch 42/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0052 - mae: 0.0084 - val_loss: 0.0053 - val_mae: 0.0165\n",
      "Epoch 43/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0061 - val_loss: 0.0046 - val_mae: 0.0056\n",
      "Epoch 44/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0072 - val_loss: 0.0044 - val_mae: 0.0091\n",
      "Epoch 45/1000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0042 - mae: 0.0051 - val_loss: 0.0041 - val_mae: 0.0088\n",
      "Epoch 46/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0064 - val_loss: 0.0043 - val_mae: 0.0173\n",
      "Epoch 47/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0058 - val_loss: 0.0036 - val_mae: 0.0076\n",
      "Epoch 48/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0068 - val_loss: 0.0034 - val_mae: 0.0052\n",
      "Epoch 49/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0073 - val_loss: 0.0035 - val_mae: 0.0184\n",
      "Epoch 50/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0085 - val_loss: 0.0030 - val_mae: 0.0035\n",
      "Epoch 51/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0054 - val_loss: 0.0029 - val_mae: 0.0076\n",
      "Epoch 52/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0059 - val_loss: 0.0028 - val_mae: 0.0079\n",
      "Epoch 53/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0057 - val_loss: 0.0026 - val_mae: 0.0069\n",
      "Epoch 54/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0068 - val_loss: 0.0024 - val_mae: 0.0034\n",
      "Epoch 55/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0083 - val_loss: 0.0023 - val_mae: 0.0046\n",
      "Epoch 56/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0059 - val_loss: 0.0028 - val_mae: 0.0180\n",
      "Epoch 57/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0074 - val_loss: 0.0022 - val_mae: 0.0038\n",
      "Epoch 58/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0052 - val_loss: 0.0021 - val_mae: 0.0068\n",
      "Epoch 59/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0061 - val_loss: 0.0024 - val_mae: 0.0184\n",
      "Epoch 60/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0072 - val_loss: 0.0020 - val_mae: 0.0072\n",
      "Epoch 61/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0059 - val_loss: 0.0022 - val_mae: 0.0187\n",
      "Epoch 62/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0077 - val_loss: 0.0019 - val_mae: 0.0073\n",
      "Epoch 63/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0078 - val_loss: 0.0045 - val_mae: 0.0460\n",
      "Epoch 64/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0071 - val_loss: 0.0017 - val_mae: 0.0037\n",
      "Epoch 65/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0046 - val_loss: 0.0017 - val_mae: 0.0076\n",
      "Epoch 66/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0052 - val_loss: 0.0018 - val_mae: 0.0095\n",
      "Epoch 67/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0057 - val_loss: 0.0016 - val_mae: 0.0042\n",
      "Epoch 68/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0051 - val_loss: 0.0017 - val_mae: 0.0083\n",
      "Epoch 69/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0074 - val_loss: 0.0020 - val_mae: 0.0215\n",
      "Epoch 70/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0055 - val_loss: 0.0016 - val_mae: 0.0111\n",
      "Epoch 71/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0079 - val_loss: 0.0015 - val_mae: 0.0038\n",
      "Epoch 72/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0058 - val_loss: 0.0015 - val_mae: 0.0050\n",
      "Epoch 73/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0055 - val_loss: 0.0017 - val_mae: 0.0148\n",
      "Epoch 74/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0060 - val_loss: 0.0015 - val_mae: 0.0059\n",
      "Epoch 75/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0066 - val_loss: 0.0021 - val_mae: 0.0250\n",
      "Epoch 76/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0056 - val_loss: 0.0014 - val_mae: 0.0029\n",
      "Epoch 77/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0057 - val_loss: 0.0015 - val_mae: 0.0093\n",
      "Epoch 78/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0055 - val_loss: 0.0021 - val_mae: 0.0222\n",
      "Epoch 79/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0076 - val_loss: 0.0014 - val_mae: 0.0071\n",
      "Epoch 80/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0050 - val_loss: 0.0014 - val_mae: 0.0061\n",
      "Epoch 81/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0068 - val_loss: 0.0013 - val_mae: 0.0036\n",
      "Epoch 82/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0049 - val_loss: 0.0017 - val_mae: 0.0182\n",
      "Epoch 83/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0077 - val_loss: 0.0013 - val_mae: 0.0066\n",
      "Epoch 84/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0056 - val_loss: 0.0013 - val_mae: 0.0041\n",
      "Epoch 85/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0055 - val_loss: 0.0015 - val_mae: 0.0143\n",
      "Epoch 86/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0063 - val_loss: 0.0013 - val_mae: 0.0075\n",
      "Epoch 87/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0059 - val_loss: 0.0013 - val_mae: 0.0070\n",
      "Epoch 88/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0054 - val_loss: 0.0013 - val_mae: 0.0073\n",
      "Epoch 89/1000\n",
      "161/163 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0067Restoring model weights from the end of the best epoch: 84.\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0067 - val_loss: 0.0016 - val_mae: 0.0138\n",
      "Epoch 89: early stopping\n",
      "Training für Fold 4...\n",
      "Epoch 1/1000\n",
      "163/163 [==============================] - 2s 4ms/step - loss: 0.1816 - mae: 0.1435 - val_loss: 0.1141 - val_mae: 0.0405\n",
      "Epoch 2/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.1051 - mae: 0.0256 - val_loss: 0.1176 - val_mae: 0.0995\n",
      "Epoch 3/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0953 - mae: 0.0240 - val_loss: 0.0898 - val_mae: 0.0116\n",
      "Epoch 4/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0872 - mae: 0.0178 - val_loss: 0.0833 - val_mae: 0.0079\n",
      "Epoch 5/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0807 - mae: 0.0113 - val_loss: 0.0778 - val_mae: 0.0063\n",
      "Epoch 6/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0754 - mae: 0.0068 - val_loss: 0.0738 - val_mae: 0.0225\n",
      "Epoch 7/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0718 - mae: 0.0189 - val_loss: 0.0688 - val_mae: 0.0074\n",
      "Epoch 8/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0668 - mae: 0.0065 - val_loss: 0.0649 - val_mae: 0.0062\n",
      "Epoch 9/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0637 - mae: 0.0162 - val_loss: 0.0615 - val_mae: 0.0115\n",
      "Epoch 10/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0599 - mae: 0.0118 - val_loss: 0.0582 - val_mae: 0.0127\n",
      "Epoch 11/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0569 - mae: 0.0135 - val_loss: 0.0552 - val_mae: 0.0118\n",
      "Epoch 12/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0537 - mae: 0.0086 - val_loss: 0.0521 - val_mae: 0.0042\n",
      "Epoch 13/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0512 - mae: 0.0135 - val_loss: 0.0528 - val_mae: 0.0450\n",
      "Epoch 14/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0484 - mae: 0.0101 - val_loss: 0.0470 - val_mae: 0.0107\n",
      "Epoch 15/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0457 - mae: 0.0072 - val_loss: 0.0445 - val_mae: 0.0065\n",
      "Epoch 16/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0434 - mae: 0.0093 - val_loss: 0.0421 - val_mae: 0.0059\n",
      "Epoch 17/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0411 - mae: 0.0100 - val_loss: 0.0402 - val_mae: 0.0164\n",
      "Epoch 18/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0389 - mae: 0.0091 - val_loss: 0.0381 - val_mae: 0.0156\n",
      "Epoch 19/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0370 - mae: 0.0135 - val_loss: 0.0469 - val_mae: 0.0797\n",
      "Epoch 20/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0358 - mae: 0.0173 - val_loss: 0.0338 - val_mae: 0.0043\n",
      "Epoch 21/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0329 - mae: 0.0044 - val_loss: 0.0320 - val_mae: 0.0060\n",
      "Epoch 22/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.0059 - val_loss: 0.0302 - val_mae: 0.0044\n",
      "Epoch 23/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.0051 - val_loss: 0.0290 - val_mae: 0.0168\n",
      "Epoch 24/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.0102 - val_loss: 0.0269 - val_mae: 0.0069\n",
      "Epoch 25/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.0061 - val_loss: 0.0253 - val_mae: 0.0068\n",
      "Epoch 26/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0246 - mae: 0.0059 - val_loss: 0.0243 - val_mae: 0.0197\n",
      "Epoch 27/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0234 - mae: 0.0127 - val_loss: 0.0223 - val_mae: 0.0037\n",
      "Epoch 28/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0217 - mae: 0.0048 - val_loss: 0.0210 - val_mae: 0.0049\n",
      "Epoch 29/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0204 - mae: 0.0059 - val_loss: 0.0204 - val_mae: 0.0244\n",
      "Epoch 30/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0192 - mae: 0.0096 - val_loss: 0.0184 - val_mae: 0.0046\n",
      "Epoch 31/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0179 - mae: 0.0061 - val_loss: 0.0173 - val_mae: 0.0072\n",
      "Epoch 32/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0167 - mae: 0.0063 - val_loss: 0.0165 - val_mae: 0.0155\n",
      "Epoch 33/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0098 - val_loss: 0.0151 - val_mae: 0.0070\n",
      "Epoch 34/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0146 - mae: 0.0056 - val_loss: 0.0141 - val_mae: 0.0037\n",
      "Epoch 35/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0075 - val_loss: 0.0132 - val_mae: 0.0094\n",
      "Epoch 36/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0056 - val_loss: 0.0132 - val_mae: 0.0279\n",
      "Epoch 37/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0083 - val_loss: 0.0115 - val_mae: 0.0123\n",
      "Epoch 38/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0112 - mae: 0.0104 - val_loss: 0.0106 - val_mae: 0.0056\n",
      "Epoch 39/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0102 - mae: 0.0044 - val_loss: 0.0100 - val_mae: 0.0110\n",
      "Epoch 40/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0061 - val_loss: 0.0096 - val_mae: 0.0187\n",
      "Epoch 41/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0079 - val_loss: 0.0086 - val_mae: 0.0067\n",
      "Epoch 42/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0072 - val_loss: 0.0079 - val_mae: 0.0041\n",
      "Epoch 43/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0052 - val_loss: 0.0077 - val_mae: 0.0176\n",
      "Epoch 44/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0072 - mae: 0.0073 - val_loss: 0.0070 - val_mae: 0.0090\n",
      "Epoch 45/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0067 - mae: 0.0075 - val_loss: 0.0064 - val_mae: 0.0056\n",
      "Epoch 46/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0062 - mae: 0.0058 - val_loss: 0.0060 - val_mae: 0.0062\n",
      "Epoch 47/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0058 - mae: 0.0079 - val_loss: 0.0056 - val_mae: 0.0078\n",
      "Epoch 48/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0054 - mae: 0.0082 - val_loss: 0.0053 - val_mae: 0.0117\n",
      "Epoch 49/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0051 - mae: 0.0067 - val_loss: 0.0049 - val_mae: 0.0085\n",
      "Epoch 50/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0047 - mae: 0.0063 - val_loss: 0.0048 - val_mae: 0.0150\n",
      "Epoch 51/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0080 - val_loss: 0.0043 - val_mae: 0.0066\n",
      "Epoch 52/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0055 - val_loss: 0.0040 - val_mae: 0.0088\n",
      "Epoch 53/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0056 - val_loss: 0.0039 - val_mae: 0.0124\n",
      "Epoch 54/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0078 - val_loss: 0.0041 - val_mae: 0.0204\n",
      "Epoch 55/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0074 - val_loss: 0.0034 - val_mae: 0.0098\n",
      "Epoch 56/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0060 - val_loss: 0.0031 - val_mae: 0.0032\n",
      "Epoch 57/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0055 - val_loss: 0.0030 - val_mae: 0.0047\n",
      "Epoch 58/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0064 - val_loss: 0.0030 - val_mae: 0.0117\n",
      "Epoch 59/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0070 - val_loss: 0.0027 - val_mae: 0.0042\n",
      "Epoch 60/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0027 - mae: 0.0076 - val_loss: 0.0028 - val_mae: 0.0172\n",
      "Epoch 61/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0025 - mae: 0.0057 - val_loss: 0.0024 - val_mae: 0.0060\n",
      "Epoch 62/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0064 - val_loss: 0.0023 - val_mae: 0.0037\n",
      "Epoch 63/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0023 - mae: 0.0063 - val_loss: 0.0022 - val_mae: 0.0037\n",
      "Epoch 64/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0022 - mae: 0.0064 - val_loss: 0.0023 - val_mae: 0.0122\n",
      "Epoch 65/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0077 - val_loss: 0.0020 - val_mae: 0.0037\n",
      "Epoch 66/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0050 - val_loss: 0.0021 - val_mae: 0.0109\n",
      "Epoch 67/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0074 - val_loss: 0.0019 - val_mae: 0.0034\n",
      "Epoch 68/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0055 - val_loss: 0.0019 - val_mae: 0.0073\n",
      "Epoch 69/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0086 - val_loss: 0.0018 - val_mae: 0.0029\n",
      "Epoch 70/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0047 - val_loss: 0.0018 - val_mae: 0.0081\n",
      "Epoch 71/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0071 - val_loss: 0.0020 - val_mae: 0.0169\n",
      "Epoch 72/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0066 - val_loss: 0.0020 - val_mae: 0.0174\n",
      "Epoch 73/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0056 - val_loss: 0.0016 - val_mae: 0.0046\n",
      "Epoch 74/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0054 - val_loss: 0.0016 - val_mae: 0.0037\n",
      "Epoch 75/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0069 - val_loss: 0.0019 - val_mae: 0.0143\n",
      "Epoch 76/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0067 - val_loss: 0.0016 - val_mae: 0.0057\n",
      "Epoch 77/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0063 - val_loss: 0.0015 - val_mae: 0.0063\n",
      "Epoch 78/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0069 - val_loss: 0.0015 - val_mae: 0.0032\n",
      "Epoch 79/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0061 - val_loss: 0.0015 - val_mae: 0.0037\n",
      "Epoch 80/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0053 - val_loss: 0.0015 - val_mae: 0.0069\n",
      "Epoch 81/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0081 - val_loss: 0.0015 - val_mae: 0.0072\n",
      "Epoch 82/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0056 - val_loss: 0.0014 - val_mae: 0.0057\n",
      "Epoch 83/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0067 - val_loss: 0.0014 - val_mae: 0.0067\n",
      "Epoch 84/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0050 - val_loss: 0.0014 - val_mae: 0.0066\n",
      "Epoch 85/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0076 - val_loss: 0.0014 - val_mae: 0.0056\n",
      "Epoch 86/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0064 - val_loss: 0.0013 - val_mae: 0.0041\n",
      "Epoch 87/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0059 - val_loss: 0.0013 - val_mae: 0.0041\n",
      "Epoch 88/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0056 - val_loss: 0.0013 - val_mae: 0.0030\n",
      "Epoch 89/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0069 - val_loss: 0.0014 - val_mae: 0.0080\n",
      "Epoch 90/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0049 - val_loss: 0.0013 - val_mae: 0.0061\n",
      "Epoch 91/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0072 - val_loss: 0.0013 - val_mae: 0.0043\n",
      "Epoch 92/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0059 - val_loss: 0.0013 - val_mae: 0.0071\n",
      "Epoch 93/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0086 - val_loss: 0.0012 - val_mae: 0.0034\n",
      "Epoch 94/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0047 - val_loss: 0.0012 - val_mae: 0.0047\n",
      "Epoch 95/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0061 - val_loss: 0.0013 - val_mae: 0.0054\n",
      "Epoch 96/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0054 - val_loss: 0.0013 - val_mae: 0.0086\n",
      "Epoch 97/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0056 - val_loss: 0.0013 - val_mae: 0.0102\n",
      "Epoch 98/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0064 - val_loss: 0.0012 - val_mae: 0.0067\n",
      "Epoch 99/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0062 - val_loss: 0.0012 - val_mae: 0.0035\n",
      "Epoch 100/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0053 - val_loss: 0.0016 - val_mae: 0.0201\n",
      "Epoch 101/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0076 - val_loss: 0.0012 - val_mae: 0.0036\n",
      "Epoch 102/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0057 - val_loss: 0.0012 - val_mae: 0.0035\n",
      "Epoch 103/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0053 - val_loss: 0.0014 - val_mae: 0.0135\n",
      "Epoch 104/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0069 - val_loss: 0.0012 - val_mae: 0.0043\n",
      "Epoch 105/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0056 - val_loss: 0.0012 - val_mae: 0.0053\n",
      "Epoch 106/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0053 - val_loss: 0.0013 - val_mae: 0.0101\n",
      "Epoch 107/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0060 - val_loss: 0.0012 - val_mae: 0.0057\n",
      "Epoch 108/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0067 - val_loss: 0.0012 - val_mae: 0.0064\n",
      "Epoch 109/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0055 - val_loss: 0.0013 - val_mae: 0.0112\n",
      "Epoch 110/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0065 - val_loss: 0.0014 - val_mae: 0.0127\n",
      "Epoch 111/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0062 - val_loss: 0.0012 - val_mae: 0.0084\n",
      "Epoch 112/1000\n",
      "156/163 [===========================>..] - ETA: 0s - loss: 0.0012 - mae: 0.0079Restoring model weights from the end of the best epoch: 107.\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0079 - val_loss: 0.0012 - val_mae: 0.0073\n",
      "Epoch 112: early stopping\n",
      "Training für Fold 5...\n",
      "Epoch 1/1000\n",
      "163/163 [==============================] - 2s 4ms/step - loss: 0.1648 - mae: 0.1116 - val_loss: 0.1075 - val_mae: 0.0251\n",
      "Epoch 2/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0988 - mae: 0.0252 - val_loss: 0.0912 - val_mae: 0.0147\n",
      "Epoch 3/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0869 - mae: 0.0153 - val_loss: 0.0831 - val_mae: 0.0214\n",
      "Epoch 4/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0800 - mae: 0.0199 - val_loss: 0.0761 - val_mae: 0.0090\n",
      "Epoch 5/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0753 - mae: 0.0277 - val_loss: 0.0737 - val_mae: 0.0431\n",
      "Epoch 6/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0690 - mae: 0.0146 - val_loss: 0.0662 - val_mae: 0.0071\n",
      "Epoch 7/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0641 - mae: 0.0061 - val_loss: 0.0622 - val_mae: 0.0081\n",
      "Epoch 8/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0603 - mae: 0.0063 - val_loss: 0.0585 - val_mae: 0.0098\n",
      "Epoch 9/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0568 - mae: 0.0082 - val_loss: 0.0551 - val_mae: 0.0062\n",
      "Epoch 10/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0538 - mae: 0.0126 - val_loss: 0.0520 - val_mae: 0.0086\n",
      "Epoch 11/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0507 - mae: 0.0091 - val_loss: 0.0492 - val_mae: 0.0105\n",
      "Epoch 12/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0478 - mae: 0.0086 - val_loss: 0.0475 - val_mae: 0.0234\n",
      "Epoch 13/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0458 - mae: 0.0168 - val_loss: 0.0444 - val_mae: 0.0188\n",
      "Epoch 14/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0428 - mae: 0.0076 - val_loss: 0.0423 - val_mae: 0.0202\n",
      "Epoch 15/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0405 - mae: 0.0078 - val_loss: 0.0393 - val_mae: 0.0063\n",
      "Epoch 16/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0383 - mae: 0.0103 - val_loss: 0.0371 - val_mae: 0.0060\n",
      "Epoch 17/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0361 - mae: 0.0087 - val_loss: 0.0351 - val_mae: 0.0081\n",
      "Epoch 18/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0342 - mae: 0.0093 - val_loss: 0.0335 - val_mae: 0.0185\n",
      "Epoch 19/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0324 - mae: 0.0103 - val_loss: 0.0312 - val_mae: 0.0049\n",
      "Epoch 20/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.0061 - val_loss: 0.0299 - val_mae: 0.0164\n",
      "Epoch 21/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.0071 - val_loss: 0.0278 - val_mae: 0.0102\n",
      "Epoch 22/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.0081 - val_loss: 0.0262 - val_mae: 0.0114\n",
      "Epoch 23/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0261 - mae: 0.0191 - val_loss: 0.0257 - val_mae: 0.0316\n",
      "Epoch 24/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0239 - mae: 0.0084 - val_loss: 0.0232 - val_mae: 0.0073\n",
      "Epoch 25/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0224 - mae: 0.0050 - val_loss: 0.0218 - val_mae: 0.0070\n",
      "Epoch 26/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0211 - mae: 0.0060 - val_loss: 0.0205 - val_mae: 0.0047\n",
      "Epoch 27/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0199 - mae: 0.0067 - val_loss: 0.0194 - val_mae: 0.0109\n",
      "Epoch 28/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0187 - mae: 0.0086 - val_loss: 0.0180 - val_mae: 0.0053\n",
      "Epoch 29/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0175 - mae: 0.0082 - val_loss: 0.0169 - val_mae: 0.0063\n",
      "Epoch 30/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0164 - mae: 0.0061 - val_loss: 0.0160 - val_mae: 0.0118\n",
      "Epoch 31/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0153 - mae: 0.0074 - val_loss: 0.0160 - val_mae: 0.0275\n",
      "Epoch 32/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0144 - mae: 0.0084 - val_loss: 0.0138 - val_mae: 0.0051\n",
      "Epoch 33/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0088 - val_loss: 0.0130 - val_mae: 0.0107\n",
      "Epoch 34/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0080 - val_loss: 0.0120 - val_mae: 0.0070\n",
      "Epoch 35/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0117 - mae: 0.0077 - val_loss: 0.0112 - val_mae: 0.0048\n",
      "Epoch 36/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0110 - mae: 0.0108 - val_loss: 0.0105 - val_mae: 0.0057\n",
      "Epoch 37/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0102 - mae: 0.0090 - val_loss: 0.0098 - val_mae: 0.0063\n",
      "Epoch 38/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0095 - mae: 0.0066 - val_loss: 0.0092 - val_mae: 0.0069\n",
      "Epoch 39/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0089 - mae: 0.0084 - val_loss: 0.0086 - val_mae: 0.0072\n",
      "Epoch 40/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0085 - val_loss: 0.0082 - val_mae: 0.0110\n",
      "Epoch 41/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0080 - val_loss: 0.0075 - val_mae: 0.0076\n",
      "Epoch 42/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0073 - mae: 0.0085 - val_loss: 0.0070 - val_mae: 0.0084\n",
      "Epoch 43/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0068 - mae: 0.0067 - val_loss: 0.0077 - val_mae: 0.0289\n",
      "Epoch 44/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0065 - mae: 0.0103 - val_loss: 0.0061 - val_mae: 0.0060\n",
      "Epoch 45/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0059 - mae: 0.0053 - val_loss: 0.0058 - val_mae: 0.0082\n",
      "Epoch 46/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0056 - mae: 0.0065 - val_loss: 0.0054 - val_mae: 0.0047\n",
      "Epoch 47/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0053 - mae: 0.0080 - val_loss: 0.0051 - val_mae: 0.0063\n",
      "Epoch 48/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0080 - val_loss: 0.0051 - val_mae: 0.0139\n",
      "Epoch 49/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0092 - val_loss: 0.0045 - val_mae: 0.0048\n",
      "Epoch 50/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0073 - val_loss: 0.0044 - val_mae: 0.0089\n",
      "Epoch 51/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0076 - val_loss: 0.0040 - val_mae: 0.0037\n",
      "Epoch 52/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0069 - val_loss: 0.0038 - val_mae: 0.0054\n",
      "Epoch 53/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0069 - val_loss: 0.0038 - val_mae: 0.0121\n",
      "Epoch 54/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0085 - val_loss: 0.0035 - val_mae: 0.0089\n",
      "Epoch 55/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0083 - val_loss: 0.0034 - val_mae: 0.0097\n",
      "Epoch 56/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0086 - val_loss: 0.0047 - val_mae: 0.0338\n",
      "Epoch 57/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0076 - val_loss: 0.0030 - val_mae: 0.0051\n",
      "Epoch 58/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0063 - val_loss: 0.0029 - val_mae: 0.0059\n",
      "Epoch 59/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0059 - val_loss: 0.0027 - val_mae: 0.0036\n",
      "Epoch 60/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0106 - val_loss: 0.0027 - val_mae: 0.0054\n",
      "Epoch 61/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0062 - val_loss: 0.0026 - val_mae: 0.0058\n",
      "Epoch 62/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0068 - val_loss: 0.0025 - val_mae: 0.0072\n",
      "Epoch 63/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0082 - val_loss: 0.0024 - val_mae: 0.0082\n",
      "Epoch 64/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0062 - val_loss: 0.0023 - val_mae: 0.0038\n",
      "Epoch 65/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0077 - val_loss: 0.0022 - val_mae: 0.0035\n",
      "Epoch 66/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0069 - val_loss: 0.0022 - val_mae: 0.0061\n",
      "Epoch 67/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0022 - mae: 0.0079 - val_loss: 0.0022 - val_mae: 0.0098\n",
      "Epoch 68/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0060 - val_loss: 0.0022 - val_mae: 0.0105\n",
      "Epoch 69/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0066 - val_loss: 0.0020 - val_mae: 0.0044\n",
      "Epoch 70/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0078 - val_loss: 0.0020 - val_mae: 0.0072\n",
      "Epoch 71/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0081 - val_loss: 0.0019 - val_mae: 0.0063\n",
      "Epoch 72/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0062 - val_loss: 0.0021 - val_mae: 0.0129\n",
      "Epoch 73/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0072 - val_loss: 0.0018 - val_mae: 0.0037\n",
      "Epoch 74/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0065 - val_loss: 0.0018 - val_mae: 0.0041\n",
      "Epoch 75/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0081 - val_loss: 0.0017 - val_mae: 0.0050\n",
      "Epoch 76/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0071 - val_loss: 0.0017 - val_mae: 0.0047\n",
      "Epoch 77/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0052 - val_loss: 0.0019 - val_mae: 0.0131\n",
      "Epoch 78/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0090 - val_loss: 0.0017 - val_mae: 0.0074\n",
      "Epoch 79/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0084 - val_loss: 0.0017 - val_mae: 0.0087\n",
      "Epoch 80/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0053 - val_loss: 0.0016 - val_mae: 0.0072\n",
      "Epoch 81/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0077 - val_loss: 0.0018 - val_mae: 0.0108\n",
      "Epoch 82/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0063 - val_loss: 0.0023 - val_mae: 0.0218\n",
      "Epoch 83/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0102 - val_loss: 0.0015 - val_mae: 0.0028\n",
      "Epoch 84/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0040 - val_loss: 0.0016 - val_mae: 0.0073\n",
      "Epoch 85/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0055 - val_loss: 0.0015 - val_mae: 0.0076\n",
      "Epoch 86/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0062 - val_loss: 0.0015 - val_mae: 0.0057\n",
      "Epoch 87/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0068 - val_loss: 0.0015 - val_mae: 0.0049\n",
      "Epoch 88/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0069 - val_loss: 0.0015 - val_mae: 0.0064\n",
      "Epoch 89/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0066 - val_loss: 0.0017 - val_mae: 0.0160\n",
      "Epoch 90/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0072 - val_loss: 0.0015 - val_mae: 0.0082\n",
      "Epoch 91/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0065 - val_loss: 0.0014 - val_mae: 0.0077\n",
      "Epoch 92/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0075 - val_loss: 0.0014 - val_mae: 0.0037\n",
      "Epoch 93/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0063 - val_loss: 0.0015 - val_mae: 0.0135\n",
      "Epoch 94/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0068 - val_loss: 0.0014 - val_mae: 0.0062\n",
      "Epoch 95/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0081 - val_loss: 0.0016 - val_mae: 0.0168\n",
      "Epoch 96/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0084 - val_loss: 0.0013 - val_mae: 0.0052\n",
      "Epoch 97/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0071 - val_loss: 0.0013 - val_mae: 0.0033\n",
      "Epoch 98/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0033\n",
      "Epoch 99/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0069 - val_loss: 0.0018 - val_mae: 0.0224\n",
      "Epoch 100/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0074 - val_loss: 0.0017 - val_mae: 0.0165\n",
      "Epoch 101/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0098 - val_loss: 0.0013 - val_mae: 0.0063\n",
      "Epoch 102/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0073\n",
      "Epoch 103/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0061 - val_loss: 0.0013 - val_mae: 0.0054\n",
      "Epoch 104/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0064 - val_loss: 0.0012 - val_mae: 0.0042\n",
      "Epoch 105/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0070 - val_loss: 0.0012 - val_mae: 0.0030\n",
      "Epoch 106/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0058 - val_loss: 0.0014 - val_mae: 0.0150\n",
      "Epoch 107/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0077 - val_loss: 0.0012 - val_mae: 0.0033\n",
      "Epoch 108/1000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0066 - val_loss: 0.0012 - val_mae: 0.0068\n",
      "Epoch 109/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0059 - val_loss: 0.0014 - val_mae: 0.0125\n",
      "Epoch 110/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0080 - val_loss: 0.0012 - val_mae: 0.0039\n",
      "Epoch 111/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0056 - val_loss: 0.0012 - val_mae: 0.0084\n",
      "Epoch 112/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0056 - val_loss: 0.0013 - val_mae: 0.0092\n",
      "Epoch 113/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0105 - val_loss: 0.0012 - val_mae: 0.0070\n",
      "Epoch 114/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0054 - val_loss: 0.0012 - val_mae: 0.0045\n",
      "Epoch 115/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0072 - val_loss: 0.0013 - val_mae: 0.0094\n",
      "Epoch 116/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0066 - val_loss: 0.0012 - val_mae: 0.0084\n",
      "Epoch 117/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0056 - val_loss: 0.0011 - val_mae: 0.0037\n",
      "Epoch 118/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0065 - val_loss: 0.0012 - val_mae: 0.0078\n",
      "Epoch 119/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0087 - val_loss: 0.0013 - val_mae: 0.0114\n",
      "Epoch 120/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0048 - val_loss: 0.0012 - val_mae: 0.0068\n",
      "Epoch 121/1000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0058 - val_loss: 0.0015 - val_mae: 0.0188\n",
      "Epoch 122/1000\n",
      "158/163 [============================>.] - ETA: 0s - loss: 0.0012 - mae: 0.0061Restoring model weights from the end of the best epoch: 117.\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0060 - val_loss: 0.0013 - val_mae: 0.0130\n",
      "Epoch 122: early stopping\n",
      "Durchschnittlicher Validation Loss: 0.0012568272184580564\n",
      "Durchschnittlicher Validation MAE: 0.0030069193337112663\n"
     ]
    }
   ],
   "source": [
    "# Initialisiere Listen, um Ergebnisse zu speichern\n",
    "val_loss_results = []\n",
    "val_mae_results = []\n",
    "\n",
    "# Funktion, um das Modell zu erstellen\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "                Dense(216, activation='relu', input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "            \n",
    "                Dense(104, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "                \n",
    "                Dense(104, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "                \n",
    "                Dense(152, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "            \n",
    "                Dense(8, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "            \n",
    "                Dense(56, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "                \n",
    "                Dense(152, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "                \n",
    "                Dense(56, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "            \n",
    "                Dense(1 , activation = 'linear')\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# K-Fold Cross-Validation Konfiguration\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Leistungsüberwachung\n",
    "fold_no = 1\n",
    "for train_index, val_index in kf.split(X_train_scaled):\n",
    "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_scaled[train_index], y_train_scaled[val_index]\n",
    "\n",
    "    model = create_model()\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "    print(f'Training für Fold {fold_no}...')\n",
    "    history = model.fit(X_train_fold, y_train_fold, batch_size=100, epochs=1000, validation_data=(X_val_fold, y_val_fold), callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "    # Speichere die Ergebnisse des aktuellen Folds\n",
    "    val_loss_results.append(min(history.history['val_loss']))\n",
    "    val_mae_results.append(min(history.history['val_mae']))\n",
    "\n",
    "    fold_no += 1\n",
    "\n",
    "# Berechne den Durchschnitt über alle Folds\n",
    "average_val_loss = np.mean(val_loss_results)\n",
    "average_val_mae = np.mean(val_mae_results)\n",
    "\n",
    "# Gib die durchschnittlichen Ergebnisse aus\n",
    "print(f'Durchschnittlicher Validation Loss: {average_val_loss}')\n",
    "print(f'Durchschnittlicher Validation MAE: {average_val_mae}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T09:54:58.514856Z",
     "start_time": "2024-03-18T09:50:48.390704700Z"
    }
   },
   "id": "43f176fd515825d9"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 - 0s - loss: 3.8120e-04 - mae: 0.0016 - 134ms/epoch - 841us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.0003812041541095823, 0.0016269657062366605]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test_scaled, y_test_scaled, verbose=2)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T14:33:45.194387600Z",
     "start_time": "2024-03-19T14:33:45.022674200Z"
    }
   },
   "id": "f27ef8e901869c23"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bsp. Predicted: [1286.2167] Actual: [1286.9] \n",
      "Durchschnittliche Abweichung (MAE): [1.54203183]\n"
     ]
    }
   ],
   "source": [
    "scaled_predicted_values = model.predict(X_test_scaled, verbose = 0)\n",
    "\n",
    "# Führen Sie die Rücktransformation der skalierten Werte durch\n",
    "original_predicted_values = scaler_target.inverse_transform(scaled_predicted_values)\n",
    "original_actual_values = scaler_target.inverse_transform(y_test_scaled)  # y_test sind die skalierten tatsächlichen Werte\n",
    "print(f' Bsp. Predicted: {original_predicted_values[100]} Actual: {original_actual_values[100]} ')\n",
    "\n",
    "def calculate_mae(list1, list2):\n",
    "    # Stelle sicher, dass beide Listen die gleiche Länge haben\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Listen müssen die gleiche Länge haben\")\n",
    "\n",
    "    # Berechne die absolute Differenz zwischen den Elementen der Listen\n",
    "    differences = [abs(x - y) for x, y in zip(list1, list2)]\n",
    "\n",
    "    # Berechne den Durchschnitt der absoluten Differenzen\n",
    "    mae = sum(differences) / len(differences)\n",
    "\n",
    "    return mae\n",
    "\n",
    "# Beispiel\n",
    "list1 = original_predicted_values\n",
    "list2 = original_actual_values\n",
    "\n",
    "mae = calculate_mae(list1, list2)\n",
    "print(f\"Durchschnittliche Abweichung (MAE): {mae}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T14:33:47.762562Z",
     "start_time": "2024-03-19T14:33:47.451729900Z"
    }
   },
   "id": "b1e271125bed3df7"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: [0.99965374]\n"
     ]
    }
   ],
   "source": [
    "def calculate_r_squared(predicted, actual):\n",
    "    # Berechnung des Mittelwerts der tatsächlichen Werte\n",
    "    mean_actual = sum(actual) / len(actual)\n",
    "    \n",
    "    # Berechnung der totalen Summe der Quadrate (SST)\n",
    "    sst = sum((x - mean_actual) ** 2 for x in actual)\n",
    "    \n",
    "    # Berechnung der Summe der Quadrate der Residuen (SSE)\n",
    "    sse = sum((actual[i] - predicted[i]) ** 2 for i in range(len(actual)))\n",
    "    \n",
    "    # Berechnung des R^2-Wertes\n",
    "    r_squared = 1 - (sse / sst)\n",
    "    \n",
    "    return r_squared\n",
    "\n",
    "# Berechnung von R^2 mit den bereitgestellten Listen\n",
    "r_squared = calculate_r_squared(list1, list2)\n",
    "\n",
    "print(f\"R^2: {r_squared}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:06:06.410394700Z",
     "start_time": "2024-03-15T10:06:06.357546700Z"
    }
   },
   "id": "79a9ed0f6e7bf14e"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mae = history.history['loss']\n",
    "val_mae = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(mae) + 1)\n",
    "\n",
    "# MAE Diagramm\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, mae, 'r', label='Training MSE')\n",
    "plt.plot(epochs, val_mae, 'b', label='Validation MSE')\n",
    "plt.title('Training and Validation MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.savefig('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Bilder Diplomarbeit/MSE_NeuroNetz/MSE_NeuroNetz_D2_2')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:06:06.730178300Z",
     "start_time": "2024-03-15T10:06:06.391394200Z"
    }
   },
   "id": "3688dd7102e95baf"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9f6f672a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T10:06:06.730178300Z",
     "start_time": "2024-03-15T10:06:06.727488100Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Werte die kleiner sind: 4985\n"
     ]
    },
    {
     "data": {
      "text/plain": "            Echt  Vorhergesagt  X-Koordinate  Y-Koordinate  Differenz\n2493  801.801208        836.38         0.992         0.900 -34.578792\n2316  722.173462        755.11         0.992         0.930 -32.936538\n2187  761.990662        793.93         0.976         0.915 -31.939338\n2696  788.550903        820.06         0.976         0.905 -31.509097\n4855  695.624695        726.52         1.000         0.940 -30.895305\n...          ...           ...           ...           ...        ...\n2686  689.296997        668.83         0.952         0.000  20.466997\n2746  682.011230        661.52         0.856         0.000  20.491230\n2248  593.890991        573.33         0.984         1.000  20.560991\n1499  686.564087        665.99         0.920         0.000  20.574087\n1631  684.248901        663.16         0.888         0.000  21.088901\n\n[5066 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Echt</th>\n      <th>Vorhergesagt</th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Differenz</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2493</th>\n      <td>801.801208</td>\n      <td>836.38</td>\n      <td>0.992</td>\n      <td>0.900</td>\n      <td>-34.578792</td>\n    </tr>\n    <tr>\n      <th>2316</th>\n      <td>722.173462</td>\n      <td>755.11</td>\n      <td>0.992</td>\n      <td>0.930</td>\n      <td>-32.936538</td>\n    </tr>\n    <tr>\n      <th>2187</th>\n      <td>761.990662</td>\n      <td>793.93</td>\n      <td>0.976</td>\n      <td>0.915</td>\n      <td>-31.939338</td>\n    </tr>\n    <tr>\n      <th>2696</th>\n      <td>788.550903</td>\n      <td>820.06</td>\n      <td>0.976</td>\n      <td>0.905</td>\n      <td>-31.509097</td>\n    </tr>\n    <tr>\n      <th>4855</th>\n      <td>695.624695</td>\n      <td>726.52</td>\n      <td>1.000</td>\n      <td>0.940</td>\n      <td>-30.895305</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2686</th>\n      <td>689.296997</td>\n      <td>668.83</td>\n      <td>0.952</td>\n      <td>0.000</td>\n      <td>20.466997</td>\n    </tr>\n    <tr>\n      <th>2746</th>\n      <td>682.011230</td>\n      <td>661.52</td>\n      <td>0.856</td>\n      <td>0.000</td>\n      <td>20.491230</td>\n    </tr>\n    <tr>\n      <th>2248</th>\n      <td>593.890991</td>\n      <td>573.33</td>\n      <td>0.984</td>\n      <td>1.000</td>\n      <td>20.560991</td>\n    </tr>\n    <tr>\n      <th>1499</th>\n      <td>686.564087</td>\n      <td>665.99</td>\n      <td>0.920</td>\n      <td>0.000</td>\n      <td>20.574087</td>\n    </tr>\n    <tr>\n      <th>1631</th>\n      <td>684.248901</td>\n      <td>663.16</td>\n      <td>0.888</td>\n      <td>0.000</td>\n      <td>21.088901</td>\n    </tr>\n  </tbody>\n</table>\n<p>5066 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame({'Echt': [val[0] for val in list1], 'Vorhergesagt': [val[0] for val in list2]})\n",
    "df_result['X-Koordinate'] = X_test_scaled[:, 0]\n",
    "df_result['Y-Koordinate'] = X_test_scaled[:, 1]\n",
    "\n",
    "df_result['Differenz'] = df_result['Echt'] - df_result['Vorhergesagt']\n",
    "df_result['Differenz'].sort_values()\n",
    "sorted_df = df_result.sort_values(by= 'Differenz')\n",
    "Anzahl_Punkte = (sorted_df['Differenz'] > -10).sum()\n",
    "print(\"Anzahl der Werte die kleiner sind:\", Anzahl_Punkte)\n",
    "\n",
    "sorted_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:06:06.749329Z",
     "start_time": "2024-03-15T10:06:06.730178300Z"
    }
   },
   "id": "6a9d8a95f5e95b9"
  },
  {
   "cell_type": "markdown",
   "id": "553df6fa",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1dca80c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T10:06:06.749845900Z",
     "start_time": "2024-03-15T10:06:06.749329Z"
    }
   },
   "outputs": [],
   "source": [
    "# def build_model(learning_rate=0.001, activation='relu', regularization=0.0001, dropout_rate=0.0):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(264, activation=activation, input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(168, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(88, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(264, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(200, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     # model.add(Dense(192, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     # model.add(Dropout(dropout_rate))\n",
    "#     # \n",
    "#     # model.add(Dense(32, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     # model.add(Dropout(dropout_rate))\n",
    "#     # \n",
    "#     # model.add(Dense(448, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     # model.add(Dropout(dropout_rate))    \n",
    "#     # \n",
    "#     # model.add(Dense(64, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     # model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mae'])\n",
    "#     return model\n",
    "# \n",
    "# # Verwenden Sie eine Funktion, um das Modell zu instanziieren, für scikit-learn Wrapper\n",
    "# model = KerasRegressor(model=build_model, verbose=2)\n",
    "# \n",
    "# # Anpassung der Parameter im param_grid\n",
    "# param_grid = {\n",
    "#     'model__learning_rate': [0.01, 0.001, 0.0001],\n",
    "#     'model__regularization': [0.001, 0.0001, 0.00001],\n",
    "#     'fit__batch_size': [50, 100, 150, 200],\n",
    "#     'fit__epochs': [50],\n",
    "#     'model__dropout_rate' : [0.0, 0.1, 0.2]\n",
    "# }\n",
    "# \n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=2)\n",
    "# # Hinweis: Stellen Sie sicher, dass Ihre Daten (X_train_scaled, y_train_scaled) korrekt definiert sind\n",
    "# grid_result = grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "# # Beste Parameter und Score ausgeben\n",
    "# print(\"Beste Parameter:\", grid_search.best_params_)\n",
    "# print(\"Beste Genauigkeit:\", grid_search.best_score_)\n",
    "# \n",
    "# with open(\"Gridsearch_D2_1.txt\", \"w\") as f:\n",
    "#     f.write(f\"Beste Parameter: {grid_search.best_params_}\\n\")\n",
    "#     f.write(f\"Beste Genauigkeit: {grid_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Search Architektur"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "315c4a978449b8a5"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "# # Funktion zum Erstellen des Modells\n",
    "# def build_model(hp):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(hp.Int('input_units', min_value=8, max_value=328, step=16), input_shape=(2,), activation='relu'))\n",
    "#     for i in range(hp.Int('n_layers', 1, 10)):\n",
    "#         model.add(Dense(hp.Int(f'units_{i}', min_value=8, max_value=328, step=16), activation='relu'))\n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     return model\n",
    "# \n",
    "# # Durchführung der Random Search dreimal\n",
    "# for run in range(1, 4):\n",
    "#     # Anpassen des Verzeichnisses und des Projektnamens für jeden Durchlauf\n",
    "#     directory = 'random_search'\n",
    "#     project_name = f'random_search_D2_{run}'\n",
    "#     \n",
    "#     tuner = RandomSearch(\n",
    "#         build_model,\n",
    "#         objective='val_loss',\n",
    "#         max_trials=100,\n",
    "#         executions_per_trial=1,\n",
    "#         directory=directory,\n",
    "#         project_name=project_name\n",
    "#     )\n",
    "#     \n",
    "#     # Durchführung des Random Search\n",
    "#     tuner.search(X_train_scaled, y_train_scaled, epochs=200, verbose =0, batch_size=50, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "#     \n",
    "#     # Abrufen und Speichern des besten Modells\n",
    "#     best_model = tuner.get_best_models(num_models=1)[0]\n",
    "#     model_path = os.path.join(directory, project_name, 'best_model.h5') \n",
    "#     best_model.save(model_path)\n",
    "#     \n",
    "# \n",
    "#     # Optional: Abrufen und Ausgeben der besten Hyperparameter\n",
    "#     best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "#     \n",
    "#     # Konvertieren der Hyperparameter in ein DataFrame\n",
    "#     df_hyperparameters = pd.DataFrame([best_hyperparameters.values])\n",
    "#     # Speichern des DataFrame als CSV\n",
    "#     df_hyperparameters.to_csv(f'random_search_D2_{run}.csv', index=False)\n",
    "#     \n",
    "#     print(f\"Beste Hyperparameter für Lauf {run}: {best_hyperparameters.values}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:06:06.753891Z",
     "start_time": "2024-03-15T10:06:06.749845900Z"
    }
   },
   "id": "611306fcc5b8bde8"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:06:06.763207300Z",
     "start_time": "2024-03-15T10:06:06.753891Z"
    }
   },
   "id": "35e7cad28493cba6"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:06:06.763207300Z",
     "start_time": "2024-03-15T10:06:06.756517800Z"
    }
   },
   "id": "d4cb47043e0762a5"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:06:06.833609300Z",
     "start_time": "2024-03-15T10:06:06.758875900Z"
    }
   },
   "id": "d26a7160fe0b33a8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
