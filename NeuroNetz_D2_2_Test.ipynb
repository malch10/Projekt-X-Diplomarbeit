{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94b0518e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T12:02:26.054460600Z",
     "start_time": "2024-03-19T12:02:19.883893600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense , Dropout\n",
    "from scikeras.wrappers import KerasRegressor \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ff61b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T12:02:26.070157500Z",
     "start_time": "2024-03-19T12:02:26.056461100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n0            0.0000      -0.00200        500   7000   9000      669.05\n1            0.0000      -0.00198        500   7000   9000      682.81\n2            0.0000      -0.00196        500   7000   9000      696.80\n3            0.0000      -0.00194        500   7000   9000      710.67\n4            0.0000      -0.00192        500   7000   9000      724.42\n...             ...           ...        ...    ...    ...         ...\n25321        0.0025       0.00192        500   7000   9000      584.84\n25322        0.0025       0.00194        500   7000   9000      581.64\n25323        0.0025       0.00196        500   7000   9000      578.47\n25324        0.0025       0.00198        500   7000   9000      575.32\n25325        0.0025       0.00200        500   7000   9000      572.20\n\n[25326 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>669.05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0000</td>\n      <td>-0.00198</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>682.81</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0000</td>\n      <td>-0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>696.80</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0000</td>\n      <td>-0.00194</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>710.67</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0000</td>\n      <td>-0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>724.42</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25321</th>\n      <td>0.0025</td>\n      <td>0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>584.84</td>\n    </tr>\n    <tr>\n      <th>25322</th>\n      <td>0.0025</td>\n      <td>0.00194</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>581.64</td>\n    </tr>\n    <tr>\n      <th>25323</th>\n      <td>0.0025</td>\n      <td>0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>578.47</td>\n    </tr>\n    <tr>\n      <th>25324</th>\n      <td>0.0025</td>\n      <td>0.00198</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>575.32</td>\n    </tr>\n    <tr>\n      <th>25325</th>\n      <td>0.0025</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>572.20</td>\n    </tr>\n  </tbody>\n</table>\n<p>25326 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/TPath_300_finish_data.pkl')\n",
    "data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_D2_I7000_F9000/TPath_500_finish_data_D2.pkl')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "966e3c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T12:02:26.085899800Z",
     "start_time": "2024-03-19T12:02:26.070157500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       X-Koordinate  Y-Koordinate  Temperatur\n0            0.0000      -0.00200      669.05\n1            0.0000      -0.00198      682.81\n2            0.0000      -0.00196      696.80\n3            0.0000      -0.00194      710.67\n4            0.0000      -0.00192      724.42\n...             ...           ...         ...\n25321        0.0025       0.00192      584.84\n25322        0.0025       0.00194      581.64\n25323        0.0025       0.00196      578.47\n25324        0.0025       0.00198      575.32\n25325        0.0025       0.00200      572.20\n\n[25326 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>669.05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0000</td>\n      <td>-0.00198</td>\n      <td>682.81</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0000</td>\n      <td>-0.00196</td>\n      <td>696.80</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0000</td>\n      <td>-0.00194</td>\n      <td>710.67</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0000</td>\n      <td>-0.00192</td>\n      <td>724.42</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25321</th>\n      <td>0.0025</td>\n      <td>0.00192</td>\n      <td>584.84</td>\n    </tr>\n    <tr>\n      <th>25322</th>\n      <td>0.0025</td>\n      <td>0.00194</td>\n      <td>581.64</td>\n    </tr>\n    <tr>\n      <th>25323</th>\n      <td>0.0025</td>\n      <td>0.00196</td>\n      <td>578.47</td>\n    </tr>\n    <tr>\n      <th>25324</th>\n      <td>0.0025</td>\n      <td>0.00198</td>\n      <td>575.32</td>\n    </tr>\n    <tr>\n      <th>25325</th>\n      <td>0.0025</td>\n      <td>0.00200</td>\n      <td>572.20</td>\n    </tr>\n  </tbody>\n</table>\n<p>25326 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.drop(data.columns[2:5], axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8783d1d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T12:02:26.121633900Z",
     "start_time": "2024-03-19T12:02:26.079900500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       X-Koordinate  Y-Koordinate  Temperatur\n",
      "5099        0.00050      -0.00052     1471.00\n",
      "12799       0.00126       0.00072     1319.30\n",
      "15071       0.00148       0.00194      595.19\n",
      "24620       0.00244      -0.00004     1249.00\n",
      "11071       0.00110      -0.00168      884.35\n",
      "...             ...           ...         ...\n",
      "21575       0.00214      -0.00064     1263.60\n",
      "5390        0.00052       0.00128     1035.40\n",
      "860         0.00008      -0.00088     1376.50\n",
      "15795       0.00156       0.00034     1383.80\n",
      "23654       0.00234       0.00074     1149.60\n",
      "\n",
      "[25326 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": "       X-Koordinate  Y-Koordinate  Temperatur\n0           0.00050      -0.00052     1471.00\n1           0.00126       0.00072     1319.30\n2           0.00148       0.00194      595.19\n3           0.00244      -0.00004     1249.00\n4           0.00110      -0.00168      884.35\n...             ...           ...         ...\n25321       0.00214      -0.00064     1263.60\n25322       0.00052       0.00128     1035.40\n25323       0.00008      -0.00088     1376.50\n25324       0.00156       0.00034     1383.80\n25325       0.00234       0.00074     1149.60\n\n[25326 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00050</td>\n      <td>-0.00052</td>\n      <td>1471.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00126</td>\n      <td>0.00072</td>\n      <td>1319.30</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00148</td>\n      <td>0.00194</td>\n      <td>595.19</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00244</td>\n      <td>-0.00004</td>\n      <td>1249.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00110</td>\n      <td>-0.00168</td>\n      <td>884.35</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25321</th>\n      <td>0.00214</td>\n      <td>-0.00064</td>\n      <td>1263.60</td>\n    </tr>\n    <tr>\n      <th>25322</th>\n      <td>0.00052</td>\n      <td>0.00128</td>\n      <td>1035.40</td>\n    </tr>\n    <tr>\n      <th>25323</th>\n      <td>0.00008</td>\n      <td>-0.00088</td>\n      <td>1376.50</td>\n    </tr>\n    <tr>\n      <th>25324</th>\n      <td>0.00156</td>\n      <td>0.00034</td>\n      <td>1383.80</td>\n    </tr>\n    <tr>\n      <th>25325</th>\n      <td>0.00234</td>\n      <td>0.00074</td>\n      <td>1149.60</td>\n    </tr>\n  </tbody>\n</table>\n<p>25326 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.sample(frac=1, random_state=42)  # Hier wird 42 als Random State verwendet, um die Ergebnisse reproduzierbar zu machen\n",
    "\n",
    "print(df1)\n",
    "df_reset = df1.reset_index(drop=True)\n",
    "df_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4e72a16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T12:02:26.148112200Z",
     "start_time": "2024-03-19T12:02:26.093173900Z"
    }
   },
   "outputs": [],
   "source": [
    "label = df_reset[\"Temperatur\"]\n",
    "# Korrektur: Verwenden Sie den Spaltennamen direkt, ohne Indexierung der columns-Eigenschaft\n",
    "df1 = df_reset.drop(\"Temperatur\", axis=1)\n",
    "X = df1\n",
    "y = label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7fa289a50d87423"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e694a236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T12:02:26.196111100Z",
     "start_time": "2024-03-19T12:02:26.098707100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       X-Koordinate  Y-Koordinate\n0           0.00050      -0.00052\n1           0.00126       0.00072\n2           0.00148       0.00194\n3           0.00244      -0.00004\n4           0.00110      -0.00168\n...             ...           ...\n25321       0.00214      -0.00064\n25322       0.00052       0.00128\n25323       0.00008      -0.00088\n25324       0.00156       0.00034\n25325       0.00234       0.00074\n\n[25326 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00050</td>\n      <td>-0.00052</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00126</td>\n      <td>0.00072</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00148</td>\n      <td>0.00194</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00244</td>\n      <td>-0.00004</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00110</td>\n      <td>-0.00168</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25321</th>\n      <td>0.00214</td>\n      <td>-0.00064</td>\n    </tr>\n    <tr>\n      <th>25322</th>\n      <td>0.00052</td>\n      <td>0.00128</td>\n    </tr>\n    <tr>\n      <th>25323</th>\n      <td>0.00008</td>\n      <td>-0.00088</td>\n    </tr>\n    <tr>\n      <th>25324</th>\n      <td>0.00156</td>\n      <td>0.00034</td>\n    </tr>\n    <tr>\n      <th>25325</th>\n      <td>0.00234</td>\n      <td>0.00074</td>\n    </tr>\n  </tbody>\n</table>\n<p>25326 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f3303b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T12:02:26.196111100Z",
     "start_time": "2024-03-19T12:02:26.105540700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0        1471.00\n1        1319.30\n2         595.19\n3        1249.00\n4         884.35\n          ...   \n25321    1263.60\n25322    1035.40\n25323    1376.50\n25324    1383.80\n25325    1149.60\nName: Temperatur, Length: 25326, dtype: float64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3ad8da0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T12:02:26.196111100Z",
     "start_time": "2024-03-19T12:02:26.112798700Z"
    }
   },
   "outputs": [],
   "source": [
    " # train_df enthält 80% der Daten, test_df enthält 20% der Daten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c705edb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T12:02:26.274112100Z",
     "start_time": "2024-03-19T12:02:26.121633900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialisiere einen MinMaxScaler für die Features\n",
    "scaler_features = MinMaxScaler()\n",
    "scaler_features2 = MinMaxScaler()\n",
    "# Skaliere X_train und X_test\n",
    "X_train_scaled = scaler_features.fit_transform(X_train)\n",
    "X_test_scaled = scaler_features.transform(X_test)  # Nutze unterschiedliche Skalierungsparameter\n",
    "\n",
    "# Initialisiere einen SEPARATEN MinMaxScaler für das Ziel, wenn nötig\n",
    "scaler_target = MinMaxScaler()\n",
    "\n",
    "\n",
    "# Skaliere y_train und y_test. Beachte, dass y_train.reshape(-1, 1) verwendet wird, da MinMaxScaler \n",
    "# erwartet, dass die Eingaben als 2D-Arrays kommen, und Ziele normalerweise als 1D-Arrays vorliegen.\n",
    "y_train_scaled = scaler_target.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test_scaled = scaler_target.transform(y_test.values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbefe631e495b483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T12:02:26.276110700Z",
     "start_time": "2024-03-19T12:02:26.128900600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.   , 0.15 ],\n       [0.984, 0.49 ],\n       [0.224, 0.905],\n       ...,\n       [0.04 , 0.585],\n       [0.976, 0.815],\n       [0.744, 0.785]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Netzwerkarchitektur"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d664797f8dcbd88c"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "163/163 [==============================] - 2s 3ms/step - loss: 0.1054 - mae: 0.2319 - val_loss: 0.0521 - val_mae: 0.1348\n",
      "Epoch 2/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0221 - mae: 0.0575 - val_loss: 0.0161 - val_mae: 0.0261\n",
      "Epoch 3/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0153 - mae: 0.0192 - val_loss: 0.0147 - val_mae: 0.0169\n",
      "Epoch 4/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0142 - mae: 0.0123 - val_loss: 0.0141 - val_mae: 0.0163\n",
      "Epoch 5/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0112 - val_loss: 0.0139 - val_mae: 0.0212\n",
      "Epoch 6/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0130 - mae: 0.0093 - val_loss: 0.0129 - val_mae: 0.0106\n",
      "Epoch 7/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0126 - mae: 0.0085 - val_loss: 0.0131 - val_mae: 0.0211\n",
      "Epoch 8/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0122 - mae: 0.0085 - val_loss: 0.0129 - val_mae: 0.0239\n",
      "Epoch 9/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0124 - mae: 0.0150 - val_loss: 0.0126 - val_mae: 0.0244\n",
      "Epoch 10/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0117 - mae: 0.0094 - val_loss: 0.0117 - val_mae: 0.0127\n",
      "Epoch 11/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0114 - mae: 0.0073 - val_loss: 0.0112 - val_mae: 0.0049\n",
      "Epoch 12/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0112 - mae: 0.0073 - val_loss: 0.0112 - val_mae: 0.0092\n",
      "Epoch 13/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0112 - mae: 0.0101 - val_loss: 0.0111 - val_mae: 0.0107\n",
      "Epoch 14/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0111 - mae: 0.0120 - val_loss: 0.0116 - val_mae: 0.0236\n",
      "Epoch 15/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0112 - mae: 0.0140 - val_loss: 0.0107 - val_mae: 0.0095\n",
      "Epoch 16/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0106 - mae: 0.0061 - val_loss: 0.0105 - val_mae: 0.0079\n",
      "Epoch 17/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0057 - val_loss: 0.0105 - val_mae: 0.0083\n",
      "Epoch 18/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0105 - mae: 0.0098 - val_loss: 0.0103 - val_mae: 0.0075\n",
      "Epoch 19/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0073 - val_loss: 0.0102 - val_mae: 0.0069\n",
      "Epoch 20/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0107 - val_loss: 0.0102 - val_mae: 0.0100\n",
      "Epoch 21/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0072 - val_loss: 0.0101 - val_mae: 0.0106\n",
      "Epoch 22/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0097 - val_loss: 0.0099 - val_mae: 0.0093\n",
      "Epoch 23/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0079 - val_loss: 0.0099 - val_mae: 0.0087\n",
      "Epoch 24/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0105 - val_loss: 0.0097 - val_mae: 0.0045\n",
      "Epoch 25/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0097 - mae: 0.0061 - val_loss: 0.0097 - val_mae: 0.0098\n",
      "Epoch 26/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0097 - mae: 0.0077 - val_loss: 0.0096 - val_mae: 0.0056\n",
      "Epoch 27/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0096 - mae: 0.0086 - val_loss: 0.0097 - val_mae: 0.0121\n",
      "Epoch 28/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0097 - mae: 0.0110 - val_loss: 0.0094 - val_mae: 0.0074\n",
      "Epoch 29/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0094 - mae: 0.0057 - val_loss: 0.0094 - val_mae: 0.0070\n",
      "Epoch 30/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0096 - mae: 0.0108 - val_loss: 0.0113 - val_mae: 0.0345\n",
      "Epoch 31/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0094 - mae: 0.0088 - val_loss: 0.0092 - val_mae: 0.0066\n",
      "Epoch 32/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0091 - mae: 0.0048 - val_loss: 0.0091 - val_mae: 0.0038\n",
      "Epoch 33/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0091 - mae: 0.0067 - val_loss: 0.0093 - val_mae: 0.0142\n",
      "Epoch 34/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0091 - mae: 0.0090 - val_loss: 0.0093 - val_mae: 0.0159\n",
      "Epoch 35/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0090 - mae: 0.0075 - val_loss: 0.0106 - val_mae: 0.0306\n",
      "Epoch 36/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0086 - val_loss: 0.0090 - val_mae: 0.0078\n",
      "Epoch 37/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0089 - mae: 0.0065 - val_loss: 0.0088 - val_mae: 0.0051\n",
      "Epoch 38/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0091 - mae: 0.0125 - val_loss: 0.0089 - val_mae: 0.0087\n",
      "Epoch 39/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0089 - mae: 0.0099 - val_loss: 0.0089 - val_mae: 0.0123\n",
      "Epoch 40/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0087 - mae: 0.0062 - val_loss: 0.0086 - val_mae: 0.0064\n",
      "Epoch 41/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0086 - mae: 0.0046 - val_loss: 0.0086 - val_mae: 0.0070\n",
      "Epoch 42/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0088 - mae: 0.0110 - val_loss: 0.0085 - val_mae: 0.0033\n",
      "Epoch 43/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0085 - mae: 0.0051 - val_loss: 0.0084 - val_mae: 0.0036\n",
      "Epoch 44/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0086 - mae: 0.0091 - val_loss: 0.0084 - val_mae: 0.0055\n",
      "Epoch 45/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0084 - mae: 0.0061 - val_loss: 0.0083 - val_mae: 0.0036\n",
      "Epoch 46/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0083 - mae: 0.0050 - val_loss: 0.0083 - val_mae: 0.0075\n",
      "Epoch 47/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0088 - mae: 0.0146 - val_loss: 0.0085 - val_mae: 0.0124\n",
      "Epoch 48/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0082 - mae: 0.0051 - val_loss: 0.0082 - val_mae: 0.0037\n",
      "Epoch 49/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0082 - mae: 0.0050 - val_loss: 0.0082 - val_mae: 0.0076\n",
      "Epoch 50/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0081 - mae: 0.0064 - val_loss: 0.0088 - val_mae: 0.0207\n",
      "Epoch 51/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0082 - mae: 0.0094 - val_loss: 0.0080 - val_mae: 0.0034\n",
      "Epoch 52/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0080 - mae: 0.0046 - val_loss: 0.0080 - val_mae: 0.0058\n",
      "Epoch 53/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0080 - mae: 0.0059 - val_loss: 0.0080 - val_mae: 0.0075\n",
      "Epoch 54/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0079 - mae: 0.0050 - val_loss: 0.0081 - val_mae: 0.0122\n",
      "Epoch 55/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0080 - mae: 0.0086 - val_loss: 0.0080 - val_mae: 0.0116\n",
      "Epoch 56/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0078 - mae: 0.0046 - val_loss: 0.0079 - val_mae: 0.0074\n",
      "Epoch 57/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0078 - mae: 0.0052 - val_loss: 0.0087 - val_mae: 0.0226\n",
      "Epoch 58/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0080 - mae: 0.0098 - val_loss: 0.0078 - val_mae: 0.0070\n",
      "Epoch 59/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0077 - mae: 0.0060 - val_loss: 0.0077 - val_mae: 0.0067\n",
      "Epoch 60/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0077 - mae: 0.0049 - val_loss: 0.0077 - val_mae: 0.0067\n",
      "Epoch 61/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0076 - mae: 0.0056 - val_loss: 0.0096 - val_mae: 0.0318\n",
      "Epoch 62/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0078 - mae: 0.0094 - val_loss: 0.0088 - val_mae: 0.0275\n",
      "Epoch 63/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0077 - mae: 0.0080 - val_loss: 0.0075 - val_mae: 0.0035\n",
      "Epoch 64/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0075 - mae: 0.0039 - val_loss: 0.0075 - val_mae: 0.0036\n",
      "Epoch 65/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0076 - mae: 0.0080 - val_loss: 0.0074 - val_mae: 0.0046\n",
      "Epoch 66/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0074 - mae: 0.0048 - val_loss: 0.0078 - val_mae: 0.0157\n",
      "Epoch 67/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0075 - mae: 0.0073 - val_loss: 0.0074 - val_mae: 0.0039\n",
      "Epoch 68/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0074 - mae: 0.0053 - val_loss: 0.0073 - val_mae: 0.0043\n",
      "Epoch 69/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0076 - mae: 0.0104 - val_loss: 0.0074 - val_mae: 0.0070\n",
      "Epoch 70/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0073 - mae: 0.0041 - val_loss: 0.0074 - val_mae: 0.0089\n",
      "Epoch 71/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0073 - mae: 0.0053 - val_loss: 0.0073 - val_mae: 0.0058\n",
      "Epoch 72/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0073 - mae: 0.0056 - val_loss: 0.0073 - val_mae: 0.0071\n",
      "Epoch 73/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0072 - mae: 0.0056 - val_loss: 0.0074 - val_mae: 0.0134\n",
      "Epoch 74/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0074 - mae: 0.0097 - val_loss: 0.0077 - val_mae: 0.0171\n",
      "Epoch 75/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0072 - mae: 0.0063 - val_loss: 0.0071 - val_mae: 0.0049\n",
      "Epoch 76/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0071 - mae: 0.0040 - val_loss: 0.0073 - val_mae: 0.0119\n",
      "Epoch 77/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0071 - mae: 0.0072 - val_loss: 0.0074 - val_mae: 0.0157\n",
      "Epoch 78/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0071 - mae: 0.0064 - val_loss: 0.0070 - val_mae: 0.0046\n",
      "Epoch 79/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0071 - mae: 0.0070 - val_loss: 0.0070 - val_mae: 0.0056\n",
      "Epoch 80/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0070 - mae: 0.0047 - val_loss: 0.0071 - val_mae: 0.0102\n",
      "Epoch 81/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0070 - mae: 0.0069 - val_loss: 0.0071 - val_mae: 0.0098\n",
      "Epoch 82/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0074 - mae: 0.0137 - val_loss: 0.0070 - val_mae: 0.0073\n",
      "Epoch 83/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0069 - mae: 0.0037 - val_loss: 0.0069 - val_mae: 0.0056\n",
      "Epoch 84/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0069 - mae: 0.0038 - val_loss: 0.0069 - val_mae: 0.0034\n",
      "Epoch 85/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0069 - mae: 0.0051 - val_loss: 0.0068 - val_mae: 0.0037\n",
      "Epoch 86/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0068 - mae: 0.0036 - val_loss: 0.0068 - val_mae: 0.0030\n",
      "Epoch 87/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0068 - mae: 0.0045 - val_loss: 0.0068 - val_mae: 0.0038\n",
      "Epoch 88/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0069 - mae: 0.0069 - val_loss: 0.0069 - val_mae: 0.0097\n",
      "Epoch 89/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0068 - mae: 0.0068 - val_loss: 0.0072 - val_mae: 0.0161\n",
      "Epoch 90/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0069 - mae: 0.0095 - val_loss: 0.0069 - val_mae: 0.0081\n",
      "Epoch 91/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0067 - mae: 0.0047 - val_loss: 0.0067 - val_mae: 0.0031\n",
      "Epoch 92/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0067 - mae: 0.0045 - val_loss: 0.0067 - val_mae: 0.0046\n",
      "Epoch 93/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0067 - mae: 0.0043 - val_loss: 0.0067 - val_mae: 0.0065\n",
      "Epoch 94/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0067 - mae: 0.0044 - val_loss: 0.0067 - val_mae: 0.0049\n",
      "Epoch 95/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0067 - mae: 0.0051 - val_loss: 0.0068 - val_mae: 0.0121\n",
      "Epoch 96/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0068 - mae: 0.0095 - val_loss: 0.0067 - val_mae: 0.0096\n",
      "Epoch 97/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0066 - mae: 0.0050 - val_loss: 0.0066 - val_mae: 0.0060\n",
      "Epoch 98/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0066 - mae: 0.0046 - val_loss: 0.0065 - val_mae: 0.0030\n",
      "Epoch 99/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0066 - mae: 0.0057 - val_loss: 0.0066 - val_mae: 0.0086\n",
      "Epoch 100/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0066 - mae: 0.0057 - val_loss: 0.0067 - val_mae: 0.0132\n",
      "Epoch 101/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0066 - mae: 0.0074 - val_loss: 0.0065 - val_mae: 0.0070\n",
      "Epoch 102/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0066 - mae: 0.0080 - val_loss: 0.0075 - val_mae: 0.0265\n",
      "Epoch 103/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0065 - mae: 0.0060 - val_loss: 0.0065 - val_mae: 0.0053\n",
      "Epoch 104/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0065 - mae: 0.0056 - val_loss: 0.0064 - val_mae: 0.0047\n",
      "Epoch 105/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0064 - mae: 0.0041 - val_loss: 0.0067 - val_mae: 0.0129\n",
      "Epoch 106/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0065 - mae: 0.0078 - val_loss: 0.0066 - val_mae: 0.0119\n",
      "Epoch 107/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0065 - mae: 0.0069 - val_loss: 0.0064 - val_mae: 0.0039\n",
      "Epoch 108/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0064 - mae: 0.0037 - val_loss: 0.0063 - val_mae: 0.0031\n",
      "Epoch 109/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0064 - mae: 0.0055 - val_loss: 0.0063 - val_mae: 0.0040\n",
      "Epoch 110/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0063 - mae: 0.0036 - val_loss: 0.0068 - val_mae: 0.0171\n",
      "Epoch 111/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0064 - mae: 0.0058 - val_loss: 0.0063 - val_mae: 0.0046\n",
      "Epoch 112/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0063 - mae: 0.0054 - val_loss: 0.0064 - val_mae: 0.0080\n",
      "Epoch 113/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0063 - mae: 0.0054 - val_loss: 0.0064 - val_mae: 0.0095\n",
      "Epoch 114/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0064 - mae: 0.0087 - val_loss: 0.0062 - val_mae: 0.0036\n",
      "Epoch 115/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0063 - mae: 0.0076 - val_loss: 0.0063 - val_mae: 0.0097\n",
      "Epoch 116/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0062 - mae: 0.0053 - val_loss: 0.0062 - val_mae: 0.0056\n",
      "Epoch 117/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0062 - mae: 0.0045 - val_loss: 0.0062 - val_mae: 0.0049\n",
      "Epoch 118/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0063 - mae: 0.0074 - val_loss: 0.0063 - val_mae: 0.0078\n",
      "Epoch 119/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0062 - mae: 0.0036 - val_loss: 0.0062 - val_mae: 0.0060\n",
      "Epoch 120/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0062 - mae: 0.0047 - val_loss: 0.0061 - val_mae: 0.0037\n",
      "Epoch 121/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0061 - mae: 0.0046 - val_loss: 0.0061 - val_mae: 0.0048\n",
      "Epoch 122/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0061 - mae: 0.0048 - val_loss: 0.0061 - val_mae: 0.0028\n",
      "Epoch 123/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0061 - mae: 0.0047 - val_loss: 0.0061 - val_mae: 0.0057\n",
      "Epoch 124/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0061 - mae: 0.0051 - val_loss: 0.0062 - val_mae: 0.0102\n",
      "Epoch 125/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0061 - mae: 0.0043 - val_loss: 0.0060 - val_mae: 0.0032\n",
      "Epoch 126/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0063 - mae: 0.0105 - val_loss: 0.0062 - val_mae: 0.0112\n",
      "Epoch 127/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0060 - mae: 0.0038 - val_loss: 0.0060 - val_mae: 0.0046\n",
      "Epoch 128/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0060 - mae: 0.0048 - val_loss: 0.0060 - val_mae: 0.0045\n",
      "Epoch 129/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0060 - mae: 0.0040 - val_loss: 0.0060 - val_mae: 0.0047\n",
      "Epoch 130/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0060 - mae: 0.0048 - val_loss: 0.0060 - val_mae: 0.0029\n",
      "Epoch 131/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0060 - mae: 0.0039 - val_loss: 0.0060 - val_mae: 0.0052\n",
      "Epoch 132/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0065 - mae: 0.0155 - val_loss: 0.0059 - val_mae: 0.0040\n",
      "Epoch 133/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0059 - mae: 0.0030 - val_loss: 0.0059 - val_mae: 0.0031\n",
      "Epoch 134/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0059 - mae: 0.0031 - val_loss: 0.0060 - val_mae: 0.0062\n",
      "Epoch 135/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0059 - mae: 0.0031 - val_loss: 0.0059 - val_mae: 0.0028\n",
      "Epoch 136/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0059 - mae: 0.0028 - val_loss: 0.0059 - val_mae: 0.0064\n",
      "Epoch 137/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0059 - mae: 0.0035 - val_loss: 0.0059 - val_mae: 0.0043\n",
      "Epoch 138/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0059 - mae: 0.0031 - val_loss: 0.0058 - val_mae: 0.0029\n",
      "Epoch 139/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0059 - mae: 0.0043 - val_loss: 0.0061 - val_mae: 0.0129\n",
      "Epoch 140/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0060 - mae: 0.0089 - val_loss: 0.0058 - val_mae: 0.0036\n",
      "Epoch 141/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0058 - mae: 0.0029 - val_loss: 0.0058 - val_mae: 0.0026\n",
      "Epoch 142/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0058 - mae: 0.0034 - val_loss: 0.0059 - val_mae: 0.0076\n",
      "Epoch 143/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0058 - mae: 0.0031 - val_loss: 0.0058 - val_mae: 0.0033\n",
      "Epoch 144/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0058 - mae: 0.0041 - val_loss: 0.0058 - val_mae: 0.0040\n",
      "Epoch 145/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0058 - mae: 0.0073 - val_loss: 0.0060 - val_mae: 0.0136\n",
      "Epoch 146/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0058 - mae: 0.0051 - val_loss: 0.0057 - val_mae: 0.0038\n",
      "Epoch 147/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0057 - mae: 0.0041 - val_loss: 0.0058 - val_mae: 0.0085\n",
      "Epoch 148/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0058 - mae: 0.0056 - val_loss: 0.0060 - val_mae: 0.0136\n",
      "Epoch 149/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0058 - mae: 0.0067 - val_loss: 0.0057 - val_mae: 0.0026\n",
      "Epoch 150/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0057 - mae: 0.0039 - val_loss: 0.0058 - val_mae: 0.0090\n",
      "Epoch 151/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0057 - mae: 0.0041 - val_loss: 0.0057 - val_mae: 0.0055\n",
      "Epoch 152/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0057 - mae: 0.0044 - val_loss: 0.0057 - val_mae: 0.0078\n",
      "Epoch 153/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0056 - mae: 0.0042 - val_loss: 0.0063 - val_mae: 0.0204\n",
      "Epoch 154/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0057 - mae: 0.0064 - val_loss: 0.0058 - val_mae: 0.0125\n",
      "Epoch 155/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0056 - mae: 0.0042 - val_loss: 0.0056 - val_mae: 0.0031\n",
      "Epoch 156/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0056 - mae: 0.0043 - val_loss: 0.0057 - val_mae: 0.0080\n",
      "Epoch 157/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0057 - mae: 0.0076 - val_loss: 0.0056 - val_mae: 0.0076\n",
      "Epoch 158/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0031 - val_loss: 0.0056 - val_mae: 0.0055\n",
      "Epoch 159/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0032 - val_loss: 0.0058 - val_mae: 0.0128\n",
      "Epoch 160/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0047 - val_loss: 0.0055 - val_mae: 0.0030\n",
      "Epoch 161/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0050 - val_loss: 0.0055 - val_mae: 0.0061\n",
      "Epoch 162/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0033 - val_loss: 0.0055 - val_mae: 0.0033\n",
      "Epoch 163/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0039 - val_loss: 0.0059 - val_mae: 0.0158\n",
      "Epoch 164/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0052 - val_loss: 0.0054 - val_mae: 0.0021\n",
      "Epoch 165/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0038 - val_loss: 0.0055 - val_mae: 0.0054\n",
      "Epoch 166/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0054 - mae: 0.0036 - val_loss: 0.0054 - val_mae: 0.0029\n",
      "Epoch 167/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0064 - val_loss: 0.0054 - val_mae: 0.0059\n",
      "Epoch 168/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0056 - mae: 0.0100 - val_loss: 0.0054 - val_mae: 0.0045\n",
      "Epoch 169/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0054 - mae: 0.0035 - val_loss: 0.0054 - val_mae: 0.0028\n",
      "Epoch 170/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0054 - mae: 0.0024 - val_loss: 0.0054 - val_mae: 0.0029\n",
      "Epoch 171/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0053 - mae: 0.0029 - val_loss: 0.0054 - val_mae: 0.0076\n",
      "Epoch 172/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0053 - mae: 0.0030 - val_loss: 0.0053 - val_mae: 0.0039\n",
      "Epoch 173/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0053 - mae: 0.0030 - val_loss: 0.0053 - val_mae: 0.0021\n",
      "Epoch 174/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0053 - mae: 0.0047 - val_loss: 0.0054 - val_mae: 0.0089\n",
      "Epoch 175/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0053 - mae: 0.0046 - val_loss: 0.0062 - val_mae: 0.0230\n",
      "Epoch 176/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0053 - mae: 0.0046 - val_loss: 0.0053 - val_mae: 0.0030\n",
      "Epoch 177/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0053 - mae: 0.0033 - val_loss: 0.0053 - val_mae: 0.0045\n",
      "Epoch 178/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0053 - mae: 0.0041 - val_loss: 0.0054 - val_mae: 0.0087\n",
      "Epoch 179/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0040 - val_loss: 0.0058 - val_mae: 0.0184\n",
      "Epoch 180/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0054 - mae: 0.0074 - val_loss: 0.0052 - val_mae: 0.0023\n",
      "Epoch 181/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0026 - val_loss: 0.0052 - val_mae: 0.0023\n",
      "Epoch 182/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0030 - val_loss: 0.0052 - val_mae: 0.0076\n",
      "Epoch 183/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0034 - val_loss: 0.0056 - val_mae: 0.0152\n",
      "Epoch 184/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0067 - val_loss: 0.0051 - val_mae: 0.0026\n",
      "Epoch 185/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0051 - mae: 0.0032 - val_loss: 0.0052 - val_mae: 0.0064\n",
      "Epoch 186/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0051 - mae: 0.0034 - val_loss: 0.0067 - val_mae: 0.0280\n",
      "Epoch 187/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0053 - mae: 0.0078 - val_loss: 0.0051 - val_mae: 0.0024\n",
      "Epoch 188/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0051 - mae: 0.0023 - val_loss: 0.0053 - val_mae: 0.0099\n",
      "Epoch 189/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0051 - mae: 0.0029 - val_loss: 0.0051 - val_mae: 0.0032\n",
      "Epoch 190/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0051 - mae: 0.0024 - val_loss: 0.0051 - val_mae: 0.0021\n",
      "Epoch 191/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0051 - mae: 0.0026 - val_loss: 0.0051 - val_mae: 0.0067\n",
      "Epoch 192/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0051 - mae: 0.0040 - val_loss: 0.0057 - val_mae: 0.0181\n",
      "Epoch 193/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0051 - mae: 0.0054 - val_loss: 0.0050 - val_mae: 0.0021\n",
      "Epoch 194/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0050 - mae: 0.0033 - val_loss: 0.0050 - val_mae: 0.0022\n",
      "Epoch 195/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0040 - val_loss: 0.0050 - val_mae: 0.0036\n",
      "Epoch 196/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0031 - val_loss: 0.0051 - val_mae: 0.0107\n",
      "Epoch 197/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0045 - val_loss: 0.0053 - val_mae: 0.0121\n",
      "Epoch 198/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0042 - val_loss: 0.0051 - val_mae: 0.0105\n",
      "Epoch 199/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0046 - val_loss: 0.0050 - val_mae: 0.0052\n",
      "Epoch 200/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0040 - val_loss: 0.0049 - val_mae: 0.0045\n",
      "Epoch 201/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0033 - val_loss: 0.0049 - val_mae: 0.0045\n",
      "Epoch 202/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0043 - val_loss: 0.0049 - val_mae: 0.0031\n",
      "Epoch 203/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0038 - val_loss: 0.0049 - val_mae: 0.0028\n",
      "Epoch 204/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0046 - val_loss: 0.0051 - val_mae: 0.0118\n",
      "Epoch 205/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0044 - val_loss: 0.0052 - val_mae: 0.0147\n",
      "Epoch 206/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0050 - val_loss: 0.0048 - val_mae: 0.0021\n",
      "Epoch 207/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0052 - val_loss: 0.0048 - val_mae: 0.0046\n",
      "Epoch 208/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0034 - val_loss: 0.0049 - val_mae: 0.0064\n",
      "Epoch 209/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0033 - val_loss: 0.0048 - val_mae: 0.0033\n",
      "Epoch 210/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0035 - val_loss: 0.0048 - val_mae: 0.0033\n",
      "Epoch 211/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0031 - val_loss: 0.0052 - val_mae: 0.0155\n",
      "Epoch 212/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0041 - val_loss: 0.0048 - val_mae: 0.0059\n",
      "Epoch 213/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0041 - val_loss: 0.0048 - val_mae: 0.0045\n",
      "Epoch 214/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0047 - mae: 0.0028 - val_loss: 0.0048 - val_mae: 0.0047\n",
      "Epoch 215/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0047 - mae: 0.0035 - val_loss: 0.0049 - val_mae: 0.0106\n",
      "Epoch 216/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0061 - val_loss: 0.0047 - val_mae: 0.0039\n",
      "Epoch 217/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0047 - mae: 0.0027 - val_loss: 0.0047 - val_mae: 0.0033\n",
      "Epoch 218/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0047 - mae: 0.0029 - val_loss: 0.0048 - val_mae: 0.0084\n",
      "Epoch 219/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0047 - mae: 0.0043 - val_loss: 0.0047 - val_mae: 0.0023\n",
      "Epoch 220/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0047 - mae: 0.0024 - val_loss: 0.0047 - val_mae: 0.0059\n",
      "Epoch 221/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0030 - val_loss: 0.0047 - val_mae: 0.0058\n",
      "Epoch 222/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0047 - mae: 0.0050 - val_loss: 0.0046 - val_mae: 0.0025\n",
      "Epoch 223/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0035 - val_loss: 0.0047 - val_mae: 0.0078\n",
      "Epoch 224/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0047 - val_loss: 0.0046 - val_mae: 0.0063\n",
      "Epoch 225/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0050 - val_loss: 0.0046 - val_mae: 0.0031\n",
      "Epoch 226/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0029 - val_loss: 0.0046 - val_mae: 0.0026\n",
      "Epoch 227/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0023 - val_loss: 0.0045 - val_mae: 0.0023\n",
      "Epoch 228/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0036 - val_loss: 0.0047 - val_mae: 0.0090\n",
      "Epoch 229/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0051 - val_loss: 0.0046 - val_mae: 0.0072\n",
      "Epoch 230/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0036 - val_loss: 0.0045 - val_mae: 0.0025\n",
      "Epoch 231/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0031 - val_loss: 0.0046 - val_mae: 0.0065\n",
      "Epoch 232/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0054 - val_loss: 0.0046 - val_mae: 0.0075\n",
      "Epoch 233/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0028 - val_loss: 0.0045 - val_mae: 0.0054\n",
      "Epoch 234/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0032 - val_loss: 0.0045 - val_mae: 0.0061\n",
      "Epoch 235/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0042 - val_loss: 0.0045 - val_mae: 0.0057\n",
      "Epoch 236/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0028 - val_loss: 0.0045 - val_mae: 0.0053\n",
      "Epoch 237/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0026 - val_loss: 0.0045 - val_mae: 0.0062\n",
      "Epoch 238/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0034 - val_loss: 0.0044 - val_mae: 0.0025\n",
      "Epoch 239/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0032 - val_loss: 0.0044 - val_mae: 0.0030\n",
      "Epoch 240/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0037 - val_loss: 0.0044 - val_mae: 0.0019\n",
      "Epoch 241/2000\n",
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0049 - val_loss: 0.0044 - val_mae: 0.0034\n",
      "Epoch 242/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0030 - val_loss: 0.0044 - val_mae: 0.0027\n",
      "Epoch 243/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0025 - val_loss: 0.0044 - val_mae: 0.0064\n",
      "Epoch 244/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0038 - val_loss: 0.0043 - val_mae: 0.0038\n",
      "Epoch 245/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0025 - val_loss: 0.0043 - val_mae: 0.0022\n",
      "Epoch 246/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0062 - val_loss: 0.0043 - val_mae: 0.0022\n",
      "Epoch 247/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0025 - val_loss: 0.0043 - val_mae: 0.0039\n",
      "Epoch 248/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0030 - val_loss: 0.0043 - val_mae: 0.0033\n",
      "Epoch 249/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0026 - val_loss: 0.0043 - val_mae: 0.0028\n",
      "Epoch 250/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0027 - val_loss: 0.0043 - val_mae: 0.0077\n",
      "Epoch 251/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0038 - val_loss: 0.0042 - val_mae: 0.0027\n",
      "Epoch 252/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0029 - val_loss: 0.0042 - val_mae: 0.0031\n",
      "Epoch 253/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0032 - val_loss: 0.0043 - val_mae: 0.0063\n",
      "Epoch 254/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0045 - val_loss: 0.0045 - val_mae: 0.0134\n",
      "Epoch 255/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0072 - val_loss: 0.0042 - val_mae: 0.0045\n",
      "Epoch 256/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0021 - val_loss: 0.0042 - val_mae: 0.0019\n",
      "Epoch 257/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0022 - val_loss: 0.0042 - val_mae: 0.0043\n",
      "Epoch 258/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0031 - val_loss: 0.0043 - val_mae: 0.0077\n",
      "Epoch 259/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0036 - val_loss: 0.0042 - val_mae: 0.0038\n",
      "Epoch 260/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0028 - val_loss: 0.0041 - val_mae: 0.0018\n",
      "Epoch 261/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0021 - val_loss: 0.0042 - val_mae: 0.0051\n",
      "Epoch 262/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0037 - val_loss: 0.0041 - val_mae: 0.0023\n",
      "Epoch 263/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0027 - val_loss: 0.0042 - val_mae: 0.0089\n",
      "Epoch 264/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0032 - val_loss: 0.0041 - val_mae: 0.0018\n",
      "Epoch 265/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0027 - val_loss: 0.0041 - val_mae: 0.0037\n",
      "Epoch 266/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0086 - val_loss: 0.0047 - val_mae: 0.0206\n",
      "Epoch 267/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0032 - val_loss: 0.0041 - val_mae: 0.0041\n",
      "Epoch 268/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0021 - val_loss: 0.0040 - val_mae: 0.0016\n",
      "Epoch 269/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0039 - val_loss: 0.0040 - val_mae: 0.0043\n",
      "Epoch 270/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0021 - val_loss: 0.0040 - val_mae: 0.0029\n",
      "Epoch 271/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0025 - val_loss: 0.0040 - val_mae: 0.0022\n",
      "Epoch 272/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0021 - val_loss: 0.0040 - val_mae: 0.0035\n",
      "Epoch 273/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0025 - val_loss: 0.0040 - val_mae: 0.0035\n",
      "Epoch 274/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0043 - val_loss: 0.0041 - val_mae: 0.0074\n",
      "Epoch 275/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0030 - val_loss: 0.0040 - val_mae: 0.0051\n",
      "Epoch 276/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0029 - val_loss: 0.0040 - val_mae: 0.0028\n",
      "Epoch 277/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0028 - val_loss: 0.0039 - val_mae: 0.0018\n",
      "Epoch 278/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0029 - val_loss: 0.0039 - val_mae: 0.0026\n",
      "Epoch 279/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0026 - val_loss: 0.0039 - val_mae: 0.0041\n",
      "Epoch 280/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0059 - val_loss: 0.0039 - val_mae: 0.0024\n",
      "Epoch 281/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0022 - val_loss: 0.0039 - val_mae: 0.0030\n",
      "Epoch 282/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0028 - val_loss: 0.0039 - val_mae: 0.0039\n",
      "Epoch 283/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0047 - val_loss: 0.0039 - val_mae: 0.0034\n",
      "Epoch 284/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0027 - val_loss: 0.0039 - val_mae: 0.0042\n",
      "Epoch 285/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0024 - val_loss: 0.0038 - val_mae: 0.0034\n",
      "Epoch 286/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0029 - val_loss: 0.0039 - val_mae: 0.0085\n",
      "Epoch 287/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0045 - val_loss: 0.0039 - val_mae: 0.0056\n",
      "Epoch 288/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0031 - val_loss: 0.0038 - val_mae: 0.0020\n",
      "Epoch 289/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0025 - val_loss: 0.0038 - val_mae: 0.0022\n",
      "Epoch 290/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0033 - val_loss: 0.0038 - val_mae: 0.0018\n",
      "Epoch 291/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0048 - val_loss: 0.0038 - val_mae: 0.0029\n",
      "Epoch 292/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0025 - val_loss: 0.0038 - val_mae: 0.0048\n",
      "Epoch 293/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0020 - val_loss: 0.0038 - val_mae: 0.0029\n",
      "Epoch 294/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0044 - val_loss: 0.0038 - val_mae: 0.0036\n",
      "Epoch 295/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0028 - val_loss: 0.0038 - val_mae: 0.0047\n",
      "Epoch 296/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0024 - val_loss: 0.0037 - val_mae: 0.0020\n",
      "Epoch 297/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0021 - val_loss: 0.0037 - val_mae: 0.0019\n",
      "Epoch 298/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0027 - val_loss: 0.0037 - val_mae: 0.0047\n",
      "Epoch 299/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0038 - val_loss: 0.0037 - val_mae: 0.0015\n",
      "Epoch 300/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0024 - val_loss: 0.0037 - val_mae: 0.0020\n",
      "Epoch 301/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0039 - val_loss: 0.0048 - val_mae: 0.0268\n",
      "Epoch 302/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0035 - val_loss: 0.0037 - val_mae: 0.0040\n",
      "Epoch 303/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0024 - val_loss: 0.0037 - val_mae: 0.0036\n",
      "Epoch 304/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0037 - val_loss: 0.0036 - val_mae: 0.0043\n",
      "Epoch 305/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0019 - val_loss: 0.0036 - val_mae: 0.0024\n",
      "Epoch 306/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0022 - val_loss: 0.0036 - val_mae: 0.0016\n",
      "Epoch 307/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0027 - val_loss: 0.0037 - val_mae: 0.0080\n",
      "Epoch 308/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0028 - val_loss: 0.0036 - val_mae: 0.0027\n",
      "Epoch 309/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0029 - val_loss: 0.0036 - val_mae: 0.0018\n",
      "Epoch 310/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0035 - val_loss: 0.0036 - val_mae: 0.0033\n",
      "Epoch 311/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0025 - val_loss: 0.0036 - val_mae: 0.0061\n",
      "Epoch 312/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0040 - val_loss: 0.0035 - val_mae: 0.0033\n",
      "Epoch 313/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0020 - val_loss: 0.0035 - val_mae: 0.0020\n",
      "Epoch 314/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0032 - val_loss: 0.0035 - val_mae: 0.0032\n",
      "Epoch 315/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0040 - val_loss: 0.0035 - val_mae: 0.0029\n",
      "Epoch 316/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0025 - val_loss: 0.0035 - val_mae: 0.0025\n",
      "Epoch 317/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0025 - val_loss: 0.0035 - val_mae: 0.0020\n",
      "Epoch 318/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0055 - val_loss: 0.0035 - val_mae: 0.0016\n",
      "Epoch 319/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0019 - val_loss: 0.0035 - val_mae: 0.0023\n",
      "Epoch 320/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0021 - val_loss: 0.0035 - val_mae: 0.0059\n",
      "Epoch 321/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0032 - val_loss: 0.0034 - val_mae: 0.0022\n",
      "Epoch 322/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0024 - val_loss: 0.0034 - val_mae: 0.0032\n",
      "Epoch 323/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0019 - val_loss: 0.0034 - val_mae: 0.0020\n",
      "Epoch 324/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0031 - val_loss: 0.0034 - val_mae: 0.0040\n",
      "Epoch 325/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0028 - val_loss: 0.0034 - val_mae: 0.0022\n",
      "Epoch 326/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0023 - val_loss: 0.0034 - val_mae: 0.0025\n",
      "Epoch 327/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0039 - val_loss: 0.0034 - val_mae: 0.0039\n",
      "Epoch 328/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0031 - val_loss: 0.0035 - val_mae: 0.0082\n",
      "Epoch 329/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0041 - val_loss: 0.0034 - val_mae: 0.0049\n",
      "Epoch 330/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0030 - val_loss: 0.0033 - val_mae: 0.0018\n",
      "Epoch 331/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0022 - val_loss: 0.0033 - val_mae: 0.0028\n",
      "Epoch 332/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0028 - val_loss: 0.0035 - val_mae: 0.0106\n",
      "Epoch 333/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0031 - val_loss: 0.0034 - val_mae: 0.0056\n",
      "Epoch 334/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0038 - val_loss: 0.0033 - val_mae: 0.0020\n",
      "Epoch 335/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0021 - val_loss: 0.0033 - val_mae: 0.0043\n",
      "Epoch 336/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0028 - val_loss: 0.0033 - val_mae: 0.0015\n",
      "Epoch 337/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0021 - val_loss: 0.0033 - val_mae: 0.0018\n",
      "Epoch 338/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0027 - val_loss: 0.0033 - val_mae: 0.0033\n",
      "Epoch 339/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0021 - val_loss: 0.0033 - val_mae: 0.0021\n",
      "Epoch 340/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0052 - val_loss: 0.0032 - val_mae: 0.0016\n",
      "Epoch 341/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0025 - val_loss: 0.0032 - val_mae: 0.0033\n",
      "Epoch 342/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0021 - val_loss: 0.0032 - val_mae: 0.0020\n",
      "Epoch 343/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0023 - val_loss: 0.0037 - val_mae: 0.0166\n",
      "Epoch 344/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0031 - val_loss: 0.0032 - val_mae: 0.0021\n",
      "Epoch 345/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0032 - val_loss: 0.0032 - val_mae: 0.0025\n",
      "Epoch 346/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0032 - val_loss: 0.0032 - val_mae: 0.0013\n",
      "Epoch 347/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0018 - val_loss: 0.0032 - val_mae: 0.0018\n",
      "Epoch 348/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0026 - val_loss: 0.0032 - val_mae: 0.0020\n",
      "Epoch 349/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0032 - val_loss: 0.0032 - val_mae: 0.0031\n",
      "Epoch 350/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0048 - val_loss: 0.0032 - val_mae: 0.0017\n",
      "Epoch 351/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0019 - val_loss: 0.0031 - val_mae: 0.0016\n",
      "Epoch 352/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0019 - val_loss: 0.0031 - val_mae: 0.0017\n",
      "Epoch 353/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0022 - val_loss: 0.0032 - val_mae: 0.0046\n",
      "Epoch 354/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0038 - val_loss: 0.0032 - val_mae: 0.0088\n",
      "Epoch 355/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0034 - val_loss: 0.0031 - val_mae: 0.0014\n",
      "Epoch 356/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0019 - val_loss: 0.0031 - val_mae: 0.0045\n",
      "Epoch 357/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0026 - val_loss: 0.0031 - val_mae: 0.0014\n",
      "Epoch 358/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0020 - val_loss: 0.0031 - val_mae: 0.0025\n",
      "Epoch 359/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0023 - val_loss: 0.0031 - val_mae: 0.0034\n",
      "Epoch 360/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0028 - val_loss: 0.0031 - val_mae: 0.0022\n",
      "Epoch 361/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0031 - mae: 0.0029 - val_loss: 0.0031 - val_mae: 0.0074\n",
      "Epoch 362/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0025 - val_loss: 0.0030 - val_mae: 0.0027\n",
      "Epoch 363/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0022 - val_loss: 0.0030 - val_mae: 0.0019\n",
      "Epoch 364/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0030 - val_mae: 0.0023\n",
      "Epoch 365/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0033 - val_loss: 0.0032 - val_mae: 0.0097\n",
      "Epoch 366/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0032 - val_loss: 0.0030 - val_mae: 0.0038\n",
      "Epoch 367/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0022 - val_loss: 0.0031 - val_mae: 0.0065\n",
      "Epoch 368/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0022 - val_loss: 0.0030 - val_mae: 0.0020\n",
      "Epoch 369/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0033 - val_loss: 0.0030 - val_mae: 0.0014\n",
      "Epoch 370/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0021 - val_loss: 0.0030 - val_mae: 0.0028\n",
      "Epoch 371/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0020 - val_loss: 0.0030 - val_mae: 0.0054\n",
      "Epoch 372/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0044 - val_loss: 0.0029 - val_mae: 0.0017\n",
      "Epoch 373/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0029 - mae: 0.0019 - val_loss: 0.0029 - val_mae: 0.0025\n",
      "Epoch 374/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0029 - mae: 0.0029 - val_loss: 0.0031 - val_mae: 0.0117\n",
      "Epoch 375/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0029 - mae: 0.0026 - val_loss: 0.0029 - val_mae: 0.0021\n",
      "Epoch 376/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0022 - val_loss: 0.0029 - val_mae: 0.0026\n",
      "Epoch 377/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0032 - val_loss: 0.0029 - val_mae: 0.0047\n",
      "Epoch 378/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0024 - val_loss: 0.0030 - val_mae: 0.0065\n",
      "Epoch 379/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0032 - val_loss: 0.0029 - val_mae: 0.0034\n",
      "Epoch 380/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0020 - val_loss: 0.0029 - val_mae: 0.0013\n",
      "Epoch 381/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0031 - val_loss: 0.0029 - val_mae: 0.0016\n",
      "Epoch 382/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0025 - val_loss: 0.0029 - val_mae: 0.0045\n",
      "Epoch 383/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0025 - val_loss: 0.0029 - val_mae: 0.0043\n",
      "Epoch 384/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0031 - val_loss: 0.0028 - val_mae: 0.0031\n",
      "Epoch 385/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0029 - val_loss: 0.0033 - val_mae: 0.0152\n",
      "Epoch 386/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0046 - val_loss: 0.0028 - val_mae: 0.0017\n",
      "Epoch 387/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0017 - val_loss: 0.0028 - val_mae: 0.0018\n",
      "Epoch 388/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0018 - val_loss: 0.0028 - val_mae: 0.0015\n",
      "Epoch 389/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0023 - val_loss: 0.0028 - val_mae: 0.0039\n",
      "Epoch 390/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0019 - val_loss: 0.0028 - val_mae: 0.0034\n",
      "Epoch 391/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0030 - val_loss: 0.0028 - val_mae: 0.0034\n",
      "Epoch 392/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0024 - val_loss: 0.0028 - val_mae: 0.0032\n",
      "Epoch 393/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0023 - val_loss: 0.0028 - val_mae: 0.0015\n",
      "Epoch 394/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0024 - val_loss: 0.0028 - val_mae: 0.0046\n",
      "Epoch 395/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0023 - val_loss: 0.0027 - val_mae: 0.0018\n",
      "Epoch 396/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0034 - val_loss: 0.0027 - val_mae: 0.0015\n",
      "Epoch 397/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0016 - val_loss: 0.0027 - val_mae: 0.0017\n",
      "Epoch 398/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0027 - mae: 0.0030 - val_loss: 0.0028 - val_mae: 0.0065\n",
      "Epoch 399/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0032 - val_loss: 0.0027 - val_mae: 0.0040\n",
      "Epoch 400/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0031 - val_loss: 0.0027 - val_mae: 0.0034\n",
      "Epoch 401/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0021 - val_loss: 0.0027 - val_mae: 0.0016\n",
      "Epoch 402/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0026 - val_loss: 0.0027 - val_mae: 0.0015\n",
      "Epoch 403/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0024 - val_loss: 0.0027 - val_mae: 0.0022\n",
      "Epoch 404/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0026 - val_loss: 0.0027 - val_mae: 0.0029\n",
      "Epoch 405/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0038 - val_loss: 0.0027 - val_mae: 0.0017\n",
      "Epoch 406/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0016 - val_loss: 0.0026 - val_mae: 0.0015\n",
      "Epoch 407/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0029 - val_loss: 0.0031 - val_mae: 0.0169\n",
      "Epoch 408/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0026 - val_loss: 0.0027 - val_mae: 0.0060\n",
      "Epoch 409/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0025 - val_loss: 0.0026 - val_mae: 0.0034\n",
      "Epoch 410/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0018 - val_loss: 0.0026 - val_mae: 0.0020\n",
      "Epoch 411/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0022 - val_loss: 0.0026 - val_mae: 0.0042\n",
      "Epoch 412/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0039 - val_loss: 0.0026 - val_mae: 0.0015\n",
      "Epoch 413/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0018 - val_loss: 0.0026 - val_mae: 0.0055\n",
      "Epoch 414/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0034 - val_loss: 0.0027 - val_mae: 0.0071\n",
      "Epoch 415/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0027 - val_loss: 0.0026 - val_mae: 0.0041\n",
      "Epoch 416/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0021 - val_loss: 0.0026 - val_mae: 0.0017\n",
      "Epoch 417/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0020 - val_loss: 0.0026 - val_mae: 0.0025\n",
      "Epoch 418/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0022 - val_loss: 0.0026 - val_mae: 0.0020\n",
      "Epoch 419/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0025 - val_loss: 0.0025 - val_mae: 0.0017\n",
      "Epoch 420/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0021 - val_loss: 0.0025 - val_mae: 0.0020\n",
      "Epoch 421/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0027 - val_loss: 0.0025 - val_mae: 0.0024\n",
      "Epoch 422/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0035 - val_loss: 0.0025 - val_mae: 0.0019\n",
      "Epoch 423/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0018 - val_loss: 0.0025 - val_mae: 0.0021\n",
      "Epoch 424/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0029 - val_loss: 0.0025 - val_mae: 0.0016\n",
      "Epoch 425/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0017 - val_loss: 0.0025 - val_mae: 0.0014\n",
      "Epoch 426/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0026 - val_loss: 0.0025 - val_mae: 0.0032\n",
      "Epoch 427/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0030 - val_loss: 0.0025 - val_mae: 0.0022\n",
      "Epoch 428/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0025 - val_loss: 0.0025 - val_mae: 0.0032\n",
      "Epoch 429/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0028 - val_loss: 0.0025 - val_mae: 0.0013\n",
      "Epoch 430/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0020 - val_loss: 0.0025 - val_mae: 0.0028\n",
      "Epoch 431/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0022 - val_loss: 0.0025 - val_mae: 0.0020\n",
      "Epoch 432/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0021 - val_loss: 0.0024 - val_mae: 0.0026\n",
      "Epoch 433/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0031 - val_loss: 0.0029 - val_mae: 0.0171\n",
      "Epoch 434/2000\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0025 - mae: 0.0032 - val_loss: 0.0024 - val_mae: 0.0030\n",
      "Epoch 435/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0020 - val_loss: 0.0024 - val_mae: 0.0021\n",
      "Epoch 436/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0019 - val_loss: 0.0024 - val_mae: 0.0018\n",
      "Epoch 437/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0019 - val_loss: 0.0026 - val_mae: 0.0111\n",
      "Epoch 438/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0033 - val_loss: 0.0024 - val_mae: 0.0041\n",
      "Epoch 439/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0019 - val_loss: 0.0024 - val_mae: 0.0052\n",
      "Epoch 440/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0020 - val_loss: 0.0024 - val_mae: 0.0017\n",
      "Epoch 441/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0025 - val_loss: 0.0024 - val_mae: 0.0021\n",
      "Epoch 442/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0022 - val_loss: 0.0024 - val_mae: 0.0042\n",
      "Epoch 443/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0024 - val_loss: 0.0024 - val_mae: 0.0031\n",
      "Epoch 444/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0023 - val_loss: 0.0024 - val_mae: 0.0071\n",
      "Epoch 445/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0031 - val_loss: 0.0024 - val_mae: 0.0031\n",
      "Epoch 446/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0018 - val_loss: 0.0025 - val_mae: 0.0097\n",
      "Epoch 447/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0029 - val_loss: 0.0023 - val_mae: 0.0016\n",
      "Epoch 448/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0026 - val_loss: 0.0023 - val_mae: 0.0017\n",
      "Epoch 449/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0024 - val_loss: 0.0023 - val_mae: 0.0026\n",
      "Epoch 450/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0029 - val_loss: 0.0023 - val_mae: 0.0022\n",
      "Epoch 451/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0030 - val_loss: 0.0023 - val_mae: 0.0042\n",
      "Epoch 452/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0021 - val_loss: 0.0023 - val_mae: 0.0038\n",
      "Epoch 453/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0026 - val_loss: 0.0023 - val_mae: 0.0017\n",
      "Epoch 454/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0021 - val_loss: 0.0023 - val_mae: 0.0035\n",
      "Epoch 455/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0023 - val_loss: 0.0023 - val_mae: 0.0033\n",
      "Epoch 456/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0025 - val_loss: 0.0023 - val_mae: 0.0015\n",
      "Epoch 457/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0021 - val_loss: 0.0023 - val_mae: 0.0031\n",
      "Epoch 458/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0024 - val_loss: 0.0023 - val_mae: 0.0020\n",
      "Epoch 459/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0024 - val_loss: 0.0023 - val_mae: 0.0058\n",
      "Epoch 460/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0026 - val_loss: 0.0022 - val_mae: 0.0026\n",
      "Epoch 461/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0018 - val_loss: 0.0022 - val_mae: 0.0030\n",
      "Epoch 462/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0031 - val_loss: 0.0023 - val_mae: 0.0065\n",
      "Epoch 463/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0028 - val_loss: 0.0022 - val_mae: 0.0020\n",
      "Epoch 464/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0019 - val_loss: 0.0022 - val_mae: 0.0014\n",
      "Epoch 465/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0018 - val_loss: 0.0022 - val_mae: 0.0012\n",
      "Epoch 466/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0028 - val_loss: 0.0022 - val_mae: 0.0041\n",
      "Epoch 467/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0021 - val_loss: 0.0022 - val_mae: 0.0016\n",
      "Epoch 468/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0017 - val_loss: 0.0022 - val_mae: 0.0017\n",
      "Epoch 469/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0021 - val_loss: 0.0022 - val_mae: 0.0048\n",
      "Epoch 470/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0029 - val_loss: 0.0022 - val_mae: 0.0018\n",
      "Epoch 471/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0031 - val_loss: 0.0022 - val_mae: 0.0028\n",
      "Epoch 472/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0023 - val_loss: 0.0022 - val_mae: 0.0028\n",
      "Epoch 473/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0019 - val_loss: 0.0022 - val_mae: 0.0029\n",
      "Epoch 474/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0020 - val_loss: 0.0021 - val_mae: 0.0031\n",
      "Epoch 475/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0022 - val_loss: 0.0021 - val_mae: 0.0031\n",
      "Epoch 476/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0032 - val_loss: 0.0021 - val_mae: 0.0028\n",
      "Epoch 477/2000\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0021 - mae: 0.0020 - val_loss: 0.0021 - val_mae: 0.0019\n",
      "Epoch 478/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0029 - val_loss: 0.0021 - val_mae: 0.0046\n",
      "Epoch 479/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0028 - val_loss: 0.0021 - val_mae: 0.0040\n",
      "Epoch 480/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0023 - val_loss: 0.0021 - val_mae: 0.0015\n",
      "Epoch 481/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0018 - val_loss: 0.0021 - val_mae: 0.0013\n",
      "Epoch 482/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0022 - val_loss: 0.0021 - val_mae: 0.0031\n",
      "Epoch 483/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0024 - val_loss: 0.0021 - val_mae: 0.0014\n",
      "Epoch 484/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0019 - val_loss: 0.0021 - val_mae: 0.0018\n",
      "Epoch 485/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0032 - val_loss: 0.0021 - val_mae: 0.0044\n",
      "Epoch 486/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0020 - val_loss: 0.0021 - val_mae: 0.0014\n",
      "Epoch 487/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0018 - val_loss: 0.0020 - val_mae: 0.0015\n",
      "Epoch 488/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0019 - val_loss: 0.0021 - val_mae: 0.0054\n",
      "Epoch 489/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0029 - val_loss: 0.0020 - val_mae: 0.0035\n",
      "Epoch 490/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0024 - val_loss: 0.0020 - val_mae: 0.0014\n",
      "Epoch 491/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0017 - val_loss: 0.0020 - val_mae: 0.0020\n",
      "Epoch 492/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0020 - val_loss: 0.0020 - val_mae: 0.0015\n",
      "Epoch 493/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0022 - val_loss: 0.0020 - val_mae: 0.0028\n",
      "Epoch 494/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0023 - val_loss: 0.0020 - val_mae: 0.0014\n",
      "Epoch 495/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0021 - val_loss: 0.0020 - val_mae: 0.0013\n",
      "Epoch 496/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0024 - val_loss: 0.0020 - val_mae: 0.0055\n",
      "Epoch 497/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0025 - val_loss: 0.0020 - val_mae: 0.0016\n",
      "Epoch 498/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0017 - val_loss: 0.0020 - val_mae: 0.0016\n",
      "Epoch 499/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0018 - val_loss: 0.0020 - val_mae: 0.0021\n",
      "Epoch 500/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0028 - val_loss: 0.0020 - val_mae: 0.0029\n",
      "Epoch 501/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0024 - val_loss: 0.0022 - val_mae: 0.0127\n",
      "Epoch 502/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0027 - val_loss: 0.0021 - val_mae: 0.0085\n",
      "Epoch 503/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0023 - val_loss: 0.0019 - val_mae: 0.0019\n",
      "Epoch 504/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0018 - val_loss: 0.0019 - val_mae: 0.0021\n",
      "Epoch 505/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0026 - val_loss: 0.0019 - val_mae: 0.0027\n",
      "Epoch 506/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0022 - val_loss: 0.0019 - val_mae: 0.0026\n",
      "Epoch 507/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0025 - val_loss: 0.0019 - val_mae: 0.0020\n",
      "Epoch 508/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0028 - val_loss: 0.0022 - val_mae: 0.0131\n",
      "Epoch 509/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0029 - val_loss: 0.0019 - val_mae: 0.0018\n",
      "Epoch 510/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0016 - val_loss: 0.0019 - val_mae: 0.0034\n",
      "Epoch 511/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0018 - val_loss: 0.0019 - val_mae: 0.0047\n",
      "Epoch 512/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0018 - val_loss: 0.0019 - val_mae: 0.0023\n",
      "Epoch 513/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0018 - val_loss: 0.0019 - val_mae: 0.0031\n",
      "Epoch 514/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0027 - val_loss: 0.0019 - val_mae: 0.0014\n",
      "Epoch 515/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0023 - val_loss: 0.0019 - val_mae: 0.0013\n",
      "Epoch 516/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0019 - val_mae: 0.0016\n",
      "Epoch 517/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0019 - val_mae: 0.0029\n",
      "Epoch 518/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0021 - val_loss: 0.0019 - val_mae: 0.0051\n",
      "Epoch 519/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0031 - val_loss: 0.0018 - val_mae: 0.0022\n",
      "Epoch 520/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0023 - val_loss: 0.0018 - val_mae: 0.0031\n",
      "Epoch 521/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0021 - val_loss: 0.0018 - val_mae: 0.0035\n",
      "Epoch 522/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0024 - val_loss: 0.0019 - val_mae: 0.0077\n",
      "Epoch 523/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0031 - val_loss: 0.0018 - val_mae: 0.0044\n",
      "Epoch 524/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0017 - val_loss: 0.0018 - val_mae: 0.0030\n",
      "Epoch 525/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0017 - val_loss: 0.0018 - val_mae: 0.0020\n",
      "Epoch 526/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0021 - val_loss: 0.0018 - val_mae: 0.0020\n",
      "Epoch 527/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0019 - val_loss: 0.0018 - val_mae: 0.0017\n",
      "Epoch 528/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0022 - val_loss: 0.0018 - val_mae: 0.0027\n",
      "Epoch 529/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0027 - val_loss: 0.0018 - val_mae: 0.0023\n",
      "Epoch 530/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0026 - val_loss: 0.0018 - val_mae: 0.0017\n",
      "Epoch 531/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0021 - val_loss: 0.0018 - val_mae: 0.0039\n",
      "Epoch 532/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0023 - val_loss: 0.0018 - val_mae: 0.0034\n",
      "Epoch 533/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0018 - val_loss: 0.0022 - val_mae: 0.0155\n",
      "Epoch 534/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0027 - val_loss: 0.0017 - val_mae: 0.0025\n",
      "Epoch 535/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0020 - val_loss: 0.0017 - val_mae: 0.0019\n",
      "Epoch 536/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0017 - val_loss: 0.0017 - val_mae: 0.0013\n",
      "Epoch 537/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0026 - val_loss: 0.0017 - val_mae: 0.0019\n",
      "Epoch 538/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0017 - val_loss: 0.0017 - val_mae: 0.0013\n",
      "Epoch 539/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0021 - val_loss: 0.0017 - val_mae: 0.0014\n",
      "Epoch 540/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0018 - val_loss: 0.0017 - val_mae: 0.0041\n",
      "Epoch 541/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0024 - val_loss: 0.0017 - val_mae: 0.0037\n",
      "Epoch 542/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0023 - val_loss: 0.0017 - val_mae: 0.0023\n",
      "Epoch 543/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0022 - val_loss: 0.0017 - val_mae: 0.0038\n",
      "Epoch 544/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0019 - val_loss: 0.0017 - val_mae: 0.0021\n",
      "Epoch 545/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0030 - val_loss: 0.0020 - val_mae: 0.0133\n",
      "Epoch 546/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0025 - val_loss: 0.0017 - val_mae: 0.0013\n",
      "Epoch 547/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0016 - val_loss: 0.0017 - val_mae: 0.0058\n",
      "Epoch 548/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0021 - val_loss: 0.0017 - val_mae: 0.0015\n",
      "Epoch 549/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0018 - val_loss: 0.0017 - val_mae: 0.0014\n",
      "Epoch 550/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0018 - val_loss: 0.0017 - val_mae: 0.0017\n",
      "Epoch 551/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0017 - val_loss: 0.0017 - val_mae: 0.0031\n",
      "Epoch 552/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0019 - val_loss: 0.0017 - val_mae: 0.0031\n",
      "Epoch 553/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0022 - val_loss: 0.0016 - val_mae: 0.0013\n",
      "Epoch 554/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0018 - val_loss: 0.0016 - val_mae: 0.0020\n",
      "Epoch 555/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0025 - val_loss: 0.0016 - val_mae: 0.0015\n",
      "Epoch 556/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0020 - val_loss: 0.0016 - val_mae: 0.0028\n",
      "Epoch 557/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0021 - val_loss: 0.0016 - val_mae: 0.0016\n",
      "Epoch 558/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0023 - val_loss: 0.0016 - val_mae: 0.0032\n",
      "Epoch 559/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0023 - val_loss: 0.0016 - val_mae: 0.0016\n",
      "Epoch 560/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0023 - val_loss: 0.0016 - val_mae: 0.0023\n",
      "Epoch 561/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0026 - val_loss: 0.0016 - val_mae: 0.0024\n",
      "Epoch 562/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0022 - val_loss: 0.0016 - val_mae: 0.0016\n",
      "Epoch 563/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0018 - val_loss: 0.0016 - val_mae: 0.0024\n",
      "Epoch 564/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0018 - val_loss: 0.0016 - val_mae: 0.0015\n",
      "Epoch 565/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0026 - val_loss: 0.0016 - val_mae: 0.0018\n",
      "Epoch 566/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0017 - val_loss: 0.0016 - val_mae: 0.0017\n",
      "Epoch 567/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0019 - val_loss: 0.0016 - val_mae: 0.0016\n",
      "Epoch 568/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0016 - val_loss: 0.0016 - val_mae: 0.0041\n",
      "Epoch 569/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0020 - val_loss: 0.0016 - val_mae: 0.0041\n",
      "Epoch 570/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0022 - val_loss: 0.0016 - val_mae: 0.0060\n",
      "Epoch 571/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0031 - val_loss: 0.0015 - val_mae: 0.0014\n",
      "Epoch 572/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0017 - val_loss: 0.0015 - val_mae: 0.0013\n",
      "Epoch 573/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0039 - val_loss: 0.0015 - val_mae: 0.0029\n",
      "Epoch 574/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0016 - val_loss: 0.0015 - val_mae: 0.0015\n",
      "Epoch 575/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0014 - val_loss: 0.0015 - val_mae: 0.0019\n",
      "Epoch 576/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0017 - val_loss: 0.0015 - val_mae: 0.0025\n",
      "Epoch 577/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0023 - val_loss: 0.0015 - val_mae: 0.0015\n",
      "Epoch 578/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0016 - val_loss: 0.0015 - val_mae: 0.0033\n",
      "Epoch 579/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0022 - val_loss: 0.0015 - val_mae: 0.0016\n",
      "Epoch 580/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0019 - val_loss: 0.0015 - val_mae: 0.0023\n",
      "Epoch 581/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0025 - val_loss: 0.0015 - val_mae: 0.0015\n",
      "Epoch 582/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0019 - val_loss: 0.0015 - val_mae: 0.0027\n",
      "Epoch 583/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0020 - val_loss: 0.0015 - val_mae: 0.0034\n",
      "Epoch 584/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0018 - val_loss: 0.0015 - val_mae: 0.0019\n",
      "Epoch 585/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0017 - val_loss: 0.0015 - val_mae: 0.0019\n",
      "Epoch 586/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0024 - val_loss: 0.0015 - val_mae: 0.0033\n",
      "Epoch 587/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0021 - val_loss: 0.0015 - val_mae: 0.0016\n",
      "Epoch 588/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0021 - val_loss: 0.0015 - val_mae: 0.0042\n",
      "Epoch 589/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0017 - val_loss: 0.0014 - val_mae: 0.0018\n",
      "Epoch 590/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0034 - val_loss: 0.0015 - val_mae: 0.0045\n",
      "Epoch 591/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0020 - val_loss: 0.0014 - val_mae: 0.0016\n",
      "Epoch 592/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0017 - val_loss: 0.0014 - val_mae: 0.0016\n",
      "Epoch 593/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0018 - val_loss: 0.0014 - val_mae: 0.0021\n",
      "Epoch 594/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0018 - val_loss: 0.0014 - val_mae: 0.0027\n",
      "Epoch 595/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0020 - val_loss: 0.0014 - val_mae: 0.0013\n",
      "Epoch 596/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0023 - val_loss: 0.0014 - val_mae: 0.0021\n",
      "Epoch 597/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0017 - val_loss: 0.0014 - val_mae: 0.0015\n",
      "Epoch 598/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0034 - val_loss: 0.0014 - val_mae: 0.0015\n",
      "Epoch 599/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0014 - val_loss: 0.0014 - val_mae: 0.0016\n",
      "Epoch 600/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0018 - val_loss: 0.0014 - val_mae: 0.0012\n",
      "Epoch 601/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0017 - val_loss: 0.0014 - val_mae: 0.0023\n",
      "Epoch 602/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0022 - val_loss: 0.0014 - val_mae: 0.0042\n",
      "Epoch 603/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0016 - val_loss: 0.0014 - val_mae: 0.0046\n",
      "Epoch 604/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0018 - val_loss: 0.0014 - val_mae: 0.0019\n",
      "Epoch 605/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0019 - val_loss: 0.0016 - val_mae: 0.0134\n",
      "Epoch 606/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0040 - val_loss: 0.0014 - val_mae: 0.0024\n",
      "Epoch 607/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0015 - val_loss: 0.0014 - val_mae: 0.0025\n",
      "Epoch 608/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0014 - val_loss: 0.0014 - val_mae: 0.0025\n",
      "Epoch 609/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0014 - val_loss: 0.0014 - val_mae: 0.0012\n",
      "Epoch 610/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0017 - val_loss: 0.0014 - val_mae: 0.0059\n",
      "Epoch 611/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0019 - val_loss: 0.0013 - val_mae: 0.0025\n",
      "Epoch 612/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0018 - val_loss: 0.0013 - val_mae: 0.0022\n",
      "Epoch 613/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0016 - val_loss: 0.0013 - val_mae: 0.0013\n",
      "Epoch 614/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0021 - val_loss: 0.0013 - val_mae: 0.0025\n",
      "Epoch 615/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0020 - val_loss: 0.0013 - val_mae: 0.0014\n",
      "Epoch 616/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0021 - val_loss: 0.0013 - val_mae: 0.0020\n",
      "Epoch 617/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0020 - val_loss: 0.0013 - val_mae: 0.0015\n",
      "Epoch 618/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0020 - val_loss: 0.0013 - val_mae: 0.0043\n",
      "Epoch 619/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0026 - val_loss: 0.0013 - val_mae: 0.0017\n",
      "Epoch 620/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0017 - val_loss: 0.0013 - val_mae: 0.0014\n",
      "Epoch 621/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0020 - val_loss: 0.0013 - val_mae: 0.0038\n",
      "Epoch 622/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0020 - val_loss: 0.0013 - val_mae: 0.0018\n",
      "Epoch 623/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0016 - val_loss: 0.0013 - val_mae: 0.0028\n",
      "Epoch 624/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0022 - val_loss: 0.0013 - val_mae: 0.0018\n",
      "Epoch 625/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0022 - val_loss: 0.0013 - val_mae: 0.0041\n",
      "Epoch 626/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0020 - val_loss: 0.0013 - val_mae: 0.0036\n",
      "Epoch 627/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0019 - val_loss: 0.0013 - val_mae: 0.0016\n",
      "Epoch 628/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0016 - val_loss: 0.0013 - val_mae: 0.0024\n",
      "Epoch 629/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0024 - val_loss: 0.0013 - val_mae: 0.0018\n",
      "Epoch 630/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0021 - val_loss: 0.0013 - val_mae: 0.0016\n",
      "Epoch 631/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0014 - val_loss: 0.0013 - val_mae: 0.0013\n",
      "Epoch 632/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0024 - val_loss: 0.0013 - val_mae: 0.0020\n",
      "Epoch 633/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0018 - val_loss: 0.0012 - val_mae: 0.0021\n",
      "Epoch 634/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0025 - val_loss: 0.0012 - val_mae: 0.0016\n",
      "Epoch 635/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0015 - val_loss: 0.0012 - val_mae: 0.0016\n",
      "Epoch 636/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0016 - val_loss: 0.0012 - val_mae: 0.0013\n",
      "Epoch 637/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0024 - val_loss: 0.0013 - val_mae: 0.0053\n",
      "Epoch 638/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0020 - val_loss: 0.0012 - val_mae: 0.0015\n",
      "Epoch 639/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0025 - val_loss: 0.0013 - val_mae: 0.0078\n",
      "Epoch 640/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0021 - val_loss: 0.0012 - val_mae: 0.0012\n",
      "Epoch 641/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0017 - val_loss: 0.0012 - val_mae: 0.0031\n",
      "Epoch 642/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0018 - val_loss: 0.0012 - val_mae: 0.0019\n",
      "Epoch 643/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0019 - val_loss: 0.0012 - val_mae: 0.0024\n",
      "Epoch 644/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0021 - val_loss: 0.0012 - val_mae: 0.0018\n",
      "Epoch 645/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0023 - val_loss: 0.0012 - val_mae: 0.0032\n",
      "Epoch 646/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0020 - val_loss: 0.0012 - val_mae: 0.0015\n",
      "Epoch 647/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0016 - val_loss: 0.0012 - val_mae: 0.0011\n",
      "Epoch 648/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0017 - val_loss: 0.0012 - val_mae: 0.0021\n",
      "Epoch 649/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0020 - val_loss: 0.0012 - val_mae: 0.0045\n",
      "Epoch 650/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0021 - val_loss: 0.0012 - val_mae: 0.0020\n",
      "Epoch 651/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0022 - val_loss: 0.0012 - val_mae: 0.0023\n",
      "Epoch 652/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0023 - val_loss: 0.0012 - val_mae: 0.0021\n",
      "Epoch 653/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0015 - val_loss: 0.0012 - val_mae: 0.0019\n",
      "Epoch 654/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0021 - val_loss: 0.0012 - val_mae: 0.0015\n",
      "Epoch 655/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0016 - val_loss: 0.0012 - val_mae: 0.0030\n",
      "Epoch 656/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0021 - val_loss: 0.0011 - val_mae: 0.0014\n",
      "Epoch 657/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0021 - val_loss: 0.0012 - val_mae: 0.0027\n",
      "Epoch 658/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0023 - val_loss: 0.0012 - val_mae: 0.0047\n",
      "Epoch 659/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0016 - val_loss: 0.0012 - val_mae: 0.0035\n",
      "Epoch 660/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0023 - val_loss: 0.0012 - val_mae: 0.0048\n",
      "Epoch 661/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0019 - val_loss: 0.0011 - val_mae: 0.0044\n",
      "Epoch 662/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0018 - val_loss: 0.0011 - val_mae: 0.0014\n",
      "Epoch 663/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0019 - val_loss: 0.0011 - val_mae: 0.0039\n",
      "Epoch 664/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0020 - val_loss: 0.0011 - val_mae: 0.0028\n",
      "Epoch 665/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0023 - val_loss: 0.0011 - val_mae: 0.0018\n",
      "Epoch 666/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0016 - val_loss: 0.0011 - val_mae: 0.0014\n",
      "Epoch 667/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0017 - val_loss: 0.0011 - val_mae: 0.0039\n",
      "Epoch 668/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0020 - val_loss: 0.0011 - val_mae: 0.0019\n",
      "Epoch 669/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0020 - val_loss: 0.0011 - val_mae: 0.0026\n",
      "Epoch 670/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0018 - val_loss: 0.0011 - val_mae: 0.0017\n",
      "Epoch 671/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0023 - val_loss: 0.0011 - val_mae: 0.0012\n",
      "Epoch 672/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0019 - val_loss: 0.0011 - val_mae: 0.0060\n",
      "Epoch 673/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0023 - val_loss: 0.0011 - val_mae: 0.0027\n",
      "Epoch 674/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0020 - val_loss: 0.0011 - val_mae: 0.0012\n",
      "Epoch 675/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0015 - val_loss: 0.0011 - val_mae: 0.0023\n",
      "Epoch 676/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0022 - val_loss: 0.0011 - val_mae: 0.0034\n",
      "Epoch 677/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0018 - val_loss: 0.0011 - val_mae: 0.0014\n",
      "Epoch 678/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0021 - val_loss: 0.0011 - val_mae: 0.0056\n",
      "Epoch 679/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0018 - val_loss: 0.0011 - val_mae: 0.0036\n",
      "Epoch 680/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0020 - val_loss: 0.0011 - val_mae: 0.0027\n",
      "Epoch 681/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0024 - val_loss: 0.0011 - val_mae: 0.0020\n",
      "Epoch 682/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0018 - val_loss: 0.0010 - val_mae: 0.0012\n",
      "Epoch 683/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0015 - val_loss: 0.0010 - val_mae: 0.0021\n",
      "Epoch 684/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0023 - val_loss: 0.0010 - val_mae: 0.0011\n",
      "Epoch 685/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0017 - val_loss: 0.0010 - val_mae: 0.0027\n",
      "Epoch 686/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0020 - val_loss: 0.0010 - val_mae: 0.0030\n",
      "Epoch 687/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0020 - val_loss: 0.0010 - val_mae: 0.0017\n",
      "Epoch 688/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0017 - val_loss: 0.0010 - val_mae: 0.0017\n",
      "Epoch 689/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0015 - val_loss: 0.0010 - val_mae: 0.0015\n",
      "Epoch 690/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0020 - val_loss: 0.0010 - val_mae: 0.0044\n",
      "Epoch 691/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0022 - val_loss: 0.0010 - val_mae: 0.0024\n",
      "Epoch 692/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0021 - val_loss: 0.0010 - val_mae: 0.0034\n",
      "Epoch 693/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0016 - val_loss: 0.0010 - val_mae: 0.0025\n",
      "Epoch 694/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0018 - val_loss: 0.0010 - val_mae: 0.0020\n",
      "Epoch 695/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0019 - val_loss: 0.0010 - val_mae: 0.0018\n",
      "Epoch 696/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0019 - val_loss: 9.9724e-04 - val_mae: 0.0013\n",
      "Epoch 697/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 9.9965e-04 - mae: 0.0018 - val_loss: 0.0010 - val_mae: 0.0045\n",
      "Epoch 698/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 9.9445e-04 - mae: 0.0018 - val_loss: 0.0010 - val_mae: 0.0052\n",
      "Epoch 699/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 9.9437e-04 - mae: 0.0022 - val_loss: 0.0011 - val_mae: 0.0074\n",
      "Epoch 700/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 9.9119e-04 - mae: 0.0020 - val_loss: 0.0010 - val_mae: 0.0038\n",
      "Epoch 701/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 9.9018e-04 - mae: 0.0025 - val_loss: 9.8310e-04 - val_mae: 0.0018\n",
      "Epoch 702/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 9.8034e-04 - mae: 0.0017 - val_loss: 9.8096e-04 - val_mae: 0.0020\n",
      "Epoch 703/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 9.7821e-04 - mae: 0.0018 - val_loss: 9.7546e-04 - val_mae: 0.0017\n",
      "Epoch 704/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 9.7491e-04 - mae: 0.0018 - val_loss: 0.0010 - val_mae: 0.0062\n",
      "Epoch 705/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 9.7952e-04 - mae: 0.0026 - val_loss: 9.6713e-04 - val_mae: 0.0012\n",
      "Epoch 706/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 9.6959e-04 - mae: 0.0019 - val_loss: 9.8369e-04 - val_mae: 0.0035\n",
      "Epoch 707/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 9.7745e-04 - mae: 0.0026 - val_loss: 9.6197e-04 - val_mae: 0.0014\n",
      "Epoch 708/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 9.6127e-04 - mae: 0.0015 - val_loss: 9.7148e-04 - val_mae: 0.0030\n",
      "Epoch 709/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 9.5970e-04 - mae: 0.0018 - val_loss: 9.6628e-04 - val_mae: 0.0031\n",
      "Epoch 710/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 9.5629e-04 - mae: 0.0017 - val_loss: 9.5481e-04 - val_mae: 0.0017\n",
      "Epoch 711/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 9.5337e-04 - mae: 0.0017 - val_loss: 9.4954e-04 - val_mae: 0.0012\n",
      "Epoch 712/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 9.4927e-04 - mae: 0.0015 - val_loss: 9.4597e-04 - val_mae: 0.0011\n",
      "Epoch 713/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 9.4693e-04 - mae: 0.0017 - val_loss: 9.5531e-04 - val_mae: 0.0034\n",
      "Epoch 714/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 9.4522e-04 - mae: 0.0019 - val_loss: 9.4874e-04 - val_mae: 0.0031\n",
      "Epoch 715/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 9.4110e-04 - mae: 0.0018 - val_loss: 9.3727e-04 - val_mae: 0.0015\n",
      "Epoch 716/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 9.3730e-04 - mae: 0.0017 - val_loss: 9.3383e-04 - val_mae: 0.0014\n",
      "Epoch 717/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 9.3342e-04 - mae: 0.0017 - val_loss: 9.5560e-04 - val_mae: 0.0044\n",
      "Epoch 718/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 9.3213e-04 - mae: 0.0020 - val_loss: 9.4298e-04 - val_mae: 0.0036\n",
      "Epoch 719/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 9.3060e-04 - mae: 0.0021 - val_loss: 9.2455e-04 - val_mae: 0.0016\n",
      "Epoch 720/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 9.2550e-04 - mae: 0.0019 - val_loss: 9.4402e-04 - val_mae: 0.0044\n",
      "Epoch 721/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 9.2055e-04 - mae: 0.0017 - val_loss: 9.1833e-04 - val_mae: 0.0017\n",
      "Epoch 722/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 9.1902e-04 - mae: 0.0019 - val_loss: 9.1952e-04 - val_mae: 0.0022\n",
      "Epoch 723/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 9.2105e-04 - mae: 0.0025 - val_loss: 9.1209e-04 - val_mae: 0.0016\n",
      "Epoch 724/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 9.1051e-04 - mae: 0.0016 - val_loss: 9.1071e-04 - val_mae: 0.0020\n",
      "Epoch 725/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 9.0738e-04 - mae: 0.0016 - val_loss: 9.0591e-04 - val_mae: 0.0017\n",
      "Epoch 726/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 9.0712e-04 - mae: 0.0020 - val_loss: 0.0011 - val_mae: 0.0108\n",
      "Epoch 727/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 9.1276e-04 - mae: 0.0025 - val_loss: 9.0084e-04 - val_mae: 0.0019\n",
      "Epoch 728/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 8.9956e-04 - mae: 0.0018 - val_loss: 9.0211e-04 - val_mae: 0.0023\n",
      "Epoch 729/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.9702e-04 - mae: 0.0018 - val_loss: 9.0314e-04 - val_mae: 0.0028\n",
      "Epoch 730/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.9596e-04 - mae: 0.0020 - val_loss: 8.9014e-04 - val_mae: 0.0013\n",
      "Epoch 731/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.8977e-04 - mae: 0.0016 - val_loss: 8.9138e-04 - val_mae: 0.0022\n",
      "Epoch 732/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.8650e-04 - mae: 0.0015 - val_loss: 8.9261e-04 - val_mae: 0.0030\n",
      "Epoch 733/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.8631e-04 - mae: 0.0019 - val_loss: 8.8116e-04 - val_mae: 0.0013\n",
      "Epoch 734/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.8016e-04 - mae: 0.0014 - val_loss: 8.8658e-04 - val_mae: 0.0030\n",
      "Epoch 735/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.8094e-04 - mae: 0.0020 - val_loss: 8.7893e-04 - val_mae: 0.0020\n",
      "Epoch 736/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.7515e-04 - mae: 0.0017 - val_loss: 8.7173e-04 - val_mae: 0.0012\n",
      "Epoch 737/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 8.7307e-04 - mae: 0.0018 - val_loss: 8.7888e-04 - val_mae: 0.0029\n",
      "Epoch 738/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 8.7497e-04 - mae: 0.0025 - val_loss: 8.7515e-04 - val_mae: 0.0029\n",
      "Epoch 739/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.6719e-04 - mae: 0.0018 - val_loss: 8.6541e-04 - val_mae: 0.0018\n",
      "Epoch 740/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.6257e-04 - mae: 0.0016 - val_loss: 8.5987e-04 - val_mae: 0.0013\n",
      "Epoch 741/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.6057e-04 - mae: 0.0018 - val_loss: 8.6779e-04 - val_mae: 0.0032\n",
      "Epoch 742/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 8.5888e-04 - mae: 0.0019 - val_loss: 8.5683e-04 - val_mae: 0.0018\n",
      "Epoch 743/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.5417e-04 - mae: 0.0016 - val_loss: 8.5141e-04 - val_mae: 0.0014\n",
      "Epoch 744/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.5703e-04 - mae: 0.0023 - val_loss: 8.5010e-04 - val_mae: 0.0020\n",
      "Epoch 745/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 8.4713e-04 - mae: 0.0015 - val_loss: 8.5705e-04 - val_mae: 0.0032\n",
      "Epoch 746/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.5165e-04 - mae: 0.0023 - val_loss: 9.4385e-04 - val_mae: 0.0091\n",
      "Epoch 747/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 8.4442e-04 - mae: 0.0018 - val_loss: 8.3896e-04 - val_mae: 0.0011\n",
      "Epoch 748/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.4032e-04 - mae: 0.0017 - val_loss: 8.4167e-04 - val_mae: 0.0023\n",
      "Epoch 749/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.4310e-04 - mae: 0.0023 - val_loss: 8.3461e-04 - val_mae: 0.0013\n",
      "Epoch 750/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.3387e-04 - mae: 0.0015 - val_loss: 8.3322e-04 - val_mae: 0.0017\n",
      "Epoch 751/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.3162e-04 - mae: 0.0016 - val_loss: 8.3351e-04 - val_mae: 0.0022\n",
      "Epoch 752/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.3240e-04 - mae: 0.0021 - val_loss: 8.2660e-04 - val_mae: 0.0014\n",
      "Epoch 753/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.2681e-04 - mae: 0.0017 - val_loss: 8.5248e-04 - val_mae: 0.0040\n",
      "Epoch 754/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.2408e-04 - mae: 0.0016 - val_loss: 8.2501e-04 - val_mae: 0.0020\n",
      "Epoch 755/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.2106e-04 - mae: 0.0017 - val_loss: 8.1959e-04 - val_mae: 0.0018\n",
      "Epoch 756/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.1903e-04 - mae: 0.0018 - val_loss: 8.1743e-04 - val_mae: 0.0017\n",
      "Epoch 757/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.1464e-04 - mae: 0.0015 - val_loss: 8.2048e-04 - val_mae: 0.0024\n",
      "Epoch 758/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.2049e-04 - mae: 0.0027 - val_loss: 8.1462e-04 - val_mae: 0.0024\n",
      "Epoch 759/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 8.1365e-04 - mae: 0.0022 - val_loss: 8.1184e-04 - val_mae: 0.0023\n",
      "Epoch 760/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.0720e-04 - mae: 0.0016 - val_loss: 8.0524e-04 - val_mae: 0.0014\n",
      "Epoch 761/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.0525e-04 - mae: 0.0017 - val_loss: 8.0335e-04 - val_mae: 0.0017\n",
      "Epoch 762/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 8.0499e-04 - mae: 0.0020 - val_loss: 8.1248e-04 - val_mae: 0.0033\n",
      "Epoch 763/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.9969e-04 - mae: 0.0016 - val_loss: 7.9956e-04 - val_mae: 0.0018\n",
      "Epoch 764/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.9748e-04 - mae: 0.0017 - val_loss: 7.9511e-04 - val_mae: 0.0015\n",
      "Epoch 765/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.9716e-04 - mae: 0.0020 - val_loss: 8.2879e-04 - val_mae: 0.0053\n",
      "Epoch 766/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.9719e-04 - mae: 0.0023 - val_loss: 7.9601e-04 - val_mae: 0.0025\n",
      "Epoch 767/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.8892e-04 - mae: 0.0016 - val_loss: 8.1823e-04 - val_mae: 0.0050\n",
      "Epoch 768/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.8834e-04 - mae: 0.0019 - val_loss: 7.8883e-04 - val_mae: 0.0023\n",
      "Epoch 769/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.8341e-04 - mae: 0.0015 - val_loss: 7.8559e-04 - val_mae: 0.0021\n",
      "Epoch 770/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.8170e-04 - mae: 0.0017 - val_loss: 7.9983e-04 - val_mae: 0.0041\n",
      "Epoch 771/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 7.8404e-04 - mae: 0.0023 - val_loss: 7.8202e-04 - val_mae: 0.0026\n",
      "Epoch 772/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 7.7772e-04 - mae: 0.0018 - val_loss: 7.8507e-04 - val_mae: 0.0027\n",
      "Epoch 773/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.7456e-04 - mae: 0.0018 - val_loss: 7.7257e-04 - val_mae: 0.0016\n",
      "Epoch 774/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.7311e-04 - mae: 0.0019 - val_loss: 7.7943e-04 - val_mae: 0.0028\n",
      "Epoch 775/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 7.7376e-04 - mae: 0.0023 - val_loss: 7.6746e-04 - val_mae: 0.0016\n",
      "Epoch 776/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 7.6602e-04 - mae: 0.0015 - val_loss: 7.6953e-04 - val_mae: 0.0023\n",
      "Epoch 777/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.6638e-04 - mae: 0.0020 - val_loss: 7.6382e-04 - val_mae: 0.0019\n",
      "Epoch 778/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.6046e-04 - mae: 0.0015 - val_loss: 7.6335e-04 - val_mae: 0.0022\n",
      "Epoch 779/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.6185e-04 - mae: 0.0020 - val_loss: 7.6132e-04 - val_mae: 0.0021\n",
      "Epoch 780/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 7.5588e-04 - mae: 0.0015 - val_loss: 7.5394e-04 - val_mae: 0.0013\n",
      "Epoch 781/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.5506e-04 - mae: 0.0018 - val_loss: 7.5599e-04 - val_mae: 0.0021\n",
      "Epoch 782/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.5357e-04 - mae: 0.0019 - val_loss: 7.5095e-04 - val_mae: 0.0018\n",
      "Epoch 783/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 7.6931e-04 - mae: 0.0033 - val_loss: 7.4800e-04 - val_mae: 0.0016\n",
      "Epoch 784/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.4594e-04 - mae: 0.0014 - val_loss: 7.4924e-04 - val_mae: 0.0022\n",
      "Epoch 785/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 7.4946e-04 - mae: 0.0021 - val_loss: 7.4245e-04 - val_mae: 0.0013\n",
      "Epoch 786/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.4184e-04 - mae: 0.0014 - val_loss: 7.4081e-04 - val_mae: 0.0013\n",
      "Epoch 787/2000\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 7.4043e-04 - mae: 0.0015 - val_loss: 7.3952e-04 - val_mae: 0.0016\n",
      "Epoch 788/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 7.3783e-04 - mae: 0.0015 - val_loss: 7.3715e-04 - val_mae: 0.0016\n",
      "Epoch 789/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 7.3738e-04 - mae: 0.0018 - val_loss: 7.4877e-04 - val_mae: 0.0032\n",
      "Epoch 790/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 7.3508e-04 - mae: 0.0018 - val_loss: 7.3928e-04 - val_mae: 0.0025\n",
      "Epoch 791/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.3258e-04 - mae: 0.0017 - val_loss: 7.2865e-04 - val_mae: 0.0012\n",
      "Epoch 792/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 7.2875e-04 - mae: 0.0015 - val_loss: 7.2660e-04 - val_mae: 0.0012\n",
      "Epoch 793/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 7.2984e-04 - mae: 0.0021 - val_loss: 7.7966e-04 - val_mae: 0.0067\n",
      "Epoch 794/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.2720e-04 - mae: 0.0020 - val_loss: 7.2694e-04 - val_mae: 0.0021\n",
      "Epoch 795/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.2172e-04 - mae: 0.0016 - val_loss: 7.2011e-04 - val_mae: 0.0014\n",
      "Epoch 796/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.2250e-04 - mae: 0.0020 - val_loss: 7.1821e-04 - val_mae: 0.0015\n",
      "Epoch 797/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.2141e-04 - mae: 0.0021 - val_loss: 7.2483e-04 - val_mae: 0.0031\n",
      "Epoch 798/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 7.1737e-04 - mae: 0.0020 - val_loss: 7.1398e-04 - val_mae: 0.0015\n",
      "Epoch 799/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.1956e-04 - mae: 0.0024 - val_loss: 7.1406e-04 - val_mae: 0.0019\n",
      "Epoch 800/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 7.0994e-04 - mae: 0.0014 - val_loss: 7.1152e-04 - val_mae: 0.0019\n",
      "Epoch 801/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 7.1174e-04 - mae: 0.0020 - val_loss: 7.0623e-04 - val_mae: 0.0012\n",
      "Epoch 802/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.0932e-04 - mae: 0.0020 - val_loss: 7.1242e-04 - val_mae: 0.0026\n",
      "Epoch 803/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 7.0490e-04 - mae: 0.0017 - val_loss: 7.0203e-04 - val_mae: 0.0012\n",
      "Epoch 804/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.0337e-04 - mae: 0.0017 - val_loss: 7.0515e-04 - val_mae: 0.0022\n",
      "Epoch 805/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.0091e-04 - mae: 0.0017 - val_loss: 7.0527e-04 - val_mae: 0.0028\n",
      "Epoch 806/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 7.0149e-04 - mae: 0.0021 - val_loss: 7.0219e-04 - val_mae: 0.0026\n",
      "Epoch 807/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.9565e-04 - mae: 0.0015 - val_loss: 7.3094e-04 - val_mae: 0.0055\n",
      "Epoch 808/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.9586e-04 - mae: 0.0019 - val_loss: 6.9507e-04 - val_mae: 0.0022\n",
      "Epoch 809/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 6.9132e-04 - mae: 0.0016 - val_loss: 7.1788e-04 - val_mae: 0.0049\n",
      "Epoch 810/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.9081e-04 - mae: 0.0018 - val_loss: 6.9321e-04 - val_mae: 0.0022\n",
      "Epoch 811/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.8709e-04 - mae: 0.0016 - val_loss: 7.0771e-04 - val_mae: 0.0038\n",
      "Epoch 812/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.8848e-04 - mae: 0.0021 - val_loss: 6.8352e-04 - val_mae: 0.0016\n",
      "Epoch 813/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.8366e-04 - mae: 0.0018 - val_loss: 6.8139e-04 - val_mae: 0.0017\n",
      "Epoch 814/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.8067e-04 - mae: 0.0017 - val_loss: 6.9100e-04 - val_mae: 0.0033\n",
      "Epoch 815/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 6.7880e-04 - mae: 0.0017 - val_loss: 6.8350e-04 - val_mae: 0.0028\n",
      "Epoch 816/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 6.7943e-04 - mae: 0.0021 - val_loss: 7.6680e-04 - val_mae: 0.0071\n",
      "Epoch 817/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 6.7871e-04 - mae: 0.0022 - val_loss: 6.7218e-04 - val_mae: 0.0014\n",
      "Epoch 818/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 6.7203e-04 - mae: 0.0017 - val_loss: 6.7405e-04 - val_mae: 0.0022\n",
      "Epoch 819/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 6.7074e-04 - mae: 0.0018 - val_loss: 6.8480e-04 - val_mae: 0.0038\n",
      "Epoch 820/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 6.6894e-04 - mae: 0.0017 - val_loss: 6.7625e-04 - val_mae: 0.0034\n",
      "Epoch 821/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 6.6670e-04 - mae: 0.0018 - val_loss: 6.6610e-04 - val_mae: 0.0019\n",
      "Epoch 822/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 6.6513e-04 - mae: 0.0018 - val_loss: 6.6103e-04 - val_mae: 0.0013\n",
      "Epoch 823/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 6.6091e-04 - mae: 0.0015 - val_loss: 7.2562e-04 - val_mae: 0.0066\n",
      "Epoch 824/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 6.6230e-04 - mae: 0.0018 - val_loss: 6.5673e-04 - val_mae: 0.0012\n",
      "Epoch 825/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.5756e-04 - mae: 0.0017 - val_loss: 6.5935e-04 - val_mae: 0.0022\n",
      "Epoch 826/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 6.5597e-04 - mae: 0.0018 - val_loss: 6.8710e-04 - val_mae: 0.0046\n",
      "Epoch 827/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 6.5899e-04 - mae: 0.0024 - val_loss: 6.5245e-04 - val_mae: 0.0016\n",
      "Epoch 828/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.5431e-04 - mae: 0.0021 - val_loss: 6.4992e-04 - val_mae: 0.0015\n",
      "Epoch 829/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 6.4955e-04 - mae: 0.0017 - val_loss: 6.5717e-04 - val_mae: 0.0033\n",
      "Epoch 830/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.5474e-04 - mae: 0.0024 - val_loss: 6.8196e-04 - val_mae: 0.0054\n",
      "Epoch 831/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 6.4670e-04 - mae: 0.0018 - val_loss: 6.4245e-04 - val_mae: 0.0011\n",
      "Epoch 832/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 6.4347e-04 - mae: 0.0016 - val_loss: 6.4736e-04 - val_mae: 0.0024\n",
      "Epoch 833/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 6.4114e-04 - mae: 0.0015 - val_loss: 6.4713e-04 - val_mae: 0.0025\n",
      "Epoch 834/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.3938e-04 - mae: 0.0015 - val_loss: 6.3806e-04 - val_mae: 0.0013\n",
      "Epoch 835/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.3804e-04 - mae: 0.0016 - val_loss: 6.3701e-04 - val_mae: 0.0016\n",
      "Epoch 836/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.3761e-04 - mae: 0.0019 - val_loss: 6.3661e-04 - val_mae: 0.0021\n",
      "Epoch 837/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.3388e-04 - mae: 0.0016 - val_loss: 6.3239e-04 - val_mae: 0.0015\n",
      "Epoch 838/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.3552e-04 - mae: 0.0020 - val_loss: 6.3212e-04 - val_mae: 0.0018\n",
      "Epoch 839/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.2961e-04 - mae: 0.0015 - val_loss: 6.4598e-04 - val_mae: 0.0036\n",
      "Epoch 840/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.3103e-04 - mae: 0.0020 - val_loss: 6.2785e-04 - val_mae: 0.0017\n",
      "Epoch 841/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 6.2572e-04 - mae: 0.0015 - val_loss: 6.2347e-04 - val_mae: 0.0013\n",
      "Epoch 842/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.3308e-04 - mae: 0.0026 - val_loss: 6.2196e-04 - val_mae: 0.0013\n",
      "Epoch 843/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.2146e-04 - mae: 0.0015 - val_loss: 6.2444e-04 - val_mae: 0.0020\n",
      "Epoch 844/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.2133e-04 - mae: 0.0017 - val_loss: 6.2475e-04 - val_mae: 0.0028\n",
      "Epoch 845/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.1892e-04 - mae: 0.0016 - val_loss: 6.1974e-04 - val_mae: 0.0019\n",
      "Epoch 846/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.1753e-04 - mae: 0.0017 - val_loss: 6.1643e-04 - val_mae: 0.0017\n",
      "Epoch 847/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.2451e-04 - mae: 0.0027 - val_loss: 6.3061e-04 - val_mae: 0.0037\n",
      "Epoch 848/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.1352e-04 - mae: 0.0016 - val_loss: 6.1497e-04 - val_mae: 0.0020\n",
      "Epoch 849/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.1068e-04 - mae: 0.0014 - val_loss: 6.1350e-04 - val_mae: 0.0021\n",
      "Epoch 850/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.1068e-04 - mae: 0.0017 - val_loss: 6.0758e-04 - val_mae: 0.0014\n",
      "Epoch 851/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.0761e-04 - mae: 0.0015 - val_loss: 6.0659e-04 - val_mae: 0.0015\n",
      "Epoch 852/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.0772e-04 - mae: 0.0018 - val_loss: 6.0358e-04 - val_mae: 0.0013\n",
      "Epoch 853/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 6.0446e-04 - mae: 0.0016 - val_loss: 6.4572e-04 - val_mae: 0.0051\n",
      "Epoch 854/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 6.0831e-04 - mae: 0.0024 - val_loss: 6.0719e-04 - val_mae: 0.0025\n",
      "Epoch 855/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.9969e-04 - mae: 0.0014 - val_loss: 6.0211e-04 - val_mae: 0.0018\n",
      "Epoch 856/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 5.9908e-04 - mae: 0.0016 - val_loss: 6.1800e-04 - val_mae: 0.0038\n",
      "Epoch 857/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 5.9806e-04 - mae: 0.0017 - val_loss: 5.9565e-04 - val_mae: 0.0015\n",
      "Epoch 858/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 5.9724e-04 - mae: 0.0019 - val_loss: 5.9728e-04 - val_mae: 0.0021\n",
      "Epoch 859/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 5.9447e-04 - mae: 0.0018 - val_loss: 5.9830e-04 - val_mae: 0.0027\n",
      "Epoch 860/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.9048e-04 - mae: 0.0014 - val_loss: 5.9395e-04 - val_mae: 0.0023\n",
      "Epoch 861/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 5.8895e-04 - mae: 0.0015 - val_loss: 6.0944e-04 - val_mae: 0.0040\n",
      "Epoch 862/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 5.9427e-04 - mae: 0.0024 - val_loss: 5.8620e-04 - val_mae: 0.0014\n",
      "Epoch 863/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 5.8527e-04 - mae: 0.0015 - val_loss: 5.9126e-04 - val_mae: 0.0024\n",
      "Epoch 864/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 5.8634e-04 - mae: 0.0019 - val_loss: 5.8303e-04 - val_mae: 0.0015\n",
      "Epoch 865/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 5.8247e-04 - mae: 0.0016 - val_loss: 5.8195e-04 - val_mae: 0.0017\n",
      "Epoch 866/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 5.8053e-04 - mae: 0.0016 - val_loss: 5.8206e-04 - val_mae: 0.0019\n",
      "Epoch 867/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.7891e-04 - mae: 0.0016 - val_loss: 7.1609e-04 - val_mae: 0.0094\n",
      "Epoch 868/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 5.8330e-04 - mae: 0.0022 - val_loss: 5.8036e-04 - val_mae: 0.0024\n",
      "Epoch 869/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.7601e-04 - mae: 0.0017 - val_loss: 5.7756e-04 - val_mae: 0.0020\n",
      "Epoch 870/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.7236e-04 - mae: 0.0014 - val_loss: 5.7140e-04 - val_mae: 0.0013\n",
      "Epoch 871/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.7492e-04 - mae: 0.0020 - val_loss: 5.7080e-04 - val_mae: 0.0016\n",
      "Epoch 872/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 5.6999e-04 - mae: 0.0015 - val_loss: 5.8688e-04 - val_mae: 0.0035\n",
      "Epoch 873/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 5.7116e-04 - mae: 0.0020 - val_loss: 5.6681e-04 - val_mae: 0.0014\n",
      "Epoch 874/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.6742e-04 - mae: 0.0017 - val_loss: 5.6714e-04 - val_mae: 0.0019\n",
      "Epoch 875/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 5.6644e-04 - mae: 0.0019 - val_loss: 5.7883e-04 - val_mae: 0.0038\n",
      "Epoch 876/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 5.6607e-04 - mae: 0.0019 - val_loss: 5.6409e-04 - val_mae: 0.0018\n",
      "Epoch 877/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 5.6060e-04 - mae: 0.0014 - val_loss: 5.8523e-04 - val_mae: 0.0042\n",
      "Epoch 878/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 5.6259e-04 - mae: 0.0019 - val_loss: 5.5736e-04 - val_mae: 0.0011\n",
      "Epoch 879/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.5872e-04 - mae: 0.0017 - val_loss: 5.5602e-04 - val_mae: 0.0012\n",
      "Epoch 880/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 5.5686e-04 - mae: 0.0016 - val_loss: 5.6166e-04 - val_mae: 0.0026\n",
      "Epoch 881/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 5.5483e-04 - mae: 0.0015 - val_loss: 5.5276e-04 - val_mae: 0.0013\n",
      "Epoch 882/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 5.5630e-04 - mae: 0.0021 - val_loss: 5.6070e-04 - val_mae: 0.0029\n",
      "Epoch 883/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 5.5265e-04 - mae: 0.0018 - val_loss: 5.6963e-04 - val_mae: 0.0036\n",
      "Epoch 884/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 5.5020e-04 - mae: 0.0016 - val_loss: 5.4930e-04 - val_mae: 0.0017\n",
      "Epoch 885/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 5.4984e-04 - mae: 0.0018 - val_loss: 5.5269e-04 - val_mae: 0.0025\n",
      "Epoch 886/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.4812e-04 - mae: 0.0018 - val_loss: 5.7661e-04 - val_mae: 0.0042\n",
      "Epoch 887/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.5644e-04 - mae: 0.0027 - val_loss: 5.4367e-04 - val_mae: 0.0013\n",
      "Epoch 888/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 5.4292e-04 - mae: 0.0014 - val_loss: 5.4155e-04 - val_mae: 0.0012\n",
      "Epoch 889/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 5.4255e-04 - mae: 0.0016 - val_loss: 5.4042e-04 - val_mae: 0.0014\n",
      "Epoch 890/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.3952e-04 - mae: 0.0013 - val_loss: 5.7470e-04 - val_mae: 0.0052\n",
      "Epoch 891/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.4066e-04 - mae: 0.0018 - val_loss: 5.3737e-04 - val_mae: 0.0014\n",
      "Epoch 892/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.3726e-04 - mae: 0.0015 - val_loss: 5.6808e-04 - val_mae: 0.0049\n",
      "Epoch 893/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.3703e-04 - mae: 0.0017 - val_loss: 5.3456e-04 - val_mae: 0.0014\n",
      "Epoch 894/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.3395e-04 - mae: 0.0015 - val_loss: 5.3538e-04 - val_mae: 0.0020\n",
      "Epoch 895/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.3792e-04 - mae: 0.0022 - val_loss: 5.4625e-04 - val_mae: 0.0039\n",
      "Epoch 896/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.3127e-04 - mae: 0.0016 - val_loss: 5.3171e-04 - val_mae: 0.0017\n",
      "Epoch 897/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.2997e-04 - mae: 0.0016 - val_loss: 5.2909e-04 - val_mae: 0.0016\n",
      "Epoch 898/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.2984e-04 - mae: 0.0018 - val_loss: 5.2782e-04 - val_mae: 0.0018\n",
      "Epoch 899/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.2749e-04 - mae: 0.0017 - val_loss: 5.2415e-04 - val_mae: 0.0011\n",
      "Epoch 900/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.2513e-04 - mae: 0.0015 - val_loss: 5.4098e-04 - val_mae: 0.0037\n",
      "Epoch 901/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.2656e-04 - mae: 0.0019 - val_loss: 5.2223e-04 - val_mae: 0.0015\n",
      "Epoch 902/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.2252e-04 - mae: 0.0016 - val_loss: 5.1994e-04 - val_mae: 0.0012\n",
      "Epoch 903/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.2068e-04 - mae: 0.0016 - val_loss: 5.1894e-04 - val_mae: 0.0014\n",
      "Epoch 904/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.1905e-04 - mae: 0.0015 - val_loss: 5.4072e-04 - val_mae: 0.0036\n",
      "Epoch 905/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.1778e-04 - mae: 0.0016 - val_loss: 5.1821e-04 - val_mae: 0.0020\n",
      "Epoch 906/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.1493e-04 - mae: 0.0014 - val_loss: 5.1983e-04 - val_mae: 0.0025\n",
      "Epoch 907/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.1421e-04 - mae: 0.0016 - val_loss: 5.2013e-04 - val_mae: 0.0025\n",
      "Epoch 908/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.1262e-04 - mae: 0.0016 - val_loss: 5.1627e-04 - val_mae: 0.0024\n",
      "Epoch 909/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.1103e-04 - mae: 0.0016 - val_loss: 5.1238e-04 - val_mae: 0.0020\n",
      "Epoch 910/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.1042e-04 - mae: 0.0018 - val_loss: 5.1011e-04 - val_mae: 0.0019\n",
      "Epoch 911/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.1234e-04 - mae: 0.0022 - val_loss: 5.1163e-04 - val_mae: 0.0025\n",
      "Epoch 912/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.0699e-04 - mae: 0.0017 - val_loss: 5.0363e-04 - val_mae: 0.0011\n",
      "Epoch 913/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.0468e-04 - mae: 0.0016 - val_loss: 5.0322e-04 - val_mae: 0.0014\n",
      "Epoch 914/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.0306e-04 - mae: 0.0015 - val_loss: 5.0159e-04 - val_mae: 0.0014\n",
      "Epoch 915/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.0490e-04 - mae: 0.0020 - val_loss: 5.0019e-04 - val_mae: 0.0013\n",
      "Epoch 916/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.0216e-04 - mae: 0.0018 - val_loss: 5.1678e-04 - val_mae: 0.0038\n",
      "Epoch 917/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 5.0166e-04 - mae: 0.0020 - val_loss: 4.9686e-04 - val_mae: 0.0012\n",
      "Epoch 918/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.9650e-04 - mae: 0.0014 - val_loss: 5.0305e-04 - val_mae: 0.0025\n",
      "Epoch 919/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.9773e-04 - mae: 0.0019 - val_loss: 4.9340e-04 - val_mae: 0.0011\n",
      "Epoch 920/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.9442e-04 - mae: 0.0016 - val_loss: 4.9525e-04 - val_mae: 0.0018\n",
      "Epoch 921/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.9277e-04 - mae: 0.0015 - val_loss: 5.1607e-04 - val_mae: 0.0041\n",
      "Epoch 922/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.9290e-04 - mae: 0.0018 - val_loss: 4.9232e-04 - val_mae: 0.0018\n",
      "Epoch 923/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.9094e-04 - mae: 0.0017 - val_loss: 4.9756e-04 - val_mae: 0.0029\n",
      "Epoch 924/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.9022e-04 - mae: 0.0018 - val_loss: 4.9384e-04 - val_mae: 0.0024\n",
      "Epoch 925/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.8706e-04 - mae: 0.0015 - val_loss: 5.0863e-04 - val_mae: 0.0037\n",
      "Epoch 926/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.8859e-04 - mae: 0.0020 - val_loss: 4.8395e-04 - val_mae: 0.0012\n",
      "Epoch 927/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.8497e-04 - mae: 0.0017 - val_loss: 4.8562e-04 - val_mae: 0.0019\n",
      "Epoch 928/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.8316e-04 - mae: 0.0016 - val_loss: 4.8599e-04 - val_mae: 0.0022\n",
      "Epoch 929/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.8140e-04 - mae: 0.0015 - val_loss: 4.8581e-04 - val_mae: 0.0024\n",
      "Epoch 930/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.8203e-04 - mae: 0.0019 - val_loss: 4.8101e-04 - val_mae: 0.0018\n",
      "Epoch 931/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.7906e-04 - mae: 0.0016 - val_loss: 4.8856e-04 - val_mae: 0.0034\n",
      "Epoch 932/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.7919e-04 - mae: 0.0019 - val_loss: 4.7606e-04 - val_mae: 0.0014\n",
      "Epoch 933/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.7574e-04 - mae: 0.0015 - val_loss: 4.7378e-04 - val_mae: 0.0012\n",
      "Epoch 934/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.7567e-04 - mae: 0.0017 - val_loss: 4.7424e-04 - val_mae: 0.0018\n",
      "Epoch 935/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.7315e-04 - mae: 0.0016 - val_loss: 4.7720e-04 - val_mae: 0.0023\n",
      "Epoch 936/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.7197e-04 - mae: 0.0016 - val_loss: 4.9298e-04 - val_mae: 0.0043\n",
      "Epoch 937/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.7285e-04 - mae: 0.0020 - val_loss: 4.6918e-04 - val_mae: 0.0015\n",
      "Epoch 938/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.7041e-04 - mae: 0.0018 - val_loss: 4.8470e-04 - val_mae: 0.0037\n",
      "Epoch 939/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.6850e-04 - mae: 0.0017 - val_loss: 4.9264e-04 - val_mae: 0.0041\n",
      "Epoch 940/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.6807e-04 - mae: 0.0018 - val_loss: 4.6501e-04 - val_mae: 0.0015\n",
      "Epoch 941/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.6489e-04 - mae: 0.0015 - val_loss: 4.7050e-04 - val_mae: 0.0024\n",
      "Epoch 942/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.6337e-04 - mae: 0.0015 - val_loss: 4.6247e-04 - val_mae: 0.0013\n",
      "Epoch 943/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.6402e-04 - mae: 0.0018 - val_loss: 4.6450e-04 - val_mae: 0.0020\n",
      "Epoch 944/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.6161e-04 - mae: 0.0016 - val_loss: 4.6192e-04 - val_mae: 0.0017\n",
      "Epoch 945/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.5849e-04 - mae: 0.0013 - val_loss: 4.6308e-04 - val_mae: 0.0022\n",
      "Epoch 946/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.5895e-04 - mae: 0.0017 - val_loss: 4.5617e-04 - val_mae: 0.0012\n",
      "Epoch 947/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.5685e-04 - mae: 0.0015 - val_loss: 4.6060e-04 - val_mae: 0.0024\n",
      "Epoch 948/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.5645e-04 - mae: 0.0017 - val_loss: 5.0397e-04 - val_mae: 0.0053\n",
      "Epoch 949/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.5915e-04 - mae: 0.0021 - val_loss: 4.5250e-04 - val_mae: 0.0013\n",
      "Epoch 950/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.5724e-04 - mae: 0.0020 - val_loss: 4.5133e-04 - val_mae: 0.0013\n",
      "Epoch 951/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.5096e-04 - mae: 0.0014 - val_loss: 4.4973e-04 - val_mae: 0.0012\n",
      "Epoch 952/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.4992e-04 - mae: 0.0014 - val_loss: 4.5003e-04 - val_mae: 0.0015\n",
      "Epoch 953/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.4998e-04 - mae: 0.0017 - val_loss: 4.5042e-04 - val_mae: 0.0018\n",
      "Epoch 954/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.4853e-04 - mae: 0.0016 - val_loss: 4.4676e-04 - val_mae: 0.0014\n",
      "Epoch 955/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.4781e-04 - mae: 0.0017 - val_loss: 4.5526e-04 - val_mae: 0.0027\n",
      "Epoch 956/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.4492e-04 - mae: 0.0014 - val_loss: 4.4758e-04 - val_mae: 0.0020\n",
      "Epoch 957/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.4544e-04 - mae: 0.0018 - val_loss: 4.4192e-04 - val_mae: 0.0011\n",
      "Epoch 958/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.4408e-04 - mae: 0.0018 - val_loss: 4.4441e-04 - val_mae: 0.0020\n",
      "Epoch 959/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.4172e-04 - mae: 0.0015 - val_loss: 4.4440e-04 - val_mae: 0.0021\n",
      "Epoch 960/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.4348e-04 - mae: 0.0020 - val_loss: 4.4209e-04 - val_mae: 0.0021\n",
      "Epoch 961/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.3858e-04 - mae: 0.0014 - val_loss: 4.3991e-04 - val_mae: 0.0017\n",
      "Epoch 962/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.3737e-04 - mae: 0.0014 - val_loss: 4.3577e-04 - val_mae: 0.0011\n",
      "Epoch 963/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.3783e-04 - mae: 0.0017 - val_loss: 4.3521e-04 - val_mae: 0.0013\n",
      "Epoch 964/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.3671e-04 - mae: 0.0017 - val_loss: 4.3760e-04 - val_mae: 0.0022\n",
      "Epoch 965/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.3476e-04 - mae: 0.0016 - val_loss: 4.3336e-04 - val_mae: 0.0014\n",
      "Epoch 966/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.3283e-04 - mae: 0.0015 - val_loss: 4.3586e-04 - val_mae: 0.0024\n",
      "Epoch 967/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.3290e-04 - mae: 0.0017 - val_loss: 4.2985e-04 - val_mae: 0.0012\n",
      "Epoch 968/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.2981e-04 - mae: 0.0014 - val_loss: 4.2818e-04 - val_mae: 0.0011\n",
      "Epoch 969/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.2955e-04 - mae: 0.0016 - val_loss: 4.4113e-04 - val_mae: 0.0030\n",
      "Epoch 970/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.3144e-04 - mae: 0.0020 - val_loss: 4.2658e-04 - val_mae: 0.0014\n",
      "Epoch 971/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.2797e-04 - mae: 0.0017 - val_loss: 4.2731e-04 - val_mae: 0.0018\n",
      "Epoch 972/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.2649e-04 - mae: 0.0017 - val_loss: 4.2561e-04 - val_mae: 0.0016\n",
      "Epoch 973/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.2567e-04 - mae: 0.0017 - val_loss: 4.2436e-04 - val_mae: 0.0016\n",
      "Epoch 974/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.2276e-04 - mae: 0.0014 - val_loss: 4.2321e-04 - val_mae: 0.0017\n",
      "Epoch 975/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.2352e-04 - mae: 0.0018 - val_loss: 4.2307e-04 - val_mae: 0.0018\n",
      "Epoch 976/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.2116e-04 - mae: 0.0016 - val_loss: 4.1931e-04 - val_mae: 0.0012\n",
      "Epoch 977/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.2033e-04 - mae: 0.0016 - val_loss: 4.3691e-04 - val_mae: 0.0038\n",
      "Epoch 978/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.2198e-04 - mae: 0.0021 - val_loss: 4.2985e-04 - val_mae: 0.0037\n",
      "Epoch 979/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.1859e-04 - mae: 0.0017 - val_loss: 4.1694e-04 - val_mae: 0.0015\n",
      "Epoch 980/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.1524e-04 - mae: 0.0013 - val_loss: 4.1447e-04 - val_mae: 0.0012\n",
      "Epoch 981/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.1496e-04 - mae: 0.0015 - val_loss: 4.1498e-04 - val_mae: 0.0016\n",
      "Epoch 982/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.1668e-04 - mae: 0.0019 - val_loss: 4.1381e-04 - val_mae: 0.0016\n",
      "Epoch 983/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.1367e-04 - mae: 0.0017 - val_loss: 4.1302e-04 - val_mae: 0.0016\n",
      "Epoch 984/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.1158e-04 - mae: 0.0015 - val_loss: 4.1251e-04 - val_mae: 0.0017\n",
      "Epoch 985/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.1088e-04 - mae: 0.0016 - val_loss: 4.2116e-04 - val_mae: 0.0029\n",
      "Epoch 986/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.1147e-04 - mae: 0.0019 - val_loss: 4.0801e-04 - val_mae: 0.0012\n",
      "Epoch 987/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.0722e-04 - mae: 0.0013 - val_loss: 4.0712e-04 - val_mae: 0.0014\n",
      "Epoch 988/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.0810e-04 - mae: 0.0017 - val_loss: 4.1371e-04 - val_mae: 0.0029\n",
      "Epoch 989/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.0736e-04 - mae: 0.0018 - val_loss: 4.1132e-04 - val_mae: 0.0026\n",
      "Epoch 990/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.0603e-04 - mae: 0.0017 - val_loss: 4.4926e-04 - val_mae: 0.0061\n",
      "Epoch 991/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.0473e-04 - mae: 0.0016 - val_loss: 4.0273e-04 - val_mae: 0.0014\n",
      "Epoch 992/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.0261e-04 - mae: 0.0015 - val_loss: 4.1063e-04 - val_mae: 0.0027\n",
      "Epoch 993/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.0408e-04 - mae: 0.0019 - val_loss: 4.0206e-04 - val_mae: 0.0016\n",
      "Epoch 994/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.0057e-04 - mae: 0.0015 - val_loss: 4.2822e-04 - val_mae: 0.0050\n",
      "Epoch 995/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 4.0131e-04 - mae: 0.0017 - val_loss: 4.2033e-04 - val_mae: 0.0039\n",
      "Epoch 996/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.9852e-04 - mae: 0.0015 - val_loss: 3.9676e-04 - val_mae: 0.0012\n",
      "Epoch 997/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.9910e-04 - mae: 0.0018 - val_loss: 3.9701e-04 - val_mae: 0.0015\n",
      "Epoch 998/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.9939e-04 - mae: 0.0020 - val_loss: 4.1679e-04 - val_mae: 0.0038\n",
      "Epoch 999/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.9854e-04 - mae: 0.0019 - val_loss: 4.0027e-04 - val_mae: 0.0024\n",
      "Epoch 1000/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.9597e-04 - mae: 0.0017 - val_loss: 3.9616e-04 - val_mae: 0.0020\n",
      "Epoch 1001/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.9349e-04 - mae: 0.0015 - val_loss: 3.9230e-04 - val_mae: 0.0013\n",
      "Epoch 1002/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.9251e-04 - mae: 0.0015 - val_loss: 3.9851e-04 - val_mae: 0.0025\n",
      "Epoch 1003/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.9218e-04 - mae: 0.0016 - val_loss: 3.9127e-04 - val_mae: 0.0015\n",
      "Epoch 1004/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.9132e-04 - mae: 0.0016 - val_loss: 3.9734e-04 - val_mae: 0.0030\n",
      "Epoch 1005/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.8960e-04 - mae: 0.0015 - val_loss: 3.8781e-04 - val_mae: 0.0011\n",
      "Epoch 1006/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.8796e-04 - mae: 0.0014 - val_loss: 4.0728e-04 - val_mae: 0.0041\n",
      "Epoch 1007/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.8839e-04 - mae: 0.0016 - val_loss: 3.8586e-04 - val_mae: 0.0012\n",
      "Epoch 1008/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.8731e-04 - mae: 0.0016 - val_loss: 3.8514e-04 - val_mae: 0.0013\n",
      "Epoch 1009/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.8725e-04 - mae: 0.0017 - val_loss: 3.9154e-04 - val_mae: 0.0028\n",
      "Epoch 1010/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.8542e-04 - mae: 0.0017 - val_loss: 3.9102e-04 - val_mae: 0.0028\n",
      "Epoch 1011/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.8521e-04 - mae: 0.0018 - val_loss: 3.9605e-04 - val_mae: 0.0037\n",
      "Epoch 1012/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.8513e-04 - mae: 0.0019 - val_loss: 3.8742e-04 - val_mae: 0.0026\n",
      "Epoch 1013/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.8275e-04 - mae: 0.0017 - val_loss: 3.8430e-04 - val_mae: 0.0022\n",
      "Epoch 1014/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.8032e-04 - mae: 0.0014 - val_loss: 3.7886e-04 - val_mae: 0.0011\n",
      "Epoch 1015/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.8009e-04 - mae: 0.0016 - val_loss: 3.8013e-04 - val_mae: 0.0016\n",
      "Epoch 1016/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.8000e-04 - mae: 0.0017 - val_loss: 4.2747e-04 - val_mae: 0.0059\n",
      "Epoch 1017/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.8183e-04 - mae: 0.0020 - val_loss: 4.6963e-04 - val_mae: 0.0078\n",
      "Epoch 1018/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.8282e-04 - mae: 0.0022 - val_loss: 3.7572e-04 - val_mae: 0.0013\n",
      "Epoch 1019/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.7626e-04 - mae: 0.0015 - val_loss: 3.8091e-04 - val_mae: 0.0025\n",
      "Epoch 1020/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.7496e-04 - mae: 0.0014 - val_loss: 3.7329e-04 - val_mae: 0.0010\n",
      "Epoch 1021/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.7317e-04 - mae: 0.0012 - val_loss: 3.7412e-04 - val_mae: 0.0015\n",
      "Epoch 1022/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.7431e-04 - mae: 0.0016 - val_loss: 3.7285e-04 - val_mae: 0.0014\n",
      "Epoch 1023/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.7250e-04 - mae: 0.0015 - val_loss: 3.7053e-04 - val_mae: 0.0010\n",
      "Epoch 1024/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.7401e-04 - mae: 0.0019 - val_loss: 3.8138e-04 - val_mae: 0.0030\n",
      "Epoch 1025/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.7221e-04 - mae: 0.0017 - val_loss: 3.7088e-04 - val_mae: 0.0016\n",
      "Epoch 1026/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.7142e-04 - mae: 0.0018 - val_loss: 3.6789e-04 - val_mae: 0.0011\n",
      "Epoch 1027/2000\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 3.6975e-04 - mae: 0.0016 - val_loss: 3.7048e-04 - val_mae: 0.0017\n",
      "Epoch 1028/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.6770e-04 - mae: 0.0014 - val_loss: 3.7059e-04 - val_mae: 0.0022\n",
      "Epoch 1029/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.6989e-04 - mae: 0.0019 - val_loss: 3.6784e-04 - val_mae: 0.0017\n",
      "Epoch 1030/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.6728e-04 - mae: 0.0016 - val_loss: 3.7736e-04 - val_mae: 0.0035\n",
      "Epoch 1031/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.6722e-04 - mae: 0.0018 - val_loss: 3.6354e-04 - val_mae: 0.0011\n",
      "Epoch 1032/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.6392e-04 - mae: 0.0014 - val_loss: 3.6648e-04 - val_mae: 0.0020\n",
      "Epoch 1033/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.6493e-04 - mae: 0.0018 - val_loss: 3.6937e-04 - val_mae: 0.0028\n",
      "Epoch 1034/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.6606e-04 - mae: 0.0019 - val_loss: 3.6182e-04 - val_mae: 0.0013\n",
      "Epoch 1035/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.6227e-04 - mae: 0.0015 - val_loss: 3.6879e-04 - val_mae: 0.0028\n",
      "Epoch 1036/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.6228e-04 - mae: 0.0017 - val_loss: 3.6069e-04 - val_mae: 0.0016\n",
      "Epoch 1037/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.6004e-04 - mae: 0.0014 - val_loss: 3.5846e-04 - val_mae: 0.0011\n",
      "Epoch 1038/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 3.6234e-04 - mae: 0.0019 - val_loss: 3.6435e-04 - val_mae: 0.0022\n",
      "Epoch 1039/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.5861e-04 - mae: 0.0015 - val_loss: 3.5875e-04 - val_mae: 0.0015\n",
      "Epoch 1040/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.5794e-04 - mae: 0.0015 - val_loss: 3.5932e-04 - val_mae: 0.0019\n",
      "Epoch 1041/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.5689e-04 - mae: 0.0014 - val_loss: 3.5571e-04 - val_mae: 0.0013\n",
      "Epoch 1042/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.5536e-04 - mae: 0.0014 - val_loss: 3.5423e-04 - val_mae: 0.0011\n",
      "Epoch 1043/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.5628e-04 - mae: 0.0017 - val_loss: 3.6013e-04 - val_mae: 0.0027\n",
      "Epoch 1044/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.5568e-04 - mae: 0.0017 - val_loss: 3.8092e-04 - val_mae: 0.0049\n",
      "Epoch 1045/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.5522e-04 - mae: 0.0017 - val_loss: 3.7101e-04 - val_mae: 0.0043\n",
      "Epoch 1046/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.5329e-04 - mae: 0.0016 - val_loss: 3.5148e-04 - val_mae: 0.0013\n",
      "Epoch 1047/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.5177e-04 - mae: 0.0015 - val_loss: 3.5242e-04 - val_mae: 0.0017\n",
      "Epoch 1048/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.5301e-04 - mae: 0.0019 - val_loss: 3.4935e-04 - val_mae: 0.0012\n",
      "Epoch 1049/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.4931e-04 - mae: 0.0013 - val_loss: 3.4925e-04 - val_mae: 0.0013\n",
      "Epoch 1050/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.4939e-04 - mae: 0.0015 - val_loss: 3.5416e-04 - val_mae: 0.0023\n",
      "Epoch 1051/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.5005e-04 - mae: 0.0018 - val_loss: 3.4679e-04 - val_mae: 0.0012\n",
      "Epoch 1052/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.4753e-04 - mae: 0.0015 - val_loss: 3.4902e-04 - val_mae: 0.0017\n",
      "Epoch 1053/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.4792e-04 - mae: 0.0017 - val_loss: 3.4459e-04 - val_mae: 0.0010\n",
      "Epoch 1054/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.4513e-04 - mae: 0.0014 - val_loss: 3.4580e-04 - val_mae: 0.0016\n",
      "Epoch 1055/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.4707e-04 - mae: 0.0018 - val_loss: 3.4334e-04 - val_mae: 0.0011\n",
      "Epoch 1056/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.4570e-04 - mae: 0.0018 - val_loss: 3.4360e-04 - val_mae: 0.0015\n",
      "Epoch 1057/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.4409e-04 - mae: 0.0017 - val_loss: 3.4412e-04 - val_mae: 0.0018\n",
      "Epoch 1058/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.4530e-04 - mae: 0.0019 - val_loss: 3.4159e-04 - val_mae: 0.0014\n",
      "Epoch 1059/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.4093e-04 - mae: 0.0013 - val_loss: 3.4206e-04 - val_mae: 0.0017\n",
      "Epoch 1060/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.4152e-04 - mae: 0.0016 - val_loss: 3.4755e-04 - val_mae: 0.0028\n",
      "Epoch 1061/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.4341e-04 - mae: 0.0021 - val_loss: 3.3891e-04 - val_mae: 0.0012\n",
      "Epoch 1062/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.3987e-04 - mae: 0.0016 - val_loss: 3.3988e-04 - val_mae: 0.0016\n",
      "Epoch 1063/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.3905e-04 - mae: 0.0015 - val_loss: 3.3918e-04 - val_mae: 0.0018\n",
      "Epoch 1064/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.3903e-04 - mae: 0.0017 - val_loss: 3.3681e-04 - val_mae: 0.0013\n",
      "Epoch 1065/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.3673e-04 - mae: 0.0014 - val_loss: 3.6481e-04 - val_mae: 0.0047\n",
      "Epoch 1066/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.3868e-04 - mae: 0.0018 - val_loss: 3.3644e-04 - val_mae: 0.0015\n",
      "Epoch 1067/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.3611e-04 - mae: 0.0016 - val_loss: 3.4294e-04 - val_mae: 0.0028\n",
      "Epoch 1068/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.3869e-04 - mae: 0.0020 - val_loss: 3.4070e-04 - val_mae: 0.0026\n",
      "Epoch 1069/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.3498e-04 - mae: 0.0016 - val_loss: 3.3378e-04 - val_mae: 0.0014\n",
      "Epoch 1070/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.3284e-04 - mae: 0.0014 - val_loss: 3.3266e-04 - val_mae: 0.0013\n",
      "Epoch 1071/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.3393e-04 - mae: 0.0017 - val_loss: 3.4474e-04 - val_mae: 0.0036\n",
      "Epoch 1072/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.3381e-04 - mae: 0.0018 - val_loss: 3.3105e-04 - val_mae: 0.0014\n",
      "Epoch 1073/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.3107e-04 - mae: 0.0015 - val_loss: 3.4118e-04 - val_mae: 0.0032\n",
      "Epoch 1074/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.3039e-04 - mae: 0.0015 - val_loss: 3.3021e-04 - val_mae: 0.0015\n",
      "Epoch 1075/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.2964e-04 - mae: 0.0015 - val_loss: 3.3159e-04 - val_mae: 0.0019\n",
      "Epoch 1076/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.3200e-04 - mae: 0.0019 - val_loss: 3.3118e-04 - val_mae: 0.0019\n",
      "Epoch 1077/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.2847e-04 - mae: 0.0015 - val_loss: 3.3063e-04 - val_mae: 0.0021\n",
      "Epoch 1078/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.2874e-04 - mae: 0.0017 - val_loss: 3.2843e-04 - val_mae: 0.0017\n",
      "Epoch 1079/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.2661e-04 - mae: 0.0015 - val_loss: 3.2633e-04 - val_mae: 0.0014\n",
      "Epoch 1080/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.2601e-04 - mae: 0.0015 - val_loss: 3.2831e-04 - val_mae: 0.0019\n",
      "Epoch 1081/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.2611e-04 - mae: 0.0016 - val_loss: 3.2602e-04 - val_mae: 0.0017\n",
      "Epoch 1082/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.2436e-04 - mae: 0.0015 - val_loss: 3.2396e-04 - val_mae: 0.0014\n",
      "Epoch 1083/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.2407e-04 - mae: 0.0016 - val_loss: 3.2382e-04 - val_mae: 0.0016\n",
      "Epoch 1084/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.2400e-04 - mae: 0.0017 - val_loss: 3.2377e-04 - val_mae: 0.0017\n",
      "Epoch 1085/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.2206e-04 - mae: 0.0014 - val_loss: 3.2224e-04 - val_mae: 0.0016\n",
      "Epoch 1086/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.2290e-04 - mae: 0.0017 - val_loss: 3.3135e-04 - val_mae: 0.0028\n",
      "Epoch 1087/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.2395e-04 - mae: 0.0020 - val_loss: 3.2883e-04 - val_mae: 0.0032\n",
      "Epoch 1088/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.2092e-04 - mae: 0.0016 - val_loss: 3.3778e-04 - val_mae: 0.0040\n",
      "Epoch 1089/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.2051e-04 - mae: 0.0017 - val_loss: 3.1831e-04 - val_mae: 0.0013\n",
      "Epoch 1090/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.1900e-04 - mae: 0.0015 - val_loss: 3.2006e-04 - val_mae: 0.0018\n",
      "Epoch 1091/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.1995e-04 - mae: 0.0018 - val_loss: 3.1850e-04 - val_mae: 0.0016\n",
      "Epoch 1092/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.1897e-04 - mae: 0.0018 - val_loss: 3.2196e-04 - val_mae: 0.0026\n",
      "Epoch 1093/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.1737e-04 - mae: 0.0016 - val_loss: 3.1813e-04 - val_mae: 0.0019\n",
      "Epoch 1094/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.1673e-04 - mae: 0.0016 - val_loss: 3.1849e-04 - val_mae: 0.0022\n",
      "Epoch 1095/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.1547e-04 - mae: 0.0015 - val_loss: 3.1604e-04 - val_mae: 0.0018\n",
      "Epoch 1096/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.1566e-04 - mae: 0.0017 - val_loss: 3.1864e-04 - val_mae: 0.0024\n",
      "Epoch 1097/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.1674e-04 - mae: 0.0020 - val_loss: 3.2405e-04 - val_mae: 0.0033\n",
      "Epoch 1098/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.1487e-04 - mae: 0.0018 - val_loss: 3.1827e-04 - val_mae: 0.0024\n",
      "Epoch 1099/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.1203e-04 - mae: 0.0013 - val_loss: 3.2127e-04 - val_mae: 0.0029\n",
      "Epoch 1100/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.1198e-04 - mae: 0.0015 - val_loss: 3.1788e-04 - val_mae: 0.0024\n",
      "Epoch 1101/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.1273e-04 - mae: 0.0017 - val_loss: 3.1185e-04 - val_mae: 0.0016\n",
      "Epoch 1102/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.1146e-04 - mae: 0.0016 - val_loss: 3.0968e-04 - val_mae: 0.0013\n",
      "Epoch 1103/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.1040e-04 - mae: 0.0015 - val_loss: 3.1449e-04 - val_mae: 0.0023\n",
      "Epoch 1104/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.0993e-04 - mae: 0.0016 - val_loss: 3.6250e-04 - val_mae: 0.0068\n",
      "Epoch 1105/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 3.1032e-04 - mae: 0.0017 - val_loss: 3.0821e-04 - val_mae: 0.0013\n",
      "Epoch 1106/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.1060e-04 - mae: 0.0019 - val_loss: 3.0678e-04 - val_mae: 0.0012\n",
      "Epoch 1107/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.0788e-04 - mae: 0.0016 - val_loss: 3.0701e-04 - val_mae: 0.0014\n",
      "Epoch 1108/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.0848e-04 - mae: 0.0018 - val_loss: 3.2324e-04 - val_mae: 0.0035\n",
      "Epoch 1109/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.0903e-04 - mae: 0.0019 - val_loss: 3.0766e-04 - val_mae: 0.0018\n",
      "Epoch 1110/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.0533e-04 - mae: 0.0014 - val_loss: 3.1002e-04 - val_mae: 0.0025\n",
      "Epoch 1111/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.0520e-04 - mae: 0.0015 - val_loss: 3.0733e-04 - val_mae: 0.0020\n",
      "Epoch 1112/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.0505e-04 - mae: 0.0016 - val_loss: 3.0877e-04 - val_mae: 0.0023\n",
      "Epoch 1113/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.0495e-04 - mae: 0.0017 - val_loss: 3.0615e-04 - val_mae: 0.0019\n",
      "Epoch 1114/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.0456e-04 - mae: 0.0017 - val_loss: 3.0412e-04 - val_mae: 0.0017\n",
      "Epoch 1115/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 3.0245e-04 - mae: 0.0015 - val_loss: 3.2066e-04 - val_mae: 0.0043\n",
      "Epoch 1116/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.0287e-04 - mae: 0.0016 - val_loss: 3.0097e-04 - val_mae: 0.0012\n",
      "Epoch 1117/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.0114e-04 - mae: 0.0015 - val_loss: 3.0247e-04 - val_mae: 0.0019\n",
      "Epoch 1118/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.0066e-04 - mae: 0.0015 - val_loss: 2.9936e-04 - val_mae: 0.0012\n",
      "Epoch 1119/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.9999e-04 - mae: 0.0015 - val_loss: 3.0644e-04 - val_mae: 0.0028\n",
      "Epoch 1120/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.0075e-04 - mae: 0.0017 - val_loss: 2.9967e-04 - val_mae: 0.0017\n",
      "Epoch 1121/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.9941e-04 - mae: 0.0016 - val_loss: 3.0640e-04 - val_mae: 0.0026\n",
      "Epoch 1122/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.9899e-04 - mae: 0.0016 - val_loss: 2.9700e-04 - val_mae: 0.0012\n",
      "Epoch 1123/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 3.0095e-04 - mae: 0.0020 - val_loss: 2.9702e-04 - val_mae: 0.0014\n",
      "Epoch 1124/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.9649e-04 - mae: 0.0014 - val_loss: 2.9543e-04 - val_mae: 0.0012\n",
      "Epoch 1125/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.9704e-04 - mae: 0.0016 - val_loss: 2.9982e-04 - val_mae: 0.0021\n",
      "Epoch 1126/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.9677e-04 - mae: 0.0017 - val_loss: 3.0022e-04 - val_mae: 0.0021\n",
      "Epoch 1127/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.9706e-04 - mae: 0.0018 - val_loss: 2.9539e-04 - val_mae: 0.0016\n",
      "Epoch 1128/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.9770e-04 - mae: 0.0020 - val_loss: 2.9338e-04 - val_mae: 0.0012\n",
      "Epoch 1129/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.9383e-04 - mae: 0.0015 - val_loss: 2.9387e-04 - val_mae: 0.0015\n",
      "Epoch 1130/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.9283e-04 - mae: 0.0014 - val_loss: 3.0646e-04 - val_mae: 0.0030\n",
      "Epoch 1131/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.9315e-04 - mae: 0.0015 - val_loss: 2.9211e-04 - val_mae: 0.0013\n",
      "Epoch 1132/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.9399e-04 - mae: 0.0018 - val_loss: 2.9327e-04 - val_mae: 0.0017\n",
      "Epoch 1133/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.9178e-04 - mae: 0.0015 - val_loss: 2.9073e-04 - val_mae: 0.0012\n",
      "Epoch 1134/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.9069e-04 - mae: 0.0014 - val_loss: 2.9420e-04 - val_mae: 0.0021\n",
      "Epoch 1135/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.9315e-04 - mae: 0.0019 - val_loss: 2.8954e-04 - val_mae: 0.0013\n",
      "Epoch 1136/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.9045e-04 - mae: 0.0016 - val_loss: 2.8975e-04 - val_mae: 0.0015\n",
      "Epoch 1137/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.8968e-04 - mae: 0.0015 - val_loss: 2.9006e-04 - val_mae: 0.0016\n",
      "Epoch 1138/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.9036e-04 - mae: 0.0018 - val_loss: 2.9350e-04 - val_mae: 0.0022\n",
      "Epoch 1139/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.8829e-04 - mae: 0.0015 - val_loss: 2.8961e-04 - val_mae: 0.0019\n",
      "Epoch 1140/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.8783e-04 - mae: 0.0015 - val_loss: 3.0195e-04 - val_mae: 0.0035\n",
      "Epoch 1141/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.9265e-04 - mae: 0.0023 - val_loss: 3.2156e-04 - val_mae: 0.0049\n",
      "Epoch 1142/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.8700e-04 - mae: 0.0015 - val_loss: 2.8791e-04 - val_mae: 0.0017\n",
      "Epoch 1143/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.8638e-04 - mae: 0.0015 - val_loss: 2.8702e-04 - val_mae: 0.0018\n",
      "Epoch 1144/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.8583e-04 - mae: 0.0015 - val_loss: 2.8636e-04 - val_mae: 0.0017\n",
      "Epoch 1145/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.8457e-04 - mae: 0.0014 - val_loss: 2.8432e-04 - val_mae: 0.0013\n",
      "Epoch 1146/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.8874e-04 - mae: 0.0021 - val_loss: 3.1035e-04 - val_mae: 0.0049\n",
      "Epoch 1147/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.8408e-04 - mae: 0.0015 - val_loss: 2.9015e-04 - val_mae: 0.0024\n",
      "Epoch 1148/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.8305e-04 - mae: 0.0014 - val_loss: 2.8733e-04 - val_mae: 0.0022\n",
      "Epoch 1149/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.8415e-04 - mae: 0.0017 - val_loss: 2.8387e-04 - val_mae: 0.0016\n",
      "Epoch 1150/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.8241e-04 - mae: 0.0015 - val_loss: 2.8381e-04 - val_mae: 0.0017\n",
      "Epoch 1151/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.8291e-04 - mae: 0.0017 - val_loss: 2.8101e-04 - val_mae: 0.0012\n",
      "Epoch 1152/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.8379e-04 - mae: 0.0019 - val_loss: 2.8181e-04 - val_mae: 0.0016\n",
      "Epoch 1153/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.8117e-04 - mae: 0.0015 - val_loss: 2.9105e-04 - val_mae: 0.0034\n",
      "Epoch 1154/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.8182e-04 - mae: 0.0017 - val_loss: 2.9010e-04 - val_mae: 0.0031\n",
      "Epoch 1155/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.8006e-04 - mae: 0.0015 - val_loss: 2.7880e-04 - val_mae: 0.0012\n",
      "Epoch 1156/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.7885e-04 - mae: 0.0014 - val_loss: 2.8090e-04 - val_mae: 0.0018\n",
      "Epoch 1157/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.7962e-04 - mae: 0.0017 - val_loss: 2.7873e-04 - val_mae: 0.0015\n",
      "Epoch 1158/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.8249e-04 - mae: 0.0021 - val_loss: 2.7906e-04 - val_mae: 0.0017\n",
      "Epoch 1159/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.7868e-04 - mae: 0.0016 - val_loss: 2.7849e-04 - val_mae: 0.0017\n",
      "Epoch 1160/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.7869e-04 - mae: 0.0017 - val_loss: 2.7677e-04 - val_mae: 0.0013\n",
      "Epoch 1161/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.7669e-04 - mae: 0.0015 - val_loss: 2.8099e-04 - val_mae: 0.0023\n",
      "Epoch 1162/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.7742e-04 - mae: 0.0017 - val_loss: 2.7752e-04 - val_mae: 0.0017\n",
      "Epoch 1163/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.7653e-04 - mae: 0.0016 - val_loss: 2.8783e-04 - val_mae: 0.0034\n",
      "Epoch 1164/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.7520e-04 - mae: 0.0014 - val_loss: 2.7608e-04 - val_mae: 0.0017\n",
      "Epoch 1165/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.7566e-04 - mae: 0.0016 - val_loss: 2.7799e-04 - val_mae: 0.0021\n",
      "Epoch 1166/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.7543e-04 - mae: 0.0016 - val_loss: 2.8032e-04 - val_mae: 0.0026\n",
      "Epoch 1167/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.7560e-04 - mae: 0.0018 - val_loss: 2.7604e-04 - val_mae: 0.0021\n",
      "Epoch 1168/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.7598e-04 - mae: 0.0019 - val_loss: 2.7286e-04 - val_mae: 0.0014\n",
      "Epoch 1169/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.7204e-04 - mae: 0.0013 - val_loss: 2.7395e-04 - val_mae: 0.0018\n",
      "Epoch 1170/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.7347e-04 - mae: 0.0016 - val_loss: 2.7145e-04 - val_mae: 0.0012\n",
      "Epoch 1171/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.7249e-04 - mae: 0.0016 - val_loss: 2.7640e-04 - val_mae: 0.0025\n",
      "Epoch 1172/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.7405e-04 - mae: 0.0019 - val_loss: 2.7220e-04 - val_mae: 0.0016\n",
      "Epoch 1173/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.7131e-04 - mae: 0.0016 - val_loss: 2.7204e-04 - val_mae: 0.0016\n",
      "Epoch 1174/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.7109e-04 - mae: 0.0016 - val_loss: 2.7979e-04 - val_mae: 0.0029\n",
      "Epoch 1175/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.7163e-04 - mae: 0.0018 - val_loss: 2.8043e-04 - val_mae: 0.0032\n",
      "Epoch 1176/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.7000e-04 - mae: 0.0016 - val_loss: 2.7201e-04 - val_mae: 0.0021\n",
      "Epoch 1177/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.6946e-04 - mae: 0.0015 - val_loss: 2.7190e-04 - val_mae: 0.0021\n",
      "Epoch 1178/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.6843e-04 - mae: 0.0015 - val_loss: 2.6914e-04 - val_mae: 0.0016\n",
      "Epoch 1179/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.6971e-04 - mae: 0.0018 - val_loss: 2.6920e-04 - val_mae: 0.0018\n",
      "Epoch 1180/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.6820e-04 - mae: 0.0016 - val_loss: 2.6693e-04 - val_mae: 0.0013\n",
      "Epoch 1181/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.6746e-04 - mae: 0.0015 - val_loss: 2.7233e-04 - val_mae: 0.0024\n",
      "Epoch 1182/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.6765e-04 - mae: 0.0017 - val_loss: 2.6594e-04 - val_mae: 0.0013\n",
      "Epoch 1183/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.6657e-04 - mae: 0.0016 - val_loss: 2.6944e-04 - val_mae: 0.0020\n",
      "Epoch 1184/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.6653e-04 - mae: 0.0016 - val_loss: 2.8166e-04 - val_mae: 0.0040\n",
      "Epoch 1185/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.6747e-04 - mae: 0.0019 - val_loss: 2.6737e-04 - val_mae: 0.0020\n",
      "Epoch 1186/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.6613e-04 - mae: 0.0017 - val_loss: 2.6445e-04 - val_mae: 0.0014\n",
      "Epoch 1187/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.6427e-04 - mae: 0.0015 - val_loss: 2.6327e-04 - val_mae: 0.0012\n",
      "Epoch 1188/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.6449e-04 - mae: 0.0016 - val_loss: 2.7517e-04 - val_mae: 0.0031\n",
      "Epoch 1189/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.6441e-04 - mae: 0.0017 - val_loss: 2.6303e-04 - val_mae: 0.0014\n",
      "Epoch 1190/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.6529e-04 - mae: 0.0019 - val_loss: 2.6164e-04 - val_mae: 0.0012\n",
      "Epoch 1191/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.6248e-04 - mae: 0.0015 - val_loss: 2.7196e-04 - val_mae: 0.0032\n",
      "Epoch 1192/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.6309e-04 - mae: 0.0017 - val_loss: 2.6293e-04 - val_mae: 0.0018\n",
      "Epoch 1193/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.6257e-04 - mae: 0.0016 - val_loss: 2.6602e-04 - val_mae: 0.0022\n",
      "Epoch 1194/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.6225e-04 - mae: 0.0017 - val_loss: 2.9948e-04 - val_mae: 0.0050\n",
      "Epoch 1195/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.6244e-04 - mae: 0.0017 - val_loss: 2.5954e-04 - val_mae: 0.0013\n",
      "Epoch 1196/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.6052e-04 - mae: 0.0015 - val_loss: 2.6511e-04 - val_mae: 0.0026\n",
      "Epoch 1197/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.5966e-04 - mae: 0.0015 - val_loss: 2.6539e-04 - val_mae: 0.0025\n",
      "Epoch 1198/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.6145e-04 - mae: 0.0019 - val_loss: 2.6461e-04 - val_mae: 0.0027\n",
      "Epoch 1199/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.5955e-04 - mae: 0.0016 - val_loss: 2.6703e-04 - val_mae: 0.0027\n",
      "Epoch 1200/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.5817e-04 - mae: 0.0014 - val_loss: 2.6297e-04 - val_mae: 0.0023\n",
      "Epoch 1201/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.5909e-04 - mae: 0.0017 - val_loss: 2.6111e-04 - val_mae: 0.0020\n",
      "Epoch 1202/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.5843e-04 - mae: 0.0016 - val_loss: 2.6982e-04 - val_mae: 0.0034\n",
      "Epoch 1203/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.5800e-04 - mae: 0.0016 - val_loss: 2.5649e-04 - val_mae: 0.0013\n",
      "Epoch 1204/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.5721e-04 - mae: 0.0016 - val_loss: 3.0677e-04 - val_mae: 0.0060\n",
      "Epoch 1205/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.5760e-04 - mae: 0.0017 - val_loss: 2.6494e-04 - val_mae: 0.0031\n",
      "Epoch 1206/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.5591e-04 - mae: 0.0015 - val_loss: 2.5866e-04 - val_mae: 0.0022\n",
      "Epoch 1207/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.5557e-04 - mae: 0.0015 - val_loss: 2.6017e-04 - val_mae: 0.0024\n",
      "Epoch 1208/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.5598e-04 - mae: 0.0017 - val_loss: 2.5376e-04 - val_mae: 0.0012\n",
      "Epoch 1209/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.5444e-04 - mae: 0.0015 - val_loss: 2.5461e-04 - val_mae: 0.0015\n",
      "Epoch 1210/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.5583e-04 - mae: 0.0019 - val_loss: 2.8766e-04 - val_mae: 0.0054\n",
      "Epoch 1211/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.5548e-04 - mae: 0.0018 - val_loss: 2.7327e-04 - val_mae: 0.0036\n",
      "Epoch 1212/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.5455e-04 - mae: 0.0017 - val_loss: 2.5392e-04 - val_mae: 0.0016\n",
      "Epoch 1213/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.5379e-04 - mae: 0.0017 - val_loss: 2.5405e-04 - val_mae: 0.0017\n",
      "Epoch 1214/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.5167e-04 - mae: 0.0014 - val_loss: 2.5353e-04 - val_mae: 0.0018\n",
      "Epoch 1215/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.5200e-04 - mae: 0.0015 - val_loss: 2.5626e-04 - val_mae: 0.0025\n",
      "Epoch 1216/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.5217e-04 - mae: 0.0017 - val_loss: 2.5244e-04 - val_mae: 0.0018\n",
      "Epoch 1217/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.5152e-04 - mae: 0.0016 - val_loss: 2.4970e-04 - val_mae: 0.0012\n",
      "Epoch 1218/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.5365e-04 - mae: 0.0020 - val_loss: 2.7020e-04 - val_mae: 0.0037\n",
      "Epoch 1219/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.5148e-04 - mae: 0.0017 - val_loss: 2.5207e-04 - val_mae: 0.0019\n",
      "Epoch 1220/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.5045e-04 - mae: 0.0016 - val_loss: 2.5130e-04 - val_mae: 0.0019\n",
      "Epoch 1221/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.4893e-04 - mae: 0.0014 - val_loss: 2.5711e-04 - val_mae: 0.0025\n",
      "Epoch 1222/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.5087e-04 - mae: 0.0018 - val_loss: 2.4868e-04 - val_mae: 0.0016\n",
      "Epoch 1223/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.5012e-04 - mae: 0.0018 - val_loss: 2.4755e-04 - val_mae: 0.0013\n",
      "Epoch 1224/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.4843e-04 - mae: 0.0015 - val_loss: 2.5080e-04 - val_mae: 0.0020\n",
      "Epoch 1225/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.4782e-04 - mae: 0.0015 - val_loss: 2.4928e-04 - val_mae: 0.0017\n",
      "Epoch 1226/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.4828e-04 - mae: 0.0017 - val_loss: 2.6235e-04 - val_mae: 0.0032\n",
      "Epoch 1227/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.5020e-04 - mae: 0.0020 - val_loss: 2.4955e-04 - val_mae: 0.0022\n",
      "Epoch 1228/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.4849e-04 - mae: 0.0018 - val_loss: 2.4575e-04 - val_mae: 0.0013\n",
      "Epoch 1229/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.4685e-04 - mae: 0.0016 - val_loss: 2.4701e-04 - val_mae: 0.0017\n",
      "Epoch 1230/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.4557e-04 - mae: 0.0014 - val_loss: 2.4884e-04 - val_mae: 0.0020\n",
      "Epoch 1231/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.4658e-04 - mae: 0.0017 - val_loss: 2.4736e-04 - val_mae: 0.0019\n",
      "Epoch 1232/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.4485e-04 - mae: 0.0014 - val_loss: 2.4400e-04 - val_mae: 0.0012\n",
      "Epoch 1233/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.4480e-04 - mae: 0.0015 - val_loss: 2.4664e-04 - val_mae: 0.0019\n",
      "Epoch 1234/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.4604e-04 - mae: 0.0018 - val_loss: 2.4654e-04 - val_mae: 0.0020\n",
      "Epoch 1235/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.4396e-04 - mae: 0.0015 - val_loss: 2.5102e-04 - val_mae: 0.0030\n",
      "Epoch 1236/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.4605e-04 - mae: 0.0019 - val_loss: 2.4455e-04 - val_mae: 0.0018\n",
      "Epoch 1237/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.4473e-04 - mae: 0.0017 - val_loss: 2.5663e-04 - val_mae: 0.0037\n",
      "Epoch 1238/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.4472e-04 - mae: 0.0018 - val_loss: 2.7196e-04 - val_mae: 0.0046\n",
      "Epoch 1239/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.4433e-04 - mae: 0.0017 - val_loss: 2.4492e-04 - val_mae: 0.0020\n",
      "Epoch 1240/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.4324e-04 - mae: 0.0017 - val_loss: 2.4418e-04 - val_mae: 0.0018\n",
      "Epoch 1241/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.4183e-04 - mae: 0.0015 - val_loss: 2.4204e-04 - val_mae: 0.0016\n",
      "Epoch 1242/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.4205e-04 - mae: 0.0016 - val_loss: 2.4131e-04 - val_mae: 0.0015\n",
      "Epoch 1243/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.4177e-04 - mae: 0.0016 - val_loss: 2.4829e-04 - val_mae: 0.0024\n",
      "Epoch 1244/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.4225e-04 - mae: 0.0018 - val_loss: 2.4221e-04 - val_mae: 0.0018\n",
      "Epoch 1245/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.4161e-04 - mae: 0.0017 - val_loss: 2.4146e-04 - val_mae: 0.0017\n",
      "Epoch 1246/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.4022e-04 - mae: 0.0015 - val_loss: 2.4121e-04 - val_mae: 0.0018\n",
      "Epoch 1247/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.4063e-04 - mae: 0.0017 - val_loss: 2.4193e-04 - val_mae: 0.0020\n",
      "Epoch 1248/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.3920e-04 - mae: 0.0015 - val_loss: 2.3941e-04 - val_mae: 0.0014\n",
      "Epoch 1249/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.3876e-04 - mae: 0.0015 - val_loss: 2.4059e-04 - val_mae: 0.0018\n",
      "Epoch 1250/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.3980e-04 - mae: 0.0017 - val_loss: 2.6176e-04 - val_mae: 0.0047\n",
      "Epoch 1251/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.4017e-04 - mae: 0.0018 - val_loss: 2.4987e-04 - val_mae: 0.0033\n",
      "Epoch 1252/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.4059e-04 - mae: 0.0019 - val_loss: 2.4201e-04 - val_mae: 0.0025\n",
      "Epoch 1253/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.3747e-04 - mae: 0.0015 - val_loss: 2.3668e-04 - val_mae: 0.0013\n",
      "Epoch 1254/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.3669e-04 - mae: 0.0014 - val_loss: 2.3641e-04 - val_mae: 0.0013\n",
      "Epoch 1255/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.3849e-04 - mae: 0.0018 - val_loss: 2.6026e-04 - val_mae: 0.0040\n",
      "Epoch 1256/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.4015e-04 - mae: 0.0019 - val_loss: 2.3521e-04 - val_mae: 0.0011\n",
      "Epoch 1257/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.3541e-04 - mae: 0.0013 - val_loss: 2.4124e-04 - val_mae: 0.0024\n",
      "Epoch 1258/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.3622e-04 - mae: 0.0016 - val_loss: 2.3606e-04 - val_mae: 0.0015\n",
      "Epoch 1259/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.3774e-04 - mae: 0.0019 - val_loss: 2.3433e-04 - val_mae: 0.0012\n",
      "Epoch 1260/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.3545e-04 - mae: 0.0016 - val_loss: 2.3444e-04 - val_mae: 0.0013\n",
      "Epoch 1261/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.3447e-04 - mae: 0.0014 - val_loss: 2.3420e-04 - val_mae: 0.0014\n",
      "Epoch 1262/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.3460e-04 - mae: 0.0015 - val_loss: 2.4100e-04 - val_mae: 0.0028\n",
      "Epoch 1263/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.3461e-04 - mae: 0.0016 - val_loss: 2.3365e-04 - val_mae: 0.0014\n",
      "Epoch 1264/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.3411e-04 - mae: 0.0016 - val_loss: 2.3380e-04 - val_mae: 0.0016\n",
      "Epoch 1265/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.3491e-04 - mae: 0.0018 - val_loss: 2.3550e-04 - val_mae: 0.0019\n",
      "Epoch 1266/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.3465e-04 - mae: 0.0018 - val_loss: 2.3523e-04 - val_mae: 0.0019\n",
      "Epoch 1267/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.3438e-04 - mae: 0.0018 - val_loss: 2.3278e-04 - val_mae: 0.0016\n",
      "Epoch 1268/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.3322e-04 - mae: 0.0016 - val_loss: 2.3260e-04 - val_mae: 0.0015\n",
      "Epoch 1269/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.3268e-04 - mae: 0.0016 - val_loss: 2.3103e-04 - val_mae: 0.0012\n",
      "Epoch 1270/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.3072e-04 - mae: 0.0013 - val_loss: 2.4169e-04 - val_mae: 0.0028\n",
      "Epoch 1271/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.3216e-04 - mae: 0.0016 - val_loss: 2.4192e-04 - val_mae: 0.0030\n",
      "Epoch 1272/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.3386e-04 - mae: 0.0018 - val_loss: 2.3293e-04 - val_mae: 0.0019\n",
      "Epoch 1273/2000\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 2.3122e-04 - mae: 0.0016 - val_loss: 2.3163e-04 - val_mae: 0.0017\n",
      "Epoch 1274/2000\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.3084e-04 - mae: 0.0016 - val_loss: 2.2986e-04 - val_mae: 0.0014\n",
      "Epoch 1275/2000\n",
      "154/163 [===========================>..] - ETA: 0s - loss: 2.3087e-04 - mae: 0.0016Restoring model weights from the end of the best epoch: 1270.\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 2.3083e-04 - mae: 0.0016 - val_loss: 2.3098e-04 - val_mae: 0.0016\n",
      "Epoch 1275: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Netzwerkarchitektur\n",
    "model = Sequential([\n",
    "\n",
    "    Dense(216, activation='relu', input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(104, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(104, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(152, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(8, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(56, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(152, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(56, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(1 , activation = 'linear')\n",
    "])\n",
    "\n",
    "# Optimierer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "# Modell kompilieren (Verwendung von mean_squared_error als Verlustfunktion für Regression)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])  # Metriken für Regression: Mean Absolute Error und Mean Squared Error\n",
    "\n",
    "# Early Stopping Callback\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "# Trainingsparameter\n",
    "batch_size = 100\n",
    "epochs = 2000\n",
    "\n",
    "# Modell trainieren (Annahme: X_train, y_train, X_val, y_val sind vordefiniert)\n",
    "history = model.fit(X_train_scaled, y_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T12:27:02.576218900Z",
     "start_time": "2024-03-19T12:17:01.105698Z"
    }
   },
   "id": "8b52e1a9a6ff3aeb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Initialisiere Listen, um Ergebnisse zu speichern\n",
    "# val_loss_results = []\n",
    "# val_mae_results = []\n",
    "# \n",
    "# # Funktion, um das Modell zu erstellen\n",
    "# def create_model():\n",
    "#     model = Sequential([\n",
    "#                 Dense(216, activation='relu', input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "#             \n",
    "#                 Dense(104, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "#                 \n",
    "#                 Dense(104, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "#                 \n",
    "#                 Dense(152, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "#             \n",
    "#                 Dense(8, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "#             \n",
    "#                 Dense(56, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "#                 \n",
    "#                 Dense(152, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "#                 \n",
    "#                 Dense(56, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "#             \n",
    "#                 Dense(1 , activation = 'linear')\n",
    "#     ])\n",
    "#     optimizer = Adam(learning_rate=0.001)\n",
    "#     model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "#     return model\n",
    "# \n",
    "# # K-Fold Cross-Validation Konfiguration\n",
    "# n_splits = 5\n",
    "# kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "# \n",
    "# # Leistungsüberwachung\n",
    "# fold_no = 1\n",
    "# for train_index, val_index in kf.split(X_train_scaled):\n",
    "#     X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "#     y_train_fold, y_val_fold = y_train_scaled[train_index], y_train_scaled[val_index]\n",
    "# \n",
    "#     model = create_model()\n",
    "# \n",
    "#     early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "# \n",
    "#     print(f'Training für Fold {fold_no}...')\n",
    "#     history = model.fit(X_train_fold, y_train_fold, batch_size=100, epochs=1000, validation_data=(X_val_fold, y_val_fold), callbacks=[early_stopping], verbose=1)\n",
    "# \n",
    "#     # Speichere die Ergebnisse des aktuellen Folds\n",
    "#     val_loss_results.append(min(history.history['val_loss']))\n",
    "#     val_mae_results.append(min(history.history['val_mae']))\n",
    "# \n",
    "#     fold_no += 1\n",
    "# \n",
    "# # Berechne den Durchschnitt über alle Folds\n",
    "# average_val_loss = np.mean(val_loss_results)\n",
    "# average_val_mae = np.mean(val_mae_results)\n",
    "# \n",
    "# # Gib die durchschnittlichen Ergebnisse aus\n",
    "# print(f'Durchschnittlicher Validation Loss: {average_val_loss}')\n",
    "# print(f'Durchschnittlicher Validation MAE: {average_val_mae}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T12:02:34.076302700Z",
     "start_time": "2024-03-19T12:02:34.071302800Z"
    }
   },
   "id": "43f176fd515825d9"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 - 0s - loss: 0.0012 - mae: 0.0036 - 126ms/epoch - 792us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.0012427656911313534, 0.003617272013798356]"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test_scaled, y_test_scaled, verbose=2)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:06:06.094547400Z",
     "start_time": "2024-03-15T10:06:05.930219200Z"
    }
   },
   "id": "f27ef8e901869c23"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bsp. Predicted: [1286.4088] Actual: [1286.9] \n",
      "Durchschnittliche Abweichung (MAE): [2.66136615]\n"
     ]
    }
   ],
   "source": [
    "scaled_predicted_values = model.predict(X_test_scaled, verbose = 0)\n",
    "\n",
    "# Führen Sie die Rücktransformation der skalierten Werte durch\n",
    "original_predicted_values = scaler_target.inverse_transform(scaled_predicted_values)\n",
    "original_actual_values = scaler_target.inverse_transform(y_test_scaled)  # y_test sind die skalierten tatsächlichen Werte\n",
    "print(f' Bsp. Predicted: {original_predicted_values[100]} Actual: {original_actual_values[100]} ')\n",
    "\n",
    "def calculate_mae(list1, list2):\n",
    "    # Stelle sicher, dass beide Listen die gleiche Länge haben\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Listen müssen die gleiche Länge haben\")\n",
    "\n",
    "    # Berechne die absolute Differenz zwischen den Elementen der Listen\n",
    "    differences = [abs(x - y) for x, y in zip(list1, list2)]\n",
    "\n",
    "    # Berechne den Durchschnitt der absoluten Differenzen\n",
    "    mae = sum(differences) / len(differences)\n",
    "\n",
    "    return mae\n",
    "\n",
    "# Beispiel\n",
    "list1 = original_predicted_values\n",
    "list2 = original_actual_values\n",
    "\n",
    "mae = calculate_mae(list1, list2)\n",
    "print(f\"Durchschnittliche Abweichung (MAE): {mae}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T12:30:38.039692500Z",
     "start_time": "2024-03-19T12:30:37.653670700Z"
    }
   },
   "id": "b1e271125bed3df7"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: [0.99965374]\n"
     ]
    }
   ],
   "source": [
    "def calculate_r_squared(predicted, actual):\n",
    "    # Berechnung des Mittelwerts der tatsächlichen Werte\n",
    "    mean_actual = sum(actual) / len(actual)\n",
    "    \n",
    "    # Berechnung der totalen Summe der Quadrate (SST)\n",
    "    sst = sum((x - mean_actual) ** 2 for x in actual)\n",
    "    \n",
    "    # Berechnung der Summe der Quadrate der Residuen (SSE)\n",
    "    sse = sum((actual[i] - predicted[i]) ** 2 for i in range(len(actual)))\n",
    "    \n",
    "    # Berechnung des R^2-Wertes\n",
    "    r_squared = 1 - (sse / sst)\n",
    "    \n",
    "    return r_squared\n",
    "\n",
    "# Berechnung von R^2 mit den bereitgestellten Listen\n",
    "r_squared = calculate_r_squared(list1, list2)\n",
    "\n",
    "print(f\"R^2: {r_squared}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:06:06.410394700Z",
     "start_time": "2024-03-15T10:06:06.357546700Z"
    }
   },
   "id": "79a9ed0f6e7bf14e"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA18AAAIjCAYAAAD80aFnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAACDhElEQVR4nOzdd3gU9drG8e/uphFCEgiQooHQpDcpEZGmkSqKoAKCVLEBCsirYgGsoKCigGIFCyDiQRQENHQLCoL0IiodQieBQNruvH+MWVgTIIEku9ncn+uaK7szv515NmfOObl5Zn5jMQzDQERERERERPKV1d0FiIiIiIiIFAUKXyIiIiIiIgVA4UtERERERKQAKHyJiIiIiIgUAIUvERERERGRAqDwJSIiIiIiUgAUvkRERERERAqAwpeIiIiIiEgBUPgSEREREREpAApfIiJerk+fPsTExFzRZ0ePHo3FYsnbgjzM7t27sVgsTJs2rcCPbbFYGD16tPP9tGnTsFgs7N69+7KfjYmJoU+fPnlaz9WcKyIicnkKXyIibmKxWHK0LF++3N2lFnmPPvooFouFv/7666JjnnnmGSwWCxs3bizAynLv4MGDjB49mvXr17u7FKfMAGyxWHjppZeyHdOjRw8sFgtBQUEu6x0OB59++imxsbGUKlWKEiVKcN1119GrVy9+/fVX57jly5df8r9nX3zxRb5+RxERAB93FyAiUlR99tlnLu8//fRT4uPjs6yvXr36VR3ngw8+wOFwXNFnn332WZ566qmrOr436NGjBxMnTmTGjBmMHDky2zEzZ86kdu3a1KlT54qPc99999GtWzf8/f2veB+Xc/DgQZ5//nliYmKoV6+ey7arOVfyQkBAADNnzuTZZ591WZ+cnMw333xDQEBAls88+uijTJ48mTvuuIMePXrg4+PDjh07WLhwIRUrVuSGG27IMr5Ro0ZZ9tOkSZO8/TIiItlQ+BIRcZOePXu6vP/111+Jj4/Psv6/zp49S2BgYI6P4+vre0X1Afj4+ODjo/+riI2NpXLlysycOTPb8LVq1Sp27drF2LFjr+o4NpsNm812Vfu4GldzruSF9u3bM2fOHDZs2EDdunWd67/55hvS0tJo27YtS5cuda4/fPgw77zzDgMGDOD999932deECRM4evRolmM0a9aMu+66K/++hIjIJeiyQxERD9ayZUtq1arF2rVrad68OYGBgTz99NOA+Qdphw4diIqKwt/fn0qVKvHiiy9it9td9vHf+3gyL/EaP34877//PpUqVcLf359GjRqxZs0al89md8+XxWJh0KBBzJ07l1q1auHv70/NmjVZtGhRlvqXL19Ow4YNCQgIoFKlSrz33ns5vo/sxx9/5O6776ZcuXL4+/sTHR3N0KFDOXfuXJbvFxQUxIEDB+jUqRNBQUGUKVOG4cOHZ/ldnDp1ij59+hASEkJoaCi9e/fm1KlTl60FzO7X9u3bWbduXZZtM2bMwGKx0L17d9LS0hg5ciQNGjQgJCSE4sWL06xZM5YtW3bZY2R3z5dhGLz00ktce+21BAYG0qpVK7Zs2ZLlsydOnGD48OHUrl2boKAggoODadeuHRs2bHCOWb58ubPr07dvX+cld5n3u2V3z1dycjKPP/440dHR+Pv7U7VqVcaPH49hGC7jcnNeXEyTJk2oUKECM2bMcFk/ffp02rZtS6lSpVzW79q1C8MwaNq0aZZ9WSwWypYtm+Nji4gUBP1zpoiIhzt+/Djt2rWjW7du9OzZk/DwcMD8Qz0oKIhhw4YRFBTE0qVLGTlyJElJSYwbN+6y+50xYwanT5/mwQcfxGKx8Nprr9G5c2f++eefy3ZAfvrpJ+bMmcMjjzxCiRIlePvtt+nSpQt79+4lLCwMgD/++IO2bdsSGRnJ888/j91u54UXXqBMmTI5+t6zZ8/m7NmzPPzww4SFhbF69WomTpzI/v37mT17tstYu91OmzZtiI2NZfz48SxevJjXX3+dSpUq8fDDDwNmiLnjjjv46aefeOihh6hevTpff/01vXv3zlE9PXr04Pnnn2fGjBlcf/31Lsf+8ssvadasGeXKlePYsWN8+OGHdO/enQEDBnD69Gk++ugj2rRpw+rVq7Nc6nc5I0eO5KWXXqJ9+/a0b9+edevW0bp1a9LS0lzG/fPPP8ydO5e7776bChUqcPjwYd577z1atGjB1q1biYqKonr16rzwwguMHDmSBx54gGbNmgFw4403ZntswzC4/fbbWbZsGf3796devXp8//33/N///R8HDhzgzTffdBmfk/Picrp3787nn3/O2LFjsVgsHDt2jB9++IHPPvssS5ArX748YJ4rd999d446wqdPn+bYsWNZ1oeFhXn95DIi4gEMERHxCAMHDjT++z/LLVq0MABjypQpWcafPXs2y7oHH3zQCAwMNFJSUpzrevfubZQvX975fteuXQZghIWFGSdOnHCu/+abbwzAmDdvnnPdqFGjstQEGH5+fsZff/3lXLdhwwYDMCZOnOhc17FjRyMwMNA4cOCAc93OnTsNHx+fLPvMTnbfb8yYMYbFYjH27Nnj8v0A44UXXnAZW79+faNBgwbO93PnzjUA47XXXnOuy8jIMJo1a2YAxtSpUy9bU6NGjYxrr73WsNvtznWLFi0yAOO9995z7jM1NdXlcydPnjTCw8ONfv36uawHjFGjRjnfT5061QCMXbt2GYZhGEeOHDH8/PyMDh06GA6Hwznu6aefNgCjd+/eznUpKSkudRmG+Z+1v7+/y+9mzZo1F/2+/z1XMn9nL730ksu4u+66y7BYLC7nQE7Pi+xknpPjxo0zNm/ebADGjz/+aBiGYUyePNkICgoykpOTjd69exvFixd3+WyvXr0MwChZsqRx5513GuPHjze2bduW5RjLli0zgIsuhw4dumSNIiJ5QZcdioh4OH9/f/r27ZtlfbFixZyvM/81v1mzZpw9e5bt27dfdr9du3alZMmSzveZXZB//vnnsp+Ni4ujUqVKzvd16tQhODjY+Vm73c7ixYvp1KkTUVFRznGVK1emXbt2l90/uH6/5ORkjh07xo033ohhGPzxxx9Zxj/00EMu75s1a+byXRYsWICPj4+zEwbmPVaDBw/OUT1g3qe3f/9+Vq5c6Vw3Y8YM/Pz8uPvuu5379PPzA8yZ+E6cOEFGRgYNGzbM9pLFS1m8eDFpaWkMHjzYpSszZMiQLGP9/f2xWs3/W7fb7Rw/fpygoCCqVq2a6+NmWrBgATabjUcffdRl/eOPP45hGCxcuNBl/eXOi5yoWbMmderUYebMmYD5+73jjjsu2tWaOnUqkyZNokKFCnz99dcMHz6c6tWrc8stt3DgwIEs40eOHEl8fHyW5b+XNIqI5AeFLxERD3fNNdc4/5i/0JYtW7jzzjsJCQkhODiYMmXKOCfrSExMvOx+y5Ur5/I+M4idPHky15/N/HzmZ48cOcK5c+eoXLlylnHZrcvO3r176dOnD6VKlXLex9WiRQsg6/cLCAjIcjnjhfUA7Nmzh8jIyCxTlVetWjVH9QB069YNm83mvCcpJSWFr7/+mnbt2rkE2U8++YQ6deoQEBBAWFgYZcqU4bvvvsvRfy4X2rNnDwBVqlRxWV+mTBmX44EZ9N58802qVKmCv78/pUuXpkyZMmzcuDHXx73w+FFRUZQoUcJlfeYMnJn1ZbrceZFT9957L7Nnz+avv/7il19+4d57773oWKvVysCBA1m7di3Hjh3jm2++oV27dixdupRu3bplGV+7dm3i4uKyLNn9d0xEJK8pfImIeLgLO0CZTp06RYsWLdiwYQMvvPAC8+bNIz4+nldffRUgR9OFX2xWPeM/Eynk9Wdzwm63c+utt/Ldd9/x5JNPMnfuXOLj450TQ/z3+xXUDIFly5bl1ltv5X//+x/p6enMmzeP06dP06NHD+eYzz//nD59+lCpUiU++ugjFi1aRHx8PDfffHO+TuP+yiuvMGzYMJo3b87nn3/O999/T3x8PDVr1iyw6ePz6rzo3r07x44dY8CAAYSFhdG6descfS4sLIzbb7+dBQsW0KJFC3766acsAVFExJ004YaISCG0fPlyjh8/zpw5c2jevLlz/a5du9xY1Xlly5YlICAg24cSX+pBxZk2bdrEn3/+ySeffEKvXr2c6+Pj46+4pvLly7NkyRLOnDnj0v3asWNHrvbTo0cPFi1axMKFC5kxYwbBwcF07NjRuf2rr76iYsWKzJkzx+VSwVGjRl1RzQA7d+6kYsWKzvVHjx7N0k366quvaNWqFR999JHL+lOnTlG6dGnn+9xMKlG+fHkWL17M6dOnXbpfmZe1ZtaX18qVK0fTpk1Zvnw5Dz/88BU97qBhw4asWLGCQ4cO5VudIiK5pc6XiEghlNlhuLCjkJaWxjvvvOOuklzYbDbi4uKYO3cuBw8edK7/66+/stwndLHPg+v3MwyDt95664prat++PRkZGbz77rvOdXa7nYkTJ+ZqP506dSIwMJB33nmHhQsX0rlzZ5eH/2ZX+2+//caqVatyXXNcXBy+vr5MnDjRZX8TJkzIMtZms2XpMM2ePTvLfU/FixcHyNEU++3bt8dutzNp0iSX9W+++SYWiyXH9+9diZdeeolRo0Zd8p68hIQEtm7dmmV9WloaS5YswWq15vgyVxGRgqDOl4hIIXTjjTdSsmRJevfuzaOPPorFYuGzzz7Ls8v+8sLo0aP54YcfaNq0KQ8//LDzj/hatWqxfv36S362WrVqVKpUieHDh3PgwAGCg4P53//+l+t7hy7UsWNHmjZtylNPPcXu3bupUaMGc+bMyfX9UEFBQXTq1Ml539eFlxwC3HbbbcyZM4c777yTDh06sGvXLqZMmUKNGjU4c+ZMro6V+byyMWPGcNttt9G+fXv++OMPFi5c6NLNyjzuCy+8QN++fbnxxhvZtGkT06dPd+mYAVSqVInQ0FCmTJlCiRIlKF68OLGxsVSoUCHL8Tt27EirVq145pln2L17N3Xr1uWHH37gm2++YciQIS6Ta+S1Fi1aOO/xu5j9+/fTuHFjbr75Zm655RYiIiI4cuQIM2fOZMOGDQwZMiTL7+nHH38kJSUly77q1KlDnTp18vQ7iIj8l8KXiEghFBYWxvz583n88cd59tlnKVmyJD179uSWW26hTZs27i4PgAYNGrBw4UKGDx/Oc889R3R0NC+88ALbtm277GyMvr6+zJs3j0cffZQxY8YQEBDAnXfeyaBBg6hbt+4V1WO1Wvn2228ZMmQIn3/+ORaLhdtvv53XX3+d+vXr52pfPXr0YMaMGURGRnLzzTe7bOvTpw8JCQm89957fP/999SoUYPPP/+c2bNns3z58lzX/dJLLxEQEMCUKVNYtmwZsbGx/PDDD3To0MFl3NNPP01ycjIzZsxg1qxZXH/99Xz33Xc89dRTLuN8fX355JNPGDFiBA899BAZGRlMnTo12/CV+TsbOXIks2bNYurUqcTExDBu3Dgef/zxXH+XvFa1alUmTJjAggULeOeddzh8+DABAQHUqlWLDz74gP79+2f5zNtvv53tvkaNGqXwJSL5zmJ40j+TioiI1+vUqRNbtmxh586d7i5FRESkQOmeLxERyTfnzp1zeb9z504WLFhAy5Yt3VOQiIiIG6nzJSIi+SYyMpI+ffpQsWJF9uzZw7vvvktqaip//PFHlmdXiYiIeDvd8yUiIvmmbdu2zJw5k4SEBPz9/WnSpAmvvPKKgpeIiBRJ6nyJiIiIiIgUAN3zJSIiIiIiUgAUvkRERERERAqA7vm6Qg6Hg4MHD1KiRAksFou7yxERERERETcxDIPTp08TFRWF1Xrx/pbC1xU6ePAg0dHR7i5DREREREQ8xL59+7j22msvul3h6wqVKFECMH/BwcHBbq5GRERERETcJSkpiejoaGdGuBiFryuUealhcHCwwpeIiIiIiFz2diRNuCEiIiIiIlIAFL5EREREREQKgMKXiIiIiIhIAdA9XyIiIiLiNQzDICMjA7vd7u5SxIvYbDZ8fHyu+hFTCl8iIiIi4hXS0tI4dOgQZ8+edXcp4oUCAwOJjIzEz8/viveh8CUiIiIihZ7D4WDXrl3YbDaioqLw8/O76i6FCJjd1LS0NI4ePcquXbuoUqXKJR+kfCkKXyIiIiJS6KWlpeFwOIiOjiYwMNDd5YiXKVasGL6+vuzZs4e0tDQCAgKuaD+acENEREREvMaVdiRELicvzi2dnSIiIiIiIgVA4UtERERERKQAKHyJiIiIiHiZmJgYJkyYkOPxy5cvx2KxcOrUqXyrSRS+RERERETcxmKxXHIZPXr0Fe13zZo1PPDAAzkef+ONN3Lo0CFCQkKu6Hg5lRnySpYsSUpKisu2NWvWOL/3hT744APq1q1LUFAQoaGh1K9fnzFjxji3jx49OtvfXbVq1fL1u1wJzXYoIiIiIuImhw4dcr6eNWsWI0eOZMeOHc51QUFBzteGYWC32/Hxufyf8GXKlMlVHX5+fkREROTqM1ejRIkSfP3113Tv3t257qOPPqJcuXLs3bvXue7jjz9myJAhvP3227Ro0YLU1FQ2btzI5s2bXfZXs2ZNFi9e7LIuJ7+ngqbOl4iIiIh4J8OA5OSCXwwjxyVGREQ4l5CQECwWi/P99u3bKVGiBAsXLqRBgwb4+/vz008/8ffff3PHHXcQHh5OUFAQjRo1yhI8/nvZocVi4cMPP+TOO+8kMDCQKlWq8O233zq3//eyw2nTphEaGsr3339P9erVCQoKom3bti5hMSMjg0cffZTQ0FDCwsJ48skn6d27N506dbrs9+7duzcff/yx8/25c+f44osv6N27t8u4b7/9lnvuuYf+/ftTuXJlatasSffu3Xn55Zddxvn4+Lj8LiMiIihduvRl6yhoCl8iIiIi4p3OnoWgoIJfzp7N06/x1FNPMXbsWLZt20adOnU4c+YM7du3Z8mSJfzxxx+0bduWjh07unSMsvP8889zzz33sHHjRtq3b0+PHj04ceLEJX59Zxk/fjyfffYZK1euZO/evQwfPty5/dVXX2X69OlMnTqVn3/+maSkJObOnZuj73Tffffx448/Omv+3//+R0xMDNdff73LuIiICH799Vf27NmTo/16OoUvEREREREP9sILL3DrrbdSqVIlSpUqRd26dXnwwQepVasWVapU4cUXX6RSpUounazs9OnTh+7du1O5cmVeeeUVzpw5w+rVqy86Pj09nSlTptCwYUOuv/56Bg0axJIlS5zbJ06cyIgRI7jzzjupVq0akyZNIjQ0NEffqWzZsrRr145p06YB5uWF/fr1yzJu1KhRhIaGEhMTQ9WqVenTpw9ffvklDofDZdymTZsICgpyWR566KEc1VKQPO9CSMmdtDT4/nvzX1juuQf+c4OiiIiISJEVGAhnzrjnuHmoYcOGLu/PnDnD6NGj+e677zh06BAZGRmcO3fusp2vOnXqOF8XL16c4OBgjhw5ctHxgYGBVKpUyfk+MjLSOT4xMZHDhw/TuHFj53abzUaDBg2yBKOL6devH4899hg9e/Zk1apVzJ49mx9//NFlTGRkJKtWrWLz5s2sXLmSX375hd69e/Phhx+yaNEi54OPq1atmiV8BgcH56iOgqTwVdilpsLtt5uvO3bM8/+yi4iIiBRaFgsUL+7uKq5a8f98h+HDhxMfH8/48eOpXLkyxYoV46677iItLe2S+/H19XV5b7FYLhmUshtv5OJ+tstp164dDzzwAP3796djx46EhYVddGytWrWoVasWjzzyCA899BDNmjVjxYoVtGrVCjAnDKlcuXKe1ZZfdNlhYXdh2Mrj64tFRERExPP8/PPP9OnThzvvvJPatWsTERHB7t27C7SGkJAQwsPDWbNmjXOd3W5n3bp1Od6Hj48PvXr1Yvny5dlecngxNWrUACA5OTnnBXsIdb4KO5sN/P3NDlhyMnjgrC4iIiIikneqVKnCnDlz6NixIxaLheeeey7Hl/rlpcGDBzNmzBgqV65MtWrVmDhxIidPnszynK5LefHFF/m///u/i3a9Hn74YaKiorj55pu59tprOXToEC+99BJlypShSZMmznEZGRkkJCS4fNZisRAeHn5lXy6fKHx5g+LFzfClzpeIiIiI13vjjTfo168fN954I6VLl+bJJ58kKSmpwOt48sknSUhIoFevXthsNh544AHatGmDzWbL8T78/PwuOSV8XFwcH3/8Me+++y7Hjx+ndOnSNGnShCVLlrgEti1bthAZGenyWX9//ywPcnY3i5GXF24WIUlJSYSEhJCYmOj+m/mio2H/flizBv5zQ6aIiIhIUZCSksKuXbuoUKECAQEB7i6nSHI4HFSvXp177rmHF1980d3l5LlLnWM5zQbqfHmDzJsw1fkSERERkQKyZ88efvjhB1q0aEFqaiqTJk1i165d3Hvvve4uzWNpwg1vkDnpRiG86VBERERECier1cq0adNo1KgRTZs2ZdOmTSxevJjq1au7uzSPpc6XN1DnS0REREQKWHR0ND///LO7yyhU3N75mjx5MjExMQQEBBAbG3vJp2xv2bKFLl26EBMTg8ViYcKECVnGZG777zJw4EDnmJYtW2bZ7olPwM4xdb5ERERERDyeW8PXrFmzGDZsGKNGjWLdunXUrVuXNm3aXPRJ22fPnqVixYqMHTuWiIiIbMesWbOGQ4cOOZf4+HgA7r77bpdxAwYMcBn32muv5e2XK0jqfImIiIiIeDy3hq833niDAQMG0LdvX2rUqMGUKVMIDAzk448/znZ8o0aNGDduHN26dcPf3z/bMWXKlCEiIsK5zJ8/n0qVKtGiRQuXcYGBgS7j3D5j4dXI7HwpfImIiIiIeCy3ha+0tDTWrl1LXFzc+WKsVuLi4li1alWeHePzzz+nX79+WR72Nn36dEqXLk2tWrUYMWIEZy8TXFJTU0lKSnJZPEZm50uXHYqIiIiIeCy3Tbhx7Ngx7HZ7lqdOh4eHs3379jw5xty5czl16hR9+vRxWX/vvfdSvnx5oqKi2LhxI08++SQ7duxgzpw5F93XmDFjeP755/OkrjynzpeIiIiIiMfz6tkOP/roI9q1a0dUVJTL+gceeMD5unbt2kRGRnLLLbfw999/U6lSpWz3NWLECIYNG+Z8n5SURHR0dP4UnlvqfImIiIiIeDy3XXZYunRpbDYbhw8fdll/+PDhi06mkRt79uxh8eLF3H///ZcdGxsbC8Bff/110TH+/v4EBwe7LB5DnS8RERGRIq1ly5YMGTLE+T4mJibbmcEvZLFYmDt37lUfO6/2UxS4LXz5+fnRoEEDlixZ4lzncDhYsmQJTZo0uer9T506lbJly9KhQ4fLjl2/fj0AkZGRV31ct9BU8yIiIiKFUseOHWnbtm2223788UcsFgsbN27M9X7XrFnjcrVXXhg9ejT16tXLsv7QoUO0a9cuT4/1X9OmTcNisWT7AOfZs2djsViIiYlxrrPb7YwdO5Zq1apRrFgxSpUqRWxsLB9++KFzTJ8+fbJ9RNXF/vPIC2697HDYsGH07t2bhg0b0rhxYyZMmEBycjJ9+/YFoFevXlxzzTWMGTMGMCfQ2Lp1q/P1gQMHWL9+PUFBQVSuXNm5X4fDwdSpU+nduzc+Pq5f8e+//2bGjBm0b9+esLAwNm7cyNChQ2nevDl16tQpoG+exzTVvIiIiEih1L9/f7p06cL+/fu59tprXbZNnTqVhg0bXtHfqGXKlMmrEi8rL65ay4nixYtz5MgRVq1a5dKs+eijjyhXrpzL2Oeff5733nuPSZMm0bBhQ5KSkvj99985efKky7i2bdsydepUl3UXm1U9L7h1qvmuXbsyfvx4Ro4cSb169Vi/fj2LFi1yTsKxd+9eDh065Bx/8OBB6tevT/369Tl06BDjx4+nfv36WS4tXLx4MXv37qVfv35Zjunn58fixYtp3bo11apV4/HHH6dLly7Mmzcvf79sflLnS0RERCQLwzD/PCroxTByXuNtt91GmTJlmDZtmsv6M2fOMHv2bPr378/x48fp3r0711xzDYGBgdSuXZuZM2decr//vexw586dNG/enICAAGrUqOF8Fu6FnnzySa677joCAwOpWLEizz33HOnp6YDZeXr++efZsGGDs0OUWfN/LzvctGkTN998M8WKFSMsLIwHHniAM2fOOLf36dOHTp06MX78eCIjIwkLC2PgwIHOY12Mj48P9957r8tjqfbv38/y5cu59957XcZ+++23PPLII9x9991UqFCBunXr0r9/f4YPH+4yzt/f3+XxUxEREZQsWfKSdVwNt0+4MWjQIAYNGpTttuXLl7u8j4mJwcjB2dy6deuLjouOjmbFihW5rtOjqfMlIiIiksXZsxAUVPDHPXPm/J9nl+Pj40OvXr2YNm0azzzzjPPxSLNnz8Zut9O9e3fOnDlDgwYNePLJJwkODua7777jvvvuo1KlSjRu3Piyx3A4HHTu3Jnw8HB+++03EhMTXe4Py1SiRAmmTZtGVFQUmzZtYsCAAZQoUYInnniCrl27snnzZhYtWsTixYsBCAkJybKP5ORk2rRpQ5MmTVizZg1Hjhzh/vvvZ9CgQS4Bc9myZURGRrJs2TL++usvunbtSr169RgwYMAlv0u/fv1o2bIlb731FoGBgUybNo22bdtmmUE9IiKCpUuX8sgjjxRoF/By3Nr5kjyizpeIiIhIodWvXz/+/vtvlwbB1KlT6dKlCyEhIVxzzTUMHz6cevXqUbFiRQYPHkzbtm358ssvc7T/xYsXs337dj799FPq1q1L8+bNeeWVV7KMe/bZZ7nxxhuJiYmhY8eODB8+3HmMYsWKERQUhI+Pj7NDVKxYsSz7mDFjBikpKXz66afUqlWLm2++mUmTJvHZZ5+5TLRXsmRJJk2aRLVq1bjtttvo0KGDy1wQF1O/fn0qVqzIV199hWEYTJs2Ldur3d544w2OHj1KREQEderU4aGHHmLhwoVZxs2fP5+goCCXJbvfTV5xe+dL8oA6XyIiIiJZBAaaXSh3HDc3qlWrxo033sjHH39My5Yt+euvv/jxxx954YUXAHPyiFdeeYUvv/ySAwcOkJaWRmpqKoE5PNC2bduIjo52efxSdhPczZo1i7fffpu///6bM2fOkJGRkesZvrdt20bdunUpfkHrr2nTpjgcDnbs2OHsUNWsWRObzeYcExkZyaZNm3J0jH79+jF16lTKlStHcnIy7du3Z9KkSS5jatSowebNm1m7di0///wzK1eupGPHjvTp08dl0o1WrVrx7rvvuny2VKlSufrOuaHw5Q3U+RIRERHJwmLJ+eV/7ta/f38GDx7M5MmTmTp1KpUqVaJFixYAjBs3jrfeeosJEyZQu3ZtihcvzpAhQ0hLS8uz469atYoePXrw/PPP06ZNG0JCQvjiiy94/fXX8+wYF/L19XV5b7FYcDgcOfpsjx49eOKJJxg9ejT33Xdflgn2MlmtVho1akSjRo0YMmQIn3/+Offddx/PPPMMFSpUAMxJPC6cuC+/6bJDb6DOl4iIiEihds8992C1WpkxYwaffvop/fr1c97/9fPPP3PHHXfQs2dP6tatS8WKFfnzzz9zvO/q1auzb98+l4nsfv31V5cxv/zyC+XLl+eZZ56hYcOGVKlShT179riM8fPzw263X/ZYGzZsIPmCpsDPP/+M1WqlatWqOa75UkqVKsXtt9/OihUrsr3k8GJq1KgB4FJbQVP48gbqfImIiIgUakFBQXTt2pURI0Zw6NAh+vTp49xWpUoV4uPj+eWXX9i2bRsPPvigy/1TlxMXF8d1111H79692bBhAz/++CPPPPOMy5gqVaqwd+9evvjiC/7++2/efvttvv76a5cxMTEx7Nq1i/Xr13Ps2DFSU1OzHKtHjx4EBATQu3dvNm/ezLJlyxg8eDD33Xdflkkxrsa0adM4duwY1apVy3b7XXfdxZtvvslvv/3Gnj17WL58OQMHDuS6665z+UxqaioJCQkuy7Fjx/Kszv9S+PIGmZ2vjAy4zBSdIiIiIuKZ+vfvz8mTJ2nTpo3L/VnPPvss119/PW3atKFly5ZERETQqVOnHO/XarXy9ddfc+7cORo3bsz999/Pyy+/7DLm9ttvZ+jQoQwaNIh69erxyy+/8Nxzz7mM6dKlC23btqVVq1aUKVMm2+nuAwMD+f777zlx4gSNGjXirrvu4pZbbslyT9bVypzG/mLatGnDvHnz6NixozN4VqtWjR9++MHlMsVFixYRGRnpstx00015WuuFLEZO5m6XLJKSkggJCSExMTHXNyLmudRUCAgwX588CaGhbi1HREREpKClpKSwa9cuKlSoQEDm30UieehS51hOs4E6X97Azw8yZ4vRfV8iIiIiIh5J4csbWCzn7/tS+BIRERER8UgKX94i874vTbohIiIiIuKRFL68hTpfIiIiIiIeTeHLW6jzJSIiIoLmkpP8khfnlsKXt1DnS0RERIowX19fAM7qbyHJJ5nnVua5diV8Lj9ECgU9aFlERESKMJvNRmhoKEeOHAHM501ZLBY3VyXewDAMzp49y5EjRwgNDcWWOcv4FVD48haZlx3qX3tERESkiIqIiABwBjCRvBQaGuo8x66Uwpe3UOdLREREijiLxUJkZCRly5YlPT3d3eWIF/H19b2qjlcmhS9voc6XiIiICGBegpgXfyiL5DVNuOEt1PkSEREREfFoCl/eQp0vERERERGPpvDlLdT5EhERERHxaApf3kKdLxERERERj6bw5S3U+RIRERER8WgKX95CnS8REREREY+m8OUt1PkSEREREfFoCl/eQp0vERERERGPpvDlLdT5EhERERHxaApf3kKdLxERERERj6bw5S0yO18KXyIiIiIiHknhy1tkdr502aGIiIiIiEdS+PIWmZ2vc+fA4XBvLSIiIiIikoXCl7fIDF9gBjAREREREfEoCl/e4sLwpfu+REREREQ8jsKXt7BaISDAfK37vkREREREPI7ClzfRdPMiIiIiIh5L4cub6EHLIiIiIiIeS+HLm6jzJSIiIiLisRS+vIk6XyIiIiIiHkvhy5uo8yUiIiIi4rEUvryJOl8iIiIiIh5L4cubqPMlIiIiIuKxFL68iTpfIiIiIiIeS+HLm6jzJSIiIiLisRS+vIk6XyIiIiIiHkvhy5uo8yUiIiIi4rEUvrxJZudL4UtERERExOMofHmTzM6XLjsUEREREfE4Cl/eRJ0vERERERGPpfDlTTThhoiIiIiIx3J7+Jo8eTIxMTEEBAQQGxvL6tWrLzp2y5YtdOnShZiYGCwWCxMmTMgyZvTo0VgsFpelWrVqLmNSUlIYOHAgYWFhBAUF0aVLFw4fPpzXX63gacINERERERGP5dbwNWvWLIYNG8aoUaNYt24ddevWpU2bNhw5ciTb8WfPnqVixYqMHTuWiIiIi+63Zs2aHDp0yLn89NNPLtuHDh3KvHnzmD17NitWrODgwYN07tw5T7+bW6jzJSIiIiLisdwavt544w0GDBhA3759qVGjBlOmTCEwMJCPP/442/GNGjVi3LhxdOvWDX9//4vu18fHh4iICOdSunRp57bExEQ++ugj3njjDW6++WYaNGjA1KlT+eWXX/j111/z/DsWKHW+REREREQ8ltvCV1paGmvXriUuLu58MVYrcXFxrFq16qr2vXPnTqKioqhYsSI9evRg7969zm1r164lPT3d5bjVqlWjXLlylzxuamoqSUlJLovHUedLRERERMRjuS18HTt2DLvdTnh4uMv68PBwEhISrni/sbGxTJs2jUWLFvHuu++ya9cumjVrxunTpwFISEjAz8+P0NDQXB13zJgxhISEOJfo6OgrrjHfqPMlIiIiIuKx3D7hRl5r164dd999N3Xq1KFNmzYsWLCAU6dO8eWXX17VfkeMGEFiYqJz2bdvXx5VnIcu7HwZhntrERERERERFz7uOnDp0qWx2WxZZhk8fPjwJSfTyK3Q0FCuu+46/vrrLwAiIiJIS0vj1KlTLt2vyx3X39//kveZeYTMzpfdDunp4Ofn3npERERERMTJbZ0vPz8/GjRowJIlS5zrHA4HS5YsoUmTJnl2nDNnzvD3338TGRkJQIMGDfD19XU57o4dO9i7d2+eHtctMjtfoPu+REREREQ8jNs6XwDDhg2jd+/eNGzYkMaNGzNhwgSSk5Pp27cvAL169eKaa65hzJgxgDlJx9atW52vDxw4wPr16wkKCqJy5coADB8+nI4dO1K+fHkOHjzIqFGjsNlsdO/eHYCQkBD69+/PsGHDKFWqFMHBwQwePJgmTZpwww03uOG3kIf8/MDHBzIyzPu+SpZ0d0UiIiIiIvIvt4avrl27cvToUUaOHElCQgL16tVj0aJFzkk49u7di9V6vjl38OBB6tev73w/fvx4xo8fT4sWLVi+fDkA+/fvp3v37hw/fpwyZcpw00038euvv1KmTBnn5958802sVitdunQhNTWVNm3a8M477xTMl85vgYGQlKTOl4iIiIiIh7EYhmZmuBJJSUmEhISQmJhIcHCwu8s5LyoKDh2CP/6AevXcXY2IiIiIiNfLaTbwutkOizw960tERERExCMpfHkbPetLRERERMQjKXx5m8zOl8KXiIiIiIhHUfjyNpmdL112KCIiIiLiURS+vI06XyIiIiIiHknhy9uo8yUiIiIi4pEUvryNOl8iIiIiIh5J4cvbaKp5ERERERGPpPDlbTTVvIiIiIiIR1L48jbqfImIiIiIeCSFL2+jzpeIiIiIiEdS+PI26nyJiIiIiHgkhS9vo86XiIiIiIhHUvjyNup8iYiIiIh4JIUvb6POl4iIiIiIR1L48jbqfImIiIiIeCSFL2+jzpeIiIiIiEdS+PI26nyJiIiIiHgkhS9vo86XiIiIiIhHUvjyNpmdr5QUsNvdW4uIiIiIiDgpfHmbzM4XwLlz7qtDRERERERcKHx5m4CA86916aGIiIiIiMdQ+PI2Vqsm3RARERER8UAKX94oM3yp8yUiIiIi4jEUvryROl8iIiIiIh5H4csbabp5ERERERGPo/DljdT5EhERERHxOApf3kidLxERERERj6Pw5Y3U+RIRERER8TgKX95InS8REREREY+j8OWN1PkSEREREfE4Cl/eSJ0vERERERGPo/DljdT5EhERERHxOApf3kidLxERERERj6Pw5Y3U+RIRERER8TgKX95InS8REREREY+j8OWN1PkSEREREfE4Cl/eSJ0vERERERGPo/DljTI7XwpfIiIiIiIeQ+HLG2V2vnTZoYiIiIiIx1D48kbqfImIiIiIeByFL2+kCTdERERERDyOwpc30oQbIiIiIiIeR+HLG13Y+TIM99YiIiIiIiKAwpd3yux8ORyQlubeWkREREREBFD48k6ZnS/QfV8iIiIiIh5C4csb+fqaC+i+LxERERERD6Hw5a0046GIiIiIiEdxe/iaPHkyMTExBAQEEBsby+rVqy86dsuWLXTp0oWYmBgsFgsTJkzIMmbMmDE0atSIEiVKULZsWTp16sSOHTtcxrRs2RKLxeKyPPTQQ3n91dxLMx6KiIiIiHgUt4avWbNmMWzYMEaNGsW6deuoW7cubdq04ciRI9mOP3v2LBUrVmTs2LFERERkO2bFihUMHDiQX3/9lfj4eNLT02ndujXJ/+kADRgwgEOHDjmX1157Lc+/n1up8yUiIiIi4lF83HnwN954gwEDBtC3b18ApkyZwnfffcfHH3/MU089lWV8o0aNaNSoEUC22wEWLVrk8n7atGmULVuWtWvX0rx5c+f6wMDAiwY4r6DOl4iIiIiIR3Fb5ystLY21a9cSFxd3vhirlbi4OFatWpVnx0lMTASgVKlSLuunT59O6dKlqVWrFiNGjODsZUJKamoqSUlJLotHU+dLRERERMSjuK3zdezYMex2O+Hh4S7rw8PD2b59e54cw+FwMGTIEJo2bUqtWrWc6++9917Kly9PVFQUGzdu5Mknn2THjh3MmTPnovsaM2YMzz//fJ7UVSDU+RIRERER8Shuvewwvw0cOJDNmzfz008/uax/4IEHnK9r165NZGQkt9xyC3///TeVKlXKdl8jRoxg2LBhzvdJSUlER0fnT+F5QZ0vERERERGP4rbwVbp0aWw2G4cPH3ZZf/jw4Ty5F2vQoEHMnz+flStXcu21115ybGxsLAB//fXXRcOXv78//v7+V11XgVHnS0RERETEo7jtni8/Pz8aNGjAkiVLnOscDgdLliyhSZMmV7xfwzAYNGgQX3/9NUuXLqVChQqX/cz69esBiIyMvOLjehx1vkREREREPIpbLzscNmwYvXv3pmHDhjRu3JgJEyaQnJzsnP2wV69eXHPNNYwZMwYwJ+nYunWr8/WBAwdYv349QUFBVK5cGTAvNZwxYwbffPMNJUqUICEhAYCQkBCKFSvG33//zYwZM2jfvj1hYWFs3LiRoUOH0rx5c+rUqeOG30I+UedLRERERMSjuDV8de3alaNHjzJy5EgSEhKoV68eixYtck7CsXfvXqzW8825gwcPUr9+fef78ePHM378eFq0aMHy5csBePfddwHzQcoXmjp1Kn369MHPz4/Fixc7g150dDRdunTh2Wefzd8vW9AyO18KXyIiIiIiHsFiGIbh7iIKo6SkJEJCQkhMTCQ4ONjd5WT14oswciQMGADvv+/uakREREREvFZOs4Hb7vmSfKbLDkVEREREPIrCl7fShBsiIiIiIh5F4ctbqfMlIiIiIuJRFL68lTpfIiIiIiIeReHLW6nzJSIiIiLiURS+vJU6XyIiIiIiHkXhy1up8yUiIiIi4lEUvryVOl8iIiIiIh5F4ctbqfMlIiIiIuJRFL68VWbnKzUV7Hb31iIiIiIiIgpfXiuz8wXqfomIiIiIeACFL28VEAAWi/la932JiIiIiLidwpe3sljOX3qozpeIiIiIiNspfHkzzXgoIiIiIuIxFL68mWY8FBERERHxGApf3kyXHYqIiIiIeAyFLy+wfz8sWpTNBl12KCIiIiLiMXzcXYBcnXXroGlTc3LDv/+GUqUu2KjLDkVEREREPIY6X4Vc3bpw3XVw6hS88sp/NqrzJSIiIiLiMRS+CjmbDV57zXw9cSLs3n3BRnW+REREREQ8hsKXF2jdGuLiIC0Nnn32gg3qfImIiIiIeAyFLy9gsZzvfk2fbt4HBqjzJSIiIiLiQRS+vET9+tCzp/n6//4PDAN1vkREREREPIjClxd56SXw84OlS+H771HnS0RERETEgyh8eZHy5WHwYPP1E0+APeDf8KXOl4iIiIiI2yl8eZmnn4bQUNi0CT7bcr25Up0vERERERG3U/jyMqVKwTPPmK+fXdCEcwSo8yUiIiIi4gEUvrzQoEFQrhwcOFmct3hMnS8REREREQ+g8OWFAgLg5ZfN12MYwbFTPu4tSEREREREFL681b33Qr3Kp0kihJf29nJ3OSIiIiIiRZ7Cl5eyWmHc4H0AvHOiK4mJbi5IRERERKSIU/jyYnGt7ESzl3T82LLF3dWIiIiIiBRtCl/eLDCQ6mwDYOtWN9ciIiIiIlLEKXx5swvC17athpuLEREREREp2hS+vFnx4tTAbHlt2+pwczEiIiIiIkWbwpc302WHIiIiIiIeQ+HLm/n4UP2a0wDs2WcjOdnN9YiIiIiIFGEKX16u9C11KcMRAHbscHMxIiIiIiJFmMKXt2vZUpceioiIiIh4AIUvb9eq1fkZDzekubkYEREREZGiS+HL28XEUKNkAgDbVp10czEiIiIiIkWXwlcRUL1hcQC2btN/3CIiIiIi7qK/xouA6u1iAPjrREnSdOWhiIiIiIhbKHwVAdd0akQJkrDjw18bNd+8iIiIiIg7KHwVAZYKMVT3+weArXN3urkaEREREZGiSeGriKhe7gwA21YccXMlIiIiIiJFk8JXEVHj+mIAbNtmuLkSEREREZGiSeGriKjephwAW4+Hw+nTbq5GRERERKTocXv4mjx5MjExMQQEBBAbG8vq1asvOnbLli106dKFmJgYLBYLEyZMuKJ9pqSkMHDgQMLCwggKCqJLly4cPnw4L7+Wx6nevAwAO6iKfcVPbq5GRERERKTocWv4mjVrFsOGDWPUqFGsW7eOunXr0qZNG44cyf6+pLNnz1KxYkXGjh1LRETEFe9z6NChzJs3j9mzZ7NixQoOHjxI586d8+U7eooKFcDflk4Kxdgzb6O7yxERERERKXIshmG47Sag2NhYGjVqxKRJkwBwOBxER0czePBgnnrqqUt+NiYmhiFDhjBkyJBc7TMxMZEyZcowY8YM7rrrLgC2b99O9erVWbVqFTfccEO2x0tNTSU1NdX5PikpiejoaBITEwkODr7SX0GBqlvuBBv3lWJelWHc9ucb7i5HRERERMQrJCUlERISctls4LbOV1paGmvXriUuLu58MVYrcXFxrFq1Kt/2uXbtWtLT013GVKtWjXLlyl3yuGPGjCEkJMS5REdHX1GN7lS9XgAA2/7yhaQkN1cjIiIiIlK0uC18HTt2DLvdTnh4uMv68PBwEhIS8m2fCQkJ+Pn5ERoamqvjjhgxgsTEROeyb9++K6rRnao3CARgm1EVftJ9XyIiIiIiBcntE24UFv7+/gQHB7sshU2NGubPrdSA5cvdWouIiIiISFHjtvBVunRpbDZbllkGDx8+fNHJNPJinxEREaSlpXHq1Kk8O25hUb26+XMb1TGWLnNvMSIiIiIiRYzbwpefnx8NGjRgyZIlznUOh4MlS5bQpEmTfNtngwYN8PX1dRmzY8cO9u7de8XHLSyqVAGr1SCJEA6tOwSJie4uSURERESkyPBx58GHDRtG7969adiwIY0bN2bChAkkJyfTt29fAHr16sU111zDmDFjAHNCja1btzpfHzhwgPXr1xMUFETlypVztM+QkBD69+/PsGHDKFWqFMHBwQwePJgmTZpcdKZDb+HvD5UrW/jzT9hqVCPqp5+gQwd3lyUiIiIiUiS4NXx17dqVo0ePMnLkSBISEqhXrx6LFi1yTpixd+9erNbzzbmDBw9Sv3595/vx48czfvx4WrRowfJ/72G63D4B3nzzTaxWK126dCE1NZU2bdrwzjvvFMyXdrPq1eHPP81LD+OWLVP4EhEREREpIG59zldhltO5/D3NiBEwdiw8zDu80+Bj+P13d5ckIiIiIlKoefxzvsQ9XGY8/OMP+M/EIyIiIiIikj8UvooY54yHtlrgcMCPP7q3IBERERGRIkLhq4ipVs38ecRemuOU0vO+REREREQKSK7C1+rVq7Hb7RfdnpqaypdffnnVRUn+CQqCcuXM19uoDsv0vC8RERERkYKQq/DVpEkTjh8/7nwfHBzMP//843x/6tQpunfvnnfVSb648GHLrF8PF/xnKiIiIiIi+SNX4eu/EyNmN1GiJk/0fM7wVaYFGAbMmuXegkREREREioA8v+fLYrHk9S4lj2XOeLgt7CbzxdSp7itGRERERKSI0IQbRVBm52vrmWjw8TGf9bV5s3uLEhERERHxcj65/cDWrVtJSEgAzEsMt2/fzpkzZwA4duxY3lYn+SIzfO3db+NMx7sJmjcTpk2D8ePdWpeIiIiIiDezGLm4SctqtWKxWLK9rytzvcViueSMiN4ip0+x9lTh4XDkCPz++goaPN7SXLFvH/j6urs0EREREZFCJafZIFedr127dl11YeIZqlc3w9fWkk1pULYsHD4MixZBx47uLk1ERERExCvlKnyVL1/+smM2696hQqF6dVixArbt9IGePeGNN8xLDxW+RERERETyRZ5MuHH69Gnef/99GjduTN26dfNil5LPnDMebgP69DHfzJsHum9PRERERCRfXFX4WrlyJb179yYyMpLx48dz88038+uvv+ZVbZKPnDMebgVq14YGDSA9HWbMcGtdIiIiIiLeKtfhKyEhgbFjx1KlShXuvvtugoODSU1NZe7cuYwdO5ZGjRrlR52SxzLD199/Q1oa0LevuULP/BIRERERyRe5Cl8dO3akatWqbNy4kQkTJnDw4EEmTpyYX7VJPoqKgrAwsNshPh7o3h38/GD9enMREREREZE8lavwtXDhQvr378/zzz9Phw4dsNls+VWX5DOL5Xyz6403gFKl4I47zBXTprmrLBERERERr5Wr8PXTTz9x+vRpGjRoQGxsLJMmTdKDlQuxwYPBZoOlS/9tdmVOvDF9+r/XIoqIiIiISF7JVfi64YYb+OCDDzh06BAPPvggX3zxBVFRUTgcDuLj4zl9+nR+1Sn5oFw5uOce8/UbbwCtW0NkpDnj4XffubU2ERERERFvc0WzHRYvXpx+/frx008/sWnTJh5//HHGjh1L2bJluf322/O6RslHw4aZP2fOhAOHfeC++8wVuvRQRERERCRPXfVzvqpWrcprr73G/v37+eKLL7BYLHlRlxSQhg2heXPIyIBJkzh/6eF338Hhw+4sTURERETEq/jkZnC/fv0uOyYsLOyKixH3GDYMVq6EKVPgmWeqExQbC7/9Zt77ldkaExERERGRq5Krzte0adNYtmwZp06d4uTJk9kup06dyqdSJb/cdhtUrgynTv17teGFz/wyDDdWJiIiIiLiPSyGkfO/rgcOHMjMmTMpX748ffv2pWfPnpQqVSo/6/NYSUlJhISEkJiYSHBwsLvLuWrvvAMDB0LFivDn6lPYro2ElBT4+We48UZ3lyciIiIi4rFymg1y1fmaPHkyhw4d4oknnmDevHlER0dzzz338P3335OLDCceqHdvKFkS/vkHvl0ZCj16mBtee82tdYmIiIiIeItcT7jh7+9P9+7diY+PZ+vWrdSsWZNHHnmEmJgYzpw5kx81SgEoXhwefth8/frrwPDh5pOYv/kGtm93a20iIiIiIt7gqmY7tFqtWCwWDMPAbrfnVU3iJgMHgq+veaXhb4nV4I47zA3jxrm3MBERERERL5Dr8JWamsrMmTO59dZbue6669i0aROTJk1i7969BAUF5UeNUkCiouDee83Xb7wBPPGE+eazz+DgQbfVJSIiIiLiDXIVvh555BEiIyMZO3Yst912G/v27WP27Nm0b98eq/WqHxkmHmDoUPPnV1/B7sgm0KwZpKfDhAlurUtEREREpLDL1WyHVquVcuXKUb9+/Us+THnOnDl5Upwn87bZDi90662weLEZxN64eT507AglSsC+fRAS4u7yREREREQ8Sr7MdtirVy9atWpFaGgoISEhF12kcMt8rvKHH8K+2u2hZk04fdp8CrOIiIiIiFyRXHW+5Dxv7nwZBlx/PaxfD1WqwIqBXxI5pCtERMDu3eDv7+4SRUREREQ8Rr50vqRoyJxhvnx52LkT4t67i6ORdSAhwZx8Q0REREREck3hS7JVrhwsWQLXXANbt1m51RLPCUqa0847HO4uT0RERESk0FH4kouqVMkMYOHhsOFgWdra4kn8M8Fsi4mIiIiISK4ofMklVa1qznwYFgZr7A3owHeceeVt88YwERERERHJMYUvuaxateCHHyAk2MHP3MTtvz/HucU/u7ssEREREZFCReFLcuT662HR91aCfFNYxs107hGA3e7uqkRERERECg+FL8mxG26ABdOOEkgyi4425JsJu9xdkoiIiIhIoaHwJbnS7N5oBlZbCsD01w64uRoRERERkcJD4Utyref4egDMP9KIk3NXuLcYEREREZFCQuFLcq1Oh2hqhx0gDX++euxHPfdLRERERCQHFL7kivR8JASAz/c2g1mz3FyNiIiIiIjnU/iSK9J9QBAWi8FKWrD7iXcgNdXdJYmIiIiIeDSFL7ki0dHQspl5ueGM/c3gvffcXJGIiIiIiGdT+JIrdl8fGwCfcR/GCy9CUpKbKxIRERER8VwKX3LFOneGgACD7VTnj+PR8Npr7i5JRERERMRjeUT4mjx5MjExMQQEBBAbG8vq1asvOX727NlUq1aNgIAAateuzYIFC1y2WyyWbJdx48Y5x8TExGTZPnbs2Hz5ft4qJARuv90CwOf0hDfegIMH3VyViIiIiIhncnv4mjVrFsOGDWPUqFGsW7eOunXr0qZNG44cOZLt+F9++YXu3bvTv39//vjjDzp16kSnTp3YvHmzc8yhQ4dclo8//hiLxUKXLl1c9vXCCy+4jBs8eHC+fldv1LOn+XOmby8yzqXB6NFurUdERERExFNZDMMw3FlAbGwsjRo1YtKkSQA4HA6io6MZPHgwTz31VJbxXbt2JTk5mfnz5zvX3XDDDdSrV48pU6Zke4xOnTpx+vRplixZ4lwXExPDkCFDGDJkyBXVnZSUREhICImJiQQHB1/RPrxBWhpERcHx4/A9rWltXQKbN0P16u4uTURERESkQOQ0G7i185WWlsbatWuJi4tzrrNarcTFxbFq1apsP7Nq1SqX8QBt2rS56PjDhw/z3Xff0b9//yzbxo4dS1hYGPXr12fcuHFkZGRctNbU1FSSkpJcFgE/P+ja1Xz9+bUjzAcujxjh3qJERERERDyQW8PXsWPHsNvthIeHu6wPDw8nISEh288kJCTkavwnn3xCiRIl6Ny5s8v6Rx99lC+++IJly5bx4IMP8sorr/DEE09ctNYxY8YQEhLiXKKjo3PyFYuEzEsP5xxvQbIlCL75BlaudG9RIiIiIiIexu33fOW3jz/+mB49ehAQEOCyftiwYbRs2ZI6derw0EMP8frrrzNx4kRSL/Kw4BEjRpCYmOhc9u3bVxDlFwo33AAVK0LyOSvftJpgrnz0UbDb3VqXiIiIiIgncWv4Kl26NDabjcOHD7usP3z4MBEREdl+JiIiIsfjf/zxR3bs2MH9999/2VpiY2PJyMhg9+7d2W739/cnODjYZRGTxXK++/W55T4IDYUNG+CDD9xal4iIiIiIJ3Fr+PLz86NBgwYuE2E4HA6WLFlCkyZNsv1MkyZNXMYDxMfHZzv+o48+okGDBtStW/eytaxfvx6r1UrZsmVz+S0EoEcP8+cPy/04PPzfKf2feQZOnHBfUSIiIiIiHsTtlx0OGzaMDz74gE8++YRt27bx8MMPk5ycTN++fQHo1asXIy6YwOGxxx5j0aJFvP7662zfvp3Ro0fz+++/M2jQIJf9JiUlMXv27Gy7XqtWrWLChAls2LCBf/75h+nTpzN06FB69uxJyZIl8/cLe6nrroPGjc0rDWcF9oWaNc3gNXKku0sTEREREfEIbg9fXbt2Zfz48YwcOZJ69eqxfv16Fi1a5JxUY+/evRw6dMg5/sYbb2TGjBm8//771K1bl6+++oq5c+dSq1Ytl/1+8cUXGIZB9+7dsxzT39+fL774ghYtWlCzZk1efvllhg4dyvvvv5+/X9bLOS89nGmDt98237z7Lmzc6L6iREREREQ8hNuf81VY6TlfWR05Yj7zy24381btF+6Gr76CFi1g2TLz5jARERERES9TKJ7zJd6lbFno1Ml8PXgwGOPGQ0AArFgBs2e7tTYREREREXdT+JI8NX48FCtm5q1PlpeHp54yNwwfDmfPurc4ERERERE3UviSPBUTA6NHm6+HD4dj/Z6A8uVh3z549VV3liYiIiIi4lYKX5Lnhg6F2rXh+HH4v5HF4PXXzQ2vvgq7drm3OBERERERN1H4kjzn6wvvvWfOrzFtGqwI6ww33wypqWY7TERERESkCFL4knzRpAk8+KD5+qGHLaSOextsNpgzB+bPd29xIiIiIiJuoPAl+WbMGAgPh+3bYdyCmjBkiLmhf384fNittYmIiIiIFDSFL8k3oaHw5pvm65degp19XoY6dcwHgvXtC3rEnIiIiIgUIQpfkq+6dYPWrc3bvR4Z6o8xfYb57K+FC2HyZHeXJyIiIiJSYBS+JF9ZLPDOO2beWrwYZm6sCePGmRuHD4ctW9xboIiIiIhIAVH4knxXqRI8+6z5euhQONF9ILRvb7bDuneHlBT3FigiIiIiUgAUvqRA/N//QY0a5u1ewx63wMcfQ5kysGkTjBjh7vJERERERPKdwpcUCD8/+OgjsFrhk0/gu9/DYepUc+OECfD9926tT0REREQkvyl8SYG54QbzskOABx6AU007wMCB5oo+feDoUbfVJiIiIiKS3xS+pEC9+CJcdx0cPAiPP445+Ub16pCQAPffr+nnRURERMRrKXxJgSpWzLzdy/LvbV+LVhSDmTPN6xK//da8/0sBTERERES8kMKXFLimTWHIEPP1gAGQGFMXJk40V7z6qjk7hwKYiIiIiHgZhS9xi5degsqVYf9+83FfPPDA+Ycuv/66eXOYApiIiIiIeBGFL3GLwMDzlx9++CH88APwyCPw3nvmgLfegkGDwOFwa50iIiIiInlF4UvcplkzGDzYfD1gACQlYXbAPvrITGXvvAMPP6wAJiIiIiJeQeFL3OqVV6BiRdi7F5544t+V/frBtGnmQ8Hef99MZna7O8sUEREREblqCl/iVsWLm5cfgnnF4f/+9++GXr3gs8/MAPbxx9C3rwKYiIiIiBRqCl/idi1anJ/98N57YelSzr+ZORNsNjOIvf66u0oUEREREblqCl/iEcaNg86dIS0N7rgD1qz5d8M998C775qvX3gBDhxwW40iIiIiIldD4Us8go8PzJgBt9wCZ85Au3awbdu/G/v3hxtugORkePJJt9YpIiIiInKlFL7EY/j7w9dfQ6NGcPw4tG5tTsSB1QqTJpkzIE6fDj/95O5SRURERERyTeFLPEqJErBgAVSvbj6A+dZb4ehRoEEDuP9+c9DgwZp8Q0REREQKHYUv8TilS5sPXS5XDv78E9q2/fcZYC+/DKGhsH69OQW9iIiIiEghovAlHunaayE+HsqUgXXr4PbbIaVEGXjxRXPAs8+a1yaKiIiIiBQSCl/isa67DhYtMi9FXLECHnoIjAcfgtq14cQJM4CJiIiIiBQSCl/i0a6/3pyEw2qFTz6BKR/6wMSJ5sb33oM//nBvgSIiIiIiOaTwJR7vlltg7Fjz9WOPwSq/FtC1KxiGOfmGYbi3QBERERGRHFD4kkJh+HC46y5ITzd/JjzxBgQGws8/m9PPi4iIiIh4OIUvKRQsFvj4Y6hRAw4ehHuGRJH+1HPmxieegNOn3VugiIiIiMhlKHxJoVGiBMyZA8HB8OOP8MTR4VCpEhw6BAMGgMPh7hJFRERERC5K4UsKlapV4dNPzdcTJvowo/s88PGBWbNg9Gi31iYiIiIicikKX1Lo3HEHPPOM+fr+16uz8bnZ5psXXzyfzEREREREPIzClxRKzz8PbdrAuXNw5yedODnkeXPD/ffDypXuLU5EREREJBsKX1Io2WwwYwZUqAD//ANdNjxHWudu5nSId94JO3e6u0QRERERERcKX1JolSoFc+eaE3EsW2bh/oDPMBo1hhMnoEMH86eIiIiIiIdQ+JJCrU4d+OorsxP22QwfRjdbAuXKmZ2vzp0hLc3dJYqIiIiIAApf4gVat4b33jNfv/BGEFPv/9lsh61YAQ88AIbh3gJFRERERFD4Ei/Rv//5GRAfeOFaFo9YYrbDPvnEnJ1DRERERMTNFL7Ea7z4Itx7L2RkQJexjdg0Yoa54fnnYcIEt9YmIiIiIqLwJV7DYoGPP4YWLSApCdpPu4eD//emuXHoUJg61b0FioiIiEiRpvAlXsXfH77+GqpVg/37oUP8Y5we/LS58f774X//c2+BIiIiIlJkKXyJ1ylZEhYsgLJlYf16C522vERK7wfB4YDu3eH7791dooiIiIgUQQpf4pUqVIDvvoOgIFi61ELXE++S3uWChzD//LO7SxQRERGRIsYjwtfkyZOJiYkhICCA2NhYVq9efcnxs2fPplq1agQEBFC7dm0WLFjgsr1Pnz5YLBaXpW3bti5jTpw4QY8ePQgODiY0NJT+/ftz5syZPP9u4j4NG8K8eRAQAN/Os9DX73McbdrBuXPmQ5jXr3d3iSIiIiJShLg9fM2aNYthw4YxatQo1q1bR926dWnTpg1HjhzJdvwvv/xC9+7d6d+/P3/88QedOnWiU6dObN682WVc27ZtOXTokHOZOXOmy/YePXqwZcsW4uPjmT9/PitXruSBBx7It+8p7tGypfkQZh8fmD7TxsDobzCa3gSJieYDwnbscHeJIiIiIlJEWAzDvU+gjY2NpVGjRkyaNAkAh8NBdHQ0gwcP5qmnnsoyvmvXriQnJzN//nznuhtuuIF69eoxZcoUwOx8nTp1irlz52Z7zG3btlGjRg3WrFlDw4YNAVi0aBHt27dn//79REVFXbbupKQkQkJCSExMJDg4OLdfWwrYrFnm7V6GAU8OSWHsihvhjz8gMhKWL4frrnN3iSIiIiJSSOU0G7i185WWlsbatWuJi4tzrrNarcTFxbFq1apsP7Nq1SqX8QBt2rTJMn758uWULVuWqlWr8vDDD3P8+HGXfYSGhjqDF0BcXBxWq5Xffvst2+OmpqaSlJTkskjh0bUrvPee+frVCQGMab8SateGQ4egVSvYudO9BYqIiIiI13Nr+Dp27Bh2u53w8HCX9eHh4SQkJGT7mYSEhMuOb9u2LZ9++ilLlizh1VdfZcWKFbRr1w673e7cR9myZV324ePjQ6lSpS563DFjxhASEuJcoqOjc/19xb0GDIDx483XT78cxOR7f4ZateDgQfP6RAUwEREREclHbr/nKz9069aN22+/ndq1a9OpUyfmz5/PmjVrWL58+RXvc8SIESQmJjqXffv25V3BUmAefxyee858PWhECcZ1XoWjxr8BrFUr+Osv9xYoIiIiIl7LreGrdOnS2Gw2Dh8+7LL+8OHDREREZPuZiIiIXI0HqFixIqVLl+avf/+wjoiIyDKhR0ZGBidOnLjofvz9/QkODnZZpHB6/nl47DHz9RMvBNEh4neOVG0GBw6YHTAFMBERERHJB24NX35+fjRo0IAlS5Y41zkcDpYsWUKTJk2y/UyTJk1cxgPEx8dfdDzA/v37OX78OJGRkc59nDp1irVr1zrHLF26FIfDQWxs7NV8JSkELBZ4802YMsWchn7RUn/qnlzG4nL9zADWqhX8/be7yxQRERERL+P2yw6HDRvGBx98wCeffMK2bdt4+OGHSU5Opm/fvgD06tWLESNGOMc/9thjLFq0iNdff53t27czevRofv/9dwYNGgTAmTNn+L//+z9+/fVXdu/ezZIlS7jjjjuoXLkybdq0AaB69eq0bduWAQMGsHr1an7++WcGDRpEt27dcjTToRR+Fgs8+CCsWQM1akDCERut933IiLD3Sd+foA6YiIiIiOQ5t4evrl27Mn78eEaOHEm9evVYv349ixYtck6qsXfvXg4dOuQcf+ONNzJjxgzef/996taty1dffcXcuXOpVasWADabjY0bN3L77bdz3XXX0b9/fxo0aMCPP/6Iv7+/cz/Tp0+nWrVq3HLLLbRv356bbrqJ999/v2C/vLhdrVpmAHvwQTAMC2OPD6B5sTXs2u8DzZrBf54fJyIiIiJypdz+nK/CSs/58j5ffQX3328+fznYepqvHJ25teRaWLgQdDmqiIiIiFxEoXjOl4gnuesuWL8emjSBJEcJOlvnsv5kObjlFvjPfYYiIiIiIrml8CVygZgYWL4cbr4ZzjiK08F/MfuSS0L79vD11+4uT0REREQKMYUvkf/w84P//Q9q1oSDqaVpH/wTiWkBZmts2jR3lyciIiIihZTCl0g2QkPhu+8gIgI2J5Xn7qifSXdYoW9feOstd5cnIiIiIoWQwpfIRZQvbwaw4sUh/mAtHqz5EwbAkCHw3HOguWpEREREJBcUvkQu4frr4YsvwGqFqVtiefnmpeaGl14yu2Bpae4tUEREREQKDYUvkcu47TaYNMl8/dzSVnzefxnYbPDJJ+bGpCT3FigiIiIihYLCl0gOPPww/N//ma/7fdqSxc///O/1iPHQvDkcOODeAkVERETE4yl8ieTQ2LFw992Qng63vRjL3OfXQ3g4bNhgPhxsyxZ3lygiIiIiHkzhSySHrFb49FPo1AlSU6HLE5WZ9vgmqFoV9u2Dpk3Nh4SJiIiIiGRD4UskFwICYPZs6NMHHA7o+0QZ3uix1gxeiYnQpg3MmuXuMkVERETEAyl8ieSSjw989BEMG2a+f3xkcZ5puhyjcxdz9sPu3WHKFPcWKSIiIiIeR+FL5ApYrTB+PLzyivn+ldd8eLj0bOwPDTSf//XwwzBmjJ4FJiIiIiJOCl8iV8higREj4L33zNfvvW/h3hMTSRsxyhzw9NPwxBMKYCIiIiICKHyJXLUHHjBv8/L1hS+/tNBm1WiOvzDZ3Dh+PNx/P2RkuLdIEREREXE7hS+RPHD33TB/PgQFmRMexn7yCNte+p95feLHH0PXruYUiSIiIiJSZCl8ieSR1q1h1SqIiYG//4YbXuvMwqd/BD8/mDMHbrsNzpxxd5kiIiIi4iYKXyJ5qFYtWL0amjeHpCS47ZUbeaPfJozA4rB4MTRrBrt3u7tMEREREXEDhS+RPFamDMTHm7d6ORzw+JTr6NdqF6mlr4H166FBAzOIiYiIiEiRovAlkg/8/OD99+Gtt8zbvqZ9V4aby//N4bqt4cQJ82HM48ZpJkQRERGRIkThSySfWCzw6KOwcCGEhMAva/2pvncR7zWZht2BOQ19t26QnOzuUkVERESkACh8ieSz1q3ht9+gbl04edLCQ6t606T8QdbaGsOXX0KTJuYMHSIiIiLi1RS+RApA1arw++8wYQKUKAFr9oTTyPErAwM/5uSmfdCwISxY4O4yRURERCQfKXyJFBAfH3jsMdixA+69FwzDwjtn+1LV5x8+OXU7RocO8MwzeiCziIiIiJdS+BIpYJGRMH06LF0K1avD0YyS9OETOjOH1FfGw623QkKCu8sUERERkTym8CXiJq1amTPPjx0L/v4wlzvpbPuGlOWroH59WLHC3SWKiIiISB5S+BJxIz8/ePJJmD8fihWDBfa23BkUz7mEU3DzzTBmjPmwMBEREREp9BS+RDxAXBx89x0EBsKiM824I3INZx3+8PTT0LEjHD/u7hJFRERE5CopfIl4iFatzGeCFS8O8Ydq0bHaTpL9SpqzIF5/PaxZ4+4SRUREROQqKHyJeJDmzeH77yEoCJZuv4YOtfdypkJt2LsXbroJpkwBw3B3mSIiIiJyBRS+RDxM06bwww8QHAwr1gbRLnwdpzt0g7Q0ePhh6N0bzp51d5kiIiIikksKXyIeqEkTiI+HkBD46VcfmuyewepBn4LNBp99BrGx8Oef7i5TRERERHJB4UvEQzVuDEuWQJkysGWLhSbv3MewzrtJLlsBNm+Ghg1hzhx3lykiIiIiOaTwJeLBGjSArVuhZ09zxvk3Z19L7YA/WVxrCJw+DV26wNChkJrq7lJFRERE5DIUvkQ8XOnS5pWGCxZAuXKwa68Pt25+k761VnOCkjBhgnmd4o4d7i5VRERERC5B4UukkGjXzrzacPBgsFhg2uZG1Ag9yNTig0j7Y7M5Hf1HH2k2RBEREREPpfAlUoiUKAFvvw0//QTVqsHhUwH0S55Ieb9DvHx2CMfufxK6doVTp9xdqoiIiIj8h8KXSCF0442wfj28+ipERUFCWhjP8jLR7OPB2bewrUYXM6GJiIiIiMdQ+BIppPz94YknYNcu+Pxz86rDFIrxPg9S49AS2jc7zW/93zefDyYiIiIibqfwJVLI+flBjx7w+++wYgV0ui0dCw4W0o7mH/fmm+uGw5o17i5TREREpMhT+BLxEhYLNG8OX8/z5c+dVm5vcIA0/Omy5w1mxk4w22Tnzrm7TBEREZEiS+FLxAtVrgz/+/Ua7rs7BTs+9DA+4+Nxx6BuXfjxR3eXJyIiIlIkKXyJeCkfH5j2RQAPPggGVvrzMZN2tjbbY4MGmQ9pFhEREZECo/Al4sWsVnj3XRg61Hw/mEm8yhMweTLUqgWLFrm3QBEREZEiROFLxMtZLPD66/Dcc+b7p3iVkSFvYezdaz65uWdPOHbMvUWKiIiIFAEKXyJFgMUCL7wAY8ea719MfJQ+NVaz2VIbpk+H6tXNn4bh3kJFREREvJjCl0gR8uSTMHGi+frTrY2obWzkhmIb+PDYHZzu+RC0bw979ri3SBEREREvpfAlUsQMGgTLlkGXLuakHL+dq8MAPiSSQ9y/qAu/VuuD8cabkJ7u7lJFREREvIpHhK/JkycTExNDQEAAsbGxrF69+pLjZ8+eTbVq1QgICKB27dosWLDAuS09PZ0nn3yS2rVrU7x4caKioujVqxcHDx502UdMTAwWi8VlGZt5TZaIl2vZEr76Cg4cgHHjoGpVSCaIj7ifJinLiH28KWurdIML/rslIiIiIlfH7eFr1qxZDBs2jFGjRrFu3Trq1q1LmzZtOHLkSLbjf/nlF7p3707//v35448/6NSpE506dWLz5s0AnD17lnXr1vHcc8+xbt065syZw44dO7j99tuz7OuFF17g0KFDzmXw4MH5+l1FPE3ZsjB8OGzbZj7+q3cvg2K+GayhMY33fMnQDjs4fWtn2LrV3aWKiIiIFHoWw3DvHfaxsbE0atSISZMmAeBwOIiOjmbw4ME89dRTWcZ37dqV5ORk5s+f71x3ww03UK9ePaZMmZLtMdasWUPjxo3Zs2cP5cqVA8zO15AhQxgyZMgV1Z2UlERISAiJiYkEBwdf0T5EPNHhwzBsUBozvvIDIJq9TLI+yu2PRMPo0RAW5t4CRURERDxMTrOBWztfaWlprF27lri4OOc6q9VKXFwcq1atyvYzq1atchkP0KZNm4uOB0hMTMRisRAaGuqyfuzYsYSFhVG/fn3GjRtHRkbGRfeRmppKUlKSyyLijcLDYfpsPxYtggrXprOPctzhmEvnSa04UKk5vP02XOK/KyIiIiKSPbeGr2PHjmG32wkPD3dZHx4eTkJCQrafSUhIyNX4lJQUnnzySbp37+6SQh999FG++OILli1bxoMPPsgrr7zCE088cdFax4wZQ0hIiHOJjo7O6dcUKZTatIHNO3x56inwsTn4ms5UT1zF5Md24KjfAFascHeJIiIiIoWK2+/5yk/p6encc889GIbBu+++67Jt2LBhtGzZkjp16vDQQw/x+uuvM3HiRFJTU7Pd14gRI0hMTHQu+/btK4ivIOJWgYEwZgys+8PKDbEGpwlmEJNpu3kcB1reC/fea87aISIiIiKX5dbwVbp0aWw2G4cPH3ZZf/jwYSIiIrL9TERERI7GZwavPXv2EB8ff9n7smJjY8nIyGD37t3Zbvf39yc4ONhlESkqateGn3+xMHEiFCtmEE9rarOJL2dmmFMlvvYapKW5u0wRERERj+bW8OXn50eDBg1YsmSJc53D4WDJkiU0adIk2880adLEZTxAfHy8y/jM4LVz504WL15MWA4mCFi/fj1Wq5WyZcte4bcR8W5Wq/mMsHXrLDRoACcpRVe+5L7kd0l88mWoUwe+/97dZYqIiIh4LLdfdjhs2DA++OADPvnkE7Zt28bDDz9McnIyffv2BaBXr16MGDHCOf6xxx5j0aJFvP7662zfvp3Ro0fz+++/M2jQIMAMXnfddRe///4706dPx263k5CQQEJCAmn//sv8qlWrmDBhAhs2bOCff/5h+vTpDB06lJ49e1KyZMmC/yWIFCLVqsGqVfDss2C1GnzOfdSxbmbFjnBo2xZat4Y//nB3mSIiIiIex+1TzQNMmjSJcePGkZCQQL169Xj77beJjY0FoGXLlsTExDBt2jTn+NmzZ/Pss8+ye/duqlSpwmuvvUb79u0B2L17NxUqVMj2OMuWLaNly5asW7eORx55hO3bt5OamkqFChW47777GDZsGP7+/jmqWVPNi5gh7L774O+/wYKDIda3GeUYRQhJ0KMHvPQSxMS4u0wRERGRfJXTbOAR4aswUvgSMZ05A0OHwocfmu/L+CcyOnUEA/gAXz8rDBwIzzyj54OJiIiI1yoUz/kSkcIvKAg++AAWLDDn3jiaGsJA3qFO4F/MS2uN8eabUKkSvPIKnDrl7nJFRERE3EbhS0TyRLt2sGkTTJ4MpUvD9rPluZ153Fx8NWsTK5ndr+hos012kVlFRURERLyZwpeI5BlfX3jkEfjrL3jqKfD3h+XJjWjIWnqGzGPnmQiYMAEqV4Zu3eD3391dsoiIiEiBUfgSkTwXEmI+nHnHDnPeDYDpibdRzfonvSJ+4E97RZg1Cxo1ghYtYP580O2nIiIi4uUUvkQk35QvD59/bja4brsNHA4LnyXcSnXrDnpW+IkdthqwciV07AhNmsDSpe4uWURERCTfKHyJSL5r0ADmzYM1a8yc5XBYmL6rKTWMzfSovpZtAfXht9/gllsgLs58LSIiIuJlFL5EpMA0bAjffmt2wm6/3QxhM7ZdT42UdbQrt4WFtttwLFkKN9wAnTqZM3iIiIiIeAmFLxEpcA0awDffwLp1ZsayWGDR3hq0t8+jWvBB3rY8StI3S6FuXbj3Xli71t0li4iIiFw1hS8RcZv69eHrr2HnTnMG+pAQ2JkUwWPGW1zjc5jBxlvsmLnWbJnddBPMng0ZGe4uW0REROSKKHyJiNtVqgRvvAH798M770D16nAmoxiTGEw1dnCrJZ45P5cl457uUKECjB0Lx4+7u2wRERGRXFH4EhGPERQEDz8MW7ZAfLx5X5jFAouNOLowhxjrXl7Y35eDI942H9g8YACsXq1p6kVERKRQUPgSEY9jsZiTHn7zDfzzD4wYAWXKwAFHFKN4gfLs4e5zn7D0w78xYmPNe8PeekvdMBEREfFoFsPQPxlfiaSkJEJCQkhMTCQ4ONjd5Yh4vdRU+N//zMsSf/75/Pqqlh08ZLxLbz6hpN9ZcwaP/v3N9GbVvy+JiIhI/stpNtBfJiJSKPj7mxMf/vQTbNgADz4IxYvDDqMqQ5lAlOUQfdOm8NuXuzHatIGKFeHll+HwYXeXLiIiIgKo83XF1PkScb+kJJgxA959FzZuPL++vm0DD9kn052ZlPBNhc6dzZvJmjc3r2kUERERyUPqfImI1wsOhocegvXr4Zdf4L77zA7ZH/a6PMj7RFkTeDB9Iutm/QktW0KtWjBpEiQmurt0ERERKYLU+bpC6nyJeKbjx2HaNHj/ffjzz/PrG1jX8aDjXbrxBSUCHdClC/TqBa1agc3mtnpFRESk8MtpNlD4ukIKXyKezTBgxQp47z2YMwfS0sz1QdZk7nV8Ti8+5UZ+wRIVBT17mkGsZk33Fi0iIiKFksJXPlP4Eik8jh6FTz4xu2E7d55fH2PdQw/HZ/RgOtXZDtdfb167eOedUL68+woWERGRQkXhK58pfIkUPoYBy5eblyXOmQNnzpzfVp8/6MlndOMLojhkPjusY0fzSc8NGmjaehEREbkoha98pvAlUridPQvffgvTp8OiRZCRYa634OBGfqETc7mTr6nEPxAZCbfdZgaxW281Z/UQERER+ZfCVz5T+BLxHseOwezZ8Pnn5qyJF6pl3cKdjv/RibnU5w8soaHm1PXdupmTdfj4uKVmERER8RwKX/lM4UvEO+3bB998A3Pnmpco2u3nt5Wz7ed2+9fczre0YAV+ZUvC3XdD9+7QpIkuTRQRESmiFL7ymcKXiPc7cQK++w6+/tq8NPHcufPbgi1JtDMWcDvf0o6FlLw2CFq3hhYtzEUTdoiIiBQZCl/5TOFLpGg5exYWL4Z588zl8OHz22xk0IwfiWMxLVhBI9bgHxNlhrCWLc2fMTFgsbirfBEREclHCl/5TOFLpOhyOGDNGnPCjm+/hc2bXbcHcI4b+YUWrKAFK4jlNwLKhZv3iLVqZQYydcZERES8hsJXPlP4EpFM//wDCxeaD3Vevtx8rtiF/EmhDhtpwFrnUjPmLH4332SGsVtvhfDwPKnF4YDffoNataBEiTzZpYiIiFyGwlc+U/gSkewYBmzfboawFSvMJSEh6zg/UqnDRhryO61Yxq11j1Ly9mbQvj00agQ2W66PvX07PPggrFwJVavC0qUQFXX130lEREQuTeErnyl8iUhOGAb8/TesXXt+WbfO4NQp1/u/rNi5gV9pyyLahvxKg/bhWNu3Ne8Xi46+5DFSU2HMGHNJSzu/vnJlM4Bd5uMiIiJylRS+8pnCl4hcKcMwL1VcuxZ+/RV+WJDOlh2+LmNKc5RbiedmltK87A6qNIvA0uQGc0r766+HgADA7Kw9+CDs2GF+rn17ePJJ6NMHdu0y5/lYuhQqVCjY7ygiIlKUKHzlM4UvEclL+/aZ09kvWuhg8Q8OkpJdH94cTgLN+JHmrKSZz69cUyeMp5Kf4+MdTQGICHfw1ttW7r7bnFRx3z64+Wb46y+z87V0qdkJExERkbyn8JXPFL5EJL+kp//bEfsBVi6z89tqC6npF3+A84NMYSxPERpV3Jxpo1YtqF+fg9Gx3PJQZbZvtxAZaQawatUK8IuIiIgUEQpf+UzhS0QKSmqqObX9jz/CypUGP/9ocDrZSo3Sh3n/utdpeuBL2LMn288eDqzALSxmy9mKhIecY/Gnh6jVofwVTeghIiIi2VP4ymcKXyLiLhkZsH8/XHst+GRenZiUBFu3wqZN5rJuHfzxB5w9y1FKcyvxbKAepTnKJL/Hia15hvKxEViurw/16pndsmLF3Pm1RERECi2Fr3ym8CUiHs9uN+efX7uWEz9tpfWMPqxNPn/dYUlOcD3rzMWynusrJVKpfjC2WtWh+r9LlSrg7+/GLyEiIuL5FL7ymcKXiBQ2p07BqJEOflycxuY/fUm3Z7300I9UKvE3VdhpLpa/qRKVTJWaflxzXXGsZUtDmTJQtqz5M/N1yZLmTB8iIiJFkMJXPlP4EpHCLDUVtmwxr05ct9Zg3W/pbNhiIyXt4veC2cggnMNEcshlieIgMUHHqVKnGOWbRGFrdL05HX6lSmC9+EQhIiIi3kLhK58pfImIt7HbzSnqd+40lz93GOzcnMrOHXZ2HQogw3H5SToyO2fX8SfX+e3hupg0KlT1o1zVYlxbK5RiVa6FcuUgMlKTfoiIiNdQ+MpnCl8iUpRkZMCRI3DoEBw8aP7MXA7ss7NrRxp/7fElNcPnkvspwxGi2Uc5yz6ig04RUyaZiuXtVLzOhwp1SlCi2jXmk6Gjo8HX95L7EhER8RQKX/lM4UtExNWFnbM/t9n587eT/LkphT2H/Nh7KpjkjIDL7qMMR6jIP1RkF5EBJynhn0aJYukEFXNQoridoECDEiWgdKQvFeqHElSnIlx3nTn1oy5xFBERN1H4ymcKXyIiOWcY5oQfe/fC3l129m1JYs/WZPb8k8E/+/z451gwx1ODcr3f0hwlht1UsO6lQqlEKlybTnSMjbKRNspc60+ZmOIUvyYUSpeGsDAICyMdX3bsgI0bz8/Mv3EjpKVBu3bQqRPceisEBub1b0FERLyVwlc+U/gSEclbiYmwaxf885eDfzad4ej+NE6fsnM6ycGZ03D6DJw5a+X0WRsJicU4kVI8R/stxlnKcJSyHCEVf7ZTjXT8Lv0ZvwzaNDxOp1aJ3BaXSlj5IIiIyLNnoaWlmWG0bNk82Z0UYampMGQILFgAEybAnXe6uyKRoknhK58pfImIuFdSEuzeDbv+srNr3Ul2bTrDrr8dHDjmx9EzxTh6LogUR/bPKCtBErXZRB02UptN1GYTGfjwDXcwl07sIcY51kYG9fmDYJIo5pNBQDEoVtxKQJAPASX8CCrpS5nSBmXDLZSNtFE22p8y5YpRJqY4lpBg/jpQjC1bLWzZYs4wuXmzeWlmRoY5IWTbttCmDbRqBUG5b/5JEXbwIHTuDL/9dn7dmDHw5JN68oNIQVP4ymcKXyIins0wIDnZnCjk6FE4etgBZ85QO/wI5XwOYjl29N8NR81BJ09CcjLGmWQ2HI1i7qFYvj7Vko1p1a+4BhsZ2Ln0JCSZfK0Z3FT2T9pcu5WW5XdRLCwQR2gpHCElsQeXxBEciiOkJEZwCMVC/AgsbqF4cfPyyOLFwc+vaP/BffKk+TsonrOGaKH3669m8Dp0CEJDzRD/xRfmtl694P339Xx0kYKk8JXPFL5ERIqGf/6BDesNzh0/S8rhRFKOJHHuWDIpJ5I5dzKF06ccHD0dwNGzxTmSGsyRtJIcdZRyhq4gTlODrdRki8sSQiLLaMX3tGERbdlFxauq04qdINs5SvqeoZR/MmEByZQqlkJY8RTCSqRSsoSdYoEW/AJ9zKW4D37F/fAL8sM3yB/fQB98Av2xBfjiE+hnLsX98QnwweZjwWYjy+LjY4adgIDLBz+7HY4fN7Pu8ePmbXiVK5uB6Uo4HPDHH/DddzB/PqxZY+6rdWvo0gVuvx1KlbqyfV/Knj3m8b77DlJSoGNH83jlyuX9sS7m44/h4YfNy1dr1oS5c83f5TvvwKOPmr/rpk3h66/N56CLXOjMGfjkE/Me3Hvvhbp13V2Rd1D4ymcKXyIicjEOB5w87iDleDKRJc5gPZdstuEuXM6ehfR0SE/HSE3jr0PF+X7zNSzaXp61ByLA4cDqsGM1MrA6/l3s6QCcoxhnCSSZ4mTg/in5fUgn2JZMsM9Zgn1TCPZPoYR/OmccxTiaGszRlBKcOFcMA9cZKW1WBxXDkqgWfpLq4SeoFn6SauEnKRXqwBoUiC24OLYSgVhLmD8JCuK3Df7M/96PBUv9SThy8WfF+fgYtLopnS532OnUCcLL+V/RjJh2O6xebQauefPMCVqy06gR3HWXGcQqVcr1YXIkPR2GDYNJk8z3nTrBp59CiRLnx8THw913m/dQxsSYddesmT/1SOFy4ABMnAjvvWfec5rp1lth+HDzZ1Hunl8tha98pvAlIiIFzjDg9GkzuP27pJ9O4eyJFJJPpXPmRBonjzs4fsLC8ZNWTpyycjzRhxNnfDl5xo/UNEhLt5xfMqyk2W2kZvhgNyxkOKxkOGxkYCMDHzLwIR1f7NiyWXJ2OeV/leI4YRwngQhOc3X//1mcM7TmBzrwHe1ZwHHC+B9d+B9d2EQd5zgLDmLYjZ8lHV+rHV+rHT+bHV+bA1+bgc1qYGAB/v1pgIEFA9hytgJH00s692XFTtPSf3LbtesJ8Mlgzt6GrDxS1SVY1gv5h1ZlthDgb+DjZ8Hm54OPnxUffxs+/jasfj5YbFawWv/9acFitYLNhtUKvj5mXb42O742Az8fB742B298dx3Lt5iztIzuuZPneu3F6udjPhPPYoFz5+DcObbvtHHbmBv5+0gwJfxTmd5tPi3rnsQWWgKf0CBsJYOxlgzBEhJsJrdLhdLMFqePj/naas3RX+jnzpldwt27zy+7dpn3qZUuDRUqmOHwwp9Xes+jw2GWpOCQvfXr4fXXzctSMzLMdVWqQK1a8O235j8wANSubYawbl0N/KwZefqsxZQU8+ruxETzf8KSklx/pqZCxYrmPxTkpCNuGJCQYJ5TYWFQtWqelXrFFL7ymcKXiIh4LYfDvKYtJcX8K9rhyLoYBvY0O2dPppJ4OIWkY2kknUgn6YSdpFMOTic6KE4yZfwSKWM7QRnbCcIsJ/BJOwspKRgOg0MpJdl+5hq2J13DttPXsv10FDtOR3E6PQCHA+yGFbthxWFYnIGvEn9xG9/RwbaI5raf8fexn78O0uEw/7pMT2dnenlnEPudRlf16wjhFO1YyG3Mpy2LCOOEy/YEwplLJ77iLpbT8oqDaU4EcZrP6ckdfHvJcccpRRf+xwpaXnSMGbPt/8ZMnD8vfG1xxtDsX1txZHltx8ZxSuf6u5WynCDQcs4Z7604LnhtkG7xJRV/UvEnxfAn1fAj1fDDjg8WHARY0wiwpBJgSaOYNeXf16n4YMfHkoENBzaLHR/Ov87AhxQCSDECSMWPFMOfFIc/KYYfPhY7gbZUAm2pFLelEGhL+/dnKjYyMOwODLsDR4aB4XDgsBsYdgOLBXx8wcfXis3XagZvPys2fxtWm3k+G4Bh/Pubywz7DgOH3YGR4XDu23CYPy0Y54O4r4GvD/j6GPj5Gth8LGC1gMWKYfk3HFvN1yv3V2DpnsrO33Hz6H94vNGP3FZ5O9a0FHbvs/HWumZ8sOdWkh3m8zWuYT99mUpoQCrWILPz7FyCg7AUD3Qm3f+miNQMGwmnAjiUGMjBxOIcOl2cg6dLcDIl58/u8LHaqVL6JDUjjlMj/AQVSydx+HQgu4+XYNeJYHadCGHPyWBSMsxwOKTTLt78ukKuz7e8VqjC1+TJkxk3bhwJCQnUrVuXiRMn0rhx44uOnz17Ns899xy7d++mSpUqvPrqq7Rv39653TAMRo0axQcffMCpU6do2rQp7777LlWqVHGOOXHiBIMHD2bevHlYrVa6dOnCW2+9RVAO/9lF4UtERKSAZf7JkpMWh2GYYSw9nf27M9i3K4P00ymkn0kl7Uwa6clppJ9NJ+1MGobd4bJbizXzMBYiQ87SpEICvkaa8zJR5+JwnO8G/fvz2NlAvtlUkW0HQ8hIc2BPs5OR5iAj3YE9zUFGhoE93cAwDDAMDAdgOP79aWB3WMjARprDl3TD54LFRmmfRF4rP5mavn86Q6bzp8NhPgohMND5My0gmMe2PMAHf7fCblz8Es38UoIkKrCLGHY7lygOcpQy7CaGXVRw/jxJPtygJ4AZsu9mNo/zOg1Zm+2Yk4TyHg/yNo9yiKh8qcOPVEJIJJgkSnDa5acNOzupwlZq5LgjbsVONPvoef02XlrbLl9qzo1CE75mzZpFr169mDJlCrGxsUyYMIHZs2ezY8cOymbzAJRffvmF5s2bM2bMGG677TZmzJjBq6++yrp166hVqxYAr776KmPGjOGTTz6hQoUKPPfcc2zatImtW7cSEBAAQLt27Th06BDvvfce6enp9O3bl0aNGjFjxowc1a3wJSIiIoVBZkaz28//dL5OzTBD4AV/DWa+NhwGhsOAjAyMDDtGhvnBzNeZXRuH8W/35t/XFgtcE2EnNMTsAmXZeWYwvmBJTIR9B6ykplvN+gwrdofFuTgc4Gu1E2BNw9+Shj9mV8ufVPwcKdgNKykZPpxL9yElw4cUuy8p6TbOpdnIMGxk2M39ZNgt5r7tkOGw4mu1429NJ8CWbnbO/l38ScVuh7OpNpJTfTibauNsms+/723YLT5YfH2w+v77088Hi58PFh8fDIdBxtk07OfSyDiX7rIYDrNLaLGA1XL+tQUDi9WCxdeGxccHi4/t/OJrwzAspKcZLktaGqSnG9gzwGI4nL/b868dlA04Tb9aqykffPKCf13496evrzkrTeYSFkZqUBgzV17DitXFsJ9NxXEuBcfZVBwpqTjOpZk/0zJcuqRw/h9DfKx2IgJPExWURGSJ00SVOENUSDKRIWcJDUwzP/ffLnrmCWkYGBl29p8OYcuJSLaejGTrqSh2nwkjPCCJCiWOUaHEMWJKHKNC8AmiS5zC1+aAFi2gZ898+e9ObhSa8BUbG0ujRo2Y9O/dow6Hg+joaAYPHsxTTz2VZXzXrl1JTk5m/vz5znU33HAD9erVY8qUKRiGQVRUFI8//jjDhw8HIDExkfDwcKZNm0a3bt3Ytm0bNWrUYM2aNTRs2BCARYsW0b59e/bv309U1OUTv8KXiIiIiIhAzrNB7qf9yUNpaWmsXbuWuLg45zqr1UpcXByrVq3K9jOrVq1yGQ/Qpk0b5/hdu3aRkJDgMiYkJITY2FjnmFWrVhEaGuoMXgBxcXFYrVZ+u/BJhRdITU0lKSnJZREREREREckpt4avY8eOYbfbCQ8Pd1kfHh5OQkJCtp9JSEi45PjMn5cb899LGn18fChVqtRFjztmzBhCQkKcS3R0dA6/pYiIiIiIiJvDV2EyYsQIEhMTncu+ffvcXZKIiIiIiBQibg1fpUuXxmazcfjwYZf1hw8fJiIiItvPREREXHJ85s/LjTly5IjL9oyMDE6cOHHR4/r7+xMcHOyyiIiIiIiI5JRbw5efnx8NGjRgyZIlznUOh4MlS5bQpEmTbD/TpEkTl/EA8fHxzvEVKlQgIiLCZUxSUhK//fabc0yTJk04deoUa9een25z6dKlOBwOYmNj8+z7iYiIiIiIZMq/pwDm0LBhw+jduzcNGzakcePGTJgwgeTkZPr27QtAr169uOaaaxgzZgwAjz32GC1atOD111+nQ4cOfPHFF/z++++8//77gPlMjiFDhvDSSy9RpUoV51TzUVFRdOrUCYDq1avTtm1bBgwYwJQpU0hPT2fQoEF069YtRzMdioiIiIiI5Jbbw1fXrl05evQoI0eOJCEhgXr16rFo0SLnhBl79+7Faj3foLvxxhuZMWMGzz77LE8//TRVqlRh7ty5zmd8ATzxxBMkJyfzwAMPcOrUKW666SYWLVrkfMYXwPTp0xk0aBC33HKL8yHLb7/9dsF9cRERERERKVLc/pyvwkrP+RIRERERESgkz/kSEREREREpKhS+RERERERECoDCl4iIiIiISAFQ+BIRERERESkACl8iIiIiIiIFQOFLRERERESkACh8iYiIiIiIFACFLxERERERkQKg8CUiIiIiIlIAFL5EREREREQKgI+7CyisDMMAICkpyc2ViIiIiIiIO2VmgsyMcDEKX1fo9OnTAERHR7u5EhERERER8QSnT58mJCTkotstxuXimWTL4XBw8OBBSpQogcViyffjJSUlER0dzb59+wgODs7340nhp3NGckvnjOSWzhnJLZ0zkluF5ZwxDIPTp08TFRWF1XrxO7vU+bpCVquVa6+9tsCPGxwc7NEnnngenTOSWzpnJLd0zkhu6ZyR3CoM58ylOl6ZNOGGiIiIiIhIAVD4EhERERERKQAKX4WEv78/o0aNwt/f392lSCGhc0ZyS+eM5JbOGcktnTOSW952zmjCDRERERERkQKgzpeIiIiIiEgBUPgSEREREREpAApfIiIiIiIiBUDhS0REREREpAAofBUCkydPJiYmhoCAAGJjY1m9erW7SxIPMWbMGBo1akSJEiUoW7YsnTp1YseOHS5jUlJSGDhwIGFhYQQFBdGlSxcOHz7sporF04wdOxaLxcKQIUOc63TOyH8dOHCAnj17EhYWRrFixahduza///67c7thGIwcOZLIyEiKFStGXFwcO3fudGPF4k52u53nnnuOChUqUKxYMSpVqsSLL77IhXO86Zwp2lauXEnHjh2JiorCYrEwd+5cl+05OT9OnDhBjx49CA4OJjQ0lP79+3PmzJkC/BZXRuHLw82aNYthw4YxatQo1q1bR926dWnTpg1Hjhxxd2niAVasWMHAgQP59ddfiY+PJz09ndatW5OcnOwcM3ToUObNm8fs2bNZsWIFBw8epHPnzm6sWjzFmjVreO+996hTp47Lep0zcqGTJ0/StGlTfH19WbhwIVu3buX111+nZMmSzjGvvfYab7/9NlOmTOG3336jePHitGnThpSUFDdWLu7y6quv8u677zJp0iS2bdvGq6++ymuvvcbEiROdY3TOFG3JycnUrVuXyZMnZ7s9J+dHjx492LJlC/Hx8cyfP5+VK1fywAMPFNRXuHKGeLTGjRsbAwcOdL632+1GVFSUMWbMGDdWJZ7qyJEjBmCsWLHCMAzDOHXqlOHr62vMnj3bOWbbtm0GYKxatcpdZYoHOH36tFGlShUjPj7eaNGihfHYY48ZhqFzRrJ68sknjZtuuumi2x0OhxEREWGMGzfOue7UqVOGv7+/MXPmzIIoUTxMhw4djH79+rms69y5s9GjRw/DMHTOiCvA+Prrr53vc3J+bN261QCMNWvWOMcsXLjQsFgsxoEDBwqs9iuhzpcHS0tLY+3atcTFxTnXWa1W4uLiWLVqlRsrE0+VmJgIQKlSpQBYu3Yt6enpLudQtWrVKFeunM6hIm7gwIF06NDB5dwAnTOS1bfffkvDhg25++67KVu2LPXr1+eDDz5wbt+1axcJCQku50xISAixsbE6Z4qoG2+8kSVLlvDnn38CsGHDBn766SfatWsH6JyRS8vJ+bFq1SpCQ0Np2LChc0xcXBxWq5XffvutwGvODR93FyAXd+zYMex2O+Hh4S7rw8PD2b59u5uqEk/lcDgYMmQITZs2pVatWgAkJCTg5+dHaGioy9jw8HASEhLcUKV4gi+++IJ169axZs2aLNt0zsh//fPPP7z77rsMGzaMp59+mjVr1vDoo4/i5+dH7969nedFdv9fpXOmaHrqqadISkqiWrVq2Gw27HY7L7/8Mj169ADQOSOXlJPzIyEhgbJly7ps9/HxoVSpUh5/Dil8iXiJgQMHsnnzZn766Sd3lyIebN++fTz22GPEx8cTEBDg7nKkEHA4HDRs2JBXXnkFgPr167N582amTJlC79693VydeKIvv/yS6dOnM2PGDGrWrMn69esZMmQIUVFROmekyNNlhx6sdOnS2Gy2LLOMHT58mIiICDdVJZ5o0KBBzJ8/n2XLlnHttdc610dERJCWlsapU6dcxuscKrrWrl3LkSNHuP766/Hx8cHHx4cVK1bw9ttv4+PjQ3h4uM4ZcREZGUmNGjVc1lWvXp29e/cCOM8L/X+VZPq///s/nnrqKbp160bt2rW57777GDp0KGPGjAF0zsil5eT8iIiIyDL5XEZGBidOnPD4c0jhy4P5+fnRoEEDlixZ4lzncDhYsmQJTZo0cWNl4ikMw2DQoEF8/fXXLF26lAoVKrhsb9CgAb6+vi7n0I4dO9i7d6/OoSLqlltuYdOmTaxfv965NGzYkB49ejhf65yRCzVt2jTLIyz+/PNPypcvD0CFChWIiIhwOWeSkpL47bffdM4UUWfPnsVqdf0T02az4XA4AJ0zcmk5OT+aNGnCqVOnWLt2rXPM0qVLcTgcxMbGFnjNueLuGT/k0r744gvD39/fmDZtmrF161bjgf9v795Conj/OI5/Jsx1VzOtNRNBShIzo+hI2+GihFqDSjEiWWL1Rjwk3kSRZRkVdBEWBC0Y6Y2SYHQw0aLjRYJZZCpk0kVJoNIRMjNvfP4XwfLbX/HH//9Xu/7y/YKBnXmenfnO8Fzsh5lntqDAxMTEmKGhoVCXhkmgqKjIzJw50zx48MAMDg76l69fv/r7FBYWmqSkJHPv3j3z5MkT43K5jMvlCmHVmGz++rZDYxgzCNTR0WHCwsLMyZMnzcuXL019fb1xOBymrq7O3+fUqVMmJibGXL9+3XR3d5sdO3aY+fPnm9HR0RBWjlDxer0mMTHRNDc3m1evXpkrV64Yp9Np9u/f7+/DmJnahoeHTWdnp+ns7DSSTFVVlens7DT9/f3GmImND7fbbZYtW2YePXpkHj58aFJSUkxubm6oTmnCCF//AufOnTNJSUkmPDzcrF692rS3t4e6JEwSkn661NbW+vuMjo6a4uJiExsbaxwOh8nOzjaDg4OhKxqTzt/DF2MGf3fjxg2zePFiY7PZzMKFC011dXVA+/j4uKmoqDDx8fHGZrOZjIwM09fXF6JqEWqfP382ZWVlJikpyURERJjk5GRz6NAhMzY25u/DmJna7t+//9PfL16v1xgzsfHx4cMHk5uba6Kiokx0dLTJz883w8PDITib/41lzF/+bhwAAAAA8Fsw5wsAAAAAgoDwBQAAAABBQPgCAAAAgCAgfAEAAABAEBC+AAAAACAICF8AAAAAEASELwAAAAAIAsIXAAAAAAQB4QsAgCCwLEvXrl0LdRkAgBAifAEA/nh5eXmyLOuHxe12h7o0AMAUEhbqAgAACAa3263a2tqAbTabLUTVAACmIu58AQCmBJvNprlz5wYssbGxkr4/Eujz+ZSZmSm73a7k5GRdvnw54Ps9PT3atGmT7Ha7Zs+erYKCAn358iWgT01NjdLT02Wz2ZSQkKC9e/cGtL9//17Z2dlyOBxKSUlRU1OTv+3Tp0/yeDyKi4uT3W5XSkrKD2ERAPDvRvgCAEBSRUWFcnJy1NXVJY/Ho927d6u3t1eSNDIyoi1btig2NlaPHz9WY2Oj7ty5ExCufD6fSkpKVFBQoJ6eHjU1NWnBggUBxzh27Jh27dql7u5ubd26VR6PRx8/fvQf//nz52ptbVVvb698Pp+cTmfwLgAA4LezjDEm1EUAAPA75eXlqa6uThEREQHby8vLVV5eLsuyVFhYKJ/P529bs2aNli9frvPnz+vChQs6cOCA3rx5o8jISElSS0uLtm3bpoGBAcXHxysxMVH5+fk6ceLET2uwLEuHDx/W8ePHJX0PdFFRUWptbZXb7db27dvldDpVU1Pzm64CACDUmPMFAJgSNm7cGBCuJGnWrFn+zy6XK6DN5XLp2bNnkqTe3l4tXbrUH7wkad26dRofH1dfX58sy9LAwIAyMjL+aw1Llizxf46MjFR0dLTevn0rSSoqKlJOTo6ePn2qzZs3KysrS2vXrv2/zhUAMDkRvgAAU0JkZOQPjwH+Kna7fUL9pk+fHrBuWZbGx8clSZmZmerv71dLS4tu376tjIwMlZSU6PTp07+8XgBAaDDnCwAASe3t7T+sp6WlSZLS0tLU1dWlkZERf3tbW5umTZum1NRUzZgxQ/PmzdPdu3f/UQ1xcXHyer2qq6vT2bNnVV1d/Y/2BwCYXLjzBQCYEsbGxjQ0NBSwLSwszP9Si8bGRq1cuVLr169XfX29Ojo6dPHiRUmSx+PR0aNH5fV6VVlZqXfv3qm0tFR79uxRfHy8JKmyslKFhYWaM2eOMjMzNTw8rLa2NpWWlk6oviNHjmjFihVKT0/X2NiYmpub/eEPAPBnIHwBAKaEmzdvKiEhIWBbamqqXrx4Ien7mwgbGhpUXFyshIQEXbp0SYsWLZIkORwO3bp1S2VlZVq1apUcDodycnJUVVXl35fX69W3b9905swZ7du3T06nUzt37pxwfeHh4Tp48KBev34tu92uDRs2qKGh4RecOQBgsuBthwCAKc+yLF29elVZWVmhLgUA8AdjzhcAAAAABAHhCwAAAACCgDlfAIApjyfwAQDBwJ0vAAAAAAgCwhcAAAAABAHhCwAAAACCgPAFAAAAAEFA+AIAAACAICB8AQAAAEAQEL4AAAAAIAgIXwAAAAAQBP8BfdJyyCXMqFcAAAAASUVORK5CYII="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mae = history.history['loss']\n",
    "val_mae = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(mae) + 1)\n",
    "\n",
    "# MAE Diagramm\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, mae, 'r', label='Training MSE')\n",
    "plt.plot(epochs, val_mae, 'b', label='Validation MSE')\n",
    "plt.title('Training and Validation MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.savefig('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Bilder Diplomarbeit/MSE_NeuroNetz/MSE_NeuroNetz_D2_2')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:06:06.730178300Z",
     "start_time": "2024-03-15T10:06:06.391394200Z"
    }
   },
   "id": "3688dd7102e95baf"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9f6f672a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T10:06:06.730178300Z",
     "start_time": "2024-03-15T10:06:06.727488100Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Werte die kleiner sind: 4985\n"
     ]
    },
    {
     "data": {
      "text/plain": "            Echt  Vorhergesagt  X-Koordinate  Y-Koordinate  Differenz\n2493  801.801208        836.38         0.992         0.900 -34.578792\n2316  722.173462        755.11         0.992         0.930 -32.936538\n2187  761.990662        793.93         0.976         0.915 -31.939338\n2696  788.550903        820.06         0.976         0.905 -31.509097\n4855  695.624695        726.52         1.000         0.940 -30.895305\n...          ...           ...           ...           ...        ...\n2686  689.296997        668.83         0.952         0.000  20.466997\n2746  682.011230        661.52         0.856         0.000  20.491230\n2248  593.890991        573.33         0.984         1.000  20.560991\n1499  686.564087        665.99         0.920         0.000  20.574087\n1631  684.248901        663.16         0.888         0.000  21.088901\n\n[5066 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Echt</th>\n      <th>Vorhergesagt</th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Differenz</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2493</th>\n      <td>801.801208</td>\n      <td>836.38</td>\n      <td>0.992</td>\n      <td>0.900</td>\n      <td>-34.578792</td>\n    </tr>\n    <tr>\n      <th>2316</th>\n      <td>722.173462</td>\n      <td>755.11</td>\n      <td>0.992</td>\n      <td>0.930</td>\n      <td>-32.936538</td>\n    </tr>\n    <tr>\n      <th>2187</th>\n      <td>761.990662</td>\n      <td>793.93</td>\n      <td>0.976</td>\n      <td>0.915</td>\n      <td>-31.939338</td>\n    </tr>\n    <tr>\n      <th>2696</th>\n      <td>788.550903</td>\n      <td>820.06</td>\n      <td>0.976</td>\n      <td>0.905</td>\n      <td>-31.509097</td>\n    </tr>\n    <tr>\n      <th>4855</th>\n      <td>695.624695</td>\n      <td>726.52</td>\n      <td>1.000</td>\n      <td>0.940</td>\n      <td>-30.895305</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2686</th>\n      <td>689.296997</td>\n      <td>668.83</td>\n      <td>0.952</td>\n      <td>0.000</td>\n      <td>20.466997</td>\n    </tr>\n    <tr>\n      <th>2746</th>\n      <td>682.011230</td>\n      <td>661.52</td>\n      <td>0.856</td>\n      <td>0.000</td>\n      <td>20.491230</td>\n    </tr>\n    <tr>\n      <th>2248</th>\n      <td>593.890991</td>\n      <td>573.33</td>\n      <td>0.984</td>\n      <td>1.000</td>\n      <td>20.560991</td>\n    </tr>\n    <tr>\n      <th>1499</th>\n      <td>686.564087</td>\n      <td>665.99</td>\n      <td>0.920</td>\n      <td>0.000</td>\n      <td>20.574087</td>\n    </tr>\n    <tr>\n      <th>1631</th>\n      <td>684.248901</td>\n      <td>663.16</td>\n      <td>0.888</td>\n      <td>0.000</td>\n      <td>21.088901</td>\n    </tr>\n  </tbody>\n</table>\n<p>5066 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame({'Echt': [val[0] for val in list1], 'Vorhergesagt': [val[0] for val in list2]})\n",
    "df_result['X-Koordinate'] = X_test_scaled[:, 0]\n",
    "df_result['Y-Koordinate'] = X_test_scaled[:, 1]\n",
    "\n",
    "df_result['Differenz'] = df_result['Echt'] - df_result['Vorhergesagt']\n",
    "df_result['Differenz'].sort_values()\n",
    "sorted_df = df_result.sort_values(by= 'Differenz')\n",
    "Anzahl_Punkte = (sorted_df['Differenz'] > -10).sum()\n",
    "print(\"Anzahl der Werte die kleiner sind:\", Anzahl_Punkte)\n",
    "\n",
    "sorted_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:06:06.749329Z",
     "start_time": "2024-03-15T10:06:06.730178300Z"
    }
   },
   "id": "6a9d8a95f5e95b9"
  },
  {
   "cell_type": "markdown",
   "id": "553df6fa",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1dca80c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T10:06:06.749845900Z",
     "start_time": "2024-03-15T10:06:06.749329Z"
    }
   },
   "outputs": [],
   "source": [
    "# def build_model(learning_rate=0.001, activation='relu', regularization=0.0001, dropout_rate=0.0):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(264, activation=activation, input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(168, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(88, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(264, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(200, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     # model.add(Dense(192, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     # model.add(Dropout(dropout_rate))\n",
    "#     # \n",
    "#     # model.add(Dense(32, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     # model.add(Dropout(dropout_rate))\n",
    "#     # \n",
    "#     # model.add(Dense(448, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     # model.add(Dropout(dropout_rate))    \n",
    "#     # \n",
    "#     # model.add(Dense(64, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     # model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mae'])\n",
    "#     return model\n",
    "# \n",
    "# # Verwenden Sie eine Funktion, um das Modell zu instanziieren, für scikit-learn Wrapper\n",
    "# model = KerasRegressor(model=build_model, verbose=2)\n",
    "# \n",
    "# # Anpassung der Parameter im param_grid\n",
    "# param_grid = {\n",
    "#     'model__learning_rate': [0.01, 0.001, 0.0001],\n",
    "#     'model__regularization': [0.001, 0.0001],\n",
    "#     'fit__batch_size': [50, 100, 150, 200],\n",
    "#     'fit__epochs': [50],\n",
    "#     'model__dropout_rate' : [0.0, 0.1, 0.2]\n",
    "# }\n",
    "# \n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=2)\n",
    "# # Hinweis: Stellen Sie sicher, dass Ihre Daten (X_train_scaled, y_train_scaled) korrekt definiert sind\n",
    "# grid_result = grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "# # Beste Parameter und Score ausgeben\n",
    "# print(\"Beste Parameter:\", grid_search.best_params_)\n",
    "# print(\"Beste Genauigkeit:\", grid_search.best_score_)\n",
    "# \n",
    "# with open(\"Gridsearch_D2_1.txt\", \"w\") as f:\n",
    "#     f.write(f\"Beste Parameter: {grid_search.best_params_}\\n\")\n",
    "#     f.write(f\"Beste Genauigkeit: {grid_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Search Architektur"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "315c4a978449b8a5"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "# # Funktion zum Erstellen des Modells\n",
    "# def build_model(hp):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(hp.Int('input_units', min_value=8, max_value=328, step=16), input_shape=(2,), activation='relu'))\n",
    "#     for i in range(hp.Int('n_layers', 1, 10)):\n",
    "#         model.add(Dense(hp.Int(f'units_{i}', min_value=8, max_value=328, step=16), activation='relu'))\n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     return model\n",
    "# \n",
    "# # Durchführung der Random Search dreimal\n",
    "# for run in range(1, 4):\n",
    "#     # Anpassen des Verzeichnisses und des Projektnamens für jeden Durchlauf\n",
    "#     directory = 'random_search'\n",
    "#     project_name = f'random_search_D2_{run}'\n",
    "#     \n",
    "#     tuner = RandomSearch(\n",
    "#         build_model,\n",
    "#         objective='val_loss',\n",
    "#         max_trials=100,\n",
    "#         executions_per_trial=1,\n",
    "#         directory=directory,\n",
    "#         project_name=project_name\n",
    "#     )\n",
    "#     \n",
    "#     # Durchführung des Random Search\n",
    "#     tuner.search(X_train_scaled, y_train_scaled, epochs=200, verbose =0, batch_size=50, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "#     \n",
    "#     # Abrufen und Speichern des besten Modells\n",
    "#     best_model = tuner.get_best_models(num_models=1)[0]\n",
    "#     model_path = os.path.join(directory, project_name, 'best_model.h5') \n",
    "#     best_model.save(model_path)\n",
    "#     \n",
    "# \n",
    "#     # Optional: Abrufen und Ausgeben der besten Hyperparameter\n",
    "#     best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "#     \n",
    "#     # Konvertieren der Hyperparameter in ein DataFrame\n",
    "#     df_hyperparameters = pd.DataFrame([best_hyperparameters.values])\n",
    "#     # Speichern des DataFrame als CSV\n",
    "#     df_hyperparameters.to_csv(f'random_search_D2_{run}.csv', index=False)\n",
    "#     \n",
    "#     print(f\"Beste Hyperparameter für Lauf {run}: {best_hyperparameters.values}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:06:06.753891Z",
     "start_time": "2024-03-15T10:06:06.749845900Z"
    }
   },
   "id": "611306fcc5b8bde8"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:06:06.763207300Z",
     "start_time": "2024-03-15T10:06:06.753891Z"
    }
   },
   "id": "35e7cad28493cba6"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:06:06.763207300Z",
     "start_time": "2024-03-15T10:06:06.756517800Z"
    }
   },
   "id": "d4cb47043e0762a5"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:06:06.833609300Z",
     "start_time": "2024-03-15T10:06:06.758875900Z"
    }
   },
   "id": "d26a7160fe0b33a8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
