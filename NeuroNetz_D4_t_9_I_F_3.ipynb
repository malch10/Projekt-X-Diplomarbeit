{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94b0518e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T08:36:12.665366700Z",
     "start_time": "2024-04-02T08:36:04.894505300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense , Dropout\n",
    "from scikeras.wrappers import KerasRegressor \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4ff61b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T08:36:18.725754300Z",
     "start_time": "2024-04-02T08:36:18.628700900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n0             0.0000      -0.00200        100   6000   5000      449.80\n1             0.0000      -0.00192        100   6000   5000      479.76\n2             0.0000      -0.00184        100   6000   5000      506.60\n3             0.0000      -0.00176        100   6000   5000      530.80\n4             0.0000      -0.00168        100   6000   5000      552.15\n...              ...           ...        ...    ...    ...         ...\n351283        0.0024       0.00168        500   9000   5000     1365.50\n351284        0.0024       0.00176        500   9000   5000     1247.20\n351285        0.0024       0.00184        500   9000   5000     1114.10\n351286        0.0024       0.00192        500   9000   5000      983.97\n351287        0.0024       0.00200        500   9000   5000      942.84\n\n[77112 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>449.80</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0000</td>\n      <td>-0.00192</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>479.76</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0000</td>\n      <td>-0.00184</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>506.60</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0000</td>\n      <td>-0.00176</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>530.80</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0000</td>\n      <td>-0.00168</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>552.15</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>351283</th>\n      <td>0.0024</td>\n      <td>0.00168</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1365.50</td>\n    </tr>\n    <tr>\n      <th>351284</th>\n      <td>0.0024</td>\n      <td>0.00176</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1247.20</td>\n    </tr>\n    <tr>\n      <th>351285</th>\n      <td>0.0024</td>\n      <td>0.00184</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1114.10</td>\n    </tr>\n    <tr>\n      <th>351286</th>\n      <td>0.0024</td>\n      <td>0.00192</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>983.97</td>\n    </tr>\n    <tr>\n      <th>351287</th>\n      <td>0.0024</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>942.84</td>\n    </tr>\n  </tbody>\n</table>\n<p>77112 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/TPath_300_finish_data.pkl')\n",
    "data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_ALL_D4_t_9_I_F_PKL.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "966e3c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T08:36:24.342925300Z",
     "start_time": "2024-04-02T08:36:24.211700300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n",
      "131733        0.0000      -0.00200        100   7000   6000      478.13\n",
      "131734        0.0000      -0.00192        100   7000   6000      511.16\n",
      "131735        0.0000      -0.00184        100   7000   6000      541.43\n",
      "131736        0.0000      -0.00176        100   7000   6000      569.14\n",
      "131737        0.0000      -0.00168        100   7000   6000      594.14\n",
      "...              ...           ...        ...    ...    ...         ...\n",
      "175639        0.0024       0.00168        500   7000   6000      942.96\n",
      "175640        0.0024       0.00176        500   7000   6000      865.10\n",
      "175641        0.0024       0.00184        500   7000   6000      786.99\n",
      "175642        0.0024       0.00192        500   7000   6000      708.11\n",
      "175643        0.0024       0.00200        500   7000   6000      690.48\n",
      "\n",
      "[9639 rows x 6 columns]\n",
      "Empty DataFrame\n",
      "Columns: [X-Koordinate, Y-Koordinate, Zeitpunkt, Strom, Kraft, Temperatur]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [X-Koordinate, Y-Koordinate, Zeitpunkt, Strom, Kraft, Temperatur]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/plain": "       X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft\n0           0.00216 -1.280000e-03        400   8000   6000\n1           0.00240 -4.000000e-04        450   7000   5000\n2           0.00060  1.120000e-03        300   6000   6000\n3           0.00012 -8.800000e-04        300   8000   6000\n4           0.00192  4.529900e-18        400   6000   5000\n...             ...           ...        ...    ...    ...\n67468       0.00180 -8.000000e-04        450   7000   9000\n67469       0.00204  1.440000e-03        350   6000   5000\n67470       0.00060 -1.200000e-03        400   8000   7000\n67471       0.00192  1.520000e-03        100   6000   5000\n67472       0.00180  8.800000e-04        350   6000   6000\n\n[67473 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00216</td>\n      <td>-1.280000e-03</td>\n      <td>400</td>\n      <td>8000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00240</td>\n      <td>-4.000000e-04</td>\n      <td>450</td>\n      <td>7000</td>\n      <td>5000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00060</td>\n      <td>1.120000e-03</td>\n      <td>300</td>\n      <td>6000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00012</td>\n      <td>-8.800000e-04</td>\n      <td>300</td>\n      <td>8000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00192</td>\n      <td>4.529900e-18</td>\n      <td>400</td>\n      <td>6000</td>\n      <td>5000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>67468</th>\n      <td>0.00180</td>\n      <td>-8.000000e-04</td>\n      <td>450</td>\n      <td>7000</td>\n      <td>9000</td>\n    </tr>\n    <tr>\n      <th>67469</th>\n      <td>0.00204</td>\n      <td>1.440000e-03</td>\n      <td>350</td>\n      <td>6000</td>\n      <td>5000</td>\n    </tr>\n    <tr>\n      <th>67470</th>\n      <td>0.00060</td>\n      <td>-1.200000e-03</td>\n      <td>400</td>\n      <td>8000</td>\n      <td>7000</td>\n    </tr>\n    <tr>\n      <th>67471</th>\n      <td>0.00192</td>\n      <td>1.520000e-03</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n    </tr>\n    <tr>\n      <th>67472</th>\n      <td>0.00180</td>\n      <td>8.800000e-04</td>\n      <td>350</td>\n      <td>6000</td>\n      <td>6000</td>\n    </tr>\n  </tbody>\n</table>\n<p>67473 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedingung = (data['Kraft'] == 6000) & (data['Strom'] == 7000)\n",
    "df_test = data[bedingung].copy()\n",
    "print(df_test)\n",
    "\n",
    "data_all = data.drop(df_test.index)\n",
    "#print(data_all)\n",
    "print(data_all[(data_all['Kraft'] == 6000) & (data_all['Strom'] == 7000)])\n",
    "\n",
    "print(data_all[(data_all['Kraft'] == 6000) & (data_all['Strom'] == 7000)])\n",
    "df_test_500 = df_test[(df_test['Zeitpunkt'] == 500)]\n",
    "\n",
    "\n",
    "data_all = data_all.sample(frac=1, random_state=42)  # Hier wird 42 als Random State verwendet, um die Ergebnisse reproduzierbar zu machen\n",
    "df_reset = data_all.reset_index(drop=True)\n",
    "df_reset\n",
    "\n",
    "y = df_reset[\"Temperatur\"]\n",
    "# Korrektur: Verwenden Sie den Spaltennamen direkt, ohne Indexierung der columns-Eigenschaft\n",
    "X = df_reset.drop(\"Temperatur\", axis=1)\n",
    "\n",
    "\n",
    "y_2 = df_test_500[\"Temperatur\"]\n",
    "# Korrektur: Verwenden Sie den Spaltennamen direkt, ohne Indexierung der columns-Eigenschaft\n",
    "X_2 = df_test_500.drop(\"Temperatur\", axis=1)\n",
    "X_2 = X_2.reset_index(drop=True)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7fa289a50d87423"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c705edb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T08:36:39.599111600Z",
     "start_time": "2024-04-02T08:36:39.503665300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialisiere einen MinMaxScaler fÃ¼r die Features\n",
    "scaler_features = MinMaxScaler()\n",
    "# Skaliere X_train und X_test\n",
    "X_train_scaled = scaler_features.fit_transform(X)\n",
    "#X_test_scaled = scaler_features.transform(X_test)  # Nutze unterschiedliche Skalierungsparameter\n",
    "X_test_scaled_2 = scaler_features.transform(X_2)\n",
    "# Initialisiere einen SEPARATEN MinMaxScaler fÃ¼r das Ziel, wenn nÃ¶tig\n",
    "scaler_target = MinMaxScaler()\n",
    "# Skaliere y_train und y_test. Beachte, dass y_train.reshape(-1, 1) verwendet wird, da MinMaxScaler \n",
    "# erwartet, dass die Eingaben als 2D-Arrays kommen, und Ziele normalerweise als 1D-Arrays vorliegen.\n",
    "y_train_scaled = scaler_target.fit_transform(y.values.reshape(-1, 1))\n",
    "#y_test_scaled = scaler_target.transform(y_test.values.reshape(-1, 1))\n",
    "y_test_scaled_2 = scaler_target.transform(y_2.values.reshape(-1, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbefe631e495b483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T08:36:43.577072300Z",
     "start_time": "2024-04-02T08:36:43.501858700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.        , 0.        , 1.        , 0.33333333, 0.25      ],\n       [0.        , 0.02      , 1.        , 0.33333333, 0.25      ],\n       [0.        , 0.04      , 1.        , 0.33333333, 0.25      ],\n       ...,\n       [1.        , 0.96      , 1.        , 0.33333333, 0.25      ],\n       [1.        , 0.98      , 1.        , 0.33333333, 0.25      ],\n       [1.        , 1.        , 1.        , 0.33333333, 0.25      ]])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.20401097],\n       [0.24270037],\n       [0.28272435],\n       ...,\n       [0.19284284],\n       [0.15727799],\n       [0.1493291 ]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_scaled_2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:36:45.182109900Z",
     "start_time": "2024-04-02T08:36:45.127095400Z"
    }
   },
   "id": "ce04ce43aac2242f"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "270/270 [==============================] - 4s 7ms/step - loss: 0.0423 - mae: 0.0839 - val_loss: 0.0292 - val_mae: 0.0509\n",
      "Epoch 2/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0267 - mae: 0.0409 - val_loss: 0.0249 - val_mae: 0.0343\n",
      "Epoch 3/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0235 - mae: 0.0295 - val_loss: 0.0225 - val_mae: 0.0262\n",
      "Epoch 4/2000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0216 - mae: 0.0228 - val_loss: 0.0210 - val_mae: 0.0207\n",
      "Epoch 5/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0204 - mae: 0.0186 - val_loss: 0.0202 - val_mae: 0.0208\n",
      "Epoch 6/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0196 - mae: 0.0159 - val_loss: 0.0193 - val_mae: 0.0160\n",
      "Epoch 7/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0189 - mae: 0.0137 - val_loss: 0.0186 - val_mae: 0.0134\n",
      "Epoch 8/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0183 - mae: 0.0123 - val_loss: 0.0181 - val_mae: 0.0130\n",
      "Epoch 9/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0179 - mae: 0.0114 - val_loss: 0.0177 - val_mae: 0.0113\n",
      "Epoch 10/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0175 - mae: 0.0105 - val_loss: 0.0173 - val_mae: 0.0108\n",
      "Epoch 11/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0171 - mae: 0.0103 - val_loss: 0.0169 - val_mae: 0.0102\n",
      "Epoch 12/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0167 - mae: 0.0103 - val_loss: 0.0166 - val_mae: 0.0114\n",
      "Epoch 13/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0164 - mae: 0.0093 - val_loss: 0.0163 - val_mae: 0.0123\n",
      "Epoch 14/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0161 - mae: 0.0094 - val_loss: 0.0160 - val_mae: 0.0127\n",
      "Epoch 15/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0157 - mae: 0.0093 - val_loss: 0.0155 - val_mae: 0.0087\n",
      "Epoch 16/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0154 - mae: 0.0095 - val_loss: 0.0152 - val_mae: 0.0083\n",
      "Epoch 17/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0151 - mae: 0.0084 - val_loss: 0.0151 - val_mae: 0.0127\n",
      "Epoch 18/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0148 - mae: 0.0085 - val_loss: 0.0146 - val_mae: 0.0075\n",
      "Epoch 19/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0145 - mae: 0.0086 - val_loss: 0.0143 - val_mae: 0.0086\n",
      "Epoch 20/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0142 - mae: 0.0088 - val_loss: 0.0140 - val_mae: 0.0076\n",
      "Epoch 21/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0139 - mae: 0.0083 - val_loss: 0.0137 - val_mae: 0.0076\n",
      "Epoch 22/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0136 - mae: 0.0083 - val_loss: 0.0136 - val_mae: 0.0115\n",
      "Epoch 23/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0133 - mae: 0.0084 - val_loss: 0.0131 - val_mae: 0.0070\n",
      "Epoch 24/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0130 - mae: 0.0076 - val_loss: 0.0129 - val_mae: 0.0076\n",
      "Epoch 25/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0128 - mae: 0.0077 - val_loss: 0.0127 - val_mae: 0.0101\n",
      "Epoch 26/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0125 - mae: 0.0084 - val_loss: 0.0124 - val_mae: 0.0096\n",
      "Epoch 27/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0123 - mae: 0.0080 - val_loss: 0.0121 - val_mae: 0.0080\n",
      "Epoch 28/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0120 - mae: 0.0078 - val_loss: 0.0118 - val_mae: 0.0065\n",
      "Epoch 29/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0118 - mae: 0.0076 - val_loss: 0.0123 - val_mae: 0.0186\n",
      "Epoch 30/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0116 - mae: 0.0086 - val_loss: 0.0114 - val_mae: 0.0076\n",
      "Epoch 31/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0113 - mae: 0.0075 - val_loss: 0.0112 - val_mae: 0.0066\n",
      "Epoch 32/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0111 - mae: 0.0068 - val_loss: 0.0109 - val_mae: 0.0061\n",
      "Epoch 33/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0109 - mae: 0.0076 - val_loss: 0.0108 - val_mae: 0.0074\n",
      "Epoch 34/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0106 - mae: 0.0073 - val_loss: 0.0105 - val_mae: 0.0061\n",
      "Epoch 35/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0105 - mae: 0.0078 - val_loss: 0.0103 - val_mae: 0.0061\n",
      "Epoch 36/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0102 - mae: 0.0067 - val_loss: 0.0101 - val_mae: 0.0063\n",
      "Epoch 37/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0101 - mae: 0.0074 - val_loss: 0.0100 - val_mae: 0.0088\n",
      "Epoch 38/2000\n",
      "270/270 [==============================] - 2s 9ms/step - loss: 0.0098 - mae: 0.0066 - val_loss: 0.0098 - val_mae: 0.0068\n",
      "Epoch 39/2000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0097 - mae: 0.0069 - val_loss: 0.0096 - val_mae: 0.0083\n",
      "Epoch 40/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0095 - mae: 0.0072 - val_loss: 0.0094 - val_mae: 0.0077\n",
      "Epoch 41/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0093 - mae: 0.0070 - val_loss: 0.0093 - val_mae: 0.0087\n",
      "Epoch 42/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0091 - mae: 0.0067 - val_loss: 0.0090 - val_mae: 0.0066\n",
      "Epoch 43/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0090 - mae: 0.0068 - val_loss: 0.0089 - val_mae: 0.0053\n",
      "Epoch 44/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0088 - mae: 0.0065 - val_loss: 0.0087 - val_mae: 0.0056\n",
      "Epoch 45/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0086 - mae: 0.0063 - val_loss: 0.0086 - val_mae: 0.0057\n",
      "Epoch 46/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0085 - mae: 0.0068 - val_loss: 0.0084 - val_mae: 0.0066\n",
      "Epoch 47/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0084 - mae: 0.0070 - val_loss: 0.0083 - val_mae: 0.0081\n",
      "Epoch 48/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0082 - mae: 0.0061 - val_loss: 0.0081 - val_mae: 0.0063\n",
      "Epoch 49/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0081 - mae: 0.0061 - val_loss: 0.0080 - val_mae: 0.0053\n",
      "Epoch 50/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0080 - mae: 0.0074 - val_loss: 0.0078 - val_mae: 0.0056\n",
      "Epoch 51/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0078 - mae: 0.0058 - val_loss: 0.0077 - val_mae: 0.0065\n",
      "Epoch 52/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0077 - mae: 0.0059 - val_loss: 0.0076 - val_mae: 0.0067\n",
      "Epoch 53/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0075 - mae: 0.0063 - val_loss: 0.0075 - val_mae: 0.0055\n",
      "Epoch 54/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0074 - mae: 0.0061 - val_loss: 0.0074 - val_mae: 0.0066\n",
      "Epoch 55/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0073 - mae: 0.0063 - val_loss: 0.0073 - val_mae: 0.0067\n",
      "Epoch 56/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0072 - mae: 0.0066 - val_loss: 0.0071 - val_mae: 0.0053\n",
      "Epoch 57/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0071 - mae: 0.0061 - val_loss: 0.0070 - val_mae: 0.0061\n",
      "Epoch 58/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0069 - mae: 0.0056 - val_loss: 0.0069 - val_mae: 0.0054\n",
      "Epoch 59/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0068 - mae: 0.0060 - val_loss: 0.0068 - val_mae: 0.0059\n",
      "Epoch 60/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0068 - mae: 0.0065 - val_loss: 0.0067 - val_mae: 0.0063\n",
      "Epoch 61/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0066 - mae: 0.0053 - val_loss: 0.0066 - val_mae: 0.0052\n",
      "Epoch 62/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0065 - mae: 0.0061 - val_loss: 0.0065 - val_mae: 0.0074\n",
      "Epoch 63/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0064 - mae: 0.0055 - val_loss: 0.0064 - val_mae: 0.0065\n",
      "Epoch 64/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0063 - mae: 0.0057 - val_loss: 0.0063 - val_mae: 0.0057\n",
      "Epoch 65/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0062 - mae: 0.0058 - val_loss: 0.0062 - val_mae: 0.0060\n",
      "Epoch 66/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0061 - mae: 0.0058 - val_loss: 0.0061 - val_mae: 0.0047\n",
      "Epoch 67/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0060 - mae: 0.0055 - val_loss: 0.0060 - val_mae: 0.0047\n",
      "Epoch 68/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0059 - mae: 0.0055 - val_loss: 0.0059 - val_mae: 0.0053\n",
      "Epoch 69/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0059 - mae: 0.0064 - val_loss: 0.0058 - val_mae: 0.0051\n",
      "Epoch 70/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0058 - mae: 0.0053 - val_loss: 0.0057 - val_mae: 0.0047\n",
      "Epoch 71/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0057 - mae: 0.0059 - val_loss: 0.0057 - val_mae: 0.0081\n",
      "Epoch 72/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0056 - mae: 0.0058 - val_loss: 0.0055 - val_mae: 0.0049\n",
      "Epoch 73/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0055 - mae: 0.0053 - val_loss: 0.0055 - val_mae: 0.0059\n",
      "Epoch 74/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0054 - mae: 0.0053 - val_loss: 0.0054 - val_mae: 0.0045\n",
      "Epoch 75/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0053 - mae: 0.0053 - val_loss: 0.0053 - val_mae: 0.0050\n",
      "Epoch 76/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0053 - mae: 0.0056 - val_loss: 0.0052 - val_mae: 0.0065\n",
      "Epoch 77/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0052 - mae: 0.0057 - val_loss: 0.0051 - val_mae: 0.0048\n",
      "Epoch 78/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0051 - mae: 0.0058 - val_loss: 0.0051 - val_mae: 0.0089\n",
      "Epoch 79/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0050 - mae: 0.0055 - val_loss: 0.0050 - val_mae: 0.0046\n",
      "Epoch 80/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0050 - mae: 0.0053 - val_loss: 0.0049 - val_mae: 0.0045\n",
      "Epoch 81/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0049 - mae: 0.0052 - val_loss: 0.0048 - val_mae: 0.0043\n",
      "Epoch 82/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0048 - mae: 0.0050 - val_loss: 0.0048 - val_mae: 0.0058\n",
      "Epoch 83/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0048 - mae: 0.0058 - val_loss: 0.0047 - val_mae: 0.0058\n",
      "Epoch 84/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0047 - mae: 0.0050 - val_loss: 0.0046 - val_mae: 0.0050\n",
      "Epoch 85/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0046 - mae: 0.0054 - val_loss: 0.0046 - val_mae: 0.0048\n",
      "Epoch 86/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0045 - mae: 0.0051 - val_loss: 0.0045 - val_mae: 0.0045\n",
      "Epoch 87/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0045 - mae: 0.0056 - val_loss: 0.0044 - val_mae: 0.0053\n",
      "Epoch 88/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0044 - mae: 0.0052 - val_loss: 0.0044 - val_mae: 0.0042\n",
      "Epoch 89/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0043 - mae: 0.0051 - val_loss: 0.0043 - val_mae: 0.0050\n",
      "Epoch 90/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0043 - mae: 0.0054 - val_loss: 0.0043 - val_mae: 0.0052\n",
      "Epoch 91/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0042 - mae: 0.0053 - val_loss: 0.0042 - val_mae: 0.0047\n",
      "Epoch 92/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0042 - mae: 0.0055 - val_loss: 0.0042 - val_mae: 0.0065\n",
      "Epoch 93/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0041 - mae: 0.0048 - val_loss: 0.0041 - val_mae: 0.0058\n",
      "Epoch 94/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0041 - mae: 0.0052 - val_loss: 0.0040 - val_mae: 0.0048\n",
      "Epoch 95/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0040 - mae: 0.0049 - val_loss: 0.0040 - val_mae: 0.0068\n",
      "Epoch 96/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0039 - mae: 0.0054 - val_loss: 0.0039 - val_mae: 0.0044\n",
      "Epoch 97/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0039 - mae: 0.0051 - val_loss: 0.0039 - val_mae: 0.0064\n",
      "Epoch 98/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0038 - mae: 0.0053 - val_loss: 0.0038 - val_mae: 0.0063\n",
      "Epoch 99/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0038 - mae: 0.0051 - val_loss: 0.0037 - val_mae: 0.0050\n",
      "Epoch 100/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0037 - mae: 0.0050 - val_loss: 0.0037 - val_mae: 0.0049\n",
      "Epoch 101/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0037 - mae: 0.0053 - val_loss: 0.0036 - val_mae: 0.0050\n",
      "Epoch 102/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0036 - mae: 0.0053 - val_loss: 0.0036 - val_mae: 0.0048\n",
      "Epoch 103/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0036 - mae: 0.0052 - val_loss: 0.0035 - val_mae: 0.0044\n",
      "Epoch 104/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0035 - mae: 0.0048 - val_loss: 0.0035 - val_mae: 0.0047\n",
      "Epoch 105/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0035 - mae: 0.0048 - val_loss: 0.0035 - val_mae: 0.0068\n",
      "Epoch 106/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0034 - mae: 0.0051 - val_loss: 0.0034 - val_mae: 0.0052\n",
      "Epoch 107/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0034 - mae: 0.0051 - val_loss: 0.0034 - val_mae: 0.0043\n",
      "Epoch 108/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0034 - mae: 0.0049 - val_loss: 0.0033 - val_mae: 0.0043\n",
      "Epoch 109/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0033 - mae: 0.0052 - val_loss: 0.0033 - val_mae: 0.0043\n",
      "Epoch 110/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0033 - mae: 0.0048 - val_loss: 0.0032 - val_mae: 0.0042\n",
      "Epoch 111/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0032 - mae: 0.0050 - val_loss: 0.0032 - val_mae: 0.0055\n",
      "Epoch 112/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0032 - mae: 0.0052 - val_loss: 0.0032 - val_mae: 0.0054\n",
      "Epoch 113/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0031 - mae: 0.0050 - val_loss: 0.0031 - val_mae: 0.0049\n",
      "Epoch 114/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0031 - mae: 0.0052 - val_loss: 0.0031 - val_mae: 0.0053\n",
      "Epoch 115/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0031 - mae: 0.0051 - val_loss: 0.0030 - val_mae: 0.0046\n",
      "Epoch 116/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0030 - mae: 0.0049 - val_loss: 0.0030 - val_mae: 0.0044\n",
      "Epoch 117/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0030 - mae: 0.0050 - val_loss: 0.0030 - val_mae: 0.0046\n",
      "Epoch 118/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0030 - mae: 0.0050 - val_loss: 0.0029 - val_mae: 0.0049\n",
      "Epoch 119/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0029 - mae: 0.0047 - val_loss: 0.0029 - val_mae: 0.0046\n",
      "Epoch 120/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0029 - mae: 0.0050 - val_loss: 0.0028 - val_mae: 0.0042\n",
      "Epoch 121/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0028 - mae: 0.0047 - val_loss: 0.0028 - val_mae: 0.0043\n",
      "Epoch 122/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0028 - mae: 0.0049 - val_loss: 0.0028 - val_mae: 0.0043\n",
      "Epoch 123/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0028 - mae: 0.0050 - val_loss: 0.0027 - val_mae: 0.0043\n",
      "Epoch 124/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0027 - mae: 0.0047 - val_loss: 0.0027 - val_mae: 0.0048\n",
      "Epoch 125/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0027 - mae: 0.0050 - val_loss: 0.0027 - val_mae: 0.0042\n",
      "Epoch 126/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0027 - mae: 0.0048 - val_loss: 0.0027 - val_mae: 0.0051\n",
      "Epoch 127/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0026 - mae: 0.0048 - val_loss: 0.0026 - val_mae: 0.0046\n",
      "Epoch 128/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0026 - mae: 0.0048 - val_loss: 0.0026 - val_mae: 0.0055\n",
      "Epoch 129/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0026 - mae: 0.0051 - val_loss: 0.0026 - val_mae: 0.0053\n",
      "Epoch 130/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0025 - mae: 0.0050 - val_loss: 0.0025 - val_mae: 0.0040\n",
      "Epoch 131/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0025 - mae: 0.0047 - val_loss: 0.0025 - val_mae: 0.0047\n",
      "Epoch 132/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0025 - mae: 0.0050 - val_loss: 0.0025 - val_mae: 0.0060\n",
      "Epoch 133/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0024 - mae: 0.0046 - val_loss: 0.0024 - val_mae: 0.0045\n",
      "Epoch 134/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0024 - mae: 0.0054 - val_loss: 0.0024 - val_mae: 0.0048\n",
      "Epoch 135/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0024 - mae: 0.0048 - val_loss: 0.0024 - val_mae: 0.0043\n",
      "Epoch 136/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0024 - mae: 0.0046 - val_loss: 0.0024 - val_mae: 0.0052\n",
      "Epoch 137/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0023 - mae: 0.0050 - val_loss: 0.0023 - val_mae: 0.0048\n",
      "Epoch 138/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0023 - mae: 0.0045 - val_loss: 0.0023 - val_mae: 0.0046\n",
      "Epoch 139/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0023 - mae: 0.0049 - val_loss: 0.0023 - val_mae: 0.0049\n",
      "Epoch 140/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0023 - mae: 0.0049 - val_loss: 0.0022 - val_mae: 0.0052\n",
      "Epoch 141/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0022 - mae: 0.0045 - val_loss: 0.0022 - val_mae: 0.0045\n",
      "Epoch 142/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0022 - mae: 0.0047 - val_loss: 0.0022 - val_mae: 0.0046\n",
      "Epoch 143/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0022 - mae: 0.0046 - val_loss: 0.0022 - val_mae: 0.0059\n",
      "Epoch 144/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0022 - mae: 0.0048 - val_loss: 0.0021 - val_mae: 0.0045\n",
      "Epoch 145/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0021 - mae: 0.0046 - val_loss: 0.0021 - val_mae: 0.0045\n",
      "Epoch 146/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0021 - mae: 0.0046 - val_loss: 0.0021 - val_mae: 0.0050\n",
      "Epoch 147/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0021 - mae: 0.0051 - val_loss: 0.0021 - val_mae: 0.0037\n",
      "Epoch 148/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0021 - mae: 0.0044 - val_loss: 0.0020 - val_mae: 0.0043\n",
      "Epoch 149/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0020 - mae: 0.0047 - val_loss: 0.0020 - val_mae: 0.0060\n",
      "Epoch 150/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0020 - mae: 0.0048 - val_loss: 0.0020 - val_mae: 0.0042\n",
      "Epoch 151/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0020 - mae: 0.0046 - val_loss: 0.0020 - val_mae: 0.0039\n",
      "Epoch 152/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0020 - mae: 0.0045 - val_loss: 0.0020 - val_mae: 0.0054\n",
      "Epoch 153/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0019 - mae: 0.0046 - val_loss: 0.0020 - val_mae: 0.0068\n",
      "Epoch 154/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0019 - mae: 0.0045 - val_loss: 0.0019 - val_mae: 0.0043\n",
      "Epoch 155/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0019 - mae: 0.0053 - val_loss: 0.0019 - val_mae: 0.0047\n",
      "Epoch 156/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0019 - mae: 0.0048 - val_loss: 0.0019 - val_mae: 0.0045\n",
      "Epoch 157/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0019 - mae: 0.0044 - val_loss: 0.0018 - val_mae: 0.0043\n",
      "Epoch 158/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0018 - mae: 0.0046 - val_loss: 0.0018 - val_mae: 0.0039\n",
      "Epoch 159/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0018 - mae: 0.0045 - val_loss: 0.0018 - val_mae: 0.0045\n",
      "Epoch 160/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0018 - mae: 0.0046 - val_loss: 0.0018 - val_mae: 0.0037\n",
      "Epoch 161/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0018 - mae: 0.0044 - val_loss: 0.0018 - val_mae: 0.0040\n",
      "Epoch 162/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0018 - mae: 0.0043 - val_loss: 0.0017 - val_mae: 0.0039\n",
      "Epoch 163/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0018 - mae: 0.0047 - val_loss: 0.0017 - val_mae: 0.0047\n",
      "Epoch 164/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0017 - mae: 0.0045 - val_loss: 0.0017 - val_mae: 0.0040\n",
      "Epoch 165/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0017 - mae: 0.0044 - val_loss: 0.0017 - val_mae: 0.0046\n",
      "Epoch 166/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0017 - mae: 0.0044 - val_loss: 0.0017 - val_mae: 0.0048\n",
      "Epoch 167/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0017 - mae: 0.0047 - val_loss: 0.0017 - val_mae: 0.0047\n",
      "Epoch 168/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0017 - mae: 0.0047 - val_loss: 0.0016 - val_mae: 0.0038\n",
      "Epoch 169/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0016 - mae: 0.0046 - val_loss: 0.0016 - val_mae: 0.0054\n",
      "Epoch 170/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0058\n",
      "Epoch 171/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0016 - mae: 0.0045 - val_loss: 0.0016 - val_mae: 0.0048\n",
      "Epoch 172/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0016 - mae: 0.0045 - val_loss: 0.0016 - val_mae: 0.0060\n",
      "Epoch 173/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0016 - mae: 0.0045 - val_loss: 0.0016 - val_mae: 0.0037\n",
      "Epoch 174/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0046\n",
      "Epoch 175/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0040\n",
      "Epoch 176/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0016 - val_mae: 0.0083\n",
      "Epoch 177/2000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0040\n",
      "Epoch 178/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 0.0015 - val_mae: 0.0045\n",
      "Epoch 179/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0015 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0045\n",
      "Epoch 180/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0045\n",
      "Epoch 181/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0015 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0043\n",
      "Epoch 182/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0035\n",
      "Epoch 183/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0038\n",
      "Epoch 184/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0072\n",
      "Epoch 185/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0038\n",
      "Epoch 186/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0041\n",
      "Epoch 187/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0037\n",
      "Epoch 188/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0041\n",
      "Epoch 189/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0046 - val_loss: 0.0013 - val_mae: 0.0039\n",
      "Epoch 190/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0048 - val_loss: 0.0013 - val_mae: 0.0041\n",
      "Epoch 191/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0060\n",
      "Epoch 192/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0042\n",
      "Epoch 193/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0040\n",
      "Epoch 194/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0047\n",
      "Epoch 195/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0053\n",
      "Epoch 196/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0013 - mae: 0.0047 - val_loss: 0.0013 - val_mae: 0.0070\n",
      "Epoch 197/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0051\n",
      "Epoch 198/2000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0012 - mae: 0.0048 - val_loss: 0.0012 - val_mae: 0.0038\n",
      "Epoch 199/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0047\n",
      "Epoch 200/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0045 - val_loss: 0.0012 - val_mae: 0.0040\n",
      "Epoch 201/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0042 - val_loss: 0.0012 - val_mae: 0.0041\n",
      "Epoch 202/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0046 - val_loss: 0.0012 - val_mae: 0.0039\n",
      "Epoch 203/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0044 - val_loss: 0.0012 - val_mae: 0.0037\n",
      "Epoch 204/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0039\n",
      "Epoch 205/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0046 - val_loss: 0.0012 - val_mae: 0.0045\n",
      "Epoch 206/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0044 - val_loss: 0.0012 - val_mae: 0.0058\n",
      "Epoch 207/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0044 - val_loss: 0.0011 - val_mae: 0.0040\n",
      "Epoch 208/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0045 - val_loss: 0.0011 - val_mae: 0.0039\n",
      "Epoch 209/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0044 - val_loss: 0.0011 - val_mae: 0.0054\n",
      "Epoch 210/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0044 - val_loss: 0.0011 - val_mae: 0.0043\n",
      "Epoch 211/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0037\n",
      "Epoch 212/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0046 - val_loss: 0.0011 - val_mae: 0.0045\n",
      "Epoch 213/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0043\n",
      "Epoch 214/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0049 - val_loss: 0.0011 - val_mae: 0.0036\n",
      "Epoch 215/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0038\n",
      "Epoch 216/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0052\n",
      "Epoch 217/2000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0055\n",
      "Epoch 218/2000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0011 - mae: 0.0047 - val_loss: 0.0011 - val_mae: 0.0046\n",
      "Epoch 219/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0046 - val_loss: 0.0010 - val_mae: 0.0040\n",
      "Epoch 220/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0042 - val_loss: 0.0010 - val_mae: 0.0036\n",
      "Epoch 221/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0040 - val_loss: 0.0010 - val_mae: 0.0037\n",
      "Epoch 222/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0042 - val_loss: 0.0010 - val_mae: 0.0050\n",
      "Epoch 223/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0046 - val_loss: 0.0010 - val_mae: 0.0045\n",
      "Epoch 224/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0042 - val_loss: 0.0010 - val_mae: 0.0051\n",
      "Epoch 225/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.9632e-04 - mae: 0.0043 - val_loss: 0.0010 - val_mae: 0.0054\n",
      "Epoch 226/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.8903e-04 - mae: 0.0043 - val_loss: 9.7470e-04 - val_mae: 0.0035\n",
      "Epoch 227/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.8548e-04 - mae: 0.0045 - val_loss: 9.6881e-04 - val_mae: 0.0037\n",
      "Epoch 228/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.7462e-04 - mae: 0.0043 - val_loss: 9.8820e-04 - val_mae: 0.0057\n",
      "Epoch 229/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.6610e-04 - mae: 0.0042 - val_loss: 9.7297e-04 - val_mae: 0.0053\n",
      "Epoch 230/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.5943e-04 - mae: 0.0042 - val_loss: 9.7466e-04 - val_mae: 0.0056\n",
      "Epoch 231/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.5183e-04 - mae: 0.0042 - val_loss: 9.4358e-04 - val_mae: 0.0040\n",
      "Epoch 232/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.4230e-04 - mae: 0.0040 - val_loss: 9.3587e-04 - val_mae: 0.0039\n",
      "Epoch 233/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.3923e-04 - mae: 0.0043 - val_loss: 9.4603e-04 - val_mae: 0.0054\n",
      "Epoch 234/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.3098e-04 - mae: 0.0042 - val_loss: 9.1665e-04 - val_mae: 0.0034\n",
      "Epoch 235/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.2687e-04 - mae: 0.0044 - val_loss: 9.2051e-04 - val_mae: 0.0043\n",
      "Epoch 236/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.1840e-04 - mae: 0.0043 - val_loss: 9.0375e-04 - val_mae: 0.0034\n",
      "Epoch 237/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.1135e-04 - mae: 0.0042 - val_loss: 9.0210e-04 - val_mae: 0.0038\n",
      "Epoch 238/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.0324e-04 - mae: 0.0041 - val_loss: 8.9196e-04 - val_mae: 0.0036\n",
      "Epoch 239/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.0040e-04 - mae: 0.0044 - val_loss: 8.9228e-04 - val_mae: 0.0040\n",
      "Epoch 240/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.9230e-04 - mae: 0.0042 - val_loss: 8.7896e-04 - val_mae: 0.0036\n",
      "Epoch 241/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.8492e-04 - mae: 0.0042 - val_loss: 8.7687e-04 - val_mae: 0.0040\n",
      "Epoch 242/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.8406e-04 - mae: 0.0044 - val_loss: 8.7145e-04 - val_mae: 0.0040\n",
      "Epoch 243/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.7476e-04 - mae: 0.0043 - val_loss: 8.6790e-04 - val_mae: 0.0043\n",
      "Epoch 244/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.6500e-04 - mae: 0.0040 - val_loss: 8.5628e-04 - val_mae: 0.0036\n",
      "Epoch 245/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.6048e-04 - mae: 0.0041 - val_loss: 8.5134e-04 - val_mae: 0.0037\n",
      "Epoch 246/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.5850e-04 - mae: 0.0044 - val_loss: 8.5890e-04 - val_mae: 0.0049\n",
      "Epoch 247/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.5127e-04 - mae: 0.0042 - val_loss: 8.4020e-04 - val_mae: 0.0038\n",
      "Epoch 248/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.4526e-04 - mae: 0.0042 - val_loss: 8.3348e-04 - val_mae: 0.0036\n",
      "Epoch 249/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.3700e-04 - mae: 0.0040 - val_loss: 8.3953e-04 - val_mae: 0.0047\n",
      "Epoch 250/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.3439e-04 - mae: 0.0042 - val_loss: 8.3744e-04 - val_mae: 0.0047\n",
      "Epoch 251/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.2526e-04 - mae: 0.0040 - val_loss: 8.2051e-04 - val_mae: 0.0039\n",
      "Epoch 252/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.2136e-04 - mae: 0.0041 - val_loss: 8.1892e-04 - val_mae: 0.0043\n",
      "Epoch 253/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.1861e-04 - mae: 0.0043 - val_loss: 8.0879e-04 - val_mae: 0.0038\n",
      "Epoch 254/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.1119e-04 - mae: 0.0041 - val_loss: 7.9736e-04 - val_mae: 0.0034\n",
      "Epoch 255/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.0445e-04 - mae: 0.0040 - val_loss: 7.9636e-04 - val_mae: 0.0037\n",
      "Epoch 256/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.0011e-04 - mae: 0.0041 - val_loss: 8.0820e-04 - val_mae: 0.0053\n",
      "Epoch 257/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.9529e-04 - mae: 0.0041 - val_loss: 7.9180e-04 - val_mae: 0.0042\n",
      "Epoch 258/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.8953e-04 - mae: 0.0041 - val_loss: 7.8773e-04 - val_mae: 0.0044\n",
      "Epoch 259/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.9161e-04 - mae: 0.0046 - val_loss: 8.0557e-04 - val_mae: 0.0054\n",
      "Epoch 260/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.7881e-04 - mae: 0.0040 - val_loss: 7.7426e-04 - val_mae: 0.0039\n",
      "Epoch 261/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.7295e-04 - mae: 0.0039 - val_loss: 7.6541e-04 - val_mae: 0.0036\n",
      "Epoch 262/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.7058e-04 - mae: 0.0041 - val_loss: 7.6767e-04 - val_mae: 0.0043\n",
      "Epoch 263/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.6521e-04 - mae: 0.0041 - val_loss: 7.6570e-04 - val_mae: 0.0046\n",
      "Epoch 264/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.5986e-04 - mae: 0.0040 - val_loss: 7.5718e-04 - val_mae: 0.0042\n",
      "Epoch 265/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.5550e-04 - mae: 0.0040 - val_loss: 7.7143e-04 - val_mae: 0.0057\n",
      "Epoch 266/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.5509e-04 - mae: 0.0044 - val_loss: 7.4152e-04 - val_mae: 0.0036\n",
      "Epoch 267/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.4733e-04 - mae: 0.0041 - val_loss: 7.3583e-04 - val_mae: 0.0035\n",
      "Epoch 268/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.4026e-04 - mae: 0.0039 - val_loss: 7.3560e-04 - val_mae: 0.0038\n",
      "Epoch 269/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.3704e-04 - mae: 0.0040 - val_loss: 7.3381e-04 - val_mae: 0.0042\n",
      "Epoch 270/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.3191e-04 - mae: 0.0040 - val_loss: 7.2649e-04 - val_mae: 0.0039\n",
      "Epoch 271/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.2992e-04 - mae: 0.0041 - val_loss: 7.2104e-04 - val_mae: 0.0037\n",
      "Epoch 272/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.2197e-04 - mae: 0.0039 - val_loss: 7.1344e-04 - val_mae: 0.0035\n",
      "Epoch 273/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.2243e-04 - mae: 0.0043 - val_loss: 7.7182e-04 - val_mae: 0.0080\n",
      "Epoch 274/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.2083e-04 - mae: 0.0044 - val_loss: 7.1083e-04 - val_mae: 0.0040\n",
      "Epoch 275/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.1165e-04 - mae: 0.0041 - val_loss: 6.9869e-04 - val_mae: 0.0031\n",
      "Epoch 276/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.0657e-04 - mae: 0.0040 - val_loss: 6.9704e-04 - val_mae: 0.0034\n",
      "Epoch 277/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.0329e-04 - mae: 0.0040 - val_loss: 6.9489e-04 - val_mae: 0.0036\n",
      "Epoch 278/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.0331e-04 - mae: 0.0042 - val_loss: 7.1536e-04 - val_mae: 0.0058\n",
      "Epoch 279/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.9375e-04 - mae: 0.0039 - val_loss: 6.8704e-04 - val_mae: 0.0036\n",
      "Epoch 280/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.9159e-04 - mae: 0.0041 - val_loss: 6.8265e-04 - val_mae: 0.0036\n",
      "Epoch 281/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.9005e-04 - mae: 0.0041 - val_loss: 6.7772e-04 - val_mae: 0.0035\n",
      "Epoch 282/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.8263e-04 - mae: 0.0039 - val_loss: 6.7383e-04 - val_mae: 0.0034\n",
      "Epoch 283/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.7927e-04 - mae: 0.0039 - val_loss: 6.7476e-04 - val_mae: 0.0038\n",
      "Epoch 284/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.8234e-04 - mae: 0.0045 - val_loss: 7.0832e-04 - val_mae: 0.0064\n",
      "Epoch 285/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.7466e-04 - mae: 0.0042 - val_loss: 6.6533e-04 - val_mae: 0.0037\n",
      "Epoch 286/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.6486e-04 - mae: 0.0037 - val_loss: 6.6214e-04 - val_mae: 0.0038\n",
      "Epoch 287/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.6690e-04 - mae: 0.0041 - val_loss: 6.6099e-04 - val_mae: 0.0040\n",
      "Epoch 288/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.6126e-04 - mae: 0.0040 - val_loss: 6.5299e-04 - val_mae: 0.0036\n",
      "Epoch 289/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.5715e-04 - mae: 0.0039 - val_loss: 6.5275e-04 - val_mae: 0.0038\n",
      "Epoch 290/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.5509e-04 - mae: 0.0040 - val_loss: 6.5254e-04 - val_mae: 0.0040\n",
      "Epoch 291/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.5248e-04 - mae: 0.0041 - val_loss: 6.4181e-04 - val_mae: 0.0035\n",
      "Epoch 292/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.4741e-04 - mae: 0.0040 - val_loss: 6.4186e-04 - val_mae: 0.0037\n",
      "Epoch 293/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.4226e-04 - mae: 0.0039 - val_loss: 6.3700e-04 - val_mae: 0.0036\n",
      "Epoch 294/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.4157e-04 - mae: 0.0041 - val_loss: 6.2914e-04 - val_mae: 0.0033\n",
      "Epoch 295/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.4106e-04 - mae: 0.0043 - val_loss: 6.2806e-04 - val_mae: 0.0035\n",
      "Epoch 296/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.3529e-04 - mae: 0.0041 - val_loss: 6.3512e-04 - val_mae: 0.0044\n",
      "Epoch 297/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.3007e-04 - mae: 0.0039 - val_loss: 6.2159e-04 - val_mae: 0.0035\n",
      "Epoch 298/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.2593e-04 - mae: 0.0039 - val_loss: 6.1489e-04 - val_mae: 0.0031\n",
      "Epoch 299/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.2582e-04 - mae: 0.0041 - val_loss: 6.2171e-04 - val_mae: 0.0041\n",
      "Epoch 300/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.2111e-04 - mae: 0.0040 - val_loss: 6.1642e-04 - val_mae: 0.0039\n",
      "Epoch 301/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.2334e-04 - mae: 0.0044 - val_loss: 6.2242e-04 - val_mae: 0.0046\n",
      "Epoch 302/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.1551e-04 - mae: 0.0040 - val_loss: 6.0996e-04 - val_mae: 0.0039\n",
      "Epoch 303/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.1325e-04 - mae: 0.0041 - val_loss: 6.0881e-04 - val_mae: 0.0040\n",
      "Epoch 304/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.1020e-04 - mae: 0.0041 - val_loss: 6.0254e-04 - val_mae: 0.0037\n",
      "Epoch 305/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.0463e-04 - mae: 0.0038 - val_loss: 6.0498e-04 - val_mae: 0.0041\n",
      "Epoch 306/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.0864e-04 - mae: 0.0043 - val_loss: 5.9445e-04 - val_mae: 0.0034\n",
      "Epoch 307/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.0087e-04 - mae: 0.0040 - val_loss: 5.9331e-04 - val_mae: 0.0037\n",
      "Epoch 308/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.9512e-04 - mae: 0.0038 - val_loss: 5.8711e-04 - val_mae: 0.0033\n",
      "Epoch 309/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.9442e-04 - mae: 0.0039 - val_loss: 5.8730e-04 - val_mae: 0.0036\n",
      "Epoch 310/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.9033e-04 - mae: 0.0039 - val_loss: 6.4055e-04 - val_mae: 0.0074\n",
      "Epoch 311/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.9126e-04 - mae: 0.0041 - val_loss: 5.8783e-04 - val_mae: 0.0042\n",
      "Epoch 312/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.8360e-04 - mae: 0.0037 - val_loss: 5.7546e-04 - val_mae: 0.0032\n",
      "Epoch 313/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.8249e-04 - mae: 0.0039 - val_loss: 5.8381e-04 - val_mae: 0.0044\n",
      "Epoch 314/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.8081e-04 - mae: 0.0040 - val_loss: 6.0064e-04 - val_mae: 0.0055\n",
      "Epoch 315/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.8257e-04 - mae: 0.0043 - val_loss: 5.7242e-04 - val_mae: 0.0037\n",
      "Epoch 316/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.7531e-04 - mae: 0.0039 - val_loss: 5.6620e-04 - val_mae: 0.0034\n",
      "Epoch 317/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.7273e-04 - mae: 0.0040 - val_loss: 5.6248e-04 - val_mae: 0.0033\n",
      "Epoch 318/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.7053e-04 - mae: 0.0040 - val_loss: 5.6022e-04 - val_mae: 0.0033\n",
      "Epoch 319/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.6525e-04 - mae: 0.0037 - val_loss: 5.6704e-04 - val_mae: 0.0043\n",
      "Epoch 320/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.6498e-04 - mae: 0.0040 - val_loss: 5.6232e-04 - val_mae: 0.0041\n",
      "Epoch 321/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.6426e-04 - mae: 0.0041 - val_loss: 5.7758e-04 - val_mae: 0.0055\n",
      "Epoch 322/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.5897e-04 - mae: 0.0039 - val_loss: 5.5138e-04 - val_mae: 0.0035\n",
      "Epoch 323/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.5571e-04 - mae: 0.0038 - val_loss: 5.7678e-04 - val_mae: 0.0055\n",
      "Epoch 324/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.5524e-04 - mae: 0.0040 - val_loss: 5.4967e-04 - val_mae: 0.0037\n",
      "Epoch 325/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.5004e-04 - mae: 0.0038 - val_loss: 5.5687e-04 - val_mae: 0.0046\n",
      "Epoch 326/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.4905e-04 - mae: 0.0039 - val_loss: 5.4012e-04 - val_mae: 0.0034\n",
      "Epoch 327/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.4721e-04 - mae: 0.0039 - val_loss: 5.5803e-04 - val_mae: 0.0052\n",
      "Epoch 328/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.4223e-04 - mae: 0.0037 - val_loss: 5.3638e-04 - val_mae: 0.0034\n",
      "Epoch 329/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.4255e-04 - mae: 0.0040 - val_loss: 5.4988e-04 - val_mae: 0.0049\n",
      "Epoch 330/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.3882e-04 - mae: 0.0039 - val_loss: 5.3816e-04 - val_mae: 0.0041\n",
      "Epoch 331/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.3679e-04 - mae: 0.0039 - val_loss: 5.4952e-04 - val_mae: 0.0052\n",
      "Epoch 332/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.3676e-04 - mae: 0.0041 - val_loss: 5.2954e-04 - val_mae: 0.0036\n",
      "Epoch 333/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.3160e-04 - mae: 0.0038 - val_loss: 5.3504e-04 - val_mae: 0.0042\n",
      "Epoch 334/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.3171e-04 - mae: 0.0040 - val_loss: 5.2208e-04 - val_mae: 0.0034\n",
      "Epoch 335/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.2651e-04 - mae: 0.0038 - val_loss: 5.2065e-04 - val_mae: 0.0035\n",
      "Epoch 336/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.2614e-04 - mae: 0.0040 - val_loss: 5.2122e-04 - val_mae: 0.0038\n",
      "Epoch 337/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.2366e-04 - mae: 0.0039 - val_loss: 5.7032e-04 - val_mae: 0.0075\n",
      "Epoch 338/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.2327e-04 - mae: 0.0040 - val_loss: 5.1409e-04 - val_mae: 0.0035\n",
      "Epoch 339/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.1580e-04 - mae: 0.0036 - val_loss: 5.1299e-04 - val_mae: 0.0035\n",
      "Epoch 340/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.1499e-04 - mae: 0.0037 - val_loss: 5.1121e-04 - val_mae: 0.0038\n",
      "Epoch 341/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.1705e-04 - mae: 0.0041 - val_loss: 5.2164e-04 - val_mae: 0.0048\n",
      "Epoch 342/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.1273e-04 - mae: 0.0039 - val_loss: 5.0627e-04 - val_mae: 0.0036\n",
      "Epoch 343/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.1390e-04 - mae: 0.0041 - val_loss: 5.0529e-04 - val_mae: 0.0036\n",
      "Epoch 344/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.1030e-04 - mae: 0.0040 - val_loss: 5.1191e-04 - val_mae: 0.0042\n",
      "Epoch 345/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.0389e-04 - mae: 0.0036 - val_loss: 5.0589e-04 - val_mae: 0.0042\n",
      "Epoch 346/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.0716e-04 - mae: 0.0041 - val_loss: 4.9747e-04 - val_mae: 0.0035\n",
      "Epoch 347/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.0696e-04 - mae: 0.0042 - val_loss: 4.9991e-04 - val_mae: 0.0038\n",
      "Epoch 348/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.9945e-04 - mae: 0.0038 - val_loss: 4.9373e-04 - val_mae: 0.0036\n",
      "Epoch 349/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.9759e-04 - mae: 0.0038 - val_loss: 4.9890e-04 - val_mae: 0.0043\n",
      "Epoch 350/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.9609e-04 - mae: 0.0038 - val_loss: 4.8774e-04 - val_mae: 0.0032\n",
      "Epoch 351/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.9292e-04 - mae: 0.0037 - val_loss: 4.8568e-04 - val_mae: 0.0033\n",
      "Epoch 352/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.9221e-04 - mae: 0.0038 - val_loss: 5.0818e-04 - val_mae: 0.0054\n",
      "Epoch 353/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.9248e-04 - mae: 0.0040 - val_loss: 4.8840e-04 - val_mae: 0.0039\n",
      "Epoch 354/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.8981e-04 - mae: 0.0039 - val_loss: 4.9110e-04 - val_mae: 0.0043\n",
      "Epoch 355/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.9200e-04 - mae: 0.0042 - val_loss: 4.8667e-04 - val_mae: 0.0042\n",
      "Epoch 356/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.8550e-04 - mae: 0.0039 - val_loss: 4.8186e-04 - val_mae: 0.0039\n",
      "Epoch 357/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.8464e-04 - mae: 0.0039 - val_loss: 4.8037e-04 - val_mae: 0.0037\n",
      "Epoch 358/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.8329e-04 - mae: 0.0040 - val_loss: 4.7736e-04 - val_mae: 0.0038\n",
      "Epoch 359/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.7743e-04 - mae: 0.0036 - val_loss: 4.7401e-04 - val_mae: 0.0035\n",
      "Epoch 360/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.7838e-04 - mae: 0.0039 - val_loss: 4.7208e-04 - val_mae: 0.0034\n",
      "Epoch 361/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.7741e-04 - mae: 0.0039 - val_loss: 4.8126e-04 - val_mae: 0.0046\n",
      "Epoch 362/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.8118e-04 - mae: 0.0043 - val_loss: 4.7644e-04 - val_mae: 0.0043\n",
      "Epoch 363/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.7191e-04 - mae: 0.0037 - val_loss: 4.6623e-04 - val_mae: 0.0034\n",
      "Epoch 364/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.7150e-04 - mae: 0.0038 - val_loss: 4.6253e-04 - val_mae: 0.0032\n",
      "Epoch 365/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.7035e-04 - mae: 0.0039 - val_loss: 4.6337e-04 - val_mae: 0.0035\n",
      "Epoch 366/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.6795e-04 - mae: 0.0038 - val_loss: 4.5980e-04 - val_mae: 0.0033\n",
      "Epoch 367/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.6861e-04 - mae: 0.0040 - val_loss: 4.6008e-04 - val_mae: 0.0034\n",
      "Epoch 368/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.6550e-04 - mae: 0.0039 - val_loss: 4.5633e-04 - val_mae: 0.0033\n",
      "Epoch 369/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.6044e-04 - mae: 0.0036 - val_loss: 4.6039e-04 - val_mae: 0.0038\n",
      "Epoch 370/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.5997e-04 - mae: 0.0037 - val_loss: 4.5334e-04 - val_mae: 0.0033\n",
      "Epoch 371/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.6245e-04 - mae: 0.0040 - val_loss: 4.5266e-04 - val_mae: 0.0034\n",
      "Epoch 372/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.5950e-04 - mae: 0.0039 - val_loss: 4.5413e-04 - val_mae: 0.0038\n",
      "Epoch 373/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.5541e-04 - mae: 0.0037 - val_loss: 4.5211e-04 - val_mae: 0.0036\n",
      "Epoch 374/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.5797e-04 - mae: 0.0041 - val_loss: 4.7110e-04 - val_mae: 0.0056\n",
      "Epoch 375/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.5741e-04 - mae: 0.0041 - val_loss: 4.4849e-04 - val_mae: 0.0035\n",
      "Epoch 376/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.5138e-04 - mae: 0.0037 - val_loss: 4.5569e-04 - val_mae: 0.0043\n",
      "Epoch 377/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.5306e-04 - mae: 0.0040 - val_loss: 4.6886e-04 - val_mae: 0.0057\n",
      "Epoch 378/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.5018e-04 - mae: 0.0039 - val_loss: 4.5312e-04 - val_mae: 0.0045\n",
      "Epoch 379/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.4713e-04 - mae: 0.0037 - val_loss: 4.4249e-04 - val_mae: 0.0036\n",
      "Epoch 380/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.4497e-04 - mae: 0.0037 - val_loss: 4.4566e-04 - val_mae: 0.0040\n",
      "Epoch 381/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.4656e-04 - mae: 0.0040 - val_loss: 4.3678e-04 - val_mae: 0.0032\n",
      "Epoch 382/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.4186e-04 - mae: 0.0036 - val_loss: 4.3597e-04 - val_mae: 0.0033\n",
      "Epoch 383/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.4523e-04 - mae: 0.0041 - val_loss: 4.5996e-04 - val_mae: 0.0056\n",
      "Epoch 384/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.4341e-04 - mae: 0.0041 - val_loss: 4.3590e-04 - val_mae: 0.0037\n",
      "Epoch 385/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.4323e-04 - mae: 0.0042 - val_loss: 4.2992e-04 - val_mae: 0.0031\n",
      "Epoch 386/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.3796e-04 - mae: 0.0038 - val_loss: 4.3022e-04 - val_mae: 0.0033\n",
      "Epoch 387/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.3369e-04 - mae: 0.0035 - val_loss: 4.3291e-04 - val_mae: 0.0037\n",
      "Epoch 388/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.3677e-04 - mae: 0.0039 - val_loss: 4.2822e-04 - val_mae: 0.0033\n",
      "Epoch 389/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.3392e-04 - mae: 0.0038 - val_loss: 4.3206e-04 - val_mae: 0.0038\n",
      "Epoch 390/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.3679e-04 - mae: 0.0041 - val_loss: 4.4808e-04 - val_mae: 0.0055\n",
      "Epoch 391/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.3027e-04 - mae: 0.0037 - val_loss: 4.2224e-04 - val_mae: 0.0031\n",
      "Epoch 392/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.3101e-04 - mae: 0.0039 - val_loss: 4.2314e-04 - val_mae: 0.0034\n",
      "Epoch 393/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.2959e-04 - mae: 0.0039 - val_loss: 4.4694e-04 - val_mae: 0.0057\n",
      "Epoch 394/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.2920e-04 - mae: 0.0040 - val_loss: 4.2255e-04 - val_mae: 0.0036\n",
      "Epoch 395/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.2455e-04 - mae: 0.0037 - val_loss: 4.2694e-04 - val_mae: 0.0042\n",
      "Epoch 396/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.2588e-04 - mae: 0.0039 - val_loss: 4.1749e-04 - val_mae: 0.0033\n",
      "Epoch 397/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.2340e-04 - mae: 0.0038 - val_loss: 4.1427e-04 - val_mae: 0.0031\n",
      "Epoch 398/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.2412e-04 - mae: 0.0039 - val_loss: 4.1986e-04 - val_mae: 0.0040\n",
      "Epoch 399/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.1993e-04 - mae: 0.0037 - val_loss: 4.2023e-04 - val_mae: 0.0040\n",
      "Epoch 400/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.2077e-04 - mae: 0.0039 - val_loss: 4.1460e-04 - val_mae: 0.0036\n",
      "Epoch 401/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.1855e-04 - mae: 0.0038 - val_loss: 4.1065e-04 - val_mae: 0.0033\n",
      "Epoch 402/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.1974e-04 - mae: 0.0040 - val_loss: 4.1605e-04 - val_mae: 0.0039\n",
      "Epoch 403/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.1453e-04 - mae: 0.0037 - val_loss: 4.1306e-04 - val_mae: 0.0036\n",
      "Epoch 404/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.1402e-04 - mae: 0.0037 - val_loss: 4.0676e-04 - val_mae: 0.0032\n",
      "Epoch 405/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.1548e-04 - mae: 0.0039 - val_loss: 4.0910e-04 - val_mae: 0.0037\n",
      "Epoch 406/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.1241e-04 - mae: 0.0038 - val_loss: 4.0576e-04 - val_mae: 0.0034\n",
      "Epoch 407/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.1102e-04 - mae: 0.0038 - val_loss: 4.0127e-04 - val_mae: 0.0030\n",
      "Epoch 408/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.0711e-04 - mae: 0.0035 - val_loss: 4.0346e-04 - val_mae: 0.0033\n",
      "Epoch 409/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.1366e-04 - mae: 0.0042 - val_loss: 4.0192e-04 - val_mae: 0.0033\n",
      "Epoch 410/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.0737e-04 - mae: 0.0038 - val_loss: 4.0633e-04 - val_mae: 0.0039\n",
      "Epoch 411/2000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.0589e-04 - mae: 0.0037 - val_loss: 4.0255e-04 - val_mae: 0.0037\n",
      "Epoch 412/2000\n",
      "264/270 [============================>.] - ETA: 0s - loss: 4.0573e-04 - mae: 0.0038Restoring model weights from the end of the best epoch: 407.\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.0578e-04 - mae: 0.0038 - val_loss: 4.0791e-04 - val_mae: 0.0041\n",
      "Epoch 412: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Netzwerkarchitektur\n",
    "model = Sequential([\n",
    "\n",
    "    Dense(200, activation='relu', input_shape=(5,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(232, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(88, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(216, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(280, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(88, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(88, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(88, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(1 , activation = 'linear')\n",
    "])\n",
    "\n",
    "# Optimierer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001) \n",
    "\n",
    "# Modell kompilieren (Verwendung von mean_squared_error als Verlustfunktion fÃ¼r Regression)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])  # Metriken fÃ¼r Regression: Mean Absolute Error und Mean Squared Error\n",
    "\n",
    "# Early Stopping Callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "# Trainingsparameter\n",
    "batch_size = 200\n",
    "epochs = 2000\n",
    "\n",
    "# Modell trainieren (Annahme: X_train, y_train, X_val, y_val sind vordefiniert)\n",
    "history = model.fit(X_train_scaled, y_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "model.save('D4_t_9_I_F_3.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T10:11:21.974501900Z",
     "start_time": "2024-04-02T10:00:45.123200900Z"
    }
   },
   "id": "8b52e1a9a6ff3aeb"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fÃ¼r Fold 1...\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 3s 5ms/step - loss: 0.1635 - mae: 0.1665 - val_loss: 0.0325 - val_mae: 0.0658\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0295 - mae: 0.0545 - val_loss: 0.0274 - val_mae: 0.0465\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0258 - mae: 0.0405 - val_loss: 0.0244 - val_mae: 0.0353\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0234 - mae: 0.0315 - val_loss: 0.0225 - val_mae: 0.0281\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0219 - mae: 0.0256 - val_loss: 0.0214 - val_mae: 0.0234\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0209 - mae: 0.0220 - val_loss: 0.0205 - val_mae: 0.0199\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0202 - mae: 0.0191 - val_loss: 0.0200 - val_mae: 0.0197\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0197 - mae: 0.0172 - val_loss: 0.0195 - val_mae: 0.0169\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0192 - mae: 0.0153 - val_loss: 0.0190 - val_mae: 0.0143\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0189 - mae: 0.0141 - val_loss: 0.0187 - val_mae: 0.0132\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0185 - mae: 0.0129 - val_loss: 0.0184 - val_mae: 0.0124\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0182 - mae: 0.0119 - val_loss: 0.0181 - val_mae: 0.0113\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0180 - mae: 0.0111 - val_loss: 0.0178 - val_mae: 0.0109\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0177 - mae: 0.0105 - val_loss: 0.0175 - val_mae: 0.0100\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0174 - mae: 0.0101 - val_loss: 0.0173 - val_mae: 0.0096\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0172 - mae: 0.0097 - val_loss: 0.0170 - val_mae: 0.0091\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0169 - mae: 0.0094 - val_loss: 0.0168 - val_mae: 0.0089\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0167 - mae: 0.0093 - val_loss: 0.0165 - val_mae: 0.0092\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0164 - mae: 0.0093 - val_loss: 0.0163 - val_mae: 0.0086\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0162 - mae: 0.0089 - val_loss: 0.0161 - val_mae: 0.0090\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0159 - mae: 0.0084 - val_loss: 0.0158 - val_mae: 0.0094\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0157 - mae: 0.0088 - val_loss: 0.0155 - val_mae: 0.0076\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0154 - mae: 0.0085 - val_loss: 0.0154 - val_mae: 0.0100\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0152 - mae: 0.0089 - val_loss: 0.0151 - val_mae: 0.0096\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0149 - mae: 0.0084 - val_loss: 0.0148 - val_mae: 0.0093\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0147 - mae: 0.0089 - val_loss: 0.0145 - val_mae: 0.0076\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0144 - mae: 0.0084 - val_loss: 0.0145 - val_mae: 0.0116\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0142 - mae: 0.0080 - val_loss: 0.0141 - val_mae: 0.0097\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0140 - mae: 0.0082 - val_loss: 0.0139 - val_mae: 0.0092\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0137 - mae: 0.0080 - val_loss: 0.0136 - val_mae: 0.0068\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0135 - mae: 0.0077 - val_loss: 0.0133 - val_mae: 0.0076\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0132 - mae: 0.0077 - val_loss: 0.0132 - val_mae: 0.0095\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0130 - mae: 0.0082 - val_loss: 0.0128 - val_mae: 0.0066\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0127 - mae: 0.0076 - val_loss: 0.0127 - val_mae: 0.0089\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0125 - mae: 0.0076 - val_loss: 0.0124 - val_mae: 0.0079\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0123 - mae: 0.0072 - val_loss: 0.0121 - val_mae: 0.0068\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0121 - mae: 0.0078 - val_loss: 0.0120 - val_mae: 0.0099\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0118 - mae: 0.0074 - val_loss: 0.0117 - val_mae: 0.0092\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0116 - mae: 0.0075 - val_loss: 0.0114 - val_mae: 0.0067\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0114 - mae: 0.0073 - val_loss: 0.0113 - val_mae: 0.0082\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0111 - mae: 0.0072 - val_loss: 0.0110 - val_mae: 0.0069\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0110 - mae: 0.0082 - val_loss: 0.0108 - val_mae: 0.0064\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0107 - mae: 0.0068 - val_loss: 0.0106 - val_mae: 0.0070\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0105 - mae: 0.0065 - val_loss: 0.0104 - val_mae: 0.0067\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0103 - mae: 0.0076 - val_loss: 0.0103 - val_mae: 0.0100\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0101 - mae: 0.0070 - val_loss: 0.0100 - val_mae: 0.0072\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0099 - mae: 0.0069 - val_loss: 0.0101 - val_mae: 0.0146\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0097 - mae: 0.0069 - val_loss: 0.0096 - val_mae: 0.0065\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0096 - mae: 0.0065 - val_loss: 0.0095 - val_mae: 0.0088\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0094 - mae: 0.0068 - val_loss: 0.0093 - val_mae: 0.0061\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0092 - mae: 0.0065 - val_loss: 0.0091 - val_mae: 0.0054\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0090 - mae: 0.0063 - val_loss: 0.0089 - val_mae: 0.0065\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0088 - mae: 0.0061 - val_loss: 0.0088 - val_mae: 0.0062\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0087 - mae: 0.0068 - val_loss: 0.0086 - val_mae: 0.0055\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0085 - mae: 0.0062 - val_loss: 0.0084 - val_mae: 0.0056\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0084 - mae: 0.0064 - val_loss: 0.0083 - val_mae: 0.0073\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0082 - mae: 0.0060 - val_loss: 0.0082 - val_mae: 0.0079\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0081 - mae: 0.0065 - val_loss: 0.0080 - val_mae: 0.0072\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0079 - mae: 0.0060 - val_loss: 0.0078 - val_mae: 0.0059\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0077 - mae: 0.0058 - val_loss: 0.0077 - val_mae: 0.0053\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0076 - mae: 0.0059 - val_loss: 0.0075 - val_mae: 0.0065\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0075 - mae: 0.0060 - val_loss: 0.0074 - val_mae: 0.0063\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0073 - mae: 0.0061 - val_loss: 0.0072 - val_mae: 0.0053\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0072 - mae: 0.0060 - val_loss: 0.0072 - val_mae: 0.0079\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0071 - mae: 0.0068 - val_loss: 0.0070 - val_mae: 0.0052\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0070 - mae: 0.0060 - val_loss: 0.0069 - val_mae: 0.0069\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0068 - mae: 0.0063 - val_loss: 0.0068 - val_mae: 0.0050\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0067 - mae: 0.0058 - val_loss: 0.0067 - val_mae: 0.0067\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0066 - mae: 0.0056 - val_loss: 0.0066 - val_mae: 0.0061\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0065 - mae: 0.0057 - val_loss: 0.0065 - val_mae: 0.0080\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0064 - mae: 0.0057 - val_loss: 0.0063 - val_mae: 0.0049\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0063 - mae: 0.0055 - val_loss: 0.0062 - val_mae: 0.0048\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0062 - mae: 0.0056 - val_loss: 0.0061 - val_mae: 0.0059\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0061 - mae: 0.0056 - val_loss: 0.0060 - val_mae: 0.0054\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0060 - mae: 0.0055 - val_loss: 0.0059 - val_mae: 0.0047\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0059 - mae: 0.0056 - val_loss: 0.0059 - val_mae: 0.0079\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0058 - mae: 0.0058 - val_loss: 0.0057 - val_mae: 0.0047\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0057 - mae: 0.0055 - val_loss: 0.0057 - val_mae: 0.0067\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0056 - mae: 0.0057 - val_loss: 0.0055 - val_mae: 0.0044\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0055 - mae: 0.0058 - val_loss: 0.0055 - val_mae: 0.0049\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0054 - mae: 0.0053 - val_loss: 0.0054 - val_mae: 0.0061\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0053 - mae: 0.0055 - val_loss: 0.0053 - val_mae: 0.0059\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0053 - mae: 0.0056 - val_loss: 0.0052 - val_mae: 0.0046\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0052 - mae: 0.0052 - val_loss: 0.0051 - val_mae: 0.0047\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0051 - mae: 0.0056 - val_loss: 0.0051 - val_mae: 0.0050\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0050 - mae: 0.0053 - val_loss: 0.0050 - val_mae: 0.0075\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0049 - mae: 0.0054 - val_loss: 0.0049 - val_mae: 0.0051\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0049 - mae: 0.0056 - val_loss: 0.0048 - val_mae: 0.0054\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0048 - mae: 0.0053 - val_loss: 0.0048 - val_mae: 0.0057\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0047 - mae: 0.0053 - val_loss: 0.0047 - val_mae: 0.0058\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0047 - mae: 0.0053 - val_loss: 0.0046 - val_mae: 0.0056\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0052 - val_loss: 0.0046 - val_mae: 0.0058\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0045 - mae: 0.0054 - val_loss: 0.0046 - val_mae: 0.0105\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0044 - mae: 0.0053 - val_loss: 0.0044 - val_mae: 0.0043\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0044 - mae: 0.0053 - val_loss: 0.0044 - val_mae: 0.0053\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0043 - mae: 0.0051 - val_loss: 0.0043 - val_mae: 0.0048\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0043 - mae: 0.0055 - val_loss: 0.0042 - val_mae: 0.0046\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0042 - mae: 0.0051 - val_loss: 0.0042 - val_mae: 0.0050\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0041 - mae: 0.0051 - val_loss: 0.0041 - val_mae: 0.0044\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0041 - mae: 0.0051 - val_loss: 0.0040 - val_mae: 0.0055\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0040 - mae: 0.0053 - val_loss: 0.0040 - val_mae: 0.0051\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0039 - mae: 0.0050 - val_loss: 0.0039 - val_mae: 0.0043\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0039 - mae: 0.0056 - val_loss: 0.0039 - val_mae: 0.0045\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0038 - mae: 0.0048 - val_loss: 0.0038 - val_mae: 0.0057\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0038 - mae: 0.0051 - val_loss: 0.0037 - val_mae: 0.0047\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0037 - mae: 0.0050 - val_loss: 0.0037 - val_mae: 0.0070\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0037 - mae: 0.0049 - val_loss: 0.0037 - val_mae: 0.0067\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0036 - mae: 0.0052 - val_loss: 0.0036 - val_mae: 0.0045\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0036 - mae: 0.0050 - val_loss: 0.0035 - val_mae: 0.0052\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0035 - mae: 0.0050 - val_loss: 0.0035 - val_mae: 0.0044\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0035 - mae: 0.0049 - val_loss: 0.0035 - val_mae: 0.0062\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0034 - mae: 0.0052 - val_loss: 0.0034 - val_mae: 0.0059\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0034 - mae: 0.0052 - val_loss: 0.0033 - val_mae: 0.0048\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0033 - mae: 0.0050 - val_loss: 0.0033 - val_mae: 0.0044\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0033 - mae: 0.0048 - val_loss: 0.0032 - val_mae: 0.0046\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0032 - mae: 0.0049 - val_loss: 0.0032 - val_mae: 0.0052\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0032 - mae: 0.0052 - val_loss: 0.0032 - val_mae: 0.0053\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0031 - mae: 0.0047 - val_loss: 0.0031 - val_mae: 0.0041\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0031 - mae: 0.0049 - val_loss: 0.0031 - val_mae: 0.0071\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0030 - mae: 0.0047 - val_loss: 0.0031 - val_mae: 0.0082\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0030 - mae: 0.0047 - val_loss: 0.0030 - val_mae: 0.0044\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0030 - mae: 0.0050 - val_loss: 0.0029 - val_mae: 0.0044\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0029 - mae: 0.0047 - val_loss: 0.0029 - val_mae: 0.0049\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0029 - mae: 0.0049 - val_loss: 0.0028 - val_mae: 0.0042\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0028 - mae: 0.0046 - val_loss: 0.0028 - val_mae: 0.0045\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0028 - mae: 0.0049 - val_loss: 0.0028 - val_mae: 0.0043\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0027 - mae: 0.0046 - val_loss: 0.0027 - val_mae: 0.0054\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0027 - mae: 0.0049 - val_loss: 0.0027 - val_mae: 0.0042\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0027 - mae: 0.0046 - val_loss: 0.0026 - val_mae: 0.0042\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0026 - mae: 0.0052 - val_loss: 0.0026 - val_mae: 0.0052\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0026 - mae: 0.0047 - val_loss: 0.0026 - val_mae: 0.0044\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0026 - mae: 0.0049 - val_loss: 0.0025 - val_mae: 0.0045\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0025 - mae: 0.0046 - val_loss: 0.0025 - val_mae: 0.0045\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0025 - mae: 0.0045 - val_loss: 0.0025 - val_mae: 0.0074\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0025 - mae: 0.0048 - val_loss: 0.0024 - val_mae: 0.0045\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0024 - mae: 0.0045 - val_loss: 0.0024 - val_mae: 0.0045\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0024 - mae: 0.0044 - val_loss: 0.0024 - val_mae: 0.0049\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0024 - mae: 0.0046 - val_loss: 0.0024 - val_mae: 0.0058\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0023 - mae: 0.0046 - val_loss: 0.0023 - val_mae: 0.0066\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0023 - mae: 0.0047 - val_loss: 0.0023 - val_mae: 0.0049\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0023 - mae: 0.0048 - val_loss: 0.0022 - val_mae: 0.0041\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0022 - mae: 0.0047 - val_loss: 0.0022 - val_mae: 0.0051\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0022 - mae: 0.0048 - val_loss: 0.0022 - val_mae: 0.0038\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0022 - mae: 0.0045 - val_loss: 0.0022 - val_mae: 0.0048\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0047 - val_loss: 0.0021 - val_mae: 0.0055\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0047 - val_loss: 0.0021 - val_mae: 0.0042\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0045 - val_loss: 0.0021 - val_mae: 0.0040\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0046 - val_loss: 0.0021 - val_mae: 0.0064\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0046 - val_loss: 0.0020 - val_mae: 0.0038\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0044 - val_loss: 0.0020 - val_mae: 0.0038\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0020 - mae: 0.0047 - val_loss: 0.0020 - val_mae: 0.0041\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0047 - val_loss: 0.0019 - val_mae: 0.0040\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0045 - val_loss: 0.0019 - val_mae: 0.0041\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0043 - val_loss: 0.0019 - val_mae: 0.0040\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0046 - val_loss: 0.0019 - val_mae: 0.0037\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0046 - val_loss: 0.0019 - val_mae: 0.0064\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0049 - val_loss: 0.0018 - val_mae: 0.0041\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0043 - val_loss: 0.0018 - val_mae: 0.0039\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0045 - val_loss: 0.0018 - val_mae: 0.0058\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0046 - val_loss: 0.0018 - val_mae: 0.0048\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0044 - val_loss: 0.0018 - val_mae: 0.0060\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0046 - val_loss: 0.0017 - val_mae: 0.0040\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0042 - val_loss: 0.0017 - val_mae: 0.0037\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0045 - val_loss: 0.0017 - val_mae: 0.0044\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0043 - val_loss: 0.0017 - val_mae: 0.0044\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0050\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0037\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0045 - val_loss: 0.0016 - val_mae: 0.0042\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0038\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0047 - val_loss: 0.0016 - val_mae: 0.0039\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0043\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0041\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 0.0015 - val_mae: 0.0045\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0041\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0038\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0048 - val_loss: 0.0015 - val_mae: 0.0038\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0038\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0037\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0046\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0039\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0046 - val_loss: 0.0014 - val_mae: 0.0037\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0046\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0038\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0037\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0047 - val_loss: 0.0013 - val_mae: 0.0037\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0043\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0037\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0049\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0039\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0045\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0067\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0063\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0045 - val_loss: 0.0012 - val_mae: 0.0039\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0042 - val_loss: 0.0012 - val_mae: 0.0045\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0054\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0045 - val_loss: 0.0012 - val_mae: 0.0039\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0041 - val_loss: 0.0012 - val_mae: 0.0040\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0044 - val_loss: 0.0012 - val_mae: 0.0037\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0046 - val_loss: 0.0011 - val_mae: 0.0041\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0044 - val_loss: 0.0011 - val_mae: 0.0043\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0040 - val_loss: 0.0011 - val_mae: 0.0054\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0044 - val_loss: 0.0011 - val_mae: 0.0039\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0038\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0044\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0038\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0037\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0044 - val_loss: 0.0011 - val_mae: 0.0040\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0039\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0045 - val_loss: 0.0010 - val_mae: 0.0041\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0044 - val_loss: 0.0010 - val_mae: 0.0041\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0042 - val_loss: 0.0010 - val_mae: 0.0043\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0078\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0043 - val_loss: 0.0010 - val_mae: 0.0035\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0042 - val_loss: 0.0010 - val_mae: 0.0045\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0044 - val_loss: 9.9820e-04 - val_mae: 0.0046\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.9345e-04 - mae: 0.0042 - val_loss: 0.0010 - val_mae: 0.0052\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.8640e-04 - mae: 0.0043 - val_loss: 9.8734e-04 - val_mae: 0.0050\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.7885e-04 - mae: 0.0044 - val_loss: 9.6545e-04 - val_mae: 0.0037\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.7090e-04 - mae: 0.0043 - val_loss: 0.0010 - val_mae: 0.0069\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.5976e-04 - mae: 0.0041 - val_loss: 9.5666e-04 - val_mae: 0.0042\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.6105e-04 - mae: 0.0047 - val_loss: 9.4257e-04 - val_mae: 0.0037\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.4728e-04 - mae: 0.0043 - val_loss: 9.3805e-04 - val_mae: 0.0040\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.3609e-04 - mae: 0.0040 - val_loss: 9.2731e-04 - val_mae: 0.0037\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.3058e-04 - mae: 0.0041 - val_loss: 9.2124e-04 - val_mae: 0.0038\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.2838e-04 - mae: 0.0045 - val_loss: 9.2667e-04 - val_mae: 0.0050\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.1799e-04 - mae: 0.0043 - val_loss: 9.1148e-04 - val_mae: 0.0043\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.1198e-04 - mae: 0.0044 - val_loss: 9.0250e-04 - val_mae: 0.0041\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.0582e-04 - mae: 0.0044 - val_loss: 9.1364e-04 - val_mae: 0.0053\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.9558e-04 - mae: 0.0041 - val_loss: 8.8695e-04 - val_mae: 0.0038\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.9220e-04 - mae: 0.0043 - val_loss: 8.7878e-04 - val_mae: 0.0036\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.8234e-04 - mae: 0.0041 - val_loss: 8.7975e-04 - val_mae: 0.0044\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.7978e-04 - mae: 0.0044 - val_loss: 8.6507e-04 - val_mae: 0.0036\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.7291e-04 - mae: 0.0043 - val_loss: 8.6263e-04 - val_mae: 0.0040\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.6347e-04 - mae: 0.0041 - val_loss: 8.6587e-04 - val_mae: 0.0048\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.5816e-04 - mae: 0.0042 - val_loss: 8.4656e-04 - val_mae: 0.0036\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.5297e-04 - mae: 0.0043 - val_loss: 8.4108e-04 - val_mae: 0.0036\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.5142e-04 - mae: 0.0046 - val_loss: 8.4231e-04 - val_mae: 0.0042\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.3810e-04 - mae: 0.0040 - val_loss: 8.3025e-04 - val_mae: 0.0037\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.3347e-04 - mae: 0.0041 - val_loss: 8.3233e-04 - val_mae: 0.0044\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.2803e-04 - mae: 0.0042 - val_loss: 8.2274e-04 - val_mae: 0.0041\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.2152e-04 - mae: 0.0041 - val_loss: 8.3404e-04 - val_mae: 0.0056\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.1937e-04 - mae: 0.0043 - val_loss: 8.0911e-04 - val_mae: 0.0040\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.1439e-04 - mae: 0.0044 - val_loss: 8.0307e-04 - val_mae: 0.0038\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.0407e-04 - mae: 0.0040 - val_loss: 7.9366e-04 - val_mae: 0.0035\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.0063e-04 - mae: 0.0042 - val_loss: 7.9088e-04 - val_mae: 0.0037\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.9672e-04 - mae: 0.0043 - val_loss: 7.8431e-04 - val_mae: 0.0036\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.8906e-04 - mae: 0.0041 - val_loss: 7.8256e-04 - val_mae: 0.0039\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.8582e-04 - mae: 0.0042 - val_loss: 7.7446e-04 - val_mae: 0.0037\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.8190e-04 - mae: 0.0044 - val_loss: 7.7614e-04 - val_mae: 0.0044\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.7333e-04 - mae: 0.0041 - val_loss: 7.6922e-04 - val_mae: 0.0042\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.6922e-04 - mae: 0.0042 - val_loss: 7.6253e-04 - val_mae: 0.0039\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.6609e-04 - mae: 0.0043 - val_loss: 7.8691e-04 - val_mae: 0.0063\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.6089e-04 - mae: 0.0043 - val_loss: 7.4970e-04 - val_mae: 0.0036\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.6129e-04 - mae: 0.0044 - val_loss: 7.4770e-04 - val_mae: 0.0038\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.4732e-04 - mae: 0.0039 - val_loss: 7.4159e-04 - val_mae: 0.0036\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.4586e-04 - mae: 0.0042 - val_loss: 7.3459e-04 - val_mae: 0.0035\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.4168e-04 - mae: 0.0042 - val_loss: 7.6602e-04 - val_mae: 0.0065\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.3770e-04 - mae: 0.0042 - val_loss: 7.2679e-04 - val_mae: 0.0037\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.3382e-04 - mae: 0.0043 - val_loss: 7.2850e-04 - val_mae: 0.0041\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.2833e-04 - mae: 0.0042 - val_loss: 7.1991e-04 - val_mae: 0.0038\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.2286e-04 - mae: 0.0041 - val_loss: 7.1340e-04 - val_mae: 0.0036\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.2167e-04 - mae: 0.0043 - val_loss: 7.3652e-04 - val_mae: 0.0059\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.1708e-04 - mae: 0.0043 - val_loss: 7.0364e-04 - val_mae: 0.0034\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.0854e-04 - mae: 0.0039 - val_loss: 7.0440e-04 - val_mae: 0.0039\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.0666e-04 - mae: 0.0041 - val_loss: 7.0180e-04 - val_mae: 0.0040\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.0691e-04 - mae: 0.0044 - val_loss: 6.9532e-04 - val_mae: 0.0037\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.9753e-04 - mae: 0.0040 - val_loss: 6.9686e-04 - val_mae: 0.0043\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.9582e-04 - mae: 0.0042 - val_loss: 6.9383e-04 - val_mae: 0.0043\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.9129e-04 - mae: 0.0042 - val_loss: 6.9095e-04 - val_mae: 0.0045\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.8441e-04 - mae: 0.0039 - val_loss: 6.7955e-04 - val_mae: 0.0039\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.8381e-04 - mae: 0.0042 - val_loss: 6.7704e-04 - val_mae: 0.0040\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.7911e-04 - mae: 0.0041 - val_loss: 7.0772e-04 - val_mae: 0.0065\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.7571e-04 - mae: 0.0042 - val_loss: 6.7065e-04 - val_mae: 0.0041\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.7454e-04 - mae: 0.0044 - val_loss: 6.6684e-04 - val_mae: 0.0040\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.7367e-04 - mae: 0.0045 - val_loss: 6.5932e-04 - val_mae: 0.0037\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.6245e-04 - mae: 0.0040 - val_loss: 6.6567e-04 - val_mae: 0.0046\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.5905e-04 - mae: 0.0040 - val_loss: 6.6761e-04 - val_mae: 0.0047\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.6058e-04 - mae: 0.0043 - val_loss: 6.9011e-04 - val_mae: 0.0068\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.5308e-04 - mae: 0.0041 - val_loss: 6.5257e-04 - val_mae: 0.0041\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.4975e-04 - mae: 0.0040 - val_loss: 6.4136e-04 - val_mae: 0.0036\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.4731e-04 - mae: 0.0041 - val_loss: 6.3957e-04 - val_mae: 0.0038\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.4461e-04 - mae: 0.0042 - val_loss: 6.3541e-04 - val_mae: 0.0036\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.3849e-04 - mae: 0.0040 - val_loss: 6.3083e-04 - val_mae: 0.0035\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.3500e-04 - mae: 0.0039 - val_loss: 6.2666e-04 - val_mae: 0.0035\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.3317e-04 - mae: 0.0041 - val_loss: 6.2452e-04 - val_mae: 0.0036\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.2881e-04 - mae: 0.0040 - val_loss: 6.1966e-04 - val_mae: 0.0035\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.2799e-04 - mae: 0.0042 - val_loss: 6.1742e-04 - val_mae: 0.0036\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.2525e-04 - mae: 0.0042 - val_loss: 6.2136e-04 - val_mae: 0.0043\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.1821e-04 - mae: 0.0039 - val_loss: 6.1076e-04 - val_mae: 0.0036\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.1850e-04 - mae: 0.0042 - val_loss: 6.1229e-04 - val_mae: 0.0039\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.1467e-04 - mae: 0.0041 - val_loss: 6.0505e-04 - val_mae: 0.0034\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.1196e-04 - mae: 0.0042 - val_loss: 6.1689e-04 - val_mae: 0.0049\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.0677e-04 - mae: 0.0040 - val_loss: 5.9731e-04 - val_mae: 0.0034\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.0430e-04 - mae: 0.0040 - val_loss: 5.9395e-04 - val_mae: 0.0034\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.0296e-04 - mae: 0.0042 - val_loss: 5.9496e-04 - val_mae: 0.0038\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.9940e-04 - mae: 0.0041 - val_loss: 5.9406e-04 - val_mae: 0.0039\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 5.9661e-04 - mae: 0.0041 - val_loss: 5.9965e-04 - val_mae: 0.0046\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.9256e-04 - mae: 0.0040 - val_loss: 5.8472e-04 - val_mae: 0.0036\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.9054e-04 - mae: 0.0041 - val_loss: 5.7978e-04 - val_mae: 0.0034\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.8542e-04 - mae: 0.0039 - val_loss: 5.8488e-04 - val_mae: 0.0042\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.8469e-04 - mae: 0.0041 - val_loss: 5.9275e-04 - val_mae: 0.0048\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.8469e-04 - mae: 0.0043 - val_loss: 5.7156e-04 - val_mae: 0.0034\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.7895e-04 - mae: 0.0041 - val_loss: 5.7033e-04 - val_mae: 0.0036\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.7687e-04 - mae: 0.0041 - val_loss: 5.6754e-04 - val_mae: 0.0035\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.7439e-04 - mae: 0.0041 - val_loss: 5.7342e-04 - val_mae: 0.0042\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.7002e-04 - mae: 0.0040 - val_loss: 5.7894e-04 - val_mae: 0.0050\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.6614e-04 - mae: 0.0038 - val_loss: 5.5900e-04 - val_mae: 0.0035\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.6893e-04 - mae: 0.0043 - val_loss: 5.6093e-04 - val_mae: 0.0038\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.6440e-04 - mae: 0.0041 - val_loss: 5.6787e-04 - val_mae: 0.0045\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.5832e-04 - mae: 0.0039 - val_loss: 5.5362e-04 - val_mae: 0.0036\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.5755e-04 - mae: 0.0040 - val_loss: 5.6233e-04 - val_mae: 0.0047\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.5751e-04 - mae: 0.0042 - val_loss: 5.5364e-04 - val_mae: 0.0042\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.5537e-04 - mae: 0.0042 - val_loss: 5.5488e-04 - val_mae: 0.0044\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.4960e-04 - mae: 0.0039 - val_loss: 5.4210e-04 - val_mae: 0.0035\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.4886e-04 - mae: 0.0040 - val_loss: 5.4444e-04 - val_mae: 0.0040\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.4898e-04 - mae: 0.0043 - val_loss: 5.3739e-04 - val_mae: 0.0036\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.4564e-04 - mae: 0.0042 - val_loss: 5.3816e-04 - val_mae: 0.0039\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.4161e-04 - mae: 0.0041 - val_loss: 5.3574e-04 - val_mae: 0.0039\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.4033e-04 - mae: 0.0041 - val_loss: 5.2997e-04 - val_mae: 0.0035\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.3601e-04 - mae: 0.0039 - val_loss: 5.3162e-04 - val_mae: 0.0040\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.3642e-04 - mae: 0.0042 - val_loss: 5.2998e-04 - val_mae: 0.0039\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.3333e-04 - mae: 0.0041 - val_loss: 5.2579e-04 - val_mae: 0.0037\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.2985e-04 - mae: 0.0040 - val_loss: 5.2184e-04 - val_mae: 0.0035\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.3020e-04 - mae: 0.0042 - val_loss: 5.1956e-04 - val_mae: 0.0035\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.2529e-04 - mae: 0.0039 - val_loss: 5.1932e-04 - val_mae: 0.0037\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.2291e-04 - mae: 0.0039 - val_loss: 5.1486e-04 - val_mae: 0.0035\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.2164e-04 - mae: 0.0040 - val_loss: 5.4307e-04 - val_mae: 0.0060\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.2032e-04 - mae: 0.0041 - val_loss: 5.1042e-04 - val_mae: 0.0034\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.1565e-04 - mae: 0.0038 - val_loss: 5.1817e-04 - val_mae: 0.0044\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.1866e-04 - mae: 0.0043 - val_loss: 5.0809e-04 - val_mae: 0.0037\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.1132e-04 - mae: 0.0039 - val_loss: 5.0478e-04 - val_mae: 0.0035\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.1319e-04 - mae: 0.0042 - val_loss: 5.0954e-04 - val_mae: 0.0040\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.0928e-04 - mae: 0.0040 - val_loss: 5.0397e-04 - val_mae: 0.0038\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 5.0854e-04 - mae: 0.0041 - val_loss: 4.9692e-04 - val_mae: 0.0033\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.0472e-04 - mae: 0.0040 - val_loss: 5.0436e-04 - val_mae: 0.0041\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.0598e-04 - mae: 0.0042 - val_loss: 4.9465e-04 - val_mae: 0.0034\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.0107e-04 - mae: 0.0040 - val_loss: 5.0176e-04 - val_mae: 0.0043\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.0065e-04 - mae: 0.0041 - val_loss: 4.9396e-04 - val_mae: 0.0038\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.9913e-04 - mae: 0.0041 - val_loss: 4.9165e-04 - val_mae: 0.0037\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.9490e-04 - mae: 0.0039 - val_loss: 5.0002e-04 - val_mae: 0.0047\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 4.9231e-04 - mae: 0.0039 - val_loss: 4.8678e-04 - val_mae: 0.0035\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 4.9106e-04 - mae: 0.0039 - val_loss: 4.8909e-04 - val_mae: 0.0040\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.9173e-04 - mae: 0.0041 - val_loss: 4.8728e-04 - val_mae: 0.0041\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 4.8771e-04 - mae: 0.0039 - val_loss: 4.7835e-04 - val_mae: 0.0033\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.8718e-04 - mae: 0.0041 - val_loss: 4.9678e-04 - val_mae: 0.0052\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.8572e-04 - mae: 0.0041 - val_loss: 4.7799e-04 - val_mae: 0.0036\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.8495e-04 - mae: 0.0041 - val_loss: 4.7955e-04 - val_mae: 0.0039\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.8152e-04 - mae: 0.0040 - val_loss: 4.9722e-04 - val_mae: 0.0055\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.7943e-04 - mae: 0.0040 - val_loss: 4.7291e-04 - val_mae: 0.0036\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.7756e-04 - mae: 0.0040 - val_loss: 4.7692e-04 - val_mae: 0.0042\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.7513e-04 - mae: 0.0039 - val_loss: 4.6968e-04 - val_mae: 0.0037\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.7604e-04 - mae: 0.0041 - val_loss: 4.6643e-04 - val_mae: 0.0035\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.7076e-04 - mae: 0.0038 - val_loss: 4.6576e-04 - val_mae: 0.0037\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.7015e-04 - mae: 0.0039 - val_loss: 4.6242e-04 - val_mae: 0.0034\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.6982e-04 - mae: 0.0040 - val_loss: 4.6162e-04 - val_mae: 0.0035\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.6918e-04 - mae: 0.0041 - val_loss: 4.5723e-04 - val_mae: 0.0032\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.6840e-04 - mae: 0.0042 - val_loss: 4.6781e-04 - val_mae: 0.0043\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.6375e-04 - mae: 0.0040 - val_loss: 4.5823e-04 - val_mae: 0.0037\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.6310e-04 - mae: 0.0040 - val_loss: 4.7952e-04 - val_mae: 0.0053\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.6092e-04 - mae: 0.0039 - val_loss: 4.5623e-04 - val_mae: 0.0039\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.5930e-04 - mae: 0.0040 - val_loss: 4.5473e-04 - val_mae: 0.0039\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.5885e-04 - mae: 0.0041 - val_loss: 4.5500e-04 - val_mae: 0.0040\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.5696e-04 - mae: 0.0040 - val_loss: 4.4820e-04 - val_mae: 0.0034\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.5647e-04 - mae: 0.0041 - val_loss: 4.4817e-04 - val_mae: 0.0036\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.5402e-04 - mae: 0.0040 - val_loss: 4.6545e-04 - val_mae: 0.0052\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.5000e-04 - mae: 0.0038 - val_loss: 4.4182e-04 - val_mae: 0.0032\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.4798e-04 - mae: 0.0038 - val_loss: 4.5130e-04 - val_mae: 0.0041\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.4801e-04 - mae: 0.0039 - val_loss: 4.4409e-04 - val_mae: 0.0038\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.4679e-04 - mae: 0.0039 - val_loss: 4.4075e-04 - val_mae: 0.0036\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.4452e-04 - mae: 0.0039 - val_loss: 4.4790e-04 - val_mae: 0.0045\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.4617e-04 - mae: 0.0041 - val_loss: 4.3775e-04 - val_mae: 0.0036\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.4290e-04 - mae: 0.0040 - val_loss: 4.3480e-04 - val_mae: 0.0034\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.4036e-04 - mae: 0.0039 - val_loss: 4.3506e-04 - val_mae: 0.0036\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.3906e-04 - mae: 0.0039 - val_loss: 4.3138e-04 - val_mae: 0.0034\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.3829e-04 - mae: 0.0040 - val_loss: 4.3254e-04 - val_mae: 0.0036\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.4031e-04 - mae: 0.0042 - val_loss: 4.4744e-04 - val_mae: 0.0050\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.3559e-04 - mae: 0.0040 - val_loss: 4.2878e-04 - val_mae: 0.0036\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.3381e-04 - mae: 0.0039 - val_loss: 4.2942e-04 - val_mae: 0.0037\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.3122e-04 - mae: 0.0038 - val_loss: 4.2475e-04 - val_mae: 0.0035\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.2932e-04 - mae: 0.0038 - val_loss: 4.2213e-04 - val_mae: 0.0033\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.3073e-04 - mae: 0.0040 - val_loss: 4.2309e-04 - val_mae: 0.0034\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.2847e-04 - mae: 0.0039 - val_loss: 4.2555e-04 - val_mae: 0.0038\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.2860e-04 - mae: 0.0041 - val_loss: 4.1867e-04 - val_mae: 0.0034\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.2450e-04 - mae: 0.0038 - val_loss: 4.1695e-04 - val_mae: 0.0034\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.2332e-04 - mae: 0.0038 - val_loss: 4.1674e-04 - val_mae: 0.0034\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.2371e-04 - mae: 0.0040 - val_loss: 4.1272e-04 - val_mae: 0.0031\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.2342e-04 - mae: 0.0041 - val_loss: 4.1546e-04 - val_mae: 0.0036\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.2011e-04 - mae: 0.0039 - val_loss: 4.2588e-04 - val_mae: 0.0046\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.1960e-04 - mae: 0.0040 - val_loss: 4.2342e-04 - val_mae: 0.0047\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.1696e-04 - mae: 0.0038 - val_loss: 4.1117e-04 - val_mae: 0.0036\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.1917e-04 - mae: 0.0041 - val_loss: 4.1421e-04 - val_mae: 0.0039\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.1519e-04 - mae: 0.0039 - val_loss: 4.0705e-04 - val_mae: 0.0033\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.1662e-04 - mae: 0.0041 - val_loss: 4.0538e-04 - val_mae: 0.0032\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.1080e-04 - mae: 0.0037 - val_loss: 4.0519e-04 - val_mae: 0.0034\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.1232e-04 - mae: 0.0040 - val_loss: 4.1128e-04 - val_mae: 0.0043\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.0773e-04 - mae: 0.0037 - val_loss: 4.0696e-04 - val_mae: 0.0038\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.1136e-04 - mae: 0.0040 - val_loss: 4.0747e-04 - val_mae: 0.0042\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.0872e-04 - mae: 0.0040 - val_loss: 4.0041e-04 - val_mae: 0.0034\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.0605e-04 - mae: 0.0038 - val_loss: 4.0159e-04 - val_mae: 0.0036\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.0429e-04 - mae: 0.0038 - val_loss: 4.1273e-04 - val_mae: 0.0048\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.1000e-04 - mae: 0.0043 - val_loss: 4.0059e-04 - val_mae: 0.0037\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.0265e-04 - mae: 0.0038 - val_loss: 3.9373e-04 - val_mae: 0.0031\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.0342e-04 - mae: 0.0040 - val_loss: 4.0368e-04 - val_mae: 0.0043\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.0142e-04 - mae: 0.0039 - val_loss: 3.9986e-04 - val_mae: 0.0040\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.9817e-04 - mae: 0.0037 - val_loss: 4.0129e-04 - val_mae: 0.0042\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.0080e-04 - mae: 0.0040 - val_loss: 3.9197e-04 - val_mae: 0.0035\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.0314e-04 - mae: 0.0042 - val_loss: 3.9196e-04 - val_mae: 0.0035\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.9423e-04 - mae: 0.0036 - val_loss: 4.0717e-04 - val_mae: 0.0050\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.9623e-04 - mae: 0.0039 - val_loss: 4.1487e-04 - val_mae: 0.0058\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.9391e-04 - mae: 0.0038 - val_loss: 3.8827e-04 - val_mae: 0.0035\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.9250e-04 - mae: 0.0038 - val_loss: 3.9260e-04 - val_mae: 0.0039\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.9208e-04 - mae: 0.0038 - val_loss: 3.8382e-04 - val_mae: 0.0032\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.9303e-04 - mae: 0.0040 - val_loss: 3.8244e-04 - val_mae: 0.0031\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.9030e-04 - mae: 0.0038 - val_loss: 3.9700e-04 - val_mae: 0.0046\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.9018e-04 - mae: 0.0040 - val_loss: 3.8223e-04 - val_mae: 0.0034\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.8714e-04 - mae: 0.0038 - val_loss: 3.8305e-04 - val_mae: 0.0035\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.8974e-04 - mae: 0.0041 - val_loss: 3.7777e-04 - val_mae: 0.0032\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.8507e-04 - mae: 0.0038 - val_loss: 3.8197e-04 - val_mae: 0.0038\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.8632e-04 - mae: 0.0039 - val_loss: 3.7528e-04 - val_mae: 0.0031\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.8442e-04 - mae: 0.0039 - val_loss: 3.7777e-04 - val_mae: 0.0035\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.8377e-04 - mae: 0.0039 - val_loss: 3.7830e-04 - val_mae: 0.0035\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.8232e-04 - mae: 0.0039 - val_loss: 3.7332e-04 - val_mae: 0.0032\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.8374e-04 - mae: 0.0041 - val_loss: 3.8114e-04 - val_mae: 0.0040\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.7961e-04 - mae: 0.0038 - val_loss: 3.7249e-04 - val_mae: 0.0033\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.7903e-04 - mae: 0.0038 - val_loss: 3.7119e-04 - val_mae: 0.0033\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.7627e-04 - mae: 0.0037 - val_loss: 3.7366e-04 - val_mae: 0.0036\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.7677e-04 - mae: 0.0038 - val_loss: 3.8259e-04 - val_mae: 0.0046\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.7623e-04 - mae: 0.0038 - val_loss: 3.7854e-04 - val_mae: 0.0044\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.7572e-04 - mae: 0.0039 - val_loss: 3.6641e-04 - val_mae: 0.0032\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.7296e-04 - mae: 0.0037 - val_loss: 3.6712e-04 - val_mae: 0.0033\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.7240e-04 - mae: 0.0038 - val_loss: 3.8647e-04 - val_mae: 0.0051\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.7154e-04 - mae: 0.0037 - val_loss: 3.6663e-04 - val_mae: 0.0035\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.7234e-04 - mae: 0.0039 - val_loss: 3.7866e-04 - val_mae: 0.0048\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 3.7174e-04 - mae: 0.0040Restoring model weights from the end of the best epoch: 429.\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.7174e-04 - mae: 0.0040 - val_loss: 3.7448e-04 - val_mae: 0.0043\n",
      "Epoch 434: early stopping\n",
      "Training fÃ¼r Fold 2...\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 4s 6ms/step - loss: 0.0647 - mae: 0.1071 - val_loss: 0.0292 - val_mae: 0.0510\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0271 - mae: 0.0424 - val_loss: 0.0252 - val_mae: 0.0358\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0239 - mae: 0.0304 - val_loss: 0.0229 - val_mae: 0.0272\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0222 - mae: 0.0243 - val_loss: 0.0216 - val_mae: 0.0218\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0211 - mae: 0.0206 - val_loss: 0.0208 - val_mae: 0.0200\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0203 - mae: 0.0178 - val_loss: 0.0200 - val_mae: 0.0167\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0197 - mae: 0.0159 - val_loss: 0.0195 - val_mae: 0.0147\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0192 - mae: 0.0140 - val_loss: 0.0190 - val_mae: 0.0138\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0188 - mae: 0.0125 - val_loss: 0.0186 - val_mae: 0.0124\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0184 - mae: 0.0113 - val_loss: 0.0183 - val_mae: 0.0112\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0181 - mae: 0.0111 - val_loss: 0.0180 - val_mae: 0.0106\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0178 - mae: 0.0102 - val_loss: 0.0176 - val_mae: 0.0096\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0175 - mae: 0.0095 - val_loss: 0.0173 - val_mae: 0.0091\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0172 - mae: 0.0096 - val_loss: 0.0171 - val_mae: 0.0104\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0170 - mae: 0.0097 - val_loss: 0.0168 - val_mae: 0.0090\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0167 - mae: 0.0093 - val_loss: 0.0165 - val_mae: 0.0094\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0164 - mae: 0.0093 - val_loss: 0.0162 - val_mae: 0.0095\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0161 - mae: 0.0090 - val_loss: 0.0159 - val_mae: 0.0076\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0158 - mae: 0.0083 - val_loss: 0.0157 - val_mae: 0.0085\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0155 - mae: 0.0080 - val_loss: 0.0154 - val_mae: 0.0100\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0153 - mae: 0.0087 - val_loss: 0.0152 - val_mae: 0.0114\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0150 - mae: 0.0084 - val_loss: 0.0149 - val_mae: 0.0094\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0147 - mae: 0.0088 - val_loss: 0.0146 - val_mae: 0.0083\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0144 - mae: 0.0081 - val_loss: 0.0143 - val_mae: 0.0075\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0141 - mae: 0.0080 - val_loss: 0.0141 - val_mae: 0.0095\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0139 - mae: 0.0080 - val_loss: 0.0137 - val_mae: 0.0078\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0136 - mae: 0.0075 - val_loss: 0.0135 - val_mae: 0.0080\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0134 - mae: 0.0082 - val_loss: 0.0132 - val_mae: 0.0073\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0131 - mae: 0.0083 - val_loss: 0.0129 - val_mae: 0.0071\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0128 - mae: 0.0072 - val_loss: 0.0127 - val_mae: 0.0069\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0126 - mae: 0.0078 - val_loss: 0.0124 - val_mae: 0.0071\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0123 - mae: 0.0077 - val_loss: 0.0123 - val_mae: 0.0105\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0121 - mae: 0.0072 - val_loss: 0.0120 - val_mae: 0.0088\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0119 - mae: 0.0079 - val_loss: 0.0117 - val_mae: 0.0074\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0116 - mae: 0.0068 - val_loss: 0.0115 - val_mae: 0.0060\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0114 - mae: 0.0072 - val_loss: 0.0115 - val_mae: 0.0134\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0112 - mae: 0.0076 - val_loss: 0.0112 - val_mae: 0.0112\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0109 - mae: 0.0072 - val_loss: 0.0108 - val_mae: 0.0058\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0107 - mae: 0.0064 - val_loss: 0.0106 - val_mae: 0.0076\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0105 - mae: 0.0077 - val_loss: 0.0104 - val_mae: 0.0088\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0103 - mae: 0.0065 - val_loss: 0.0102 - val_mae: 0.0073\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0101 - mae: 0.0064 - val_loss: 0.0100 - val_mae: 0.0060\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0099 - mae: 0.0064 - val_loss: 0.0098 - val_mae: 0.0071\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0097 - mae: 0.0072 - val_loss: 0.0096 - val_mae: 0.0066\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0095 - mae: 0.0063 - val_loss: 0.0094 - val_mae: 0.0052\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0094 - mae: 0.0066 - val_loss: 0.0093 - val_mae: 0.0066\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0092 - mae: 0.0069 - val_loss: 0.0091 - val_mae: 0.0057\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0090 - mae: 0.0065 - val_loss: 0.0089 - val_mae: 0.0060\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0088 - mae: 0.0063 - val_loss: 0.0088 - val_mae: 0.0066\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0087 - mae: 0.0065 - val_loss: 0.0086 - val_mae: 0.0076\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0085 - mae: 0.0065 - val_loss: 0.0085 - val_mae: 0.0060\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0084 - mae: 0.0063 - val_loss: 0.0083 - val_mae: 0.0060\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0082 - mae: 0.0063 - val_loss: 0.0082 - val_mae: 0.0062\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0081 - mae: 0.0063 - val_loss: 0.0080 - val_mae: 0.0056\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0080 - mae: 0.0059 - val_loss: 0.0079 - val_mae: 0.0072\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0078 - mae: 0.0057 - val_loss: 0.0078 - val_mae: 0.0053\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0077 - mae: 0.0060 - val_loss: 0.0076 - val_mae: 0.0059\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0076 - mae: 0.0061 - val_loss: 0.0075 - val_mae: 0.0051\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0074 - mae: 0.0063 - val_loss: 0.0074 - val_mae: 0.0070\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0073 - mae: 0.0063 - val_loss: 0.0073 - val_mae: 0.0062\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0072 - mae: 0.0056 - val_loss: 0.0072 - val_mae: 0.0065\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0071 - mae: 0.0058 - val_loss: 0.0070 - val_mae: 0.0066\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0070 - mae: 0.0060 - val_loss: 0.0069 - val_mae: 0.0061\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0069 - mae: 0.0057 - val_loss: 0.0068 - val_mae: 0.0054\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0067 - mae: 0.0056 - val_loss: 0.0067 - val_mae: 0.0056\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0066 - mae: 0.0060 - val_loss: 0.0066 - val_mae: 0.0072\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0065 - mae: 0.0059 - val_loss: 0.0065 - val_mae: 0.0057\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0064 - mae: 0.0060 - val_loss: 0.0064 - val_mae: 0.0051\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0063 - mae: 0.0056 - val_loss: 0.0063 - val_mae: 0.0045\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0062 - mae: 0.0054 - val_loss: 0.0062 - val_mae: 0.0077\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0061 - mae: 0.0056 - val_loss: 0.0061 - val_mae: 0.0054\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0060 - mae: 0.0056 - val_loss: 0.0060 - val_mae: 0.0048\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0060 - mae: 0.0060 - val_loss: 0.0059 - val_mae: 0.0053\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0059 - mae: 0.0054 - val_loss: 0.0058 - val_mae: 0.0050\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0058 - mae: 0.0055 - val_loss: 0.0057 - val_mae: 0.0059\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0057 - mae: 0.0053 - val_loss: 0.0056 - val_mae: 0.0052\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0056 - mae: 0.0058 - val_loss: 0.0056 - val_mae: 0.0068\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0055 - mae: 0.0052 - val_loss: 0.0055 - val_mae: 0.0056\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0054 - mae: 0.0055 - val_loss: 0.0054 - val_mae: 0.0046\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0053 - mae: 0.0054 - val_loss: 0.0053 - val_mae: 0.0048\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0053 - mae: 0.0053 - val_loss: 0.0052 - val_mae: 0.0052\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0052 - mae: 0.0058 - val_loss: 0.0051 - val_mae: 0.0053\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0051 - mae: 0.0053 - val_loss: 0.0051 - val_mae: 0.0052\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0050 - mae: 0.0051 - val_loss: 0.0050 - val_mae: 0.0059\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0050 - mae: 0.0052 - val_loss: 0.0049 - val_mae: 0.0047\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0049 - mae: 0.0053 - val_loss: 0.0048 - val_mae: 0.0050\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0048 - mae: 0.0055 - val_loss: 0.0048 - val_mae: 0.0059\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0047 - mae: 0.0053 - val_loss: 0.0047 - val_mae: 0.0047\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0047 - mae: 0.0053 - val_loss: 0.0046 - val_mae: 0.0055\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0046 - mae: 0.0052 - val_loss: 0.0046 - val_mae: 0.0052\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0045 - mae: 0.0051 - val_loss: 0.0045 - val_mae: 0.0051\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0045 - mae: 0.0057 - val_loss: 0.0044 - val_mae: 0.0048\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0044 - mae: 0.0053 - val_loss: 0.0044 - val_mae: 0.0047\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0043 - mae: 0.0052 - val_loss: 0.0043 - val_mae: 0.0056\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0043 - mae: 0.0050 - val_loss: 0.0043 - val_mae: 0.0060\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0042 - mae: 0.0053 - val_loss: 0.0042 - val_mae: 0.0057\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0041 - mae: 0.0051 - val_loss: 0.0042 - val_mae: 0.0065\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0041 - mae: 0.0052 - val_loss: 0.0041 - val_mae: 0.0048\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0040 - mae: 0.0051 - val_loss: 0.0040 - val_mae: 0.0068\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0040 - mae: 0.0049 - val_loss: 0.0039 - val_mae: 0.0044\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0039 - mae: 0.0052 - val_loss: 0.0039 - val_mae: 0.0045\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0039 - mae: 0.0051 - val_loss: 0.0038 - val_mae: 0.0055\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0038 - mae: 0.0051 - val_loss: 0.0038 - val_mae: 0.0060\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0038 - mae: 0.0054 - val_loss: 0.0037 - val_mae: 0.0059\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0037 - mae: 0.0052 - val_loss: 0.0037 - val_mae: 0.0046\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0036 - mae: 0.0048 - val_loss: 0.0036 - val_mae: 0.0051\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0036 - mae: 0.0048 - val_loss: 0.0036 - val_mae: 0.0053\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0035 - mae: 0.0051 - val_loss: 0.0035 - val_mae: 0.0049\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0035 - mae: 0.0052 - val_loss: 0.0035 - val_mae: 0.0056\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0035 - mae: 0.0050 - val_loss: 0.0034 - val_mae: 0.0047\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0034 - mae: 0.0051 - val_loss: 0.0034 - val_mae: 0.0047\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0034 - mae: 0.0049 - val_loss: 0.0033 - val_mae: 0.0043\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0033 - mae: 0.0050 - val_loss: 0.0033 - val_mae: 0.0045\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0033 - mae: 0.0051 - val_loss: 0.0032 - val_mae: 0.0047\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0032 - mae: 0.0049 - val_loss: 0.0032 - val_mae: 0.0041\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0032 - mae: 0.0048 - val_loss: 0.0032 - val_mae: 0.0049\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0031 - mae: 0.0049 - val_loss: 0.0031 - val_mae: 0.0054\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0031 - mae: 0.0052 - val_loss: 0.0031 - val_mae: 0.0056\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0031 - mae: 0.0050 - val_loss: 0.0030 - val_mae: 0.0053\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0030 - mae: 0.0052 - val_loss: 0.0030 - val_mae: 0.0039\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0030 - mae: 0.0046 - val_loss: 0.0030 - val_mae: 0.0047\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0029 - mae: 0.0048 - val_loss: 0.0029 - val_mae: 0.0043\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0029 - mae: 0.0050 - val_loss: 0.0029 - val_mae: 0.0064\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0029 - mae: 0.0049 - val_loss: 0.0028 - val_mae: 0.0046\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0028 - mae: 0.0052 - val_loss: 0.0028 - val_mae: 0.0046\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0028 - mae: 0.0049 - val_loss: 0.0028 - val_mae: 0.0058\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0028 - mae: 0.0047 - val_loss: 0.0028 - val_mae: 0.0059\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0027 - mae: 0.0049 - val_loss: 0.0027 - val_mae: 0.0040\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0027 - mae: 0.0051 - val_loss: 0.0027 - val_mae: 0.0050\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0027 - mae: 0.0046 - val_loss: 0.0026 - val_mae: 0.0043\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0026 - mae: 0.0049 - val_loss: 0.0026 - val_mae: 0.0041\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0026 - mae: 0.0047 - val_loss: 0.0026 - val_mae: 0.0055\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0026 - mae: 0.0048 - val_loss: 0.0025 - val_mae: 0.0041\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0025 - mae: 0.0049 - val_loss: 0.0025 - val_mae: 0.0048\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0025 - mae: 0.0048 - val_loss: 0.0025 - val_mae: 0.0061\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0025 - mae: 0.0049 - val_loss: 0.0024 - val_mae: 0.0045\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0024 - mae: 0.0051 - val_loss: 0.0025 - val_mae: 0.0073\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0024 - mae: 0.0045 - val_loss: 0.0024 - val_mae: 0.0046\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0024 - mae: 0.0046 - val_loss: 0.0024 - val_mae: 0.0071\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0023 - mae: 0.0045 - val_loss: 0.0023 - val_mae: 0.0045\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0023 - mae: 0.0046 - val_loss: 0.0023 - val_mae: 0.0052\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0023 - mae: 0.0047 - val_loss: 0.0023 - val_mae: 0.0037\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0023 - mae: 0.0047 - val_loss: 0.0023 - val_mae: 0.0089\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0022 - mae: 0.0050 - val_loss: 0.0022 - val_mae: 0.0040\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0022 - mae: 0.0046 - val_loss: 0.0022 - val_mae: 0.0039\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0022 - mae: 0.0047 - val_loss: 0.0022 - val_mae: 0.0048\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0022 - mae: 0.0047 - val_loss: 0.0021 - val_mae: 0.0047\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0021 - mae: 0.0049 - val_loss: 0.0021 - val_mae: 0.0054\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0021 - mae: 0.0047 - val_loss: 0.0021 - val_mae: 0.0038\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0021 - mae: 0.0046 - val_loss: 0.0021 - val_mae: 0.0044\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0021 - mae: 0.0044 - val_loss: 0.0020 - val_mae: 0.0037\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0020 - mae: 0.0046 - val_loss: 0.0020 - val_mae: 0.0062\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0020 - mae: 0.0045 - val_loss: 0.0020 - val_mae: 0.0040\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0020 - mae: 0.0045 - val_loss: 0.0020 - val_mae: 0.0037\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0020 - mae: 0.0043 - val_loss: 0.0020 - val_mae: 0.0062\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0020 - mae: 0.0048 - val_loss: 0.0019 - val_mae: 0.0053\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0019 - mae: 0.0046 - val_loss: 0.0019 - val_mae: 0.0049\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0019 - mae: 0.0045 - val_loss: 0.0019 - val_mae: 0.0047\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0019 - mae: 0.0046 - val_loss: 0.0019 - val_mae: 0.0042\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0019 - mae: 0.0044 - val_loss: 0.0018 - val_mae: 0.0042\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0018 - mae: 0.0046 - val_loss: 0.0018 - val_mae: 0.0045\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0018 - mae: 0.0044 - val_loss: 0.0018 - val_mae: 0.0051\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0018 - mae: 0.0044 - val_loss: 0.0018 - val_mae: 0.0039\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0018 - mae: 0.0046 - val_loss: 0.0018 - val_mae: 0.0038\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0018 - mae: 0.0046 - val_loss: 0.0018 - val_mae: 0.0048\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0017 - mae: 0.0044 - val_loss: 0.0017 - val_mae: 0.0039\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0017 - mae: 0.0043 - val_loss: 0.0017 - val_mae: 0.0056\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0017 - mae: 0.0045 - val_loss: 0.0017 - val_mae: 0.0039\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0017 - mae: 0.0047 - val_loss: 0.0017 - val_mae: 0.0046\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0017 - mae: 0.0044 - val_loss: 0.0017 - val_mae: 0.0044\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0044\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0042\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0052\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0074\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0016 - mae: 0.0047 - val_loss: 0.0017 - val_mae: 0.0088\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0016 - mae: 0.0043 - val_loss: 0.0016 - val_mae: 0.0041\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0016 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0038\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0015 - mae: 0.0047 - val_loss: 0.0016 - val_mae: 0.0062\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0015 - mae: 0.0041 - val_loss: 0.0015 - val_mae: 0.0064\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 0.0015 - val_mae: 0.0044\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0046\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0015 - mae: 0.0049 - val_loss: 0.0015 - val_mae: 0.0038\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0015 - mae: 0.0041 - val_loss: 0.0015 - val_mae: 0.0046\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0049\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0038\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0036\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0014 - mae: 0.0041 - val_loss: 0.0014 - val_mae: 0.0038\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0040\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0040\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0014 - mae: 0.0046 - val_loss: 0.0014 - val_mae: 0.0038\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0014 - mae: 0.0046 - val_loss: 0.0013 - val_mae: 0.0034\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0040\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0051\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0036\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0036\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0037\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0041\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0039\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0013 - mae: 0.0040 - val_loss: 0.0012 - val_mae: 0.0037\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0041 - val_loss: 0.0012 - val_mae: 0.0042\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0045 - val_loss: 0.0012 - val_mae: 0.0044\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0063\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0012 - mae: 0.0041 - val_loss: 0.0012 - val_mae: 0.0036\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0012 - mae: 0.0041 - val_loss: 0.0012 - val_mae: 0.0039\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0012 - mae: 0.0044 - val_loss: 0.0012 - val_mae: 0.0034\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0048\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0046 - val_loss: 0.0012 - val_mae: 0.0041\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0046 - val_loss: 0.0012 - val_mae: 0.0040\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0043\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0040 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0038\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0037\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0041\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0036\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0040 - val_loss: 0.0011 - val_mae: 0.0037\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0048\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0040 - val_loss: 0.0011 - val_mae: 0.0042\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0043\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0010 - mae: 0.0041 - val_loss: 0.0010 - val_mae: 0.0046\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0010 - mae: 0.0045 - val_loss: 0.0010 - val_mae: 0.0034\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0010 - mae: 0.0041 - val_loss: 0.0010 - val_mae: 0.0056\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0010 - mae: 0.0042 - val_loss: 0.0010 - val_mae: 0.0041\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0010 - mae: 0.0041 - val_loss: 0.0010 - val_mae: 0.0045\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0010 - mae: 0.0041 - val_loss: 9.9911e-04 - val_mae: 0.0041\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.9814e-04 - mae: 0.0043 - val_loss: 0.0010 - val_mae: 0.0054\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.8936e-04 - mae: 0.0042 - val_loss: 9.8030e-04 - val_mae: 0.0035\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 9.8053e-04 - mae: 0.0041 - val_loss: 9.8099e-04 - val_mae: 0.0043\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 9.7407e-04 - mae: 0.0042 - val_loss: 9.6204e-04 - val_mae: 0.0034\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 9.6653e-04 - mae: 0.0042 - val_loss: 9.6059e-04 - val_mae: 0.0039\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 9.5819e-04 - mae: 0.0041 - val_loss: 9.5087e-04 - val_mae: 0.0037\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.5128e-04 - mae: 0.0041 - val_loss: 9.4597e-04 - val_mae: 0.0039\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 9.4392e-04 - mae: 0.0041 - val_loss: 9.3229e-04 - val_mae: 0.0034\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.3828e-04 - mae: 0.0043 - val_loss: 9.5990e-04 - val_mae: 0.0061\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.3197e-04 - mae: 0.0043 - val_loss: 9.2396e-04 - val_mae: 0.0039\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.2170e-04 - mae: 0.0040 - val_loss: 9.1464e-04 - val_mae: 0.0036\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.1818e-04 - mae: 0.0042 - val_loss: 9.0727e-04 - val_mae: 0.0036\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 9.0640e-04 - mae: 0.0038 - val_loss: 9.0102e-04 - val_mae: 0.0036\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 9.0348e-04 - mae: 0.0042 - val_loss: 8.9396e-04 - val_mae: 0.0035\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 8.9749e-04 - mae: 0.0042 - val_loss: 9.0734e-04 - val_mae: 0.0053\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.9062e-04 - mae: 0.0042 - val_loss: 8.8586e-04 - val_mae: 0.0039\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.8546e-04 - mae: 0.0043 - val_loss: 8.8180e-04 - val_mae: 0.0042\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 8.7662e-04 - mae: 0.0041 - val_loss: 8.7362e-04 - val_mae: 0.0042\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 8.7138e-04 - mae: 0.0041 - val_loss: 8.6892e-04 - val_mae: 0.0041\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.6873e-04 - mae: 0.0043 - val_loss: 8.6933e-04 - val_mae: 0.0045\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 8.5891e-04 - mae: 0.0040 - val_loss: 8.5245e-04 - val_mae: 0.0038\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 8.5269e-04 - mae: 0.0040 - val_loss: 8.4384e-04 - val_mae: 0.0034\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 8.4685e-04 - mae: 0.0040 - val_loss: 8.4406e-04 - val_mae: 0.0041\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.3961e-04 - mae: 0.0039 - val_loss: 8.3274e-04 - val_mae: 0.0036\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 8.3654e-04 - mae: 0.0042 - val_loss: 8.2728e-04 - val_mae: 0.0036\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 8.2891e-04 - mae: 0.0040 - val_loss: 8.2017e-04 - val_mae: 0.0034\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 8.2428e-04 - mae: 0.0041 - val_loss: 8.7955e-04 - val_mae: 0.0079\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.1866e-04 - mae: 0.0041 - val_loss: 8.1818e-04 - val_mae: 0.0044\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 8.1642e-04 - mae: 0.0043 - val_loss: 8.1826e-04 - val_mae: 0.0046\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.0597e-04 - mae: 0.0039 - val_loss: 7.9830e-04 - val_mae: 0.0034\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.9882e-04 - mae: 0.0038 - val_loss: 7.9059e-04 - val_mae: 0.0033\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.9726e-04 - mae: 0.0041 - val_loss: 7.8656e-04 - val_mae: 0.0034\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.9150e-04 - mae: 0.0041 - val_loss: 7.8140e-04 - val_mae: 0.0034\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.8516e-04 - mae: 0.0040 - val_loss: 7.8380e-04 - val_mae: 0.0039\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.8137e-04 - mae: 0.0041 - val_loss: 7.7666e-04 - val_mae: 0.0039\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.7683e-04 - mae: 0.0041 - val_loss: 7.6578e-04 - val_mae: 0.0033\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.6912e-04 - mae: 0.0040 - val_loss: 7.6198e-04 - val_mae: 0.0035\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.6485e-04 - mae: 0.0040 - val_loss: 7.6521e-04 - val_mae: 0.0042\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.6194e-04 - mae: 0.0041 - val_loss: 7.5532e-04 - val_mae: 0.0039\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.5516e-04 - mae: 0.0040 - val_loss: 7.6407e-04 - val_mae: 0.0048\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.5038e-04 - mae: 0.0040 - val_loss: 7.4666e-04 - val_mae: 0.0039\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.4689e-04 - mae: 0.0041 - val_loss: 7.3603e-04 - val_mae: 0.0033\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.4165e-04 - mae: 0.0041 - val_loss: 7.4427e-04 - val_mae: 0.0044\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.3538e-04 - mae: 0.0039 - val_loss: 7.3987e-04 - val_mae: 0.0046\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.3276e-04 - mae: 0.0041 - val_loss: 7.2203e-04 - val_mae: 0.0033\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.2491e-04 - mae: 0.0038 - val_loss: 7.4850e-04 - val_mae: 0.0060\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.2450e-04 - mae: 0.0042 - val_loss: 7.1492e-04 - val_mae: 0.0035\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.1718e-04 - mae: 0.0039 - val_loss: 7.0966e-04 - val_mae: 0.0034\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.1425e-04 - mae: 0.0041 - val_loss: 7.0697e-04 - val_mae: 0.0036\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.1306e-04 - mae: 0.0043 - val_loss: 7.0250e-04 - val_mae: 0.0036\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.0370e-04 - mae: 0.0039 - val_loss: 6.9812e-04 - val_mae: 0.0035\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.0572e-04 - mae: 0.0044 - val_loss: 7.0843e-04 - val_mae: 0.0047\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 6.9827e-04 - mae: 0.0041 - val_loss: 7.0189e-04 - val_mae: 0.0046\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 6.9312e-04 - mae: 0.0040 - val_loss: 6.8720e-04 - val_mae: 0.0037\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.8765e-04 - mae: 0.0039 - val_loss: 6.8819e-04 - val_mae: 0.0042\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.8257e-04 - mae: 0.0038 - val_loss: 6.8250e-04 - val_mae: 0.0040\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.8334e-04 - mae: 0.0042 - val_loss: 6.7481e-04 - val_mae: 0.0036\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.7580e-04 - mae: 0.0039 - val_loss: 6.7691e-04 - val_mae: 0.0041\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 6.7224e-04 - mae: 0.0039 - val_loss: 6.7457e-04 - val_mae: 0.0043\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.7157e-04 - mae: 0.0043 - val_loss: 6.6082e-04 - val_mae: 0.0034\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.6460e-04 - mae: 0.0039 - val_loss: 6.7471e-04 - val_mae: 0.0051\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.6110e-04 - mae: 0.0040 - val_loss: 6.6061e-04 - val_mae: 0.0042\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.6197e-04 - mae: 0.0043 - val_loss: 6.4902e-04 - val_mae: 0.0033\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.5282e-04 - mae: 0.0039 - val_loss: 6.4800e-04 - val_mae: 0.0036\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 6.5065e-04 - mae: 0.0040 - val_loss: 6.5479e-04 - val_mae: 0.0045\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.5110e-04 - mae: 0.0042 - val_loss: 6.3959e-04 - val_mae: 0.0034\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 6.4461e-04 - mae: 0.0041 - val_loss: 6.3694e-04 - val_mae: 0.0036\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.3903e-04 - mae: 0.0039 - val_loss: 6.3022e-04 - val_mae: 0.0032\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.3523e-04 - mae: 0.0039 - val_loss: 6.4048e-04 - val_mae: 0.0046\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.3627e-04 - mae: 0.0042 - val_loss: 6.2572e-04 - val_mae: 0.0034\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 6.3370e-04 - mae: 0.0043 - val_loss: 6.3112e-04 - val_mae: 0.0042\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.2528e-04 - mae: 0.0039 - val_loss: 6.1726e-04 - val_mae: 0.0033\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.2367e-04 - mae: 0.0040 - val_loss: 6.2375e-04 - val_mae: 0.0041\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.2309e-04 - mae: 0.0042 - val_loss: 6.4823e-04 - val_mae: 0.0061\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 6.1610e-04 - mae: 0.0039 - val_loss: 6.0876e-04 - val_mae: 0.0034\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 6.1193e-04 - mae: 0.0038 - val_loss: 6.1213e-04 - val_mae: 0.0040\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.1051e-04 - mae: 0.0040 - val_loss: 6.1424e-04 - val_mae: 0.0046\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.1312e-04 - mae: 0.0045 - val_loss: 6.0582e-04 - val_mae: 0.0040\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.0373e-04 - mae: 0.0039 - val_loss: 6.0651e-04 - val_mae: 0.0043\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.0039e-04 - mae: 0.0039 - val_loss: 6.0415e-04 - val_mae: 0.0044\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.9732e-04 - mae: 0.0039 - val_loss: 6.3725e-04 - val_mae: 0.0072\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.9457e-04 - mae: 0.0039 - val_loss: 6.2127e-04 - val_mae: 0.0061\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.9107e-04 - mae: 0.0039 - val_loss: 6.0614e-04 - val_mae: 0.0053\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.8717e-04 - mae: 0.0038 - val_loss: 5.8846e-04 - val_mae: 0.0042\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.8724e-04 - mae: 0.0041 - val_loss: 5.7877e-04 - val_mae: 0.0035\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.8364e-04 - mae: 0.0041 - val_loss: 5.7473e-04 - val_mae: 0.0034\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.7725e-04 - mae: 0.0038 - val_loss: 5.9180e-04 - val_mae: 0.0053\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.7740e-04 - mae: 0.0040 - val_loss: 5.6900e-04 - val_mae: 0.0033\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.7288e-04 - mae: 0.0039 - val_loss: 5.8927e-04 - val_mae: 0.0053\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.7339e-04 - mae: 0.0042 - val_loss: 5.6767e-04 - val_mae: 0.0038\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.6648e-04 - mae: 0.0038 - val_loss: 5.6832e-04 - val_mae: 0.0041\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.6848e-04 - mae: 0.0042 - val_loss: 5.6038e-04 - val_mae: 0.0037\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.6257e-04 - mae: 0.0040 - val_loss: 5.7465e-04 - val_mae: 0.0049\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.6277e-04 - mae: 0.0042 - val_loss: 5.5186e-04 - val_mae: 0.0033\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.5741e-04 - mae: 0.0040 - val_loss: 5.4920e-04 - val_mae: 0.0033\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.5307e-04 - mae: 0.0038 - val_loss: 5.6376e-04 - val_mae: 0.0045\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.5342e-04 - mae: 0.0041 - val_loss: 5.4969e-04 - val_mae: 0.0039\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.5090e-04 - mae: 0.0041 - val_loss: 5.4623e-04 - val_mae: 0.0039\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.4654e-04 - mae: 0.0039 - val_loss: 5.4762e-04 - val_mae: 0.0041\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.4520e-04 - mae: 0.0040 - val_loss: 5.3991e-04 - val_mae: 0.0037\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.4229e-04 - mae: 0.0040 - val_loss: 5.4395e-04 - val_mae: 0.0044\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.4027e-04 - mae: 0.0040 - val_loss: 5.3096e-04 - val_mae: 0.0032\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.3473e-04 - mae: 0.0038 - val_loss: 5.3412e-04 - val_mae: 0.0038\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.3510e-04 - mae: 0.0040 - val_loss: 5.4489e-04 - val_mae: 0.0049\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.3188e-04 - mae: 0.0040 - val_loss: 5.3523e-04 - val_mae: 0.0045\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.2956e-04 - mae: 0.0039 - val_loss: 5.2833e-04 - val_mae: 0.0039\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.2849e-04 - mae: 0.0040 - val_loss: 5.2115e-04 - val_mae: 0.0035\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.2566e-04 - mae: 0.0040 - val_loss: 5.2691e-04 - val_mae: 0.0041\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.2219e-04 - mae: 0.0039 - val_loss: 5.1440e-04 - val_mae: 0.0033\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.1840e-04 - mae: 0.0038 - val_loss: 5.1832e-04 - val_mae: 0.0038\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.2080e-04 - mae: 0.0042 - val_loss: 5.1066e-04 - val_mae: 0.0033\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.1667e-04 - mae: 0.0040 - val_loss: 5.3858e-04 - val_mae: 0.0059\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.1355e-04 - mae: 0.0040 - val_loss: 5.0903e-04 - val_mae: 0.0037\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.1110e-04 - mae: 0.0040 - val_loss: 5.0467e-04 - val_mae: 0.0034\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.1039e-04 - mae: 0.0040 - val_loss: 5.2794e-04 - val_mae: 0.0056\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.0355e-04 - mae: 0.0037 - val_loss: 5.0121e-04 - val_mae: 0.0035\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.0687e-04 - mae: 0.0041 - val_loss: 5.0150e-04 - val_mae: 0.0038\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.0191e-04 - mae: 0.0039 - val_loss: 5.1632e-04 - val_mae: 0.0054\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.0106e-04 - mae: 0.0040 - val_loss: 4.9274e-04 - val_mae: 0.0033\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.9781e-04 - mae: 0.0039 - val_loss: 4.9139e-04 - val_mae: 0.0034\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.9343e-04 - mae: 0.0037 - val_loss: 4.9781e-04 - val_mae: 0.0043\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.9316e-04 - mae: 0.0039 - val_loss: 4.9134e-04 - val_mae: 0.0037\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.9234e-04 - mae: 0.0040 - val_loss: 5.0133e-04 - val_mae: 0.0048\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.9313e-04 - mae: 0.0042 - val_loss: 4.8195e-04 - val_mae: 0.0033\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.8554e-04 - mae: 0.0037 - val_loss: 4.9648e-04 - val_mae: 0.0050\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.8695e-04 - mae: 0.0040 - val_loss: 4.8592e-04 - val_mae: 0.0041\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.8774e-04 - mae: 0.0042 - val_loss: 4.8596e-04 - val_mae: 0.0044\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.8160e-04 - mae: 0.0039 - val_loss: 4.7837e-04 - val_mae: 0.0035\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.7928e-04 - mae: 0.0039 - val_loss: 4.8297e-04 - val_mae: 0.0042\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.8138e-04 - mae: 0.0042 - val_loss: 4.8025e-04 - val_mae: 0.0041\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.7496e-04 - mae: 0.0038 - val_loss: 4.7024e-04 - val_mae: 0.0033\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 4.7406e-04 - mae: 0.0039 - val_loss: 4.6564e-04 - val_mae: 0.0031\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 4.7387e-04 - mae: 0.0040 - val_loss: 4.8010e-04 - val_mae: 0.0046\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 4.6989e-04 - mae: 0.0038 - val_loss: 4.6340e-04 - val_mae: 0.0033\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 4.6992e-04 - mae: 0.0040 - val_loss: 4.9014e-04 - val_mae: 0.0058\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 4.6533e-04 - mae: 0.0038 - val_loss: 4.6916e-04 - val_mae: 0.0041\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 4.6581e-04 - mae: 0.0039 - val_loss: 4.6394e-04 - val_mae: 0.0040\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.6068e-04 - mae: 0.0037 - val_loss: 4.5600e-04 - val_mae: 0.0032\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 2s 9ms/step - loss: 4.6530e-04 - mae: 0.0042 - val_loss: 4.6270e-04 - val_mae: 0.0040\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 4.6157e-04 - mae: 0.0040 - val_loss: 4.7079e-04 - val_mae: 0.0048\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 4.5809e-04 - mae: 0.0039 - val_loss: 4.9654e-04 - val_mae: 0.0071\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.5683e-04 - mae: 0.0039 - val_loss: 5.2946e-04 - val_mae: 0.0090\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.5471e-04 - mae: 0.0039 - val_loss: 4.5258e-04 - val_mae: 0.0038\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 4.5496e-04 - mae: 0.0041 - val_loss: 4.5182e-04 - val_mae: 0.0037\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 4.5224e-04 - mae: 0.0040 - val_loss: 4.7135e-04 - val_mae: 0.0056\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.5025e-04 - mae: 0.0039 - val_loss: 4.4332e-04 - val_mae: 0.0033\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.4936e-04 - mae: 0.0040 - val_loss: 4.4945e-04 - val_mae: 0.0042\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.4554e-04 - mae: 0.0038 - val_loss: 4.3967e-04 - val_mae: 0.0033\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.4372e-04 - mae: 0.0038 - val_loss: 4.4326e-04 - val_mae: 0.0038\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.4207e-04 - mae: 0.0038 - val_loss: 4.5093e-04 - val_mae: 0.0046\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.4254e-04 - mae: 0.0039 - val_loss: 4.4341e-04 - val_mae: 0.0041\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.4294e-04 - mae: 0.0042 - val_loss: 4.3510e-04 - val_mae: 0.0035\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.3817e-04 - mae: 0.0038 - val_loss: 4.3479e-04 - val_mae: 0.0037\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.3853e-04 - mae: 0.0040 - val_loss: 4.3587e-04 - val_mae: 0.0038\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.3633e-04 - mae: 0.0039 - val_loss: 4.4526e-04 - val_mae: 0.0049\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.3236e-04 - mae: 0.0037 - val_loss: 4.4137e-04 - val_mae: 0.0046\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.3253e-04 - mae: 0.0039 - val_loss: 4.2656e-04 - val_mae: 0.0034\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.3078e-04 - mae: 0.0039 - val_loss: 4.3891e-04 - val_mae: 0.0045\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.2881e-04 - mae: 0.0038 - val_loss: 4.3859e-04 - val_mae: 0.0046\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.2649e-04 - mae: 0.0037 - val_loss: 4.4186e-04 - val_mae: 0.0052\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.2599e-04 - mae: 0.0038 - val_loss: 4.3055e-04 - val_mae: 0.0043\n",
      "Epoch 387/1000\n",
      "269/270 [============================>.] - ETA: 0s - loss: 4.2679e-04 - mae: 0.0040Restoring model weights from the end of the best epoch: 382.\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.2681e-04 - mae: 0.0040 - val_loss: 4.3876e-04 - val_mae: 0.0051\n",
      "Epoch 387: early stopping\n",
      "Training fÃ¼r Fold 3...\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 7s 9ms/step - loss: 0.0456 - mae: 0.0879 - val_loss: 0.0294 - val_mae: 0.0495\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0271 - mae: 0.0414 - val_loss: 0.0252 - val_mae: 0.0348\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0240 - mae: 0.0306 - val_loss: 0.0229 - val_mae: 0.0262\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0222 - mae: 0.0235 - val_loss: 0.0216 - val_mae: 0.0211\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0211 - mae: 0.0201 - val_loss: 0.0207 - val_mae: 0.0196\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0202 - mae: 0.0171 - val_loss: 0.0199 - val_mae: 0.0155\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0196 - mae: 0.0149 - val_loss: 0.0194 - val_mae: 0.0160\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0190 - mae: 0.0133 - val_loss: 0.0189 - val_mae: 0.0143\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0186 - mae: 0.0121 - val_loss: 0.0185 - val_mae: 0.0136\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0182 - mae: 0.0117 - val_loss: 0.0179 - val_mae: 0.0109\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0178 - mae: 0.0109 - val_loss: 0.0176 - val_mae: 0.0112\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0174 - mae: 0.0108 - val_loss: 0.0172 - val_mae: 0.0100\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0170 - mae: 0.0095 - val_loss: 0.0169 - val_mae: 0.0095\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0167 - mae: 0.0093 - val_loss: 0.0168 - val_mae: 0.0145\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0164 - mae: 0.0097 - val_loss: 0.0162 - val_mae: 0.0091\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0161 - mae: 0.0094 - val_loss: 0.0159 - val_mae: 0.0085\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0157 - mae: 0.0088 - val_loss: 0.0156 - val_mae: 0.0090\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0154 - mae: 0.0090 - val_loss: 0.0153 - val_mae: 0.0081\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0151 - mae: 0.0091 - val_loss: 0.0149 - val_mae: 0.0077\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0148 - mae: 0.0081 - val_loss: 0.0147 - val_mae: 0.0096\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0145 - mae: 0.0089 - val_loss: 0.0144 - val_mae: 0.0079\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0142 - mae: 0.0083 - val_loss: 0.0141 - val_mae: 0.0081\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0140 - mae: 0.0093 - val_loss: 0.0138 - val_mae: 0.0098\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0137 - mae: 0.0086 - val_loss: 0.0136 - val_mae: 0.0103\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0134 - mae: 0.0083 - val_loss: 0.0132 - val_mae: 0.0068\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0131 - mae: 0.0078 - val_loss: 0.0130 - val_mae: 0.0082\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0129 - mae: 0.0077 - val_loss: 0.0127 - val_mae: 0.0077\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0126 - mae: 0.0079 - val_loss: 0.0125 - val_mae: 0.0072\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0124 - mae: 0.0080 - val_loss: 0.0122 - val_mae: 0.0076\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0121 - mae: 0.0074 - val_loss: 0.0120 - val_mae: 0.0066\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0119 - mae: 0.0087 - val_loss: 0.0117 - val_mae: 0.0065\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0116 - mae: 0.0068 - val_loss: 0.0115 - val_mae: 0.0066\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0114 - mae: 0.0074 - val_loss: 0.0113 - val_mae: 0.0059\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0112 - mae: 0.0074 - val_loss: 0.0111 - val_mae: 0.0075\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0110 - mae: 0.0072 - val_loss: 0.0109 - val_mae: 0.0082\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0108 - mae: 0.0068 - val_loss: 0.0106 - val_mae: 0.0063\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0106 - mae: 0.0074 - val_loss: 0.0104 - val_mae: 0.0061\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0103 - mae: 0.0071 - val_loss: 0.0103 - val_mae: 0.0083\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0102 - mae: 0.0069 - val_loss: 0.0101 - val_mae: 0.0077\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0100 - mae: 0.0069 - val_loss: 0.0100 - val_mae: 0.0099\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0098 - mae: 0.0066 - val_loss: 0.0098 - val_mae: 0.0104\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0096 - mae: 0.0064 - val_loss: 0.0095 - val_mae: 0.0091\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0094 - mae: 0.0075 - val_loss: 0.0093 - val_mae: 0.0059\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0092 - mae: 0.0060 - val_loss: 0.0091 - val_mae: 0.0055\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0091 - mae: 0.0070 - val_loss: 0.0090 - val_mae: 0.0065\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0089 - mae: 0.0065 - val_loss: 0.0089 - val_mae: 0.0071\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0087 - mae: 0.0060 - val_loss: 0.0087 - val_mae: 0.0063\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0086 - mae: 0.0067 - val_loss: 0.0085 - val_mae: 0.0060\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0085 - mae: 0.0066 - val_loss: 0.0084 - val_mae: 0.0055\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0083 - mae: 0.0066 - val_loss: 0.0082 - val_mae: 0.0067\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0082 - mae: 0.0068 - val_loss: 0.0081 - val_mae: 0.0055\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0080 - mae: 0.0060 - val_loss: 0.0080 - val_mae: 0.0066\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0079 - mae: 0.0064 - val_loss: 0.0078 - val_mae: 0.0055\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0078 - mae: 0.0056 - val_loss: 0.0077 - val_mae: 0.0052\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0077 - mae: 0.0071 - val_loss: 0.0076 - val_mae: 0.0064\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0075 - mae: 0.0058 - val_loss: 0.0075 - val_mae: 0.0065\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0074 - mae: 0.0057 - val_loss: 0.0073 - val_mae: 0.0052\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0073 - mae: 0.0066 - val_loss: 0.0073 - val_mae: 0.0094\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0072 - mae: 0.0059 - val_loss: 0.0071 - val_mae: 0.0057\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0071 - mae: 0.0056 - val_loss: 0.0070 - val_mae: 0.0070\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0069 - mae: 0.0055 - val_loss: 0.0069 - val_mae: 0.0053\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0068 - mae: 0.0057 - val_loss: 0.0068 - val_mae: 0.0057\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0067 - mae: 0.0062 - val_loss: 0.0067 - val_mae: 0.0051\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0066 - mae: 0.0060 - val_loss: 0.0065 - val_mae: 0.0047\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0065 - mae: 0.0060 - val_loss: 0.0065 - val_mae: 0.0059\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0064 - mae: 0.0054 - val_loss: 0.0064 - val_mae: 0.0058\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0063 - mae: 0.0054 - val_loss: 0.0063 - val_mae: 0.0056\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0062 - mae: 0.0053 - val_loss: 0.0061 - val_mae: 0.0049\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0061 - mae: 0.0062 - val_loss: 0.0060 - val_mae: 0.0045\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0060 - mae: 0.0054 - val_loss: 0.0060 - val_mae: 0.0051\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0059 - mae: 0.0058 - val_loss: 0.0060 - val_mae: 0.0099\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0058 - mae: 0.0056 - val_loss: 0.0058 - val_mae: 0.0050\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0057 - mae: 0.0057 - val_loss: 0.0058 - val_mae: 0.0089\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0057 - mae: 0.0055 - val_loss: 0.0056 - val_mae: 0.0050\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0056 - mae: 0.0057 - val_loss: 0.0055 - val_mae: 0.0051\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0055 - mae: 0.0052 - val_loss: 0.0054 - val_mae: 0.0051\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0054 - mae: 0.0055 - val_loss: 0.0053 - val_mae: 0.0048\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0053 - mae: 0.0059 - val_loss: 0.0053 - val_mae: 0.0091\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0052 - mae: 0.0055 - val_loss: 0.0052 - val_mae: 0.0057\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0052 - mae: 0.0052 - val_loss: 0.0051 - val_mae: 0.0053\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0051 - mae: 0.0053 - val_loss: 0.0050 - val_mae: 0.0055\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0050 - mae: 0.0050 - val_loss: 0.0050 - val_mae: 0.0054\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0049 - mae: 0.0055 - val_loss: 0.0049 - val_mae: 0.0048\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0049 - mae: 0.0054 - val_loss: 0.0048 - val_mae: 0.0053\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0048 - mae: 0.0056 - val_loss: 0.0047 - val_mae: 0.0048\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0047 - mae: 0.0055 - val_loss: 0.0047 - val_mae: 0.0047\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0046 - mae: 0.0048 - val_loss: 0.0046 - val_mae: 0.0046\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0046 - mae: 0.0051 - val_loss: 0.0045 - val_mae: 0.0047\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0045 - mae: 0.0051 - val_loss: 0.0045 - val_mae: 0.0051\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0044 - mae: 0.0051 - val_loss: 0.0044 - val_mae: 0.0044\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0044 - mae: 0.0057 - val_loss: 0.0043 - val_mae: 0.0046\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0043 - mae: 0.0053 - val_loss: 0.0043 - val_mae: 0.0049\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0042 - mae: 0.0053 - val_loss: 0.0042 - val_mae: 0.0050\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0042 - mae: 0.0052 - val_loss: 0.0041 - val_mae: 0.0043\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0041 - mae: 0.0053 - val_loss: 0.0041 - val_mae: 0.0053\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0041 - mae: 0.0051 - val_loss: 0.0040 - val_mae: 0.0050\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0040 - mae: 0.0050 - val_loss: 0.0040 - val_mae: 0.0041\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0040 - mae: 0.0053 - val_loss: 0.0039 - val_mae: 0.0043\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0039 - mae: 0.0048 - val_loss: 0.0039 - val_mae: 0.0044\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0038 - mae: 0.0052 - val_loss: 0.0038 - val_mae: 0.0046\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0038 - mae: 0.0048 - val_loss: 0.0037 - val_mae: 0.0044\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0037 - mae: 0.0053 - val_loss: 0.0037 - val_mae: 0.0047\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0037 - mae: 0.0051 - val_loss: 0.0036 - val_mae: 0.0047\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0036 - mae: 0.0050 - val_loss: 0.0036 - val_mae: 0.0044\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0036 - mae: 0.0050 - val_loss: 0.0035 - val_mae: 0.0044\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0035 - mae: 0.0046 - val_loss: 0.0035 - val_mae: 0.0047\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0035 - mae: 0.0054 - val_loss: 0.0034 - val_mae: 0.0044\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0034 - mae: 0.0046 - val_loss: 0.0034 - val_mae: 0.0044\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0034 - mae: 0.0049 - val_loss: 0.0034 - val_mae: 0.0052\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0033 - mae: 0.0048 - val_loss: 0.0033 - val_mae: 0.0040\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0033 - mae: 0.0049 - val_loss: 0.0033 - val_mae: 0.0078\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0032 - mae: 0.0049 - val_loss: 0.0032 - val_mae: 0.0049\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0032 - mae: 0.0045 - val_loss: 0.0032 - val_mae: 0.0043\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0031 - mae: 0.0046 - val_loss: 0.0031 - val_mae: 0.0048\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0031 - mae: 0.0046 - val_loss: 0.0031 - val_mae: 0.0061\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0031 - mae: 0.0048 - val_loss: 0.0030 - val_mae: 0.0042\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0030 - mae: 0.0049 - val_loss: 0.0030 - val_mae: 0.0058\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0030 - mae: 0.0048 - val_loss: 0.0029 - val_mae: 0.0048\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0029 - mae: 0.0047 - val_loss: 0.0029 - val_mae: 0.0044\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0029 - mae: 0.0047 - val_loss: 0.0029 - val_mae: 0.0040\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0028 - mae: 0.0048 - val_loss: 0.0028 - val_mae: 0.0043\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0028 - mae: 0.0051 - val_loss: 0.0028 - val_mae: 0.0051\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 2s 9ms/step - loss: 0.0028 - mae: 0.0048 - val_loss: 0.0027 - val_mae: 0.0039\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 2s 9ms/step - loss: 0.0027 - mae: 0.0044 - val_loss: 0.0027 - val_mae: 0.0040\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0027 - mae: 0.0046 - val_loss: 0.0027 - val_mae: 0.0049\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0027 - mae: 0.0045 - val_loss: 0.0027 - val_mae: 0.0064\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0026 - mae: 0.0048 - val_loss: 0.0026 - val_mae: 0.0045\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 3s 9ms/step - loss: 0.0026 - mae: 0.0046 - val_loss: 0.0026 - val_mae: 0.0049\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 3s 9ms/step - loss: 0.0026 - mae: 0.0045 - val_loss: 0.0025 - val_mae: 0.0040\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0025 - mae: 0.0045 - val_loss: 0.0025 - val_mae: 0.0047\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0025 - mae: 0.0043 - val_loss: 0.0025 - val_mae: 0.0049\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0025 - mae: 0.0048 - val_loss: 0.0024 - val_mae: 0.0046\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0024 - mae: 0.0045 - val_loss: 0.0025 - val_mae: 0.0078\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0024 - mae: 0.0045 - val_loss: 0.0024 - val_mae: 0.0059\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0024 - mae: 0.0051 - val_loss: 0.0024 - val_mae: 0.0047\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0023 - mae: 0.0045 - val_loss: 0.0023 - val_mae: 0.0037\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0023 - mae: 0.0042 - val_loss: 0.0023 - val_mae: 0.0043\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0023 - mae: 0.0042 - val_loss: 0.0023 - val_mae: 0.0052\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0022 - mae: 0.0044 - val_loss: 0.0022 - val_mae: 0.0040\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0022 - mae: 0.0043 - val_loss: 0.0023 - val_mae: 0.0077\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0022 - mae: 0.0046 - val_loss: 0.0022 - val_mae: 0.0040\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0022 - mae: 0.0043 - val_loss: 0.0021 - val_mae: 0.0038\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0021 - mae: 0.0046 - val_loss: 0.0021 - val_mae: 0.0040\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0021 - mae: 0.0045 - val_loss: 0.0021 - val_mae: 0.0039\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0021 - mae: 0.0045 - val_loss: 0.0021 - val_mae: 0.0073\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 2s 9ms/step - loss: 0.0021 - mae: 0.0043 - val_loss: 0.0020 - val_mae: 0.0040\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0020 - mae: 0.0045 - val_loss: 0.0020 - val_mae: 0.0041\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0020 - mae: 0.0041 - val_loss: 0.0020 - val_mae: 0.0049\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0020 - mae: 0.0042 - val_loss: 0.0020 - val_mae: 0.0045\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0020 - mae: 0.0048 - val_loss: 0.0019 - val_mae: 0.0041\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0019 - mae: 0.0042 - val_loss: 0.0019 - val_mae: 0.0056\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0019 - mae: 0.0044 - val_loss: 0.0019 - val_mae: 0.0039\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0019 - mae: 0.0044 - val_loss: 0.0019 - val_mae: 0.0037\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0019 - mae: 0.0045 - val_loss: 0.0019 - val_mae: 0.0040\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0019 - mae: 0.0044 - val_loss: 0.0019 - val_mae: 0.0048\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0018 - mae: 0.0041 - val_loss: 0.0018 - val_mae: 0.0047\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0018 - mae: 0.0045 - val_loss: 0.0018 - val_mae: 0.0048\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0018 - mae: 0.0042 - val_loss: 0.0018 - val_mae: 0.0047\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0018 - mae: 0.0042 - val_loss: 0.0018 - val_mae: 0.0065\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0017 - mae: 0.0043 - val_loss: 0.0018 - val_mae: 0.0060\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0017 - mae: 0.0042 - val_loss: 0.0017 - val_mae: 0.0043\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0017 - mae: 0.0042 - val_loss: 0.0017 - val_mae: 0.0055\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0017 - mae: 0.0045 - val_loss: 0.0017 - val_mae: 0.0042\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0017 - mae: 0.0042 - val_loss: 0.0017 - val_mae: 0.0037\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0016 - mae: 0.0043 - val_loss: 0.0016 - val_mae: 0.0045\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0016 - mae: 0.0043 - val_loss: 0.0016 - val_mae: 0.0063\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0035\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0016 - mae: 0.0042 - val_loss: 0.0016 - val_mae: 0.0044\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0016 - mae: 0.0043 - val_loss: 0.0016 - val_mae: 0.0037\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0016 - mae: 0.0045 - val_loss: 0.0016 - val_mae: 0.0045\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0015 - mae: 0.0041 - val_loss: 0.0015 - val_mae: 0.0038\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0015 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0043\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0042\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0034\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0035\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0046\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0037\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0049\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0040\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0037\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0045\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0014 - mae: 0.0041 - val_loss: 0.0014 - val_mae: 0.0044\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0039\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0053\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0043\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0041 - val_loss: 0.0013 - val_mae: 0.0048\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0041 - val_loss: 0.0013 - val_mae: 0.0035\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0036\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0049\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0040 - val_loss: 0.0013 - val_mae: 0.0043\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0012 - val_mae: 0.0037\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0012 - mae: 0.0041 - val_loss: 0.0012 - val_mae: 0.0034\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0012 - mae: 0.0042 - val_loss: 0.0012 - val_mae: 0.0038\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0046\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0012 - mae: 0.0042 - val_loss: 0.0012 - val_mae: 0.0056\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0012 - mae: 0.0040 - val_loss: 0.0012 - val_mae: 0.0037\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0012 - mae: 0.0041 - val_loss: 0.0012 - val_mae: 0.0035\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0012 - mae: 0.0044 - val_loss: 0.0012 - val_mae: 0.0070\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0042\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0012 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0039\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0042\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0037\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0046\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0047\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0041\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0042\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0036\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0039\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0038\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0052\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0040 - val_loss: 0.0010 - val_mae: 0.0042\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0010 - mae: 0.0040 - val_loss: 0.0010 - val_mae: 0.0051\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0010 - mae: 0.0042 - val_loss: 0.0010 - val_mae: 0.0051\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0010 - mae: 0.0042 - val_loss: 0.0010 - val_mae: 0.0044\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0010 - mae: 0.0041 - val_loss: 0.0010 - val_mae: 0.0050\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0010 - mae: 0.0040 - val_loss: 9.9684e-04 - val_mae: 0.0035\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0010 - mae: 0.0041 - val_loss: 9.9890e-04 - val_mae: 0.0043\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 9.9326e-04 - mae: 0.0042 - val_loss: 9.8697e-04 - val_mae: 0.0041\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 9.8212e-04 - mae: 0.0040 - val_loss: 9.7068e-04 - val_mae: 0.0034\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 9.7484e-04 - mae: 0.0041 - val_loss: 9.6316e-04 - val_mae: 0.0035\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 9.6764e-04 - mae: 0.0041 - val_loss: 9.6688e-04 - val_mae: 0.0041\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 9.6061e-04 - mae: 0.0042 - val_loss: 9.6497e-04 - val_mae: 0.0051\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 9.5179e-04 - mae: 0.0041 - val_loss: 9.5615e-04 - val_mae: 0.0049\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 9.4325e-04 - mae: 0.0040 - val_loss: 9.4897e-04 - val_mae: 0.0047\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 9.3721e-04 - mae: 0.0042 - val_loss: 9.3308e-04 - val_mae: 0.0043\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 9.2888e-04 - mae: 0.0041 - val_loss: 9.2133e-04 - val_mae: 0.0038\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 9.2350e-04 - mae: 0.0042 - val_loss: 9.0955e-04 - val_mae: 0.0034\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 9.1629e-04 - mae: 0.0042 - val_loss: 9.0205e-04 - val_mae: 0.0033\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 9.0816e-04 - mae: 0.0041 - val_loss: 8.9702e-04 - val_mae: 0.0034\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 9.0063e-04 - mae: 0.0041 - val_loss: 8.8864e-04 - val_mae: 0.0033\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 8.9416e-04 - mae: 0.0041 - val_loss: 8.9427e-04 - val_mae: 0.0045\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 8.8565e-04 - mae: 0.0040 - val_loss: 8.7808e-04 - val_mae: 0.0036\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 8.7965e-04 - mae: 0.0040 - val_loss: 8.7127e-04 - val_mae: 0.0036\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 8.7425e-04 - mae: 0.0041 - val_loss: 8.7152e-04 - val_mae: 0.0043\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 8.6957e-04 - mae: 0.0042 - val_loss: 8.6765e-04 - val_mae: 0.0045\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 8.5995e-04 - mae: 0.0040 - val_loss: 8.4884e-04 - val_mae: 0.0033\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 8.5415e-04 - mae: 0.0040 - val_loss: 8.5360e-04 - val_mae: 0.0044\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 8.4952e-04 - mae: 0.0041 - val_loss: 8.3986e-04 - val_mae: 0.0037\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 8.4162e-04 - mae: 0.0040 - val_loss: 8.4879e-04 - val_mae: 0.0050\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 8.3631e-04 - mae: 0.0041 - val_loss: 8.5785e-04 - val_mae: 0.0059\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 8.3525e-04 - mae: 0.0044 - val_loss: 8.2745e-04 - val_mae: 0.0040\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 8.2372e-04 - mae: 0.0040 - val_loss: 8.1906e-04 - val_mae: 0.0039\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 8.1686e-04 - mae: 0.0039 - val_loss: 8.1861e-04 - val_mae: 0.0044\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 8.1128e-04 - mae: 0.0039 - val_loss: 8.2220e-04 - val_mae: 0.0052\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 8.0688e-04 - mae: 0.0040 - val_loss: 8.0275e-04 - val_mae: 0.0041\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 8.0189e-04 - mae: 0.0041 - val_loss: 7.9545e-04 - val_mae: 0.0038\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.9361e-04 - mae: 0.0039 - val_loss: 7.8606e-04 - val_mae: 0.0035\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.8753e-04 - mae: 0.0039 - val_loss: 7.8167e-04 - val_mae: 0.0036\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.8640e-04 - mae: 0.0042 - val_loss: 7.7837e-04 - val_mae: 0.0038\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.7560e-04 - mae: 0.0038 - val_loss: 7.6675e-04 - val_mae: 0.0033\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.7266e-04 - mae: 0.0040 - val_loss: 7.6483e-04 - val_mae: 0.0036\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.6773e-04 - mae: 0.0040 - val_loss: 7.5998e-04 - val_mae: 0.0036\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.6436e-04 - mae: 0.0042 - val_loss: 7.6843e-04 - val_mae: 0.0049\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.5875e-04 - mae: 0.0042 - val_loss: 7.5578e-04 - val_mae: 0.0042\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.5390e-04 - mae: 0.0041 - val_loss: 7.4411e-04 - val_mae: 0.0036\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.4564e-04 - mae: 0.0039 - val_loss: 7.3915e-04 - val_mae: 0.0036\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.4119e-04 - mae: 0.0039 - val_loss: 7.3477e-04 - val_mae: 0.0037\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.4325e-04 - mae: 0.0044 - val_loss: 7.2739e-04 - val_mae: 0.0034\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.3107e-04 - mae: 0.0038 - val_loss: 7.3609e-04 - val_mae: 0.0044\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.2938e-04 - mae: 0.0041 - val_loss: 7.2243e-04 - val_mae: 0.0037\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.2264e-04 - mae: 0.0039 - val_loss: 7.2066e-04 - val_mae: 0.0041\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.1928e-04 - mae: 0.0040 - val_loss: 7.0935e-04 - val_mae: 0.0034\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.1233e-04 - mae: 0.0038 - val_loss: 7.0919e-04 - val_mae: 0.0036\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.0790e-04 - mae: 0.0038 - val_loss: 7.0574e-04 - val_mae: 0.0039\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.0603e-04 - mae: 0.0040 - val_loss: 7.1435e-04 - val_mae: 0.0050\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.0162e-04 - mae: 0.0041 - val_loss: 7.2998e-04 - val_mae: 0.0065\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 6.9675e-04 - mae: 0.0041 - val_loss: 7.0359e-04 - val_mae: 0.0048\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 6.9122e-04 - mae: 0.0039 - val_loss: 7.0186e-04 - val_mae: 0.0048\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 6.8647e-04 - mae: 0.0039 - val_loss: 6.8366e-04 - val_mae: 0.0039\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 6.8386e-04 - mae: 0.0041 - val_loss: 6.9781e-04 - val_mae: 0.0051\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 6.7836e-04 - mae: 0.0039 - val_loss: 6.7263e-04 - val_mae: 0.0036\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 6.7338e-04 - mae: 0.0039 - val_loss: 6.9181e-04 - val_mae: 0.0056\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 6.6968e-04 - mae: 0.0039 - val_loss: 6.6364e-04 - val_mae: 0.0036\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 6.7077e-04 - mae: 0.0043 - val_loss: 6.7380e-04 - val_mae: 0.0046\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 6.6163e-04 - mae: 0.0039 - val_loss: 6.7378e-04 - val_mae: 0.0052\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.5653e-04 - mae: 0.0038 - val_loss: 6.5509e-04 - val_mae: 0.0039\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 6.5205e-04 - mae: 0.0037 - val_loss: 6.4804e-04 - val_mae: 0.0035\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 6.5166e-04 - mae: 0.0040 - val_loss: 6.5221e-04 - val_mae: 0.0044\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 6.4585e-04 - mae: 0.0039 - val_loss: 6.4864e-04 - val_mae: 0.0045\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 6.4354e-04 - mae: 0.0040 - val_loss: 6.5507e-04 - val_mae: 0.0048\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 6.4263e-04 - mae: 0.0042 - val_loss: 6.3136e-04 - val_mae: 0.0035\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.3374e-04 - mae: 0.0038 - val_loss: 6.2711e-04 - val_mae: 0.0034\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 6.3035e-04 - mae: 0.0038 - val_loss: 6.2089e-04 - val_mae: 0.0031\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 6.2739e-04 - mae: 0.0039 - val_loss: 6.1875e-04 - val_mae: 0.0033\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 6.2540e-04 - mae: 0.0040 - val_loss: 6.1583e-04 - val_mae: 0.0033\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 6.2051e-04 - mae: 0.0039 - val_loss: 6.1497e-04 - val_mae: 0.0036\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 6.2383e-04 - mae: 0.0043 - val_loss: 6.1520e-04 - val_mae: 0.0037\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.1257e-04 - mae: 0.0038 - val_loss: 6.0569e-04 - val_mae: 0.0032\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 6.1112e-04 - mae: 0.0040 - val_loss: 6.0469e-04 - val_mae: 0.0036\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 6.0772e-04 - mae: 0.0039 - val_loss: 6.0716e-04 - val_mae: 0.0042\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 6.0494e-04 - mae: 0.0040 - val_loss: 5.9849e-04 - val_mae: 0.0036\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.9810e-04 - mae: 0.0037 - val_loss: 5.9204e-04 - val_mae: 0.0032\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.9640e-04 - mae: 0.0038 - val_loss: 6.0593e-04 - val_mae: 0.0048\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.9579e-04 - mae: 0.0040 - val_loss: 5.8743e-04 - val_mae: 0.0035\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.8980e-04 - mae: 0.0038 - val_loss: 5.9269e-04 - val_mae: 0.0043\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.8713e-04 - mae: 0.0039 - val_loss: 6.1837e-04 - val_mae: 0.0061\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.8627e-04 - mae: 0.0040 - val_loss: 5.9098e-04 - val_mae: 0.0047\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.8117e-04 - mae: 0.0039 - val_loss: 5.8603e-04 - val_mae: 0.0045\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.7675e-04 - mae: 0.0037 - val_loss: 5.7398e-04 - val_mae: 0.0037\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.7853e-04 - mae: 0.0041 - val_loss: 5.6976e-04 - val_mae: 0.0036\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.7144e-04 - mae: 0.0038 - val_loss: 5.7508e-04 - val_mae: 0.0042\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.6829e-04 - mae: 0.0038 - val_loss: 5.7025e-04 - val_mae: 0.0041\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.6504e-04 - mae: 0.0038 - val_loss: 5.6470e-04 - val_mae: 0.0039\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.6373e-04 - mae: 0.0039 - val_loss: 5.6368e-04 - val_mae: 0.0039\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.6055e-04 - mae: 0.0039 - val_loss: 5.5720e-04 - val_mae: 0.0038\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.5855e-04 - mae: 0.0040 - val_loss: 5.5015e-04 - val_mae: 0.0034\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.5381e-04 - mae: 0.0038 - val_loss: 5.4867e-04 - val_mae: 0.0035\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.5403e-04 - mae: 0.0041 - val_loss: 5.5481e-04 - val_mae: 0.0043\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.5025e-04 - mae: 0.0040 - val_loss: 5.4437e-04 - val_mae: 0.0034\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.4407e-04 - mae: 0.0037 - val_loss: 5.3862e-04 - val_mae: 0.0033\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.4410e-04 - mae: 0.0039 - val_loss: 5.3908e-04 - val_mae: 0.0037\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.4137e-04 - mae: 0.0039 - val_loss: 5.3592e-04 - val_mae: 0.0035\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.3732e-04 - mae: 0.0038 - val_loss: 5.3718e-04 - val_mae: 0.0040\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.3735e-04 - mae: 0.0040 - val_loss: 5.3873e-04 - val_mae: 0.0045\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.3323e-04 - mae: 0.0039 - val_loss: 5.2525e-04 - val_mae: 0.0032\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.3193e-04 - mae: 0.0040 - val_loss: 5.2840e-04 - val_mae: 0.0037\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.3435e-04 - mae: 0.0043 - val_loss: 5.3173e-04 - val_mae: 0.0044\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.2466e-04 - mae: 0.0038 - val_loss: 5.2353e-04 - val_mae: 0.0037\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.2248e-04 - mae: 0.0038 - val_loss: 5.2362e-04 - val_mae: 0.0039\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.2146e-04 - mae: 0.0038 - val_loss: 5.3098e-04 - val_mae: 0.0048\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.1681e-04 - mae: 0.0037 - val_loss: 5.1540e-04 - val_mae: 0.0037\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.1601e-04 - mae: 0.0038 - val_loss: 5.0721e-04 - val_mae: 0.0031\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.1324e-04 - mae: 0.0038 - val_loss: 5.1257e-04 - val_mae: 0.0038\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.1492e-04 - mae: 0.0041 - val_loss: 5.0353e-04 - val_mae: 0.0033\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.0869e-04 - mae: 0.0038 - val_loss: 5.1722e-04 - val_mae: 0.0046\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.0817e-04 - mae: 0.0039 - val_loss: 5.0712e-04 - val_mae: 0.0040\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.0364e-04 - mae: 0.0038 - val_loss: 5.0986e-04 - val_mae: 0.0045\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.0573e-04 - mae: 0.0041 - val_loss: 4.9801e-04 - val_mae: 0.0035\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.9800e-04 - mae: 0.0036 - val_loss: 4.9446e-04 - val_mae: 0.0033\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.9871e-04 - mae: 0.0039 - val_loss: 4.9143e-04 - val_mae: 0.0034\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.9604e-04 - mae: 0.0038 - val_loss: 4.9327e-04 - val_mae: 0.0038\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.9392e-04 - mae: 0.0039 - val_loss: 5.0346e-04 - val_mae: 0.0048\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.9126e-04 - mae: 0.0038 - val_loss: 4.8396e-04 - val_mae: 0.0032\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.8877e-04 - mae: 0.0038 - val_loss: 4.8800e-04 - val_mae: 0.0038\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.8685e-04 - mae: 0.0038 - val_loss: 4.9165e-04 - val_mae: 0.0043\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.8687e-04 - mae: 0.0040 - val_loss: 4.8184e-04 - val_mae: 0.0036\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.8255e-04 - mae: 0.0038 - val_loss: 4.8628e-04 - val_mae: 0.0042\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.8336e-04 - mae: 0.0040 - val_loss: 5.1071e-04 - val_mae: 0.0061\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.7932e-04 - mae: 0.0038 - val_loss: 4.7227e-04 - val_mae: 0.0032\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.7709e-04 - mae: 0.0038 - val_loss: 4.7293e-04 - val_mae: 0.0035\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.7897e-04 - mae: 0.0041 - val_loss: 4.7197e-04 - val_mae: 0.0036\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.7402e-04 - mae: 0.0039 - val_loss: 4.6718e-04 - val_mae: 0.0033\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.7109e-04 - mae: 0.0038 - val_loss: 4.7197e-04 - val_mae: 0.0040\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.7043e-04 - mae: 0.0039 - val_loss: 4.8107e-04 - val_mae: 0.0051\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.6746e-04 - mae: 0.0038 - val_loss: 4.7646e-04 - val_mae: 0.0046\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.6686e-04 - mae: 0.0039 - val_loss: 4.6929e-04 - val_mae: 0.0044\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.6486e-04 - mae: 0.0039 - val_loss: 4.6649e-04 - val_mae: 0.0042\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.6179e-04 - mae: 0.0038 - val_loss: 4.6260e-04 - val_mae: 0.0038\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.6262e-04 - mae: 0.0040 - val_loss: 4.6008e-04 - val_mae: 0.0039\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.5674e-04 - mae: 0.0037 - val_loss: 4.5286e-04 - val_mae: 0.0034\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.5721e-04 - mae: 0.0038 - val_loss: 4.5453e-04 - val_mae: 0.0038\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.5437e-04 - mae: 0.0038 - val_loss: 4.6672e-04 - val_mae: 0.0050\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.5660e-04 - mae: 0.0041 - val_loss: 4.5075e-04 - val_mae: 0.0037\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.5146e-04 - mae: 0.0038 - val_loss: 4.5204e-04 - val_mae: 0.0040\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.4956e-04 - mae: 0.0038 - val_loss: 4.5142e-04 - val_mae: 0.0041\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.4853e-04 - mae: 0.0039 - val_loss: 4.4542e-04 - val_mae: 0.0036\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.4868e-04 - mae: 0.0040 - val_loss: 4.4161e-04 - val_mae: 0.0035\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.4724e-04 - mae: 0.0040 - val_loss: 4.5841e-04 - val_mae: 0.0051\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.4189e-04 - mae: 0.0037 - val_loss: 4.3985e-04 - val_mae: 0.0037\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.4337e-04 - mae: 0.0040 - val_loss: 4.3541e-04 - val_mae: 0.0033\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.3910e-04 - mae: 0.0037 - val_loss: 4.4363e-04 - val_mae: 0.0043\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.3808e-04 - mae: 0.0038 - val_loss: 4.3474e-04 - val_mae: 0.0036\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.3651e-04 - mae: 0.0038 - val_loss: 4.3269e-04 - val_mae: 0.0035\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.3519e-04 - mae: 0.0038 - val_loss: 4.4964e-04 - val_mae: 0.0052\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.3522e-04 - mae: 0.0040 - val_loss: 4.2823e-04 - val_mae: 0.0033\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.3065e-04 - mae: 0.0037 - val_loss: 4.2594e-04 - val_mae: 0.0033\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.3040e-04 - mae: 0.0038 - val_loss: 4.2576e-04 - val_mae: 0.0035\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.2859e-04 - mae: 0.0038 - val_loss: 4.2251e-04 - val_mae: 0.0033\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.2585e-04 - mae: 0.0037 - val_loss: 4.2839e-04 - val_mae: 0.0040\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.2477e-04 - mae: 0.0038 - val_loss: 4.2636e-04 - val_mae: 0.0041\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.2839e-04 - mae: 0.0042 - val_loss: 4.2417e-04 - val_mae: 0.0040\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.2426e-04 - mae: 0.0039 - val_loss: 4.2312e-04 - val_mae: 0.0039\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.2043e-04 - mae: 0.0037 - val_loss: 4.2017e-04 - val_mae: 0.0038\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.2118e-04 - mae: 0.0039 - val_loss: 4.2786e-04 - val_mae: 0.0046\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.1881e-04 - mae: 0.0039 - val_loss: 4.1373e-04 - val_mae: 0.0034\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.1953e-04 - mae: 0.0040 - val_loss: 4.2170e-04 - val_mae: 0.0044\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.1620e-04 - mae: 0.0039 - val_loss: 4.2748e-04 - val_mae: 0.0049\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.1188e-04 - mae: 0.0036 - val_loss: 4.1727e-04 - val_mae: 0.0041\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.1410e-04 - mae: 0.0039 - val_loss: 4.2096e-04 - val_mae: 0.0047\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.1137e-04 - mae: 0.0038 - val_loss: 4.1252e-04 - val_mae: 0.0040\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.0915e-04 - mae: 0.0037 - val_loss: 4.1053e-04 - val_mae: 0.0039\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.0700e-04 - mae: 0.0037 - val_loss: 4.0782e-04 - val_mae: 0.0039\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.0828e-04 - mae: 0.0039 - val_loss: 4.0065e-04 - val_mae: 0.0032\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.0466e-04 - mae: 0.0037 - val_loss: 4.3081e-04 - val_mae: 0.0059\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.0488e-04 - mae: 0.0038 - val_loss: 4.1331e-04 - val_mae: 0.0047\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.0594e-04 - mae: 0.0040 - val_loss: 3.9705e-04 - val_mae: 0.0033\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.0144e-04 - mae: 0.0037 - val_loss: 3.9880e-04 - val_mae: 0.0035\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 4.0102e-04 - mae: 0.0038 - val_loss: 3.9944e-04 - val_mae: 0.0039\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.9843e-04 - mae: 0.0037 - val_loss: 3.9720e-04 - val_mae: 0.0035\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 3.9762e-04 - mae: 0.0037 - val_loss: 3.9404e-04 - val_mae: 0.0035\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.9630e-04 - mae: 0.0037 - val_loss: 3.9304e-04 - val_mae: 0.0035\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.9674e-04 - mae: 0.0039 - val_loss: 3.9347e-04 - val_mae: 0.0036\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.9539e-04 - mae: 0.0039 - val_loss: 3.9658e-04 - val_mae: 0.0039\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 3.9365e-04 - mae: 0.0038 - val_loss: 3.8587e-04 - val_mae: 0.0031\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.9298e-04 - mae: 0.0039 - val_loss: 4.0037e-04 - val_mae: 0.0048\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 3.9041e-04 - mae: 0.0037 - val_loss: 3.8800e-04 - val_mae: 0.0036\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.9039e-04 - mae: 0.0039 - val_loss: 3.8946e-04 - val_mae: 0.0038\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 3.8685e-04 - mae: 0.0037 - val_loss: 3.8604e-04 - val_mae: 0.0035\n",
      "Epoch 399/1000\n",
      "266/270 [============================>.] - ETA: 0s - loss: 3.8932e-04 - mae: 0.0039Restoring model weights from the end of the best epoch: 394.\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 3.8977e-04 - mae: 0.0039 - val_loss: 4.0896e-04 - val_mae: 0.0055\n",
      "Epoch 399: early stopping\n",
      "Training fÃ¼r Fold 4...\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 5s 8ms/step - loss: 0.0459 - mae: 0.0877 - val_loss: 0.0297 - val_mae: 0.0512\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0272 - mae: 0.0414 - val_loss: 0.0253 - val_mae: 0.0345\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0241 - mae: 0.0303 - val_loss: 0.0233 - val_mae: 0.0296\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0224 - mae: 0.0245 - val_loss: 0.0218 - val_mae: 0.0224\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0212 - mae: 0.0207 - val_loss: 0.0207 - val_mae: 0.0188\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0203 - mae: 0.0176 - val_loss: 0.0200 - val_mae: 0.0168\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0196 - mae: 0.0152 - val_loss: 0.0193 - val_mae: 0.0145\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0191 - mae: 0.0134 - val_loss: 0.0188 - val_mae: 0.0129\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0186 - mae: 0.0125 - val_loss: 0.0185 - val_mae: 0.0135\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0182 - mae: 0.0113 - val_loss: 0.0180 - val_mae: 0.0113\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0178 - mae: 0.0107 - val_loss: 0.0176 - val_mae: 0.0101\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0174 - mae: 0.0103 - val_loss: 0.0172 - val_mae: 0.0099\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0171 - mae: 0.0104 - val_loss: 0.0169 - val_mae: 0.0100\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0167 - mae: 0.0091 - val_loss: 0.0166 - val_mae: 0.0090\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0164 - mae: 0.0094 - val_loss: 0.0162 - val_mae: 0.0085\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0161 - mae: 0.0091 - val_loss: 0.0159 - val_mae: 0.0086\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0158 - mae: 0.0094 - val_loss: 0.0156 - val_mae: 0.0090\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0154 - mae: 0.0090 - val_loss: 0.0153 - val_mae: 0.0079\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0151 - mae: 0.0080 - val_loss: 0.0150 - val_mae: 0.0080\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0148 - mae: 0.0086 - val_loss: 0.0146 - val_mae: 0.0076\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0145 - mae: 0.0088 - val_loss: 0.0143 - val_mae: 0.0075\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0142 - mae: 0.0077 - val_loss: 0.0141 - val_mae: 0.0075\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0139 - mae: 0.0074 - val_loss: 0.0137 - val_mae: 0.0070\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0136 - mae: 0.0075 - val_loss: 0.0135 - val_mae: 0.0073\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0133 - mae: 0.0086 - val_loss: 0.0132 - val_mae: 0.0081\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0130 - mae: 0.0076 - val_loss: 0.0129 - val_mae: 0.0069\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0128 - mae: 0.0076 - val_loss: 0.0127 - val_mae: 0.0110\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0125 - mae: 0.0076 - val_loss: 0.0124 - val_mae: 0.0075\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0122 - mae: 0.0072 - val_loss: 0.0121 - val_mae: 0.0067\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0120 - mae: 0.0076 - val_loss: 0.0118 - val_mae: 0.0059\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0117 - mae: 0.0081 - val_loss: 0.0116 - val_mae: 0.0087\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0115 - mae: 0.0070 - val_loss: 0.0114 - val_mae: 0.0073\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0112 - mae: 0.0069 - val_loss: 0.0111 - val_mae: 0.0063\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0110 - mae: 0.0066 - val_loss: 0.0109 - val_mae: 0.0072\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0108 - mae: 0.0071 - val_loss: 0.0106 - val_mae: 0.0063\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0106 - mae: 0.0071 - val_loss: 0.0105 - val_mae: 0.0092\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0104 - mae: 0.0076 - val_loss: 0.0102 - val_mae: 0.0058\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0101 - mae: 0.0064 - val_loss: 0.0100 - val_mae: 0.0067\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0099 - mae: 0.0068 - val_loss: 0.0098 - val_mae: 0.0067\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0097 - mae: 0.0067 - val_loss: 0.0096 - val_mae: 0.0071\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0095 - mae: 0.0066 - val_loss: 0.0095 - val_mae: 0.0080\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0093 - mae: 0.0063 - val_loss: 0.0093 - val_mae: 0.0090\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0092 - mae: 0.0066 - val_loss: 0.0091 - val_mae: 0.0064\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0090 - mae: 0.0059 - val_loss: 0.0089 - val_mae: 0.0072\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0088 - mae: 0.0066 - val_loss: 0.0087 - val_mae: 0.0069\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0086 - mae: 0.0065 - val_loss: 0.0086 - val_mae: 0.0061\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0085 - mae: 0.0070 - val_loss: 0.0084 - val_mae: 0.0056\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0083 - mae: 0.0061 - val_loss: 0.0082 - val_mae: 0.0060\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0082 - mae: 0.0066 - val_loss: 0.0082 - val_mae: 0.0084\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0080 - mae: 0.0059 - val_loss: 0.0080 - val_mae: 0.0060\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0079 - mae: 0.0061 - val_loss: 0.0078 - val_mae: 0.0061\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0078 - mae: 0.0061 - val_loss: 0.0077 - val_mae: 0.0061\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0076 - mae: 0.0063 - val_loss: 0.0076 - val_mae: 0.0082\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0075 - mae: 0.0063 - val_loss: 0.0074 - val_mae: 0.0059\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0074 - mae: 0.0056 - val_loss: 0.0073 - val_mae: 0.0055\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0072 - mae: 0.0062 - val_loss: 0.0072 - val_mae: 0.0059\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0071 - mae: 0.0063 - val_loss: 0.0070 - val_mae: 0.0050\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0070 - mae: 0.0059 - val_loss: 0.0069 - val_mae: 0.0056\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0069 - mae: 0.0055 - val_loss: 0.0068 - val_mae: 0.0058\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0068 - mae: 0.0058 - val_loss: 0.0067 - val_mae: 0.0058\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0067 - mae: 0.0054 - val_loss: 0.0066 - val_mae: 0.0054\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0065 - mae: 0.0058 - val_loss: 0.0065 - val_mae: 0.0056\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0064 - mae: 0.0056 - val_loss: 0.0064 - val_mae: 0.0054\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0063 - mae: 0.0058 - val_loss: 0.0063 - val_mae: 0.0069\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0062 - mae: 0.0059 - val_loss: 0.0062 - val_mae: 0.0050\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0061 - mae: 0.0054 - val_loss: 0.0061 - val_mae: 0.0059\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0060 - mae: 0.0057 - val_loss: 0.0060 - val_mae: 0.0057\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0059 - mae: 0.0056 - val_loss: 0.0059 - val_mae: 0.0054\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0058 - mae: 0.0053 - val_loss: 0.0059 - val_mae: 0.0099\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0058 - mae: 0.0061 - val_loss: 0.0057 - val_mae: 0.0049\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0057 - mae: 0.0052 - val_loss: 0.0057 - val_mae: 0.0070\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0056 - mae: 0.0055 - val_loss: 0.0055 - val_mae: 0.0047\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0055 - mae: 0.0054 - val_loss: 0.0054 - val_mae: 0.0047\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0054 - mae: 0.0052 - val_loss: 0.0054 - val_mae: 0.0050\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0053 - mae: 0.0056 - val_loss: 0.0053 - val_mae: 0.0049\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0052 - mae: 0.0052 - val_loss: 0.0052 - val_mae: 0.0052\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0052 - mae: 0.0052 - val_loss: 0.0051 - val_mae: 0.0052\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0051 - mae: 0.0051 - val_loss: 0.0050 - val_mae: 0.0051\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0050 - mae: 0.0052 - val_loss: 0.0050 - val_mae: 0.0056\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0049 - mae: 0.0056 - val_loss: 0.0049 - val_mae: 0.0053\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0048 - mae: 0.0052 - val_loss: 0.0048 - val_mae: 0.0056\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0048 - mae: 0.0053 - val_loss: 0.0047 - val_mae: 0.0053\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0047 - mae: 0.0057 - val_loss: 0.0047 - val_mae: 0.0051\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0046 - mae: 0.0051 - val_loss: 0.0046 - val_mae: 0.0069\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0046 - mae: 0.0051 - val_loss: 0.0046 - val_mae: 0.0071\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0045 - mae: 0.0050 - val_loss: 0.0045 - val_mae: 0.0048\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0044 - mae: 0.0054 - val_loss: 0.0044 - val_mae: 0.0044\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0044 - mae: 0.0049 - val_loss: 0.0044 - val_mae: 0.0056\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0043 - mae: 0.0050 - val_loss: 0.0043 - val_mae: 0.0046\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0042 - mae: 0.0049 - val_loss: 0.0042 - val_mae: 0.0062\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0042 - mae: 0.0053 - val_loss: 0.0041 - val_mae: 0.0046\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0041 - mae: 0.0053 - val_loss: 0.0041 - val_mae: 0.0059\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0041 - mae: 0.0051 - val_loss: 0.0040 - val_mae: 0.0050\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0040 - mae: 0.0048 - val_loss: 0.0040 - val_mae: 0.0057\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0040 - mae: 0.0054 - val_loss: 0.0039 - val_mae: 0.0047\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0039 - mae: 0.0048 - val_loss: 0.0039 - val_mae: 0.0044\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0038 - mae: 0.0050 - val_loss: 0.0038 - val_mae: 0.0072\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0038 - mae: 0.0053 - val_loss: 0.0038 - val_mae: 0.0054\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0037 - mae: 0.0049 - val_loss: 0.0037 - val_mae: 0.0046\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0037 - mae: 0.0049 - val_loss: 0.0037 - val_mae: 0.0053\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0036 - mae: 0.0050 - val_loss: 0.0036 - val_mae: 0.0044\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0036 - mae: 0.0050 - val_loss: 0.0036 - val_mae: 0.0066\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0035 - mae: 0.0051 - val_loss: 0.0035 - val_mae: 0.0058\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0035 - mae: 0.0049 - val_loss: 0.0035 - val_mae: 0.0064\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0034 - mae: 0.0051 - val_loss: 0.0034 - val_mae: 0.0057\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0034 - mae: 0.0049 - val_loss: 0.0034 - val_mae: 0.0041\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0034 - mae: 0.0052 - val_loss: 0.0033 - val_mae: 0.0047\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0033 - mae: 0.0047 - val_loss: 0.0033 - val_mae: 0.0048\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0033 - mae: 0.0050 - val_loss: 0.0032 - val_mae: 0.0043\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0032 - mae: 0.0049 - val_loss: 0.0032 - val_mae: 0.0039\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0032 - mae: 0.0051 - val_loss: 0.0032 - val_mae: 0.0042\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0031 - mae: 0.0048 - val_loss: 0.0031 - val_mae: 0.0054\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0031 - mae: 0.0050 - val_loss: 0.0031 - val_mae: 0.0063\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0031 - mae: 0.0047 - val_loss: 0.0030 - val_mae: 0.0048\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0030 - mae: 0.0048 - val_loss: 0.0030 - val_mae: 0.0045\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0030 - mae: 0.0049 - val_loss: 0.0030 - val_mae: 0.0041\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0029 - mae: 0.0049 - val_loss: 0.0029 - val_mae: 0.0042\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0029 - mae: 0.0048 - val_loss: 0.0029 - val_mae: 0.0047\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0029 - mae: 0.0048 - val_loss: 0.0029 - val_mae: 0.0052\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0028 - mae: 0.0047 - val_loss: 0.0028 - val_mae: 0.0066\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0028 - mae: 0.0053 - val_loss: 0.0028 - val_mae: 0.0047\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0028 - mae: 0.0049 - val_loss: 0.0027 - val_mae: 0.0044\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0027 - mae: 0.0047 - val_loss: 0.0027 - val_mae: 0.0039\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0027 - mae: 0.0049 - val_loss: 0.0027 - val_mae: 0.0041\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0027 - mae: 0.0043 - val_loss: 0.0026 - val_mae: 0.0039\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0026 - mae: 0.0047 - val_loss: 0.0026 - val_mae: 0.0043\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0026 - mae: 0.0049 - val_loss: 0.0026 - val_mae: 0.0051\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0026 - mae: 0.0047 - val_loss: 0.0025 - val_mae: 0.0049\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0049 - val_loss: 0.0025 - val_mae: 0.0055\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0025 - mae: 0.0047 - val_loss: 0.0025 - val_mae: 0.0041\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0049 - val_loss: 0.0025 - val_mae: 0.0049\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0024 - mae: 0.0047 - val_loss: 0.0024 - val_mae: 0.0044\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0024 - mae: 0.0048 - val_loss: 0.0024 - val_mae: 0.0049\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0024 - mae: 0.0046 - val_loss: 0.0024 - val_mae: 0.0042\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0023 - mae: 0.0042 - val_loss: 0.0023 - val_mae: 0.0041\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0023 - mae: 0.0044 - val_loss: 0.0023 - val_mae: 0.0050\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0023 - mae: 0.0049 - val_loss: 0.0023 - val_mae: 0.0039\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0023 - mae: 0.0047 - val_loss: 0.0023 - val_mae: 0.0059\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0022 - mae: 0.0046 - val_loss: 0.0022 - val_mae: 0.0047\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0022 - mae: 0.0044 - val_loss: 0.0022 - val_mae: 0.0046\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0022 - mae: 0.0046 - val_loss: 0.0022 - val_mae: 0.0046\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0022 - mae: 0.0048 - val_loss: 0.0021 - val_mae: 0.0043\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0021 - mae: 0.0045 - val_loss: 0.0021 - val_mae: 0.0048\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0021 - mae: 0.0050 - val_loss: 0.0021 - val_mae: 0.0051\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0021 - mae: 0.0046 - val_loss: 0.0021 - val_mae: 0.0046\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0021 - mae: 0.0043 - val_loss: 0.0021 - val_mae: 0.0044\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0020 - mae: 0.0046 - val_loss: 0.0020 - val_mae: 0.0046\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0020 - mae: 0.0048 - val_loss: 0.0020 - val_mae: 0.0047\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0020 - mae: 0.0046 - val_loss: 0.0020 - val_mae: 0.0045\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0020 - mae: 0.0047 - val_loss: 0.0020 - val_mae: 0.0039\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0020 - mae: 0.0044 - val_loss: 0.0019 - val_mae: 0.0039\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0019 - mae: 0.0048 - val_loss: 0.0019 - val_mae: 0.0057\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0019 - mae: 0.0046 - val_loss: 0.0019 - val_mae: 0.0043\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0019 - mae: 0.0045 - val_loss: 0.0019 - val_mae: 0.0041\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0019 - mae: 0.0044 - val_loss: 0.0019 - val_mae: 0.0042\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0019 - mae: 0.0048 - val_loss: 0.0018 - val_mae: 0.0043\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0018 - mae: 0.0046 - val_loss: 0.0018 - val_mae: 0.0038\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0018 - mae: 0.0044 - val_loss: 0.0018 - val_mae: 0.0039\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0018 - mae: 0.0045 - val_loss: 0.0018 - val_mae: 0.0041\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0018 - mae: 0.0047 - val_loss: 0.0018 - val_mae: 0.0062\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0018 - mae: 0.0045 - val_loss: 0.0018 - val_mae: 0.0067\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0017 - mae: 0.0046 - val_loss: 0.0017 - val_mae: 0.0044\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0017 - mae: 0.0048 - val_loss: 0.0017 - val_mae: 0.0051\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0017 - mae: 0.0043 - val_loss: 0.0017 - val_mae: 0.0047\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0017 - mae: 0.0043 - val_loss: 0.0017 - val_mae: 0.0049\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0017 - mae: 0.0041 - val_loss: 0.0017 - val_mae: 0.0040\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0017 - mae: 0.0049 - val_loss: 0.0017 - val_mae: 0.0063\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0052\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0043\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0059\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0016 - mae: 0.0046 - val_loss: 0.0016 - val_mae: 0.0038\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0038\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0016 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0037\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0053\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0040\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0039\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0051\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0044\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0042\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0015 - mae: 0.0047 - val_loss: 0.0014 - val_mae: 0.0047\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0037\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0049\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0070\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0046\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0036\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0014 - mae: 0.0040 - val_loss: 0.0014 - val_mae: 0.0042\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0037\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0045\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0051\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0037\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0046\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0041\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0047\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0050\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0042\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0012 - mae: 0.0042 - val_loss: 0.0012 - val_mae: 0.0036\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0044\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0048 - val_loss: 0.0012 - val_mae: 0.0057\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0042 - val_loss: 0.0012 - val_mae: 0.0052\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0042 - val_loss: 0.0012 - val_mae: 0.0036\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0012 - mae: 0.0045 - val_loss: 0.0012 - val_mae: 0.0047\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0045\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0044 - val_loss: 0.0012 - val_mae: 0.0067\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0044 - val_loss: 0.0012 - val_mae: 0.0039\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0049\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0037\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0044 - val_loss: 0.0011 - val_mae: 0.0036\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0049\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0041\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0011 - mae: 0.0044 - val_loss: 0.0011 - val_mae: 0.0038\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0044 - val_loss: 0.0011 - val_mae: 0.0036\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0045 - val_loss: 0.0011 - val_mae: 0.0049\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0064\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0010 - mae: 0.0046 - val_loss: 0.0010 - val_mae: 0.0039\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0010 - mae: 0.0041 - val_loss: 0.0010 - val_mae: 0.0043\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0010 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0063\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0010 - mae: 0.0046 - val_loss: 0.0010 - val_mae: 0.0042\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0010 - mae: 0.0044 - val_loss: 0.0010 - val_mae: 0.0037\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0010 - mae: 0.0045 - val_loss: 0.0010 - val_mae: 0.0042\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0010 - mae: 0.0044 - val_loss: 9.9460e-04 - val_mae: 0.0039\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.9015e-04 - mae: 0.0041 - val_loss: 9.8802e-04 - val_mae: 0.0040\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.8850e-04 - mae: 0.0045 - val_loss: 9.7936e-04 - val_mae: 0.0038\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.7921e-04 - mae: 0.0044 - val_loss: 9.7423e-04 - val_mae: 0.0039\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 9.6901e-04 - mae: 0.0041 - val_loss: 9.7603e-04 - val_mae: 0.0045\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 9.6416e-04 - mae: 0.0043 - val_loss: 9.5592e-04 - val_mae: 0.0036\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.5752e-04 - mae: 0.0043 - val_loss: 9.9318e-04 - val_mae: 0.0068\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.4786e-04 - mae: 0.0041 - val_loss: 9.4778e-04 - val_mae: 0.0040\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.4388e-04 - mae: 0.0043 - val_loss: 9.4170e-04 - val_mae: 0.0040\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.3803e-04 - mae: 0.0044 - val_loss: 9.4415e-04 - val_mae: 0.0051\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 9.3249e-04 - mae: 0.0045 - val_loss: 9.2362e-04 - val_mae: 0.0037\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 9.2252e-04 - mae: 0.0041 - val_loss: 9.1804e-04 - val_mae: 0.0039\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.1562e-04 - mae: 0.0042 - val_loss: 9.2945e-04 - val_mae: 0.0052\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.0709e-04 - mae: 0.0040 - val_loss: 9.0331e-04 - val_mae: 0.0036\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.0953e-04 - mae: 0.0046 - val_loss: 9.0513e-04 - val_mae: 0.0045\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 8.9521e-04 - mae: 0.0041 - val_loss: 8.9034e-04 - val_mae: 0.0036\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.9068e-04 - mae: 0.0042 - val_loss: 8.8343e-04 - val_mae: 0.0036\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 8.8743e-04 - mae: 0.0044 - val_loss: 8.8264e-04 - val_mae: 0.0039\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.8237e-04 - mae: 0.0044 - val_loss: 8.9270e-04 - val_mae: 0.0053\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.7288e-04 - mae: 0.0042 - val_loss: 8.6817e-04 - val_mae: 0.0037\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 8.7050e-04 - mae: 0.0045 - val_loss: 8.7223e-04 - val_mae: 0.0048\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.5951e-04 - mae: 0.0040 - val_loss: 8.5805e-04 - val_mae: 0.0038\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 8.5447e-04 - mae: 0.0041 - val_loss: 8.8415e-04 - val_mae: 0.0063\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.5069e-04 - mae: 0.0042 - val_loss: 8.5823e-04 - val_mae: 0.0050\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 8.4385e-04 - mae: 0.0041 - val_loss: 8.5491e-04 - val_mae: 0.0051\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.3776e-04 - mae: 0.0041 - val_loss: 8.4660e-04 - val_mae: 0.0046\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.3491e-04 - mae: 0.0043 - val_loss: 8.3311e-04 - val_mae: 0.0041\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.3231e-04 - mae: 0.0045 - val_loss: 8.4668e-04 - val_mae: 0.0057\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.2065e-04 - mae: 0.0040 - val_loss: 8.2283e-04 - val_mae: 0.0042\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.1710e-04 - mae: 0.0042 - val_loss: 8.1586e-04 - val_mae: 0.0041\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.1541e-04 - mae: 0.0044 - val_loss: 8.2289e-04 - val_mae: 0.0050\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.1005e-04 - mae: 0.0043 - val_loss: 8.0332e-04 - val_mae: 0.0038\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 8.0234e-04 - mae: 0.0042 - val_loss: 7.9700e-04 - val_mae: 0.0037\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.9947e-04 - mae: 0.0043 - val_loss: 8.0499e-04 - val_mae: 0.0046\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 7.8857e-04 - mae: 0.0039 - val_loss: 8.0047e-04 - val_mae: 0.0049\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.8940e-04 - mae: 0.0043 - val_loss: 7.9125e-04 - val_mae: 0.0045\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.8385e-04 - mae: 0.0042 - val_loss: 8.2063e-04 - val_mae: 0.0069\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 7.8158e-04 - mae: 0.0044 - val_loss: 7.8895e-04 - val_mae: 0.0049\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.7786e-04 - mae: 0.0045 - val_loss: 7.7669e-04 - val_mae: 0.0043\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 7.6446e-04 - mae: 0.0038 - val_loss: 7.6146e-04 - val_mae: 0.0034\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 7.6414e-04 - mae: 0.0041 - val_loss: 7.5920e-04 - val_mae: 0.0037\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.6042e-04 - mae: 0.0042 - val_loss: 7.6850e-04 - val_mae: 0.0046\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 7.5378e-04 - mae: 0.0040 - val_loss: 7.5744e-04 - val_mae: 0.0044\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.5157e-04 - mae: 0.0042 - val_loss: 7.5378e-04 - val_mae: 0.0043\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 7.5017e-04 - mae: 0.0044 - val_loss: 7.8735e-04 - val_mae: 0.0073\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.4311e-04 - mae: 0.0042 - val_loss: 7.3682e-04 - val_mae: 0.0036\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.4452e-04 - mae: 0.0045 - val_loss: 7.3993e-04 - val_mae: 0.0044\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 7.3374e-04 - mae: 0.0041 - val_loss: 7.2843e-04 - val_mae: 0.0036\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.3257e-04 - mae: 0.0044 - val_loss: 7.2941e-04 - val_mae: 0.0039\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.2807e-04 - mae: 0.0042 - val_loss: 7.2208e-04 - val_mae: 0.0038\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.1981e-04 - mae: 0.0040 - val_loss: 7.1787e-04 - val_mae: 0.0037\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.1681e-04 - mae: 0.0041 - val_loss: 7.1199e-04 - val_mae: 0.0035\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 7.1440e-04 - mae: 0.0042 - val_loss: 7.2375e-04 - val_mae: 0.0048\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.0965e-04 - mae: 0.0041 - val_loss: 7.4866e-04 - val_mae: 0.0070\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 7.0565e-04 - mae: 0.0042 - val_loss: 7.0034e-04 - val_mae: 0.0036\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 7.0287e-04 - mae: 0.0042 - val_loss: 7.0225e-04 - val_mae: 0.0042\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.9757e-04 - mae: 0.0041 - val_loss: 6.9096e-04 - val_mae: 0.0034\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 6.9267e-04 - mae: 0.0041 - val_loss: 6.8884e-04 - val_mae: 0.0037\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.8807e-04 - mae: 0.0040 - val_loss: 6.9216e-04 - val_mae: 0.0044\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 6.9066e-04 - mae: 0.0044 - val_loss: 6.8559e-04 - val_mae: 0.0041\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.8257e-04 - mae: 0.0041 - val_loss: 7.1611e-04 - val_mae: 0.0068\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 6.8096e-04 - mae: 0.0043 - val_loss: 6.7830e-04 - val_mae: 0.0041\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.7554e-04 - mae: 0.0042 - val_loss: 6.6973e-04 - val_mae: 0.0036\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 6.7232e-04 - mae: 0.0042 - val_loss: 6.7261e-04 - val_mae: 0.0043\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 6.7005e-04 - mae: 0.0043 - val_loss: 6.6094e-04 - val_mae: 0.0034\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.6534e-04 - mae: 0.0042 - val_loss: 6.6966e-04 - val_mae: 0.0044\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.5977e-04 - mae: 0.0040 - val_loss: 6.6282e-04 - val_mae: 0.0041\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.6110e-04 - mae: 0.0044 - val_loss: 6.7622e-04 - val_mae: 0.0053\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 6.5839e-04 - mae: 0.0044 - val_loss: 6.5991e-04 - val_mae: 0.0047\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.4816e-04 - mae: 0.0039 - val_loss: 6.4556e-04 - val_mae: 0.0035\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.4929e-04 - mae: 0.0042 - val_loss: 6.4785e-04 - val_mae: 0.0040\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 6.4459e-04 - mae: 0.0041 - val_loss: 6.4400e-04 - val_mae: 0.0039\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.4122e-04 - mae: 0.0041 - val_loss: 6.4940e-04 - val_mae: 0.0045\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.3988e-04 - mae: 0.0042 - val_loss: 6.3945e-04 - val_mae: 0.0041\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.3585e-04 - mae: 0.0042 - val_loss: 6.3904e-04 - val_mae: 0.0044\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.3236e-04 - mae: 0.0041 - val_loss: 6.7513e-04 - val_mae: 0.0071\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 6.2668e-04 - mae: 0.0039 - val_loss: 6.3747e-04 - val_mae: 0.0048\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.2633e-04 - mae: 0.0042 - val_loss: 6.3130e-04 - val_mae: 0.0043\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 6.2301e-04 - mae: 0.0041 - val_loss: 6.1837e-04 - val_mae: 0.0036\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.1822e-04 - mae: 0.0040 - val_loss: 6.2702e-04 - val_mae: 0.0048\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 6.1718e-04 - mae: 0.0042 - val_loss: 6.1038e-04 - val_mae: 0.0034\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.1538e-04 - mae: 0.0043 - val_loss: 6.1056e-04 - val_mae: 0.0037\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.1017e-04 - mae: 0.0041 - val_loss: 6.0322e-04 - val_mae: 0.0033\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 6.0822e-04 - mae: 0.0042 - val_loss: 6.0741e-04 - val_mae: 0.0041\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.0686e-04 - mae: 0.0043 - val_loss: 5.9938e-04 - val_mae: 0.0035\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 6.0053e-04 - mae: 0.0040 - val_loss: 5.9581e-04 - val_mae: 0.0034\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.0091e-04 - mae: 0.0042 - val_loss: 5.9818e-04 - val_mae: 0.0039\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.9247e-04 - mae: 0.0038 - val_loss: 5.9090e-04 - val_mae: 0.0035\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 5.9355e-04 - mae: 0.0041 - val_loss: 5.9001e-04 - val_mae: 0.0037\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.8907e-04 - mae: 0.0040 - val_loss: 5.8785e-04 - val_mae: 0.0038\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 5.9022e-04 - mae: 0.0043 - val_loss: 5.8134e-04 - val_mae: 0.0034\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 5.8235e-04 - mae: 0.0039 - val_loss: 5.8974e-04 - val_mae: 0.0043\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.8584e-04 - mae: 0.0043 - val_loss: 5.9586e-04 - val_mae: 0.0050\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.8004e-04 - mae: 0.0041 - val_loss: 5.8386e-04 - val_mae: 0.0044\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 5.7831e-04 - mae: 0.0042 - val_loss: 5.9102e-04 - val_mae: 0.0050\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 5.7580e-04 - mae: 0.0042 - val_loss: 5.6814e-04 - val_mae: 0.0033\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.7062e-04 - mae: 0.0040 - val_loss: 5.7394e-04 - val_mae: 0.0041\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.6714e-04 - mae: 0.0040 - val_loss: 5.7737e-04 - val_mae: 0.0047\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.6981e-04 - mae: 0.0043 - val_loss: 5.6652e-04 - val_mae: 0.0040\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 5.6346e-04 - mae: 0.0040 - val_loss: 5.6239e-04 - val_mae: 0.0038\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.5930e-04 - mae: 0.0039 - val_loss: 5.6197e-04 - val_mae: 0.0041\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.5937e-04 - mae: 0.0041 - val_loss: 5.5446e-04 - val_mae: 0.0035\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 5.5527e-04 - mae: 0.0040 - val_loss: 5.6938e-04 - val_mae: 0.0048\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.5720e-04 - mae: 0.0043 - val_loss: 5.6579e-04 - val_mae: 0.0050\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.5265e-04 - mae: 0.0041 - val_loss: 5.4768e-04 - val_mae: 0.0036\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.4768e-04 - mae: 0.0039 - val_loss: 5.4804e-04 - val_mae: 0.0037\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.4309e-04 - mae: 0.0038 - val_loss: 5.4172e-04 - val_mae: 0.0034\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.4601e-04 - mae: 0.0042 - val_loss: 6.1706e-04 - val_mae: 0.0089\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.4553e-04 - mae: 0.0043 - val_loss: 5.5526e-04 - val_mae: 0.0050\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.4176e-04 - mae: 0.0042 - val_loss: 5.5504e-04 - val_mae: 0.0049\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.3585e-04 - mae: 0.0039 - val_loss: 5.3515e-04 - val_mae: 0.0035\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.3430e-04 - mae: 0.0040 - val_loss: 5.6577e-04 - val_mae: 0.0065\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.3306e-04 - mae: 0.0041 - val_loss: 5.3016e-04 - val_mae: 0.0037\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.3119e-04 - mae: 0.0041 - val_loss: 5.2602e-04 - val_mae: 0.0034\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.2807e-04 - mae: 0.0041 - val_loss: 5.2440e-04 - val_mae: 0.0035\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.2558e-04 - mae: 0.0040 - val_loss: 5.2746e-04 - val_mae: 0.0041\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.2332e-04 - mae: 0.0040 - val_loss: 5.2552e-04 - val_mae: 0.0040\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 5.2251e-04 - mae: 0.0041 - val_loss: 5.2567e-04 - val_mae: 0.0042\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.1982e-04 - mae: 0.0041 - val_loss: 5.1698e-04 - val_mae: 0.0037\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.1816e-04 - mae: 0.0041 - val_loss: 5.2001e-04 - val_mae: 0.0042\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.1491e-04 - mae: 0.0040 - val_loss: 5.2225e-04 - val_mae: 0.0043\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.1730e-04 - mae: 0.0044 - val_loss: 5.1176e-04 - val_mae: 0.0038\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.0996e-04 - mae: 0.0039 - val_loss: 5.1105e-04 - val_mae: 0.0037\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.0935e-04 - mae: 0.0041 - val_loss: 5.0481e-04 - val_mae: 0.0034\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.0651e-04 - mae: 0.0040 - val_loss: 5.1039e-04 - val_mae: 0.0043\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.0567e-04 - mae: 0.0041 - val_loss: 5.0176e-04 - val_mae: 0.0035\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.9922e-04 - mae: 0.0037 - val_loss: 4.9987e-04 - val_mae: 0.0035\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.0481e-04 - mae: 0.0043 - val_loss: 5.0914e-04 - val_mae: 0.0047\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.0053e-04 - mae: 0.0041 - val_loss: 4.9907e-04 - val_mae: 0.0039\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.9784e-04 - mae: 0.0041 - val_loss: 5.1945e-04 - val_mae: 0.0059\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.9656e-04 - mae: 0.0041 - val_loss: 4.9751e-04 - val_mae: 0.0040\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.9327e-04 - mae: 0.0040 - val_loss: 5.3593e-04 - val_mae: 0.0073\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.9313e-04 - mae: 0.0041 - val_loss: 5.0534e-04 - val_mae: 0.0050\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.8854e-04 - mae: 0.0039 - val_loss: 4.8744e-04 - val_mae: 0.0037\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.8807e-04 - mae: 0.0040 - val_loss: 4.8539e-04 - val_mae: 0.0037\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.8507e-04 - mae: 0.0039 - val_loss: 4.9594e-04 - val_mae: 0.0046\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.9010e-04 - mae: 0.0044 - val_loss: 5.0130e-04 - val_mae: 0.0050\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.8307e-04 - mae: 0.0041 - val_loss: 4.8241e-04 - val_mae: 0.0037\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.7991e-04 - mae: 0.0040 - val_loss: 4.7638e-04 - val_mae: 0.0034\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.7714e-04 - mae: 0.0039 - val_loss: 4.8070e-04 - val_mae: 0.0041\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.7785e-04 - mae: 0.0041 - val_loss: 4.7817e-04 - val_mae: 0.0040\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.7773e-04 - mae: 0.0042 - val_loss: 4.7799e-04 - val_mae: 0.0042\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.7431e-04 - mae: 0.0041 - val_loss: 4.7845e-04 - val_mae: 0.0042\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.7286e-04 - mae: 0.0041 - val_loss: 4.6969e-04 - val_mae: 0.0036\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.6818e-04 - mae: 0.0038 - val_loss: 4.7338e-04 - val_mae: 0.0041\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.6685e-04 - mae: 0.0039 - val_loss: 4.6533e-04 - val_mae: 0.0035\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.6462e-04 - mae: 0.0038 - val_loss: 4.7138e-04 - val_mae: 0.0044\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.6755e-04 - mae: 0.0042 - val_loss: 4.7496e-04 - val_mae: 0.0046\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.6222e-04 - mae: 0.0039 - val_loss: 4.7650e-04 - val_mae: 0.0050\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.6459e-04 - mae: 0.0043 - val_loss: 4.7102e-04 - val_mae: 0.0047\n",
      "Epoch 373/1000\n",
      "259/270 [===========================>..] - ETA: 0s - loss: 4.6098e-04 - mae: 0.0041Restoring model weights from the end of the best epoch: 368.\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.6088e-04 - mae: 0.0041 - val_loss: 4.6655e-04 - val_mae: 0.0046\n",
      "Epoch 373: early stopping\n",
      "Training fÃ¼r Fold 5...\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 4s 6ms/step - loss: 0.0605 - mae: 0.1029 - val_loss: 0.0292 - val_mae: 0.0527\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0271 - mae: 0.0438 - val_loss: 0.0250 - val_mae: 0.0355\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0238 - mae: 0.0315 - val_loss: 0.0227 - val_mae: 0.0269\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0220 - mae: 0.0247 - val_loss: 0.0213 - val_mae: 0.0220\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0208 - mae: 0.0204 - val_loss: 0.0203 - val_mae: 0.0184\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0200 - mae: 0.0180 - val_loss: 0.0197 - val_mae: 0.0178\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0194 - mae: 0.0156 - val_loss: 0.0191 - val_mae: 0.0145\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0188 - mae: 0.0139 - val_loss: 0.0186 - val_mae: 0.0130\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0184 - mae: 0.0125 - val_loss: 0.0182 - val_mae: 0.0129\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0180 - mae: 0.0114 - val_loss: 0.0178 - val_mae: 0.0111\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0176 - mae: 0.0107 - val_loss: 0.0175 - val_mae: 0.0121\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0173 - mae: 0.0101 - val_loss: 0.0172 - val_mae: 0.0102\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0170 - mae: 0.0102 - val_loss: 0.0168 - val_mae: 0.0093\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0167 - mae: 0.0094 - val_loss: 0.0165 - val_mae: 0.0092\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0164 - mae: 0.0091 - val_loss: 0.0162 - val_mae: 0.0088\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0161 - mae: 0.0090 - val_loss: 0.0159 - val_mae: 0.0083\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0158 - mae: 0.0089 - val_loss: 0.0157 - val_mae: 0.0108\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0155 - mae: 0.0091 - val_loss: 0.0154 - val_mae: 0.0082\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0153 - mae: 0.0095 - val_loss: 0.0151 - val_mae: 0.0095\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0149 - mae: 0.0084 - val_loss: 0.0148 - val_mae: 0.0090\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0147 - mae: 0.0085 - val_loss: 0.0145 - val_mae: 0.0090\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0144 - mae: 0.0085 - val_loss: 0.0142 - val_mae: 0.0080\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0141 - mae: 0.0089 - val_loss: 0.0143 - val_mae: 0.0170\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0139 - mae: 0.0083 - val_loss: 0.0137 - val_mae: 0.0074\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0136 - mae: 0.0078 - val_loss: 0.0134 - val_mae: 0.0080\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0133 - mae: 0.0087 - val_loss: 0.0132 - val_mae: 0.0083\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0131 - mae: 0.0085 - val_loss: 0.0129 - val_mae: 0.0076\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0128 - mae: 0.0081 - val_loss: 0.0127 - val_mae: 0.0076\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0126 - mae: 0.0077 - val_loss: 0.0124 - val_mae: 0.0075\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0123 - mae: 0.0077 - val_loss: 0.0123 - val_mae: 0.0094\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0121 - mae: 0.0079 - val_loss: 0.0119 - val_mae: 0.0068\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0118 - mae: 0.0071 - val_loss: 0.0117 - val_mae: 0.0076\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0116 - mae: 0.0074 - val_loss: 0.0115 - val_mae: 0.0086\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0114 - mae: 0.0080 - val_loss: 0.0114 - val_mae: 0.0123\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0111 - mae: 0.0068 - val_loss: 0.0110 - val_mae: 0.0074\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0109 - mae: 0.0068 - val_loss: 0.0108 - val_mae: 0.0062\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0107 - mae: 0.0071 - val_loss: 0.0105 - val_mae: 0.0057\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0105 - mae: 0.0069 - val_loss: 0.0104 - val_mae: 0.0067\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0102 - mae: 0.0064 - val_loss: 0.0102 - val_mae: 0.0074\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0100 - mae: 0.0070 - val_loss: 0.0099 - val_mae: 0.0069\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0098 - mae: 0.0065 - val_loss: 0.0097 - val_mae: 0.0065\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0096 - mae: 0.0066 - val_loss: 0.0096 - val_mae: 0.0080\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0095 - mae: 0.0073 - val_loss: 0.0093 - val_mae: 0.0066\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0093 - mae: 0.0066 - val_loss: 0.0092 - val_mae: 0.0063\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0091 - mae: 0.0065 - val_loss: 0.0090 - val_mae: 0.0061\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0089 - mae: 0.0062 - val_loss: 0.0088 - val_mae: 0.0069\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0087 - mae: 0.0065 - val_loss: 0.0086 - val_mae: 0.0058\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0086 - mae: 0.0062 - val_loss: 0.0085 - val_mae: 0.0054\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0084 - mae: 0.0060 - val_loss: 0.0083 - val_mae: 0.0061\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0082 - mae: 0.0065 - val_loss: 0.0081 - val_mae: 0.0064\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0081 - mae: 0.0059 - val_loss: 0.0080 - val_mae: 0.0072\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0079 - mae: 0.0071 - val_loss: 0.0079 - val_mae: 0.0074\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0078 - mae: 0.0061 - val_loss: 0.0077 - val_mae: 0.0052\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0076 - mae: 0.0063 - val_loss: 0.0076 - val_mae: 0.0068\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0075 - mae: 0.0057 - val_loss: 0.0074 - val_mae: 0.0052\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0074 - mae: 0.0061 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0072 - mae: 0.0058 - val_loss: 0.0072 - val_mae: 0.0063\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0071 - mae: 0.0062 - val_loss: 0.0070 - val_mae: 0.0056\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0070 - mae: 0.0060 - val_loss: 0.0069 - val_mae: 0.0050\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0069 - mae: 0.0055 - val_loss: 0.0068 - val_mae: 0.0056\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0068 - mae: 0.0063 - val_loss: 0.0067 - val_mae: 0.0054\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0066 - mae: 0.0055 - val_loss: 0.0066 - val_mae: 0.0059\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0065 - mae: 0.0057 - val_loss: 0.0065 - val_mae: 0.0058\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0064 - mae: 0.0053 - val_loss: 0.0063 - val_mae: 0.0055\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0063 - mae: 0.0059 - val_loss: 0.0063 - val_mae: 0.0066\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0062 - mae: 0.0061 - val_loss: 0.0062 - val_mae: 0.0070\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0061 - mae: 0.0057 - val_loss: 0.0061 - val_mae: 0.0070\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0060 - mae: 0.0054 - val_loss: 0.0060 - val_mae: 0.0061\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0059 - mae: 0.0054 - val_loss: 0.0058 - val_mae: 0.0054\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0058 - mae: 0.0058 - val_loss: 0.0059 - val_mae: 0.0099\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0057 - mae: 0.0057 - val_loss: 0.0056 - val_mae: 0.0050\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0056 - mae: 0.0055 - val_loss: 0.0056 - val_mae: 0.0083\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0055 - mae: 0.0056 - val_loss: 0.0055 - val_mae: 0.0049\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0054 - mae: 0.0053 - val_loss: 0.0054 - val_mae: 0.0051\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0053 - mae: 0.0052 - val_loss: 0.0053 - val_mae: 0.0049\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0053 - mae: 0.0055 - val_loss: 0.0052 - val_mae: 0.0051\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0052 - mae: 0.0050 - val_loss: 0.0051 - val_mae: 0.0049\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0051 - mae: 0.0062 - val_loss: 0.0050 - val_mae: 0.0046\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0050 - mae: 0.0052 - val_loss: 0.0050 - val_mae: 0.0057\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0049 - mae: 0.0051 - val_loss: 0.0049 - val_mae: 0.0061\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0049 - mae: 0.0053 - val_loss: 0.0048 - val_mae: 0.0048\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0048 - mae: 0.0053 - val_loss: 0.0048 - val_mae: 0.0076\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0047 - mae: 0.0058 - val_loss: 0.0047 - val_mae: 0.0065\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0046 - mae: 0.0048 - val_loss: 0.0046 - val_mae: 0.0059\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0046 - mae: 0.0053 - val_loss: 0.0045 - val_mae: 0.0049\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0045 - mae: 0.0049 - val_loss: 0.0045 - val_mae: 0.0057\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0044 - mae: 0.0055 - val_loss: 0.0044 - val_mae: 0.0051\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0044 - mae: 0.0053 - val_loss: 0.0044 - val_mae: 0.0067\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0043 - mae: 0.0051 - val_loss: 0.0043 - val_mae: 0.0047\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0042 - mae: 0.0050 - val_loss: 0.0042 - val_mae: 0.0062\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0042 - mae: 0.0050 - val_loss: 0.0042 - val_mae: 0.0064\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0041 - mae: 0.0051 - val_loss: 0.0041 - val_mae: 0.0046\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0041 - mae: 0.0054 - val_loss: 0.0040 - val_mae: 0.0043\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0040 - mae: 0.0055 - val_loss: 0.0040 - val_mae: 0.0048\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0039 - mae: 0.0047 - val_loss: 0.0039 - val_mae: 0.0053\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0039 - mae: 0.0051 - val_loss: 0.0039 - val_mae: 0.0057\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0038 - mae: 0.0052 - val_loss: 0.0038 - val_mae: 0.0045\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0038 - mae: 0.0049 - val_loss: 0.0037 - val_mae: 0.0048\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0037 - mae: 0.0048 - val_loss: 0.0037 - val_mae: 0.0046\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0037 - mae: 0.0050 - val_loss: 0.0036 - val_mae: 0.0043\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0036 - mae: 0.0050 - val_loss: 0.0036 - val_mae: 0.0046\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0035 - mae: 0.0051 - val_loss: 0.0035 - val_mae: 0.0064\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0035 - mae: 0.0050 - val_loss: 0.0035 - val_mae: 0.0042\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0034 - mae: 0.0051 - val_loss: 0.0034 - val_mae: 0.0046\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0034 - mae: 0.0052 - val_loss: 0.0034 - val_mae: 0.0049\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0033 - mae: 0.0047 - val_loss: 0.0033 - val_mae: 0.0045\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0033 - mae: 0.0049 - val_loss: 0.0033 - val_mae: 0.0061\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0033 - mae: 0.0051 - val_loss: 0.0032 - val_mae: 0.0049\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0032 - mae: 0.0045 - val_loss: 0.0032 - val_mae: 0.0057\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0032 - mae: 0.0050 - val_loss: 0.0031 - val_mae: 0.0055\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0031 - mae: 0.0053 - val_loss: 0.0031 - val_mae: 0.0051\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0031 - mae: 0.0047 - val_loss: 0.0031 - val_mae: 0.0059\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0030 - mae: 0.0047 - val_loss: 0.0030 - val_mae: 0.0044\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0030 - mae: 0.0050 - val_loss: 0.0030 - val_mae: 0.0070\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0029 - mae: 0.0050 - val_loss: 0.0029 - val_mae: 0.0044\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0029 - mae: 0.0048 - val_loss: 0.0029 - val_mae: 0.0049\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0029 - mae: 0.0047 - val_loss: 0.0028 - val_mae: 0.0048\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0028 - mae: 0.0048 - val_loss: 0.0028 - val_mae: 0.0060\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0028 - mae: 0.0047 - val_loss: 0.0028 - val_mae: 0.0050\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0027 - mae: 0.0047 - val_loss: 0.0027 - val_mae: 0.0042\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0027 - mae: 0.0048 - val_loss: 0.0027 - val_mae: 0.0078\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0027 - mae: 0.0049 - val_loss: 0.0027 - val_mae: 0.0049\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0026 - mae: 0.0046 - val_loss: 0.0026 - val_mae: 0.0042\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0026 - mae: 0.0048 - val_loss: 0.0026 - val_mae: 0.0044\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0026 - mae: 0.0051 - val_loss: 0.0025 - val_mae: 0.0043\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0025 - mae: 0.0045 - val_loss: 0.0025 - val_mae: 0.0041\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0025 - mae: 0.0046 - val_loss: 0.0025 - val_mae: 0.0044\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0025 - mae: 0.0049 - val_loss: 0.0025 - val_mae: 0.0046\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0024 - mae: 0.0045 - val_loss: 0.0024 - val_mae: 0.0038\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0024 - mae: 0.0047 - val_loss: 0.0024 - val_mae: 0.0044\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0024 - mae: 0.0045 - val_loss: 0.0024 - val_mae: 0.0043\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0023 - mae: 0.0048 - val_loss: 0.0023 - val_mae: 0.0045\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0023 - mae: 0.0043 - val_loss: 0.0023 - val_mae: 0.0049\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0023 - mae: 0.0047 - val_loss: 0.0023 - val_mae: 0.0044\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0023 - mae: 0.0045 - val_loss: 0.0022 - val_mae: 0.0046\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0022 - mae: 0.0051 - val_loss: 0.0022 - val_mae: 0.0059\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0022 - mae: 0.0044 - val_loss: 0.0022 - val_mae: 0.0040\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0022 - mae: 0.0044 - val_loss: 0.0021 - val_mae: 0.0038\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0045 - val_loss: 0.0021 - val_mae: 0.0058\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0045 - val_loss: 0.0021 - val_mae: 0.0051\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0047 - val_loss: 0.0021 - val_mae: 0.0038\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0045 - val_loss: 0.0020 - val_mae: 0.0040\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0046 - val_loss: 0.0020 - val_mae: 0.0047\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0046 - val_loss: 0.0020 - val_mae: 0.0044\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0044 - val_loss: 0.0020 - val_mae: 0.0042\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0043 - val_loss: 0.0019 - val_mae: 0.0042\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0046 - val_loss: 0.0019 - val_mae: 0.0041\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0045 - val_loss: 0.0019 - val_mae: 0.0047\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0046 - val_loss: 0.0019 - val_mae: 0.0060\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0048 - val_loss: 0.0019 - val_mae: 0.0052\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0044 - val_loss: 0.0018 - val_mae: 0.0044\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0044 - val_loss: 0.0018 - val_mae: 0.0050\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0043 - val_loss: 0.0018 - val_mae: 0.0039\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0044 - val_loss: 0.0018 - val_mae: 0.0044\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0048 - val_loss: 0.0018 - val_mae: 0.0047\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0045 - val_loss: 0.0017 - val_mae: 0.0038\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0045 - val_loss: 0.0017 - val_mae: 0.0044\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0043 - val_loss: 0.0017 - val_mae: 0.0039\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0045 - val_loss: 0.0017 - val_mae: 0.0039\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0046 - val_loss: 0.0017 - val_mae: 0.0051\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0043 - val_loss: 0.0017 - val_mae: 0.0052\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0038\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0042 - val_loss: 0.0016 - val_mae: 0.0041\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0043 - val_loss: 0.0016 - val_mae: 0.0042\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0045 - val_loss: 0.0016 - val_mae: 0.0086\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0045 - val_loss: 0.0016 - val_mae: 0.0061\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0036\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0039\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 0.0015 - val_mae: 0.0041\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0048 - val_loss: 0.0015 - val_mae: 0.0041\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0041 - val_loss: 0.0015 - val_mae: 0.0038\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0056\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0039\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0038\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0045\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0039\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0046\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0050\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0046 - val_loss: 0.0014 - val_mae: 0.0059\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0042\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0046\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0041 - val_loss: 0.0013 - val_mae: 0.0045\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0038\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0048 - val_loss: 0.0013 - val_mae: 0.0041\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0046\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0045\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0040 - val_loss: 0.0013 - val_mae: 0.0047\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0047\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0012 - val_mae: 0.0040\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0046 - val_loss: 0.0013 - val_mae: 0.0062\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0042 - val_loss: 0.0012 - val_mae: 0.0037\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0041 - val_loss: 0.0012 - val_mae: 0.0040\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0045 - val_loss: 0.0012 - val_mae: 0.0045\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0041 - val_loss: 0.0012 - val_mae: 0.0038\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0046\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0041 - val_loss: 0.0012 - val_mae: 0.0040\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0046\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0038\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0036\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0042\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0045\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0045\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0044 - val_loss: 0.0011 - val_mae: 0.0042\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0038\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0039\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0040\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0054\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0042 - val_loss: 0.0010 - val_mae: 0.0039\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0041 - val_loss: 0.0010 - val_mae: 0.0041\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0042 - val_loss: 0.0010 - val_mae: 0.0039\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0040 - val_loss: 0.0010 - val_mae: 0.0043\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0041 - val_loss: 0.0010 - val_mae: 0.0043\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0040 - val_loss: 0.0010 - val_mae: 0.0043\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0045 - val_loss: 9.9401e-04 - val_mae: 0.0043\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.9508e-04 - mae: 0.0046 - val_loss: 9.8487e-04 - val_mae: 0.0041\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.8007e-04 - mae: 0.0041 - val_loss: 9.7949e-04 - val_mae: 0.0044\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.7288e-04 - mae: 0.0040 - val_loss: 9.7299e-04 - val_mae: 0.0044\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.6688e-04 - mae: 0.0041 - val_loss: 9.5648e-04 - val_mae: 0.0036\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.5662e-04 - mae: 0.0039 - val_loss: 9.5393e-04 - val_mae: 0.0039\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.5498e-04 - mae: 0.0043 - val_loss: 9.4979e-04 - val_mae: 0.0043\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.4715e-04 - mae: 0.0043 - val_loss: 9.3479e-04 - val_mae: 0.0035\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.3571e-04 - mae: 0.0040 - val_loss: 9.3949e-04 - val_mae: 0.0046\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.2991e-04 - mae: 0.0041 - val_loss: 9.5351e-04 - val_mae: 0.0061\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.2630e-04 - mae: 0.0043 - val_loss: 9.1642e-04 - val_mae: 0.0037\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.1941e-04 - mae: 0.0043 - val_loss: 9.1282e-04 - val_mae: 0.0040\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.0824e-04 - mae: 0.0040 - val_loss: 9.0817e-04 - val_mae: 0.0041\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.0503e-04 - mae: 0.0042 - val_loss: 9.1001e-04 - val_mae: 0.0049\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.9619e-04 - mae: 0.0041 - val_loss: 9.1754e-04 - val_mae: 0.0057\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.9133e-04 - mae: 0.0042 - val_loss: 8.8442e-04 - val_mae: 0.0038\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.8543e-04 - mae: 0.0042 - val_loss: 8.7689e-04 - val_mae: 0.0037\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.7720e-04 - mae: 0.0040 - val_loss: 8.7251e-04 - val_mae: 0.0038\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.7514e-04 - mae: 0.0044 - val_loss: 8.7816e-04 - val_mae: 0.0050\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.6760e-04 - mae: 0.0043 - val_loss: 8.6279e-04 - val_mae: 0.0040\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.5969e-04 - mae: 0.0041 - val_loss: 8.5170e-04 - val_mae: 0.0036\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.5481e-04 - mae: 0.0042 - val_loss: 8.4695e-04 - val_mae: 0.0037\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.4803e-04 - mae: 0.0040 - val_loss: 8.4290e-04 - val_mae: 0.0039\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.4178e-04 - mae: 0.0040 - val_loss: 8.3350e-04 - val_mae: 0.0035\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.3531e-04 - mae: 0.0040 - val_loss: 8.2856e-04 - val_mae: 0.0036\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.3110e-04 - mae: 0.0041 - val_loss: 8.3968e-04 - val_mae: 0.0052\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.2472e-04 - mae: 0.0041 - val_loss: 8.2241e-04 - val_mae: 0.0039\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.2114e-04 - mae: 0.0042 - val_loss: 8.2362e-04 - val_mae: 0.0048\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.1533e-04 - mae: 0.0042 - val_loss: 8.1724e-04 - val_mae: 0.0047\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.0649e-04 - mae: 0.0039 - val_loss: 8.0033e-04 - val_mae: 0.0036\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.0133e-04 - mae: 0.0039 - val_loss: 7.9854e-04 - val_mae: 0.0040\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.9639e-04 - mae: 0.0040 - val_loss: 7.9366e-04 - val_mae: 0.0038\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.9197e-04 - mae: 0.0040 - val_loss: 7.8767e-04 - val_mae: 0.0038\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.9921e-04 - mae: 0.0049 - val_loss: 7.8755e-04 - val_mae: 0.0042\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.7921e-04 - mae: 0.0038 - val_loss: 7.9528e-04 - val_mae: 0.0052\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.7615e-04 - mae: 0.0040 - val_loss: 7.8421e-04 - val_mae: 0.0048\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.7275e-04 - mae: 0.0041 - val_loss: 7.7042e-04 - val_mae: 0.0040\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.6580e-04 - mae: 0.0039 - val_loss: 7.7206e-04 - val_mae: 0.0046\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.6206e-04 - mae: 0.0040 - val_loss: 7.6051e-04 - val_mae: 0.0041\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.5875e-04 - mae: 0.0042 - val_loss: 7.5143e-04 - val_mae: 0.0036\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.5202e-04 - mae: 0.0040 - val_loss: 7.4476e-04 - val_mae: 0.0035\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.5347e-04 - mae: 0.0045 - val_loss: 7.4038e-04 - val_mae: 0.0034\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.4624e-04 - mae: 0.0042 - val_loss: 7.3846e-04 - val_mae: 0.0038\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.3927e-04 - mae: 0.0040 - val_loss: 7.3408e-04 - val_mae: 0.0038\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.3402e-04 - mae: 0.0039 - val_loss: 7.3033e-04 - val_mae: 0.0038\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.3056e-04 - mae: 0.0040 - val_loss: 7.2382e-04 - val_mae: 0.0035\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.2756e-04 - mae: 0.0042 - val_loss: 7.3210e-04 - val_mae: 0.0047\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.2320e-04 - mae: 0.0041 - val_loss: 7.2263e-04 - val_mae: 0.0043\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.1773e-04 - mae: 0.0040 - val_loss: 7.0973e-04 - val_mae: 0.0034\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.1928e-04 - mae: 0.0044 - val_loss: 7.0974e-04 - val_mae: 0.0039\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.0654e-04 - mae: 0.0038 - val_loss: 7.0465e-04 - val_mae: 0.0038\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.0320e-04 - mae: 0.0039 - val_loss: 7.0332e-04 - val_mae: 0.0039\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.0152e-04 - mae: 0.0041 - val_loss: 7.0629e-04 - val_mae: 0.0045\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.9741e-04 - mae: 0.0041 - val_loss: 6.9239e-04 - val_mae: 0.0037\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.9203e-04 - mae: 0.0039 - val_loss: 6.9048e-04 - val_mae: 0.0040\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.8977e-04 - mae: 0.0041 - val_loss: 6.8671e-04 - val_mae: 0.0040\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.8537e-04 - mae: 0.0041 - val_loss: 6.8585e-04 - val_mae: 0.0043\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.8032e-04 - mae: 0.0040 - val_loss: 6.8720e-04 - val_mae: 0.0047\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.8022e-04 - mae: 0.0042 - val_loss: 6.7109e-04 - val_mae: 0.0036\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.7275e-04 - mae: 0.0039 - val_loss: 6.6602e-04 - val_mae: 0.0034\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.6884e-04 - mae: 0.0039 - val_loss: 6.6532e-04 - val_mae: 0.0038\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.7050e-04 - mae: 0.0043 - val_loss: 6.8112e-04 - val_mae: 0.0056\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.6365e-04 - mae: 0.0041 - val_loss: 6.6457e-04 - val_mae: 0.0042\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.6035e-04 - mae: 0.0041 - val_loss: 6.6002e-04 - val_mae: 0.0041\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.5795e-04 - mae: 0.0042 - val_loss: 6.8311e-04 - val_mae: 0.0060\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.5133e-04 - mae: 0.0039 - val_loss: 6.6382e-04 - val_mae: 0.0050\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.4990e-04 - mae: 0.0041 - val_loss: 6.4628e-04 - val_mae: 0.0038\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 6.4427e-04 - mae: 0.0039 - val_loss: 6.3887e-04 - val_mae: 0.0035\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 6.4245e-04 - mae: 0.0040 - val_loss: 6.3417e-04 - val_mae: 0.0033\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 6.3954e-04 - mae: 0.0041 - val_loss: 6.3218e-04 - val_mae: 0.0034\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 6.3727e-04 - mae: 0.0042 - val_loss: 6.3409e-04 - val_mae: 0.0039\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 6.3148e-04 - mae: 0.0040 - val_loss: 6.4048e-04 - val_mae: 0.0048\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.2928e-04 - mae: 0.0041 - val_loss: 6.2315e-04 - val_mae: 0.0035\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.2439e-04 - mae: 0.0039 - val_loss: 6.2676e-04 - val_mae: 0.0042\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.2081e-04 - mae: 0.0039 - val_loss: 6.1537e-04 - val_mae: 0.0034\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 6.2479e-04 - mae: 0.0044 - val_loss: 6.2076e-04 - val_mae: 0.0042\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.1631e-04 - mae: 0.0040 - val_loss: 6.2266e-04 - val_mae: 0.0047\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 6.1305e-04 - mae: 0.0040 - val_loss: 6.0903e-04 - val_mae: 0.0037\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.1162e-04 - mae: 0.0041 - val_loss: 6.6125e-04 - val_mae: 0.0078\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 6.0587e-04 - mae: 0.0039 - val_loss: 6.0420e-04 - val_mae: 0.0039\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.0331e-04 - mae: 0.0039 - val_loss: 5.9917e-04 - val_mae: 0.0037\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.9951e-04 - mae: 0.0039 - val_loss: 6.0415e-04 - val_mae: 0.0043\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.0109e-04 - mae: 0.0042 - val_loss: 5.9206e-04 - val_mae: 0.0034\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.9763e-04 - mae: 0.0041 - val_loss: 6.0292e-04 - val_mae: 0.0049\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.9666e-04 - mae: 0.0043 - val_loss: 6.0760e-04 - val_mae: 0.0053\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.8795e-04 - mae: 0.0038 - val_loss: 5.8876e-04 - val_mae: 0.0039\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.8394e-04 - mae: 0.0037 - val_loss: 5.8709e-04 - val_mae: 0.0039\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.8358e-04 - mae: 0.0039 - val_loss: 5.8062e-04 - val_mae: 0.0036\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.8084e-04 - mae: 0.0039 - val_loss: 5.8114e-04 - val_mae: 0.0039\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 5.7652e-04 - mae: 0.0038 - val_loss: 5.8158e-04 - val_mae: 0.0044\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.7953e-04 - mae: 0.0043 - val_loss: 5.7276e-04 - val_mae: 0.0037\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.7437e-04 - mae: 0.0041 - val_loss: 5.6813e-04 - val_mae: 0.0035\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.6680e-04 - mae: 0.0037 - val_loss: 5.6463e-04 - val_mae: 0.0035\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.7143e-04 - mae: 0.0042 - val_loss: 5.7719e-04 - val_mae: 0.0050\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.6586e-04 - mae: 0.0040 - val_loss: 5.9815e-04 - val_mae: 0.0057\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.6421e-04 - mae: 0.0041 - val_loss: 5.6045e-04 - val_mae: 0.0038\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.6170e-04 - mae: 0.0041 - val_loss: 5.7296e-04 - val_mae: 0.0051\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.5742e-04 - mae: 0.0040 - val_loss: 5.5504e-04 - val_mae: 0.0037\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.5812e-04 - mae: 0.0042 - val_loss: 5.6243e-04 - val_mae: 0.0046\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.5166e-04 - mae: 0.0039 - val_loss: 5.4728e-04 - val_mae: 0.0034\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.4987e-04 - mae: 0.0039 - val_loss: 5.4725e-04 - val_mae: 0.0037\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.4837e-04 - mae: 0.0040 - val_loss: 5.4068e-04 - val_mae: 0.0033\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 5.4371e-04 - mae: 0.0038 - val_loss: 5.4744e-04 - val_mae: 0.0042\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.4385e-04 - mae: 0.0040 - val_loss: 5.3497e-04 - val_mae: 0.0032\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.4075e-04 - mae: 0.0040 - val_loss: 5.4187e-04 - val_mae: 0.0042\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.3681e-04 - mae: 0.0039 - val_loss: 5.4610e-04 - val_mae: 0.0046\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.3840e-04 - mae: 0.0042 - val_loss: 5.3262e-04 - val_mae: 0.0037\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.3573e-04 - mae: 0.0041 - val_loss: 5.6093e-04 - val_mae: 0.0063\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.3347e-04 - mae: 0.0041 - val_loss: 5.3062e-04 - val_mae: 0.0039\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.2874e-04 - mae: 0.0039 - val_loss: 5.2188e-04 - val_mae: 0.0033\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.2659e-04 - mae: 0.0039 - val_loss: 5.2109e-04 - val_mae: 0.0034\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.2426e-04 - mae: 0.0039 - val_loss: 5.1781e-04 - val_mae: 0.0033\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.2134e-04 - mae: 0.0038 - val_loss: 5.1929e-04 - val_mae: 0.0036\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.2113e-04 - mae: 0.0040 - val_loss: 5.3249e-04 - val_mae: 0.0052\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.1962e-04 - mae: 0.0040 - val_loss: 5.3796e-04 - val_mae: 0.0057\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.2326e-04 - mae: 0.0044 - val_loss: 5.9030e-04 - val_mae: 0.0090\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.1518e-04 - mae: 0.0040 - val_loss: 5.0797e-04 - val_mae: 0.0034\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.0917e-04 - mae: 0.0037 - val_loss: 5.0940e-04 - val_mae: 0.0037\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.1073e-04 - mae: 0.0040 - val_loss: 5.1371e-04 - val_mae: 0.0043\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.0828e-04 - mae: 0.0040 - val_loss: 5.2325e-04 - val_mae: 0.0054\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.0580e-04 - mae: 0.0039 - val_loss: 4.9887e-04 - val_mae: 0.0033\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.0360e-04 - mae: 0.0039 - val_loss: 4.9990e-04 - val_mae: 0.0035\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.0007e-04 - mae: 0.0038 - val_loss: 4.9426e-04 - val_mae: 0.0032\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.9981e-04 - mae: 0.0040 - val_loss: 4.9483e-04 - val_mae: 0.0035\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.9771e-04 - mae: 0.0039 - val_loss: 4.8985e-04 - val_mae: 0.0032\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.9969e-04 - mae: 0.0042 - val_loss: 4.9225e-04 - val_mae: 0.0036\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 4.9318e-04 - mae: 0.0039 - val_loss: 5.1464e-04 - val_mae: 0.0057\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.9080e-04 - mae: 0.0038 - val_loss: 4.9106e-04 - val_mae: 0.0038\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.9022e-04 - mae: 0.0040 - val_loss: 4.8153e-04 - val_mae: 0.0031\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.8847e-04 - mae: 0.0040 - val_loss: 4.8334e-04 - val_mae: 0.0034\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.8693e-04 - mae: 0.0040 - val_loss: 4.8188e-04 - val_mae: 0.0036\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.8951e-04 - mae: 0.0043 - val_loss: 4.9143e-04 - val_mae: 0.0047\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.8202e-04 - mae: 0.0039 - val_loss: 4.7959e-04 - val_mae: 0.0037\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.7979e-04 - mae: 0.0038 - val_loss: 4.7784e-04 - val_mae: 0.0036\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.7811e-04 - mae: 0.0038 - val_loss: 4.7443e-04 - val_mae: 0.0036\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.7579e-04 - mae: 0.0038 - val_loss: 4.7026e-04 - val_mae: 0.0032\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.7691e-04 - mae: 0.0041 - val_loss: 4.9062e-04 - val_mae: 0.0053\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.7558e-04 - mae: 0.0041 - val_loss: 4.7743e-04 - val_mae: 0.0043\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.7057e-04 - mae: 0.0038 - val_loss: 4.6470e-04 - val_mae: 0.0032\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.7145e-04 - mae: 0.0040 - val_loss: 4.6471e-04 - val_mae: 0.0034\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.6538e-04 - mae: 0.0037 - val_loss: 4.6181e-04 - val_mae: 0.0033\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.6570e-04 - mae: 0.0038 - val_loss: 4.6128e-04 - val_mae: 0.0034\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.6428e-04 - mae: 0.0039 - val_loss: 4.6333e-04 - val_mae: 0.0038\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.6510e-04 - mae: 0.0041 - val_loss: 4.6578e-04 - val_mae: 0.0042\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.6245e-04 - mae: 0.0040 - val_loss: 4.5452e-04 - val_mae: 0.0032\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.6100e-04 - mae: 0.0040 - val_loss: 4.7872e-04 - val_mae: 0.0054\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.5644e-04 - mae: 0.0038 - val_loss: 4.6160e-04 - val_mae: 0.0042\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.5758e-04 - mae: 0.0040 - val_loss: 4.5255e-04 - val_mae: 0.0035\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.5434e-04 - mae: 0.0039 - val_loss: 4.5327e-04 - val_mae: 0.0038\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.5342e-04 - mae: 0.0039 - val_loss: 4.6245e-04 - val_mae: 0.0047\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.5813e-04 - mae: 0.0044 - val_loss: 4.5059e-04 - val_mae: 0.0038\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.4894e-04 - mae: 0.0038 - val_loss: 4.5735e-04 - val_mae: 0.0046\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 4.4578e-04 - mae: 0.0037 - val_loss: 4.4627e-04 - val_mae: 0.0037\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 4.4720e-04 - mae: 0.0039 - val_loss: 4.4203e-04 - val_mae: 0.0034\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.4441e-04 - mae: 0.0038 - val_loss: 4.4843e-04 - val_mae: 0.0042\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 4.4700e-04 - mae: 0.0041 - val_loss: 4.4826e-04 - val_mae: 0.0043\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 4.4215e-04 - mae: 0.0039 - val_loss: 4.5238e-04 - val_mae: 0.0047\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.3828e-04 - mae: 0.0037 - val_loss: 4.3751e-04 - val_mae: 0.0036\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.3919e-04 - mae: 0.0039 - val_loss: 4.5049e-04 - val_mae: 0.0048\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 4.3842e-04 - mae: 0.0040 - val_loss: 4.3974e-04 - val_mae: 0.0042\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 4.3728e-04 - mae: 0.0040 - val_loss: 4.3319e-04 - val_mae: 0.0036\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.3416e-04 - mae: 0.0038 - val_loss: 4.2739e-04 - val_mae: 0.0031\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.3611e-04 - mae: 0.0041 - val_loss: 4.2729e-04 - val_mae: 0.0032\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 4.2929e-04 - mae: 0.0037 - val_loss: 4.2998e-04 - val_mae: 0.0037\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 4.2823e-04 - mae: 0.0037 - val_loss: 4.4993e-04 - val_mae: 0.0056\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.3293e-04 - mae: 0.0042 - val_loss: 4.2388e-04 - val_mae: 0.0034\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.3164e-04 - mae: 0.0042 - val_loss: 4.2294e-04 - val_mae: 0.0034\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 4.2305e-04 - mae: 0.0036 - val_loss: 4.4055e-04 - val_mae: 0.0051\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.2872e-04 - mae: 0.0042 - val_loss: 4.2138e-04 - val_mae: 0.0035\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.2434e-04 - mae: 0.0040 - val_loss: 4.2098e-04 - val_mae: 0.0036\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.2186e-04 - mae: 0.0038 - val_loss: 4.2310e-04 - val_mae: 0.0038\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.2107e-04 - mae: 0.0039 - val_loss: 4.1604e-04 - val_mae: 0.0034\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.1694e-04 - mae: 0.0037 - val_loss: 4.2877e-04 - val_mae: 0.0047\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.1954e-04 - mae: 0.0040 - val_loss: 4.2153e-04 - val_mae: 0.0041\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.1631e-04 - mae: 0.0038 - val_loss: 4.1759e-04 - val_mae: 0.0039\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.1663e-04 - mae: 0.0040 - val_loss: 4.1544e-04 - val_mae: 0.0040\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.1279e-04 - mae: 0.0037 - val_loss: 4.1456e-04 - val_mae: 0.0038\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.1111e-04 - mae: 0.0037 - val_loss: 4.1954e-04 - val_mae: 0.0047\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 4.1510e-04 - mae: 0.0042 - val_loss: 4.3445e-04 - val_mae: 0.0052\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 4.1162e-04 - mae: 0.0040 - val_loss: 4.1796e-04 - val_mae: 0.0046\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.0896e-04 - mae: 0.0039 - val_loss: 4.0659e-04 - val_mae: 0.0036\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.0531e-04 - mae: 0.0037 - val_loss: 4.0256e-04 - val_mae: 0.0033\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.0739e-04 - mae: 0.0039 - val_loss: 4.0337e-04 - val_mae: 0.0035\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.0402e-04 - mae: 0.0038 - val_loss: 4.0791e-04 - val_mae: 0.0042\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.0609e-04 - mae: 0.0040 - val_loss: 4.0855e-04 - val_mae: 0.0042\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.0610e-04 - mae: 0.0040 - val_loss: 3.9804e-04 - val_mae: 0.0032\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.0310e-04 - mae: 0.0040 - val_loss: 3.9719e-04 - val_mae: 0.0033\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.9817e-04 - mae: 0.0036 - val_loss: 3.9755e-04 - val_mae: 0.0034\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.9767e-04 - mae: 0.0037 - val_loss: 4.0449e-04 - val_mae: 0.0045\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.9988e-04 - mae: 0.0040 - val_loss: 3.9224e-04 - val_mae: 0.0032\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.0240e-04 - mae: 0.0043 - val_loss: 4.3082e-04 - val_mae: 0.0065\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.9927e-04 - mae: 0.0041 - val_loss: 3.9983e-04 - val_mae: 0.0042\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.9348e-04 - mae: 0.0037 - val_loss: 4.0178e-04 - val_mae: 0.0043\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.9088e-04 - mae: 0.0036 - val_loss: 3.9130e-04 - val_mae: 0.0035\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.9574e-04 - mae: 0.0041 - val_loss: 3.8669e-04 - val_mae: 0.0032\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.9264e-04 - mae: 0.0040 - val_loss: 3.8691e-04 - val_mae: 0.0033\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.8970e-04 - mae: 0.0038 - val_loss: 3.8900e-04 - val_mae: 0.0037\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 3.9209e-04 - mae: 0.0041 - val_loss: 3.8550e-04 - val_mae: 0.0035\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.8938e-04 - mae: 0.0040 - val_loss: 3.8729e-04 - val_mae: 0.0038\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.8615e-04 - mae: 0.0038 - val_loss: 3.8172e-04 - val_mae: 0.0032\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.8688e-04 - mae: 0.0039 - val_loss: 3.8168e-04 - val_mae: 0.0033\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.8338e-04 - mae: 0.0037 - val_loss: 3.8513e-04 - val_mae: 0.0039\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.8827e-04 - mae: 0.0042 - val_loss: 3.8082e-04 - val_mae: 0.0035\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.8251e-04 - mae: 0.0038 - val_loss: 3.7645e-04 - val_mae: 0.0031\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.8012e-04 - mae: 0.0037 - val_loss: 3.7800e-04 - val_mae: 0.0034\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.8138e-04 - mae: 0.0039 - val_loss: 3.9199e-04 - val_mae: 0.0049\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.7849e-04 - mae: 0.0037 - val_loss: 3.7663e-04 - val_mae: 0.0035\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.7848e-04 - mae: 0.0038 - val_loss: 3.7417e-04 - val_mae: 0.0034\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.7908e-04 - mae: 0.0040 - val_loss: 3.7192e-04 - val_mae: 0.0032\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.7825e-04 - mae: 0.0040 - val_loss: 3.7911e-04 - val_mae: 0.0041\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.8066e-04 - mae: 0.0043 - val_loss: 3.7178e-04 - val_mae: 0.0034\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.7270e-04 - mae: 0.0037 - val_loss: 3.8283e-04 - val_mae: 0.0046\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.7396e-04 - mae: 0.0038 - val_loss: 3.7476e-04 - val_mae: 0.0039\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.7282e-04 - mae: 0.0038 - val_loss: 3.7089e-04 - val_mae: 0.0036\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.7424e-04 - mae: 0.0040 - val_loss: 3.6897e-04 - val_mae: 0.0035\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.7432e-04 - mae: 0.0041 - val_loss: 3.6734e-04 - val_mae: 0.0034\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.6916e-04 - mae: 0.0038 - val_loss: 3.6701e-04 - val_mae: 0.0035\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.7160e-04 - mae: 0.0040 - val_loss: 3.6753e-04 - val_mae: 0.0037\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.6702e-04 - mae: 0.0037 - val_loss: 3.6421e-04 - val_mae: 0.0034\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.6872e-04 - mae: 0.0040 - val_loss: 3.6871e-04 - val_mae: 0.0039\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.6576e-04 - mae: 0.0038 - val_loss: 3.6305e-04 - val_mae: 0.0035\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.6389e-04 - mae: 0.0037 - val_loss: 3.6666e-04 - val_mae: 0.0038\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.6319e-04 - mae: 0.0037 - val_loss: 3.7701e-04 - val_mae: 0.0050\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.6503e-04 - mae: 0.0040 - val_loss: 3.7506e-04 - val_mae: 0.0050\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.6120e-04 - mae: 0.0037 - val_loss: 3.5756e-04 - val_mae: 0.0032\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.6167e-04 - mae: 0.0039 - val_loss: 3.5813e-04 - val_mae: 0.0034\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.6141e-04 - mae: 0.0039 - val_loss: 3.5703e-04 - val_mae: 0.0035\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.6159e-04 - mae: 0.0040 - val_loss: 3.5920e-04 - val_mae: 0.0038\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.5696e-04 - mae: 0.0037 - val_loss: 3.6803e-04 - val_mae: 0.0047\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.6338e-04 - mae: 0.0043 - val_loss: 3.5519e-04 - val_mae: 0.0035\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.5452e-04 - mae: 0.0036 - val_loss: 3.5375e-04 - val_mae: 0.0034\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.5854e-04 - mae: 0.0040 - val_loss: 3.5517e-04 - val_mae: 0.0037\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.5446e-04 - mae: 0.0037 - val_loss: 3.6219e-04 - val_mae: 0.0043\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.5509e-04 - mae: 0.0039 - val_loss: 3.5946e-04 - val_mae: 0.0042\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.5634e-04 - mae: 0.0041 - val_loss: 3.4958e-04 - val_mae: 0.0034\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.5223e-04 - mae: 0.0038 - val_loss: 3.4676e-04 - val_mae: 0.0031\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.5423e-04 - mae: 0.0040 - val_loss: 3.6527e-04 - val_mae: 0.0051\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.4999e-04 - mae: 0.0037 - val_loss: 3.5204e-04 - val_mae: 0.0039\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.5290e-04 - mae: 0.0040 - val_loss: 3.4495e-04 - val_mae: 0.0032\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.4908e-04 - mae: 0.0038 - val_loss: 3.4998e-04 - val_mae: 0.0038\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.4698e-04 - mae: 0.0036 - val_loss: 3.7213e-04 - val_mae: 0.0057\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.4786e-04 - mae: 0.0038 - val_loss: 3.5751e-04 - val_mae: 0.0045\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.4908e-04 - mae: 0.0040 - val_loss: 3.4218e-04 - val_mae: 0.0032\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.4539e-04 - mae: 0.0037 - val_loss: 3.5430e-04 - val_mae: 0.0045\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.4621e-04 - mae: 0.0039 - val_loss: 3.3924e-04 - val_mae: 0.0031\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.4826e-04 - mae: 0.0041 - val_loss: 3.4714e-04 - val_mae: 0.0039\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.4161e-04 - mae: 0.0036 - val_loss: 3.4479e-04 - val_mae: 0.0038\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.4406e-04 - mae: 0.0039 - val_loss: 3.5053e-04 - val_mae: 0.0044\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.4278e-04 - mae: 0.0038 - val_loss: 3.4368e-04 - val_mae: 0.0039\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.4600e-04 - mae: 0.0041 - val_loss: 3.3863e-04 - val_mae: 0.0035\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.3935e-04 - mae: 0.0037 - val_loss: 3.3619e-04 - val_mae: 0.0032\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.4389e-04 - mae: 0.0041 - val_loss: 3.4852e-04 - val_mae: 0.0046\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.4041e-04 - mae: 0.0039 - val_loss: 3.4360e-04 - val_mae: 0.0041\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.3649e-04 - mae: 0.0036 - val_loss: 3.3300e-04 - val_mae: 0.0032\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.3776e-04 - mae: 0.0038 - val_loss: 3.3541e-04 - val_mae: 0.0035\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.3790e-04 - mae: 0.0039 - val_loss: 3.3541e-04 - val_mae: 0.0036\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.3918e-04 - mae: 0.0040 - val_loss: 3.6214e-04 - val_mae: 0.0060\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.3335e-04 - mae: 0.0036 - val_loss: 3.3149e-04 - val_mae: 0.0033\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.3918e-04 - mae: 0.0041 - val_loss: 3.2961e-04 - val_mae: 0.0032\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.3720e-04 - mae: 0.0040 - val_loss: 3.3893e-04 - val_mae: 0.0043\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.3222e-04 - mae: 0.0037 - val_loss: 3.3140e-04 - val_mae: 0.0036\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.3639e-04 - mae: 0.0041 - val_loss: 3.3266e-04 - val_mae: 0.0037\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.3319e-04 - mae: 0.0039 - val_loss: 3.3013e-04 - val_mae: 0.0035\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.2969e-04 - mae: 0.0036 - val_loss: 3.2646e-04 - val_mae: 0.0032\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.3059e-04 - mae: 0.0038 - val_loss: 3.3761e-04 - val_mae: 0.0041\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.3035e-04 - mae: 0.0038 - val_loss: 3.4547e-04 - val_mae: 0.0052\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.2960e-04 - mae: 0.0038 - val_loss: 3.3804e-04 - val_mae: 0.0046\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.2856e-04 - mae: 0.0038 - val_loss: 3.2466e-04 - val_mae: 0.0032\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.2827e-04 - mae: 0.0038 - val_loss: 3.4071e-04 - val_mae: 0.0048\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.2790e-04 - mae: 0.0039 - val_loss: 3.2928e-04 - val_mae: 0.0039\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.2573e-04 - mae: 0.0037 - val_loss: 3.2993e-04 - val_mae: 0.0041\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.2991e-04 - mae: 0.0041 - val_loss: 3.2257e-04 - val_mae: 0.0034\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 3.2730e-04 - mae: 0.0039 - val_loss: 3.3206e-04 - val_mae: 0.0043\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.2321e-04 - mae: 0.0037 - val_loss: 3.2131e-04 - val_mae: 0.0032\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.2360e-04 - mae: 0.0038 - val_loss: 3.2421e-04 - val_mae: 0.0037\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 3.2322e-04 - mae: 0.0038 - val_loss: 3.2284e-04 - val_mae: 0.0036\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.2154e-04 - mae: 0.0037 - val_loss: 3.2270e-04 - val_mae: 0.0036\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.2258e-04 - mae: 0.0038 - val_loss: 3.2556e-04 - val_mae: 0.0041\n",
      "Epoch 494/1000\n",
      "267/270 [============================>.] - ETA: 0s - loss: 3.2157e-04 - mae: 0.0038Restoring model weights from the end of the best epoch: 489.\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.2150e-04 - mae: 0.0038 - val_loss: 3.3432e-04 - val_mae: 0.0050\n",
      "Epoch 494: early stopping\n",
      "Durchschnittlicher Validation Loss: 0.00039309572312049566\n",
      "Durchschnittlicher Validation MAE: 0.0031488311477005483\n"
     ]
    }
   ],
   "source": [
    " # Initialisiere Listen, um Ergebnisse zu speichern\n",
    "val_loss_results = []\n",
    "val_mae_results = []\n",
    "\n",
    "# Funktion, um das Modell zu erstellen\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "\n",
    "                            Dense(200, activation='relu', input_shape=(5,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "                            Dense(232, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "                            Dense(88, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "                            Dense(216, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "                            Dense(280, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "                            Dense(88, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "                            Dense(88, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "                            Dense(88, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "                            Dense(1 , activation = 'linear')\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# K-Fold Cross-Validation Konfiguration\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# LeistungsÃ¼berwachung\n",
    "fold_no = 1\n",
    "for train_index, val_index in kf.split(X_train_scaled):\n",
    "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_scaled[train_index], y_train_scaled[val_index]\n",
    "\n",
    "    model = create_model()\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "    print(f'Training fÃ¼r Fold {fold_no}...')\n",
    "    history = model.fit(X_train_fold, y_train_fold, batch_size=200, epochs=1000, validation_data=(X_val_fold, y_val_fold), callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "    # Speichere die Ergebnisse des aktuellen Folds\n",
    "    val_loss_results.append(min(history.history['val_loss']))\n",
    "    val_mae_results.append(min(history.history['val_mae']))\n",
    "\n",
    "    fold_no += 1\n",
    "\n",
    "# Berechne den Durchschnitt Ã¼ber alle Folds\n",
    "average_val_loss = np.mean(val_loss_results)\n",
    "average_val_mae = np.mean(val_mae_results)\n",
    "\n",
    "# Umwandeln der Listen in Pandas DataFrames\n",
    "val_loss_df = pd.DataFrame(val_loss_results, columns=['Validation Loss'])\n",
    "val_mae_df = pd.DataFrame(val_mae_results, columns=['Validation MAE'])\n",
    "\n",
    "# Speichern der DataFrames in CSV-Dateien\n",
    "val_loss_df.to_csv('val_loss_results_D4_t_I_F_3.csv', index=False)\n",
    "val_mae_df.to_csv('val_mae_results_D4_t_I_F_3.csv', index=False)\n",
    "\n",
    "# Gib die durchschnittlichen Ergebnisse aus\n",
    "print(f'Durchschnittlicher Validation Loss: {average_val_loss}')\n",
    "print(f'Durchschnittlicher Validation MAE: {average_val_mae}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T09:58:57.250630300Z",
     "start_time": "2024-04-02T09:04:53.646240500Z"
    }
   },
   "id": "929336b1a7ac475d"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 - 0s - loss: 4.0516e-04 - mae: 0.0041 - 64ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.0004051643772982061, 0.004083062522113323]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test_scaled_2, y_test_scaled_2, verbose=2)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T10:24:17.169021700Z",
     "start_time": "2024-04-02T10:24:17.025166400Z"
    }
   },
   "id": "4b02697cbcecd185"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bsp. Predicted: [772.46246] Actual: [754.68] \n",
      "Durchschnittliche Abweichung (MAE): [9.05591286]\n",
      "0.727207976078563\n"
     ]
    }
   ],
   "source": [
    "scaled_predicted_values = model.predict(X_test_scaled_2, verbose = 0)\n",
    "\n",
    "# FÃ¼hren Sie die RÃ¼cktransformation der skalierten Werte durch\n",
    "original_predicted_values = scaler_target.inverse_transform(scaled_predicted_values)\n",
    "original_actual_values = scaler_target.inverse_transform(y_test_scaled_2)  # y_test sind die skalierten tatsÃ¤chlichen Werte\n",
    "print(f' Bsp. Predicted: {original_predicted_values[100]} Actual: {original_actual_values[100]} ')\n",
    "\n",
    "def calculate_mae(list1, list2):\n",
    "    # Stelle sicher, dass beide Listen die gleiche LÃ¤nge haben\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Listen mÃ¼ssen die gleiche LÃ¤nge haben\")\n",
    "\n",
    "    # Berechne die absolute Differenz zwischen den Elementen der Listen\n",
    "    differences = [abs(x - y) for x, y in zip(list1, list2)]\n",
    "\n",
    "    # Berechne den Durchschnitt der absoluten Differenzen\n",
    "    mae = sum(differences) / len(differences)\n",
    "\n",
    "    return mae\n",
    "\n",
    "# Beispiel\n",
    "list1 = original_predicted_values\n",
    "list2 = original_actual_values\n",
    "\n",
    "mae = calculate_mae(list1, list2)\n",
    "print(f\"Durchschnittliche Abweichung (MAE): {mae}\")\n",
    "\n",
    "errors = np.abs((original_actual_values - original_predicted_values) / original_actual_values)\n",
    "mape = np.mean(errors) * 100\n",
    "print(mape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T10:24:43.541951200Z",
     "start_time": "2024-04-02T10:24:43.310893Z"
    }
   },
   "id": "a402d28abbd82f60"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Werte die kleiner sind: 99\n"
     ]
    },
    {
     "data": {
      "text/plain": "             Echt  Vorhergesagt  X-Koordinate  Y-Koordinate  Zeitpunkt  \\\n464   1203.249268       1243.30          0.45          0.10        1.0   \n465   1285.497681       1324.40          0.45          0.12        1.0   \n413   1209.738770       1248.50          0.40          0.10        1.0   \n515   1198.858154       1237.40          0.50          0.10        1.0   \n414   1291.585083       1330.00          0.40          0.12        1.0   \n...           ...           ...           ...           ...        ...   \n253    779.971313        752.88          0.20          0.98        1.0   \n304    779.003296        751.80          0.25          0.98        1.0   \n406    776.215698        749.00          0.35          0.98        1.0   \n1069   735.995361        708.11          1.00          0.98        1.0   \n355    778.476257        750.51          0.30          0.98        1.0   \n\n         Strom  Kraft  Differenz  \n464   0.333333   0.25 -40.050732  \n465   0.333333   0.25 -38.902319  \n413   0.333333   0.25 -38.761230  \n515   0.333333   0.25 -38.541846  \n414   0.333333   0.25 -38.414917  \n...        ...    ...        ...  \n253   0.333333   0.25  27.091313  \n304   0.333333   0.25  27.203296  \n406   0.333333   0.25  27.215698  \n1069  0.333333   0.25  27.885361  \n355   0.333333   0.25  27.966257  \n\n[1071 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Echt</th>\n      <th>Vorhergesagt</th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Differenz</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>464</th>\n      <td>1203.249268</td>\n      <td>1243.30</td>\n      <td>0.45</td>\n      <td>0.10</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.25</td>\n      <td>-40.050732</td>\n    </tr>\n    <tr>\n      <th>465</th>\n      <td>1285.497681</td>\n      <td>1324.40</td>\n      <td>0.45</td>\n      <td>0.12</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.25</td>\n      <td>-38.902319</td>\n    </tr>\n    <tr>\n      <th>413</th>\n      <td>1209.738770</td>\n      <td>1248.50</td>\n      <td>0.40</td>\n      <td>0.10</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.25</td>\n      <td>-38.761230</td>\n    </tr>\n    <tr>\n      <th>515</th>\n      <td>1198.858154</td>\n      <td>1237.40</td>\n      <td>0.50</td>\n      <td>0.10</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.25</td>\n      <td>-38.541846</td>\n    </tr>\n    <tr>\n      <th>414</th>\n      <td>1291.585083</td>\n      <td>1330.00</td>\n      <td>0.40</td>\n      <td>0.12</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.25</td>\n      <td>-38.414917</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>253</th>\n      <td>779.971313</td>\n      <td>752.88</td>\n      <td>0.20</td>\n      <td>0.98</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.25</td>\n      <td>27.091313</td>\n    </tr>\n    <tr>\n      <th>304</th>\n      <td>779.003296</td>\n      <td>751.80</td>\n      <td>0.25</td>\n      <td>0.98</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.25</td>\n      <td>27.203296</td>\n    </tr>\n    <tr>\n      <th>406</th>\n      <td>776.215698</td>\n      <td>749.00</td>\n      <td>0.35</td>\n      <td>0.98</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.25</td>\n      <td>27.215698</td>\n    </tr>\n    <tr>\n      <th>1069</th>\n      <td>735.995361</td>\n      <td>708.11</td>\n      <td>1.00</td>\n      <td>0.98</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.25</td>\n      <td>27.885361</td>\n    </tr>\n    <tr>\n      <th>355</th>\n      <td>778.476257</td>\n      <td>750.51</td>\n      <td>0.30</td>\n      <td>0.98</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.25</td>\n      <td>27.966257</td>\n    </tr>\n  </tbody>\n</table>\n<p>1071 rows Ã— 8 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame({'Echt': [val[0] for val in list1], 'Vorhergesagt': [val[0] for val in list2]})\n",
    "df_result['X-Koordinate'] = X_test_scaled_2[:, 0]\n",
    "df_result['Y-Koordinate'] = X_test_scaled_2[:, 1]\n",
    "df_result['Zeitpunkt'] = X_test_scaled_2[:, 2]\n",
    "df_result['Strom'] = X_test_scaled_2[:, 3]\n",
    "df_result['Kraft'] = X_test_scaled_2[:, 4]\n",
    "\n",
    "df_result['Differenz'] = df_result['Echt'] - df_result['Vorhergesagt']\n",
    "df_result['Differenz'].sort_values()\n",
    "sorted_df = df_result.sort_values(by= 'Differenz')\n",
    "Anzahl_Punkte = (sorted_df['Differenz'] < -20).sum()\n",
    "print(\"Anzahl der Werte die kleiner sind:\", Anzahl_Punkte)\n",
    "\n",
    "sorted_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T09:03:45.521822600Z",
     "start_time": "2024-04-02T09:03:45.434442Z"
    }
   },
   "id": "7ffe8ddf2200f429"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: [0.99905697]\n"
     ]
    }
   ],
   "source": [
    "#Berechnung der AuswertungsgrÃ¶ÃŸe R^2\n",
    "\n",
    "def calculate_r_squared(predicted, actual):\n",
    "    # Berechnung des Mittelwerts der tatsÃ¤chlichen Werte\n",
    "    mean_actual = sum(actual) / len(actual)\n",
    "    \n",
    "    # Berechnung der totalen Summe der Quadrate (SST)\n",
    "    sst = sum((x - mean_actual) ** 2 for x in actual)\n",
    "    \n",
    "    # Berechnung der Summe der Quadrate der Residuen (SSE)\n",
    "    sse = sum((actual[i] - predicted[i]) ** 2 for i in range(len(actual)))\n",
    "    \n",
    "    # Berechnung des R^2-Wertes\n",
    "    r_squared = 1 - (sse / sst)\n",
    "    \n",
    "    return r_squared\n",
    "\n",
    "# Berechnung von R^2 mit den bereitgestellten Listen\n",
    "r_squared = calculate_r_squared(list1, list2)\n",
    "\n",
    "print(f\"R^2: {r_squared}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T10:25:07.467733900Z",
     "start_time": "2024-04-02T10:25:07.409070500Z"
    }
   },
   "id": "4c350477801f0961"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mae = history.history['loss']\n",
    "val_mae = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(mae) + 1)\n",
    "\n",
    "# MAE Diagramm\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, mae, 'r', label='Training MSE')\n",
    "plt.plot(epochs, val_mae, 'b', label='Validation MSE')\n",
    "plt.title('Training and Validation MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T13:19:36.804139100Z",
     "start_time": "2024-03-20T13:19:36.515474400Z"
    }
   },
   "id": "3688dd7102e95baf"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mae = history.history['mae']\n",
    "val_mae = history.history['val_mae']\n",
    "\n",
    "epochs = range(1, len(mae) + 1)\n",
    "\n",
    "# MAE Diagramm\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, mae, 'r', label='Training MAE')\n",
    "plt.plot(epochs, val_mae, 'b', label='Validation MAE')\n",
    "plt.title('Training and Validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "#plt.ylim(0.00, 0.01)\n",
    "\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T13:19:49.232762600Z",
     "start_time": "2024-03-20T13:19:49.099626600Z"
    }
   },
   "id": "b8d71e5c44c48bef"
  },
  {
   "cell_type": "markdown",
   "id": "553df6fa",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x000001B625802E50>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 770, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 47\u001B[0m\n\u001B[0;32m     45\u001B[0m grid_search \u001B[38;5;241m=\u001B[39m GridSearchCV(estimator\u001B[38;5;241m=\u001B[39mmodel, param_grid\u001B[38;5;241m=\u001B[39mparam_grid, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m     46\u001B[0m \u001B[38;5;66;03m# Hinweis: Stellen Sie sicher, dass Ihre Daten (X_train_scaled, y_train_scaled) korrekt definiert sind\u001B[39;00m\n\u001B[1;32m---> 47\u001B[0m grid_result \u001B[38;5;241m=\u001B[39m \u001B[43mgrid_search\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_scaled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train_scaled\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;66;03m# Beste Parameter und Score ausgeben\u001B[39;00m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBeste Parameter:\u001B[39m\u001B[38;5;124m\"\u001B[39m, grid_search\u001B[38;5;241m.\u001B[39mbest_params_)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\base.py:1351\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1344\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1346\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1347\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1348\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1349\u001B[0m     )\n\u001B[0;32m   1350\u001B[0m ):\n\u001B[1;32m-> 1351\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, **params)\u001B[0m\n\u001B[0;32m    964\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m    965\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m    966\u001B[0m     )\n\u001B[0;32m    968\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m--> 970\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    972\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m    973\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m    974\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1525\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1526\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1527\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    908\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    909\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m    910\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    911\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    912\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[0;32m    913\u001B[0m         )\n\u001B[0;32m    914\u001B[0m     )\n\u001B[1;32m--> 916\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    917\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    918\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    919\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    920\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    921\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    922\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    923\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    924\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    925\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    926\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    927\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    928\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    929\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    930\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrouted_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplitter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    931\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    932\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    934\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    935\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    936\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    937\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    938\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    939\u001B[0m     )\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     62\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     63\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     64\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     66\u001B[0m )\n\u001B[1;32m---> 67\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\joblib\\parallel.py:1952\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1946\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[0;32m   1947\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[0;32m   1948\u001B[0m \u001B[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001B[39;00m\n\u001B[0;32m   1949\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[0;32m   1950\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 1952\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\joblib\\parallel.py:1595\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[1;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[0;32m   1592\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[0;32m   1594\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[1;32m-> 1595\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[0;32m   1597\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[0;32m   1598\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[0;32m   1599\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[0;32m   1600\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[0;32m   1601\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\joblib\\parallel.py:1707\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1702\u001B[0m \u001B[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001B[39;00m\n\u001B[0;32m   1703\u001B[0m \u001B[38;5;66;03m# async callbacks to progress.\u001B[39;00m\n\u001B[0;32m   1704\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ((\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m   1705\u001B[0m     (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mget_status(\n\u001B[0;32m   1706\u001B[0m         timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout) \u001B[38;5;241m==\u001B[39m TASK_PENDING)):\n\u001B[1;32m-> 1707\u001B[0m     time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m0.01\u001B[39m)\n\u001B[0;32m   1708\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m   1710\u001B[0m \u001B[38;5;66;03m# We need to be careful: the job list can be filling up as\u001B[39;00m\n\u001B[0;32m   1711\u001B[0m \u001B[38;5;66;03m# we empty it and Python list are not thread-safe by\u001B[39;00m\n\u001B[0;32m   1712\u001B[0m \u001B[38;5;66;03m# default hence the use of the lock\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def build_model(learning_rate=0.00001, activation='relu', regularization=0.00001, dropout_rate=0.0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(232, activation=activation, input_shape=(3,), kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(152, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(232, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Verwenden Sie eine Funktion, um das Modell zu instanziieren, fÃ¼r scikit-learn Wrapper\n",
    "model = KerasRegressor(model=build_model, verbose=2, callbacks=[early_stopping])\n",
    "\n",
    "# Anpassung der Parameter im param_grid\n",
    "param_grid = {\n",
    "    'model__learning_rate': [0.00001],\n",
    "    'model__regularization': [0.00001],\n",
    "    'fit__batch_size': [16, 32, 64, 100],\n",
    "    'fit__epochs': [100],\n",
    "    'model__dropout_rate' : [0.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=2)\n",
    "# Hinweis: Stellen Sie sicher, dass Ihre Daten (X_train_scaled, y_train_scaled) korrekt definiert sind\n",
    "grid_result = grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "# Beste Parameter und Score ausgeben\n",
    "print(\"Beste Parameter:\", grid_search.best_params_)\n",
    "print(\"Beste Genauigkeit:\", grid_search.best_score_)\n",
    "\n",
    "with open(\"Gridsearch_D4_t_1.txt\", \"w\") as f:\n",
    "    f.write(f\"Beste Parameter: {grid_search.best_params_}\\n\")\n",
    "    f.write(f\"Beste Genauigkeit: {grid_search.best_score_}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T12:15:54.960082300Z",
     "start_time": "2024-03-18T11:56:34.729533600Z"
    }
   },
   "id": "7464a951f44a07ee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Funktion zum Erstellen des Modells\n",
    "# def build_model(hp):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(hp.Int('input_units', min_value=8, max_value=328, step=16), input_shape=(3,), activation='relu'))\n",
    "#     for i in range(hp.Int('n_layers', 1, 10)):\n",
    "#         model.add(Dense(hp.Int(f'units_{i}', min_value=8, max_value=328, step=16), activation='relu'))\n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     return model\n",
    "# \n",
    "# # DurchfÃ¼hrung der Random Search dreimal\n",
    "# for run in range(1, 4):\n",
    "#     # Anpassen des Verzeichnisses und des Projektnamens fÃ¼r jeden Durchlauf\n",
    "#     directory = 'random_search'\n",
    "#     project_name = f'random_search_D4_t_1_{run}'\n",
    "# \n",
    "#     tuner = RandomSearch(\n",
    "#         build_model,\n",
    "#         objective='val_loss',\n",
    "#         max_trials=100,\n",
    "#         executions_per_trial=2,\n",
    "#         directory=directory,\n",
    "#         project_name=project_name\n",
    "#     )\n",
    "# \n",
    "#     # DurchfÃ¼hrung des Random Search\n",
    "#     tuner.search(X_train_scaled, y_train_scaled, epochs=50, verbose =0, batch_size=50, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "# \n",
    "#     # Abrufen und Speichern des besten Modells\n",
    "#     best_model = tuner.get_best_models(num_models=1)[0]\n",
    "#     model_path = os.path.join(directory, project_name, 'best_model.h5') \n",
    "#     best_model.save(model_path)\n",
    "# \n",
    "# \n",
    "#     # Optional: Abrufen und Ausgeben der besten Hyperparameter\n",
    "#     best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "# \n",
    "#     # Konvertieren der Hyperparameter in ein DataFrame\n",
    "#     df_hyperparameters = pd.DataFrame([best_hyperparameters.values])\n",
    "#     # Speichern des DataFrame als CSV\n",
    "#     df_hyperparameters.to_csv(f'random_search_D4_t_1_{run}.csv', index=False)\n",
    "# \n",
    "#     print(f\"Beste Hyperparameter fÃ¼r Lauf {run}: {best_hyperparameters.values}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T10:03:46.649218900Z"
    }
   },
   "id": "d0f02feb42b652f5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T10:03:46.650224Z"
    }
   },
   "id": "3e35d5ebef369658"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
