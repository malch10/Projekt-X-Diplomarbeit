{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94b0518e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T15:19:01.369436700Z",
     "start_time": "2024-04-02T15:19:01.330976300Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense , Dropout\n",
    "from scikeras.wrappers import KerasRegressor \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4ff61b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T15:20:45.093956400Z",
     "start_time": "2024-04-02T15:20:45.012564900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n0             0.0000      -0.00200        100   6000   5000      449.80\n1             0.0000      -0.00192        100   6000   5000      479.76\n2             0.0000      -0.00184        100   6000   5000      506.60\n3             0.0000      -0.00176        100   6000   5000      530.80\n4             0.0000      -0.00168        100   6000   5000      552.15\n...              ...           ...        ...    ...    ...         ...\n351283        0.0024       0.00168        500   9000   5000     1365.50\n351284        0.0024       0.00176        500   9000   5000     1247.20\n351285        0.0024       0.00184        500   9000   5000     1114.10\n351286        0.0024       0.00192        500   9000   5000      983.97\n351287        0.0024       0.00200        500   9000   5000      942.84\n\n[179928 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>449.80</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0000</td>\n      <td>-0.00192</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>479.76</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0000</td>\n      <td>-0.00184</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>506.60</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0000</td>\n      <td>-0.00176</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>530.80</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0000</td>\n      <td>-0.00168</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>552.15</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>351283</th>\n      <td>0.0024</td>\n      <td>0.00168</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1365.50</td>\n    </tr>\n    <tr>\n      <th>351284</th>\n      <td>0.0024</td>\n      <td>0.00176</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1247.20</td>\n    </tr>\n    <tr>\n      <th>351285</th>\n      <td>0.0024</td>\n      <td>0.00184</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1114.10</td>\n    </tr>\n    <tr>\n      <th>351286</th>\n      <td>0.0024</td>\n      <td>0.00192</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>983.97</td>\n    </tr>\n    <tr>\n      <th>351287</th>\n      <td>0.0024</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>942.84</td>\n    </tr>\n  </tbody>\n</table>\n<p>179928 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/TPath_300_finish_data.pkl')\n",
    "data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_ALL_D4_t_I_F_PKL.pkl')\n",
    "# selected_points = data.loc[data['Zeitpunkt'] % 20 == 0, 'Zeitpunkt']\n",
    "# selected_points\n",
    "# copy =  data.loc[selected_points.index]\n",
    "# copy.to_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_ALL_D4_t_21_I_F_PKL.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n",
      "131733        0.0000      -0.00200        100   7000   6000      478.13\n",
      "131734        0.0000      -0.00192        100   7000   6000      511.16\n",
      "131735        0.0000      -0.00184        100   7000   6000      541.43\n",
      "131736        0.0000      -0.00176        100   7000   6000      569.14\n",
      "131737        0.0000      -0.00168        100   7000   6000      594.14\n",
      "...              ...           ...        ...    ...    ...         ...\n",
      "175639        0.0024       0.00168        500   7000   6000      942.96\n",
      "175640        0.0024       0.00176        500   7000   6000      865.10\n",
      "175641        0.0024       0.00184        500   7000   6000      786.99\n",
      "175642        0.0024       0.00192        500   7000   6000      708.11\n",
      "175643        0.0024       0.00200        500   7000   6000      690.48\n",
      "\n",
      "[9639 rows x 6 columns]\n",
      "Empty DataFrame\n",
      "Columns: [X-Koordinate, Y-Koordinate, Zeitpunkt, Strom, Kraft, Temperatur]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [X-Koordinate, Y-Koordinate, Zeitpunkt, Strom, Kraft, Temperatur]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/plain": "       X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft\n0           0.00216 -1.280000e-03        400   8000   6000\n1           0.00240 -4.000000e-04        450   7000   5000\n2           0.00060  1.120000e-03        300   6000   6000\n3           0.00012 -8.800000e-04        300   8000   6000\n4           0.00192  4.529900e-18        400   6000   5000\n...             ...           ...        ...    ...    ...\n67468       0.00180 -8.000000e-04        450   7000   9000\n67469       0.00204  1.440000e-03        350   6000   5000\n67470       0.00060 -1.200000e-03        400   8000   7000\n67471       0.00192  1.520000e-03        100   6000   5000\n67472       0.00180  8.800000e-04        350   6000   6000\n\n[67473 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00216</td>\n      <td>-1.280000e-03</td>\n      <td>400</td>\n      <td>8000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00240</td>\n      <td>-4.000000e-04</td>\n      <td>450</td>\n      <td>7000</td>\n      <td>5000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00060</td>\n      <td>1.120000e-03</td>\n      <td>300</td>\n      <td>6000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00012</td>\n      <td>-8.800000e-04</td>\n      <td>300</td>\n      <td>8000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00192</td>\n      <td>4.529900e-18</td>\n      <td>400</td>\n      <td>6000</td>\n      <td>5000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>67468</th>\n      <td>0.00180</td>\n      <td>-8.000000e-04</td>\n      <td>450</td>\n      <td>7000</td>\n      <td>9000</td>\n    </tr>\n    <tr>\n      <th>67469</th>\n      <td>0.00204</td>\n      <td>1.440000e-03</td>\n      <td>350</td>\n      <td>6000</td>\n      <td>5000</td>\n    </tr>\n    <tr>\n      <th>67470</th>\n      <td>0.00060</td>\n      <td>-1.200000e-03</td>\n      <td>400</td>\n      <td>8000</td>\n      <td>7000</td>\n    </tr>\n    <tr>\n      <th>67471</th>\n      <td>0.00192</td>\n      <td>1.520000e-03</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n    </tr>\n    <tr>\n      <th>67472</th>\n      <td>0.00180</td>\n      <td>8.800000e-04</td>\n      <td>350</td>\n      <td>6000</td>\n      <td>6000</td>\n    </tr>\n  </tbody>\n</table>\n<p>67473 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedingung = (data['Kraft'] == 6000) & (data['Strom'] == 7000)\n",
    "df_test = data[bedingung].copy()\n",
    "print(df_test)\n",
    "\n",
    "data_all = data.drop(df_test.index)\n",
    "#print(data_all)\n",
    "print(data_all[(data_all['Kraft'] == 6000) & (data_all['Strom'] == 7000)])\n",
    "\n",
    "print(data_all[(data_all['Kraft'] == 6000) & (data_all['Strom'] == 7000)])\n",
    "df_test_500 = df_test[(df_test['Zeitpunkt'] == 500)]\n",
    "\n",
    "\n",
    "data_all = data_all.sample(frac=1, random_state=42)  # Hier wird 42 als Random State verwendet, um die Ergebnisse reproduzierbar zu machen\n",
    "df_reset = data_all.reset_index(drop=True)\n",
    "df_reset\n",
    "\n",
    "y = df_reset[\"Temperatur\"]\n",
    "# Korrektur: Verwenden Sie den Spaltennamen direkt, ohne Indexierung der columns-Eigenschaft\n",
    "X = df_reset.drop(\"Temperatur\", axis=1)\n",
    "\n",
    "\n",
    "y_2 = df_test_500[\"Temperatur\"]\n",
    "# Korrektur: Verwenden Sie den Spaltennamen direkt, ohne Indexierung der columns-Eigenschaft\n",
    "X_2 = df_test_500.drop(\"Temperatur\", axis=1)\n",
    "X_2 = X_2.reset_index(drop=True)\n",
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:33:02.385653600Z",
     "start_time": "2024-04-02T08:33:02.256871900Z"
    }
   },
   "id": "f3128fa3a4407365"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c705edb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T08:33:02.386653200Z",
     "start_time": "2024-04-02T08:33:02.291570600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialisiere einen MinMaxScaler für die Features\n",
    "scaler_features = MinMaxScaler()\n",
    "# Skaliere X_train und X_test\n",
    "X_train_scaled = scaler_features.fit_transform(X)\n",
    "#X_test_scaled = scaler_features.transform(X_test)  # Nutze unterschiedliche Skalierungsparameter\n",
    "X_test_scaled_2 = scaler_features.transform(X_2)\n",
    "# Initialisiere einen SEPARATEN MinMaxScaler für das Ziel, wenn nötig\n",
    "scaler_target = MinMaxScaler()\n",
    "# Skaliere y_train und y_test. Beachte, dass y_train.reshape(-1, 1) verwendet wird, da MinMaxScaler \n",
    "# erwartet, dass die Eingaben als 2D-Arrays kommen, und Ziele normalerweise als 1D-Arrays vorliegen.\n",
    "y_train_scaled = scaler_target.fit_transform(y.values.reshape(-1, 1))\n",
    "#y_test_scaled = scaler_target.transform(y_test.values.reshape(-1, 1))\n",
    "y_test_scaled_2 = scaler_target.transform(y_2.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbefe631e495b483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T08:33:02.386653200Z",
     "start_time": "2024-04-02T08:33:02.304586Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.9       , 0.18      , 0.75      , 0.66666667, 0.25      ],\n       [1.        , 0.4       , 0.875     , 0.33333333, 0.        ],\n       [0.25      , 0.78      , 0.5       , 0.        , 0.25      ],\n       ...,\n       [0.25      , 0.2       , 0.75      , 0.66666667, 0.5       ],\n       [0.8       , 0.88      , 0.        , 0.        , 0.        ],\n       [0.75      , 0.72      , 0.625     , 0.        , 0.25      ]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.54074087],\n       [0.61914767],\n       [0.25281345],\n       ...,\n       [0.58515185],\n       [0.10187924],\n       [0.30150772]])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:33:02.387653200Z",
     "start_time": "2024-04-02T08:33:02.308315400Z"
    }
   },
   "id": "ce04ce43aac2242f"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "270/270 [==============================] - 2s 4ms/step - loss: 0.0298 - mae: 0.0723 - val_loss: 0.0225 - val_mae: 0.0467\n",
      "Epoch 2/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0206 - mae: 0.0389 - val_loss: 0.0193 - val_mae: 0.0329\n",
      "Epoch 3/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0184 - mae: 0.0296 - val_loss: 0.0178 - val_mae: 0.0274\n",
      "Epoch 4/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0173 - mae: 0.0261 - val_loss: 0.0169 - val_mae: 0.0255\n",
      "Epoch 5/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0163 - mae: 0.0214 - val_loss: 0.0161 - val_mae: 0.0204\n",
      "Epoch 6/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0157 - mae: 0.0194 - val_loss: 0.0155 - val_mae: 0.0180\n",
      "Epoch 7/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0152 - mae: 0.0162 - val_loss: 0.0150 - val_mae: 0.0162\n",
      "Epoch 8/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0148 - mae: 0.0149 - val_loss: 0.0147 - val_mae: 0.0163\n",
      "Epoch 9/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0144 - mae: 0.0138 - val_loss: 0.0144 - val_mae: 0.0166\n",
      "Epoch 10/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0141 - mae: 0.0127 - val_loss: 0.0140 - val_mae: 0.0126\n",
      "Epoch 11/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0138 - mae: 0.0122 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 12/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0135 - mae: 0.0113 - val_loss: 0.0134 - val_mae: 0.0112\n",
      "Epoch 13/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0133 - mae: 0.0114 - val_loss: 0.0131 - val_mae: 0.0102\n",
      "Epoch 14/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0130 - mae: 0.0101 - val_loss: 0.0129 - val_mae: 0.0098\n",
      "Epoch 15/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0128 - mae: 0.0105 - val_loss: 0.0127 - val_mae: 0.0109\n",
      "Epoch 16/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0126 - mae: 0.0105 - val_loss: 0.0124 - val_mae: 0.0089\n",
      "Epoch 17/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0123 - mae: 0.0090 - val_loss: 0.0122 - val_mae: 0.0104\n",
      "Epoch 18/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0121 - mae: 0.0092 - val_loss: 0.0121 - val_mae: 0.0120\n",
      "Epoch 19/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0119 - mae: 0.0092 - val_loss: 0.0117 - val_mae: 0.0084\n",
      "Epoch 20/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0116 - mae: 0.0087 - val_loss: 0.0115 - val_mae: 0.0077\n",
      "Epoch 21/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0114 - mae: 0.0088 - val_loss: 0.0115 - val_mae: 0.0132\n",
      "Epoch 22/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0112 - mae: 0.0088 - val_loss: 0.0112 - val_mae: 0.0113\n",
      "Epoch 23/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0110 - mae: 0.0082 - val_loss: 0.0109 - val_mae: 0.0075\n",
      "Epoch 24/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0108 - mae: 0.0081 - val_loss: 0.0107 - val_mae: 0.0084\n",
      "Epoch 25/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0106 - mae: 0.0083 - val_loss: 0.0105 - val_mae: 0.0073\n",
      "Epoch 26/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0104 - mae: 0.0076 - val_loss: 0.0103 - val_mae: 0.0073\n",
      "Epoch 27/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0103 - mae: 0.0076 - val_loss: 0.0102 - val_mae: 0.0072\n",
      "Epoch 28/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0101 - mae: 0.0075 - val_loss: 0.0100 - val_mae: 0.0080\n",
      "Epoch 29/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0099 - mae: 0.0078 - val_loss: 0.0099 - val_mae: 0.0094\n",
      "Epoch 30/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0097 - mae: 0.0080 - val_loss: 0.0096 - val_mae: 0.0065\n",
      "Epoch 31/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0095 - mae: 0.0071 - val_loss: 0.0095 - val_mae: 0.0068\n",
      "Epoch 32/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0094 - mae: 0.0074 - val_loss: 0.0093 - val_mae: 0.0068\n",
      "Epoch 33/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0092 - mae: 0.0070 - val_loss: 0.0091 - val_mae: 0.0067\n",
      "Epoch 34/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0091 - mae: 0.0072 - val_loss: 0.0091 - val_mae: 0.0103\n",
      "Epoch 35/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0089 - mae: 0.0070 - val_loss: 0.0088 - val_mae: 0.0066\n",
      "Epoch 36/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0088 - mae: 0.0074 - val_loss: 0.0087 - val_mae: 0.0067\n",
      "Epoch 37/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0086 - mae: 0.0070 - val_loss: 0.0085 - val_mae: 0.0060\n",
      "Epoch 38/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0085 - mae: 0.0070 - val_loss: 0.0084 - val_mae: 0.0073\n",
      "Epoch 39/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0083 - mae: 0.0069 - val_loss: 0.0082 - val_mae: 0.0060\n",
      "Epoch 40/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0082 - mae: 0.0070 - val_loss: 0.0082 - val_mae: 0.0098\n",
      "Epoch 41/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0081 - mae: 0.0069 - val_loss: 0.0080 - val_mae: 0.0079\n",
      "Epoch 42/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0079 - mae: 0.0067 - val_loss: 0.0078 - val_mae: 0.0060\n",
      "Epoch 43/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0078 - mae: 0.0071 - val_loss: 0.0077 - val_mae: 0.0073\n",
      "Epoch 44/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0077 - mae: 0.0067 - val_loss: 0.0076 - val_mae: 0.0066\n",
      "Epoch 45/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0076 - mae: 0.0066 - val_loss: 0.0075 - val_mae: 0.0069\n",
      "Epoch 46/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0074 - mae: 0.0068 - val_loss: 0.0074 - val_mae: 0.0068\n",
      "Epoch 47/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0073 - mae: 0.0064 - val_loss: 0.0073 - val_mae: 0.0066\n",
      "Epoch 48/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0072 - mae: 0.0070 - val_loss: 0.0071 - val_mae: 0.0055\n",
      "Epoch 49/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0071 - mae: 0.0062 - val_loss: 0.0070 - val_mae: 0.0056\n",
      "Epoch 50/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0070 - mae: 0.0063 - val_loss: 0.0069 - val_mae: 0.0054\n",
      "Epoch 51/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0069 - mae: 0.0064 - val_loss: 0.0068 - val_mae: 0.0074\n",
      "Epoch 52/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0068 - mae: 0.0063 - val_loss: 0.0068 - val_mae: 0.0097\n",
      "Epoch 53/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0067 - mae: 0.0066 - val_loss: 0.0067 - val_mae: 0.0086\n",
      "Epoch 54/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0066 - mae: 0.0065 - val_loss: 0.0065 - val_mae: 0.0063\n",
      "Epoch 55/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0065 - mae: 0.0059 - val_loss: 0.0064 - val_mae: 0.0061\n",
      "Epoch 56/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0064 - mae: 0.0061 - val_loss: 0.0063 - val_mae: 0.0062\n",
      "Epoch 57/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0063 - mae: 0.0063 - val_loss: 0.0062 - val_mae: 0.0075\n",
      "Epoch 58/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0062 - mae: 0.0067 - val_loss: 0.0061 - val_mae: 0.0064\n",
      "Epoch 59/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0061 - mae: 0.0060 - val_loss: 0.0060 - val_mae: 0.0055\n",
      "Epoch 60/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0060 - mae: 0.0061 - val_loss: 0.0059 - val_mae: 0.0058\n",
      "Epoch 61/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0059 - mae: 0.0060 - val_loss: 0.0058 - val_mae: 0.0054\n",
      "Epoch 62/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0058 - mae: 0.0059 - val_loss: 0.0058 - val_mae: 0.0070\n",
      "Epoch 63/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0057 - mae: 0.0061 - val_loss: 0.0057 - val_mae: 0.0059\n",
      "Epoch 64/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0056 - mae: 0.0062 - val_loss: 0.0056 - val_mae: 0.0077\n",
      "Epoch 65/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0055 - mae: 0.0060 - val_loss: 0.0055 - val_mae: 0.0054\n",
      "Epoch 66/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0055 - mae: 0.0060 - val_loss: 0.0055 - val_mae: 0.0088\n",
      "Epoch 67/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0054 - mae: 0.0060 - val_loss: 0.0053 - val_mae: 0.0053\n",
      "Epoch 68/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0053 - mae: 0.0058 - val_loss: 0.0052 - val_mae: 0.0053\n",
      "Epoch 69/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0052 - mae: 0.0055 - val_loss: 0.0052 - val_mae: 0.0058\n",
      "Epoch 70/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0051 - mae: 0.0061 - val_loss: 0.0051 - val_mae: 0.0051\n",
      "Epoch 71/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0051 - mae: 0.0059 - val_loss: 0.0050 - val_mae: 0.0054\n",
      "Epoch 72/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0050 - mae: 0.0058 - val_loss: 0.0049 - val_mae: 0.0051\n",
      "Epoch 73/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0049 - mae: 0.0056 - val_loss: 0.0049 - val_mae: 0.0049\n",
      "Epoch 74/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0048 - mae: 0.0055 - val_loss: 0.0048 - val_mae: 0.0048\n",
      "Epoch 75/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0048 - mae: 0.0060 - val_loss: 0.0047 - val_mae: 0.0057\n",
      "Epoch 76/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0047 - mae: 0.0055 - val_loss: 0.0047 - val_mae: 0.0060\n",
      "Epoch 77/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0046 - mae: 0.0058 - val_loss: 0.0046 - val_mae: 0.0052\n",
      "Epoch 78/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0046 - mae: 0.0056 - val_loss: 0.0045 - val_mae: 0.0050\n",
      "Epoch 79/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0045 - mae: 0.0054 - val_loss: 0.0045 - val_mae: 0.0058\n",
      "Epoch 80/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0044 - mae: 0.0056 - val_loss: 0.0044 - val_mae: 0.0074\n",
      "Epoch 81/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0044 - mae: 0.0055 - val_loss: 0.0043 - val_mae: 0.0054\n",
      "Epoch 82/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0043 - mae: 0.0055 - val_loss: 0.0042 - val_mae: 0.0050\n",
      "Epoch 83/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0042 - mae: 0.0055 - val_loss: 0.0042 - val_mae: 0.0046\n",
      "Epoch 84/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0042 - mae: 0.0052 - val_loss: 0.0041 - val_mae: 0.0049\n",
      "Epoch 85/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0041 - mae: 0.0053 - val_loss: 0.0041 - val_mae: 0.0053\n",
      "Epoch 86/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0040 - mae: 0.0052 - val_loss: 0.0040 - val_mae: 0.0047\n",
      "Epoch 87/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0040 - mae: 0.0054 - val_loss: 0.0039 - val_mae: 0.0052\n",
      "Epoch 88/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0039 - mae: 0.0053 - val_loss: 0.0039 - val_mae: 0.0054\n",
      "Epoch 89/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0039 - mae: 0.0058 - val_loss: 0.0038 - val_mae: 0.0045\n",
      "Epoch 90/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0038 - mae: 0.0051 - val_loss: 0.0038 - val_mae: 0.0051\n",
      "Epoch 91/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0037 - mae: 0.0051 - val_loss: 0.0037 - val_mae: 0.0048\n",
      "Epoch 92/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0037 - mae: 0.0053 - val_loss: 0.0037 - val_mae: 0.0050\n",
      "Epoch 93/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0036 - mae: 0.0051 - val_loss: 0.0036 - val_mae: 0.0051\n",
      "Epoch 94/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0051 - val_loss: 0.0035 - val_mae: 0.0046\n",
      "Epoch 95/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0035 - mae: 0.0053 - val_loss: 0.0035 - val_mae: 0.0057\n",
      "Epoch 96/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0035 - mae: 0.0054 - val_loss: 0.0034 - val_mae: 0.0046\n",
      "Epoch 97/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0051 - val_loss: 0.0034 - val_mae: 0.0048\n",
      "Epoch 98/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0052 - val_loss: 0.0033 - val_mae: 0.0056\n",
      "Epoch 99/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0050 - val_loss: 0.0033 - val_mae: 0.0052\n",
      "Epoch 100/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0052 - val_loss: 0.0032 - val_mae: 0.0046\n",
      "Epoch 101/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0032 - mae: 0.0052 - val_loss: 0.0032 - val_mae: 0.0055\n",
      "Epoch 102/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0032 - mae: 0.0051 - val_loss: 0.0031 - val_mae: 0.0047\n",
      "Epoch 103/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0031 - mae: 0.0049 - val_loss: 0.0031 - val_mae: 0.0072\n",
      "Epoch 104/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0031 - mae: 0.0057 - val_loss: 0.0030 - val_mae: 0.0045\n",
      "Epoch 105/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0030 - mae: 0.0048 - val_loss: 0.0030 - val_mae: 0.0043\n",
      "Epoch 106/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0030 - mae: 0.0049 - val_loss: 0.0030 - val_mae: 0.0062\n",
      "Epoch 107/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0029 - mae: 0.0047 - val_loss: 0.0029 - val_mae: 0.0049\n",
      "Epoch 108/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0029 - mae: 0.0053 - val_loss: 0.0029 - val_mae: 0.0047\n",
      "Epoch 109/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0029 - mae: 0.0050 - val_loss: 0.0029 - val_mae: 0.0070\n",
      "Epoch 110/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0028 - mae: 0.0051 - val_loss: 0.0028 - val_mae: 0.0052\n",
      "Epoch 111/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0028 - mae: 0.0049 - val_loss: 0.0027 - val_mae: 0.0045\n",
      "Epoch 112/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0027 - mae: 0.0050 - val_loss: 0.0027 - val_mae: 0.0046\n",
      "Epoch 113/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0027 - mae: 0.0050 - val_loss: 0.0027 - val_mae: 0.0048\n",
      "Epoch 114/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0027 - mae: 0.0049 - val_loss: 0.0026 - val_mae: 0.0049\n",
      "Epoch 115/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0049 - val_loss: 0.0026 - val_mae: 0.0052\n",
      "Epoch 116/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0046 - val_loss: 0.0025 - val_mae: 0.0043\n",
      "Epoch 117/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0052 - val_loss: 0.0025 - val_mae: 0.0047\n",
      "Epoch 118/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0049 - val_loss: 0.0025 - val_mae: 0.0045\n",
      "Epoch 119/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0046 - val_loss: 0.0024 - val_mae: 0.0041\n",
      "Epoch 120/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0050 - val_loss: 0.0024 - val_mae: 0.0052\n",
      "Epoch 121/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0050 - val_loss: 0.0024 - val_mae: 0.0051\n",
      "Epoch 122/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0050 - val_loss: 0.0024 - val_mae: 0.0060\n",
      "Epoch 123/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0047 - val_loss: 0.0023 - val_mae: 0.0044\n",
      "Epoch 124/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0050 - val_loss: 0.0023 - val_mae: 0.0046\n",
      "Epoch 125/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0047 - val_loss: 0.0023 - val_mae: 0.0048\n",
      "Epoch 126/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0048 - val_loss: 0.0022 - val_mae: 0.0059\n",
      "Epoch 127/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0049 - val_loss: 0.0022 - val_mae: 0.0054\n",
      "Epoch 128/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0049 - val_loss: 0.0022 - val_mae: 0.0044\n",
      "Epoch 129/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0047 - val_loss: 0.0021 - val_mae: 0.0045\n",
      "Epoch 130/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0049 - val_loss: 0.0021 - val_mae: 0.0049\n",
      "Epoch 131/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0049 - val_loss: 0.0021 - val_mae: 0.0048\n",
      "Epoch 132/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0048 - val_loss: 0.0020 - val_mae: 0.0041\n",
      "Epoch 133/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0046 - val_loss: 0.0020 - val_mae: 0.0059\n",
      "Epoch 134/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0047 - val_loss: 0.0020 - val_mae: 0.0049\n",
      "Epoch 135/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0049 - val_loss: 0.0020 - val_mae: 0.0048\n",
      "Epoch 136/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0048 - val_loss: 0.0019 - val_mae: 0.0048\n",
      "Epoch 137/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0048 - val_loss: 0.0019 - val_mae: 0.0042\n",
      "Epoch 138/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0045 - val_loss: 0.0019 - val_mae: 0.0043\n",
      "Epoch 139/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0046 - val_loss: 0.0019 - val_mae: 0.0042\n",
      "Epoch 140/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0018 - mae: 0.0048 - val_loss: 0.0018 - val_mae: 0.0044\n",
      "Epoch 141/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0018 - mae: 0.0049 - val_loss: 0.0018 - val_mae: 0.0057\n",
      "Epoch 142/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0018 - mae: 0.0047 - val_loss: 0.0018 - val_mae: 0.0041\n",
      "Epoch 143/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0018 - mae: 0.0046 - val_loss: 0.0018 - val_mae: 0.0045\n",
      "Epoch 144/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0018 - mae: 0.0049 - val_loss: 0.0017 - val_mae: 0.0044\n",
      "Epoch 145/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0017 - mae: 0.0046 - val_loss: 0.0017 - val_mae: 0.0044\n",
      "Epoch 146/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0017 - mae: 0.0047 - val_loss: 0.0017 - val_mae: 0.0047\n",
      "Epoch 147/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0017 - mae: 0.0047 - val_loss: 0.0017 - val_mae: 0.0045\n",
      "Epoch 148/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0017 - mae: 0.0047 - val_loss: 0.0016 - val_mae: 0.0045\n",
      "Epoch 149/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0049 - val_loss: 0.0016 - val_mae: 0.0051\n",
      "Epoch 150/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0046 - val_loss: 0.0016 - val_mae: 0.0044\n",
      "Epoch 151/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0048 - val_loss: 0.0016 - val_mae: 0.0061\n",
      "Epoch 152/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0049 - val_loss: 0.0016 - val_mae: 0.0052\n",
      "Epoch 153/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0046\n",
      "Epoch 154/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0048 - val_loss: 0.0015 - val_mae: 0.0041\n",
      "Epoch 155/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0045\n",
      "Epoch 156/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0048 - val_loss: 0.0015 - val_mae: 0.0050\n",
      "Epoch 157/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0042\n",
      "Epoch 158/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0046\n",
      "Epoch 159/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0039\n",
      "Epoch 160/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0049\n",
      "Epoch 161/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0045\n",
      "Epoch 162/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0039\n",
      "Epoch 163/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0039\n",
      "Epoch 164/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0045\n",
      "Epoch 165/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0050\n",
      "Epoch 166/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0055\n",
      "Epoch 167/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0041\n",
      "Epoch 168/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0046 - val_loss: 0.0013 - val_mae: 0.0041\n",
      "Epoch 169/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0046\n",
      "Epoch 170/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0044 - val_loss: 0.0012 - val_mae: 0.0041\n",
      "Epoch 171/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0044 - val_loss: 0.0012 - val_mae: 0.0055\n",
      "Epoch 172/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0046 - val_loss: 0.0012 - val_mae: 0.0053\n",
      "Epoch 173/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0037\n",
      "Epoch 174/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0038\n",
      "Epoch 175/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0044\n",
      "Epoch 176/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0045 - val_loss: 0.0012 - val_mae: 0.0059\n",
      "Epoch 177/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0044\n",
      "Epoch 178/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0039\n",
      "Epoch 179/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0037\n",
      "Epoch 180/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0044 - val_loss: 0.0011 - val_mae: 0.0038\n",
      "Epoch 181/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0039\n",
      "Epoch 182/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0037\n",
      "Epoch 183/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0044 - val_loss: 0.0011 - val_mae: 0.0042\n",
      "Epoch 184/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0010 - val_mae: 0.0046\n",
      "Epoch 185/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0043 - val_loss: 0.0010 - val_mae: 0.0044\n",
      "Epoch 186/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0043 - val_loss: 0.0010 - val_mae: 0.0048\n",
      "Epoch 187/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0042 - val_loss: 0.0010 - val_mae: 0.0038\n",
      "Epoch 188/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0042 - val_loss: 9.8906e-04 - val_mae: 0.0036\n",
      "Epoch 189/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 9.9492e-04 - mae: 0.0045 - val_loss: 9.9592e-04 - val_mae: 0.0049\n",
      "Epoch 190/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 9.8268e-04 - mae: 0.0044 - val_loss: 9.8333e-04 - val_mae: 0.0049\n",
      "Epoch 191/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 9.7214e-04 - mae: 0.0043 - val_loss: 9.6504e-04 - val_mae: 0.0044\n",
      "Epoch 192/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 9.5899e-04 - mae: 0.0042 - val_loss: 9.6604e-04 - val_mae: 0.0052\n",
      "Epoch 193/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 9.5001e-04 - mae: 0.0042 - val_loss: 9.3919e-04 - val_mae: 0.0039\n",
      "Epoch 194/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 9.3798e-04 - mae: 0.0041 - val_loss: 9.2566e-04 - val_mae: 0.0037\n",
      "Epoch 195/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 9.3004e-04 - mae: 0.0043 - val_loss: 9.3368e-04 - val_mae: 0.0053\n",
      "Epoch 196/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 9.1760e-04 - mae: 0.0041 - val_loss: 9.1194e-04 - val_mae: 0.0041\n",
      "Epoch 197/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 9.0733e-04 - mae: 0.0041 - val_loss: 9.0152e-04 - val_mae: 0.0041\n",
      "Epoch 198/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 8.9902e-04 - mae: 0.0042 - val_loss: 8.8461e-04 - val_mae: 0.0035\n",
      "Epoch 199/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 8.8899e-04 - mae: 0.0042 - val_loss: 8.7848e-04 - val_mae: 0.0038\n",
      "Epoch 200/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 8.8075e-04 - mae: 0.0043 - val_loss: 8.6831e-04 - val_mae: 0.0038\n",
      "Epoch 201/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 8.6958e-04 - mae: 0.0042 - val_loss: 8.6409e-04 - val_mae: 0.0041\n",
      "Epoch 202/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 8.6154e-04 - mae: 0.0042 - val_loss: 8.6088e-04 - val_mae: 0.0046\n",
      "Epoch 203/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 8.5323e-04 - mae: 0.0043 - val_loss: 8.4137e-04 - val_mae: 0.0037\n",
      "Epoch 204/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 8.4328e-04 - mae: 0.0042 - val_loss: 8.4778e-04 - val_mae: 0.0047\n",
      "Epoch 205/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 8.3416e-04 - mae: 0.0041 - val_loss: 8.2355e-04 - val_mae: 0.0037\n",
      "Epoch 206/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 8.2732e-04 - mae: 0.0043 - val_loss: 8.2898e-04 - val_mae: 0.0051\n",
      "Epoch 207/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 8.1647e-04 - mae: 0.0040 - val_loss: 8.1749e-04 - val_mae: 0.0045\n",
      "Epoch 208/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 8.0794e-04 - mae: 0.0041 - val_loss: 8.0410e-04 - val_mae: 0.0041\n",
      "Epoch 209/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 8.0141e-04 - mae: 0.0042 - val_loss: 7.9429e-04 - val_mae: 0.0040\n",
      "Epoch 210/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 7.9466e-04 - mae: 0.0043 - val_loss: 7.8698e-04 - val_mae: 0.0041\n",
      "Epoch 211/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 7.8561e-04 - mae: 0.0042 - val_loss: 7.7872e-04 - val_mae: 0.0040\n",
      "Epoch 212/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 7.7687e-04 - mae: 0.0041 - val_loss: 7.6582e-04 - val_mae: 0.0037\n",
      "Epoch 213/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 7.6887e-04 - mae: 0.0041 - val_loss: 7.6181e-04 - val_mae: 0.0038\n",
      "Epoch 214/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 7.6254e-04 - mae: 0.0042 - val_loss: 7.5417e-04 - val_mae: 0.0039\n",
      "Epoch 215/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 7.5392e-04 - mae: 0.0041 - val_loss: 7.5053e-04 - val_mae: 0.0043\n",
      "Epoch 216/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 7.4521e-04 - mae: 0.0040 - val_loss: 7.4088e-04 - val_mae: 0.0040\n",
      "Epoch 217/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 7.4102e-04 - mae: 0.0042 - val_loss: 7.3190e-04 - val_mae: 0.0038\n",
      "Epoch 218/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 7.3324e-04 - mae: 0.0041 - val_loss: 7.2478e-04 - val_mae: 0.0038\n",
      "Epoch 219/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 7.2661e-04 - mae: 0.0042 - val_loss: 7.2422e-04 - val_mae: 0.0043\n",
      "Epoch 220/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 7.1720e-04 - mae: 0.0039 - val_loss: 7.0902e-04 - val_mae: 0.0035\n",
      "Epoch 221/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 7.1133e-04 - mae: 0.0040 - val_loss: 7.0629e-04 - val_mae: 0.0042\n",
      "Epoch 222/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 7.0419e-04 - mae: 0.0040 - val_loss: 6.9745e-04 - val_mae: 0.0038\n",
      "Epoch 223/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 6.9840e-04 - mae: 0.0041 - val_loss: 6.8896e-04 - val_mae: 0.0037\n",
      "Epoch 224/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 6.9269e-04 - mae: 0.0041 - val_loss: 6.9554e-04 - val_mae: 0.0048\n",
      "Epoch 225/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 6.8651e-04 - mae: 0.0042 - val_loss: 6.7836e-04 - val_mae: 0.0039\n",
      "Epoch 226/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 6.7906e-04 - mae: 0.0041 - val_loss: 6.6947e-04 - val_mae: 0.0036\n",
      "Epoch 227/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 6.7414e-04 - mae: 0.0041 - val_loss: 6.6562e-04 - val_mae: 0.0038\n",
      "Epoch 228/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 6.6636e-04 - mae: 0.0040 - val_loss: 6.6456e-04 - val_mae: 0.0041\n",
      "Epoch 229/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 6.6002e-04 - mae: 0.0039 - val_loss: 6.5916e-04 - val_mae: 0.0042\n",
      "Epoch 230/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 6.5496e-04 - mae: 0.0040 - val_loss: 6.5436e-04 - val_mae: 0.0043\n",
      "Epoch 231/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 6.5152e-04 - mae: 0.0042 - val_loss: 6.4594e-04 - val_mae: 0.0041\n",
      "Epoch 232/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 6.4402e-04 - mae: 0.0041 - val_loss: 6.3778e-04 - val_mae: 0.0039\n",
      "Epoch 233/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 6.3909e-04 - mae: 0.0041 - val_loss: 6.3246e-04 - val_mae: 0.0040\n",
      "Epoch 234/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 6.3215e-04 - mae: 0.0039 - val_loss: 6.2748e-04 - val_mae: 0.0039\n",
      "Epoch 235/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 6.2789e-04 - mae: 0.0040 - val_loss: 6.2388e-04 - val_mae: 0.0041\n",
      "Epoch 236/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 6.2151e-04 - mae: 0.0040 - val_loss: 6.3167e-04 - val_mae: 0.0049\n",
      "Epoch 237/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 6.1811e-04 - mae: 0.0041 - val_loss: 6.2384e-04 - val_mae: 0.0050\n",
      "Epoch 238/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 6.1111e-04 - mae: 0.0040 - val_loss: 6.0367e-04 - val_mae: 0.0037\n",
      "Epoch 239/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 6.0742e-04 - mae: 0.0041 - val_loss: 6.0384e-04 - val_mae: 0.0042\n",
      "Epoch 240/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 6.0151e-04 - mae: 0.0040 - val_loss: 5.9569e-04 - val_mae: 0.0039\n",
      "Epoch 241/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 5.9439e-04 - mae: 0.0038 - val_loss: 5.9269e-04 - val_mae: 0.0039\n",
      "Epoch 242/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 5.9278e-04 - mae: 0.0041 - val_loss: 5.9675e-04 - val_mae: 0.0045\n",
      "Epoch 243/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 5.8869e-04 - mae: 0.0041 - val_loss: 5.8220e-04 - val_mae: 0.0039\n",
      "Epoch 244/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 5.8096e-04 - mae: 0.0039 - val_loss: 5.7256e-04 - val_mae: 0.0034\n",
      "Epoch 245/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.7779e-04 - mae: 0.0040 - val_loss: 5.8167e-04 - val_mae: 0.0047\n",
      "Epoch 246/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 5.7302e-04 - mae: 0.0040 - val_loss: 5.7065e-04 - val_mae: 0.0041\n",
      "Epoch 247/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.6919e-04 - mae: 0.0040 - val_loss: 5.7078e-04 - val_mae: 0.0046\n",
      "Epoch 248/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.6525e-04 - mae: 0.0041 - val_loss: 5.5698e-04 - val_mae: 0.0037\n",
      "Epoch 249/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.6074e-04 - mae: 0.0041 - val_loss: 5.5798e-04 - val_mae: 0.0040\n",
      "Epoch 250/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.5633e-04 - mae: 0.0040 - val_loss: 5.6085e-04 - val_mae: 0.0049\n",
      "Epoch 251/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.5169e-04 - mae: 0.0040 - val_loss: 5.4462e-04 - val_mae: 0.0037\n",
      "Epoch 252/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.4872e-04 - mae: 0.0041 - val_loss: 5.4289e-04 - val_mae: 0.0040\n",
      "Epoch 253/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.4201e-04 - mae: 0.0039 - val_loss: 5.3844e-04 - val_mae: 0.0038\n",
      "Epoch 254/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.4041e-04 - mae: 0.0041 - val_loss: 5.4358e-04 - val_mae: 0.0044\n",
      "Epoch 255/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.3847e-04 - mae: 0.0042 - val_loss: 5.2997e-04 - val_mae: 0.0038\n",
      "Epoch 256/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.3127e-04 - mae: 0.0040 - val_loss: 5.2583e-04 - val_mae: 0.0036\n",
      "Epoch 257/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.2687e-04 - mae: 0.0039 - val_loss: 5.2440e-04 - val_mae: 0.0039\n",
      "Epoch 258/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.2627e-04 - mae: 0.0041 - val_loss: 5.1920e-04 - val_mae: 0.0039\n",
      "Epoch 259/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.1986e-04 - mae: 0.0039 - val_loss: 5.1904e-04 - val_mae: 0.0042\n",
      "Epoch 260/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.1549e-04 - mae: 0.0039 - val_loss: 5.0949e-04 - val_mae: 0.0036\n",
      "Epoch 261/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.1173e-04 - mae: 0.0039 - val_loss: 5.0704e-04 - val_mae: 0.0037\n",
      "Epoch 262/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.0983e-04 - mae: 0.0040 - val_loss: 5.0374e-04 - val_mae: 0.0038\n",
      "Epoch 263/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.0532e-04 - mae: 0.0039 - val_loss: 4.9807e-04 - val_mae: 0.0035\n",
      "Epoch 264/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.0267e-04 - mae: 0.0040 - val_loss: 4.9730e-04 - val_mae: 0.0037\n",
      "Epoch 265/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.9906e-04 - mae: 0.0040 - val_loss: 5.0229e-04 - val_mae: 0.0046\n",
      "Epoch 266/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.9654e-04 - mae: 0.0041 - val_loss: 4.8983e-04 - val_mae: 0.0038\n",
      "Epoch 267/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.9251e-04 - mae: 0.0040 - val_loss: 4.8633e-04 - val_mae: 0.0036\n",
      "Epoch 268/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.9128e-04 - mae: 0.0042 - val_loss: 4.9572e-04 - val_mae: 0.0045\n",
      "Epoch 269/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.8558e-04 - mae: 0.0040 - val_loss: 4.8145e-04 - val_mae: 0.0039\n",
      "Epoch 270/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.8090e-04 - mae: 0.0038 - val_loss: 4.7531e-04 - val_mae: 0.0035\n",
      "Epoch 271/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.8135e-04 - mae: 0.0041 - val_loss: 4.9466e-04 - val_mae: 0.0055\n",
      "Epoch 272/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.7660e-04 - mae: 0.0040 - val_loss: 4.7171e-04 - val_mae: 0.0038\n",
      "Epoch 273/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.7355e-04 - mae: 0.0040 - val_loss: 4.7421e-04 - val_mae: 0.0043\n",
      "Epoch 274/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.7119e-04 - mae: 0.0040 - val_loss: 4.6575e-04 - val_mae: 0.0038\n",
      "Epoch 275/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.6757e-04 - mae: 0.0040 - val_loss: 4.6697e-04 - val_mae: 0.0040\n",
      "Epoch 276/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.6600e-04 - mae: 0.0041 - val_loss: 4.8771e-04 - val_mae: 0.0059\n",
      "Epoch 277/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.6118e-04 - mae: 0.0039 - val_loss: 4.5404e-04 - val_mae: 0.0035\n",
      "Epoch 278/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.5859e-04 - mae: 0.0039 - val_loss: 4.5338e-04 - val_mae: 0.0038\n",
      "Epoch 279/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.5492e-04 - mae: 0.0039 - val_loss: 4.4906e-04 - val_mae: 0.0035\n",
      "Epoch 280/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.5275e-04 - mae: 0.0039 - val_loss: 4.5271e-04 - val_mae: 0.0040\n",
      "Epoch 281/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.5167e-04 - mae: 0.0040 - val_loss: 4.4790e-04 - val_mae: 0.0039\n",
      "Epoch 282/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.4886e-04 - mae: 0.0041 - val_loss: 4.4657e-04 - val_mae: 0.0042\n",
      "Epoch 283/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.4492e-04 - mae: 0.0039 - val_loss: 4.4656e-04 - val_mae: 0.0044\n",
      "Epoch 284/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.4170e-04 - mae: 0.0039 - val_loss: 4.3931e-04 - val_mae: 0.0039\n",
      "Epoch 285/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.3980e-04 - mae: 0.0039 - val_loss: 4.4691e-04 - val_mae: 0.0047\n",
      "Epoch 286/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.3882e-04 - mae: 0.0041 - val_loss: 4.3878e-04 - val_mae: 0.0042\n",
      "Epoch 287/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.3850e-04 - mae: 0.0042 - val_loss: 4.4353e-04 - val_mae: 0.0050\n",
      "Epoch 288/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.3063e-04 - mae: 0.0038 - val_loss: 4.2836e-04 - val_mae: 0.0038\n",
      "Epoch 289/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.2984e-04 - mae: 0.0039 - val_loss: 4.2809e-04 - val_mae: 0.0040\n",
      "Epoch 290/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.2803e-04 - mae: 0.0039 - val_loss: 4.3767e-04 - val_mae: 0.0052\n",
      "Epoch 291/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.2687e-04 - mae: 0.0040 - val_loss: 4.2627e-04 - val_mae: 0.0043\n",
      "Epoch 292/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.2407e-04 - mae: 0.0040 - val_loss: 4.1900e-04 - val_mae: 0.0038\n",
      "Epoch 293/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.1992e-04 - mae: 0.0038 - val_loss: 4.1386e-04 - val_mae: 0.0035\n",
      "Epoch 294/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.1933e-04 - mae: 0.0040 - val_loss: 4.1568e-04 - val_mae: 0.0038\n",
      "Epoch 295/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.1564e-04 - mae: 0.0038 - val_loss: 4.1110e-04 - val_mae: 0.0037\n",
      "Epoch 296/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.1339e-04 - mae: 0.0039 - val_loss: 4.0988e-04 - val_mae: 0.0038\n",
      "Epoch 297/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.1197e-04 - mae: 0.0039 - val_loss: 4.0707e-04 - val_mae: 0.0038\n",
      "Epoch 298/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.0868e-04 - mae: 0.0038 - val_loss: 4.1195e-04 - val_mae: 0.0043\n",
      "Epoch 299/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.0770e-04 - mae: 0.0040 - val_loss: 4.0367e-04 - val_mae: 0.0037\n",
      "Epoch 300/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.0483e-04 - mae: 0.0039 - val_loss: 4.0051e-04 - val_mae: 0.0038\n",
      "Epoch 301/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.0319e-04 - mae: 0.0039 - val_loss: 4.0494e-04 - val_mae: 0.0042\n",
      "Epoch 302/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.0082e-04 - mae: 0.0039 - val_loss: 3.9703e-04 - val_mae: 0.0038\n",
      "Epoch 303/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.9993e-04 - mae: 0.0040 - val_loss: 3.9308e-04 - val_mae: 0.0035\n",
      "Epoch 304/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.9563e-04 - mae: 0.0038 - val_loss: 3.8857e-04 - val_mae: 0.0033\n",
      "Epoch 305/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.9444e-04 - mae: 0.0039 - val_loss: 3.9254e-04 - val_mae: 0.0040\n",
      "Epoch 306/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.9312e-04 - mae: 0.0040 - val_loss: 3.8673e-04 - val_mae: 0.0036\n",
      "Epoch 307/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.8862e-04 - mae: 0.0037 - val_loss: 3.9562e-04 - val_mae: 0.0046\n",
      "Epoch 308/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.8830e-04 - mae: 0.0039 - val_loss: 3.8279e-04 - val_mae: 0.0036\n",
      "Epoch 309/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.8388e-04 - mae: 0.0037 - val_loss: 3.8235e-04 - val_mae: 0.0037\n",
      "Epoch 310/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.8442e-04 - mae: 0.0039 - val_loss: 3.7895e-04 - val_mae: 0.0037\n",
      "Epoch 311/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.8277e-04 - mae: 0.0040 - val_loss: 3.7588e-04 - val_mae: 0.0036\n",
      "Epoch 312/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.7940e-04 - mae: 0.0039 - val_loss: 3.7327e-04 - val_mae: 0.0034\n",
      "Epoch 313/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 3.7834e-04 - mae: 0.0039 - val_loss: 3.7768e-04 - val_mae: 0.0042\n",
      "Epoch 314/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.7429e-04 - mae: 0.0038 - val_loss: 3.7869e-04 - val_mae: 0.0044\n",
      "Epoch 315/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 3.7224e-04 - mae: 0.0037 - val_loss: 3.8073e-04 - val_mae: 0.0047\n",
      "Epoch 316/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 3.7470e-04 - mae: 0.0041 - val_loss: 3.7351e-04 - val_mae: 0.0043\n",
      "Epoch 317/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.6898e-04 - mae: 0.0038 - val_loss: 3.6649e-04 - val_mae: 0.0038\n",
      "Epoch 318/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.6611e-04 - mae: 0.0037 - val_loss: 3.6771e-04 - val_mae: 0.0038\n",
      "Epoch 319/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.6637e-04 - mae: 0.0039 - val_loss: 3.6841e-04 - val_mae: 0.0042\n",
      "Epoch 320/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.6437e-04 - mae: 0.0039 - val_loss: 3.5926e-04 - val_mae: 0.0036\n",
      "Epoch 321/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.6087e-04 - mae: 0.0038 - val_loss: 3.6423e-04 - val_mae: 0.0040\n",
      "Epoch 322/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.6050e-04 - mae: 0.0039 - val_loss: 3.5856e-04 - val_mae: 0.0040\n",
      "Epoch 323/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.5786e-04 - mae: 0.0038 - val_loss: 3.7144e-04 - val_mae: 0.0053\n",
      "Epoch 324/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.5660e-04 - mae: 0.0039 - val_loss: 3.5470e-04 - val_mae: 0.0040\n",
      "Epoch 325/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.5332e-04 - mae: 0.0037 - val_loss: 3.5127e-04 - val_mae: 0.0037\n",
      "Epoch 326/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.5479e-04 - mae: 0.0040 - val_loss: 3.5367e-04 - val_mae: 0.0041\n",
      "Epoch 327/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.5150e-04 - mae: 0.0038 - val_loss: 3.4330e-04 - val_mae: 0.0032\n",
      "Epoch 328/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.4787e-04 - mae: 0.0037 - val_loss: 3.5376e-04 - val_mae: 0.0044\n",
      "Epoch 329/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.4800e-04 - mae: 0.0038 - val_loss: 3.4522e-04 - val_mae: 0.0038\n",
      "Epoch 330/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.4539e-04 - mae: 0.0037 - val_loss: 3.4443e-04 - val_mae: 0.0038\n",
      "Epoch 331/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.4333e-04 - mae: 0.0037 - val_loss: 3.3809e-04 - val_mae: 0.0034\n",
      "Epoch 332/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.4270e-04 - mae: 0.0038 - val_loss: 3.4314e-04 - val_mae: 0.0038\n",
      "Epoch 333/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.4142e-04 - mae: 0.0038 - val_loss: 3.3601e-04 - val_mae: 0.0035\n",
      "Epoch 334/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.4137e-04 - mae: 0.0039 - val_loss: 3.3935e-04 - val_mae: 0.0039\n",
      "Epoch 335/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.4073e-04 - mae: 0.0040 - val_loss: 3.3874e-04 - val_mae: 0.0041\n",
      "Epoch 336/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.3610e-04 - mae: 0.0037 - val_loss: 3.2936e-04 - val_mae: 0.0032\n",
      "Epoch 337/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.3532e-04 - mae: 0.0038 - val_loss: 3.2992e-04 - val_mae: 0.0033\n",
      "Epoch 338/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.3446e-04 - mae: 0.0038 - val_loss: 3.2738e-04 - val_mae: 0.0033\n",
      "Epoch 339/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.3274e-04 - mae: 0.0038 - val_loss: 3.2590e-04 - val_mae: 0.0033\n",
      "Epoch 340/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.3041e-04 - mae: 0.0037 - val_loss: 3.2835e-04 - val_mae: 0.0036\n",
      "Epoch 341/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.2851e-04 - mae: 0.0036 - val_loss: 3.2624e-04 - val_mae: 0.0036\n",
      "Epoch 342/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.2787e-04 - mae: 0.0037 - val_loss: 3.3127e-04 - val_mae: 0.0041\n",
      "Epoch 343/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.2847e-04 - mae: 0.0039 - val_loss: 3.3035e-04 - val_mae: 0.0043\n",
      "Epoch 344/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.2608e-04 - mae: 0.0038 - val_loss: 3.1922e-04 - val_mae: 0.0033\n",
      "Epoch 345/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.2761e-04 - mae: 0.0040 - val_loss: 3.2288e-04 - val_mae: 0.0039\n",
      "Epoch 346/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.2367e-04 - mae: 0.0038 - val_loss: 3.2221e-04 - val_mae: 0.0037\n",
      "Epoch 347/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.2248e-04 - mae: 0.0038 - val_loss: 3.4118e-04 - val_mae: 0.0055\n",
      "Epoch 348/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 3.1954e-04 - mae: 0.0036 - val_loss: 3.1971e-04 - val_mae: 0.0037\n",
      "Epoch 349/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 3.1893e-04 - mae: 0.0037 - val_loss: 3.1694e-04 - val_mae: 0.0037\n",
      "Epoch 350/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 3.1862e-04 - mae: 0.0038 - val_loss: 3.1563e-04 - val_mae: 0.0037\n",
      "Epoch 351/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 3.1555e-04 - mae: 0.0036 - val_loss: 3.1181e-04 - val_mae: 0.0035\n",
      "Epoch 352/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 3.1657e-04 - mae: 0.0038 - val_loss: 3.1617e-04 - val_mae: 0.0040\n",
      "Epoch 353/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 3.1629e-04 - mae: 0.0039 - val_loss: 3.1080e-04 - val_mae: 0.0036\n",
      "Epoch 354/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 3.1507e-04 - mae: 0.0039 - val_loss: 3.0768e-04 - val_mae: 0.0034\n",
      "Epoch 355/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 3.1270e-04 - mae: 0.0038 - val_loss: 3.1511e-04 - val_mae: 0.0043\n",
      "Epoch 356/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 3.1034e-04 - mae: 0.0037 - val_loss: 3.1052e-04 - val_mae: 0.0040\n",
      "Epoch 357/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 3.0875e-04 - mae: 0.0036 - val_loss: 3.0485e-04 - val_mae: 0.0035\n",
      "Epoch 358/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 3.0952e-04 - mae: 0.0038 - val_loss: 3.3205e-04 - val_mae: 0.0059\n",
      "Epoch 359/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 3.0991e-04 - mae: 0.0039 - val_loss: 3.3178e-04 - val_mae: 0.0059\n",
      "Epoch 360/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 3.0553e-04 - mae: 0.0037 - val_loss: 3.1641e-04 - val_mae: 0.0049\n",
      "Epoch 361/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 3.0508e-04 - mae: 0.0037 - val_loss: 3.0462e-04 - val_mae: 0.0039\n",
      "Epoch 362/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 3.0538e-04 - mae: 0.0038 - val_loss: 3.0764e-04 - val_mae: 0.0041\n",
      "Epoch 363/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 3.0511e-04 - mae: 0.0039 - val_loss: 2.9869e-04 - val_mae: 0.0035\n",
      "Epoch 364/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 3.0113e-04 - mae: 0.0036 - val_loss: 2.9817e-04 - val_mae: 0.0034\n",
      "Epoch 365/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 3.0007e-04 - mae: 0.0036 - val_loss: 3.0999e-04 - val_mae: 0.0048\n",
      "Epoch 366/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 3.0257e-04 - mae: 0.0039 - val_loss: 3.0011e-04 - val_mae: 0.0041\n",
      "Epoch 367/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.9830e-04 - mae: 0.0036 - val_loss: 2.9337e-04 - val_mae: 0.0033\n",
      "Epoch 368/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.9919e-04 - mae: 0.0038 - val_loss: 2.9578e-04 - val_mae: 0.0037\n",
      "Epoch 369/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.9691e-04 - mae: 0.0037 - val_loss: 2.9232e-04 - val_mae: 0.0035\n",
      "Epoch 370/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.9640e-04 - mae: 0.0037 - val_loss: 3.1344e-04 - val_mae: 0.0052\n",
      "Epoch 371/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.9476e-04 - mae: 0.0037 - val_loss: 2.9299e-04 - val_mae: 0.0037\n",
      "Epoch 372/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.9245e-04 - mae: 0.0036 - val_loss: 2.9193e-04 - val_mae: 0.0038\n",
      "Epoch 373/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.9402e-04 - mae: 0.0038 - val_loss: 2.9045e-04 - val_mae: 0.0037\n",
      "Epoch 374/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.9353e-04 - mae: 0.0038 - val_loss: 2.9324e-04 - val_mae: 0.0039\n",
      "Epoch 375/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.9057e-04 - mae: 0.0037 - val_loss: 2.8839e-04 - val_mae: 0.0037\n",
      "Epoch 376/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.9068e-04 - mae: 0.0037 - val_loss: 3.1997e-04 - val_mae: 0.0064\n",
      "Epoch 377/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.9123e-04 - mae: 0.0039 - val_loss: 2.8444e-04 - val_mae: 0.0033\n",
      "Epoch 378/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.8833e-04 - mae: 0.0037 - val_loss: 2.8527e-04 - val_mae: 0.0037\n",
      "Epoch 379/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.8653e-04 - mae: 0.0036 - val_loss: 2.8942e-04 - val_mae: 0.0041\n",
      "Epoch 380/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.8616e-04 - mae: 0.0037 - val_loss: 2.9454e-04 - val_mae: 0.0045\n",
      "Epoch 381/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.8552e-04 - mae: 0.0037 - val_loss: 2.8186e-04 - val_mae: 0.0035\n",
      "Epoch 382/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.8443e-04 - mae: 0.0037 - val_loss: 2.9249e-04 - val_mae: 0.0045\n",
      "Epoch 383/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.8354e-04 - mae: 0.0037 - val_loss: 2.8187e-04 - val_mae: 0.0038\n",
      "Epoch 384/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.8203e-04 - mae: 0.0036 - val_loss: 2.8264e-04 - val_mae: 0.0039\n",
      "Epoch 385/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.8074e-04 - mae: 0.0036 - val_loss: 2.7768e-04 - val_mae: 0.0035\n",
      "Epoch 386/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.8007e-04 - mae: 0.0036 - val_loss: 2.7739e-04 - val_mae: 0.0035\n",
      "Epoch 387/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.8091e-04 - mae: 0.0037 - val_loss: 2.7512e-04 - val_mae: 0.0034\n",
      "Epoch 388/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.8102e-04 - mae: 0.0039 - val_loss: 2.8143e-04 - val_mae: 0.0040\n",
      "Epoch 389/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.7807e-04 - mae: 0.0037 - val_loss: 2.7362e-04 - val_mae: 0.0034\n",
      "Epoch 390/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.7753e-04 - mae: 0.0037 - val_loss: 2.7457e-04 - val_mae: 0.0036\n",
      "Epoch 391/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.7643e-04 - mae: 0.0037 - val_loss: 2.7399e-04 - val_mae: 0.0036\n",
      "Epoch 392/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.7748e-04 - mae: 0.0038 - val_loss: 2.7349e-04 - val_mae: 0.0036\n",
      "Epoch 393/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.7336e-04 - mae: 0.0035 - val_loss: 2.7540e-04 - val_mae: 0.0039\n",
      "Epoch 394/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.7315e-04 - mae: 0.0036 - val_loss: 2.6798e-04 - val_mae: 0.0032\n",
      "Epoch 395/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.7356e-04 - mae: 0.0037 - val_loss: 2.7280e-04 - val_mae: 0.0038\n",
      "Epoch 396/2000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 2.7277e-04 - mae: 0.0037 - val_loss: 2.6706e-04 - val_mae: 0.0033\n",
      "Epoch 397/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.7394e-04 - mae: 0.0039 - val_loss: 2.6686e-04 - val_mae: 0.0033\n",
      "Epoch 398/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.7068e-04 - mae: 0.0037 - val_loss: 2.7494e-04 - val_mae: 0.0042\n",
      "Epoch 399/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.7182e-04 - mae: 0.0038 - val_loss: 2.6445e-04 - val_mae: 0.0032\n",
      "Epoch 400/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.6799e-04 - mae: 0.0035 - val_loss: 2.7179e-04 - val_mae: 0.0040\n",
      "Epoch 401/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.6854e-04 - mae: 0.0037 - val_loss: 2.6676e-04 - val_mae: 0.0036\n",
      "Epoch 402/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.6741e-04 - mae: 0.0036 - val_loss: 2.6645e-04 - val_mae: 0.0037\n",
      "Epoch 403/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.6654e-04 - mae: 0.0036 - val_loss: 2.6173e-04 - val_mae: 0.0034\n",
      "Epoch 404/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.6615e-04 - mae: 0.0037 - val_loss: 2.6157e-04 - val_mae: 0.0034\n",
      "Epoch 405/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.6577e-04 - mae: 0.0037 - val_loss: 2.5938e-04 - val_mae: 0.0032\n",
      "Epoch 406/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.6505e-04 - mae: 0.0037 - val_loss: 2.6459e-04 - val_mae: 0.0039\n",
      "Epoch 407/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.6455e-04 - mae: 0.0037 - val_loss: 2.6585e-04 - val_mae: 0.0041\n",
      "Epoch 408/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.6276e-04 - mae: 0.0036 - val_loss: 2.6039e-04 - val_mae: 0.0036\n",
      "Epoch 409/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.6156e-04 - mae: 0.0036 - val_loss: 2.5904e-04 - val_mae: 0.0035\n",
      "Epoch 410/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.6258e-04 - mae: 0.0038 - val_loss: 2.6228e-04 - val_mae: 0.0039\n",
      "Epoch 411/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.6090e-04 - mae: 0.0037 - val_loss: 2.5421e-04 - val_mae: 0.0032\n",
      "Epoch 412/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.5856e-04 - mae: 0.0035 - val_loss: 2.6251e-04 - val_mae: 0.0041\n",
      "Epoch 413/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.5907e-04 - mae: 0.0036 - val_loss: 2.6179e-04 - val_mae: 0.0042\n",
      "Epoch 414/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.5911e-04 - mae: 0.0037 - val_loss: 2.5312e-04 - val_mae: 0.0033\n",
      "Epoch 415/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.5654e-04 - mae: 0.0035 - val_loss: 2.6225e-04 - val_mae: 0.0043\n",
      "Epoch 416/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.5629e-04 - mae: 0.0036 - val_loss: 2.5130e-04 - val_mae: 0.0032\n",
      "Epoch 417/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.5559e-04 - mae: 0.0036 - val_loss: 2.5063e-04 - val_mae: 0.0032\n",
      "Epoch 418/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.5513e-04 - mae: 0.0036 - val_loss: 2.5208e-04 - val_mae: 0.0035\n",
      "Epoch 419/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.5594e-04 - mae: 0.0037 - val_loss: 2.5249e-04 - val_mae: 0.0036\n",
      "Epoch 420/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.5311e-04 - mae: 0.0035 - val_loss: 2.5734e-04 - val_mae: 0.0041\n",
      "Epoch 421/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.5394e-04 - mae: 0.0037 - val_loss: 2.5854e-04 - val_mae: 0.0042\n",
      "Epoch 422/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.5350e-04 - mae: 0.0037 - val_loss: 2.4915e-04 - val_mae: 0.0034\n",
      "Epoch 423/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.5205e-04 - mae: 0.0036 - val_loss: 2.5362e-04 - val_mae: 0.0038\n",
      "Epoch 424/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.5121e-04 - mae: 0.0036 - val_loss: 2.6132e-04 - val_mae: 0.0048\n",
      "Epoch 425/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.5067e-04 - mae: 0.0036 - val_loss: 2.5283e-04 - val_mae: 0.0038\n",
      "Epoch 426/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.5001e-04 - mae: 0.0036 - val_loss: 2.4945e-04 - val_mae: 0.0037\n",
      "Epoch 427/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.4897e-04 - mae: 0.0036 - val_loss: 2.4788e-04 - val_mae: 0.0036\n",
      "Epoch 428/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.4738e-04 - mae: 0.0035 - val_loss: 2.5048e-04 - val_mae: 0.0038\n",
      "Epoch 429/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.4779e-04 - mae: 0.0036 - val_loss: 2.4185e-04 - val_mae: 0.0032\n",
      "Epoch 430/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.4842e-04 - mae: 0.0037 - val_loss: 2.5698e-04 - val_mae: 0.0047\n",
      "Epoch 431/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.4996e-04 - mae: 0.0039 - val_loss: 2.4281e-04 - val_mae: 0.0034\n",
      "Epoch 432/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.4605e-04 - mae: 0.0036 - val_loss: 2.4281e-04 - val_mae: 0.0034\n",
      "Epoch 433/2000\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.4688e-04 - mae: 0.0037 - val_loss: 2.4264e-04 - val_mae: 0.0036\n",
      "Epoch 434/2000\n",
      "265/270 [============================>.] - ETA: 0s - loss: 2.4326e-04 - mae: 0.0034Restoring model weights from the end of the best epoch: 429.\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 2.4324e-04 - mae: 0.0034 - val_loss: 2.4246e-04 - val_mae: 0.0035\n",
      "Epoch 434: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Netzwerkarchitektur\n",
    "model = Sequential([\n",
    "\n",
    "    Dense(248, activation='relu', input_shape=(5,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(184, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(248, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(264, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(8, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(1 , activation = 'linear')\n",
    "])\n",
    "\n",
    "# Optimierer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "# Modell kompilieren (Verwendung von mean_squared_error als Verlustfunktion für Regression)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])  # Metriken für Regression: Mean Absolute Error und Mean Squared Error\n",
    "\n",
    "# Early Stopping Callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "# Trainingsparameter\n",
    "batch_size = 200 \n",
    "epochs = 2000\n",
    "\n",
    "# Modell trainieren (Annahme: X_train, y_train, X_val, y_val sind vordefiniert)\n",
    "history = model.fit(X_train_scaled, y_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "model.save('D4_t_9_I_F_1.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T10:30:32.083243400Z",
     "start_time": "2024-04-02T10:23:50.406164200Z"
    }
   },
   "id": "8b52e1a9a6ff3aeb"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training für Fold 1...\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 2s 5ms/step - loss: 0.2073 - mae: 0.3723 - val_loss: 0.1996 - val_mae: 0.3626\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.1466 - mae: 0.2826 - val_loss: 0.0279 - val_mae: 0.0842\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0221 - mae: 0.0580 - val_loss: 0.0195 - val_mae: 0.0481\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0175 - mae: 0.0389 - val_loss: 0.0161 - val_mae: 0.0334\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0152 - mae: 0.0293 - val_loss: 0.0144 - val_mae: 0.0265\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0138 - mae: 0.0224 - val_loss: 0.0132 - val_mae: 0.0190\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0129 - mae: 0.0171 - val_loss: 0.0125 - val_mae: 0.0148\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0123 - mae: 0.0138 - val_loss: 0.0121 - val_mae: 0.0131\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0119 - mae: 0.0121 - val_loss: 0.0117 - val_mae: 0.0119\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0115 - mae: 0.0107 - val_loss: 0.0113 - val_mae: 0.0100\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0112 - mae: 0.0099 - val_loss: 0.0110 - val_mae: 0.0095\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0108 - mae: 0.0095 - val_loss: 0.0107 - val_mae: 0.0084\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0105 - mae: 0.0086 - val_loss: 0.0104 - val_mae: 0.0087\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0102 - mae: 0.0084 - val_loss: 0.0101 - val_mae: 0.0098\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0099 - mae: 0.0078 - val_loss: 0.0098 - val_mae: 0.0076\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0096 - mae: 0.0076 - val_loss: 0.0095 - val_mae: 0.0071\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0093 - mae: 0.0075 - val_loss: 0.0092 - val_mae: 0.0083\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0091 - mae: 0.0077 - val_loss: 0.0089 - val_mae: 0.0073\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0088 - mae: 0.0070 - val_loss: 0.0086 - val_mae: 0.0073\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0085 - mae: 0.0071 - val_loss: 0.0084 - val_mae: 0.0069\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0082 - mae: 0.0070 - val_loss: 0.0081 - val_mae: 0.0067\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0080 - mae: 0.0068 - val_loss: 0.0079 - val_mae: 0.0062\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0078 - mae: 0.0071 - val_loss: 0.0076 - val_mae: 0.0073\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0075 - mae: 0.0069 - val_loss: 0.0074 - val_mae: 0.0089\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0073 - mae: 0.0069 - val_loss: 0.0072 - val_mae: 0.0069\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0071 - mae: 0.0066 - val_loss: 0.0070 - val_mae: 0.0078\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0069 - mae: 0.0065 - val_loss: 0.0068 - val_mae: 0.0070\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0067 - mae: 0.0067 - val_loss: 0.0066 - val_mae: 0.0061\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0065 - mae: 0.0063 - val_loss: 0.0064 - val_mae: 0.0065\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0063 - mae: 0.0068 - val_loss: 0.0062 - val_mae: 0.0067\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0062 - mae: 0.0065 - val_loss: 0.0061 - val_mae: 0.0065\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0060 - mae: 0.0064 - val_loss: 0.0059 - val_mae: 0.0065\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0058 - mae: 0.0064 - val_loss: 0.0058 - val_mae: 0.0065\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0057 - mae: 0.0065 - val_loss: 0.0056 - val_mae: 0.0057\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0056 - mae: 0.0063 - val_loss: 0.0055 - val_mae: 0.0065\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0054 - mae: 0.0062 - val_loss: 0.0054 - val_mae: 0.0057\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0053 - mae: 0.0062 - val_loss: 0.0052 - val_mae: 0.0055\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0052 - mae: 0.0062 - val_loss: 0.0051 - val_mae: 0.0065\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0051 - mae: 0.0062 - val_loss: 0.0050 - val_mae: 0.0067\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0050 - mae: 0.0063 - val_loss: 0.0049 - val_mae: 0.0057\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0048 - mae: 0.0060 - val_loss: 0.0048 - val_mae: 0.0064\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0047 - mae: 0.0060 - val_loss: 0.0047 - val_mae: 0.0063\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0046 - mae: 0.0062 - val_loss: 0.0046 - val_mae: 0.0063\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0045 - mae: 0.0058 - val_loss: 0.0045 - val_mae: 0.0055\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0044 - mae: 0.0058 - val_loss: 0.0044 - val_mae: 0.0058\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0044 - mae: 0.0061 - val_loss: 0.0043 - val_mae: 0.0055\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0043 - mae: 0.0061 - val_loss: 0.0042 - val_mae: 0.0053\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0042 - mae: 0.0060 - val_loss: 0.0041 - val_mae: 0.0059\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0041 - mae: 0.0057 - val_loss: 0.0041 - val_mae: 0.0053\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0040 - mae: 0.0058 - val_loss: 0.0040 - val_mae: 0.0053\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0040 - mae: 0.0058 - val_loss: 0.0039 - val_mae: 0.0063\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0039 - mae: 0.0058 - val_loss: 0.0038 - val_mae: 0.0058\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0038 - mae: 0.0059 - val_loss: 0.0038 - val_mae: 0.0066\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0037 - mae: 0.0056 - val_loss: 0.0037 - val_mae: 0.0065\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0037 - mae: 0.0057 - val_loss: 0.0036 - val_mae: 0.0054\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0036 - mae: 0.0059 - val_loss: 0.0036 - val_mae: 0.0058\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0035 - mae: 0.0058 - val_loss: 0.0035 - val_mae: 0.0053\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0035 - mae: 0.0059 - val_loss: 0.0035 - val_mae: 0.0059\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0034 - mae: 0.0057 - val_loss: 0.0034 - val_mae: 0.0052\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0034 - mae: 0.0060 - val_loss: 0.0033 - val_mae: 0.0057\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0033 - mae: 0.0054 - val_loss: 0.0033 - val_mae: 0.0053\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0033 - mae: 0.0056 - val_loss: 0.0032 - val_mae: 0.0050\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0032 - mae: 0.0057 - val_loss: 0.0032 - val_mae: 0.0051\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0032 - mae: 0.0055 - val_loss: 0.0031 - val_mae: 0.0058\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0031 - mae: 0.0058 - val_loss: 0.0031 - val_mae: 0.0050\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0031 - mae: 0.0055 - val_loss: 0.0030 - val_mae: 0.0052\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0030 - mae: 0.0055 - val_loss: 0.0030 - val_mae: 0.0051\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0030 - mae: 0.0054 - val_loss: 0.0029 - val_mae: 0.0054\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0029 - mae: 0.0056 - val_loss: 0.0029 - val_mae: 0.0069\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0029 - mae: 0.0054 - val_loss: 0.0028 - val_mae: 0.0052\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0028 - mae: 0.0055 - val_loss: 0.0028 - val_mae: 0.0056\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0028 - mae: 0.0056 - val_loss: 0.0028 - val_mae: 0.0055\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0027 - mae: 0.0053 - val_loss: 0.0028 - val_mae: 0.0084\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0027 - mae: 0.0055 - val_loss: 0.0027 - val_mae: 0.0049\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0027 - mae: 0.0055 - val_loss: 0.0026 - val_mae: 0.0051\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0026 - mae: 0.0054 - val_loss: 0.0026 - val_mae: 0.0053\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0026 - mae: 0.0054 - val_loss: 0.0025 - val_mae: 0.0053\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0025 - mae: 0.0052 - val_loss: 0.0025 - val_mae: 0.0052\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0025 - mae: 0.0056 - val_loss: 0.0025 - val_mae: 0.0047\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0025 - mae: 0.0053 - val_loss: 0.0024 - val_mae: 0.0046\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0024 - mae: 0.0054 - val_loss: 0.0024 - val_mae: 0.0053\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0024 - mae: 0.0054 - val_loss: 0.0024 - val_mae: 0.0049\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0024 - mae: 0.0056 - val_loss: 0.0024 - val_mae: 0.0071\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0023 - mae: 0.0053 - val_loss: 0.0023 - val_mae: 0.0048\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0023 - mae: 0.0054 - val_loss: 0.0023 - val_mae: 0.0081\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0023 - mae: 0.0056 - val_loss: 0.0022 - val_mae: 0.0048\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0022 - mae: 0.0052 - val_loss: 0.0022 - val_mae: 0.0050\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0022 - mae: 0.0053 - val_loss: 0.0022 - val_mae: 0.0052\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0022 - mae: 0.0053 - val_loss: 0.0021 - val_mae: 0.0047\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0021 - mae: 0.0051 - val_loss: 0.0021 - val_mae: 0.0056\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0021 - mae: 0.0054 - val_loss: 0.0021 - val_mae: 0.0047\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0021 - mae: 0.0052 - val_loss: 0.0021 - val_mae: 0.0046\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0051 - val_loss: 0.0020 - val_mae: 0.0050\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0051 - val_loss: 0.0020 - val_mae: 0.0047\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0053 - val_loss: 0.0020 - val_mae: 0.0051\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0051 - val_loss: 0.0020 - val_mae: 0.0055\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0053 - val_loss: 0.0019 - val_mae: 0.0047\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0049 - val_loss: 0.0019 - val_mae: 0.0048\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0053 - val_loss: 0.0019 - val_mae: 0.0062\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0050 - val_loss: 0.0019 - val_mae: 0.0056\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0018 - mae: 0.0052 - val_loss: 0.0018 - val_mae: 0.0058\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0050 - val_loss: 0.0018 - val_mae: 0.0055\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0054 - val_loss: 0.0018 - val_mae: 0.0054\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0049 - val_loss: 0.0018 - val_mae: 0.0054\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0051 - val_loss: 0.0017 - val_mae: 0.0049\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0052 - val_loss: 0.0017 - val_mae: 0.0044\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0050 - val_loss: 0.0017 - val_mae: 0.0046\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0050 - val_loss: 0.0017 - val_mae: 0.0050\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0049 - val_loss: 0.0016 - val_mae: 0.0050\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0051 - val_loss: 0.0016 - val_mae: 0.0051\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0050 - val_loss: 0.0016 - val_mae: 0.0046\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0048 - val_loss: 0.0016 - val_mae: 0.0047\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0049 - val_loss: 0.0016 - val_mae: 0.0046\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0050 - val_loss: 0.0015 - val_mae: 0.0044\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0048 - val_loss: 0.0015 - val_mae: 0.0045\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0051 - val_loss: 0.0015 - val_mae: 0.0055\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0050 - val_loss: 0.0015 - val_mae: 0.0045\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0050 - val_loss: 0.0015 - val_mae: 0.0063\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0048 - val_loss: 0.0014 - val_mae: 0.0044\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0048 - val_loss: 0.0014 - val_mae: 0.0050\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0050 - val_loss: 0.0014 - val_mae: 0.0048\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0048 - val_loss: 0.0014 - val_mae: 0.0043\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0049 - val_loss: 0.0014 - val_mae: 0.0050\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0048 - val_loss: 0.0014 - val_mae: 0.0045\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0047 - val_loss: 0.0013 - val_mae: 0.0044\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0049 - val_loss: 0.0013 - val_mae: 0.0052\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0050 - val_loss: 0.0013 - val_mae: 0.0044\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0047 - val_loss: 0.0013 - val_mae: 0.0049\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0048 - val_loss: 0.0013 - val_mae: 0.0043\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0047 - val_loss: 0.0013 - val_mae: 0.0049\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0048 - val_loss: 0.0013 - val_mae: 0.0050\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0049 - val_loss: 0.0013 - val_mae: 0.0059\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0048 - val_loss: 0.0012 - val_mae: 0.0044\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0050 - val_loss: 0.0012 - val_mae: 0.0045\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0045 - val_loss: 0.0012 - val_mae: 0.0048\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0048 - val_loss: 0.0012 - val_mae: 0.0045\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0047 - val_loss: 0.0012 - val_mae: 0.0054\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0047 - val_loss: 0.0012 - val_mae: 0.0043\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0048 - val_loss: 0.0011 - val_mae: 0.0046\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0049 - val_loss: 0.0011 - val_mae: 0.0042\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0046 - val_loss: 0.0011 - val_mae: 0.0048\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0049 - val_loss: 0.0011 - val_mae: 0.0046\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0046 - val_loss: 0.0011 - val_mae: 0.0049\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0048 - val_loss: 0.0011 - val_mae: 0.0049\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0048 - val_loss: 0.0011 - val_mae: 0.0044\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0047 - val_loss: 0.0011 - val_mae: 0.0045\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0047 - val_loss: 0.0010 - val_mae: 0.0047\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0047 - val_loss: 0.0010 - val_mae: 0.0044\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0047 - val_loss: 0.0010 - val_mae: 0.0045\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0048 - val_loss: 0.0010 - val_mae: 0.0046\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0047 - val_loss: 0.0010 - val_mae: 0.0052\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0047 - val_loss: 0.0010 - val_mae: 0.0060\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 9.9519e-04 - mae: 0.0047 - val_loss: 0.0010 - val_mae: 0.0057\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 9.8601e-04 - mae: 0.0048 - val_loss: 9.7281e-04 - val_mae: 0.0042\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 9.7380e-04 - mae: 0.0046 - val_loss: 9.6790e-04 - val_mae: 0.0047\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 9.6602e-04 - mae: 0.0047 - val_loss: 9.5259e-04 - val_mae: 0.0042\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 9.5556e-04 - mae: 0.0047 - val_loss: 9.4309e-04 - val_mae: 0.0042\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 9.4676e-04 - mae: 0.0047 - val_loss: 9.4887e-04 - val_mae: 0.0053\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.3868e-04 - mae: 0.0048 - val_loss: 9.2483e-04 - val_mae: 0.0042\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 9.2684e-04 - mae: 0.0046 - val_loss: 9.2569e-04 - val_mae: 0.0050\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.2430e-04 - mae: 0.0049 - val_loss: 9.0668e-04 - val_mae: 0.0041\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.0894e-04 - mae: 0.0045 - val_loss: 9.0238e-04 - val_mae: 0.0045\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 8.9950e-04 - mae: 0.0045 - val_loss: 8.9143e-04 - val_mae: 0.0042\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 8.9260e-04 - mae: 0.0046 - val_loss: 8.9155e-04 - val_mae: 0.0049\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 8.8409e-04 - mae: 0.0046 - val_loss: 8.7702e-04 - val_mae: 0.0045\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 8.7603e-04 - mae: 0.0046 - val_loss: 8.6999e-04 - val_mae: 0.0044\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.6891e-04 - mae: 0.0047 - val_loss: 8.5947e-04 - val_mae: 0.0045\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 8.5986e-04 - mae: 0.0046 - val_loss: 8.5632e-04 - val_mae: 0.0047\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 8.5287e-04 - mae: 0.0047 - val_loss: 8.4175e-04 - val_mae: 0.0043\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 8.4368e-04 - mae: 0.0046 - val_loss: 8.3838e-04 - val_mae: 0.0045\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.3427e-04 - mae: 0.0044 - val_loss: 8.2348e-04 - val_mae: 0.0040\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 8.2899e-04 - mae: 0.0046 - val_loss: 8.4013e-04 - val_mae: 0.0059\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 8.1985e-04 - mae: 0.0045 - val_loss: 8.1590e-04 - val_mae: 0.0047\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.1405e-04 - mae: 0.0046 - val_loss: 8.0573e-04 - val_mae: 0.0043\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 8.0799e-04 - mae: 0.0047 - val_loss: 8.2956e-04 - val_mae: 0.0066\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 7.9901e-04 - mae: 0.0045 - val_loss: 7.8942e-04 - val_mae: 0.0042\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 7.9534e-04 - mae: 0.0048 - val_loss: 7.9932e-04 - val_mae: 0.0052\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 7.8833e-04 - mae: 0.0047 - val_loss: 7.7709e-04 - val_mae: 0.0042\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 7.8257e-04 - mae: 0.0048 - val_loss: 7.9310e-04 - val_mae: 0.0060\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 7.7312e-04 - mae: 0.0045 - val_loss: 7.6327e-04 - val_mae: 0.0042\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.6754e-04 - mae: 0.0046 - val_loss: 7.5545e-04 - val_mae: 0.0040\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.5998e-04 - mae: 0.0045 - val_loss: 7.5429e-04 - val_mae: 0.0044\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 7.5747e-04 - mae: 0.0047 - val_loss: 7.4801e-04 - val_mae: 0.0044\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.4852e-04 - mae: 0.0045 - val_loss: 7.3866e-04 - val_mae: 0.0041\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.4181e-04 - mae: 0.0045 - val_loss: 7.4150e-04 - val_mae: 0.0050\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 7.3861e-04 - mae: 0.0046 - val_loss: 7.4792e-04 - val_mae: 0.0057\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 7.3375e-04 - mae: 0.0047 - val_loss: 7.3361e-04 - val_mae: 0.0050\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.2697e-04 - mae: 0.0046 - val_loss: 7.2947e-04 - val_mae: 0.0051\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 7.1919e-04 - mae: 0.0044 - val_loss: 7.1613e-04 - val_mae: 0.0046\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 7.1529e-04 - mae: 0.0046 - val_loss: 7.0758e-04 - val_mae: 0.0044\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 7.0874e-04 - mae: 0.0045 - val_loss: 6.9989e-04 - val_mae: 0.0042\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.0224e-04 - mae: 0.0044 - val_loss: 7.2351e-04 - val_mae: 0.0061\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.0025e-04 - mae: 0.0046 - val_loss: 6.9398e-04 - val_mae: 0.0046\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.9120e-04 - mae: 0.0044 - val_loss: 6.8618e-04 - val_mae: 0.0044\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.8848e-04 - mae: 0.0046 - val_loss: 7.0168e-04 - val_mae: 0.0058\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.8489e-04 - mae: 0.0047 - val_loss: 6.7890e-04 - val_mae: 0.0047\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 6.7612e-04 - mae: 0.0044 - val_loss: 6.6892e-04 - val_mae: 0.0043\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.7379e-04 - mae: 0.0046 - val_loss: 6.6542e-04 - val_mae: 0.0042\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.6634e-04 - mae: 0.0044 - val_loss: 6.6113e-04 - val_mae: 0.0044\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 6.6266e-04 - mae: 0.0045 - val_loss: 6.6340e-04 - val_mae: 0.0050\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 6.5903e-04 - mae: 0.0046 - val_loss: 6.7210e-04 - val_mae: 0.0056\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.5333e-04 - mae: 0.0045 - val_loss: 6.4405e-04 - val_mae: 0.0042\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.5024e-04 - mae: 0.0046 - val_loss: 6.3894e-04 - val_mae: 0.0041\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 6.4446e-04 - mae: 0.0045 - val_loss: 6.4239e-04 - val_mae: 0.0047\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 6.4084e-04 - mae: 0.0046 - val_loss: 6.3248e-04 - val_mae: 0.0043\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 6.3329e-04 - mae: 0.0044 - val_loss: 6.4281e-04 - val_mae: 0.0054\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 6.3020e-04 - mae: 0.0045 - val_loss: 6.2048e-04 - val_mae: 0.0040\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.2532e-04 - mae: 0.0044 - val_loss: 6.2881e-04 - val_mae: 0.0050\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.2192e-04 - mae: 0.0045 - val_loss: 6.1154e-04 - val_mae: 0.0040\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.1554e-04 - mae: 0.0044 - val_loss: 6.1480e-04 - val_mae: 0.0048\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 6.1474e-04 - mae: 0.0046 - val_loss: 6.0836e-04 - val_mae: 0.0045\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.1116e-04 - mae: 0.0047 - val_loss: 6.0196e-04 - val_mae: 0.0043\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 6.0234e-04 - mae: 0.0043 - val_loss: 6.0706e-04 - val_mae: 0.0049\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.9836e-04 - mae: 0.0044 - val_loss: 5.9336e-04 - val_mae: 0.0042\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.9518e-04 - mae: 0.0044 - val_loss: 5.8723e-04 - val_mae: 0.0040\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.8967e-04 - mae: 0.0043 - val_loss: 6.0775e-04 - val_mae: 0.0060\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.9192e-04 - mae: 0.0048 - val_loss: 5.8403e-04 - val_mae: 0.0045\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.8395e-04 - mae: 0.0045 - val_loss: 5.8757e-04 - val_mae: 0.0049\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.7906e-04 - mae: 0.0044 - val_loss: 6.1429e-04 - val_mae: 0.0071\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.7571e-04 - mae: 0.0044 - val_loss: 5.6909e-04 - val_mae: 0.0042\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.7474e-04 - mae: 0.0046 - val_loss: 5.6584e-04 - val_mae: 0.0042\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.7029e-04 - mae: 0.0045 - val_loss: 5.6224e-04 - val_mae: 0.0042\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.6686e-04 - mae: 0.0045 - val_loss: 5.6154e-04 - val_mae: 0.0045\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.6018e-04 - mae: 0.0043 - val_loss: 5.5424e-04 - val_mae: 0.0041\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.6005e-04 - mae: 0.0045 - val_loss: 5.5841e-04 - val_mae: 0.0046\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.5492e-04 - mae: 0.0044 - val_loss: 5.4663e-04 - val_mae: 0.0040\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.5344e-04 - mae: 0.0045 - val_loss: 5.4644e-04 - val_mae: 0.0042\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.5064e-04 - mae: 0.0046 - val_loss: 5.4511e-04 - val_mae: 0.0045\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.4550e-04 - mae: 0.0044 - val_loss: 5.3917e-04 - val_mae: 0.0041\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.4255e-04 - mae: 0.0044 - val_loss: 5.4208e-04 - val_mae: 0.0046\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.3923e-04 - mae: 0.0044 - val_loss: 5.5806e-04 - val_mae: 0.0057\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.3835e-04 - mae: 0.0046 - val_loss: 5.3190e-04 - val_mae: 0.0043\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.3408e-04 - mae: 0.0045 - val_loss: 5.3125e-04 - val_mae: 0.0046\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.2977e-04 - mae: 0.0044 - val_loss: 5.2895e-04 - val_mae: 0.0044\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.2672e-04 - mae: 0.0044 - val_loss: 5.1941e-04 - val_mae: 0.0040\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.2366e-04 - mae: 0.0044 - val_loss: 5.2191e-04 - val_mae: 0.0045\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.2171e-04 - mae: 0.0044 - val_loss: 5.1567e-04 - val_mae: 0.0042\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.1846e-04 - mae: 0.0044 - val_loss: 5.1362e-04 - val_mae: 0.0042\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.1812e-04 - mae: 0.0046 - val_loss: 5.1274e-04 - val_mae: 0.0044\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.1069e-04 - mae: 0.0042 - val_loss: 5.0994e-04 - val_mae: 0.0046\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.0977e-04 - mae: 0.0044 - val_loss: 5.0375e-04 - val_mae: 0.0042\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.1087e-04 - mae: 0.0047 - val_loss: 5.2055e-04 - val_mae: 0.0055\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.0636e-04 - mae: 0.0045 - val_loss: 4.9795e-04 - val_mae: 0.0042\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.0067e-04 - mae: 0.0043 - val_loss: 4.9465e-04 - val_mae: 0.0040\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 5.0229e-04 - mae: 0.0046 - val_loss: 5.1525e-04 - val_mae: 0.0060\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.9985e-04 - mae: 0.0046 - val_loss: 4.9779e-04 - val_mae: 0.0048\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.9531e-04 - mae: 0.0044 - val_loss: 4.9117e-04 - val_mae: 0.0045\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.9017e-04 - mae: 0.0042 - val_loss: 4.8389e-04 - val_mae: 0.0040\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.8901e-04 - mae: 0.0043 - val_loss: 4.8315e-04 - val_mae: 0.0041\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.8689e-04 - mae: 0.0044 - val_loss: 5.1001e-04 - val_mae: 0.0065\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.8504e-04 - mae: 0.0044 - val_loss: 4.7652e-04 - val_mae: 0.0040\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.8158e-04 - mae: 0.0043 - val_loss: 4.7582e-04 - val_mae: 0.0041\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.7907e-04 - mae: 0.0043 - val_loss: 4.7219e-04 - val_mae: 0.0040\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.8194e-04 - mae: 0.0047 - val_loss: 4.7216e-04 - val_mae: 0.0042\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.7327e-04 - mae: 0.0042 - val_loss: 4.7954e-04 - val_mae: 0.0048\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.7433e-04 - mae: 0.0045 - val_loss: 4.7461e-04 - val_mae: 0.0046\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.6994e-04 - mae: 0.0043 - val_loss: 4.6467e-04 - val_mae: 0.0041\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.6603e-04 - mae: 0.0042 - val_loss: 4.6725e-04 - val_mae: 0.0047\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.6858e-04 - mae: 0.0045 - val_loss: 4.6391e-04 - val_mae: 0.0044\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.6624e-04 - mae: 0.0045 - val_loss: 4.7554e-04 - val_mae: 0.0054\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.6126e-04 - mae: 0.0043 - val_loss: 4.6149e-04 - val_mae: 0.0045\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.6095e-04 - mae: 0.0044 - val_loss: 4.6257e-04 - val_mae: 0.0050\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.5533e-04 - mae: 0.0042 - val_loss: 4.5042e-04 - val_mae: 0.0041\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.5632e-04 - mae: 0.0044 - val_loss: 4.4622e-04 - val_mae: 0.0039\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.5413e-04 - mae: 0.0044 - val_loss: 4.4631e-04 - val_mae: 0.0040\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.4903e-04 - mae: 0.0042 - val_loss: 4.4259e-04 - val_mae: 0.0038\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.5030e-04 - mae: 0.0044 - val_loss: 4.5315e-04 - val_mae: 0.0049\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.4499e-04 - mae: 0.0042 - val_loss: 4.4552e-04 - val_mae: 0.0043\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.4614e-04 - mae: 0.0044 - val_loss: 4.3803e-04 - val_mae: 0.0040\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.4433e-04 - mae: 0.0045 - val_loss: 4.3784e-04 - val_mae: 0.0041\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.4173e-04 - mae: 0.0044 - val_loss: 4.3445e-04 - val_mae: 0.0041\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.3867e-04 - mae: 0.0043 - val_loss: 4.3315e-04 - val_mae: 0.0041\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.3656e-04 - mae: 0.0043 - val_loss: 4.4263e-04 - val_mae: 0.0048\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.3708e-04 - mae: 0.0045 - val_loss: 4.6251e-04 - val_mae: 0.0058\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.3326e-04 - mae: 0.0043 - val_loss: 4.2627e-04 - val_mae: 0.0040\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.3000e-04 - mae: 0.0042 - val_loss: 4.2572e-04 - val_mae: 0.0041\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.3008e-04 - mae: 0.0043 - val_loss: 4.3104e-04 - val_mae: 0.0046\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.2771e-04 - mae: 0.0043 - val_loss: 4.3301e-04 - val_mae: 0.0049\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.2828e-04 - mae: 0.0045 - val_loss: 4.2491e-04 - val_mae: 0.0045\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.2359e-04 - mae: 0.0043 - val_loss: 4.2263e-04 - val_mae: 0.0043\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.2056e-04 - mae: 0.0041 - val_loss: 4.2842e-04 - val_mae: 0.0051\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.2324e-04 - mae: 0.0045 - val_loss: 4.2334e-04 - val_mae: 0.0049\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.1772e-04 - mae: 0.0042 - val_loss: 4.1204e-04 - val_mae: 0.0039\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.1812e-04 - mae: 0.0043 - val_loss: 4.1167e-04 - val_mae: 0.0040\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.1665e-04 - mae: 0.0044 - val_loss: 4.1344e-04 - val_mae: 0.0045\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.1421e-04 - mae: 0.0043 - val_loss: 4.0543e-04 - val_mae: 0.0038\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.1461e-04 - mae: 0.0045 - val_loss: 4.0672e-04 - val_mae: 0.0040\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.0816e-04 - mae: 0.0041 - val_loss: 4.0689e-04 - val_mae: 0.0041\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 4.0895e-04 - mae: 0.0043 - val_loss: 4.1085e-04 - val_mae: 0.0045\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.0606e-04 - mae: 0.0042 - val_loss: 4.0396e-04 - val_mae: 0.0041\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.0724e-04 - mae: 0.0044 - val_loss: 3.9794e-04 - val_mae: 0.0038\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.0344e-04 - mae: 0.0042 - val_loss: 4.1079e-04 - val_mae: 0.0050\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.0567e-04 - mae: 0.0045 - val_loss: 3.9899e-04 - val_mae: 0.0042\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.0185e-04 - mae: 0.0043 - val_loss: 3.9671e-04 - val_mae: 0.0042\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.9837e-04 - mae: 0.0042 - val_loss: 4.0108e-04 - val_mae: 0.0044\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.9809e-04 - mae: 0.0043 - val_loss: 3.9407e-04 - val_mae: 0.0041\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.9537e-04 - mae: 0.0042 - val_loss: 3.9026e-04 - val_mae: 0.0039\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.9490e-04 - mae: 0.0042 - val_loss: 3.8766e-04 - val_mae: 0.0038\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.9484e-04 - mae: 0.0043 - val_loss: 3.8583e-04 - val_mae: 0.0038\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.9221e-04 - mae: 0.0043 - val_loss: 3.8719e-04 - val_mae: 0.0041\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.9131e-04 - mae: 0.0043 - val_loss: 3.9448e-04 - val_mae: 0.0048\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.8875e-04 - mae: 0.0042 - val_loss: 3.9396e-04 - val_mae: 0.0049\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.8816e-04 - mae: 0.0043 - val_loss: 3.9453e-04 - val_mae: 0.0047\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.8678e-04 - mae: 0.0043 - val_loss: 3.8468e-04 - val_mae: 0.0042\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.8330e-04 - mae: 0.0041 - val_loss: 3.7763e-04 - val_mae: 0.0039\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.8610e-04 - mae: 0.0044 - val_loss: 3.8255e-04 - val_mae: 0.0044\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.8143e-04 - mae: 0.0042 - val_loss: 3.8617e-04 - val_mae: 0.0049\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.7981e-04 - mae: 0.0042 - val_loss: 3.7865e-04 - val_mae: 0.0042\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.7998e-04 - mae: 0.0042 - val_loss: 3.8853e-04 - val_mae: 0.0052\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.7965e-04 - mae: 0.0043 - val_loss: 3.6997e-04 - val_mae: 0.0038\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.7786e-04 - mae: 0.0043 - val_loss: 3.9610e-04 - val_mae: 0.0057\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.7601e-04 - mae: 0.0042 - val_loss: 3.7300e-04 - val_mae: 0.0043\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.7555e-04 - mae: 0.0043 - val_loss: 3.7732e-04 - val_mae: 0.0046\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.7431e-04 - mae: 0.0043 - val_loss: 3.6579e-04 - val_mae: 0.0038\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.7147e-04 - mae: 0.0042 - val_loss: 3.6579e-04 - val_mae: 0.0039\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.7098e-04 - mae: 0.0042 - val_loss: 3.6590e-04 - val_mae: 0.0040\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.7161e-04 - mae: 0.0043 - val_loss: 3.6482e-04 - val_mae: 0.0040\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.6832e-04 - mae: 0.0042 - val_loss: 3.6202e-04 - val_mae: 0.0038\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.6902e-04 - mae: 0.0043 - val_loss: 3.6292e-04 - val_mae: 0.0041\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.6450e-04 - mae: 0.0040 - val_loss: 3.8720e-04 - val_mae: 0.0061\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.6561e-04 - mae: 0.0042 - val_loss: 3.6005e-04 - val_mae: 0.0040\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.6345e-04 - mae: 0.0041 - val_loss: 3.6285e-04 - val_mae: 0.0042\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.6304e-04 - mae: 0.0042 - val_loss: 3.5570e-04 - val_mae: 0.0038\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.6254e-04 - mae: 0.0043 - val_loss: 3.5673e-04 - val_mae: 0.0039\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.6039e-04 - mae: 0.0042 - val_loss: 3.7076e-04 - val_mae: 0.0053\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.5984e-04 - mae: 0.0042 - val_loss: 3.6224e-04 - val_mae: 0.0046\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.5887e-04 - mae: 0.0042 - val_loss: 3.5412e-04 - val_mae: 0.0040\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.5664e-04 - mae: 0.0041 - val_loss: 3.5143e-04 - val_mae: 0.0039\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.5613e-04 - mae: 0.0042 - val_loss: 4.2190e-04 - val_mae: 0.0089\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.5566e-04 - mae: 0.0042 - val_loss: 3.4800e-04 - val_mae: 0.0037\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.5256e-04 - mae: 0.0041 - val_loss: 3.5080e-04 - val_mae: 0.0041\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.5163e-04 - mae: 0.0041 - val_loss: 3.4491e-04 - val_mae: 0.0037\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.5136e-04 - mae: 0.0041 - val_loss: 3.4772e-04 - val_mae: 0.0040\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.5044e-04 - mae: 0.0042 - val_loss: 3.4468e-04 - val_mae: 0.0038\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.5340e-04 - mae: 0.0045 - val_loss: 3.4944e-04 - val_mae: 0.0043\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.4894e-04 - mae: 0.0042 - val_loss: 3.4991e-04 - val_mae: 0.0045\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.4741e-04 - mae: 0.0041 - val_loss: 3.4393e-04 - val_mae: 0.0040\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.4566e-04 - mae: 0.0041 - val_loss: 3.4169e-04 - val_mae: 0.0039\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.4678e-04 - mae: 0.0042 - val_loss: 3.4062e-04 - val_mae: 0.0038\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.4571e-04 - mae: 0.0043 - val_loss: 3.4298e-04 - val_mae: 0.0042\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.4394e-04 - mae: 0.0042 - val_loss: 3.4198e-04 - val_mae: 0.0042\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.4094e-04 - mae: 0.0040 - val_loss: 3.3776e-04 - val_mae: 0.0040\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.4189e-04 - mae: 0.0042 - val_loss: 3.4103e-04 - val_mae: 0.0043\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.4104e-04 - mae: 0.0042 - val_loss: 3.3572e-04 - val_mae: 0.0039\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.4008e-04 - mae: 0.0042 - val_loss: 3.3332e-04 - val_mae: 0.0038\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.4052e-04 - mae: 0.0043 - val_loss: 3.4794e-04 - val_mae: 0.0051\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.3669e-04 - mae: 0.0040 - val_loss: 3.3262e-04 - val_mae: 0.0039\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.3708e-04 - mae: 0.0042 - val_loss: 3.4429e-04 - val_mae: 0.0048\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.3696e-04 - mae: 0.0042 - val_loss: 3.3848e-04 - val_mae: 0.0045\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.3491e-04 - mae: 0.0041 - val_loss: 3.4245e-04 - val_mae: 0.0049\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.3641e-04 - mae: 0.0043 - val_loss: 3.4860e-04 - val_mae: 0.0053\n",
      "Epoch 352/1000\n",
      "268/270 [============================>.] - ETA: 0s - loss: 3.3404e-04 - mae: 0.0042Restoring model weights from the end of the best epoch: 347.\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.3421e-04 - mae: 0.0042 - val_loss: 3.5825e-04 - val_mae: 0.0065\n",
      "Epoch 352: early stopping\n",
      "Training für Fold 2...\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 3s 5ms/step - loss: 0.1033 - mae: 0.1759 - val_loss: 0.0331 - val_mae: 0.0920\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0290 - mae: 0.0769 - val_loss: 0.0257 - val_mae: 0.0640\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0238 - mae: 0.0559 - val_loss: 0.0224 - val_mae: 0.0498\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0211 - mae: 0.0461 - val_loss: 0.0200 - val_mae: 0.0419\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0193 - mae: 0.0390 - val_loss: 0.0185 - val_mae: 0.0360\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0179 - mae: 0.0334 - val_loss: 0.0173 - val_mae: 0.0304\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0169 - mae: 0.0283 - val_loss: 0.0165 - val_mae: 0.0265\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0161 - mae: 0.0240 - val_loss: 0.0157 - val_mae: 0.0221\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0155 - mae: 0.0207 - val_loss: 0.0153 - val_mae: 0.0201\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0150 - mae: 0.0177 - val_loss: 0.0148 - val_mae: 0.0163\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0146 - mae: 0.0155 - val_loss: 0.0145 - val_mae: 0.0152\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0143 - mae: 0.0141 - val_loss: 0.0142 - val_mae: 0.0136\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0141 - mae: 0.0129 - val_loss: 0.0139 - val_mae: 0.0122\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0138 - mae: 0.0120 - val_loss: 0.0137 - val_mae: 0.0118\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0135 - mae: 0.0112 - val_loss: 0.0134 - val_mae: 0.0106\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0133 - mae: 0.0107 - val_loss: 0.0132 - val_mae: 0.0108\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0130 - mae: 0.0102 - val_loss: 0.0129 - val_mae: 0.0105\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0128 - mae: 0.0097 - val_loss: 0.0127 - val_mae: 0.0097\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0125 - mae: 0.0095 - val_loss: 0.0125 - val_mae: 0.0121\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0123 - mae: 0.0094 - val_loss: 0.0122 - val_mae: 0.0090\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0121 - mae: 0.0089 - val_loss: 0.0119 - val_mae: 0.0089\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0118 - mae: 0.0091 - val_loss: 0.0117 - val_mae: 0.0083\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0116 - mae: 0.0085 - val_loss: 0.0115 - val_mae: 0.0089\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0113 - mae: 0.0086 - val_loss: 0.0112 - val_mae: 0.0081\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0111 - mae: 0.0083 - val_loss: 0.0110 - val_mae: 0.0078\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0109 - mae: 0.0086 - val_loss: 0.0108 - val_mae: 0.0102\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0106 - mae: 0.0087 - val_loss: 0.0105 - val_mae: 0.0082\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0104 - mae: 0.0080 - val_loss: 0.0103 - val_mae: 0.0076\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0102 - mae: 0.0078 - val_loss: 0.0100 - val_mae: 0.0076\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0099 - mae: 0.0079 - val_loss: 0.0099 - val_mae: 0.0092\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0097 - mae: 0.0078 - val_loss: 0.0096 - val_mae: 0.0075\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0095 - mae: 0.0077 - val_loss: 0.0094 - val_mae: 0.0084\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0093 - mae: 0.0075 - val_loss: 0.0092 - val_mae: 0.0071\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0091 - mae: 0.0076 - val_loss: 0.0090 - val_mae: 0.0078\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0089 - mae: 0.0076 - val_loss: 0.0087 - val_mae: 0.0071\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0087 - mae: 0.0075 - val_loss: 0.0086 - val_mae: 0.0073\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0085 - mae: 0.0078 - val_loss: 0.0083 - val_mae: 0.0070\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0083 - mae: 0.0073 - val_loss: 0.0082 - val_mae: 0.0069\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0081 - mae: 0.0074 - val_loss: 0.0080 - val_mae: 0.0071\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0079 - mae: 0.0073 - val_loss: 0.0078 - val_mae: 0.0073\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0077 - mae: 0.0072 - val_loss: 0.0076 - val_mae: 0.0071\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0075 - mae: 0.0070 - val_loss: 0.0075 - val_mae: 0.0096\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0074 - mae: 0.0074 - val_loss: 0.0073 - val_mae: 0.0067\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0072 - mae: 0.0072 - val_loss: 0.0071 - val_mae: 0.0064\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0070 - mae: 0.0070 - val_loss: 0.0070 - val_mae: 0.0067\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0069 - mae: 0.0072 - val_loss: 0.0068 - val_mae: 0.0070\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0067 - mae: 0.0069 - val_loss: 0.0067 - val_mae: 0.0063\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0066 - mae: 0.0071 - val_loss: 0.0065 - val_mae: 0.0071\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0065 - mae: 0.0070 - val_loss: 0.0064 - val_mae: 0.0069\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0063 - mae: 0.0071 - val_loss: 0.0063 - val_mae: 0.0063\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0062 - mae: 0.0069 - val_loss: 0.0062 - val_mae: 0.0073\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0061 - mae: 0.0067 - val_loss: 0.0061 - val_mae: 0.0101\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0060 - mae: 0.0068 - val_loss: 0.0059 - val_mae: 0.0069\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0059 - mae: 0.0069 - val_loss: 0.0058 - val_mae: 0.0064\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0057 - mae: 0.0068 - val_loss: 0.0057 - val_mae: 0.0064\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0056 - mae: 0.0068 - val_loss: 0.0056 - val_mae: 0.0076\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0055 - mae: 0.0067 - val_loss: 0.0055 - val_mae: 0.0082\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0054 - mae: 0.0066 - val_loss: 0.0054 - val_mae: 0.0080\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0053 - mae: 0.0064 - val_loss: 0.0053 - val_mae: 0.0062\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0052 - mae: 0.0065 - val_loss: 0.0052 - val_mae: 0.0068\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0051 - mae: 0.0069 - val_loss: 0.0051 - val_mae: 0.0069\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0050 - mae: 0.0067 - val_loss: 0.0050 - val_mae: 0.0062\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0050 - mae: 0.0066 - val_loss: 0.0049 - val_mae: 0.0069\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0049 - mae: 0.0064 - val_loss: 0.0048 - val_mae: 0.0060\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0048 - mae: 0.0064 - val_loss: 0.0047 - val_mae: 0.0058\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0047 - mae: 0.0062 - val_loss: 0.0047 - val_mae: 0.0070\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0046 - mae: 0.0067 - val_loss: 0.0046 - val_mae: 0.0063\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0045 - mae: 0.0062 - val_loss: 0.0045 - val_mae: 0.0063\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0044 - mae: 0.0061 - val_loss: 0.0044 - val_mae: 0.0061\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0044 - mae: 0.0061 - val_loss: 0.0043 - val_mae: 0.0066\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0043 - mae: 0.0065 - val_loss: 0.0043 - val_mae: 0.0060\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0042 - mae: 0.0060 - val_loss: 0.0042 - val_mae: 0.0061\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0041 - mae: 0.0061 - val_loss: 0.0041 - val_mae: 0.0057\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0041 - mae: 0.0060 - val_loss: 0.0040 - val_mae: 0.0062\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0040 - mae: 0.0061 - val_loss: 0.0040 - val_mae: 0.0066\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0039 - mae: 0.0058 - val_loss: 0.0039 - val_mae: 0.0055\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0039 - mae: 0.0060 - val_loss: 0.0038 - val_mae: 0.0058\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0038 - mae: 0.0059 - val_loss: 0.0038 - val_mae: 0.0059\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0037 - mae: 0.0060 - val_loss: 0.0037 - val_mae: 0.0054\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0037 - mae: 0.0060 - val_loss: 0.0036 - val_mae: 0.0058\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0036 - mae: 0.0057 - val_loss: 0.0036 - val_mae: 0.0056\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0036 - mae: 0.0057 - val_loss: 0.0035 - val_mae: 0.0065\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0035 - mae: 0.0060 - val_loss: 0.0035 - val_mae: 0.0066\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0034 - mae: 0.0062 - val_loss: 0.0034 - val_mae: 0.0070\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0034 - mae: 0.0059 - val_loss: 0.0034 - val_mae: 0.0070\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0033 - mae: 0.0060 - val_loss: 0.0033 - val_mae: 0.0057\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0033 - mae: 0.0056 - val_loss: 0.0032 - val_mae: 0.0053\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0032 - mae: 0.0058 - val_loss: 0.0033 - val_mae: 0.0089\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0032 - mae: 0.0058 - val_loss: 0.0031 - val_mae: 0.0051\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0031 - mae: 0.0059 - val_loss: 0.0031 - val_mae: 0.0054\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0031 - mae: 0.0055 - val_loss: 0.0031 - val_mae: 0.0058\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0030 - mae: 0.0058 - val_loss: 0.0030 - val_mae: 0.0058\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0030 - mae: 0.0058 - val_loss: 0.0030 - val_mae: 0.0052\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0029 - mae: 0.0054 - val_loss: 0.0029 - val_mae: 0.0059\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0029 - mae: 0.0053 - val_loss: 0.0029 - val_mae: 0.0055\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0029 - mae: 0.0055 - val_loss: 0.0028 - val_mae: 0.0049\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0028 - mae: 0.0055 - val_loss: 0.0028 - val_mae: 0.0054\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0028 - mae: 0.0053 - val_loss: 0.0027 - val_mae: 0.0048\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0027 - mae: 0.0056 - val_loss: 0.0027 - val_mae: 0.0049\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0027 - mae: 0.0054 - val_loss: 0.0027 - val_mae: 0.0061\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0026 - mae: 0.0056 - val_loss: 0.0026 - val_mae: 0.0049\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0026 - mae: 0.0054 - val_loss: 0.0026 - val_mae: 0.0070\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0026 - mae: 0.0055 - val_loss: 0.0025 - val_mae: 0.0052\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0025 - mae: 0.0056 - val_loss: 0.0025 - val_mae: 0.0064\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0025 - mae: 0.0055 - val_loss: 0.0025 - val_mae: 0.0068\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0025 - mae: 0.0054 - val_loss: 0.0024 - val_mae: 0.0048\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0024 - mae: 0.0052 - val_loss: 0.0024 - val_mae: 0.0053\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0024 - mae: 0.0054 - val_loss: 0.0024 - val_mae: 0.0057\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0023 - mae: 0.0053 - val_loss: 0.0023 - val_mae: 0.0055\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0023 - mae: 0.0054 - val_loss: 0.0023 - val_mae: 0.0052\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0023 - mae: 0.0055 - val_loss: 0.0023 - val_mae: 0.0047\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0022 - mae: 0.0053 - val_loss: 0.0022 - val_mae: 0.0057\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0022 - mae: 0.0054 - val_loss: 0.0022 - val_mae: 0.0066\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0022 - mae: 0.0054 - val_loss: 0.0022 - val_mae: 0.0053\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0022 - mae: 0.0055 - val_loss: 0.0022 - val_mae: 0.0059\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0021 - mae: 0.0052 - val_loss: 0.0022 - val_mae: 0.0082\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0053 - val_loss: 0.0021 - val_mae: 0.0059\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0052 - val_loss: 0.0021 - val_mae: 0.0053\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0054 - val_loss: 0.0020 - val_mae: 0.0050\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0051 - val_loss: 0.0020 - val_mae: 0.0052\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0051 - val_loss: 0.0020 - val_mae: 0.0050\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0053 - val_loss: 0.0019 - val_mae: 0.0048\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0050 - val_loss: 0.0019 - val_mae: 0.0051\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0052 - val_loss: 0.0019 - val_mae: 0.0050\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0051 - val_loss: 0.0019 - val_mae: 0.0051\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0052 - val_loss: 0.0018 - val_mae: 0.0046\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0052 - val_loss: 0.0019 - val_mae: 0.0072\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0050 - val_loss: 0.0018 - val_mae: 0.0055\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0018 - mae: 0.0051 - val_loss: 0.0018 - val_mae: 0.0053\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0052 - val_loss: 0.0018 - val_mae: 0.0049\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0052 - val_loss: 0.0017 - val_mae: 0.0063\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0051 - val_loss: 0.0017 - val_mae: 0.0051\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0049 - val_loss: 0.0017 - val_mae: 0.0052\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0051 - val_loss: 0.0017 - val_mae: 0.0052\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0050 - val_loss: 0.0016 - val_mae: 0.0050\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0050 - val_loss: 0.0016 - val_mae: 0.0060\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0052 - val_loss: 0.0016 - val_mae: 0.0055\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0050 - val_loss: 0.0016 - val_mae: 0.0048\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0050 - val_loss: 0.0016 - val_mae: 0.0051\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0050 - val_loss: 0.0016 - val_mae: 0.0055\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0052 - val_loss: 0.0015 - val_mae: 0.0048\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0049 - val_loss: 0.0015 - val_mae: 0.0056\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0050 - val_loss: 0.0015 - val_mae: 0.0054\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0049 - val_loss: 0.0015 - val_mae: 0.0047\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0049 - val_loss: 0.0014 - val_mae: 0.0046\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0051 - val_loss: 0.0014 - val_mae: 0.0050\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0052 - val_loss: 0.0014 - val_mae: 0.0047\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0048 - val_loss: 0.0014 - val_mae: 0.0054\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0048 - val_loss: 0.0014 - val_mae: 0.0046\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0049 - val_loss: 0.0014 - val_mae: 0.0045\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0052 - val_loss: 0.0014 - val_mae: 0.0050\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0049 - val_loss: 0.0013 - val_mae: 0.0046\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0049 - val_loss: 0.0013 - val_mae: 0.0053\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0049 - val_loss: 0.0013 - val_mae: 0.0046\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0048 - val_loss: 0.0013 - val_mae: 0.0059\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0048 - val_loss: 0.0013 - val_mae: 0.0059\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0048 - val_loss: 0.0013 - val_mae: 0.0048\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0048 - val_loss: 0.0013 - val_mae: 0.0065\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0049 - val_loss: 0.0012 - val_mae: 0.0054\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0050 - val_loss: 0.0012 - val_mae: 0.0043\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0048 - val_loss: 0.0012 - val_mae: 0.0058\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0049 - val_loss: 0.0012 - val_mae: 0.0065\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0048 - val_loss: 0.0012 - val_mae: 0.0042\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0048 - val_loss: 0.0012 - val_mae: 0.0044\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0049 - val_loss: 0.0012 - val_mae: 0.0051\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0048 - val_loss: 0.0012 - val_mae: 0.0054\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0049 - val_loss: 0.0011 - val_mae: 0.0047\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0047 - val_loss: 0.0011 - val_mae: 0.0044\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0047 - val_loss: 0.0011 - val_mae: 0.0049\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0047 - val_loss: 0.0011 - val_mae: 0.0053\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0050 - val_loss: 0.0011 - val_mae: 0.0045\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0046 - val_loss: 0.0011 - val_mae: 0.0053\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0048 - val_loss: 0.0011 - val_mae: 0.0044\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0047 - val_loss: 0.0010 - val_mae: 0.0042\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0048 - val_loss: 0.0010 - val_mae: 0.0049\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0047 - val_loss: 0.0011 - val_mae: 0.0067\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0050 - val_loss: 0.0010 - val_mae: 0.0046\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0046 - val_loss: 0.0010 - val_mae: 0.0044\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0047 - val_loss: 9.9903e-04 - val_mae: 0.0047\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.9375e-04 - mae: 0.0046 - val_loss: 9.8727e-04 - val_mae: 0.0045\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.8822e-04 - mae: 0.0049 - val_loss: 9.8159e-04 - val_mae: 0.0047\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.7476e-04 - mae: 0.0046 - val_loss: 9.7944e-04 - val_mae: 0.0051\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.6762e-04 - mae: 0.0048 - val_loss: 9.6188e-04 - val_mae: 0.0046\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.5810e-04 - mae: 0.0047 - val_loss: 9.5089e-04 - val_mae: 0.0045\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.4826e-04 - mae: 0.0046 - val_loss: 9.5363e-04 - val_mae: 0.0054\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.4000e-04 - mae: 0.0047 - val_loss: 9.4239e-04 - val_mae: 0.0051\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.3522e-04 - mae: 0.0049 - val_loss: 9.2684e-04 - val_mae: 0.0046\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.2094e-04 - mae: 0.0045 - val_loss: 9.1605e-04 - val_mae: 0.0045\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.1462e-04 - mae: 0.0047 - val_loss: 9.1961e-04 - val_mae: 0.0053\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.0486e-04 - mae: 0.0046 - val_loss: 9.1055e-04 - val_mae: 0.0052\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.9946e-04 - mae: 0.0047 - val_loss: 9.0592e-04 - val_mae: 0.0057\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.9132e-04 - mae: 0.0047 - val_loss: 8.8577e-04 - val_mae: 0.0045\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.8028e-04 - mae: 0.0045 - val_loss: 8.7274e-04 - val_mae: 0.0041\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.7522e-04 - mae: 0.0047 - val_loss: 8.6717e-04 - val_mae: 0.0043\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.6679e-04 - mae: 0.0046 - val_loss: 8.6401e-04 - val_mae: 0.0046\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.5772e-04 - mae: 0.0045 - val_loss: 8.5653e-04 - val_mae: 0.0048\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.5800e-04 - mae: 0.0050 - val_loss: 8.9274e-04 - val_mae: 0.0072\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.4248e-04 - mae: 0.0044 - val_loss: 8.3587e-04 - val_mae: 0.0042\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.3822e-04 - mae: 0.0046 - val_loss: 8.5469e-04 - val_mae: 0.0062\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.3023e-04 - mae: 0.0045 - val_loss: 8.2250e-04 - val_mae: 0.0042\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.2231e-04 - mae: 0.0045 - val_loss: 8.2111e-04 - val_mae: 0.0046\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.1608e-04 - mae: 0.0045 - val_loss: 8.0872e-04 - val_mae: 0.0041\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.1180e-04 - mae: 0.0047 - val_loss: 8.1394e-04 - val_mae: 0.0051\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 8.0223e-04 - mae: 0.0045 - val_loss: 7.9624e-04 - val_mae: 0.0042\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.9720e-04 - mae: 0.0046 - val_loss: 7.9214e-04 - val_mae: 0.0044\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.9048e-04 - mae: 0.0046 - val_loss: 7.8326e-04 - val_mae: 0.0041\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 7.8492e-04 - mae: 0.0046 - val_loss: 7.9019e-04 - val_mae: 0.0053\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.7654e-04 - mae: 0.0045 - val_loss: 7.7143e-04 - val_mae: 0.0042\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.6968e-04 - mae: 0.0044 - val_loss: 7.6705e-04 - val_mae: 0.0044\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.6492e-04 - mae: 0.0045 - val_loss: 7.6116e-04 - val_mae: 0.0043\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.6118e-04 - mae: 0.0047 - val_loss: 7.5784e-04 - val_mae: 0.0048\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.5166e-04 - mae: 0.0044 - val_loss: 7.6698e-04 - val_mae: 0.0054\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.4713e-04 - mae: 0.0045 - val_loss: 7.3947e-04 - val_mae: 0.0040\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.4253e-04 - mae: 0.0046 - val_loss: 7.3696e-04 - val_mae: 0.0043\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.3725e-04 - mae: 0.0046 - val_loss: 7.3615e-04 - val_mae: 0.0048\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.3271e-04 - mae: 0.0047 - val_loss: 7.2561e-04 - val_mae: 0.0044\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.2266e-04 - mae: 0.0043 - val_loss: 7.1862e-04 - val_mae: 0.0042\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.2052e-04 - mae: 0.0046 - val_loss: 7.1286e-04 - val_mae: 0.0041\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.1147e-04 - mae: 0.0043 - val_loss: 7.0763e-04 - val_mae: 0.0041\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.1054e-04 - mae: 0.0046 - val_loss: 7.0649e-04 - val_mae: 0.0045\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.0681e-04 - mae: 0.0047 - val_loss: 7.1768e-04 - val_mae: 0.0059\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.0005e-04 - mae: 0.0046 - val_loss: 6.9642e-04 - val_mae: 0.0043\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.9436e-04 - mae: 0.0045 - val_loss: 6.9603e-04 - val_mae: 0.0050\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.8989e-04 - mae: 0.0045 - val_loss: 6.8475e-04 - val_mae: 0.0043\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.8297e-04 - mae: 0.0044 - val_loss: 6.7602e-04 - val_mae: 0.0040\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.8070e-04 - mae: 0.0046 - val_loss: 6.7449e-04 - val_mae: 0.0043\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.7283e-04 - mae: 0.0044 - val_loss: 6.6774e-04 - val_mae: 0.0041\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.7103e-04 - mae: 0.0046 - val_loss: 6.6083e-04 - val_mae: 0.0039\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.6311e-04 - mae: 0.0043 - val_loss: 6.5742e-04 - val_mae: 0.0040\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.5969e-04 - mae: 0.0044 - val_loss: 6.5314e-04 - val_mae: 0.0040\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.5427e-04 - mae: 0.0044 - val_loss: 6.4946e-04 - val_mae: 0.0042\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.4990e-04 - mae: 0.0044 - val_loss: 6.4240e-04 - val_mae: 0.0039\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.4693e-04 - mae: 0.0045 - val_loss: 6.3987e-04 - val_mae: 0.0041\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.4700e-04 - mae: 0.0048 - val_loss: 6.4292e-04 - val_mae: 0.0047\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.3717e-04 - mae: 0.0044 - val_loss: 6.3589e-04 - val_mae: 0.0045\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.3386e-04 - mae: 0.0044 - val_loss: 6.2600e-04 - val_mae: 0.0039\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.2817e-04 - mae: 0.0043 - val_loss: 6.3265e-04 - val_mae: 0.0048\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.2734e-04 - mae: 0.0046 - val_loss: 6.2519e-04 - val_mae: 0.0043\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 6.2320e-04 - mae: 0.0045 - val_loss: 6.3233e-04 - val_mae: 0.0054\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.1707e-04 - mae: 0.0044 - val_loss: 6.0965e-04 - val_mae: 0.0039\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.1197e-04 - mae: 0.0043 - val_loss: 6.1040e-04 - val_mae: 0.0043\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.0858e-04 - mae: 0.0043 - val_loss: 6.1151e-04 - val_mae: 0.0048\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.0545e-04 - mae: 0.0044 - val_loss: 6.1084e-04 - val_mae: 0.0050\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.0148e-04 - mae: 0.0043 - val_loss: 5.9703e-04 - val_mae: 0.0041\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.9870e-04 - mae: 0.0044 - val_loss: 5.9717e-04 - val_mae: 0.0045\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.9443e-04 - mae: 0.0044 - val_loss: 5.9043e-04 - val_mae: 0.0042\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.9251e-04 - mae: 0.0045 - val_loss: 6.0566e-04 - val_mae: 0.0057\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.8673e-04 - mae: 0.0044 - val_loss: 6.0115e-04 - val_mae: 0.0054\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.8334e-04 - mae: 0.0044 - val_loss: 5.7847e-04 - val_mae: 0.0041\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.7870e-04 - mae: 0.0043 - val_loss: 5.8019e-04 - val_mae: 0.0044\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.7655e-04 - mae: 0.0044 - val_loss: 5.7349e-04 - val_mae: 0.0042\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.7489e-04 - mae: 0.0045 - val_loss: 5.6822e-04 - val_mae: 0.0041\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.7042e-04 - mae: 0.0044 - val_loss: 5.6665e-04 - val_mae: 0.0043\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.6484e-04 - mae: 0.0042 - val_loss: 5.8080e-04 - val_mae: 0.0058\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.6353e-04 - mae: 0.0044 - val_loss: 5.8124e-04 - val_mae: 0.0057\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.6162e-04 - mae: 0.0045 - val_loss: 5.6419e-04 - val_mae: 0.0047\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.5613e-04 - mae: 0.0043 - val_loss: 5.4936e-04 - val_mae: 0.0037\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.5125e-04 - mae: 0.0042 - val_loss: 5.5192e-04 - val_mae: 0.0044\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.4938e-04 - mae: 0.0043 - val_loss: 5.4493e-04 - val_mae: 0.0041\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.4795e-04 - mae: 0.0044 - val_loss: 5.4362e-04 - val_mae: 0.0042\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.4288e-04 - mae: 0.0042 - val_loss: 5.4348e-04 - val_mae: 0.0043\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.4036e-04 - mae: 0.0043 - val_loss: 5.3339e-04 - val_mae: 0.0037\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.3664e-04 - mae: 0.0042 - val_loss: 5.3652e-04 - val_mae: 0.0043\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.3646e-04 - mae: 0.0044 - val_loss: 5.2850e-04 - val_mae: 0.0039\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.3184e-04 - mae: 0.0043 - val_loss: 5.2523e-04 - val_mae: 0.0038\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.2933e-04 - mae: 0.0044 - val_loss: 5.2504e-04 - val_mae: 0.0041\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.2372e-04 - mae: 0.0042 - val_loss: 5.2131e-04 - val_mae: 0.0041\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.2504e-04 - mae: 0.0044 - val_loss: 5.1619e-04 - val_mae: 0.0038\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.2011e-04 - mae: 0.0043 - val_loss: 5.2318e-04 - val_mae: 0.0047\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.1679e-04 - mae: 0.0043 - val_loss: 5.2314e-04 - val_mae: 0.0049\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.1511e-04 - mae: 0.0043 - val_loss: 5.1163e-04 - val_mae: 0.0041\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.1136e-04 - mae: 0.0043 - val_loss: 5.3721e-04 - val_mae: 0.0058\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.0983e-04 - mae: 0.0043 - val_loss: 5.0625e-04 - val_mae: 0.0042\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.0730e-04 - mae: 0.0044 - val_loss: 5.2099e-04 - val_mae: 0.0056\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.0208e-04 - mae: 0.0042 - val_loss: 5.0185e-04 - val_mae: 0.0043\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.0150e-04 - mae: 0.0043 - val_loss: 4.9220e-04 - val_mae: 0.0037\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.9687e-04 - mae: 0.0042 - val_loss: 5.2108e-04 - val_mae: 0.0061\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.9595e-04 - mae: 0.0044 - val_loss: 5.0775e-04 - val_mae: 0.0054\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.9433e-04 - mae: 0.0044 - val_loss: 4.8511e-04 - val_mae: 0.0038\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.8878e-04 - mae: 0.0042 - val_loss: 4.9042e-04 - val_mae: 0.0046\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.8633e-04 - mae: 0.0042 - val_loss: 4.8430e-04 - val_mae: 0.0042\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.8857e-04 - mae: 0.0045 - val_loss: 4.7851e-04 - val_mae: 0.0038\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.8202e-04 - mae: 0.0042 - val_loss: 4.7851e-04 - val_mae: 0.0040\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.7789e-04 - mae: 0.0041 - val_loss: 4.8035e-04 - val_mae: 0.0043\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.7896e-04 - mae: 0.0043 - val_loss: 5.0098e-04 - val_mae: 0.0059\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.7467e-04 - mae: 0.0042 - val_loss: 4.6701e-04 - val_mae: 0.0036\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.7238e-04 - mae: 0.0042 - val_loss: 4.6788e-04 - val_mae: 0.0040\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.7309e-04 - mae: 0.0044 - val_loss: 4.6430e-04 - val_mae: 0.0038\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.6596e-04 - mae: 0.0040 - val_loss: 4.6536e-04 - val_mae: 0.0040\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.6795e-04 - mae: 0.0043 - val_loss: 4.5845e-04 - val_mae: 0.0036\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.6222e-04 - mae: 0.0041 - val_loss: 4.7363e-04 - val_mae: 0.0051\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.6102e-04 - mae: 0.0041 - val_loss: 4.5530e-04 - val_mae: 0.0038\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.6066e-04 - mae: 0.0043 - val_loss: 4.5273e-04 - val_mae: 0.0037\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.6314e-04 - mae: 0.0045 - val_loss: 4.5934e-04 - val_mae: 0.0045\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.5797e-04 - mae: 0.0043 - val_loss: 4.6357e-04 - val_mae: 0.0051\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.5249e-04 - mae: 0.0041 - val_loss: 4.4991e-04 - val_mae: 0.0039\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.5165e-04 - mae: 0.0042 - val_loss: 4.4538e-04 - val_mae: 0.0038\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.4615e-04 - mae: 0.0039 - val_loss: 4.4492e-04 - val_mae: 0.0038\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.4910e-04 - mae: 0.0043 - val_loss: 4.4815e-04 - val_mae: 0.0042\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.4408e-04 - mae: 0.0041 - val_loss: 4.4560e-04 - val_mae: 0.0042\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.4302e-04 - mae: 0.0041 - val_loss: 4.4564e-04 - val_mae: 0.0045\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.4264e-04 - mae: 0.0042 - val_loss: 4.3480e-04 - val_mae: 0.0037\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.3813e-04 - mae: 0.0041 - val_loss: 4.5638e-04 - val_mae: 0.0054\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.3631e-04 - mae: 0.0041 - val_loss: 4.3601e-04 - val_mae: 0.0039\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.3569e-04 - mae: 0.0041 - val_loss: 4.4572e-04 - val_mae: 0.0052\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.3325e-04 - mae: 0.0041 - val_loss: 4.3836e-04 - val_mae: 0.0045\n",
      "Epoch 307/1000\n",
      "268/270 [============================>.] - ETA: 0s - loss: 4.3134e-04 - mae: 0.0041Restoring model weights from the end of the best epoch: 302.\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.3134e-04 - mae: 0.0041 - val_loss: 4.3946e-04 - val_mae: 0.0049\n",
      "Epoch 307: early stopping\n",
      "Training für Fold 3...\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 5s 7ms/step - loss: 0.0311 - mae: 0.0794 - val_loss: 0.0233 - val_mae: 0.0494\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0204 - mae: 0.0391 - val_loss: 0.0185 - val_mae: 0.0317\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0174 - mae: 0.0269 - val_loss: 0.0166 - val_mae: 0.0240\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0160 - mae: 0.0204 - val_loss: 0.0155 - val_mae: 0.0191\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0151 - mae: 0.0173 - val_loss: 0.0146 - val_mae: 0.0150\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0144 - mae: 0.0148 - val_loss: 0.0141 - val_mae: 0.0139\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0139 - mae: 0.0135 - val_loss: 0.0136 - val_mae: 0.0120\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0134 - mae: 0.0120 - val_loss: 0.0132 - val_mae: 0.0109\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0130 - mae: 0.0107 - val_loss: 0.0128 - val_mae: 0.0103\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0127 - mae: 0.0108 - val_loss: 0.0125 - val_mae: 0.0106\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0123 - mae: 0.0100 - val_loss: 0.0122 - val_mae: 0.0104\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0120 - mae: 0.0091 - val_loss: 0.0118 - val_mae: 0.0090\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0117 - mae: 0.0089 - val_loss: 0.0115 - val_mae: 0.0083\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0114 - mae: 0.0088 - val_loss: 0.0112 - val_mae: 0.0079\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0111 - mae: 0.0084 - val_loss: 0.0110 - val_mae: 0.0091\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0108 - mae: 0.0083 - val_loss: 0.0107 - val_mae: 0.0088\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0105 - mae: 0.0079 - val_loss: 0.0104 - val_mae: 0.0087\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0103 - mae: 0.0080 - val_loss: 0.0102 - val_mae: 0.0076\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0101 - mae: 0.0084 - val_loss: 0.0099 - val_mae: 0.0090\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0098 - mae: 0.0075 - val_loss: 0.0097 - val_mae: 0.0072\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0096 - mae: 0.0079 - val_loss: 0.0095 - val_mae: 0.0083\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0094 - mae: 0.0076 - val_loss: 0.0093 - val_mae: 0.0086\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0091 - mae: 0.0073 - val_loss: 0.0091 - val_mae: 0.0088\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0089 - mae: 0.0076 - val_loss: 0.0088 - val_mae: 0.0066\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0087 - mae: 0.0072 - val_loss: 0.0086 - val_mae: 0.0062\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0086 - mae: 0.0076 - val_loss: 0.0084 - val_mae: 0.0065\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0084 - mae: 0.0074 - val_loss: 0.0083 - val_mae: 0.0074\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0082 - mae: 0.0067 - val_loss: 0.0081 - val_mae: 0.0075\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0080 - mae: 0.0069 - val_loss: 0.0080 - val_mae: 0.0073\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0079 - mae: 0.0068 - val_loss: 0.0078 - val_mae: 0.0063\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0077 - mae: 0.0064 - val_loss: 0.0076 - val_mae: 0.0077\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0075 - mae: 0.0067 - val_loss: 0.0075 - val_mae: 0.0066\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0074 - mae: 0.0070 - val_loss: 0.0074 - val_mae: 0.0081\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0072 - mae: 0.0065 - val_loss: 0.0073 - val_mae: 0.0103\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0071 - mae: 0.0065 - val_loss: 0.0070 - val_mae: 0.0058\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0070 - mae: 0.0064 - val_loss: 0.0071 - val_mae: 0.0129\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0068 - mae: 0.0067 - val_loss: 0.0068 - val_mae: 0.0058\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0067 - mae: 0.0066 - val_loss: 0.0067 - val_mae: 0.0069\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0066 - mae: 0.0066 - val_loss: 0.0065 - val_mae: 0.0060\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0065 - mae: 0.0062 - val_loss: 0.0064 - val_mae: 0.0066\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0064 - mae: 0.0064 - val_loss: 0.0063 - val_mae: 0.0064\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0062 - mae: 0.0065 - val_loss: 0.0062 - val_mae: 0.0065\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0061 - mae: 0.0063 - val_loss: 0.0061 - val_mae: 0.0055\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0060 - mae: 0.0065 - val_loss: 0.0060 - val_mae: 0.0055\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0059 - mae: 0.0060 - val_loss: 0.0059 - val_mae: 0.0054\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0058 - mae: 0.0059 - val_loss: 0.0058 - val_mae: 0.0059\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0057 - mae: 0.0064 - val_loss: 0.0057 - val_mae: 0.0065\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0056 - mae: 0.0058 - val_loss: 0.0056 - val_mae: 0.0058\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0055 - mae: 0.0059 - val_loss: 0.0055 - val_mae: 0.0055\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0054 - mae: 0.0060 - val_loss: 0.0054 - val_mae: 0.0068\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0054 - mae: 0.0058 - val_loss: 0.0053 - val_mae: 0.0053\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0053 - mae: 0.0058 - val_loss: 0.0052 - val_mae: 0.0068\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0052 - mae: 0.0059 - val_loss: 0.0052 - val_mae: 0.0074\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0051 - mae: 0.0059 - val_loss: 0.0050 - val_mae: 0.0060\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0050 - mae: 0.0061 - val_loss: 0.0050 - val_mae: 0.0055\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0049 - mae: 0.0059 - val_loss: 0.0049 - val_mae: 0.0057\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0048 - mae: 0.0058 - val_loss: 0.0048 - val_mae: 0.0054\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0048 - mae: 0.0057 - val_loss: 0.0047 - val_mae: 0.0053\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0047 - mae: 0.0057 - val_loss: 0.0047 - val_mae: 0.0063\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0046 - mae: 0.0059 - val_loss: 0.0046 - val_mae: 0.0056\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0045 - mae: 0.0059 - val_loss: 0.0045 - val_mae: 0.0056\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0045 - mae: 0.0061 - val_loss: 0.0044 - val_mae: 0.0048\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0044 - mae: 0.0058 - val_loss: 0.0044 - val_mae: 0.0060\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0043 - mae: 0.0057 - val_loss: 0.0043 - val_mae: 0.0050\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0043 - mae: 0.0055 - val_loss: 0.0042 - val_mae: 0.0048\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0042 - mae: 0.0056 - val_loss: 0.0042 - val_mae: 0.0054\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0042 - mae: 0.0063 - val_loss: 0.0041 - val_mae: 0.0065\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0041 - mae: 0.0055 - val_loss: 0.0040 - val_mae: 0.0050\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0040 - mae: 0.0055 - val_loss: 0.0040 - val_mae: 0.0050\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0040 - mae: 0.0056 - val_loss: 0.0039 - val_mae: 0.0060\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0039 - mae: 0.0054 - val_loss: 0.0039 - val_mae: 0.0069\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0038 - mae: 0.0054 - val_loss: 0.0038 - val_mae: 0.0056\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0038 - mae: 0.0055 - val_loss: 0.0038 - val_mae: 0.0069\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0037 - mae: 0.0057 - val_loss: 0.0037 - val_mae: 0.0052\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0037 - mae: 0.0054 - val_loss: 0.0036 - val_mae: 0.0051\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0036 - mae: 0.0053 - val_loss: 0.0036 - val_mae: 0.0073\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0036 - mae: 0.0055 - val_loss: 0.0035 - val_mae: 0.0055\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0035 - mae: 0.0055 - val_loss: 0.0035 - val_mae: 0.0071\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0035 - mae: 0.0052 - val_loss: 0.0034 - val_mae: 0.0046\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0034 - mae: 0.0053 - val_loss: 0.0034 - val_mae: 0.0056\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0034 - mae: 0.0055 - val_loss: 0.0034 - val_mae: 0.0071\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0033 - mae: 0.0053 - val_loss: 0.0033 - val_mae: 0.0052\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0033 - mae: 0.0052 - val_loss: 0.0032 - val_mae: 0.0045\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0032 - mae: 0.0053 - val_loss: 0.0032 - val_mae: 0.0046\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0032 - mae: 0.0052 - val_loss: 0.0031 - val_mae: 0.0047\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0031 - mae: 0.0052 - val_loss: 0.0031 - val_mae: 0.0050\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0031 - mae: 0.0055 - val_loss: 0.0030 - val_mae: 0.0049\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0030 - mae: 0.0053 - val_loss: 0.0030 - val_mae: 0.0060\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0030 - mae: 0.0051 - val_loss: 0.0030 - val_mae: 0.0051\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0029 - mae: 0.0052 - val_loss: 0.0029 - val_mae: 0.0053\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0029 - mae: 0.0052 - val_loss: 0.0029 - val_mae: 0.0057\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0029 - mae: 0.0049 - val_loss: 0.0028 - val_mae: 0.0046\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0028 - mae: 0.0052 - val_loss: 0.0028 - val_mae: 0.0051\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0028 - mae: 0.0052 - val_loss: 0.0028 - val_mae: 0.0052\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0027 - mae: 0.0052 - val_loss: 0.0027 - val_mae: 0.0052\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0027 - mae: 0.0051 - val_loss: 0.0027 - val_mae: 0.0047\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0027 - mae: 0.0051 - val_loss: 0.0026 - val_mae: 0.0050\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0026 - mae: 0.0052 - val_loss: 0.0026 - val_mae: 0.0054\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0026 - mae: 0.0049 - val_loss: 0.0026 - val_mae: 0.0044\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0026 - mae: 0.0053 - val_loss: 0.0025 - val_mae: 0.0048\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0049 - val_loss: 0.0025 - val_mae: 0.0047\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0050 - val_loss: 0.0025 - val_mae: 0.0049\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0024 - mae: 0.0049 - val_loss: 0.0024 - val_mae: 0.0055\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0024 - mae: 0.0051 - val_loss: 0.0024 - val_mae: 0.0056\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0024 - mae: 0.0053 - val_loss: 0.0024 - val_mae: 0.0053\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0023 - mae: 0.0049 - val_loss: 0.0023 - val_mae: 0.0060\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0023 - mae: 0.0049 - val_loss: 0.0023 - val_mae: 0.0045\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0023 - mae: 0.0050 - val_loss: 0.0023 - val_mae: 0.0055\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0023 - mae: 0.0050 - val_loss: 0.0022 - val_mae: 0.0048\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0022 - mae: 0.0048 - val_loss: 0.0022 - val_mae: 0.0045\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0022 - mae: 0.0047 - val_loss: 0.0022 - val_mae: 0.0049\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0022 - mae: 0.0051 - val_loss: 0.0022 - val_mae: 0.0051\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0021 - mae: 0.0047 - val_loss: 0.0021 - val_mae: 0.0043\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0021 - mae: 0.0048 - val_loss: 0.0021 - val_mae: 0.0047\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0021 - mae: 0.0051 - val_loss: 0.0021 - val_mae: 0.0051\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0021 - mae: 0.0047 - val_loss: 0.0020 - val_mae: 0.0045\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0020 - mae: 0.0048 - val_loss: 0.0020 - val_mae: 0.0044\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0020 - mae: 0.0050 - val_loss: 0.0020 - val_mae: 0.0046\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0020 - mae: 0.0047 - val_loss: 0.0020 - val_mae: 0.0045\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0019 - mae: 0.0048 - val_loss: 0.0019 - val_mae: 0.0056\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0019 - mae: 0.0050 - val_loss: 0.0019 - val_mae: 0.0041\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0019 - mae: 0.0047 - val_loss: 0.0019 - val_mae: 0.0048\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0019 - mae: 0.0047 - val_loss: 0.0019 - val_mae: 0.0050\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0018 - mae: 0.0047 - val_loss: 0.0018 - val_mae: 0.0044\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0018 - mae: 0.0046 - val_loss: 0.0018 - val_mae: 0.0065\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0018 - mae: 0.0049 - val_loss: 0.0018 - val_mae: 0.0044\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0018 - mae: 0.0047 - val_loss: 0.0018 - val_mae: 0.0061\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0018 - mae: 0.0046 - val_loss: 0.0017 - val_mae: 0.0041\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0017 - mae: 0.0047 - val_loss: 0.0017 - val_mae: 0.0041\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0017 - mae: 0.0046 - val_loss: 0.0017 - val_mae: 0.0042\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0017 - mae: 0.0044 - val_loss: 0.0017 - val_mae: 0.0042\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0017 - mae: 0.0045 - val_loss: 0.0016 - val_mae: 0.0040\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0016 - mae: 0.0048 - val_loss: 0.0016 - val_mae: 0.0043\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0016 - mae: 0.0048 - val_loss: 0.0016 - val_mae: 0.0052\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0047 - val_loss: 0.0016 - val_mae: 0.0043\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0016 - mae: 0.0046 - val_loss: 0.0016 - val_mae: 0.0045\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0016 - mae: 0.0047 - val_loss: 0.0016 - val_mae: 0.0056\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0041\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0043\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0040\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0044\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0015 - mae: 0.0048 - val_loss: 0.0015 - val_mae: 0.0042\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0015 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0047\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0049\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0014 - mae: 0.0046 - val_loss: 0.0014 - val_mae: 0.0047\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0014 - mae: 0.0048 - val_loss: 0.0014 - val_mae: 0.0051\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0014 - mae: 0.0047 - val_loss: 0.0014 - val_mae: 0.0042\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0014 - mae: 0.0048 - val_loss: 0.0014 - val_mae: 0.0046\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0014 - mae: 0.0047 - val_loss: 0.0014 - val_mae: 0.0044\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0043\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0013 - mae: 0.0046 - val_loss: 0.0013 - val_mae: 0.0043\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0013 - mae: 0.0048 - val_loss: 0.0013 - val_mae: 0.0040\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0013 - mae: 0.0046 - val_loss: 0.0013 - val_mae: 0.0040\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0041\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0049\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0045\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0013 - mae: 0.0048 - val_loss: 0.0012 - val_mae: 0.0044\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0048\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0046 - val_loss: 0.0012 - val_mae: 0.0039\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0045 - val_loss: 0.0012 - val_mae: 0.0042\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0046 - val_loss: 0.0012 - val_mae: 0.0040\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0045 - val_loss: 0.0012 - val_mae: 0.0040\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0047 - val_loss: 0.0012 - val_mae: 0.0041\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0051\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0044 - val_loss: 0.0011 - val_mae: 0.0043\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0045 - val_loss: 0.0011 - val_mae: 0.0045\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0044 - val_loss: 0.0011 - val_mae: 0.0039\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0046 - val_loss: 0.0011 - val_mae: 0.0051\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0045 - val_loss: 0.0011 - val_mae: 0.0042\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0045 - val_loss: 0.0011 - val_mae: 0.0041\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0046 - val_loss: 0.0011 - val_mae: 0.0040\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0047 - val_loss: 0.0011 - val_mae: 0.0043\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0010 - mae: 0.0044 - val_loss: 0.0010 - val_mae: 0.0049\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0010 - mae: 0.0046 - val_loss: 0.0010 - val_mae: 0.0039\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0045 - val_loss: 0.0010 - val_mae: 0.0042\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0010 - mae: 0.0043 - val_loss: 0.0010 - val_mae: 0.0043\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0010 - mae: 0.0045 - val_loss: 0.0010 - val_mae: 0.0050\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.9695e-04 - mae: 0.0045 - val_loss: 9.8415e-04 - val_mae: 0.0039\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.8725e-04 - mae: 0.0045 - val_loss: 9.9354e-04 - val_mae: 0.0054\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.7868e-04 - mae: 0.0046 - val_loss: 9.6988e-04 - val_mae: 0.0043\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.6557e-04 - mae: 0.0043 - val_loss: 9.7486e-04 - val_mae: 0.0056\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.6081e-04 - mae: 0.0047 - val_loss: 9.4462e-04 - val_mae: 0.0038\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.4728e-04 - mae: 0.0044 - val_loss: 9.4150e-04 - val_mae: 0.0043\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.4150e-04 - mae: 0.0046 - val_loss: 9.3917e-04 - val_mae: 0.0048\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.3323e-04 - mae: 0.0046 - val_loss: 9.1825e-04 - val_mae: 0.0038\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.2354e-04 - mae: 0.0045 - val_loss: 9.1661e-04 - val_mae: 0.0045\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.1432e-04 - mae: 0.0045 - val_loss: 9.0513e-04 - val_mae: 0.0041\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.0272e-04 - mae: 0.0043 - val_loss: 9.0060e-04 - val_mae: 0.0045\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.9579e-04 - mae: 0.0044 - val_loss: 8.8372e-04 - val_mae: 0.0037\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.8921e-04 - mae: 0.0045 - val_loss: 8.8013e-04 - val_mae: 0.0041\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.8113e-04 - mae: 0.0045 - val_loss: 8.7535e-04 - val_mae: 0.0045\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.7122e-04 - mae: 0.0043 - val_loss: 8.5965e-04 - val_mae: 0.0038\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.6701e-04 - mae: 0.0046 - val_loss: 8.5765e-04 - val_mae: 0.0043\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.5574e-04 - mae: 0.0043 - val_loss: 8.4806e-04 - val_mae: 0.0040\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 8.5005e-04 - mae: 0.0045 - val_loss: 8.4082e-04 - val_mae: 0.0041\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 8.4371e-04 - mae: 0.0046 - val_loss: 8.3083e-04 - val_mae: 0.0039\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 8.3180e-04 - mae: 0.0042 - val_loss: 8.2714e-04 - val_mae: 0.0041\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 8.2978e-04 - mae: 0.0046 - val_loss: 8.2290e-04 - val_mae: 0.0043\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 2s 8ms/step - loss: 8.1569e-04 - mae: 0.0041 - val_loss: 8.1419e-04 - val_mae: 0.0043\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 8.1059e-04 - mae: 0.0043 - val_loss: 8.0425e-04 - val_mae: 0.0040\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 8.0482e-04 - mae: 0.0044 - val_loss: 8.0120e-04 - val_mae: 0.0044\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.9631e-04 - mae: 0.0043 - val_loss: 7.9083e-04 - val_mae: 0.0042\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.9232e-04 - mae: 0.0045 - val_loss: 7.9096e-04 - val_mae: 0.0046\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.8431e-04 - mae: 0.0044 - val_loss: 7.8022e-04 - val_mae: 0.0043\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.7736e-04 - mae: 0.0044 - val_loss: 7.8068e-04 - val_mae: 0.0050\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.7127e-04 - mae: 0.0044 - val_loss: 7.7557e-04 - val_mae: 0.0048\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 7.6531e-04 - mae: 0.0044 - val_loss: 7.6152e-04 - val_mae: 0.0044\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.5718e-04 - mae: 0.0043 - val_loss: 7.4876e-04 - val_mae: 0.0040\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.5378e-04 - mae: 0.0045 - val_loss: 7.4275e-04 - val_mae: 0.0039\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.4457e-04 - mae: 0.0043 - val_loss: 7.5734e-04 - val_mae: 0.0052\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.4009e-04 - mae: 0.0043 - val_loss: 7.4394e-04 - val_mae: 0.0047\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.3597e-04 - mae: 0.0045 - val_loss: 7.2887e-04 - val_mae: 0.0041\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.2826e-04 - mae: 0.0043 - val_loss: 7.2195e-04 - val_mae: 0.0041\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.2400e-04 - mae: 0.0044 - val_loss: 7.1619e-04 - val_mae: 0.0041\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.1642e-04 - mae: 0.0043 - val_loss: 7.1873e-04 - val_mae: 0.0046\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.1066e-04 - mae: 0.0042 - val_loss: 7.1231e-04 - val_mae: 0.0045\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.0466e-04 - mae: 0.0042 - val_loss: 7.0205e-04 - val_mae: 0.0043\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.0244e-04 - mae: 0.0044 - val_loss: 6.9236e-04 - val_mae: 0.0039\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.9669e-04 - mae: 0.0044 - val_loss: 6.8558e-04 - val_mae: 0.0037\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.9070e-04 - mae: 0.0043 - val_loss: 7.0086e-04 - val_mae: 0.0053\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.8456e-04 - mae: 0.0043 - val_loss: 6.8391e-04 - val_mae: 0.0045\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.7809e-04 - mae: 0.0042 - val_loss: 6.7234e-04 - val_mae: 0.0039\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.7442e-04 - mae: 0.0043 - val_loss: 6.7565e-04 - val_mae: 0.0047\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.6836e-04 - mae: 0.0042 - val_loss: 6.6948e-04 - val_mae: 0.0045\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.6403e-04 - mae: 0.0043 - val_loss: 6.5967e-04 - val_mae: 0.0041\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.5986e-04 - mae: 0.0043 - val_loss: 6.5467e-04 - val_mae: 0.0042\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.5414e-04 - mae: 0.0042 - val_loss: 6.4513e-04 - val_mae: 0.0037\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.5294e-04 - mae: 0.0045 - val_loss: 6.4706e-04 - val_mae: 0.0042\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.4465e-04 - mae: 0.0042 - val_loss: 6.3708e-04 - val_mae: 0.0038\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.4498e-04 - mae: 0.0045 - val_loss: 6.3270e-04 - val_mae: 0.0038\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.3452e-04 - mae: 0.0041 - val_loss: 6.2824e-04 - val_mae: 0.0038\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.2994e-04 - mae: 0.0041 - val_loss: 6.4078e-04 - val_mae: 0.0052\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.2823e-04 - mae: 0.0043 - val_loss: 6.2763e-04 - val_mae: 0.0045\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.2313e-04 - mae: 0.0043 - val_loss: 6.2304e-04 - val_mae: 0.0044\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.1820e-04 - mae: 0.0042 - val_loss: 6.1598e-04 - val_mae: 0.0042\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.1453e-04 - mae: 0.0043 - val_loss: 6.1801e-04 - val_mae: 0.0047\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.1297e-04 - mae: 0.0044 - val_loss: 6.0692e-04 - val_mae: 0.0042\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.0776e-04 - mae: 0.0043 - val_loss: 6.0147e-04 - val_mae: 0.0041\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.0084e-04 - mae: 0.0041 - val_loss: 6.0010e-04 - val_mae: 0.0043\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.9656e-04 - mae: 0.0041 - val_loss: 5.8897e-04 - val_mae: 0.0037\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.9534e-04 - mae: 0.0043 - val_loss: 6.0327e-04 - val_mae: 0.0050\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.9109e-04 - mae: 0.0043 - val_loss: 5.9343e-04 - val_mae: 0.0048\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 5.8664e-04 - mae: 0.0043 - val_loss: 6.0296e-04 - val_mae: 0.0056\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.8331e-04 - mae: 0.0043 - val_loss: 5.7935e-04 - val_mae: 0.0041\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.7799e-04 - mae: 0.0042 - val_loss: 5.7821e-04 - val_mae: 0.0045\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.7473e-04 - mae: 0.0042 - val_loss: 5.7046e-04 - val_mae: 0.0040\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.7357e-04 - mae: 0.0044 - val_loss: 5.7072e-04 - val_mae: 0.0044\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.6890e-04 - mae: 0.0043 - val_loss: 5.5870e-04 - val_mae: 0.0036\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.6272e-04 - mae: 0.0041 - val_loss: 5.5610e-04 - val_mae: 0.0037\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.6045e-04 - mae: 0.0042 - val_loss: 5.5959e-04 - val_mae: 0.0042\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.5690e-04 - mae: 0.0042 - val_loss: 5.5039e-04 - val_mae: 0.0038\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.5333e-04 - mae: 0.0042 - val_loss: 5.4694e-04 - val_mae: 0.0039\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.5121e-04 - mae: 0.0043 - val_loss: 5.6658e-04 - val_mae: 0.0058\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.4723e-04 - mae: 0.0042 - val_loss: 5.4154e-04 - val_mae: 0.0039\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.4414e-04 - mae: 0.0042 - val_loss: 5.3887e-04 - val_mae: 0.0039\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.3967e-04 - mae: 0.0041 - val_loss: 5.3898e-04 - val_mae: 0.0042\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.3680e-04 - mae: 0.0042 - val_loss: 5.2977e-04 - val_mae: 0.0037\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.3344e-04 - mae: 0.0041 - val_loss: 5.3203e-04 - val_mae: 0.0042\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.3296e-04 - mae: 0.0044 - val_loss: 5.2604e-04 - val_mae: 0.0039\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.2979e-04 - mae: 0.0043 - val_loss: 5.2334e-04 - val_mae: 0.0039\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.2351e-04 - mae: 0.0041 - val_loss: 5.2250e-04 - val_mae: 0.0042\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.1984e-04 - mae: 0.0040 - val_loss: 5.2694e-04 - val_mae: 0.0047\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.1864e-04 - mae: 0.0042 - val_loss: 5.1901e-04 - val_mae: 0.0045\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.1643e-04 - mae: 0.0042 - val_loss: 5.1084e-04 - val_mae: 0.0039\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.1236e-04 - mae: 0.0041 - val_loss: 5.1202e-04 - val_mae: 0.0042\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.0915e-04 - mae: 0.0041 - val_loss: 5.0406e-04 - val_mae: 0.0039\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.0675e-04 - mae: 0.0041 - val_loss: 5.0455e-04 - val_mae: 0.0041\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.0297e-04 - mae: 0.0041 - val_loss: 4.9967e-04 - val_mae: 0.0039\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.0217e-04 - mae: 0.0043 - val_loss: 5.1013e-04 - val_mae: 0.0047\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.0090e-04 - mae: 0.0043 - val_loss: 4.9381e-04 - val_mae: 0.0038\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.9516e-04 - mae: 0.0041 - val_loss: 4.9115e-04 - val_mae: 0.0038\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.9347e-04 - mae: 0.0042 - val_loss: 4.8577e-04 - val_mae: 0.0037\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.8910e-04 - mae: 0.0040 - val_loss: 4.9122e-04 - val_mae: 0.0044\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.8555e-04 - mae: 0.0040 - val_loss: 4.8580e-04 - val_mae: 0.0042\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.8871e-04 - mae: 0.0044 - val_loss: 4.7770e-04 - val_mae: 0.0036\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.8486e-04 - mae: 0.0043 - val_loss: 4.8119e-04 - val_mae: 0.0041\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.8002e-04 - mae: 0.0041 - val_loss: 4.7341e-04 - val_mae: 0.0037\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.7770e-04 - mae: 0.0041 - val_loss: 4.8250e-04 - val_mae: 0.0044\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.7629e-04 - mae: 0.0042 - val_loss: 4.7043e-04 - val_mae: 0.0039\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.7185e-04 - mae: 0.0041 - val_loss: 4.7073e-04 - val_mae: 0.0042\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.7030e-04 - mae: 0.0041 - val_loss: 4.6880e-04 - val_mae: 0.0042\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.6714e-04 - mae: 0.0041 - val_loss: 4.6028e-04 - val_mae: 0.0036\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.6645e-04 - mae: 0.0042 - val_loss: 4.6108e-04 - val_mae: 0.0039\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.6134e-04 - mae: 0.0040 - val_loss: 4.5746e-04 - val_mae: 0.0038\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.6092e-04 - mae: 0.0041 - val_loss: 4.5585e-04 - val_mae: 0.0038\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.5991e-04 - mae: 0.0042 - val_loss: 4.5493e-04 - val_mae: 0.0040\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.5991e-04 - mae: 0.0044 - val_loss: 4.5795e-04 - val_mae: 0.0045\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.5674e-04 - mae: 0.0043 - val_loss: 4.5016e-04 - val_mae: 0.0039\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.5117e-04 - mae: 0.0040 - val_loss: 4.4484e-04 - val_mae: 0.0036\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.5016e-04 - mae: 0.0041 - val_loss: 4.5289e-04 - val_mae: 0.0044\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.4843e-04 - mae: 0.0041 - val_loss: 4.4184e-04 - val_mae: 0.0037\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.4532e-04 - mae: 0.0041 - val_loss: 4.4143e-04 - val_mae: 0.0039\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.4310e-04 - mae: 0.0040 - val_loss: 4.4284e-04 - val_mae: 0.0042\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.4160e-04 - mae: 0.0041 - val_loss: 4.4374e-04 - val_mae: 0.0044\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.4011e-04 - mae: 0.0041 - val_loss: 4.3410e-04 - val_mae: 0.0037\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.3752e-04 - mae: 0.0041 - val_loss: 4.3621e-04 - val_mae: 0.0041\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.3500e-04 - mae: 0.0041 - val_loss: 4.2805e-04 - val_mae: 0.0036\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.3259e-04 - mae: 0.0040 - val_loss: 4.2612e-04 - val_mae: 0.0036\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.3241e-04 - mae: 0.0042 - val_loss: 4.2914e-04 - val_mae: 0.0041\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.2941e-04 - mae: 0.0041 - val_loss: 4.2243e-04 - val_mae: 0.0036\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.2590e-04 - mae: 0.0040 - val_loss: 4.2424e-04 - val_mae: 0.0040\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.2558e-04 - mae: 0.0041 - val_loss: 4.1955e-04 - val_mae: 0.0037\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.2276e-04 - mae: 0.0040 - val_loss: 4.1721e-04 - val_mae: 0.0036\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.2052e-04 - mae: 0.0040 - val_loss: 4.1782e-04 - val_mae: 0.0039\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.2000e-04 - mae: 0.0041 - val_loss: 4.2028e-04 - val_mae: 0.0041\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.1511e-04 - mae: 0.0039 - val_loss: 4.1539e-04 - val_mae: 0.0041\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.1600e-04 - mae: 0.0041 - val_loss: 4.1516e-04 - val_mae: 0.0041\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.1281e-04 - mae: 0.0040 - val_loss: 4.0623e-04 - val_mae: 0.0036\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.1215e-04 - mae: 0.0041 - val_loss: 4.0537e-04 - val_mae: 0.0037\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.1042e-04 - mae: 0.0041 - val_loss: 4.1888e-04 - val_mae: 0.0049\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.0819e-04 - mae: 0.0041 - val_loss: 4.0225e-04 - val_mae: 0.0037\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.0591e-04 - mae: 0.0040 - val_loss: 4.0039e-04 - val_mae: 0.0036\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.0451e-04 - mae: 0.0041 - val_loss: 4.0271e-04 - val_mae: 0.0040\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.0209e-04 - mae: 0.0040 - val_loss: 3.9776e-04 - val_mae: 0.0038\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.0096e-04 - mae: 0.0041 - val_loss: 3.9744e-04 - val_mae: 0.0040\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.9892e-04 - mae: 0.0040 - val_loss: 3.9544e-04 - val_mae: 0.0039\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.9635e-04 - mae: 0.0040 - val_loss: 3.9723e-04 - val_mae: 0.0042\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.9674e-04 - mae: 0.0041 - val_loss: 3.9490e-04 - val_mae: 0.0041\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.9389e-04 - mae: 0.0040 - val_loss: 3.9199e-04 - val_mae: 0.0039\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.9230e-04 - mae: 0.0041 - val_loss: 4.0845e-04 - val_mae: 0.0053\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.9224e-04 - mae: 0.0042 - val_loss: 3.8760e-04 - val_mae: 0.0038\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.8736e-04 - mae: 0.0039 - val_loss: 3.8347e-04 - val_mae: 0.0036\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.8729e-04 - mae: 0.0040 - val_loss: 3.9715e-04 - val_mae: 0.0049\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.8633e-04 - mae: 0.0041 - val_loss: 4.0254e-04 - val_mae: 0.0055\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.8414e-04 - mae: 0.0041 - val_loss: 3.7592e-04 - val_mae: 0.0035\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.8009e-04 - mae: 0.0039 - val_loss: 3.7844e-04 - val_mae: 0.0038\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.7969e-04 - mae: 0.0040 - val_loss: 3.7399e-04 - val_mae: 0.0034\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.7871e-04 - mae: 0.0040 - val_loss: 3.7253e-04 - val_mae: 0.0035\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.7524e-04 - mae: 0.0039 - val_loss: 3.7049e-04 - val_mae: 0.0036\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.7354e-04 - mae: 0.0039 - val_loss: 3.6847e-04 - val_mae: 0.0035\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.7424e-04 - mae: 0.0041 - val_loss: 3.8308e-04 - val_mae: 0.0048\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.7209e-04 - mae: 0.0040 - val_loss: 3.6611e-04 - val_mae: 0.0036\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.6983e-04 - mae: 0.0040 - val_loss: 3.6711e-04 - val_mae: 0.0039\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.6821e-04 - mae: 0.0039 - val_loss: 3.8220e-04 - val_mae: 0.0055\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.6588e-04 - mae: 0.0039 - val_loss: 3.6355e-04 - val_mae: 0.0038\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.6348e-04 - mae: 0.0038 - val_loss: 3.5955e-04 - val_mae: 0.0034\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.6507e-04 - mae: 0.0041 - val_loss: 3.5791e-04 - val_mae: 0.0035\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.6265e-04 - mae: 0.0040 - val_loss: 3.7003e-04 - val_mae: 0.0048\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.6006e-04 - mae: 0.0039 - val_loss: 3.6092e-04 - val_mae: 0.0040\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.5943e-04 - mae: 0.0039 - val_loss: 3.9087e-04 - val_mae: 0.0065\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.5873e-04 - mae: 0.0040 - val_loss: 3.5229e-04 - val_mae: 0.0035\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.5764e-04 - mae: 0.0040 - val_loss: 3.5763e-04 - val_mae: 0.0042\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.5374e-04 - mae: 0.0038 - val_loss: 3.5005e-04 - val_mae: 0.0035\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.5313e-04 - mae: 0.0039 - val_loss: 3.5035e-04 - val_mae: 0.0037\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.5269e-04 - mae: 0.0039 - val_loss: 3.4954e-04 - val_mae: 0.0037\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.5136e-04 - mae: 0.0040 - val_loss: 3.4546e-04 - val_mae: 0.0036\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.5096e-04 - mae: 0.0040 - val_loss: 3.4623e-04 - val_mae: 0.0037\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.4736e-04 - mae: 0.0038 - val_loss: 3.5041e-04 - val_mae: 0.0041\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.4827e-04 - mae: 0.0040 - val_loss: 3.4265e-04 - val_mae: 0.0035\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.4567e-04 - mae: 0.0039 - val_loss: 3.4305e-04 - val_mae: 0.0037\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.4616e-04 - mae: 0.0040 - val_loss: 3.3802e-04 - val_mae: 0.0034\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.4380e-04 - mae: 0.0039 - val_loss: 3.4492e-04 - val_mae: 0.0041\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.4151e-04 - mae: 0.0038 - val_loss: 3.3528e-04 - val_mae: 0.0033\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.3942e-04 - mae: 0.0038 - val_loss: 3.3535e-04 - val_mae: 0.0034\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.3992e-04 - mae: 0.0039 - val_loss: 3.3643e-04 - val_mae: 0.0037\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.3687e-04 - mae: 0.0038 - val_loss: 3.3850e-04 - val_mae: 0.0040\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.3718e-04 - mae: 0.0039 - val_loss: 3.3335e-04 - val_mae: 0.0036\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.3507e-04 - mae: 0.0038 - val_loss: 3.3486e-04 - val_mae: 0.0040\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.3363e-04 - mae: 0.0038 - val_loss: 3.3072e-04 - val_mae: 0.0036\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.3395e-04 - mae: 0.0039 - val_loss: 3.2810e-04 - val_mae: 0.0034\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.3324e-04 - mae: 0.0040 - val_loss: 3.4222e-04 - val_mae: 0.0048\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.3129e-04 - mae: 0.0039 - val_loss: 3.2521e-04 - val_mae: 0.0034\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.3012e-04 - mae: 0.0039 - val_loss: 3.2917e-04 - val_mae: 0.0037\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.3234e-04 - mae: 0.0042 - val_loss: 3.3277e-04 - val_mae: 0.0043\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.2911e-04 - mae: 0.0040 - val_loss: 3.2342e-04 - val_mae: 0.0036\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.2579e-04 - mae: 0.0038 - val_loss: 3.3076e-04 - val_mae: 0.0043\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.2520e-04 - mae: 0.0038 - val_loss: 3.2117e-04 - val_mae: 0.0035\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.2280e-04 - mae: 0.0037 - val_loss: 3.2146e-04 - val_mae: 0.0037\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.2265e-04 - mae: 0.0038 - val_loss: 3.2018e-04 - val_mae: 0.0036\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.2537e-04 - mae: 0.0041 - val_loss: 3.1822e-04 - val_mae: 0.0035\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.2315e-04 - mae: 0.0040 - val_loss: 3.2198e-04 - val_mae: 0.0040\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.2194e-04 - mae: 0.0040 - val_loss: 3.1716e-04 - val_mae: 0.0036\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.1968e-04 - mae: 0.0039 - val_loss: 3.1899e-04 - val_mae: 0.0039\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.1925e-04 - mae: 0.0040 - val_loss: 3.1343e-04 - val_mae: 0.0036\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.1749e-04 - mae: 0.0039 - val_loss: 3.1506e-04 - val_mae: 0.0037\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.1518e-04 - mae: 0.0038 - val_loss: 3.1282e-04 - val_mae: 0.0037\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.1975e-04 - mae: 0.0042 - val_loss: 3.1356e-04 - val_mae: 0.0038\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.1546e-04 - mae: 0.0039 - val_loss: 3.1091e-04 - val_mae: 0.0036\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 3.1353e-04 - mae: 0.0039 - val_loss: 3.0767e-04 - val_mae: 0.0034\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 3.1277e-04 - mae: 0.0039 - val_loss: 3.1217e-04 - val_mae: 0.0038\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 3.1062e-04 - mae: 0.0038 - val_loss: 3.0637e-04 - val_mae: 0.0035\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.1104e-04 - mae: 0.0039 - val_loss: 3.0794e-04 - val_mae: 0.0037\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.1069e-04 - mae: 0.0039 - val_loss: 3.0690e-04 - val_mae: 0.0037\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.0853e-04 - mae: 0.0038 - val_loss: 3.1308e-04 - val_mae: 0.0044\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.0663e-04 - mae: 0.0037 - val_loss: 3.0258e-04 - val_mae: 0.0034\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 3.0799e-04 - mae: 0.0039 - val_loss: 3.0300e-04 - val_mae: 0.0035\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 3.0645e-04 - mae: 0.0039 - val_loss: 3.0314e-04 - val_mae: 0.0036\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 3.0539e-04 - mae: 0.0039 - val_loss: 3.0820e-04 - val_mae: 0.0041\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.0361e-04 - mae: 0.0038 - val_loss: 2.9919e-04 - val_mae: 0.0035\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 3.0477e-04 - mae: 0.0040 - val_loss: 3.0106e-04 - val_mae: 0.0037\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.0224e-04 - mae: 0.0038 - val_loss: 3.0507e-04 - val_mae: 0.0042\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.0080e-04 - mae: 0.0038 - val_loss: 2.9941e-04 - val_mae: 0.0037\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.0076e-04 - mae: 0.0039 - val_loss: 2.9750e-04 - val_mae: 0.0036\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.9950e-04 - mae: 0.0038 - val_loss: 3.0740e-04 - val_mae: 0.0045\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.0014e-04 - mae: 0.0039 - val_loss: 3.0128e-04 - val_mae: 0.0041\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.9655e-04 - mae: 0.0037 - val_loss: 2.9468e-04 - val_mae: 0.0035\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.9692e-04 - mae: 0.0038 - val_loss: 2.9397e-04 - val_mae: 0.0037\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.9604e-04 - mae: 0.0038 - val_loss: 3.0246e-04 - val_mae: 0.0045\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.9660e-04 - mae: 0.0039 - val_loss: 2.9863e-04 - val_mae: 0.0040\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.9418e-04 - mae: 0.0038 - val_loss: 3.0580e-04 - val_mae: 0.0049\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 2.9383e-04 - mae: 0.0039 - val_loss: 2.8900e-04 - val_mae: 0.0035\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.9242e-04 - mae: 0.0038 - val_loss: 2.8894e-04 - val_mae: 0.0035\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.9251e-04 - mae: 0.0038 - val_loss: 3.0147e-04 - val_mae: 0.0048\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 2.9069e-04 - mae: 0.0038 - val_loss: 2.8678e-04 - val_mae: 0.0035\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 2.9083e-04 - mae: 0.0038 - val_loss: 2.9886e-04 - val_mae: 0.0045\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.9227e-04 - mae: 0.0041 - val_loss: 2.9117e-04 - val_mae: 0.0041\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.8904e-04 - mae: 0.0038 - val_loss: 2.9669e-04 - val_mae: 0.0047\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 2.8762e-04 - mae: 0.0038 - val_loss: 2.8422e-04 - val_mae: 0.0035\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 2.8660e-04 - mae: 0.0038 - val_loss: 2.8507e-04 - val_mae: 0.0037\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 2.8836e-04 - mae: 0.0040 - val_loss: 2.8908e-04 - val_mae: 0.0042\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 2.8660e-04 - mae: 0.0039 - val_loss: 2.8483e-04 - val_mae: 0.0038\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 2.8504e-04 - mae: 0.0038 - val_loss: 2.8222e-04 - val_mae: 0.0035\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.8431e-04 - mae: 0.0038 - val_loss: 2.8506e-04 - val_mae: 0.0037\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.8410e-04 - mae: 0.0038 - val_loss: 2.9294e-04 - val_mae: 0.0045\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.8338e-04 - mae: 0.0039 - val_loss: 2.8145e-04 - val_mae: 0.0037\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.8386e-04 - mae: 0.0039 - val_loss: 2.8510e-04 - val_mae: 0.0042\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.8233e-04 - mae: 0.0039 - val_loss: 2.8178e-04 - val_mae: 0.0038\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.7981e-04 - mae: 0.0037 - val_loss: 2.8051e-04 - val_mae: 0.0038\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.8097e-04 - mae: 0.0039 - val_loss: 2.8780e-04 - val_mae: 0.0044\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.8120e-04 - mae: 0.0040 - val_loss: 2.8207e-04 - val_mae: 0.0040\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.8025e-04 - mae: 0.0039 - val_loss: 2.9989e-04 - val_mae: 0.0055\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.7700e-04 - mae: 0.0037 - val_loss: 2.7847e-04 - val_mae: 0.0039\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.7811e-04 - mae: 0.0039 - val_loss: 2.7840e-04 - val_mae: 0.0039\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.7621e-04 - mae: 0.0038 - val_loss: 2.7240e-04 - val_mae: 0.0034\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.7586e-04 - mae: 0.0038 - val_loss: 2.7620e-04 - val_mae: 0.0037\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.7644e-04 - mae: 0.0039 - val_loss: 2.7617e-04 - val_mae: 0.0040\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.7507e-04 - mae: 0.0038 - val_loss: 2.7271e-04 - val_mae: 0.0037\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.7528e-04 - mae: 0.0039 - val_loss: 2.8676e-04 - val_mae: 0.0049\n",
      "Epoch 429/1000\n",
      "268/270 [============================>.] - ETA: 0s - loss: 2.7250e-04 - mae: 0.0037Restoring model weights from the end of the best epoch: 424.\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.7246e-04 - mae: 0.0037 - val_loss: 2.7324e-04 - val_mae: 0.0037\n",
      "Epoch 429: early stopping\n",
      "Training für Fold 4...\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 5s 7ms/step - loss: 0.0472 - mae: 0.1050 - val_loss: 0.0259 - val_mae: 0.0624\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0234 - mae: 0.0534 - val_loss: 0.0215 - val_mae: 0.0465\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0199 - mae: 0.0400 - val_loss: 0.0187 - val_mae: 0.0355\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0178 - mae: 0.0317 - val_loss: 0.0170 - val_mae: 0.0292\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0164 - mae: 0.0263 - val_loss: 0.0159 - val_mae: 0.0236\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0156 - mae: 0.0221 - val_loss: 0.0153 - val_mae: 0.0200\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0149 - mae: 0.0189 - val_loss: 0.0146 - val_mae: 0.0171\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0144 - mae: 0.0164 - val_loss: 0.0142 - val_mae: 0.0152\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0140 - mae: 0.0143 - val_loss: 0.0139 - val_mae: 0.0137\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0137 - mae: 0.0130 - val_loss: 0.0137 - val_mae: 0.0138\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0134 - mae: 0.0117 - val_loss: 0.0133 - val_mae: 0.0113\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0131 - mae: 0.0106 - val_loss: 0.0130 - val_mae: 0.0111\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0129 - mae: 0.0102 - val_loss: 0.0128 - val_mae: 0.0102\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0126 - mae: 0.0100 - val_loss: 0.0125 - val_mae: 0.0093\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 0.0124 - mae: 0.0097 - val_loss: 0.0122 - val_mae: 0.0086\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0121 - mae: 0.0089 - val_loss: 0.0120 - val_mae: 0.0089\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0119 - mae: 0.0091 - val_loss: 0.0118 - val_mae: 0.0087\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0117 - mae: 0.0087 - val_loss: 0.0116 - val_mae: 0.0101\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0115 - mae: 0.0087 - val_loss: 0.0113 - val_mae: 0.0083\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0112 - mae: 0.0087 - val_loss: 0.0111 - val_mae: 0.0082\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0110 - mae: 0.0079 - val_loss: 0.0109 - val_mae: 0.0081\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0108 - mae: 0.0084 - val_loss: 0.0107 - val_mae: 0.0086\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0106 - mae: 0.0079 - val_loss: 0.0104 - val_mae: 0.0071\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0103 - mae: 0.0076 - val_loss: 0.0103 - val_mae: 0.0080\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0102 - mae: 0.0082 - val_loss: 0.0101 - val_mae: 0.0108\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0099 - mae: 0.0077 - val_loss: 0.0098 - val_mae: 0.0069\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0097 - mae: 0.0078 - val_loss: 0.0096 - val_mae: 0.0077\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0095 - mae: 0.0074 - val_loss: 0.0094 - val_mae: 0.0070\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0093 - mae: 0.0076 - val_loss: 0.0093 - val_mae: 0.0074\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0092 - mae: 0.0076 - val_loss: 0.0091 - val_mae: 0.0066\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0090 - mae: 0.0079 - val_loss: 0.0089 - val_mae: 0.0080\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0088 - mae: 0.0068 - val_loss: 0.0087 - val_mae: 0.0068\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0086 - mae: 0.0072 - val_loss: 0.0085 - val_mae: 0.0064\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0085 - mae: 0.0068 - val_loss: 0.0084 - val_mae: 0.0067\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0083 - mae: 0.0073 - val_loss: 0.0082 - val_mae: 0.0067\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0081 - mae: 0.0068 - val_loss: 0.0080 - val_mae: 0.0062\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0080 - mae: 0.0074 - val_loss: 0.0079 - val_mae: 0.0083\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0078 - mae: 0.0072 - val_loss: 0.0079 - val_mae: 0.0107\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0077 - mae: 0.0069 - val_loss: 0.0076 - val_mae: 0.0072\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0075 - mae: 0.0067 - val_loss: 0.0075 - val_mae: 0.0074\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0074 - mae: 0.0067 - val_loss: 0.0073 - val_mae: 0.0069\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0073 - mae: 0.0070 - val_loss: 0.0072 - val_mae: 0.0075\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0072 - mae: 0.0074 - val_loss: 0.0071 - val_mae: 0.0064\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0070 - mae: 0.0066 - val_loss: 0.0069 - val_mae: 0.0060\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0069 - mae: 0.0061 - val_loss: 0.0068 - val_mae: 0.0059\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0068 - mae: 0.0063 - val_loss: 0.0067 - val_mae: 0.0064\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0067 - mae: 0.0066 - val_loss: 0.0066 - val_mae: 0.0062\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0066 - mae: 0.0073 - val_loss: 0.0066 - val_mae: 0.0090\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0064 - mae: 0.0066 - val_loss: 0.0064 - val_mae: 0.0074\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0063 - mae: 0.0064 - val_loss: 0.0063 - val_mae: 0.0059\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0062 - mae: 0.0068 - val_loss: 0.0062 - val_mae: 0.0076\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0061 - mae: 0.0067 - val_loss: 0.0061 - val_mae: 0.0058\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0060 - mae: 0.0062 - val_loss: 0.0060 - val_mae: 0.0055\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0059 - mae: 0.0063 - val_loss: 0.0059 - val_mae: 0.0054\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0058 - mae: 0.0061 - val_loss: 0.0058 - val_mae: 0.0067\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0058 - mae: 0.0065 - val_loss: 0.0057 - val_mae: 0.0059\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0057 - mae: 0.0061 - val_loss: 0.0056 - val_mae: 0.0070\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0056 - mae: 0.0059 - val_loss: 0.0055 - val_mae: 0.0056\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0055 - mae: 0.0062 - val_loss: 0.0054 - val_mae: 0.0057\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0054 - mae: 0.0059 - val_loss: 0.0053 - val_mae: 0.0053\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0053 - mae: 0.0064 - val_loss: 0.0053 - val_mae: 0.0076\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0052 - mae: 0.0060 - val_loss: 0.0052 - val_mae: 0.0052\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0051 - mae: 0.0061 - val_loss: 0.0051 - val_mae: 0.0056\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0051 - mae: 0.0061 - val_loss: 0.0050 - val_mae: 0.0058\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0050 - mae: 0.0059 - val_loss: 0.0049 - val_mae: 0.0058\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0049 - mae: 0.0057 - val_loss: 0.0049 - val_mae: 0.0070\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0048 - mae: 0.0060 - val_loss: 0.0048 - val_mae: 0.0066\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0047 - mae: 0.0059 - val_loss: 0.0048 - val_mae: 0.0094\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0047 - mae: 0.0060 - val_loss: 0.0046 - val_mae: 0.0056\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0046 - mae: 0.0059 - val_loss: 0.0046 - val_mae: 0.0061\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0045 - mae: 0.0058 - val_loss: 0.0045 - val_mae: 0.0052\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0045 - mae: 0.0058 - val_loss: 0.0044 - val_mae: 0.0067\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0044 - mae: 0.0057 - val_loss: 0.0044 - val_mae: 0.0056\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0043 - mae: 0.0053 - val_loss: 0.0043 - val_mae: 0.0048\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0043 - mae: 0.0055 - val_loss: 0.0043 - val_mae: 0.0084\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0042 - mae: 0.0059 - val_loss: 0.0042 - val_mae: 0.0067\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0041 - mae: 0.0056 - val_loss: 0.0041 - val_mae: 0.0050\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0041 - mae: 0.0054 - val_loss: 0.0040 - val_mae: 0.0048\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0040 - mae: 0.0058 - val_loss: 0.0040 - val_mae: 0.0059\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0039 - mae: 0.0058 - val_loss: 0.0039 - val_mae: 0.0050\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0039 - mae: 0.0054 - val_loss: 0.0038 - val_mae: 0.0050\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0038 - mae: 0.0054 - val_loss: 0.0038 - val_mae: 0.0053\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0038 - mae: 0.0055 - val_loss: 0.0037 - val_mae: 0.0051\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0037 - mae: 0.0053 - val_loss: 0.0037 - val_mae: 0.0049\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0036 - mae: 0.0054 - val_loss: 0.0036 - val_mae: 0.0046\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0036 - mae: 0.0058 - val_loss: 0.0036 - val_mae: 0.0069\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0035 - mae: 0.0054 - val_loss: 0.0035 - val_mae: 0.0065\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0035 - mae: 0.0053 - val_loss: 0.0035 - val_mae: 0.0064\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0034 - mae: 0.0054 - val_loss: 0.0034 - val_mae: 0.0054\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0034 - mae: 0.0052 - val_loss: 0.0034 - val_mae: 0.0050\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0033 - mae: 0.0052 - val_loss: 0.0034 - val_mae: 0.0080\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0033 - mae: 0.0053 - val_loss: 0.0033 - val_mae: 0.0057\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0032 - mae: 0.0052 - val_loss: 0.0032 - val_mae: 0.0048\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0032 - mae: 0.0051 - val_loss: 0.0032 - val_mae: 0.0051\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0031 - mae: 0.0053 - val_loss: 0.0031 - val_mae: 0.0048\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0031 - mae: 0.0054 - val_loss: 0.0031 - val_mae: 0.0047\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0030 - mae: 0.0051 - val_loss: 0.0030 - val_mae: 0.0057\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0030 - mae: 0.0054 - val_loss: 0.0030 - val_mae: 0.0047\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0030 - mae: 0.0053 - val_loss: 0.0029 - val_mae: 0.0049\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0029 - mae: 0.0050 - val_loss: 0.0029 - val_mae: 0.0049\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0029 - mae: 0.0050 - val_loss: 0.0029 - val_mae: 0.0053\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0028 - mae: 0.0056 - val_loss: 0.0028 - val_mae: 0.0059\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0028 - mae: 0.0051 - val_loss: 0.0028 - val_mae: 0.0047\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0028 - mae: 0.0053 - val_loss: 0.0027 - val_mae: 0.0049\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0027 - mae: 0.0051 - val_loss: 0.0027 - val_mae: 0.0044\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0027 - mae: 0.0055 - val_loss: 0.0027 - val_mae: 0.0055\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0026 - mae: 0.0052 - val_loss: 0.0026 - val_mae: 0.0044\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0026 - mae: 0.0051 - val_loss: 0.0026 - val_mae: 0.0050\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0026 - mae: 0.0048 - val_loss: 0.0025 - val_mae: 0.0046\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0052 - val_loss: 0.0025 - val_mae: 0.0047\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0053 - val_loss: 0.0025 - val_mae: 0.0047\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0047 - val_loss: 0.0025 - val_mae: 0.0057\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0024 - mae: 0.0050 - val_loss: 0.0024 - val_mae: 0.0051\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0024 - mae: 0.0051 - val_loss: 0.0024 - val_mae: 0.0046\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0024 - mae: 0.0051 - val_loss: 0.0023 - val_mae: 0.0046\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0023 - mae: 0.0050 - val_loss: 0.0023 - val_mae: 0.0047\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0023 - mae: 0.0051 - val_loss: 0.0023 - val_mae: 0.0064\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0023 - mae: 0.0049 - val_loss: 0.0023 - val_mae: 0.0061\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0022 - mae: 0.0048 - val_loss: 0.0022 - val_mae: 0.0051\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0022 - mae: 0.0050 - val_loss: 0.0022 - val_mae: 0.0054\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0022 - mae: 0.0049 - val_loss: 0.0022 - val_mae: 0.0050\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0021 - mae: 0.0047 - val_loss: 0.0021 - val_mae: 0.0047\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0021 - mae: 0.0049 - val_loss: 0.0021 - val_mae: 0.0048\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0021 - mae: 0.0049 - val_loss: 0.0021 - val_mae: 0.0050\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0021 - mae: 0.0050 - val_loss: 0.0020 - val_mae: 0.0049\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0020 - mae: 0.0050 - val_loss: 0.0020 - val_mae: 0.0047\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0020 - mae: 0.0048 - val_loss: 0.0020 - val_mae: 0.0044\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0020 - mae: 0.0051 - val_loss: 0.0020 - val_mae: 0.0044\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0019 - mae: 0.0047 - val_loss: 0.0019 - val_mae: 0.0047\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0019 - mae: 0.0049 - val_loss: 0.0019 - val_mae: 0.0052\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0019 - mae: 0.0046 - val_loss: 0.0019 - val_mae: 0.0048\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0019 - mae: 0.0048 - val_loss: 0.0019 - val_mae: 0.0049\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0019 - mae: 0.0050 - val_loss: 0.0018 - val_mae: 0.0047\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0018 - mae: 0.0047 - val_loss: 0.0018 - val_mae: 0.0045\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0018 - mae: 0.0047 - val_loss: 0.0018 - val_mae: 0.0046\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0018 - mae: 0.0049 - val_loss: 0.0018 - val_mae: 0.0045\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0018 - mae: 0.0046 - val_loss: 0.0017 - val_mae: 0.0044\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0017 - mae: 0.0048 - val_loss: 0.0017 - val_mae: 0.0047\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0017 - mae: 0.0047 - val_loss: 0.0017 - val_mae: 0.0047\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0017 - mae: 0.0047 - val_loss: 0.0017 - val_mae: 0.0046\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0017 - mae: 0.0049 - val_loss: 0.0017 - val_mae: 0.0044\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0016 - mae: 0.0048 - val_loss: 0.0016 - val_mae: 0.0044\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0016 - mae: 0.0047 - val_loss: 0.0016 - val_mae: 0.0044\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0016 - mae: 0.0046 - val_loss: 0.0016 - val_mae: 0.0055\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0016 - mae: 0.0049 - val_loss: 0.0016 - val_mae: 0.0046\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0016 - mae: 0.0048 - val_loss: 0.0016 - val_mae: 0.0047\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0043\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0015 - mae: 0.0047 - val_loss: 0.0015 - val_mae: 0.0042\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0015 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0045\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0015 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0047\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0015 - mae: 0.0048 - val_loss: 0.0015 - val_mae: 0.0045\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0015 - mae: 0.0047 - val_loss: 0.0015 - val_mae: 0.0047\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0014 - mae: 0.0046 - val_loss: 0.0014 - val_mae: 0.0052\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0014 - mae: 0.0047 - val_loss: 0.0015 - val_mae: 0.0080\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0014 - mae: 0.0049 - val_loss: 0.0014 - val_mae: 0.0044\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0043\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0014 - mae: 0.0047 - val_loss: 0.0014 - val_mae: 0.0043\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0014 - mae: 0.0047 - val_loss: 0.0014 - val_mae: 0.0063\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0056\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0013 - mae: 0.0046 - val_loss: 0.0013 - val_mae: 0.0049\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0013 - mae: 0.0046 - val_loss: 0.0013 - val_mae: 0.0046\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0013 - mae: 0.0046 - val_loss: 0.0013 - val_mae: 0.0046\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0013 - mae: 0.0047 - val_loss: 0.0013 - val_mae: 0.0042\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0049\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0046 - val_loss: 0.0012 - val_mae: 0.0040\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0044 - val_loss: 0.0012 - val_mae: 0.0046\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0046 - val_loss: 0.0012 - val_mae: 0.0042\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0012 - mae: 0.0045 - val_loss: 0.0012 - val_mae: 0.0053\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0046 - val_loss: 0.0012 - val_mae: 0.0047\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0045 - val_loss: 0.0012 - val_mae: 0.0047\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0012 - mae: 0.0046 - val_loss: 0.0012 - val_mae: 0.0045\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0011 - mae: 0.0046 - val_loss: 0.0012 - val_mae: 0.0051\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0045 - val_loss: 0.0011 - val_mae: 0.0043\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0044 - val_loss: 0.0011 - val_mae: 0.0044\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0045\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0011 - mae: 0.0044 - val_loss: 0.0011 - val_mae: 0.0046\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0011 - mae: 0.0046 - val_loss: 0.0011 - val_mae: 0.0049\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0045 - val_loss: 0.0011 - val_mae: 0.0040\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0040\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0010 - mae: 0.0044 - val_loss: 0.0010 - val_mae: 0.0041\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0010 - mae: 0.0044 - val_loss: 0.0010 - val_mae: 0.0043\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0010 - mae: 0.0044 - val_loss: 0.0010 - val_mae: 0.0046\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0010 - mae: 0.0044 - val_loss: 0.0010 - val_mae: 0.0046\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0010 - mae: 0.0044 - val_loss: 0.0010 - val_mae: 0.0045\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.9504e-04 - mae: 0.0045 - val_loss: 0.0010 - val_mae: 0.0064\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.8395e-04 - mae: 0.0044 - val_loss: 0.0010 - val_mae: 0.0059\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 9.7247e-04 - mae: 0.0043 - val_loss: 9.6931e-04 - val_mae: 0.0042\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.6692e-04 - mae: 0.0046 - val_loss: 9.6349e-04 - val_mae: 0.0045\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.5502e-04 - mae: 0.0044 - val_loss: 9.5194e-04 - val_mae: 0.0044\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.4323e-04 - mae: 0.0042 - val_loss: 9.4477e-04 - val_mae: 0.0044\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.3347e-04 - mae: 0.0042 - val_loss: 9.3443e-04 - val_mae: 0.0044\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.2430e-04 - mae: 0.0043 - val_loss: 9.2062e-04 - val_mae: 0.0040\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.1422e-04 - mae: 0.0042 - val_loss: 9.0787e-04 - val_mae: 0.0038\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 9.0652e-04 - mae: 0.0044 - val_loss: 9.4237e-04 - val_mae: 0.0070\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 8.9499e-04 - mae: 0.0042 - val_loss: 8.9417e-04 - val_mae: 0.0043\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.8807e-04 - mae: 0.0044 - val_loss: 8.8024e-04 - val_mae: 0.0038\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 8.7756e-04 - mae: 0.0043 - val_loss: 8.7669e-04 - val_mae: 0.0042\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.7067e-04 - mae: 0.0044 - val_loss: 8.6602e-04 - val_mae: 0.0041\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 8.5889e-04 - mae: 0.0042 - val_loss: 8.5621e-04 - val_mae: 0.0041\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.5230e-04 - mae: 0.0043 - val_loss: 8.6268e-04 - val_mae: 0.0051\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.4516e-04 - mae: 0.0044 - val_loss: 8.3728e-04 - val_mae: 0.0038\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.3722e-04 - mae: 0.0044 - val_loss: 8.3384e-04 - val_mae: 0.0042\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.2417e-04 - mae: 0.0040 - val_loss: 8.2955e-04 - val_mae: 0.0045\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.1919e-04 - mae: 0.0042 - val_loss: 8.3539e-04 - val_mae: 0.0054\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.1321e-04 - mae: 0.0044 - val_loss: 8.0740e-04 - val_mae: 0.0039\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 8.0445e-04 - mae: 0.0043 - val_loss: 8.0508e-04 - val_mae: 0.0045\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.9844e-04 - mae: 0.0044 - val_loss: 7.9013e-04 - val_mae: 0.0037\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 7.8692e-04 - mae: 0.0041 - val_loss: 7.9331e-04 - val_mae: 0.0046\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.8053e-04 - mae: 0.0042 - val_loss: 7.7622e-04 - val_mae: 0.0038\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.7307e-04 - mae: 0.0042 - val_loss: 7.7559e-04 - val_mae: 0.0044\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.6402e-04 - mae: 0.0040 - val_loss: 7.6441e-04 - val_mae: 0.0040\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.6069e-04 - mae: 0.0043 - val_loss: 7.5879e-04 - val_mae: 0.0043\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.5360e-04 - mae: 0.0043 - val_loss: 7.5162e-04 - val_mae: 0.0042\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 7.4555e-04 - mae: 0.0042 - val_loss: 7.4045e-04 - val_mae: 0.0038\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.3847e-04 - mae: 0.0042 - val_loss: 7.5945e-04 - val_mae: 0.0056\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.3605e-04 - mae: 0.0045 - val_loss: 7.3647e-04 - val_mae: 0.0045\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 7.2578e-04 - mae: 0.0042 - val_loss: 7.2818e-04 - val_mae: 0.0043\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 7.1861e-04 - mae: 0.0041 - val_loss: 7.2879e-04 - val_mae: 0.0050\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.1377e-04 - mae: 0.0042 - val_loss: 7.1766e-04 - val_mae: 0.0043\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.0778e-04 - mae: 0.0042 - val_loss: 7.0382e-04 - val_mae: 0.0038\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.0205e-04 - mae: 0.0042 - val_loss: 7.0439e-04 - val_mae: 0.0043\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.9315e-04 - mae: 0.0040 - val_loss: 6.9107e-04 - val_mae: 0.0037\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.9082e-04 - mae: 0.0042 - val_loss: 6.8801e-04 - val_mae: 0.0040\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.8470e-04 - mae: 0.0042 - val_loss: 6.8429e-04 - val_mae: 0.0041\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.7970e-04 - mae: 0.0043 - val_loss: 6.7772e-04 - val_mae: 0.0041\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.7250e-04 - mae: 0.0041 - val_loss: 6.6895e-04 - val_mae: 0.0037\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.6622e-04 - mae: 0.0041 - val_loss: 6.6568e-04 - val_mae: 0.0040\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 6.6021e-04 - mae: 0.0040 - val_loss: 6.5866e-04 - val_mae: 0.0038\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.5363e-04 - mae: 0.0040 - val_loss: 6.5942e-04 - val_mae: 0.0043\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.5135e-04 - mae: 0.0042 - val_loss: 6.5983e-04 - val_mae: 0.0047\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.4692e-04 - mae: 0.0043 - val_loss: 6.4319e-04 - val_mae: 0.0039\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.3919e-04 - mae: 0.0041 - val_loss: 6.4489e-04 - val_mae: 0.0044\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.3464e-04 - mae: 0.0041 - val_loss: 6.3214e-04 - val_mae: 0.0038\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 6.2897e-04 - mae: 0.0041 - val_loss: 6.2605e-04 - val_mae: 0.0037\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.2308e-04 - mae: 0.0040 - val_loss: 6.2153e-04 - val_mae: 0.0038\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.1978e-04 - mae: 0.0041 - val_loss: 6.1886e-04 - val_mae: 0.0040\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.1474e-04 - mae: 0.0041 - val_loss: 6.1665e-04 - val_mae: 0.0044\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 2s 7ms/step - loss: 6.0947e-04 - mae: 0.0041 - val_loss: 6.1392e-04 - val_mae: 0.0045\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.0600e-04 - mae: 0.0042 - val_loss: 6.1038e-04 - val_mae: 0.0043\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 6.0134e-04 - mae: 0.0042 - val_loss: 5.9990e-04 - val_mae: 0.0040\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.9858e-04 - mae: 0.0043 - val_loss: 6.0307e-04 - val_mae: 0.0043\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 5.9250e-04 - mae: 0.0041 - val_loss: 5.9134e-04 - val_mae: 0.0040\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.8468e-04 - mae: 0.0039 - val_loss: 5.8587e-04 - val_mae: 0.0038\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.8214e-04 - mae: 0.0040 - val_loss: 5.7901e-04 - val_mae: 0.0036\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.7830e-04 - mae: 0.0041 - val_loss: 5.7861e-04 - val_mae: 0.0039\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.7410e-04 - mae: 0.0041 - val_loss: 5.7626e-04 - val_mae: 0.0041\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.7071e-04 - mae: 0.0041 - val_loss: 5.6699e-04 - val_mae: 0.0037\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.6639e-04 - mae: 0.0041 - val_loss: 5.6758e-04 - val_mae: 0.0042\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.6065e-04 - mae: 0.0040 - val_loss: 5.6415e-04 - val_mae: 0.0042\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.5768e-04 - mae: 0.0041 - val_loss: 5.5420e-04 - val_mae: 0.0036\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 5.5257e-04 - mae: 0.0040 - val_loss: 5.5173e-04 - val_mae: 0.0037\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 5.4978e-04 - mae: 0.0041 - val_loss: 5.4987e-04 - val_mae: 0.0039\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.4378e-04 - mae: 0.0039 - val_loss: 5.4460e-04 - val_mae: 0.0037\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.4133e-04 - mae: 0.0040 - val_loss: 5.4051e-04 - val_mae: 0.0038\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.3772e-04 - mae: 0.0040 - val_loss: 5.3531e-04 - val_mae: 0.0037\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.3556e-04 - mae: 0.0041 - val_loss: 5.3186e-04 - val_mae: 0.0038\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.3161e-04 - mae: 0.0041 - val_loss: 5.3021e-04 - val_mae: 0.0038\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.2704e-04 - mae: 0.0040 - val_loss: 5.3353e-04 - val_mae: 0.0045\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.2314e-04 - mae: 0.0040 - val_loss: 5.3222e-04 - val_mae: 0.0046\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.1969e-04 - mae: 0.0040 - val_loss: 5.1965e-04 - val_mae: 0.0038\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.1843e-04 - mae: 0.0042 - val_loss: 5.1881e-04 - val_mae: 0.0039\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.1152e-04 - mae: 0.0038 - val_loss: 5.1329e-04 - val_mae: 0.0039\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.0915e-04 - mae: 0.0039 - val_loss: 5.0782e-04 - val_mae: 0.0037\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 5.1066e-04 - mae: 0.0043 - val_loss: 5.1964e-04 - val_mae: 0.0049\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 5.0310e-04 - mae: 0.0040 - val_loss: 5.0233e-04 - val_mae: 0.0038\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.9912e-04 - mae: 0.0039 - val_loss: 5.0061e-04 - val_mae: 0.0039\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.9811e-04 - mae: 0.0040 - val_loss: 4.9542e-04 - val_mae: 0.0037\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 4.9434e-04 - mae: 0.0040 - val_loss: 4.9197e-04 - val_mae: 0.0036\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 4.9293e-04 - mae: 0.0041 - val_loss: 4.9177e-04 - val_mae: 0.0040\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.8905e-04 - mae: 0.0040 - val_loss: 4.8863e-04 - val_mae: 0.0039\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 4.8462e-04 - mae: 0.0039 - val_loss: 4.8297e-04 - val_mae: 0.0036\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.8232e-04 - mae: 0.0040 - val_loss: 4.8055e-04 - val_mae: 0.0037\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.7861e-04 - mae: 0.0039 - val_loss: 4.8553e-04 - val_mae: 0.0044\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.7838e-04 - mae: 0.0041 - val_loss: 4.7912e-04 - val_mae: 0.0040\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.7366e-04 - mae: 0.0040 - val_loss: 4.7365e-04 - val_mae: 0.0038\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.7127e-04 - mae: 0.0040 - val_loss: 4.8072e-04 - val_mae: 0.0046\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.6922e-04 - mae: 0.0040 - val_loss: 4.6916e-04 - val_mae: 0.0039\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 4.6626e-04 - mae: 0.0040 - val_loss: 4.8928e-04 - val_mae: 0.0058\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.6120e-04 - mae: 0.0038 - val_loss: 4.6485e-04 - val_mae: 0.0040\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.5967e-04 - mae: 0.0039 - val_loss: 4.6805e-04 - val_mae: 0.0046\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 4.5746e-04 - mae: 0.0040 - val_loss: 4.5735e-04 - val_mae: 0.0038\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.5453e-04 - mae: 0.0039 - val_loss: 4.5397e-04 - val_mae: 0.0038\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.5198e-04 - mae: 0.0039 - val_loss: 4.6309e-04 - val_mae: 0.0049\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.5030e-04 - mae: 0.0040 - val_loss: 4.5063e-04 - val_mae: 0.0038\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 4.4745e-04 - mae: 0.0040 - val_loss: 4.5159e-04 - val_mae: 0.0041\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.4399e-04 - mae: 0.0039 - val_loss: 4.5214e-04 - val_mae: 0.0045\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.4349e-04 - mae: 0.0040 - val_loss: 4.4451e-04 - val_mae: 0.0039\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.3945e-04 - mae: 0.0039 - val_loss: 4.3917e-04 - val_mae: 0.0037\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.3850e-04 - mae: 0.0040 - val_loss: 4.4691e-04 - val_mae: 0.0045\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.3389e-04 - mae: 0.0038 - val_loss: 4.3536e-04 - val_mae: 0.0037\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 4.3254e-04 - mae: 0.0039 - val_loss: 4.3235e-04 - val_mae: 0.0038\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.3109e-04 - mae: 0.0040 - val_loss: 4.2893e-04 - val_mae: 0.0036\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.3035e-04 - mae: 0.0040 - val_loss: 4.3235e-04 - val_mae: 0.0040\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.2486e-04 - mae: 0.0038 - val_loss: 4.2415e-04 - val_mae: 0.0036\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 4.2479e-04 - mae: 0.0040 - val_loss: 4.2354e-04 - val_mae: 0.0037\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.2284e-04 - mae: 0.0040 - val_loss: 4.2654e-04 - val_mae: 0.0041\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.2005e-04 - mae: 0.0039 - val_loss: 4.2399e-04 - val_mae: 0.0040\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.1558e-04 - mae: 0.0037 - val_loss: 4.3239e-04 - val_mae: 0.0051\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.1621e-04 - mae: 0.0040 - val_loss: 4.2020e-04 - val_mae: 0.0041\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.1287e-04 - mae: 0.0039 - val_loss: 4.1045e-04 - val_mae: 0.0034\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.1191e-04 - mae: 0.0039 - val_loss: 4.1077e-04 - val_mae: 0.0036\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.1014e-04 - mae: 0.0040 - val_loss: 4.2374e-04 - val_mae: 0.0050\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.0732e-04 - mae: 0.0039 - val_loss: 4.0952e-04 - val_mae: 0.0038\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.0454e-04 - mae: 0.0038 - val_loss: 4.0410e-04 - val_mae: 0.0036\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.0289e-04 - mae: 0.0038 - val_loss: 4.1547e-04 - val_mae: 0.0048\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 4.0287e-04 - mae: 0.0040 - val_loss: 4.0310e-04 - val_mae: 0.0038\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.9917e-04 - mae: 0.0039 - val_loss: 4.0543e-04 - val_mae: 0.0041\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.9739e-04 - mae: 0.0038 - val_loss: 3.9812e-04 - val_mae: 0.0037\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.9456e-04 - mae: 0.0038 - val_loss: 3.9381e-04 - val_mae: 0.0035\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.9401e-04 - mae: 0.0039 - val_loss: 3.9477e-04 - val_mae: 0.0036\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.9015e-04 - mae: 0.0037 - val_loss: 3.9156e-04 - val_mae: 0.0036\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.8775e-04 - mae: 0.0036 - val_loss: 3.9764e-04 - val_mae: 0.0045\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.8853e-04 - mae: 0.0039 - val_loss: 3.8814e-04 - val_mae: 0.0036\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 3.8854e-04 - mae: 0.0040 - val_loss: 3.8649e-04 - val_mae: 0.0037\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 3.8375e-04 - mae: 0.0038 - val_loss: 3.8568e-04 - val_mae: 0.0038\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 3.8102e-04 - mae: 0.0037 - val_loss: 3.8340e-04 - val_mae: 0.0038\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 3.8015e-04 - mae: 0.0038 - val_loss: 3.8714e-04 - val_mae: 0.0042\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.7801e-04 - mae: 0.0038 - val_loss: 3.7721e-04 - val_mae: 0.0034\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.7689e-04 - mae: 0.0038 - val_loss: 3.7641e-04 - val_mae: 0.0035\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.7559e-04 - mae: 0.0038 - val_loss: 3.8882e-04 - val_mae: 0.0049\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.7432e-04 - mae: 0.0039 - val_loss: 3.7205e-04 - val_mae: 0.0034\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.7168e-04 - mae: 0.0038 - val_loss: 3.7235e-04 - val_mae: 0.0036\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.7009e-04 - mae: 0.0038 - val_loss: 3.7626e-04 - val_mae: 0.0042\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.6986e-04 - mae: 0.0039 - val_loss: 3.6760e-04 - val_mae: 0.0035\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.6624e-04 - mae: 0.0038 - val_loss: 3.6537e-04 - val_mae: 0.0035\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 3.6505e-04 - mae: 0.0038 - val_loss: 3.6402e-04 - val_mae: 0.0034\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.6402e-04 - mae: 0.0038 - val_loss: 3.7438e-04 - val_mae: 0.0046\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.6276e-04 - mae: 0.0039 - val_loss: 3.6076e-04 - val_mae: 0.0034\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.6065e-04 - mae: 0.0038 - val_loss: 3.6290e-04 - val_mae: 0.0038\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.5898e-04 - mae: 0.0038 - val_loss: 3.5964e-04 - val_mae: 0.0037\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.5658e-04 - mae: 0.0038 - val_loss: 3.6685e-04 - val_mae: 0.0045\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.5586e-04 - mae: 0.0038 - val_loss: 3.6085e-04 - val_mae: 0.0042\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.5424e-04 - mae: 0.0038 - val_loss: 3.5620e-04 - val_mae: 0.0038\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.5288e-04 - mae: 0.0038 - val_loss: 3.5550e-04 - val_mae: 0.0038\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 3.5210e-04 - mae: 0.0039 - val_loss: 3.4974e-04 - val_mae: 0.0034\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.4907e-04 - mae: 0.0037 - val_loss: 3.5020e-04 - val_mae: 0.0036\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.4640e-04 - mae: 0.0037 - val_loss: 3.6221e-04 - val_mae: 0.0050\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 3.4581e-04 - mae: 0.0038 - val_loss: 3.4803e-04 - val_mae: 0.0037\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.4338e-04 - mae: 0.0037 - val_loss: 3.4632e-04 - val_mae: 0.0038\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 3.4613e-04 - mae: 0.0040 - val_loss: 3.4174e-04 - val_mae: 0.0034\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 3.3966e-04 - mae: 0.0036 - val_loss: 3.4265e-04 - val_mae: 0.0037\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 3.3862e-04 - mae: 0.0037 - val_loss: 3.4078e-04 - val_mae: 0.0036\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.3775e-04 - mae: 0.0037 - val_loss: 3.3679e-04 - val_mae: 0.0034\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.3637e-04 - mae: 0.0037 - val_loss: 3.4212e-04 - val_mae: 0.0042\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.3741e-04 - mae: 0.0040 - val_loss: 3.4191e-04 - val_mae: 0.0042\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.3209e-04 - mae: 0.0036 - val_loss: 3.3388e-04 - val_mae: 0.0036\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.3286e-04 - mae: 0.0038 - val_loss: 3.4068e-04 - val_mae: 0.0044\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.2913e-04 - mae: 0.0036 - val_loss: 3.3073e-04 - val_mae: 0.0035\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 3.2948e-04 - mae: 0.0038 - val_loss: 3.2861e-04 - val_mae: 0.0036\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.2834e-04 - mae: 0.0038 - val_loss: 3.2549e-04 - val_mae: 0.0033\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 3.2724e-04 - mae: 0.0038 - val_loss: 3.2587e-04 - val_mae: 0.0035\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 3.2351e-04 - mae: 0.0036 - val_loss: 3.2933e-04 - val_mae: 0.0039\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.2525e-04 - mae: 0.0039 - val_loss: 3.2761e-04 - val_mae: 0.0038\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.2299e-04 - mae: 0.0038 - val_loss: 3.2127e-04 - val_mae: 0.0034\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 3.2353e-04 - mae: 0.0039 - val_loss: 3.2168e-04 - val_mae: 0.0036\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.1928e-04 - mae: 0.0037 - val_loss: 3.1980e-04 - val_mae: 0.0035\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.1855e-04 - mae: 0.0037 - val_loss: 3.1872e-04 - val_mae: 0.0035\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.1837e-04 - mae: 0.0038 - val_loss: 3.1889e-04 - val_mae: 0.0036\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.1728e-04 - mae: 0.0038 - val_loss: 3.1617e-04 - val_mae: 0.0036\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 3.1415e-04 - mae: 0.0036 - val_loss: 3.1542e-04 - val_mae: 0.0035\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.1314e-04 - mae: 0.0037 - val_loss: 3.2079e-04 - val_mae: 0.0041\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.1511e-04 - mae: 0.0039 - val_loss: 3.2176e-04 - val_mae: 0.0044\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.1254e-04 - mae: 0.0038 - val_loss: 3.2130e-04 - val_mae: 0.0043\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.1066e-04 - mae: 0.0038 - val_loss: 3.1373e-04 - val_mae: 0.0037\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.0855e-04 - mae: 0.0037 - val_loss: 3.0862e-04 - val_mae: 0.0034\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.0811e-04 - mae: 0.0037 - val_loss: 3.0743e-04 - val_mae: 0.0034\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.0618e-04 - mae: 0.0036 - val_loss: 3.1335e-04 - val_mae: 0.0041\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 3.0550e-04 - mae: 0.0037 - val_loss: 3.0870e-04 - val_mae: 0.0037\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.0500e-04 - mae: 0.0037 - val_loss: 3.0809e-04 - val_mae: 0.0038\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 3.0337e-04 - mae: 0.0037 - val_loss: 3.0326e-04 - val_mae: 0.0035\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.0316e-04 - mae: 0.0038 - val_loss: 3.0799e-04 - val_mae: 0.0041\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.0313e-04 - mae: 0.0038 - val_loss: 3.0036e-04 - val_mae: 0.0034\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 3.0130e-04 - mae: 0.0038 - val_loss: 3.0222e-04 - val_mae: 0.0037\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.9995e-04 - mae: 0.0037 - val_loss: 3.1077e-04 - val_mae: 0.0045\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 3.0052e-04 - mae: 0.0039 - val_loss: 3.0066e-04 - val_mae: 0.0037\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.9608e-04 - mae: 0.0036 - val_loss: 2.9867e-04 - val_mae: 0.0036\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.9707e-04 - mae: 0.0038 - val_loss: 2.9699e-04 - val_mae: 0.0034\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.9564e-04 - mae: 0.0037 - val_loss: 2.9626e-04 - val_mae: 0.0036\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.9471e-04 - mae: 0.0037 - val_loss: 2.9337e-04 - val_mae: 0.0034\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.9407e-04 - mae: 0.0038 - val_loss: 2.9756e-04 - val_mae: 0.0039\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 2.9456e-04 - mae: 0.0039 - val_loss: 2.9357e-04 - val_mae: 0.0036\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 2.9179e-04 - mae: 0.0037 - val_loss: 2.9973e-04 - val_mae: 0.0042\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 2.9082e-04 - mae: 0.0037 - val_loss: 2.9477e-04 - val_mae: 0.0039\n",
      "Epoch 384/1000\n",
      "265/270 [============================>.] - ETA: 0s - loss: 2.8954e-04 - mae: 0.0037Restoring model weights from the end of the best epoch: 379.\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 2.8989e-04 - mae: 0.0037 - val_loss: 3.0146e-04 - val_mae: 0.0045\n",
      "Epoch 384: early stopping\n",
      "Training für Fold 5...\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 4s 7ms/step - loss: 0.0906 - mae: 0.1684 - val_loss: 0.0257 - val_mae: 0.0609\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0239 - mae: 0.0540 - val_loss: 0.0220 - val_mae: 0.0472\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0208 - mae: 0.0423 - val_loss: 0.0196 - val_mae: 0.0393\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0187 - mae: 0.0347 - val_loss: 0.0179 - val_mae: 0.0314\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0174 - mae: 0.0293 - val_loss: 0.0168 - val_mae: 0.0266\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0164 - mae: 0.0248 - val_loss: 0.0160 - val_mae: 0.0226\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0156 - mae: 0.0212 - val_loss: 0.0153 - val_mae: 0.0188\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0151 - mae: 0.0183 - val_loss: 0.0149 - val_mae: 0.0179\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0147 - mae: 0.0159 - val_loss: 0.0145 - val_mae: 0.0150\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0144 - mae: 0.0147 - val_loss: 0.0142 - val_mae: 0.0140\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0141 - mae: 0.0131 - val_loss: 0.0139 - val_mae: 0.0121\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0138 - mae: 0.0120 - val_loss: 0.0137 - val_mae: 0.0115\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0135 - mae: 0.0111 - val_loss: 0.0134 - val_mae: 0.0104\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0133 - mae: 0.0103 - val_loss: 0.0132 - val_mae: 0.0105\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0131 - mae: 0.0098 - val_loss: 0.0130 - val_mae: 0.0102\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0128 - mae: 0.0094 - val_loss: 0.0127 - val_mae: 0.0093\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0126 - mae: 0.0090 - val_loss: 0.0125 - val_mae: 0.0087\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0124 - mae: 0.0090 - val_loss: 0.0123 - val_mae: 0.0086\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0122 - mae: 0.0086 - val_loss: 0.0121 - val_mae: 0.0102\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0120 - mae: 0.0087 - val_loss: 0.0119 - val_mae: 0.0085\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0117 - mae: 0.0081 - val_loss: 0.0117 - val_mae: 0.0085\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0115 - mae: 0.0084 - val_loss: 0.0114 - val_mae: 0.0071\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0113 - mae: 0.0083 - val_loss: 0.0113 - val_mae: 0.0099\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0111 - mae: 0.0078 - val_loss: 0.0110 - val_mae: 0.0083\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0109 - mae: 0.0078 - val_loss: 0.0108 - val_mae: 0.0090\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0107 - mae: 0.0081 - val_loss: 0.0107 - val_mae: 0.0101\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0105 - mae: 0.0077 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0103 - mae: 0.0077 - val_loss: 0.0102 - val_mae: 0.0073\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0101 - mae: 0.0077 - val_loss: 0.0100 - val_mae: 0.0069\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0099 - mae: 0.0073 - val_loss: 0.0098 - val_mae: 0.0069\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0097 - mae: 0.0072 - val_loss: 0.0096 - val_mae: 0.0070\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0095 - mae: 0.0074 - val_loss: 0.0094 - val_mae: 0.0063\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0094 - mae: 0.0073 - val_loss: 0.0093 - val_mae: 0.0077\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0092 - mae: 0.0071 - val_loss: 0.0091 - val_mae: 0.0071\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0090 - mae: 0.0076 - val_loss: 0.0089 - val_mae: 0.0082\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0088 - mae: 0.0074 - val_loss: 0.0087 - val_mae: 0.0064\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0087 - mae: 0.0069 - val_loss: 0.0086 - val_mae: 0.0065\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0085 - mae: 0.0071 - val_loss: 0.0084 - val_mae: 0.0069\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0083 - mae: 0.0070 - val_loss: 0.0083 - val_mae: 0.0081\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0082 - mae: 0.0072 - val_loss: 0.0081 - val_mae: 0.0063\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0080 - mae: 0.0066 - val_loss: 0.0080 - val_mae: 0.0064\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0079 - mae: 0.0067 - val_loss: 0.0078 - val_mae: 0.0060\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0077 - mae: 0.0072 - val_loss: 0.0077 - val_mae: 0.0066\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0076 - mae: 0.0068 - val_loss: 0.0075 - val_mae: 0.0074\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0075 - mae: 0.0068 - val_loss: 0.0074 - val_mae: 0.0067\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0073 - mae: 0.0067 - val_loss: 0.0073 - val_mae: 0.0059\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0072 - mae: 0.0066 - val_loss: 0.0071 - val_mae: 0.0060\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0071 - mae: 0.0070 - val_loss: 0.0070 - val_mae: 0.0066\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0070 - mae: 0.0066 - val_loss: 0.0069 - val_mae: 0.0077\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0068 - mae: 0.0065 - val_loss: 0.0068 - val_mae: 0.0062\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0067 - mae: 0.0063 - val_loss: 0.0066 - val_mae: 0.0057\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0066 - mae: 0.0063 - val_loss: 0.0066 - val_mae: 0.0087\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0065 - mae: 0.0068 - val_loss: 0.0064 - val_mae: 0.0068\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0064 - mae: 0.0065 - val_loss: 0.0063 - val_mae: 0.0063\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0063 - mae: 0.0062 - val_loss: 0.0062 - val_mae: 0.0062\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0061 - mae: 0.0063 - val_loss: 0.0061 - val_mae: 0.0065\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0060 - mae: 0.0063 - val_loss: 0.0060 - val_mae: 0.0062\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0060 - mae: 0.0067 - val_loss: 0.0059 - val_mae: 0.0058\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 0.0058 - mae: 0.0060 - val_loss: 0.0058 - val_mae: 0.0060\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0057 - mae: 0.0059 - val_loss: 0.0057 - val_mae: 0.0055\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0056 - mae: 0.0060 - val_loss: 0.0056 - val_mae: 0.0058\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0056 - mae: 0.0062 - val_loss: 0.0055 - val_mae: 0.0060\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0055 - mae: 0.0061 - val_loss: 0.0054 - val_mae: 0.0056\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 0.0054 - mae: 0.0059 - val_loss: 0.0053 - val_mae: 0.0057\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0053 - mae: 0.0062 - val_loss: 0.0052 - val_mae: 0.0069\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0052 - mae: 0.0059 - val_loss: 0.0052 - val_mae: 0.0064\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0051 - mae: 0.0058 - val_loss: 0.0051 - val_mae: 0.0058\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0050 - mae: 0.0058 - val_loss: 0.0050 - val_mae: 0.0053\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0049 - mae: 0.0058 - val_loss: 0.0049 - val_mae: 0.0064\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0048 - mae: 0.0060 - val_loss: 0.0048 - val_mae: 0.0062\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0048 - mae: 0.0058 - val_loss: 0.0047 - val_mae: 0.0066\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0047 - mae: 0.0061 - val_loss: 0.0046 - val_mae: 0.0051\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0058 - val_loss: 0.0046 - val_mae: 0.0073\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0045 - mae: 0.0056 - val_loss: 0.0045 - val_mae: 0.0055\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0045 - mae: 0.0058 - val_loss: 0.0044 - val_mae: 0.0067\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0044 - mae: 0.0056 - val_loss: 0.0044 - val_mae: 0.0063\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0043 - mae: 0.0063 - val_loss: 0.0043 - val_mae: 0.0060\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0043 - mae: 0.0059 - val_loss: 0.0042 - val_mae: 0.0058\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0042 - mae: 0.0054 - val_loss: 0.0041 - val_mae: 0.0050\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0041 - mae: 0.0055 - val_loss: 0.0041 - val_mae: 0.0050\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0041 - mae: 0.0053 - val_loss: 0.0040 - val_mae: 0.0052\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0040 - mae: 0.0058 - val_loss: 0.0039 - val_mae: 0.0049\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0039 - mae: 0.0056 - val_loss: 0.0039 - val_mae: 0.0055\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0039 - mae: 0.0055 - val_loss: 0.0038 - val_mae: 0.0054\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0038 - mae: 0.0055 - val_loss: 0.0038 - val_mae: 0.0061\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0037 - mae: 0.0054 - val_loss: 0.0037 - val_mae: 0.0055\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0037 - mae: 0.0054 - val_loss: 0.0036 - val_mae: 0.0046\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0036 - mae: 0.0053 - val_loss: 0.0036 - val_mae: 0.0047\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0036 - mae: 0.0053 - val_loss: 0.0036 - val_mae: 0.0071\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0035 - mae: 0.0055 - val_loss: 0.0035 - val_mae: 0.0066\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0035 - mae: 0.0055 - val_loss: 0.0034 - val_mae: 0.0050\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0034 - mae: 0.0054 - val_loss: 0.0034 - val_mae: 0.0045\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0033 - mae: 0.0052 - val_loss: 0.0033 - val_mae: 0.0062\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0033 - mae: 0.0053 - val_loss: 0.0033 - val_mae: 0.0052\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0032 - mae: 0.0052 - val_loss: 0.0032 - val_mae: 0.0047\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0032 - mae: 0.0053 - val_loss: 0.0032 - val_mae: 0.0055\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0031 - mae: 0.0056 - val_loss: 0.0031 - val_mae: 0.0048\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0031 - mae: 0.0053 - val_loss: 0.0031 - val_mae: 0.0060\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0030 - mae: 0.0054 - val_loss: 0.0030 - val_mae: 0.0055\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0030 - mae: 0.0051 - val_loss: 0.0030 - val_mae: 0.0049\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0029 - mae: 0.0052 - val_loss: 0.0029 - val_mae: 0.0057\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0029 - mae: 0.0053 - val_loss: 0.0029 - val_mae: 0.0059\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0029 - mae: 0.0051 - val_loss: 0.0028 - val_mae: 0.0054\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0028 - mae: 0.0051 - val_loss: 0.0028 - val_mae: 0.0066\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0028 - mae: 0.0051 - val_loss: 0.0027 - val_mae: 0.0046\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0027 - mae: 0.0051 - val_loss: 0.0027 - val_mae: 0.0047\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0027 - mae: 0.0052 - val_loss: 0.0027 - val_mae: 0.0048\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0026 - mae: 0.0050 - val_loss: 0.0026 - val_mae: 0.0050\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0026 - mae: 0.0050 - val_loss: 0.0026 - val_mae: 0.0046\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0026 - mae: 0.0051 - val_loss: 0.0025 - val_mae: 0.0046\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0025 - mae: 0.0051 - val_loss: 0.0025 - val_mae: 0.0044\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0025 - mae: 0.0051 - val_loss: 0.0025 - val_mae: 0.0051\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0024 - mae: 0.0049 - val_loss: 0.0024 - val_mae: 0.0048\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0024 - mae: 0.0048 - val_loss: 0.0024 - val_mae: 0.0048\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0024 - mae: 0.0051 - val_loss: 0.0024 - val_mae: 0.0048\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0023 - mae: 0.0049 - val_loss: 0.0023 - val_mae: 0.0055\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0023 - mae: 0.0050 - val_loss: 0.0023 - val_mae: 0.0048\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0023 - mae: 0.0050 - val_loss: 0.0022 - val_mae: 0.0048\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0022 - mae: 0.0052 - val_loss: 0.0022 - val_mae: 0.0063\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0022 - mae: 0.0047 - val_loss: 0.0022 - val_mae: 0.0049\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0022 - mae: 0.0050 - val_loss: 0.0022 - val_mae: 0.0054\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0049 - val_loss: 0.0021 - val_mae: 0.0046\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0052 - val_loss: 0.0021 - val_mae: 0.0050\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0051 - val_loss: 0.0021 - val_mae: 0.0042\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0047 - val_loss: 0.0020 - val_mae: 0.0052\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0047 - val_loss: 0.0020 - val_mae: 0.0045\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0047 - val_loss: 0.0020 - val_mae: 0.0051\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0050 - val_loss: 0.0019 - val_mae: 0.0046\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0048 - val_loss: 0.0019 - val_mae: 0.0046\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0049 - val_loss: 0.0019 - val_mae: 0.0042\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0047 - val_loss: 0.0019 - val_mae: 0.0041\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0048 - val_loss: 0.0018 - val_mae: 0.0043\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0049 - val_loss: 0.0018 - val_mae: 0.0051\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0048 - val_loss: 0.0018 - val_mae: 0.0044\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0047 - val_loss: 0.0018 - val_mae: 0.0051\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0048 - val_loss: 0.0018 - val_mae: 0.0058\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0047 - val_loss: 0.0017 - val_mae: 0.0049\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0049 - val_loss: 0.0017 - val_mae: 0.0041\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0046 - val_loss: 0.0017 - val_mae: 0.0046\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0046 - val_loss: 0.0016 - val_mae: 0.0046\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0046 - val_loss: 0.0016 - val_mae: 0.0044\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0049 - val_loss: 0.0016 - val_mae: 0.0047\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0045 - val_loss: 0.0016 - val_mae: 0.0044\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0048 - val_loss: 0.0016 - val_mae: 0.0051\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0047 - val_loss: 0.0015 - val_mae: 0.0043\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0047 - val_loss: 0.0015 - val_mae: 0.0047\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0057\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0045\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0014 - val_mae: 0.0046\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0048\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0043\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0047 - val_loss: 0.0014 - val_mae: 0.0042\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0045\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0047 - val_loss: 0.0013 - val_mae: 0.0041\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0047 - val_loss: 0.0013 - val_mae: 0.0050\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0046 - val_loss: 0.0013 - val_mae: 0.0049\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0049\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0047 - val_loss: 0.0013 - val_mae: 0.0040\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0047 - val_loss: 0.0013 - val_mae: 0.0043\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0012 - val_mae: 0.0046\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0044 - val_loss: 0.0012 - val_mae: 0.0039\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0044 - val_loss: 0.0012 - val_mae: 0.0054\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0047 - val_loss: 0.0012 - val_mae: 0.0047\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0048 - val_loss: 0.0012 - val_mae: 0.0065\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0045 - val_loss: 0.0012 - val_mae: 0.0043\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0012 - mae: 0.0046 - val_loss: 0.0012 - val_mae: 0.0046\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0044 - val_loss: 0.0011 - val_mae: 0.0044\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0048 - val_loss: 0.0011 - val_mae: 0.0046\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0044 - val_loss: 0.0011 - val_mae: 0.0048\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0044 - val_loss: 0.0011 - val_mae: 0.0043\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0044 - val_loss: 0.0011 - val_mae: 0.0044\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0044 - val_loss: 0.0011 - val_mae: 0.0073\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0046 - val_loss: 0.0011 - val_mae: 0.0047\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0044 - val_loss: 0.0011 - val_mae: 0.0042\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0042 - val_loss: 0.0010 - val_mae: 0.0050\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0044 - val_loss: 0.0010 - val_mae: 0.0042\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0045 - val_loss: 0.0010 - val_mae: 0.0043\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0045 - val_loss: 0.0010 - val_mae: 0.0041\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.9976e-04 - mae: 0.0047 - val_loss: 9.8597e-04 - val_mae: 0.0038\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.8330e-04 - mae: 0.0043 - val_loss: 9.8704e-04 - val_mae: 0.0050\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.7335e-04 - mae: 0.0044 - val_loss: 9.7768e-04 - val_mae: 0.0046\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.6329e-04 - mae: 0.0044 - val_loss: 9.6325e-04 - val_mae: 0.0047\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.5203e-04 - mae: 0.0044 - val_loss: 9.6286e-04 - val_mae: 0.0054\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.4151e-04 - mae: 0.0044 - val_loss: 9.4783e-04 - val_mae: 0.0053\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.3404e-04 - mae: 0.0046 - val_loss: 9.5164e-04 - val_mae: 0.0062\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.2255e-04 - mae: 0.0045 - val_loss: 9.3013e-04 - val_mae: 0.0053\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.1447e-04 - mae: 0.0046 - val_loss: 9.0639e-04 - val_mae: 0.0043\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 9.0049e-04 - mae: 0.0042 - val_loss: 9.0807e-04 - val_mae: 0.0050\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.9499e-04 - mae: 0.0045 - val_loss: 8.8644e-04 - val_mae: 0.0041\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.8197e-04 - mae: 0.0042 - val_loss: 9.0186e-04 - val_mae: 0.0055\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.7396e-04 - mae: 0.0043 - val_loss: 8.6773e-04 - val_mae: 0.0041\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.6656e-04 - mae: 0.0045 - val_loss: 8.5545e-04 - val_mae: 0.0038\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.5598e-04 - mae: 0.0044 - val_loss: 8.4920e-04 - val_mae: 0.0040\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.4944e-04 - mae: 0.0045 - val_loss: 8.4508e-04 - val_mae: 0.0044\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.3630e-04 - mae: 0.0041 - val_loss: 8.4195e-04 - val_mae: 0.0048\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.2929e-04 - mae: 0.0043 - val_loss: 8.2426e-04 - val_mae: 0.0041\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.2085e-04 - mae: 0.0043 - val_loss: 8.1467e-04 - val_mae: 0.0040\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.1368e-04 - mae: 0.0044 - val_loss: 8.0929e-04 - val_mae: 0.0043\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 8.0511e-04 - mae: 0.0044 - val_loss: 8.0091e-04 - val_mae: 0.0043\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.9773e-04 - mae: 0.0044 - val_loss: 7.9207e-04 - val_mae: 0.0041\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.9159e-04 - mae: 0.0045 - val_loss: 7.8299e-04 - val_mae: 0.0040\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.8167e-04 - mae: 0.0043 - val_loss: 7.9378e-04 - val_mae: 0.0054\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.7576e-04 - mae: 0.0044 - val_loss: 7.8096e-04 - val_mae: 0.0052\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.6929e-04 - mae: 0.0045 - val_loss: 7.6232e-04 - val_mae: 0.0042\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.5813e-04 - mae: 0.0041 - val_loss: 7.9527e-04 - val_mae: 0.0067\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.5348e-04 - mae: 0.0043 - val_loss: 7.4600e-04 - val_mae: 0.0038\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.4492e-04 - mae: 0.0042 - val_loss: 7.4734e-04 - val_mae: 0.0046\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.3989e-04 - mae: 0.0044 - val_loss: 7.3964e-04 - val_mae: 0.0043\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.3298e-04 - mae: 0.0043 - val_loss: 7.3151e-04 - val_mae: 0.0043\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.2468e-04 - mae: 0.0042 - val_loss: 7.1749e-04 - val_mae: 0.0037\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.2263e-04 - mae: 0.0045 - val_loss: 7.1342e-04 - val_mae: 0.0039\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.1153e-04 - mae: 0.0042 - val_loss: 7.2019e-04 - val_mae: 0.0050\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.0834e-04 - mae: 0.0044 - val_loss: 7.0153e-04 - val_mae: 0.0041\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 7.0385e-04 - mae: 0.0045 - val_loss: 6.9618e-04 - val_mae: 0.0040\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.9472e-04 - mae: 0.0043 - val_loss: 7.0499e-04 - val_mae: 0.0051\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.8902e-04 - mae: 0.0043 - val_loss: 6.8288e-04 - val_mae: 0.0039\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.8362e-04 - mae: 0.0043 - val_loss: 6.8124e-04 - val_mae: 0.0042\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.7777e-04 - mae: 0.0043 - val_loss: 6.7133e-04 - val_mae: 0.0039\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.7492e-04 - mae: 0.0045 - val_loss: 6.7616e-04 - val_mae: 0.0047\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.6493e-04 - mae: 0.0041 - val_loss: 6.8679e-04 - val_mae: 0.0059\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.6013e-04 - mae: 0.0042 - val_loss: 6.5552e-04 - val_mae: 0.0039\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.5583e-04 - mae: 0.0043 - val_loss: 6.5353e-04 - val_mae: 0.0042\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.5054e-04 - mae: 0.0043 - val_loss: 6.4708e-04 - val_mae: 0.0040\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.4514e-04 - mae: 0.0043 - val_loss: 6.4137e-04 - val_mae: 0.0041\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.3914e-04 - mae: 0.0042 - val_loss: 6.3798e-04 - val_mae: 0.0042\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.3638e-04 - mae: 0.0044 - val_loss: 6.3856e-04 - val_mae: 0.0047\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.2727e-04 - mae: 0.0041 - val_loss: 6.2335e-04 - val_mae: 0.0038\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.2679e-04 - mae: 0.0044 - val_loss: 6.1724e-04 - val_mae: 0.0037\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.1824e-04 - mae: 0.0041 - val_loss: 6.1597e-04 - val_mae: 0.0039\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.1364e-04 - mae: 0.0041 - val_loss: 6.1156e-04 - val_mae: 0.0040\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.0940e-04 - mae: 0.0042 - val_loss: 6.0534e-04 - val_mae: 0.0039\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.0399e-04 - mae: 0.0041 - val_loss: 5.9938e-04 - val_mae: 0.0038\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 6.0062e-04 - mae: 0.0042 - val_loss: 6.0216e-04 - val_mae: 0.0044\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.9538e-04 - mae: 0.0042 - val_loss: 5.9999e-04 - val_mae: 0.0046\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.9136e-04 - mae: 0.0042 - val_loss: 5.8961e-04 - val_mae: 0.0042\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.8677e-04 - mae: 0.0042 - val_loss: 5.8014e-04 - val_mae: 0.0037\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.8230e-04 - mae: 0.0042 - val_loss: 6.0514e-04 - val_mae: 0.0057\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.7822e-04 - mae: 0.0042 - val_loss: 5.7840e-04 - val_mae: 0.0044\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.7282e-04 - mae: 0.0041 - val_loss: 5.7056e-04 - val_mae: 0.0041\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.6809e-04 - mae: 0.0041 - val_loss: 5.7493e-04 - val_mae: 0.0047\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.6736e-04 - mae: 0.0043 - val_loss: 5.5861e-04 - val_mae: 0.0037\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.6094e-04 - mae: 0.0041 - val_loss: 5.5911e-04 - val_mae: 0.0040\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.5689e-04 - mae: 0.0041 - val_loss: 5.5091e-04 - val_mae: 0.0036\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.5585e-04 - mae: 0.0044 - val_loss: 5.6297e-04 - val_mae: 0.0050\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.4962e-04 - mae: 0.0042 - val_loss: 5.4646e-04 - val_mae: 0.0039\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.4283e-04 - mae: 0.0039 - val_loss: 5.4046e-04 - val_mae: 0.0038\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.4206e-04 - mae: 0.0041 - val_loss: 5.4303e-04 - val_mae: 0.0043\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.4148e-04 - mae: 0.0044 - val_loss: 5.3331e-04 - val_mae: 0.0037\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.3571e-04 - mae: 0.0042 - val_loss: 5.2898e-04 - val_mae: 0.0037\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.3073e-04 - mae: 0.0041 - val_loss: 5.2698e-04 - val_mae: 0.0038\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.2731e-04 - mae: 0.0041 - val_loss: 5.2162e-04 - val_mae: 0.0037\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.2329e-04 - mae: 0.0041 - val_loss: 5.3536e-04 - val_mae: 0.0050\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.1951e-04 - mae: 0.0041 - val_loss: 5.1417e-04 - val_mae: 0.0037\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.1786e-04 - mae: 0.0042 - val_loss: 5.1360e-04 - val_mae: 0.0039\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.1571e-04 - mae: 0.0043 - val_loss: 5.1057e-04 - val_mae: 0.0040\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.0836e-04 - mae: 0.0040 - val_loss: 5.2591e-04 - val_mae: 0.0054\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.0596e-04 - mae: 0.0041 - val_loss: 5.0466e-04 - val_mae: 0.0040\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.0372e-04 - mae: 0.0041 - val_loss: 5.1150e-04 - val_mae: 0.0048\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 5.0050e-04 - mae: 0.0042 - val_loss: 5.0023e-04 - val_mae: 0.0042\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.9567e-04 - mae: 0.0040 - val_loss: 4.9112e-04 - val_mae: 0.0037\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.9250e-04 - mae: 0.0040 - val_loss: 4.9136e-04 - val_mae: 0.0040\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.8959e-04 - mae: 0.0040 - val_loss: 5.0658e-04 - val_mae: 0.0054\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.8866e-04 - mae: 0.0042 - val_loss: 4.9439e-04 - val_mae: 0.0046\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.8279e-04 - mae: 0.0040 - val_loss: 4.9263e-04 - val_mae: 0.0048\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.8193e-04 - mae: 0.0041 - val_loss: 4.7772e-04 - val_mae: 0.0038\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.7847e-04 - mae: 0.0041 - val_loss: 4.7271e-04 - val_mae: 0.0036\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.7648e-04 - mae: 0.0041 - val_loss: 4.9812e-04 - val_mae: 0.0055\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.7247e-04 - mae: 0.0040 - val_loss: 4.7067e-04 - val_mae: 0.0040\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.6926e-04 - mae: 0.0040 - val_loss: 4.7624e-04 - val_mae: 0.0046\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.6863e-04 - mae: 0.0041 - val_loss: 4.7632e-04 - val_mae: 0.0048\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.6353e-04 - mae: 0.0039 - val_loss: 4.6005e-04 - val_mae: 0.0036\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.6121e-04 - mae: 0.0040 - val_loss: 4.6657e-04 - val_mae: 0.0044\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.5784e-04 - mae: 0.0039 - val_loss: 4.8702e-04 - val_mae: 0.0060\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.5779e-04 - mae: 0.0042 - val_loss: 4.7114e-04 - val_mae: 0.0052\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.5616e-04 - mae: 0.0042 - val_loss: 4.5171e-04 - val_mae: 0.0038\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.4976e-04 - mae: 0.0039 - val_loss: 4.5439e-04 - val_mae: 0.0043\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.4873e-04 - mae: 0.0040 - val_loss: 4.4701e-04 - val_mae: 0.0039\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.4633e-04 - mae: 0.0040 - val_loss: 4.4348e-04 - val_mae: 0.0038\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.4609e-04 - mae: 0.0042 - val_loss: 4.6694e-04 - val_mae: 0.0058\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.4246e-04 - mae: 0.0041 - val_loss: 4.4161e-04 - val_mae: 0.0040\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.4140e-04 - mae: 0.0041 - val_loss: 4.3546e-04 - val_mae: 0.0036\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.3604e-04 - mae: 0.0039 - val_loss: 4.4190e-04 - val_mae: 0.0044\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.3690e-04 - mae: 0.0042 - val_loss: 4.3371e-04 - val_mae: 0.0039\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.3142e-04 - mae: 0.0039 - val_loss: 4.3086e-04 - val_mae: 0.0039\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.3042e-04 - mae: 0.0040 - val_loss: 4.2662e-04 - val_mae: 0.0036\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.2934e-04 - mae: 0.0041 - val_loss: 4.2693e-04 - val_mae: 0.0038\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.2826e-04 - mae: 0.0041 - val_loss: 4.6576e-04 - val_mae: 0.0068\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.2442e-04 - mae: 0.0040 - val_loss: 4.2115e-04 - val_mae: 0.0037\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.2207e-04 - mae: 0.0040 - val_loss: 4.2270e-04 - val_mae: 0.0040\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.1903e-04 - mae: 0.0039 - val_loss: 4.1627e-04 - val_mae: 0.0036\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.1750e-04 - mae: 0.0039 - val_loss: 4.2184e-04 - val_mae: 0.0042\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.1638e-04 - mae: 0.0040 - val_loss: 4.1879e-04 - val_mae: 0.0044\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.1296e-04 - mae: 0.0039 - val_loss: 4.1075e-04 - val_mae: 0.0037\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.1423e-04 - mae: 0.0042 - val_loss: 4.0695e-04 - val_mae: 0.0035\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.0838e-04 - mae: 0.0039 - val_loss: 4.0678e-04 - val_mae: 0.0036\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.0693e-04 - mae: 0.0039 - val_loss: 4.0911e-04 - val_mae: 0.0042\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.0627e-04 - mae: 0.0040 - val_loss: 4.0543e-04 - val_mae: 0.0039\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.0564e-04 - mae: 0.0041 - val_loss: 4.0792e-04 - val_mae: 0.0044\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.0230e-04 - mae: 0.0040 - val_loss: 4.0333e-04 - val_mae: 0.0042\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 4.0119e-04 - mae: 0.0040 - val_loss: 4.2092e-04 - val_mae: 0.0058\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.9866e-04 - mae: 0.0040 - val_loss: 4.0622e-04 - val_mae: 0.0046\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.9784e-04 - mae: 0.0041 - val_loss: 3.9549e-04 - val_mae: 0.0038\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.9756e-04 - mae: 0.0042 - val_loss: 3.9192e-04 - val_mae: 0.0037\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.9484e-04 - mae: 0.0041 - val_loss: 3.8921e-04 - val_mae: 0.0035\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.9126e-04 - mae: 0.0039 - val_loss: 3.9222e-04 - val_mae: 0.0040\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.8776e-04 - mae: 0.0037 - val_loss: 3.8927e-04 - val_mae: 0.0038\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.8967e-04 - mae: 0.0040 - val_loss: 3.8875e-04 - val_mae: 0.0040\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.8761e-04 - mae: 0.0040 - val_loss: 3.8647e-04 - val_mae: 0.0039\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.8546e-04 - mae: 0.0040 - val_loss: 3.8462e-04 - val_mae: 0.0038\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.8488e-04 - mae: 0.0040 - val_loss: 3.7923e-04 - val_mae: 0.0034\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.8116e-04 - mae: 0.0039 - val_loss: 3.7757e-04 - val_mae: 0.0035\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.8159e-04 - mae: 0.0040 - val_loss: 3.7848e-04 - val_mae: 0.0038\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.7671e-04 - mae: 0.0038 - val_loss: 3.7453e-04 - val_mae: 0.0035\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.7800e-04 - mae: 0.0040 - val_loss: 3.7411e-04 - val_mae: 0.0036\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.7570e-04 - mae: 0.0039 - val_loss: 3.8408e-04 - val_mae: 0.0047\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.7383e-04 - mae: 0.0039 - val_loss: 3.7214e-04 - val_mae: 0.0037\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.7079e-04 - mae: 0.0038 - val_loss: 3.7016e-04 - val_mae: 0.0037\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.7081e-04 - mae: 0.0039 - val_loss: 3.7013e-04 - val_mae: 0.0038\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.6767e-04 - mae: 0.0038 - val_loss: 3.7081e-04 - val_mae: 0.0040\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.6718e-04 - mae: 0.0039 - val_loss: 3.6381e-04 - val_mae: 0.0034\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.6753e-04 - mae: 0.0040 - val_loss: 3.9641e-04 - val_mae: 0.0062\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.6569e-04 - mae: 0.0040 - val_loss: 3.6414e-04 - val_mae: 0.0038\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.6298e-04 - mae: 0.0039 - val_loss: 3.5997e-04 - val_mae: 0.0035\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.6274e-04 - mae: 0.0040 - val_loss: 3.6084e-04 - val_mae: 0.0036\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.6028e-04 - mae: 0.0039 - val_loss: 3.6002e-04 - val_mae: 0.0038\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.5899e-04 - mae: 0.0039 - val_loss: 3.6049e-04 - val_mae: 0.0040\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.5874e-04 - mae: 0.0040 - val_loss: 3.5883e-04 - val_mae: 0.0040\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.5665e-04 - mae: 0.0040 - val_loss: 3.5187e-04 - val_mae: 0.0035\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.5477e-04 - mae: 0.0039 - val_loss: 3.5990e-04 - val_mae: 0.0042\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.5340e-04 - mae: 0.0039 - val_loss: 3.4997e-04 - val_mae: 0.0035\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.5312e-04 - mae: 0.0040 - val_loss: 3.4841e-04 - val_mae: 0.0035\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.5085e-04 - mae: 0.0039 - val_loss: 3.5933e-04 - val_mae: 0.0047\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.5166e-04 - mae: 0.0041 - val_loss: 3.4615e-04 - val_mae: 0.0035\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.4815e-04 - mae: 0.0039 - val_loss: 3.5582e-04 - val_mae: 0.0044\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.4733e-04 - mae: 0.0039 - val_loss: 3.4371e-04 - val_mae: 0.0036\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.4537e-04 - mae: 0.0039 - val_loss: 3.4257e-04 - val_mae: 0.0036\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.4485e-04 - mae: 0.0039 - val_loss: 3.4680e-04 - val_mae: 0.0040\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.4507e-04 - mae: 0.0040 - val_loss: 3.3992e-04 - val_mae: 0.0035\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.4127e-04 - mae: 0.0038 - val_loss: 3.4228e-04 - val_mae: 0.0038\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.4230e-04 - mae: 0.0040 - val_loss: 3.6805e-04 - val_mae: 0.0061\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.4105e-04 - mae: 0.0040 - val_loss: 3.3645e-04 - val_mae: 0.0035\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.3930e-04 - mae: 0.0040 - val_loss: 3.3942e-04 - val_mae: 0.0037\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.3601e-04 - mae: 0.0037 - val_loss: 3.4084e-04 - val_mae: 0.0041\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.3483e-04 - mae: 0.0038 - val_loss: 3.3470e-04 - val_mae: 0.0037\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.3588e-04 - mae: 0.0039 - val_loss: 3.3125e-04 - val_mae: 0.0034\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.3643e-04 - mae: 0.0041 - val_loss: 3.3340e-04 - val_mae: 0.0038\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.3357e-04 - mae: 0.0039 - val_loss: 3.3463e-04 - val_mae: 0.0039\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.3091e-04 - mae: 0.0038 - val_loss: 3.3152e-04 - val_mae: 0.0037\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.2933e-04 - mae: 0.0037 - val_loss: 3.2900e-04 - val_mae: 0.0036\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.2995e-04 - mae: 0.0039 - val_loss: 3.3468e-04 - val_mae: 0.0042\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.2900e-04 - mae: 0.0039 - val_loss: 3.2769e-04 - val_mae: 0.0038\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.2819e-04 - mae: 0.0039 - val_loss: 3.2519e-04 - val_mae: 0.0037\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.2731e-04 - mae: 0.0040 - val_loss: 3.3996e-04 - val_mae: 0.0049\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.2684e-04 - mae: 0.0040 - val_loss: 3.2557e-04 - val_mae: 0.0039\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.2392e-04 - mae: 0.0038 - val_loss: 3.2561e-04 - val_mae: 0.0039\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.2332e-04 - mae: 0.0039 - val_loss: 3.3221e-04 - val_mae: 0.0047\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.2131e-04 - mae: 0.0038 - val_loss: 3.1817e-04 - val_mae: 0.0034\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 1s 4ms/step - loss: 3.2208e-04 - mae: 0.0039 - val_loss: 3.2293e-04 - val_mae: 0.0039\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.2010e-04 - mae: 0.0039 - val_loss: 3.1640e-04 - val_mae: 0.0034\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.1844e-04 - mae: 0.0038 - val_loss: 3.2348e-04 - val_mae: 0.0042\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.1966e-04 - mae: 0.0040 - val_loss: 3.2083e-04 - val_mae: 0.0040\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.1698e-04 - mae: 0.0038 - val_loss: 3.1450e-04 - val_mae: 0.0035\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.1735e-04 - mae: 0.0040 - val_loss: 3.1215e-04 - val_mae: 0.0034\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.1503e-04 - mae: 0.0038 - val_loss: 3.1655e-04 - val_mae: 0.0038\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.1318e-04 - mae: 0.0038 - val_loss: 3.1117e-04 - val_mae: 0.0034\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.1505e-04 - mae: 0.0040 - val_loss: 3.1014e-04 - val_mae: 0.0035\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.1250e-04 - mae: 0.0039 - val_loss: 3.2102e-04 - val_mae: 0.0046\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.1225e-04 - mae: 0.0039 - val_loss: 3.1004e-04 - val_mae: 0.0036\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.1134e-04 - mae: 0.0039 - val_loss: 3.0973e-04 - val_mae: 0.0036\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.0956e-04 - mae: 0.0038 - val_loss: 3.1051e-04 - val_mae: 0.0038\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.0992e-04 - mae: 0.0039 - val_loss: 3.3641e-04 - val_mae: 0.0058\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.0903e-04 - mae: 0.0039 - val_loss: 3.1161e-04 - val_mae: 0.0041\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.0891e-04 - mae: 0.0040 - val_loss: 3.0398e-04 - val_mae: 0.0034\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.0741e-04 - mae: 0.0039 - val_loss: 3.0664e-04 - val_mae: 0.0038\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.0337e-04 - mae: 0.0037 - val_loss: 3.0113e-04 - val_mae: 0.0034\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.0472e-04 - mae: 0.0039 - val_loss: 3.1218e-04 - val_mae: 0.0044\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.0296e-04 - mae: 0.0038 - val_loss: 3.0237e-04 - val_mae: 0.0037\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.0376e-04 - mae: 0.0039 - val_loss: 3.0267e-04 - val_mae: 0.0037\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.0189e-04 - mae: 0.0038 - val_loss: 3.0265e-04 - val_mae: 0.0038\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.0219e-04 - mae: 0.0039 - val_loss: 2.9996e-04 - val_mae: 0.0036\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.0288e-04 - mae: 0.0040 - val_loss: 2.9925e-04 - val_mae: 0.0036\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.9921e-04 - mae: 0.0038 - val_loss: 2.9821e-04 - val_mae: 0.0036\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.9875e-04 - mae: 0.0038 - val_loss: 2.9973e-04 - val_mae: 0.0038\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 3.0111e-04 - mae: 0.0040 - val_loss: 2.9555e-04 - val_mae: 0.0035\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.9600e-04 - mae: 0.0037 - val_loss: 2.9393e-04 - val_mae: 0.0035\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.9526e-04 - mae: 0.0037 - val_loss: 2.9694e-04 - val_mae: 0.0039\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.9469e-04 - mae: 0.0038 - val_loss: 2.9486e-04 - val_mae: 0.0037\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.9501e-04 - mae: 0.0038 - val_loss: 3.0139e-04 - val_mae: 0.0043\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.9563e-04 - mae: 0.0039 - val_loss: 2.9266e-04 - val_mae: 0.0036\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.9221e-04 - mae: 0.0037 - val_loss: 2.9154e-04 - val_mae: 0.0036\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.9484e-04 - mae: 0.0040 - val_loss: 3.0364e-04 - val_mae: 0.0047\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.9131e-04 - mae: 0.0038 - val_loss: 2.9026e-04 - val_mae: 0.0037\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.9131e-04 - mae: 0.0039 - val_loss: 3.1433e-04 - val_mae: 0.0056\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.9228e-04 - mae: 0.0040 - val_loss: 2.9488e-04 - val_mae: 0.0042\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.9003e-04 - mae: 0.0038 - val_loss: 3.0729e-04 - val_mae: 0.0054\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.8913e-04 - mae: 0.0038 - val_loss: 2.8821e-04 - val_mae: 0.0038\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.8796e-04 - mae: 0.0038 - val_loss: 2.9840e-04 - val_mae: 0.0047\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.8724e-04 - mae: 0.0038 - val_loss: 2.9360e-04 - val_mae: 0.0045\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.8679e-04 - mae: 0.0038 - val_loss: 2.8304e-04 - val_mae: 0.0033\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.8790e-04 - mae: 0.0040 - val_loss: 2.8901e-04 - val_mae: 0.0038\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.8537e-04 - mae: 0.0038 - val_loss: 2.8199e-04 - val_mae: 0.0034\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.8546e-04 - mae: 0.0039 - val_loss: 2.8246e-04 - val_mae: 0.0035\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.8364e-04 - mae: 0.0038 - val_loss: 2.8731e-04 - val_mae: 0.0041\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.8666e-04 - mae: 0.0041 - val_loss: 2.8184e-04 - val_mae: 0.0035\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.8117e-04 - mae: 0.0037 - val_loss: 2.9342e-04 - val_mae: 0.0047\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.8269e-04 - mae: 0.0039 - val_loss: 2.7873e-04 - val_mae: 0.0035\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.8213e-04 - mae: 0.0039 - val_loss: 2.8175e-04 - val_mae: 0.0038\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.8172e-04 - mae: 0.0039 - val_loss: 2.8209e-04 - val_mae: 0.0039\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.7955e-04 - mae: 0.0038 - val_loss: 2.7934e-04 - val_mae: 0.0037\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.8024e-04 - mae: 0.0039 - val_loss: 2.7910e-04 - val_mae: 0.0036\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.7794e-04 - mae: 0.0037 - val_loss: 2.7705e-04 - val_mae: 0.0035\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.7733e-04 - mae: 0.0037 - val_loss: 2.7399e-04 - val_mae: 0.0033\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 1s 6ms/step - loss: 2.7859e-04 - mae: 0.0039 - val_loss: 2.7806e-04 - val_mae: 0.0037\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.7702e-04 - mae: 0.0038 - val_loss: 2.7690e-04 - val_mae: 0.0037\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.7782e-04 - mae: 0.0039 - val_loss: 3.0956e-04 - val_mae: 0.0062\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.7757e-04 - mae: 0.0040 - val_loss: 2.7277e-04 - val_mae: 0.0035\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.7377e-04 - mae: 0.0037 - val_loss: 2.8170e-04 - val_mae: 0.0044\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 2s 6ms/step - loss: 2.7799e-04 - mae: 0.0041 - val_loss: 2.7252e-04 - val_mae: 0.0035\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.7409e-04 - mae: 0.0038 - val_loss: 2.7955e-04 - val_mae: 0.0044\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.7333e-04 - mae: 0.0038 - val_loss: 2.8249e-04 - val_mae: 0.0045\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.7431e-04 - mae: 0.0039 - val_loss: 2.7502e-04 - val_mae: 0.0039\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.7339e-04 - mae: 0.0039 - val_loss: 2.7191e-04 - val_mae: 0.0037\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.7384e-04 - mae: 0.0040 - val_loss: 3.0737e-04 - val_mae: 0.0066\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.6998e-04 - mae: 0.0037 - val_loss: 2.7353e-04 - val_mae: 0.0040\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.6968e-04 - mae: 0.0037 - val_loss: 2.7202e-04 - val_mae: 0.0038\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.7024e-04 - mae: 0.0038 - val_loss: 2.6648e-04 - val_mae: 0.0034\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.6876e-04 - mae: 0.0038 - val_loss: 2.6794e-04 - val_mae: 0.0036\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.7182e-04 - mae: 0.0041 - val_loss: 2.7053e-04 - val_mae: 0.0040\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.6895e-04 - mae: 0.0039 - val_loss: 2.6801e-04 - val_mae: 0.0037\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.6728e-04 - mae: 0.0038 - val_loss: 2.7102e-04 - val_mae: 0.0040\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.6890e-04 - mae: 0.0039 - val_loss: 2.6514e-04 - val_mae: 0.0035\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.7083e-04 - mae: 0.0041 - val_loss: 2.6899e-04 - val_mae: 0.0038\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.6764e-04 - mae: 0.0039 - val_loss: 2.7362e-04 - val_mae: 0.0044\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.6633e-04 - mae: 0.0038 - val_loss: 2.6702e-04 - val_mae: 0.0038\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.6552e-04 - mae: 0.0038 - val_loss: 2.7232e-04 - val_mae: 0.0042\n",
      "Epoch 436/1000\n",
      "263/270 [============================>.] - ETA: 0s - loss: 2.6424e-04 - mae: 0.0037Restoring model weights from the end of the best epoch: 431.\n",
      "270/270 [==============================] - 1s 5ms/step - loss: 2.6410e-04 - mae: 0.0038 - val_loss: 2.7178e-04 - val_mae: 0.0044\n",
      "Epoch 436: early stopping\n",
      "Durchschnittlicher Validation Loss: 0.00031966681126505136\n",
      "Durchschnittlicher Validation MAE: 0.003432324714958668\n"
     ]
    }
   ],
   "source": [
    "# Initialisiere Listen, um Ergebnisse zu speichern\n",
    "val_loss_results = []\n",
    "val_mae_results = []\n",
    "\n",
    "# Funktion, um das Modell zu erstellen\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "    Dense(248, activation='relu', input_shape=(5,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(184, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(248, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(264, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(8, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(1 , activation = 'linear')\n",
    "\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# K-Fold Cross-Validation Konfiguration\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Leistungsüberwachung\n",
    "fold_no = 1\n",
    "for train_index, val_index in kf.split(X_train_scaled):\n",
    "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_scaled[train_index], y_train_scaled[val_index]\n",
    "\n",
    "    model = create_model()\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "    print(f'Training für Fold {fold_no}...')\n",
    "    history = model.fit(X_train_fold, y_train_fold, batch_size=200, epochs=1000, validation_data=(X_val_fold, y_val_fold), callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "    # Speichere die Ergebnisse des aktuellen Folds\n",
    "    val_loss_results.append(min(history.history['val_loss']))\n",
    "    val_mae_results.append(min(history.history['val_mae']))\n",
    "\n",
    "    fold_no += 1\n",
    "\n",
    "# Berechne den Durchschnitt über alle Folds\n",
    "average_val_loss = np.mean(val_loss_results)\n",
    "average_val_mae = np.mean(val_mae_results)\n",
    "\n",
    "# Umwandeln der Listen in Pandas DataFrames\n",
    "val_loss_df = pd.DataFrame(val_loss_results, columns=['Validation Loss'])\n",
    "val_mae_df = pd.DataFrame(val_mae_results, columns=['Validation MAE'])\n",
    "\n",
    "# Speichern der DataFrames in CSV-Dateien\n",
    "val_loss_df.to_csv('val_loss_results_D4_t_I_F_1.csv', index=False)\n",
    "val_mae_df.to_csv('val_mae_results_D4_t_I_F_1.csv', index=False)\n",
    "\n",
    "# Gib die durchschnittlichen Ergebnisse aus\n",
    "print(f'Durchschnittlicher Validation Loss: {average_val_loss}')\n",
    "print(f'Durchschnittlicher Validation MAE: {average_val_mae}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T09:51:05.424148Z",
     "start_time": "2024-04-02T09:05:41.667152800Z"
    }
   },
   "id": "929336b1a7ac475d"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 - 0s - loss: 2.4222e-04 - mae: 0.0039 - 43ms/epoch - 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.0002422189136268571, 0.0038872624281793833]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test_scaled_2, y_test_scaled_2, verbose=2)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T10:31:07.595222100Z",
     "start_time": "2024-04-02T10:31:07.512641200Z"
    }
   },
   "id": "4b02697cbcecd185"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bsp. Predicted: [778.0962] Actual: [754.68] \n",
      "Durchschnittliche Abweichung (MAE): [8.62162608]\n",
      "0.6228628528250221\n"
     ]
    }
   ],
   "source": [
    "scaled_predicted_values = model.predict(X_test_scaled_2, verbose = 0)\n",
    "\n",
    "# Führen Sie die Rücktransformation der skalierten Werte durch\n",
    "original_predicted_values = scaler_target.inverse_transform(scaled_predicted_values)\n",
    "original_actual_values = scaler_target.inverse_transform(y_test_scaled_2)  # y_test sind die skalierten tatsächlichen Werte\n",
    "print(f' Bsp. Predicted: {original_predicted_values[100]} Actual: {original_actual_values[100]} ')\n",
    "\n",
    "def calculate_mae(list1, list2):\n",
    "    # Stelle sicher, dass beide Listen die gleiche Länge haben\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Listen müssen die gleiche Länge haben\")\n",
    "\n",
    "    # Berechne die absolute Differenz zwischen den Elementen der Listen\n",
    "    differences = [abs(x - y) for x, y in zip(list1, list2)]\n",
    "\n",
    "    # Berechne den Durchschnitt der absoluten Differenzen\n",
    "    mae = sum(differences) / len(differences)\n",
    "\n",
    "    return mae\n",
    "\n",
    "# Beispiel\n",
    "list1 = original_predicted_values\n",
    "list2 = original_actual_values\n",
    "\n",
    "mae = calculate_mae(list1, list2)\n",
    "print(f\"Durchschnittliche Abweichung (MAE): {mae}\")\n",
    "errors = np.abs((original_actual_values - original_predicted_values) / original_actual_values)\n",
    "mape = np.mean(errors) * 100\n",
    "print(mape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T10:31:11.265765600Z",
     "start_time": "2024-04-02T10:31:11.129479100Z"
    }
   },
   "id": "a402d28abbd82f60"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Werte die kleiner sind: 1063\n"
     ]
    },
    {
     "data": {
      "text/plain": "             Echt  Vorhergesagt  X-Koordinate  Y-Koordinate  Zeitpunkt  \\\n1049  1637.294312       1677.50          1.00          0.58        1.0   \n1048  1650.624023       1690.00          1.00          0.56        1.0   \n1050  1624.779419       1662.20          1.00          0.60        1.0   \n1047  1662.904419       1699.70          1.00          0.54        1.0   \n998   1667.599121       1704.30          0.95          0.58        1.0   \n...           ...           ...           ...           ...        ...   \n202    775.587402        753.72          0.15          0.98        1.0   \n1069   730.569092        708.11          1.00          0.98        1.0   \n151    776.837646        754.33          0.10          0.98        1.0   \n100    778.096191        754.68          0.05          0.98        1.0   \n49     779.646790        754.80          0.00          0.98        1.0   \n\n         Strom  Kraft  Differenz  \n1049  0.333333   0.25 -40.205688  \n1048  0.333333   0.25 -39.375977  \n1050  0.333333   0.25 -37.420581  \n1047  0.333333   0.25 -36.795581  \n998   0.333333   0.25 -36.700879  \n...        ...    ...        ...  \n202   0.333333   0.25  21.867402  \n1069  0.333333   0.25  22.459092  \n151   0.333333   0.25  22.507646  \n100   0.333333   0.25  23.416191  \n49    0.333333   0.25  24.846790  \n\n[1071 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Echt</th>\n      <th>Vorhergesagt</th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Differenz</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1049</th>\n      <td>1637.294312</td>\n      <td>1677.50</td>\n      <td>1.00</td>\n      <td>0.58</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.25</td>\n      <td>-40.205688</td>\n    </tr>\n    <tr>\n      <th>1048</th>\n      <td>1650.624023</td>\n      <td>1690.00</td>\n      <td>1.00</td>\n      <td>0.56</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.25</td>\n      <td>-39.375977</td>\n    </tr>\n    <tr>\n      <th>1050</th>\n      <td>1624.779419</td>\n      <td>1662.20</td>\n      <td>1.00</td>\n      <td>0.60</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.25</td>\n      <td>-37.420581</td>\n    </tr>\n    <tr>\n      <th>1047</th>\n      <td>1662.904419</td>\n      <td>1699.70</td>\n      <td>1.00</td>\n      <td>0.54</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.25</td>\n      <td>-36.795581</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>1667.599121</td>\n      <td>1704.30</td>\n      <td>0.95</td>\n      <td>0.58</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.25</td>\n      <td>-36.700879</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>202</th>\n      <td>775.587402</td>\n      <td>753.72</td>\n      <td>0.15</td>\n      <td>0.98</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.25</td>\n      <td>21.867402</td>\n    </tr>\n    <tr>\n      <th>1069</th>\n      <td>730.569092</td>\n      <td>708.11</td>\n      <td>1.00</td>\n      <td>0.98</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.25</td>\n      <td>22.459092</td>\n    </tr>\n    <tr>\n      <th>151</th>\n      <td>776.837646</td>\n      <td>754.33</td>\n      <td>0.10</td>\n      <td>0.98</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.25</td>\n      <td>22.507646</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>778.096191</td>\n      <td>754.68</td>\n      <td>0.05</td>\n      <td>0.98</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.25</td>\n      <td>23.416191</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>779.646790</td>\n      <td>754.80</td>\n      <td>0.00</td>\n      <td>0.98</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.25</td>\n      <td>24.846790</td>\n    </tr>\n  </tbody>\n</table>\n<p>1071 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame({'Echt': [val[0] for val in list1], 'Vorhergesagt': [val[0] for val in list2]})\n",
    "df_result['X-Koordinate'] = X_test_scaled_2[:, 0]\n",
    "df_result['Y-Koordinate'] = X_test_scaled_2[:, 1]\n",
    "df_result['Zeitpunkt'] = X_test_scaled_2[:, 2]\n",
    "df_result['Strom'] = X_test_scaled_2[:, 3]\n",
    "df_result['Kraft'] = X_test_scaled_2[:, 4]\n",
    "\n",
    "df_result['Differenz'] = df_result['Echt'] - df_result['Vorhergesagt']\n",
    "df_result['Differenz'].sort_values()\n",
    "sorted_df = df_result.sort_values(by= 'Differenz')\n",
    "Anzahl_Punkte = (sorted_df['Differenz'] < 20).sum()\n",
    "print(\"Anzahl der Werte die kleiner sind:\", Anzahl_Punkte)\n",
    "\n",
    "sorted_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T10:32:05.493726800Z",
     "start_time": "2024-04-02T10:32:05.461134100Z"
    }
   },
   "id": "7ffe8ddf2200f429"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: [0.99989271]\n"
     ]
    }
   ],
   "source": [
    "#Berechnung der Auswertungsgröße R^2\n",
    "\n",
    "def calculate_r_squared(predicted, actual):\n",
    "    # Berechnung des Mittelwerts der tatsächlichen Werte\n",
    "    mean_actual = sum(actual) / len(actual)\n",
    "    \n",
    "    # Berechnung der totalen Summe der Quadrate (SST)\n",
    "    sst = sum((x - mean_actual) ** 2 for x in actual)\n",
    "    \n",
    "    # Berechnung der Summe der Quadrate der Residuen (SSE)\n",
    "    sse = sum((actual[i] - predicted[i]) ** 2 for i in range(len(actual)))\n",
    "    \n",
    "    # Berechnung des R^2-Wertes\n",
    "    r_squared = 1 - (sse / sst)\n",
    "    \n",
    "    return r_squared\n",
    "\n",
    "# Berechnung von R^2 mit den bereitgestellten Listen\n",
    "r_squared = calculate_r_squared(list1, list2)\n",
    "\n",
    "print(f\"R^2: {r_squared}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T13:59:02.256620900Z",
     "start_time": "2024-03-26T13:59:01.728316700Z"
    }
   },
   "id": "4c350477801f0961"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mae = history.history['loss']\n",
    "val_mae = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(mae) + 1)\n",
    "\n",
    "# MAE Diagramm\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, mae, 'r', label='Training MSE')\n",
    "plt.plot(epochs, val_mae, 'b', label='Validation MSE')\n",
    "plt.title('Training and Validation MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T12:29:07.617414Z",
     "start_time": "2024-03-25T12:29:07.401346700Z"
    }
   },
   "id": "3688dd7102e95baf"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mae = history.history['mae']\n",
    "val_mae = history.history['val_mae']\n",
    "\n",
    "epochs = range(1, len(mae) + 1)\n",
    "\n",
    "# MAE Diagramm\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, mae, 'r', label='Training MAE')\n",
    "plt.plot(epochs, val_mae, 'b', label='Validation MAE')\n",
    "plt.title('Training and Validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "#plt.ylim(0.00, 0.01)\n",
    "\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T12:29:10.425247700Z",
     "start_time": "2024-03-25T12:29:10.293470600Z"
    }
   },
   "id": "b8d71e5c44c48bef"
  },
  {
   "cell_type": "markdown",
   "id": "553df6fa",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x000001B625802E50>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 770, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 47\u001B[0m\n\u001B[0;32m     45\u001B[0m grid_search \u001B[38;5;241m=\u001B[39m GridSearchCV(estimator\u001B[38;5;241m=\u001B[39mmodel, param_grid\u001B[38;5;241m=\u001B[39mparam_grid, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m     46\u001B[0m \u001B[38;5;66;03m# Hinweis: Stellen Sie sicher, dass Ihre Daten (X_train_scaled, y_train_scaled) korrekt definiert sind\u001B[39;00m\n\u001B[1;32m---> 47\u001B[0m grid_result \u001B[38;5;241m=\u001B[39m \u001B[43mgrid_search\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_scaled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train_scaled\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;66;03m# Beste Parameter und Score ausgeben\u001B[39;00m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBeste Parameter:\u001B[39m\u001B[38;5;124m\"\u001B[39m, grid_search\u001B[38;5;241m.\u001B[39mbest_params_)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\base.py:1351\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1344\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1346\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1347\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1348\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1349\u001B[0m     )\n\u001B[0;32m   1350\u001B[0m ):\n\u001B[1;32m-> 1351\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, **params)\u001B[0m\n\u001B[0;32m    964\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m    965\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m    966\u001B[0m     )\n\u001B[0;32m    968\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m--> 970\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    972\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m    973\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m    974\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1525\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1526\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1527\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    908\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    909\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m    910\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    911\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    912\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[0;32m    913\u001B[0m         )\n\u001B[0;32m    914\u001B[0m     )\n\u001B[1;32m--> 916\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    917\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    918\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    919\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    920\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    921\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    922\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    923\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    924\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    925\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    926\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    927\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    928\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    929\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    930\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrouted_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplitter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    931\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    932\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    934\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    935\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    936\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    937\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    938\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    939\u001B[0m     )\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     62\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     63\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     64\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     66\u001B[0m )\n\u001B[1;32m---> 67\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\joblib\\parallel.py:1952\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1946\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[0;32m   1947\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[0;32m   1948\u001B[0m \u001B[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001B[39;00m\n\u001B[0;32m   1949\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[0;32m   1950\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 1952\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\joblib\\parallel.py:1595\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[1;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[0;32m   1592\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[0;32m   1594\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[1;32m-> 1595\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[0;32m   1597\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[0;32m   1598\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[0;32m   1599\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[0;32m   1600\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[0;32m   1601\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\joblib\\parallel.py:1707\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1702\u001B[0m \u001B[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001B[39;00m\n\u001B[0;32m   1703\u001B[0m \u001B[38;5;66;03m# async callbacks to progress.\u001B[39;00m\n\u001B[0;32m   1704\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ((\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m   1705\u001B[0m     (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mget_status(\n\u001B[0;32m   1706\u001B[0m         timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout) \u001B[38;5;241m==\u001B[39m TASK_PENDING)):\n\u001B[1;32m-> 1707\u001B[0m     time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m0.01\u001B[39m)\n\u001B[0;32m   1708\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m   1710\u001B[0m \u001B[38;5;66;03m# We need to be careful: the job list can be filling up as\u001B[39;00m\n\u001B[0;32m   1711\u001B[0m \u001B[38;5;66;03m# we empty it and Python list are not thread-safe by\u001B[39;00m\n\u001B[0;32m   1712\u001B[0m \u001B[38;5;66;03m# default hence the use of the lock\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def build_model(learning_rate=0.00001, activation='relu', regularization=0.00001, dropout_rate=0.0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(232, activation=activation, input_shape=(3,), kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(152, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(232, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Verwenden Sie eine Funktion, um das Modell zu instanziieren, für scikit-learn Wrapper\n",
    "model = KerasRegressor(model=build_model, verbose=2, callbacks=[early_stopping])\n",
    "\n",
    "# Anpassung der Parameter im param_grid\n",
    "param_grid = {\n",
    "    'model__learning_rate': [0.00001],\n",
    "    'model__regularization': [0.00001],\n",
    "    'fit__batch_size': [16, 32, 64, 100],\n",
    "    'fit__epochs': [100],\n",
    "    'model__dropout_rate' : [0.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=2)\n",
    "# Hinweis: Stellen Sie sicher, dass Ihre Daten (X_train_scaled, y_train_scaled) korrekt definiert sind\n",
    "grid_result = grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "# Beste Parameter und Score ausgeben\n",
    "print(\"Beste Parameter:\", grid_search.best_params_)\n",
    "print(\"Beste Genauigkeit:\", grid_search.best_score_)\n",
    "\n",
    "with open(\"Gridsearch_D4_t_1.txt\", \"w\") as f:\n",
    "    f.write(f\"Beste Parameter: {grid_search.best_params_}\\n\")\n",
    "    f.write(f\"Beste Genauigkeit: {grid_search.best_score_}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T12:15:54.960082300Z",
     "start_time": "2024-03-18T11:56:34.729533600Z"
    }
   },
   "id": "7464a951f44a07ee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Funktion zum Erstellen des Modells\n",
    "# def build_model(hp):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(hp.Int('input_units', min_value=8, max_value=328, step=16), input_shape=(3,), activation='relu'))\n",
    "#     for i in range(hp.Int('n_layers', 1, 10)):\n",
    "#         model.add(Dense(hp.Int(f'units_{i}', min_value=8, max_value=328, step=16), activation='relu'))\n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     return modeDer\n",
    "# \n",
    "# # Durchführung der Random Search dreimal\n",
    "# for run in range(1, 4):\n",
    "#     # Anpassen des Verzeichnisses und des Projektnamens für jeden Durchlauf\n",
    "#     directory = 'random_search'\n",
    "#     project_name = f'random_search_D4_t_1_{run}'\n",
    "# \n",
    "#     tuner = RandomSearch(\n",
    "#         build_model,\n",
    "#         objective='val_loss',\n",
    "#         max_trials=100,\n",
    "#         executions_per_trial=2,\n",
    "#         directory=directory,\n",
    "#         project_name=project_name\n",
    "#     )\n",
    "# \n",
    "#     # Durchführung des Random Search\n",
    "#     tuner.search(X_train_scaled, y_train_scaled, epochs=50, verbose =0, batch_size=50, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=5\n",
    "#     # Abrufen und Speichern des besten Modells\n",
    "#     best_model = tuner.get_best_models(num_models=1)[0]\n",
    "#     model_path = os.path.join(directory, project_name, 'best_model.h5') \n",
    "#     best_model.save(model_path)\n",
    "# \n",
    "# \n",
    "#     # Optional: Abrufen und Ausgeben der besten Hyperparameter\n",
    "#     best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "# \n",
    "#     # Konvertieren der Hyperparameter in ein DataFrame\n",
    "#     df_hyperparameters = pd.DataFrame([best_hyperparameters.values])\n",
    "#     # Speichern des DataFrame als CSV\n",
    "#     df_hyperparameters.to_csv(f'random_search_D4_t_1_{run}.csv', index=False)\n",
    "# \n",
    "#     print(f\"Beste Hyperparameter für Lauf {run}: {best_hyperparameters.values}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T10:03:46.649218900Z"
    }
   },
   "id": "d0f02feb42b652f5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T10:03:46.650224Z"
    }
   },
   "id": "3e35d5ebef369658"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
