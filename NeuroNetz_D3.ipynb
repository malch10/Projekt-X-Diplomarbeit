{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94b0518e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T09:47:16.024889800Z",
     "start_time": "2024-03-15T09:47:15.824779900Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense , Dropout\n",
    "from scikeras.wrappers import KerasRegressor \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4ff61b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T09:47:16.054861500Z",
     "start_time": "2024-03-15T09:47:15.834781200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n0          0.00000      -0.00200        500   7000   9000      669.05\n1          0.00000      -0.00196        500   7000   9000      696.80\n2          0.00000      -0.00192        500   7000   9000      724.42\n3          0.00000      -0.00188        500   7000   9000      751.84\n4          0.00000      -0.00184        500   7000   9000      779.83\n...            ...           ...        ...    ...    ...         ...\n6358       0.00248       0.00184        500   7000   9000      651.36\n6359       0.00248       0.00188        500   7000   9000      612.09\n6360       0.00248       0.00192        500   7000   9000      584.59\n6361       0.00248       0.00196        500   7000   9000      578.64\n6362       0.00248       0.00200        500   7000   9000      572.78\n\n[6363 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00000</td>\n      <td>-0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>669.05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00000</td>\n      <td>-0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>696.80</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00000</td>\n      <td>-0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>724.42</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00000</td>\n      <td>-0.00188</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>751.84</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00000</td>\n      <td>-0.00184</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>779.83</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6358</th>\n      <td>0.00248</td>\n      <td>0.00184</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>651.36</td>\n    </tr>\n    <tr>\n      <th>6359</th>\n      <td>0.00248</td>\n      <td>0.00188</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>612.09</td>\n    </tr>\n    <tr>\n      <th>6360</th>\n      <td>0.00248</td>\n      <td>0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>584.59</td>\n    </tr>\n    <tr>\n      <th>6361</th>\n      <td>0.00248</td>\n      <td>0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>578.64</td>\n    </tr>\n    <tr>\n      <th>6362</th>\n      <td>0.00248</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>572.78</td>\n    </tr>\n  </tbody>\n</table>\n<p>6363 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/TPath_300_finish_data.pkl')\n",
    "data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_D3_I7000_F9000/TPath_500_finish_data_D3.pkl')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "966e3c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T09:47:16.054861500Z",
     "start_time": "2024-03-15T09:47:15.846108900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      X-Koordinate  Y-Koordinate  Temperatur\n0          0.00000      -0.00200      669.05\n1          0.00000      -0.00196      696.80\n2          0.00000      -0.00192      724.42\n3          0.00000      -0.00188      751.84\n4          0.00000      -0.00184      779.83\n...            ...           ...         ...\n6358       0.00248       0.00184      651.36\n6359       0.00248       0.00188      612.09\n6360       0.00248       0.00192      584.59\n6361       0.00248       0.00196      578.64\n6362       0.00248       0.00200      572.78\n\n[6363 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00000</td>\n      <td>-0.00200</td>\n      <td>669.05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00000</td>\n      <td>-0.00196</td>\n      <td>696.80</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00000</td>\n      <td>-0.00192</td>\n      <td>724.42</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00000</td>\n      <td>-0.00188</td>\n      <td>751.84</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00000</td>\n      <td>-0.00184</td>\n      <td>779.83</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6358</th>\n      <td>0.00248</td>\n      <td>0.00184</td>\n      <td>651.36</td>\n    </tr>\n    <tr>\n      <th>6359</th>\n      <td>0.00248</td>\n      <td>0.00188</td>\n      <td>612.09</td>\n    </tr>\n    <tr>\n      <th>6360</th>\n      <td>0.00248</td>\n      <td>0.00192</td>\n      <td>584.59</td>\n    </tr>\n    <tr>\n      <th>6361</th>\n      <td>0.00248</td>\n      <td>0.00196</td>\n      <td>578.64</td>\n    </tr>\n    <tr>\n      <th>6362</th>\n      <td>0.00248</td>\n      <td>0.00200</td>\n      <td>572.78</td>\n    </tr>\n  </tbody>\n</table>\n<p>6363 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.drop(data.columns[2:5], axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8783d1d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T09:47:16.134410700Z",
     "start_time": "2024-03-15T09:47:15.855764100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      X-Koordinate  Y-Koordinate  Temperatur\n",
      "6243       0.00244       0.00128      978.37\n",
      "2949       0.00116      -0.00120     1193.00\n",
      "393        0.00012       0.00160      816.01\n",
      "3844       0.00152      -0.00176      827.43\n",
      "2154       0.00084      -0.00068     1419.40\n",
      "...            ...           ...         ...\n",
      "3772       0.00148      -0.00060     1381.60\n",
      "5191       0.00204      -0.00040     1320.60\n",
      "5226       0.00204       0.00100     1122.50\n",
      "5390       0.00212      -0.00052     1288.40\n",
      "860        0.00032       0.00008     1509.50\n",
      "\n",
      "[6363 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": "      X-Koordinate  Y-Koordinate  Temperatur\n0          0.00244       0.00128      978.37\n1          0.00116      -0.00120     1193.00\n2          0.00012       0.00160      816.01\n3          0.00152      -0.00176      827.43\n4          0.00084      -0.00068     1419.40\n...            ...           ...         ...\n6358       0.00148      -0.00060     1381.60\n6359       0.00204      -0.00040     1320.60\n6360       0.00204       0.00100     1122.50\n6361       0.00212      -0.00052     1288.40\n6362       0.00032       0.00008     1509.50\n\n[6363 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00244</td>\n      <td>0.00128</td>\n      <td>978.37</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00116</td>\n      <td>-0.00120</td>\n      <td>1193.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00012</td>\n      <td>0.00160</td>\n      <td>816.01</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00152</td>\n      <td>-0.00176</td>\n      <td>827.43</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00084</td>\n      <td>-0.00068</td>\n      <td>1419.40</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6358</th>\n      <td>0.00148</td>\n      <td>-0.00060</td>\n      <td>1381.60</td>\n    </tr>\n    <tr>\n      <th>6359</th>\n      <td>0.00204</td>\n      <td>-0.00040</td>\n      <td>1320.60</td>\n    </tr>\n    <tr>\n      <th>6360</th>\n      <td>0.00204</td>\n      <td>0.00100</td>\n      <td>1122.50</td>\n    </tr>\n    <tr>\n      <th>6361</th>\n      <td>0.00212</td>\n      <td>-0.00052</td>\n      <td>1288.40</td>\n    </tr>\n    <tr>\n      <th>6362</th>\n      <td>0.00032</td>\n      <td>0.00008</td>\n      <td>1509.50</td>\n    </tr>\n  </tbody>\n</table>\n<p>6363 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.sample(frac=1, random_state=42)  # Hier wird 42 als Random State verwendet, um die Ergebnisse reproduzierbar zu machen\n",
    "\n",
    "print(df1)\n",
    "df_reset = df1.reset_index(drop=True)\n",
    "df_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4e72a16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T09:47:16.134410700Z",
     "start_time": "2024-03-15T09:47:15.866550700Z"
    }
   },
   "outputs": [],
   "source": [
    "label = df_reset[\"Temperatur\"]\n",
    "# Korrektur: Verwenden Sie den Spaltennamen direkt, ohne Indexierung der columns-Eigenschaft\n",
    "df1 = df_reset.drop(\"Temperatur\", axis=1)\n",
    "X = df1\n",
    "y = label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7fa289a50d87423"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e694a236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T09:47:16.134410700Z",
     "start_time": "2024-03-15T09:47:15.871824300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      X-Koordinate  Y-Koordinate\n0          0.00244       0.00128\n1          0.00116      -0.00120\n2          0.00012       0.00160\n3          0.00152      -0.00176\n4          0.00084      -0.00068\n...            ...           ...\n6358       0.00148      -0.00060\n6359       0.00204      -0.00040\n6360       0.00204       0.00100\n6361       0.00212      -0.00052\n6362       0.00032       0.00008\n\n[6363 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00244</td>\n      <td>0.00128</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00116</td>\n      <td>-0.00120</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00012</td>\n      <td>0.00160</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00152</td>\n      <td>-0.00176</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00084</td>\n      <td>-0.00068</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6358</th>\n      <td>0.00148</td>\n      <td>-0.00060</td>\n    </tr>\n    <tr>\n      <th>6359</th>\n      <td>0.00204</td>\n      <td>-0.00040</td>\n    </tr>\n    <tr>\n      <th>6360</th>\n      <td>0.00204</td>\n      <td>0.00100</td>\n    </tr>\n    <tr>\n      <th>6361</th>\n      <td>0.00212</td>\n      <td>-0.00052</td>\n    </tr>\n    <tr>\n      <th>6362</th>\n      <td>0.00032</td>\n      <td>0.00008</td>\n    </tr>\n  </tbody>\n</table>\n<p>6363 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f3303b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T09:47:16.154864700Z",
     "start_time": "2024-03-15T09:47:15.879111900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0        978.37\n1       1193.00\n2        816.01\n3        827.43\n4       1419.40\n         ...   \n6358    1381.60\n6359    1320.60\n6360    1122.50\n6361    1288.40\n6362    1509.50\nName: Temperatur, Length: 6363, dtype: float64"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3ad8da0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T09:47:16.154864700Z",
     "start_time": "2024-03-15T09:47:15.886116400Z"
    }
   },
   "outputs": [],
   "source": [
    " # train_df enthält 80% der Daten, test_df enthält 20% der Daten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c705edb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T09:47:16.154864700Z",
     "start_time": "2024-03-15T09:47:15.891746300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialisiere einen MinMaxScaler für die Features\n",
    "scaler_features = MinMaxScaler()\n",
    "scaler_features2 = MinMaxScaler()\n",
    "# Skaliere X_train und X_test\n",
    "X_train_scaled = scaler_features.fit_transform(X_train)\n",
    "X_test_scaled = scaler_features.transform(X_test)  # Nutze gleiche Skalierungsparameter ohne das X_Test Informationen einfließen\n",
    "\n",
    "# Initialisiere einen SEPARATEN MinMaxScaler für das Ziel, wenn nötig\n",
    "scaler_target = MinMaxScaler()\n",
    "\n",
    "\n",
    "# Skaliere y_train und y_test. Beachte, dass y_train.reshape(-1, 1) verwendet wird, da MinMaxScaler \n",
    "# erwartet, dass die Eingaben als 2D-Arrays kommen, und Ziele normalerweise als 1D-Arrays vorliegen.\n",
    "y_train_scaled = scaler_target.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test_scaled = scaler_target.transform(y_test.values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbefe631e495b483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T09:47:16.154864700Z",
     "start_time": "2024-03-15T09:47:15.900100200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.96774194, 0.58      ],\n       [0.12903226, 0.07      ],\n       [0.03225806, 0.07      ],\n       ...,\n       [0.01612903, 0.25      ],\n       [0.67741935, 0.82      ],\n       [0.5483871 , 0.65      ]])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9999999999999999"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_scaled.max()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:47:16.154864700Z",
     "start_time": "2024-03-15T09:47:15.905311500Z"
    }
   },
   "id": "ce04ce43aac2242f"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "163/163 [==============================] - 3s 5ms/step - loss: 0.4889 - mae: 0.2923 - val_loss: 0.4246 - val_mae: 0.2348\n",
      "Epoch 2/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.3606 - mae: 0.1590 - val_loss: 0.3058 - val_mae: 0.0680\n",
      "Epoch 3/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.2906 - mae: 0.0528 - val_loss: 0.2767 - val_mae: 0.0431\n",
      "Epoch 4/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.2636 - mae: 0.0258 - val_loss: 0.2533 - val_mae: 0.0217\n",
      "Epoch 5/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.2448 - mae: 0.0154 - val_loss: 0.2376 - val_mae: 0.0221\n",
      "Epoch 6/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.2356 - mae: 0.0450 - val_loss: 0.2248 - val_mae: 0.0183\n",
      "Epoch 7/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.2193 - mae: 0.0134 - val_loss: 0.2142 - val_mae: 0.0078\n",
      "Epoch 8/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.2104 - mae: 0.0158 - val_loss: 0.2059 - val_mae: 0.0086\n",
      "Epoch 9/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.2028 - mae: 0.0147 - val_loss: 0.1996 - val_mae: 0.0175\n",
      "Epoch 10/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1989 - mae: 0.0317 - val_loss: 0.2117 - val_mae: 0.1061\n",
      "Epoch 11/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1913 - mae: 0.0164 - val_loss: 0.1886 - val_mae: 0.0189\n",
      "Epoch 12/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1863 - mae: 0.0141 - val_loss: 0.1839 - val_mae: 0.0137\n",
      "Epoch 13/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1820 - mae: 0.0147 - val_loss: 0.1812 - val_mae: 0.0311\n",
      "Epoch 14/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1783 - mae: 0.0165 - val_loss: 0.1758 - val_mae: 0.0076\n",
      "Epoch 15/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1748 - mae: 0.0198 - val_loss: 0.1725 - val_mae: 0.0151\n",
      "Epoch 16/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1707 - mae: 0.0111 - val_loss: 0.1689 - val_mae: 0.0082\n",
      "Epoch 17/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1677 - mae: 0.0141 - val_loss: 0.1659 - val_mae: 0.0121\n",
      "Epoch 18/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1643 - mae: 0.0101 - val_loss: 0.1626 - val_mae: 0.0080\n",
      "Epoch 19/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1612 - mae: 0.0092 - val_loss: 0.1596 - val_mae: 0.0073\n",
      "Epoch 20/500\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.1613 - mae: 0.0343 - val_loss: 0.1571 - val_mae: 0.0181\n",
      "Epoch 21/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1555 - mae: 0.0110 - val_loss: 0.1540 - val_mae: 0.0105\n",
      "Epoch 22/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1526 - mae: 0.0084 - val_loss: 0.1513 - val_mae: 0.0094\n",
      "Epoch 23/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1502 - mae: 0.0131 - val_loss: 0.1486 - val_mae: 0.0083\n",
      "Epoch 24/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1475 - mae: 0.0111 - val_loss: 0.1462 - val_mae: 0.0138\n",
      "Epoch 25/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1447 - mae: 0.0075 - val_loss: 0.1438 - val_mae: 0.0169\n",
      "Epoch 26/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1423 - mae: 0.0107 - val_loss: 0.1414 - val_mae: 0.0198\n",
      "Epoch 27/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1413 - mae: 0.0238 - val_loss: 0.1588 - val_mae: 0.0993\n",
      "Epoch 28/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1388 - mae: 0.0228 - val_loss: 0.1367 - val_mae: 0.0212\n",
      "Epoch 29/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1358 - mae: 0.0214 - val_loss: 0.1351 - val_mae: 0.0264\n",
      "Epoch 30/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1332 - mae: 0.0132 - val_loss: 0.1317 - val_mae: 0.0108\n",
      "Epoch 31/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1306 - mae: 0.0093 - val_loss: 0.1295 - val_mae: 0.0104\n",
      "Epoch 32/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1283 - mae: 0.0062 - val_loss: 0.1272 - val_mae: 0.0058\n",
      "Epoch 33/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1278 - mae: 0.0248 - val_loss: 0.1375 - val_mae: 0.0861\n",
      "Epoch 34/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1248 - mae: 0.0150 - val_loss: 0.1230 - val_mae: 0.0084\n",
      "Epoch 35/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1225 - mae: 0.0152 - val_loss: 0.1211 - val_mae: 0.0111\n",
      "Epoch 36/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1199 - mae: 0.0061 - val_loss: 0.1189 - val_mae: 0.0050\n",
      "Epoch 37/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1180 - mae: 0.0083 - val_loss: 0.1169 - val_mae: 0.0076\n",
      "Epoch 38/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1161 - mae: 0.0119 - val_loss: 0.1149 - val_mae: 0.0092\n",
      "Epoch 39/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1152 - mae: 0.0232 - val_loss: 0.1129 - val_mae: 0.0064\n",
      "Epoch 40/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1120 - mae: 0.0078 - val_loss: 0.1112 - val_mae: 0.0112\n",
      "Epoch 41/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1102 - mae: 0.0092 - val_loss: 0.1091 - val_mae: 0.0061\n",
      "Epoch 42/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1081 - mae: 0.0048 - val_loss: 0.1071 - val_mae: 0.0050\n",
      "Epoch 43/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1063 - mae: 0.0097 - val_loss: 0.1053 - val_mae: 0.0085\n",
      "Epoch 44/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1044 - mae: 0.0092 - val_loss: 0.1034 - val_mae: 0.0093\n",
      "Epoch 45/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1026 - mae: 0.0119 - val_loss: 0.1018 - val_mae: 0.0139\n",
      "Epoch 46/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1009 - mae: 0.0120 - val_loss: 0.1000 - val_mae: 0.0140\n",
      "Epoch 47/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0988 - mae: 0.0060 - val_loss: 0.0978 - val_mae: 0.0061\n",
      "Epoch 48/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0979 - mae: 0.0195 - val_loss: 0.0962 - val_mae: 0.0131\n",
      "Epoch 49/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0955 - mae: 0.0115 - val_loss: 0.0944 - val_mae: 0.0049\n",
      "Epoch 50/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0939 - mae: 0.0109 - val_loss: 0.0930 - val_mae: 0.0149\n",
      "Epoch 51/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0920 - mae: 0.0077 - val_loss: 0.0911 - val_mae: 0.0050\n",
      "Epoch 52/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0904 - mae: 0.0071 - val_loss: 0.0899 - val_mae: 0.0162\n",
      "Epoch 53/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0888 - mae: 0.0074 - val_loss: 0.0879 - val_mae: 0.0040\n",
      "Epoch 54/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0871 - mae: 0.0059 - val_loss: 0.0863 - val_mae: 0.0077\n",
      "Epoch 55/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0858 - mae: 0.0107 - val_loss: 0.0847 - val_mae: 0.0053\n",
      "Epoch 56/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0843 - mae: 0.0125 - val_loss: 0.0832 - val_mae: 0.0074\n",
      "Epoch 57/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0825 - mae: 0.0074 - val_loss: 0.0827 - val_mae: 0.0238\n",
      "Epoch 58/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0812 - mae: 0.0114 - val_loss: 0.0803 - val_mae: 0.0072\n",
      "Epoch 59/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0796 - mae: 0.0069 - val_loss: 0.0790 - val_mae: 0.0118\n",
      "Epoch 60/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0783 - mae: 0.0114 - val_loss: 0.0783 - val_mae: 0.0225\n",
      "Epoch 61/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0768 - mae: 0.0093 - val_loss: 0.0763 - val_mae: 0.0144\n",
      "Epoch 62/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0761 - mae: 0.0186 - val_loss: 0.0749 - val_mae: 0.0111\n",
      "Epoch 63/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0741 - mae: 0.0065 - val_loss: 0.0735 - val_mae: 0.0038\n",
      "Epoch 64/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0734 - mae: 0.0147 - val_loss: 0.0723 - val_mae: 0.0068\n",
      "Epoch 65/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0717 - mae: 0.0066 - val_loss: 0.0713 - val_mae: 0.0128\n",
      "Epoch 66/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0706 - mae: 0.0086 - val_loss: 0.0700 - val_mae: 0.0064\n",
      "Epoch 67/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0695 - mae: 0.0089 - val_loss: 0.0689 - val_mae: 0.0108\n",
      "Epoch 68/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0683 - mae: 0.0076 - val_loss: 0.0677 - val_mae: 0.0064\n",
      "Epoch 69/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0671 - mae: 0.0067 - val_loss: 0.0665 - val_mae: 0.0083\n",
      "Epoch 70/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0662 - mae: 0.0125 - val_loss: 0.0682 - val_mae: 0.0414\n",
      "Epoch 71/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0649 - mae: 0.0071 - val_loss: 0.0642 - val_mae: 0.0037\n",
      "Epoch 72/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0639 - mae: 0.0099 - val_loss: 0.0632 - val_mae: 0.0036\n",
      "Epoch 73/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0628 - mae: 0.0082 - val_loss: 0.0622 - val_mae: 0.0092\n",
      "Epoch 74/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0619 - mae: 0.0122 - val_loss: 0.0611 - val_mae: 0.0042\n",
      "Epoch 75/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0607 - mae: 0.0073 - val_loss: 0.0601 - val_mae: 0.0066\n",
      "Epoch 76/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0596 - mae: 0.0050 - val_loss: 0.0591 - val_mae: 0.0052\n",
      "Epoch 77/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0590 - mae: 0.0110 - val_loss: 0.0584 - val_mae: 0.0143\n",
      "Epoch 78/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0577 - mae: 0.0070 - val_loss: 0.0572 - val_mae: 0.0042\n",
      "Epoch 79/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0567 - mae: 0.0056 - val_loss: 0.0563 - val_mae: 0.0088\n",
      "Epoch 80/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0558 - mae: 0.0073 - val_loss: 0.0553 - val_mae: 0.0048\n",
      "Epoch 81/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0551 - mae: 0.0110 - val_loss: 0.0543 - val_mae: 0.0034\n",
      "Epoch 82/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0540 - mae: 0.0076 - val_loss: 0.0536 - val_mae: 0.0101\n",
      "Epoch 83/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0531 - mae: 0.0064 - val_loss: 0.0527 - val_mae: 0.0083\n",
      "Epoch 84/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0522 - mae: 0.0060 - val_loss: 0.0517 - val_mae: 0.0081\n",
      "Epoch 85/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0513 - mae: 0.0082 - val_loss: 0.0509 - val_mae: 0.0110\n",
      "Epoch 86/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0504 - mae: 0.0072 - val_loss: 0.0499 - val_mae: 0.0065\n",
      "Epoch 87/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0497 - mae: 0.0110 - val_loss: 0.0493 - val_mae: 0.0149\n",
      "Epoch 88/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0487 - mae: 0.0083 - val_loss: 0.0485 - val_mae: 0.0144\n",
      "Epoch 89/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0480 - mae: 0.0099 - val_loss: 0.0474 - val_mae: 0.0054\n",
      "Epoch 90/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0471 - mae: 0.0075 - val_loss: 0.0469 - val_mae: 0.0128\n",
      "Epoch 91/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0463 - mae: 0.0073 - val_loss: 0.0459 - val_mae: 0.0048\n",
      "Epoch 92/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0455 - mae: 0.0050 - val_loss: 0.0451 - val_mae: 0.0041\n",
      "Epoch 93/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0449 - mae: 0.0108 - val_loss: 0.0443 - val_mae: 0.0041\n",
      "Epoch 94/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0440 - mae: 0.0068 - val_loss: 0.0437 - val_mae: 0.0107\n",
      "Epoch 95/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0433 - mae: 0.0065 - val_loss: 0.0429 - val_mae: 0.0058\n",
      "Epoch 96/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0427 - mae: 0.0103 - val_loss: 0.0422 - val_mae: 0.0051\n",
      "Epoch 97/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0421 - mae: 0.0115 - val_loss: 0.0415 - val_mae: 0.0064\n",
      "Epoch 98/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0412 - mae: 0.0049 - val_loss: 0.0408 - val_mae: 0.0058\n",
      "Epoch 99/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0406 - mae: 0.0076 - val_loss: 0.0402 - val_mae: 0.0055\n",
      "Epoch 100/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0398 - mae: 0.0048 - val_loss: 0.0395 - val_mae: 0.0055\n",
      "Epoch 101/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0392 - mae: 0.0067 - val_loss: 0.0388 - val_mae: 0.0038\n",
      "Epoch 102/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0385 - mae: 0.0071 - val_loss: 0.0381 - val_mae: 0.0040\n",
      "Epoch 103/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0380 - mae: 0.0110 - val_loss: 0.0377 - val_mae: 0.0114\n",
      "Epoch 104/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0373 - mae: 0.0074 - val_loss: 0.0369 - val_mae: 0.0041\n",
      "Epoch 105/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0366 - mae: 0.0049 - val_loss: 0.0363 - val_mae: 0.0053\n",
      "Epoch 106/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0361 - mae: 0.0092 - val_loss: 0.0357 - val_mae: 0.0041\n",
      "Epoch 107/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0355 - mae: 0.0084 - val_loss: 0.0351 - val_mae: 0.0046\n",
      "Epoch 108/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0348 - mae: 0.0060 - val_loss: 0.0345 - val_mae: 0.0034\n",
      "Epoch 109/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0342 - mae: 0.0052 - val_loss: 0.0339 - val_mae: 0.0043\n",
      "Epoch 110/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0336 - mae: 0.0052 - val_loss: 0.0333 - val_mae: 0.0033\n",
      "Epoch 111/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0330 - mae: 0.0055 - val_loss: 0.0327 - val_mae: 0.0035\n",
      "Epoch 112/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0324 - mae: 0.0055 - val_loss: 0.0322 - val_mae: 0.0083\n",
      "Epoch 113/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0319 - mae: 0.0082 - val_loss: 0.0316 - val_mae: 0.0092\n",
      "Epoch 114/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0313 - mae: 0.0070 - val_loss: 0.0310 - val_mae: 0.0057\n",
      "Epoch 115/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.0069 - val_loss: 0.0306 - val_mae: 0.0105\n",
      "Epoch 116/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0304 - mae: 0.0116 - val_loss: 0.0299 - val_mae: 0.0051\n",
      "Epoch 117/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.0055 - val_loss: 0.0294 - val_mae: 0.0043\n",
      "Epoch 118/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.0045 - val_loss: 0.0289 - val_mae: 0.0037\n",
      "Epoch 119/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.0054 - val_loss: 0.0284 - val_mae: 0.0039\n",
      "Epoch 120/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.0058 - val_loss: 0.0280 - val_mae: 0.0103\n",
      "Epoch 121/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.0061 - val_loss: 0.0274 - val_mae: 0.0059\n",
      "Epoch 122/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0272 - mae: 0.0061 - val_loss: 0.0269 - val_mae: 0.0038\n",
      "Epoch 123/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0267 - mae: 0.0063 - val_loss: 0.0265 - val_mae: 0.0072\n",
      "Epoch 124/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.0099 - val_loss: 0.0262 - val_mae: 0.0141\n",
      "Epoch 125/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0258 - mae: 0.0088 - val_loss: 0.0256 - val_mae: 0.0065\n",
      "Epoch 126/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0254 - mae: 0.0065 - val_loss: 0.0251 - val_mae: 0.0064\n",
      "Epoch 127/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0249 - mae: 0.0050 - val_loss: 0.0247 - val_mae: 0.0077\n",
      "Epoch 128/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0246 - mae: 0.0082 - val_loss: 0.0242 - val_mae: 0.0035\n",
      "Epoch 129/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0241 - mae: 0.0050 - val_loss: 0.0238 - val_mae: 0.0045\n",
      "Epoch 130/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0237 - mae: 0.0069 - val_loss: 0.0234 - val_mae: 0.0053\n",
      "Epoch 131/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0233 - mae: 0.0066 - val_loss: 0.0230 - val_mae: 0.0044\n",
      "Epoch 132/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0228 - mae: 0.0051 - val_loss: 0.0227 - val_mae: 0.0062\n",
      "Epoch 133/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0226 - mae: 0.0086 - val_loss: 0.0222 - val_mae: 0.0046\n",
      "Epoch 134/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0221 - mae: 0.0062 - val_loss: 0.0219 - val_mae: 0.0065\n",
      "Epoch 135/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0217 - mae: 0.0059 - val_loss: 0.0215 - val_mae: 0.0044\n",
      "Epoch 136/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0213 - mae: 0.0049 - val_loss: 0.0211 - val_mae: 0.0048\n",
      "Epoch 137/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0211 - mae: 0.0084 - val_loss: 0.0208 - val_mae: 0.0037\n",
      "Epoch 138/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0206 - mae: 0.0068 - val_loss: 0.0204 - val_mae: 0.0036\n",
      "Epoch 139/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0203 - mae: 0.0053 - val_loss: 0.0201 - val_mae: 0.0045\n",
      "Epoch 140/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0199 - mae: 0.0056 - val_loss: 0.0199 - val_mae: 0.0113\n",
      "Epoch 141/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0196 - mae: 0.0063 - val_loss: 0.0194 - val_mae: 0.0068\n",
      "Epoch 142/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0192 - mae: 0.0048 - val_loss: 0.0190 - val_mae: 0.0042\n",
      "Epoch 143/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0189 - mae: 0.0051 - val_loss: 0.0187 - val_mae: 0.0046\n",
      "Epoch 144/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0185 - mae: 0.0059 - val_loss: 0.0184 - val_mae: 0.0083\n",
      "Epoch 145/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0182 - mae: 0.0054 - val_loss: 0.0181 - val_mae: 0.0091\n",
      "Epoch 146/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0179 - mae: 0.0075 - val_loss: 0.0177 - val_mae: 0.0060\n",
      "Epoch 147/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0176 - mae: 0.0096 - val_loss: 0.0174 - val_mae: 0.0047\n",
      "Epoch 148/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0172 - mae: 0.0053 - val_loss: 0.0171 - val_mae: 0.0038\n",
      "Epoch 149/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0169 - mae: 0.0058 - val_loss: 0.0168 - val_mae: 0.0062\n",
      "Epoch 150/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0047 - val_loss: 0.0165 - val_mae: 0.0034\n",
      "Epoch 151/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0163 - mae: 0.0050 - val_loss: 0.0162 - val_mae: 0.0036\n",
      "Epoch 152/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0161 - mae: 0.0063 - val_loss: 0.0159 - val_mae: 0.0056\n",
      "Epoch 153/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0070 - val_loss: 0.0157 - val_mae: 0.0075\n",
      "Epoch 154/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0155 - mae: 0.0052 - val_loss: 0.0153 - val_mae: 0.0035\n",
      "Epoch 155/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0153 - mae: 0.0067 - val_loss: 0.0151 - val_mae: 0.0041\n",
      "Epoch 156/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0150 - mae: 0.0061 - val_loss: 0.0149 - val_mae: 0.0086\n",
      "Epoch 157/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0147 - mae: 0.0058 - val_loss: 0.0146 - val_mae: 0.0049\n",
      "Epoch 158/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0055 - val_loss: 0.0143 - val_mae: 0.0039\n",
      "Epoch 159/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0143 - mae: 0.0073 - val_loss: 0.0141 - val_mae: 0.0072\n",
      "Epoch 160/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0142 - mae: 0.0112 - val_loss: 0.0139 - val_mae: 0.0079\n",
      "Epoch 161/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0047 - val_loss: 0.0136 - val_mae: 0.0051\n",
      "Epoch 162/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0136 - mae: 0.0050 - val_loss: 0.0135 - val_mae: 0.0078\n",
      "Epoch 163/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0054 - val_loss: 0.0133 - val_mae: 0.0067\n",
      "Epoch 164/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0054 - val_loss: 0.0130 - val_mae: 0.0046\n",
      "Epoch 165/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0062 - val_loss: 0.0128 - val_mae: 0.0035\n",
      "Epoch 166/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0051 - val_loss: 0.0126 - val_mae: 0.0062\n",
      "Epoch 167/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0054 - val_loss: 0.0124 - val_mae: 0.0033\n",
      "Epoch 168/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0059 - val_loss: 0.0122 - val_mae: 0.0036\n",
      "Epoch 169/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0043 - val_loss: 0.0120 - val_mae: 0.0035\n",
      "Epoch 170/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0049 - val_loss: 0.0118 - val_mae: 0.0050\n",
      "Epoch 171/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0117 - mae: 0.0053 - val_loss: 0.0116 - val_mae: 0.0050\n",
      "Epoch 172/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0115 - mae: 0.0062 - val_loss: 0.0114 - val_mae: 0.0042\n",
      "Epoch 173/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0113 - mae: 0.0055 - val_loss: 0.0112 - val_mae: 0.0040\n",
      "Epoch 174/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0112 - mae: 0.0080 - val_loss: 0.0111 - val_mae: 0.0086\n",
      "Epoch 175/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0109 - mae: 0.0057 - val_loss: 0.0109 - val_mae: 0.0091\n",
      "Epoch 176/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0108 - mae: 0.0057 - val_loss: 0.0106 - val_mae: 0.0047\n",
      "Epoch 177/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0106 - mae: 0.0053 - val_loss: 0.0105 - val_mae: 0.0038\n",
      "Epoch 178/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0104 - mae: 0.0048 - val_loss: 0.0103 - val_mae: 0.0056\n",
      "Epoch 179/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0102 - mae: 0.0056 - val_loss: 0.0101 - val_mae: 0.0052\n",
      "Epoch 180/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0101 - mae: 0.0063 - val_loss: 0.0100 - val_mae: 0.0068\n",
      "Epoch 181/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0099 - mae: 0.0056 - val_loss: 0.0098 - val_mae: 0.0041\n",
      "Epoch 182/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0097 - mae: 0.0056 - val_loss: 0.0097 - val_mae: 0.0082\n",
      "Epoch 183/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0051 - val_loss: 0.0095 - val_mae: 0.0035\n",
      "Epoch 184/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0094 - mae: 0.0056 - val_loss: 0.0093 - val_mae: 0.0047\n",
      "Epoch 185/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0068 - val_loss: 0.0094 - val_mae: 0.0117\n",
      "Epoch 186/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0079 - val_loss: 0.0091 - val_mae: 0.0098\n",
      "Epoch 187/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0101 - val_loss: 0.0089 - val_mae: 0.0036\n",
      "Epoch 188/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0049 - val_loss: 0.0088 - val_mae: 0.0042\n",
      "Epoch 189/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0059 - val_loss: 0.0087 - val_mae: 0.0034\n",
      "Epoch 190/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0042 - val_loss: 0.0086 - val_mae: 0.0039\n",
      "Epoch 191/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0048 - val_loss: 0.0085 - val_mae: 0.0049\n",
      "Epoch 192/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0057 - val_loss: 0.0083 - val_mae: 0.0041\n",
      "Epoch 193/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0052 - val_loss: 0.0082 - val_mae: 0.0034\n",
      "Epoch 194/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0070 - val_loss: 0.0083 - val_mae: 0.0131\n",
      "Epoch 195/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0083 - val_loss: 0.0080 - val_mae: 0.0032\n",
      "Epoch 196/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0050 - val_loss: 0.0079 - val_mae: 0.0065\n",
      "Epoch 197/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0048 - val_loss: 0.0078 - val_mae: 0.0047\n",
      "Epoch 198/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0043 - val_loss: 0.0077 - val_mae: 0.0041\n",
      "Epoch 199/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0063 - val_loss: 0.0076 - val_mae: 0.0049\n",
      "Epoch 200/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0081 - val_loss: 0.0075 - val_mae: 0.0062\n",
      "Epoch 201/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0075 - mae: 0.0056 - val_loss: 0.0074 - val_mae: 0.0030\n",
      "Epoch 202/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0073 - mae: 0.0045 - val_loss: 0.0073 - val_mae: 0.0037\n",
      "Epoch 203/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0073 - mae: 0.0056 - val_loss: 0.0072 - val_mae: 0.0031\n",
      "Epoch 204/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0072 - mae: 0.0060 - val_loss: 0.0071 - val_mae: 0.0046\n",
      "Epoch 205/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0071 - mae: 0.0047 - val_loss: 0.0070 - val_mae: 0.0040\n",
      "Epoch 206/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0070 - mae: 0.0057 - val_loss: 0.0069 - val_mae: 0.0053\n",
      "Epoch 207/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0069 - mae: 0.0070 - val_loss: 0.0068 - val_mae: 0.0033\n",
      "Epoch 208/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0068 - mae: 0.0048 - val_loss: 0.0067 - val_mae: 0.0032\n",
      "Epoch 209/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0067 - mae: 0.0044 - val_loss: 0.0066 - val_mae: 0.0038\n",
      "Epoch 210/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0066 - mae: 0.0055 - val_loss: 0.0066 - val_mae: 0.0086\n",
      "Epoch 211/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0065 - mae: 0.0050 - val_loss: 0.0065 - val_mae: 0.0054\n",
      "Epoch 212/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0065 - mae: 0.0072 - val_loss: 0.0065 - val_mae: 0.0087\n",
      "Epoch 213/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0064 - mae: 0.0049 - val_loss: 0.0063 - val_mae: 0.0070\n",
      "Epoch 214/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0063 - mae: 0.0047 - val_loss: 0.0062 - val_mae: 0.0052\n",
      "Epoch 215/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0062 - mae: 0.0072 - val_loss: 0.0062 - val_mae: 0.0056\n",
      "Epoch 216/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0061 - mae: 0.0051 - val_loss: 0.0062 - val_mae: 0.0123\n",
      "Epoch 217/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0060 - mae: 0.0050 - val_loss: 0.0060 - val_mae: 0.0033\n",
      "Epoch 218/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0060 - mae: 0.0054 - val_loss: 0.0059 - val_mae: 0.0049\n",
      "Epoch 219/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0059 - mae: 0.0047 - val_loss: 0.0059 - val_mae: 0.0076\n",
      "Epoch 220/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0058 - mae: 0.0048 - val_loss: 0.0058 - val_mae: 0.0043\n",
      "Epoch 221/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0057 - mae: 0.0056 - val_loss: 0.0057 - val_mae: 0.0033\n",
      "Epoch 222/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0057 - mae: 0.0059 - val_loss: 0.0056 - val_mae: 0.0055\n",
      "Epoch 223/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0056 - mae: 0.0050 - val_loss: 0.0056 - val_mae: 0.0059\n",
      "Epoch 224/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0055 - mae: 0.0053 - val_loss: 0.0055 - val_mae: 0.0035\n",
      "Epoch 225/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0055 - mae: 0.0084 - val_loss: 0.0054 - val_mae: 0.0034\n",
      "Epoch 226/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0054 - mae: 0.0051 - val_loss: 0.0054 - val_mae: 0.0064\n",
      "Epoch 227/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0053 - mae: 0.0047 - val_loss: 0.0053 - val_mae: 0.0036\n",
      "Epoch 228/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0053 - mae: 0.0053 - val_loss: 0.0052 - val_mae: 0.0037\n",
      "Epoch 229/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0052 - mae: 0.0052 - val_loss: 0.0053 - val_mae: 0.0105\n",
      "Epoch 230/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0051 - mae: 0.0052 - val_loss: 0.0051 - val_mae: 0.0053\n",
      "Epoch 231/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0051 - mae: 0.0057 - val_loss: 0.0050 - val_mae: 0.0039\n",
      "Epoch 232/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0052 - val_loss: 0.0050 - val_mae: 0.0032\n",
      "Epoch 233/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0065 - val_loss: 0.0049 - val_mae: 0.0044\n",
      "Epoch 234/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0062 - val_loss: 0.0049 - val_mae: 0.0061\n",
      "Epoch 235/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0048 - val_loss: 0.0048 - val_mae: 0.0062\n",
      "Epoch 236/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0059 - val_loss: 0.0048 - val_mae: 0.0085\n",
      "Epoch 237/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0047 - mae: 0.0044 - val_loss: 0.0047 - val_mae: 0.0042\n",
      "Epoch 238/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0047 - mae: 0.0054 - val_loss: 0.0047 - val_mae: 0.0074\n",
      "Epoch 239/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0046 - mae: 0.0047 - val_loss: 0.0046 - val_mae: 0.0038\n",
      "Epoch 240/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0046 - mae: 0.0050 - val_loss: 0.0045 - val_mae: 0.0037\n",
      "Epoch 241/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0051 - val_loss: 0.0045 - val_mae: 0.0031\n",
      "Epoch 242/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0062 - val_loss: 0.0045 - val_mae: 0.0094\n",
      "Epoch 243/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0066 - val_loss: 0.0044 - val_mae: 0.0039\n",
      "Epoch 244/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0056 - val_loss: 0.0043 - val_mae: 0.0036\n",
      "Epoch 245/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0056 - val_loss: 0.0043 - val_mae: 0.0033\n",
      "Epoch 246/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0044 - val_loss: 0.0042 - val_mae: 0.0037\n",
      "Epoch 247/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0048 - val_loss: 0.0042 - val_mae: 0.0048\n",
      "Epoch 248/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0052 - val_loss: 0.0042 - val_mae: 0.0046\n",
      "Epoch 249/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0054 - val_loss: 0.0042 - val_mae: 0.0073\n",
      "Epoch 250/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0068 - val_loss: 0.0041 - val_mae: 0.0078\n",
      "Epoch 251/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0052 - val_loss: 0.0040 - val_mae: 0.0047\n",
      "Epoch 252/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0047 - val_loss: 0.0040 - val_mae: 0.0063\n",
      "Epoch 253/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0051 - val_loss: 0.0040 - val_mae: 0.0046\n",
      "Epoch 254/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0047 - val_loss: 0.0039 - val_mae: 0.0063\n",
      "Epoch 255/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0048 - val_loss: 0.0039 - val_mae: 0.0034\n",
      "Epoch 256/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0065 - val_loss: 0.0038 - val_mae: 0.0035\n",
      "Epoch 257/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0060 - val_loss: 0.0038 - val_mae: 0.0065\n",
      "Epoch 258/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0043 - val_loss: 0.0038 - val_mae: 0.0073\n",
      "Epoch 259/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0055 - val_loss: 0.0039 - val_mae: 0.0125\n",
      "Epoch 260/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0061 - val_loss: 0.0037 - val_mae: 0.0040\n",
      "Epoch 261/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0053 - val_loss: 0.0037 - val_mae: 0.0065\n",
      "Epoch 262/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0061 - val_loss: 0.0036 - val_mae: 0.0052\n",
      "Epoch 263/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0059 - val_loss: 0.0036 - val_mae: 0.0085\n",
      "Epoch 264/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0060 - val_loss: 0.0035 - val_mae: 0.0038\n",
      "Epoch 265/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0053 - val_loss: 0.0035 - val_mae: 0.0050\n",
      "Epoch 266/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0050 - val_loss: 0.0035 - val_mae: 0.0036\n",
      "Epoch 267/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0043 - val_loss: 0.0035 - val_mae: 0.0043\n",
      "Epoch 268/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0052 - val_loss: 0.0034 - val_mae: 0.0043\n",
      "Epoch 269/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0055 - val_loss: 0.0034 - val_mae: 0.0054\n",
      "Epoch 270/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0047 - val_loss: 0.0034 - val_mae: 0.0045\n",
      "Epoch 271/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0053 - val_loss: 0.0033 - val_mae: 0.0033\n",
      "Epoch 272/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0067 - val_loss: 0.0033 - val_mae: 0.0052\n",
      "Epoch 273/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0046 - val_loss: 0.0033 - val_mae: 0.0038\n",
      "Epoch 274/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0049 - val_loss: 0.0033 - val_mae: 0.0057\n",
      "Epoch 275/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0049 - val_loss: 0.0032 - val_mae: 0.0037\n",
      "Epoch 276/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0052 - val_loss: 0.0032 - val_mae: 0.0034\n",
      "Epoch 277/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0032 - mae: 0.0047 - val_loss: 0.0032 - val_mae: 0.0042\n",
      "Epoch 278/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0032 - mae: 0.0056 - val_loss: 0.0031 - val_mae: 0.0041\n",
      "Epoch 279/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0046 - val_loss: 0.0031 - val_mae: 0.0034\n",
      "Epoch 280/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0048 - val_loss: 0.0032 - val_mae: 0.0089\n",
      "Epoch 281/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0071 - val_loss: 0.0031 - val_mae: 0.0070\n",
      "Epoch 282/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0045 - val_loss: 0.0031 - val_mae: 0.0083\n",
      "Epoch 283/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0066 - val_loss: 0.0031 - val_mae: 0.0070\n",
      "Epoch 284/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0054 - val_loss: 0.0030 - val_mae: 0.0071\n",
      "Epoch 285/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0054 - val_loss: 0.0030 - val_mae: 0.0053\n",
      "Epoch 286/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0045 - val_loss: 0.0030 - val_mae: 0.0060\n",
      "Epoch 287/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0082 - val_loss: 0.0030 - val_mae: 0.0058\n",
      "Epoch 288/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0054 - val_loss: 0.0029 - val_mae: 0.0031\n",
      "Epoch 289/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0044 - val_loss: 0.0029 - val_mae: 0.0067\n",
      "Epoch 290/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0049 - val_loss: 0.0029 - val_mae: 0.0042\n",
      "Epoch 291/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0048 - val_loss: 0.0029 - val_mae: 0.0034\n",
      "Epoch 292/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0054 - val_loss: 0.0030 - val_mae: 0.0104\n",
      "Epoch 293/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0051 - val_loss: 0.0028 - val_mae: 0.0058\n",
      "Epoch 294/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0047 - val_loss: 0.0028 - val_mae: 0.0030\n",
      "Epoch 295/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0056 - val_loss: 0.0034 - val_mae: 0.0235\n",
      "Epoch 296/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0082 - val_loss: 0.0031 - val_mae: 0.0156\n",
      "Epoch 297/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0055 - val_loss: 0.0028 - val_mae: 0.0041\n",
      "Epoch 298/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0048 - val_loss: 0.0027 - val_mae: 0.0032\n",
      "Epoch 299/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0050 - val_loss: 0.0028 - val_mae: 0.0067\n",
      "Epoch 300/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0045 - val_loss: 0.0027 - val_mae: 0.0035\n",
      "Epoch 301/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0040 - val_loss: 0.0027 - val_mae: 0.0070\n",
      "Epoch 302/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0060 - val_loss: 0.0027 - val_mae: 0.0047\n",
      "Epoch 303/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0042 - val_loss: 0.0026 - val_mae: 0.0038\n",
      "Epoch 304/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0050 - val_loss: 0.0026 - val_mae: 0.0029\n",
      "Epoch 305/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0045 - val_loss: 0.0026 - val_mae: 0.0059\n",
      "Epoch 306/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0054 - val_loss: 0.0027 - val_mae: 0.0085\n",
      "Epoch 307/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0056 - val_loss: 0.0026 - val_mae: 0.0038\n",
      "Epoch 308/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0039 - val_loss: 0.0026 - val_mae: 0.0040\n",
      "Epoch 309/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0050 - val_loss: 0.0025 - val_mae: 0.0035\n",
      "Epoch 310/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0052 - val_loss: 0.0025 - val_mae: 0.0035\n",
      "Epoch 311/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0050 - val_loss: 0.0026 - val_mae: 0.0091\n",
      "Epoch 312/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0076 - val_loss: 0.0025 - val_mae: 0.0034\n",
      "Epoch 313/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0042 - val_loss: 0.0025 - val_mae: 0.0066\n",
      "Epoch 314/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0043 - val_loss: 0.0025 - val_mae: 0.0061\n",
      "Epoch 315/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0050 - val_loss: 0.0025 - val_mae: 0.0047\n",
      "Epoch 316/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0052 - val_loss: 0.0025 - val_mae: 0.0069\n",
      "Epoch 317/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0055 - val_loss: 0.0024 - val_mae: 0.0047\n",
      "Epoch 318/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0062 - val_loss: 0.0024 - val_mae: 0.0048\n",
      "Epoch 319/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0041 - val_loss: 0.0024 - val_mae: 0.0036\n",
      "Epoch 320/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0055 - val_loss: 0.0025 - val_mae: 0.0097\n",
      "Epoch 321/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0045 - val_loss: 0.0024 - val_mae: 0.0070\n",
      "Epoch 322/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0051 - val_loss: 0.0024 - val_mae: 0.0042\n",
      "Epoch 323/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0040 - val_loss: 0.0024 - val_mae: 0.0059\n",
      "Epoch 324/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0047 - val_loss: 0.0023 - val_mae: 0.0041\n",
      "Epoch 325/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0044 - val_loss: 0.0023 - val_mae: 0.0043\n",
      "Epoch 326/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0053 - val_loss: 0.0023 - val_mae: 0.0052\n",
      "Epoch 327/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0047 - val_loss: 0.0023 - val_mae: 0.0039\n",
      "Epoch 328/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0054 - val_loss: 0.0023 - val_mae: 0.0071\n",
      "Epoch 329/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0068 - val_loss: 0.0023 - val_mae: 0.0044\n",
      "Epoch 330/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0045 - val_loss: 0.0023 - val_mae: 0.0037\n",
      "Epoch 331/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0048 - val_loss: 0.0023 - val_mae: 0.0055\n",
      "Epoch 332/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0052 - val_loss: 0.0022 - val_mae: 0.0041\n",
      "Epoch 333/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0048 - val_loss: 0.0023 - val_mae: 0.0096\n",
      "Epoch 334/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0049 - val_loss: 0.0022 - val_mae: 0.0044\n",
      "Epoch 335/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0052 - val_loss: 0.0022 - val_mae: 0.0055\n",
      "Epoch 336/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0043 - val_loss: 0.0022 - val_mae: 0.0030\n",
      "Epoch 337/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0052 - val_loss: 0.0022 - val_mae: 0.0060\n",
      "Epoch 338/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0053 - val_loss: 0.0022 - val_mae: 0.0039\n",
      "Epoch 339/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0044 - val_loss: 0.0022 - val_mae: 0.0048\n",
      "Epoch 340/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0064 - val_loss: 0.0022 - val_mae: 0.0040\n",
      "Epoch 341/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0042 - val_loss: 0.0022 - val_mae: 0.0043\n",
      "Epoch 342/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0048 - val_loss: 0.0021 - val_mae: 0.0034\n",
      "Epoch 343/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0042 - val_loss: 0.0022 - val_mae: 0.0078\n",
      "Epoch 344/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0073 - val_loss: 0.0026 - val_mae: 0.0200\n",
      "Epoch 345/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0047 - val_loss: 0.0021 - val_mae: 0.0034\n",
      "Epoch 346/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0048 - val_loss: 0.0021 - val_mae: 0.0031\n",
      "Epoch 347/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0049 - val_loss: 0.0021 - val_mae: 0.0055\n",
      "Epoch 348/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0053 - val_loss: 0.0021 - val_mae: 0.0050\n",
      "Epoch 349/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0057 - val_loss: 0.0021 - val_mae: 0.0039\n",
      "Epoch 350/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0039 - val_loss: 0.0021 - val_mae: 0.0036\n",
      "Epoch 351/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0048 - val_loss: 0.0021 - val_mae: 0.0070\n",
      "Epoch 352/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0044 - val_loss: 0.0021 - val_mae: 0.0043\n",
      "Epoch 353/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0050 - val_loss: 0.0021 - val_mae: 0.0059\n",
      "Epoch 354/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0058 - val_loss: 0.0021 - val_mae: 0.0064\n",
      "Epoch 355/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0048 - val_loss: 0.0020 - val_mae: 0.0055\n",
      "Epoch 356/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0057 - val_loss: 0.0020 - val_mae: 0.0047\n",
      "Epoch 357/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0047 - val_loss: 0.0020 - val_mae: 0.0052\n",
      "Epoch 358/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0046 - val_loss: 0.0020 - val_mae: 0.0058\n",
      "Epoch 359/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0060 - val_loss: 0.0022 - val_mae: 0.0148\n",
      "Epoch 360/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0053 - val_loss: 0.0020 - val_mae: 0.0030\n",
      "Epoch 361/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0040 - val_loss: 0.0020 - val_mae: 0.0032\n",
      "Epoch 362/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0061 - val_loss: 0.0020 - val_mae: 0.0035\n",
      "Epoch 363/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0053 - val_loss: 0.0020 - val_mae: 0.0060\n",
      "Epoch 364/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0044 - val_loss: 0.0020 - val_mae: 0.0042\n",
      "Epoch 365/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0051 - val_loss: 0.0020 - val_mae: 0.0068\n",
      "Epoch 366/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0056 - val_loss: 0.0019 - val_mae: 0.0034\n",
      "Epoch 367/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0046 - val_loss: 0.0020 - val_mae: 0.0059\n",
      "Epoch 368/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0046 - val_loss: 0.0019 - val_mae: 0.0042\n",
      "Epoch 369/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0053 - val_loss: 0.0019 - val_mae: 0.0037\n",
      "Epoch 370/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0055 - val_loss: 0.0019 - val_mae: 0.0055\n",
      "Epoch 371/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0048 - val_loss: 0.0019 - val_mae: 0.0031\n",
      "Epoch 372/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0048 - val_loss: 0.0019 - val_mae: 0.0035\n",
      "Epoch 373/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0070 - val_loss: 0.0019 - val_mae: 0.0069\n",
      "Epoch 374/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0047 - val_loss: 0.0019 - val_mae: 0.0064\n",
      "Epoch 375/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0048 - val_loss: 0.0019 - val_mae: 0.0049\n",
      "Epoch 376/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0052 - val_loss: 0.0019 - val_mae: 0.0065\n",
      "Epoch 377/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0051 - val_loss: 0.0019 - val_mae: 0.0065\n",
      "Epoch 378/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0050 - val_loss: 0.0019 - val_mae: 0.0049\n",
      "Epoch 379/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0056 - val_loss: 0.0021 - val_mae: 0.0129\n",
      "Epoch 380/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0060 - val_loss: 0.0018 - val_mae: 0.0034\n",
      "Epoch 381/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0052 - val_loss: 0.0018 - val_mae: 0.0038\n",
      "Epoch 382/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0050 - val_loss: 0.0019 - val_mae: 0.0071\n",
      "Epoch 383/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0054 - val_loss: 0.0018 - val_mae: 0.0034\n",
      "Epoch 384/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0056 - val_loss: 0.0018 - val_mae: 0.0039\n",
      "Epoch 385/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0042 - val_loss: 0.0018 - val_mae: 0.0031\n",
      "Epoch 386/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0051 - val_loss: 0.0018 - val_mae: 0.0037\n",
      "Epoch 387/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0018 - mae: 0.0054 - val_loss: 0.0018 - val_mae: 0.0036\n",
      "Epoch 388/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0053 - val_loss: 0.0018 - val_mae: 0.0029\n",
      "Epoch 389/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0042 - val_loss: 0.0018 - val_mae: 0.0052\n",
      "Epoch 390/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0050 - val_loss: 0.0018 - val_mae: 0.0031\n",
      "Epoch 391/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0049 - val_loss: 0.0018 - val_mae: 0.0084\n",
      "Epoch 392/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0053 - val_loss: 0.0018 - val_mae: 0.0062\n",
      "Epoch 393/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0055 - val_loss: 0.0018 - val_mae: 0.0054\n",
      "Epoch 394/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0046 - val_loss: 0.0018 - val_mae: 0.0098\n",
      "Epoch 395/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0060 - val_loss: 0.0019 - val_mae: 0.0117\n",
      "Epoch 396/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0044 - val_loss: 0.0017 - val_mae: 0.0036\n",
      "Epoch 397/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0048 - val_loss: 0.0017 - val_mae: 0.0035\n",
      "Epoch 398/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0059 - val_loss: 0.0018 - val_mae: 0.0085\n",
      "Epoch 399/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0049 - val_loss: 0.0017 - val_mae: 0.0043\n",
      "Epoch 400/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0038 - val_loss: 0.0017 - val_mae: 0.0038\n",
      "Epoch 401/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0051 - val_loss: 0.0017 - val_mae: 0.0039\n",
      "Epoch 402/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0044 - val_loss: 0.0017 - val_mae: 0.0032\n",
      "Epoch 403/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0051 - val_loss: 0.0017 - val_mae: 0.0033\n",
      "Epoch 404/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0049 - val_loss: 0.0017 - val_mae: 0.0059\n",
      "Epoch 405/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0059 - val_loss: 0.0017 - val_mae: 0.0042\n",
      "Epoch 406/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0049 - val_loss: 0.0017 - val_mae: 0.0038\n",
      "Epoch 407/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0052 - val_loss: 0.0017 - val_mae: 0.0060\n",
      "Epoch 408/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0046 - val_loss: 0.0017 - val_mae: 0.0040\n",
      "Epoch 409/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0046 - val_loss: 0.0017 - val_mae: 0.0052\n",
      "Epoch 410/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0059 - val_loss: 0.0017 - val_mae: 0.0068\n",
      "Epoch 411/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0055 - val_loss: 0.0017 - val_mae: 0.0039\n",
      "Epoch 412/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0054 - val_loss: 0.0017 - val_mae: 0.0043\n",
      "Epoch 413/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0052 - val_loss: 0.0016 - val_mae: 0.0041\n",
      "Epoch 414/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0041 - val_loss: 0.0016 - val_mae: 0.0039\n",
      "Epoch 415/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0059 - val_loss: 0.0017 - val_mae: 0.0064\n",
      "Epoch 416/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0046 - val_loss: 0.0017 - val_mae: 0.0057\n",
      "Epoch 417/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0051 - val_loss: 0.0016 - val_mae: 0.0045\n",
      "Epoch 418/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0048 - val_loss: 0.0016 - val_mae: 0.0033\n",
      "Epoch 419/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0048 - val_loss: 0.0016 - val_mae: 0.0042\n",
      "Epoch 420/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0043 - val_loss: 0.0016 - val_mae: 0.0043\n",
      "Epoch 421/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0052 - val_loss: 0.0017 - val_mae: 0.0069\n",
      "Epoch 422/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0048 - val_loss: 0.0016 - val_mae: 0.0028\n",
      "Epoch 423/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0055 - val_loss: 0.0016 - val_mae: 0.0039\n",
      "Epoch 424/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0047 - val_loss: 0.0016 - val_mae: 0.0072\n",
      "Epoch 425/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0078 - val_loss: 0.0016 - val_mae: 0.0066\n",
      "Epoch 426/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0039 - val_loss: 0.0016 - val_mae: 0.0036\n",
      "Epoch 427/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0039 - val_loss: 0.0016 - val_mae: 0.0047\n",
      "Epoch 428/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0043 - val_loss: 0.0016 - val_mae: 0.0032\n",
      "Epoch 429/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0070\n",
      "Epoch 430/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0046 - val_loss: 0.0016 - val_mae: 0.0036\n",
      "Epoch 431/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0046 - val_loss: 0.0016 - val_mae: 0.0047\n",
      "Epoch 432/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0050 - val_loss: 0.0016 - val_mae: 0.0075\n",
      "Epoch 433/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0057 - val_loss: 0.0016 - val_mae: 0.0087\n",
      "Epoch 434/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0050 - val_loss: 0.0016 - val_mae: 0.0044\n",
      "Epoch 435/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0015 - val_mae: 0.0046\n",
      "Epoch 436/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0045 - val_loss: 0.0016 - val_mae: 0.0059\n",
      "Epoch 437/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0050 - val_loss: 0.0015 - val_mae: 0.0034\n",
      "Epoch 438/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0061 - val_loss: 0.0015 - val_mae: 0.0041\n",
      "Epoch 439/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0048 - val_loss: 0.0015 - val_mae: 0.0030\n",
      "Epoch 440/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0034\n",
      "Epoch 441/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0055 - val_loss: 0.0015 - val_mae: 0.0030\n",
      "Epoch 442/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0056 - val_loss: 0.0015 - val_mae: 0.0050\n",
      "Epoch 443/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0064 - val_loss: 0.0015 - val_mae: 0.0060\n",
      "Epoch 444/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0047 - val_loss: 0.0015 - val_mae: 0.0028\n",
      "Epoch 445/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0041 - val_loss: 0.0015 - val_mae: 0.0041\n",
      "Epoch 446/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0040 - val_loss: 0.0015 - val_mae: 0.0044\n",
      "Epoch 447/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0035\n",
      "Epoch 448/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0040 - val_loss: 0.0015 - val_mae: 0.0053\n",
      "Epoch 449/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0047 - val_loss: 0.0016 - val_mae: 0.0085\n",
      "Epoch 450/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0058 - val_loss: 0.0015 - val_mae: 0.0048\n",
      "Epoch 451/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0042\n",
      "Epoch 452/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0037\n",
      "Epoch 453/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0047 - val_loss: 0.0015 - val_mae: 0.0045\n",
      "Epoch 454/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0048 - val_loss: 0.0015 - val_mae: 0.0035\n",
      "Epoch 455/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0052 - val_loss: 0.0015 - val_mae: 0.0066\n",
      "Epoch 456/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0058 - val_loss: 0.0015 - val_mae: 0.0049\n",
      "Epoch 457/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0049 - val_loss: 0.0015 - val_mae: 0.0035\n",
      "Epoch 458/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0052 - val_loss: 0.0015 - val_mae: 0.0050\n",
      "Epoch 459/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0047 - val_loss: 0.0015 - val_mae: 0.0091\n",
      "Epoch 460/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0048 - val_loss: 0.0015 - val_mae: 0.0044\n",
      "Epoch 461/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0079\n",
      "Epoch 462/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0052 - val_loss: 0.0015 - val_mae: 0.0070\n",
      "Epoch 463/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0055 - val_loss: 0.0014 - val_mae: 0.0039\n",
      "Epoch 464/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0054 - val_loss: 0.0014 - val_mae: 0.0037\n",
      "Epoch 465/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0046 - val_loss: 0.0014 - val_mae: 0.0034\n",
      "Epoch 466/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0056 - val_loss: 0.0015 - val_mae: 0.0092\n",
      "Epoch 467/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0060 - val_loss: 0.0015 - val_mae: 0.0067\n",
      "Epoch 468/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0052\n",
      "Epoch 469/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0046 - val_loss: 0.0014 - val_mae: 0.0040\n",
      "Epoch 470/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0049 - val_loss: 0.0014 - val_mae: 0.0047\n",
      "Epoch 471/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0054 - val_loss: 0.0017 - val_mae: 0.0150\n",
      "Epoch 472/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0056 - val_loss: 0.0014 - val_mae: 0.0050\n",
      "Epoch 473/500\n",
      "145/163 [=========================>....] - ETA: 0s - loss: 0.0015 - mae: 0.0068Restoring model weights from the end of the best epoch: 468.\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0064 - val_loss: 0.0014 - val_mae: 0.0031\n",
      "Epoch 473: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Netzwerkarchitektur\n",
    "model = Sequential([\n",
    "\n",
    "    Dense(248, activation='relu', input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "    Dense(296, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(280, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(216, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(184, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(40, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(312, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(200, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(104, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "    Dense(1 , activation = 'linear')\n",
    "])\n",
    "\n",
    "# Optimierer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "# Modell kompilieren (Verwendung von mean_squared_error als Verlustfunktion für Regression)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])  # Metriken für Regression: Mean Absolute Error und Mean Squared Error\n",
    "\n",
    "# Early Stopping Callback\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "# Trainingsparameter\n",
    "batch_size = 25\n",
    "epochs = 500\n",
    "\n",
    "# Modell trainieren (Annahme: X_train, y_train, X_val, y_val sind vordefiniert)\n",
    "history = model.fit(X_train_scaled, y_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:51:18.794327100Z",
     "start_time": "2024-03-15T09:47:15.909605Z"
    }
   },
   "id": "8b52e1a9a6ff3aeb"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 - 0s - loss: 0.0014 - mae: 0.0051 - 60ms/epoch - 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.0014465928543359041, 0.0050717745907604694]"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test_scaled, y_test_scaled, verbose=2)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:51:18.904331400Z",
     "start_time": "2024-03-15T09:51:18.789798800Z"
    }
   },
   "id": "9050ab66ab36f169"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bsp. Predicted: [1462.3865] Actual: [1463.6] \n",
      "Durchschnittliche Abweichung (MAE): [4.79824349]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scaled_predicted_values = model.predict(X_test_scaled, verbose = 0)\n",
    "\n",
    "# Führen Sie die Rücktransformation der skalierten Werte durch\n",
    "original_predicted_values = scaler_target.inverse_transform(scaled_predicted_values)\n",
    "original_actual_values = scaler_target.inverse_transform(y_test_scaled)  # y_test sind die skalierten tatsächlichen Werte\n",
    "print(f' Bsp. Predicted: {original_predicted_values[100]} Actual: {original_actual_values[100]} ')\n",
    "\n",
    "def calculate_mae(list1, list2):\n",
    "    # Stelle sicher, dass beide Listen die gleiche Länge haben\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Listen müssen die gleiche Länge haben\")\n",
    "\n",
    "    # Berechne die absolute Differenz zwischen den Elementen der Listen\n",
    "    differences = [abs(x - y) for x, y in zip(list1, list2)]\n",
    "\n",
    "    # Berechne den Durchschnitt der absoluten Differenzen\n",
    "    mae = sum(differences) / len(differences)\n",
    "\n",
    "    return mae\n",
    "\n",
    "# Beispiel\n",
    "list1 = original_predicted_values\n",
    "list2 = original_actual_values\n",
    "\n",
    "mae = calculate_mae(list1, list2)\n",
    "print(f\"Durchschnittliche Abweichung (MAE): {mae}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:51:19.115630800Z",
     "start_time": "2024-03-15T09:51:18.899808300Z"
    }
   },
   "id": "10cd79ca028075dd"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: [0.99944471]\n"
     ]
    }
   ],
   "source": [
    "def calculate_r_squared(predicted, actual):\n",
    "    # Berechnung des Mittelwerts der tatsächlichen Werte\n",
    "    mean_actual = sum(actual) / len(actual)\n",
    "    \n",
    "    # Berechnung der totalen Summe der Quadrate (SST)\n",
    "    sst = sum((x - mean_actual) ** 2 for x in actual)\n",
    "    \n",
    "    # Berechnung der Summe der Quadrate der Residuen (SSE)\n",
    "    sse = sum((actual[i] - predicted[i]) ** 2 for i in range(len(actual)))\n",
    "    \n",
    "    # Berechnung des R^2-Wertes\n",
    "    r_squared = 1 - (sse / sst)\n",
    "    \n",
    "    return r_squared\n",
    "\n",
    "# Berechnung von R^2 mit den bereitgestellten Listen\n",
    "r_squared = calculate_r_squared(list1, list2)\n",
    "\n",
    "print(f\"R^2: {r_squared}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:51:19.128930900Z",
     "start_time": "2024-03-15T09:51:19.115630800Z"
    }
   },
   "id": "d0505d16afcbef4a"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Werte die kleiner sind: 13\n"
     ]
    },
    {
     "data": {
      "text/plain": "             Echt  Vorhergesagt  X-Koordinate  Y-Koordinate  Differenz\n302    718.482117        755.11      1.000000          0.93 -36.627883\n423    869.190613        898.99      1.000000          0.87 -29.799387\n542    849.398682        877.41      0.983871          0.88 -28.011318\n656    772.105347        799.88      0.951613          0.91 -27.774653\n642    825.466248        852.98      0.967742          0.89 -27.513752\n...           ...           ...           ...           ...        ...\n34    1104.227051       1086.80      1.000000          0.24  17.427051\n482    681.660034        660.80      0.806452          0.00  20.860034\n1104   693.596191        672.09      0.983871          0.00  21.506191\n354    691.588196        669.05      0.000000          0.00  22.538196\n1127   685.564941        661.84      0.870968          0.00  23.724941\n\n[1273 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Echt</th>\n      <th>Vorhergesagt</th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Differenz</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>302</th>\n      <td>718.482117</td>\n      <td>755.11</td>\n      <td>1.000000</td>\n      <td>0.93</td>\n      <td>-36.627883</td>\n    </tr>\n    <tr>\n      <th>423</th>\n      <td>869.190613</td>\n      <td>898.99</td>\n      <td>1.000000</td>\n      <td>0.87</td>\n      <td>-29.799387</td>\n    </tr>\n    <tr>\n      <th>542</th>\n      <td>849.398682</td>\n      <td>877.41</td>\n      <td>0.983871</td>\n      <td>0.88</td>\n      <td>-28.011318</td>\n    </tr>\n    <tr>\n      <th>656</th>\n      <td>772.105347</td>\n      <td>799.88</td>\n      <td>0.951613</td>\n      <td>0.91</td>\n      <td>-27.774653</td>\n    </tr>\n    <tr>\n      <th>642</th>\n      <td>825.466248</td>\n      <td>852.98</td>\n      <td>0.967742</td>\n      <td>0.89</td>\n      <td>-27.513752</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>1104.227051</td>\n      <td>1086.80</td>\n      <td>1.000000</td>\n      <td>0.24</td>\n      <td>17.427051</td>\n    </tr>\n    <tr>\n      <th>482</th>\n      <td>681.660034</td>\n      <td>660.80</td>\n      <td>0.806452</td>\n      <td>0.00</td>\n      <td>20.860034</td>\n    </tr>\n    <tr>\n      <th>1104</th>\n      <td>693.596191</td>\n      <td>672.09</td>\n      <td>0.983871</td>\n      <td>0.00</td>\n      <td>21.506191</td>\n    </tr>\n    <tr>\n      <th>354</th>\n      <td>691.588196</td>\n      <td>669.05</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>22.538196</td>\n    </tr>\n    <tr>\n      <th>1127</th>\n      <td>685.564941</td>\n      <td>661.84</td>\n      <td>0.870968</td>\n      <td>0.00</td>\n      <td>23.724941</td>\n    </tr>\n  </tbody>\n</table>\n<p>1273 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame({'Echt': [val[0] for val in list1], 'Vorhergesagt': [val[0] for val in list2]})\n",
    "df_result['X-Koordinate'] = X_test_scaled[:, 0]\n",
    "df_result['Y-Koordinate'] = X_test_scaled[:, 1]\n",
    "\n",
    "df_result['Differenz'] = df_result['Echt'] - df_result['Vorhergesagt']\n",
    "df_result['Differenz'].sort_values()\n",
    "sorted_df = df_result.sort_values(by= 'Differenz')\n",
    "Anzahl_Punkte = (sorted_df['Differenz'] < -20).sum()\n",
    "print(\"Anzahl der Werte die kleiner sind:\", Anzahl_Punkte)\n",
    "\n",
    "sorted_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:51:19.149164200Z",
     "start_time": "2024-03-15T09:51:19.128930900Z"
    }
   },
   "id": "47d4a39665ed1159"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mae = history.history['loss']\n",
    "val_mae = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(mae) + 1)\n",
    "\n",
    "# MAE Diagramm\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, mae, 'r', label='Training MSE')\n",
    "plt.plot(epochs, val_mae, 'b', label='Validation MSE')\n",
    "plt.title('Training and Validation MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.savefig('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Bilder Diplomarbeit/MSE_NeuroNetz/MSE_NeuroNetz_D3_1')\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:51:19.381901300Z",
     "start_time": "2024-03-15T09:51:19.144472600Z"
    }
   },
   "id": "3688dd7102e95baf"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f6f672a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T09:51:19.381901300Z",
     "start_time": "2024-03-15T09:51:19.376877Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "553df6fa",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# def build_model(learning_rate=0.001, activation='relu', regularization=0.0001, dropout_rate=0.0):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(200, activation=activation, input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(448, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(352, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(320, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(256, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(416, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(128, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(96, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))    \n",
    "# \n",
    "#     model.add(Dense(32, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mae'])\n",
    "#     return model\n",
    "# \n",
    "# # Verwenden Sie eine Funktion, um das Modell zu instanziieren, für scikit-learn Wrapper\n",
    "# model = KerasRegressor(model=build_model, verbose=2)\n",
    "# \n",
    "# # Anpassung der Parameter im param_grid\n",
    "# param_grid = {\n",
    "#     'model__learning_rate': [0.01, 0.001, 0.0001],\n",
    "#     'model__regularization': [0.001, 0.0001],\n",
    "#     'fit__batch_size': [25, 50, 75, 100],\n",
    "#     'fit__epochs': [50],\n",
    "#     'model__dropout_rate' : [0.0, 0.1, 0.2]\n",
    "# }\n",
    "# \n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=2)\n",
    "# # Hinweis: Stellen Sie sicher, dass Ihre Daten (X_train_scaled, y_train_scaled) korrekt definiert sind\n",
    "# grid_result = grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "# # Beste Parameter und Score ausgeben\n",
    "# print(\"Beste Parameter:\", grid_search.best_params_)\n",
    "# print(\"Beste Genauigkeit:\", grid_search.best_score_)\n",
    "# \n",
    "# with open(\"Gridsearch_D3.txt\", \"w\") as f:\n",
    "#     f.write(f\"Beste Parameter: {grid_search.best_params_}\\n\")\n",
    "#     f.write(f\"Beste Genauigkeit: {grid_search.best_score_}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:51:19.390019700Z",
     "start_time": "2024-03-15T09:51:19.381901300Z"
    }
   },
   "id": "578403f6e218787a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Search"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69b9aef262bcb2c3"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "492cf0ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T09:51:19.390019700Z",
     "start_time": "2024-03-15T09:51:19.384424600Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Funktion zum Erstellen des Modells\n",
    "# def build_model(hp):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(hp.Int('input_units', min_value=8, max_value=328, step=16), input_shape=(2,), activation='relu'))\n",
    "#     for i in range(hp.Int('n_layers', 1, 10)):\n",
    "#         model.add(Dense(hp.Int(f'units_{i}', min_value=8, max_value=328, step=16), activation='relu'))\n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     return model\n",
    "# \n",
    "# # Durchführung der Random Search dreimal\n",
    "# for run in range(1, 4):\n",
    "#     # Anpassen des Verzeichnisses und des Projektnamens für jeden Durchlauf\n",
    "#     directory = 'random_search'\n",
    "#     project_name = f'random_search_D3_{run}'\n",
    "#     \n",
    "#     tuner = RandomSearch(\n",
    "#         build_model,\n",
    "#         objective='val_loss',\n",
    "#         max_trials=100,\n",
    "#         executions_per_trial=1,\n",
    "#         directory=directory,\n",
    "#         project_name=project_name\n",
    "#     )\n",
    "#     \n",
    "#     # Durchführung des Random Search\n",
    "#     tuner.search(X_train_scaled, y_train_scaled, epochs=50, verbose =0, batch_size=50, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "#     \n",
    "#     # Abrufen und Speichern des besten Modells\n",
    "#     best_model = tuner.get_best_models(num_models=1)[0]\n",
    "#     model_path = os.path.join(directory, project_name, 'best_model.h5') \n",
    "#     best_model.save(model_path)\n",
    "#     \n",
    "# \n",
    "#     # Optional: Abrufen und Ausgeben der besten Hyperparameter\n",
    "#     best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "#     \n",
    "#     # Konvertieren der Hyperparameter in ein DataFrame\n",
    "#     df_hyperparameters = pd.DataFrame([best_hyperparameters.values])\n",
    "#     # Speichern des DataFrame als CSV\n",
    "#     df_hyperparameters.to_csv(f'random_search_D3_{run}.csv', index=False)\n",
    "#     \n",
    "#     print(f\"Beste Hyperparameter für Lauf {run}: {best_hyperparameters.values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:51:19.394559400Z",
     "start_time": "2024-03-15T09:51:19.386745900Z"
    }
   },
   "id": "412f38f9b1e03d5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
