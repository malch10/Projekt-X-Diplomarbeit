{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94b0518e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T16:03:11.628909900Z",
     "start_time": "2024-03-14T16:03:11.484345500Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense , Dropout\n",
    "from scikeras.wrappers import KerasRegressor \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4ff61b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T16:03:11.818846300Z",
     "start_time": "2024-03-14T16:03:11.492344600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n0          0.00000      -0.00200        500   7000   9000      669.05\n1          0.00000      -0.00196        500   7000   9000      696.80\n2          0.00000      -0.00192        500   7000   9000      724.42\n3          0.00000      -0.00188        500   7000   9000      751.84\n4          0.00000      -0.00184        500   7000   9000      779.83\n...            ...           ...        ...    ...    ...         ...\n6358       0.00248       0.00184        500   7000   9000      651.36\n6359       0.00248       0.00188        500   7000   9000      612.09\n6360       0.00248       0.00192        500   7000   9000      584.59\n6361       0.00248       0.00196        500   7000   9000      578.64\n6362       0.00248       0.00200        500   7000   9000      572.78\n\n[6363 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00000</td>\n      <td>-0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>669.05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00000</td>\n      <td>-0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>696.80</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00000</td>\n      <td>-0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>724.42</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00000</td>\n      <td>-0.00188</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>751.84</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00000</td>\n      <td>-0.00184</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>779.83</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6358</th>\n      <td>0.00248</td>\n      <td>0.00184</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>651.36</td>\n    </tr>\n    <tr>\n      <th>6359</th>\n      <td>0.00248</td>\n      <td>0.00188</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>612.09</td>\n    </tr>\n    <tr>\n      <th>6360</th>\n      <td>0.00248</td>\n      <td>0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>584.59</td>\n    </tr>\n    <tr>\n      <th>6361</th>\n      <td>0.00248</td>\n      <td>0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>578.64</td>\n    </tr>\n    <tr>\n      <th>6362</th>\n      <td>0.00248</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>572.78</td>\n    </tr>\n  </tbody>\n</table>\n<p>6363 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/TPath_300_finish_data.pkl')\n",
    "data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_D3_I7000_F9000/TPath_500_finish_data_D3.pkl')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "966e3c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T16:03:11.823854Z",
     "start_time": "2024-03-14T16:03:11.514696200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      X-Koordinate  Y-Koordinate  Temperatur\n0          0.00000      -0.00200      669.05\n1          0.00000      -0.00196      696.80\n2          0.00000      -0.00192      724.42\n3          0.00000      -0.00188      751.84\n4          0.00000      -0.00184      779.83\n...            ...           ...         ...\n6358       0.00248       0.00184      651.36\n6359       0.00248       0.00188      612.09\n6360       0.00248       0.00192      584.59\n6361       0.00248       0.00196      578.64\n6362       0.00248       0.00200      572.78\n\n[6363 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00000</td>\n      <td>-0.00200</td>\n      <td>669.05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00000</td>\n      <td>-0.00196</td>\n      <td>696.80</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00000</td>\n      <td>-0.00192</td>\n      <td>724.42</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00000</td>\n      <td>-0.00188</td>\n      <td>751.84</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00000</td>\n      <td>-0.00184</td>\n      <td>779.83</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6358</th>\n      <td>0.00248</td>\n      <td>0.00184</td>\n      <td>651.36</td>\n    </tr>\n    <tr>\n      <th>6359</th>\n      <td>0.00248</td>\n      <td>0.00188</td>\n      <td>612.09</td>\n    </tr>\n    <tr>\n      <th>6360</th>\n      <td>0.00248</td>\n      <td>0.00192</td>\n      <td>584.59</td>\n    </tr>\n    <tr>\n      <th>6361</th>\n      <td>0.00248</td>\n      <td>0.00196</td>\n      <td>578.64</td>\n    </tr>\n    <tr>\n      <th>6362</th>\n      <td>0.00248</td>\n      <td>0.00200</td>\n      <td>572.78</td>\n    </tr>\n  </tbody>\n</table>\n<p>6363 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.drop(data.columns[2:5], axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8783d1d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T16:03:11.823854Z",
     "start_time": "2024-03-14T16:03:11.525006400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      X-Koordinate  Y-Koordinate  Temperatur\n",
      "6243       0.00244       0.00128      978.37\n",
      "2949       0.00116      -0.00120     1193.00\n",
      "393        0.00012       0.00160      816.01\n",
      "3844       0.00152      -0.00176      827.43\n",
      "2154       0.00084      -0.00068     1419.40\n",
      "...            ...           ...         ...\n",
      "3772       0.00148      -0.00060     1381.60\n",
      "5191       0.00204      -0.00040     1320.60\n",
      "5226       0.00204       0.00100     1122.50\n",
      "5390       0.00212      -0.00052     1288.40\n",
      "860        0.00032       0.00008     1509.50\n",
      "\n",
      "[6363 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": "      X-Koordinate  Y-Koordinate  Temperatur\n0          0.00244       0.00128      978.37\n1          0.00116      -0.00120     1193.00\n2          0.00012       0.00160      816.01\n3          0.00152      -0.00176      827.43\n4          0.00084      -0.00068     1419.40\n...            ...           ...         ...\n6358       0.00148      -0.00060     1381.60\n6359       0.00204      -0.00040     1320.60\n6360       0.00204       0.00100     1122.50\n6361       0.00212      -0.00052     1288.40\n6362       0.00032       0.00008     1509.50\n\n[6363 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00244</td>\n      <td>0.00128</td>\n      <td>978.37</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00116</td>\n      <td>-0.00120</td>\n      <td>1193.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00012</td>\n      <td>0.00160</td>\n      <td>816.01</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00152</td>\n      <td>-0.00176</td>\n      <td>827.43</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00084</td>\n      <td>-0.00068</td>\n      <td>1419.40</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6358</th>\n      <td>0.00148</td>\n      <td>-0.00060</td>\n      <td>1381.60</td>\n    </tr>\n    <tr>\n      <th>6359</th>\n      <td>0.00204</td>\n      <td>-0.00040</td>\n      <td>1320.60</td>\n    </tr>\n    <tr>\n      <th>6360</th>\n      <td>0.00204</td>\n      <td>0.00100</td>\n      <td>1122.50</td>\n    </tr>\n    <tr>\n      <th>6361</th>\n      <td>0.00212</td>\n      <td>-0.00052</td>\n      <td>1288.40</td>\n    </tr>\n    <tr>\n      <th>6362</th>\n      <td>0.00032</td>\n      <td>0.00008</td>\n      <td>1509.50</td>\n    </tr>\n  </tbody>\n</table>\n<p>6363 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.sample(frac=1, random_state=42)  # Hier wird 42 als Random State verwendet, um die Ergebnisse reproduzierbar zu machen\n",
    "\n",
    "print(df1)\n",
    "df_reset = df1.reset_index(drop=True)\n",
    "df_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4e72a16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T16:03:11.823854Z",
     "start_time": "2024-03-14T16:03:11.543256700Z"
    }
   },
   "outputs": [],
   "source": [
    "label = df_reset[\"Temperatur\"]\n",
    "# Korrektur: Verwenden Sie den Spaltennamen direkt, ohne Indexierung der columns-Eigenschaft\n",
    "df1 = df_reset.drop(\"Temperatur\", axis=1)\n",
    "X = df1\n",
    "y = label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7fa289a50d87423"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e694a236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T16:03:11.823854Z",
     "start_time": "2024-03-14T16:03:11.548993300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      X-Koordinate  Y-Koordinate\n0          0.00244       0.00128\n1          0.00116      -0.00120\n2          0.00012       0.00160\n3          0.00152      -0.00176\n4          0.00084      -0.00068\n...            ...           ...\n6358       0.00148      -0.00060\n6359       0.00204      -0.00040\n6360       0.00204       0.00100\n6361       0.00212      -0.00052\n6362       0.00032       0.00008\n\n[6363 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00244</td>\n      <td>0.00128</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00116</td>\n      <td>-0.00120</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00012</td>\n      <td>0.00160</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00152</td>\n      <td>-0.00176</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00084</td>\n      <td>-0.00068</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6358</th>\n      <td>0.00148</td>\n      <td>-0.00060</td>\n    </tr>\n    <tr>\n      <th>6359</th>\n      <td>0.00204</td>\n      <td>-0.00040</td>\n    </tr>\n    <tr>\n      <th>6360</th>\n      <td>0.00204</td>\n      <td>0.00100</td>\n    </tr>\n    <tr>\n      <th>6361</th>\n      <td>0.00212</td>\n      <td>-0.00052</td>\n    </tr>\n    <tr>\n      <th>6362</th>\n      <td>0.00032</td>\n      <td>0.00008</td>\n    </tr>\n  </tbody>\n</table>\n<p>6363 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f3303b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T16:03:11.823854Z",
     "start_time": "2024-03-14T16:03:11.554958600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0        978.37\n1       1193.00\n2        816.01\n3        827.43\n4       1419.40\n         ...   \n6358    1381.60\n6359    1320.60\n6360    1122.50\n6361    1288.40\n6362    1509.50\nName: Temperatur, Length: 6363, dtype: float64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3ad8da0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T16:03:11.823854Z",
     "start_time": "2024-03-14T16:03:11.562701800Z"
    }
   },
   "outputs": [],
   "source": [
    " # train_df enthält 80% der Daten, test_df enthält 20% der Daten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c705edb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T16:03:11.828863300Z",
     "start_time": "2024-03-14T16:03:11.569243200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialisiere einen MinMaxScaler für die Features\n",
    "scaler_features = MinMaxScaler()\n",
    "scaler_features2 = MinMaxScaler()\n",
    "# Skaliere X_train und X_test\n",
    "X_train_scaled = scaler_features.fit_transform(X_train)\n",
    "X_test_scaled = scaler_features.transform(X_test)  # Nutze gleiche Skalierungsparameter ohne das X_Test Informationen einfließen\n",
    "\n",
    "# Initialisiere einen SEPARATEN MinMaxScaler für das Ziel, wenn nötig\n",
    "scaler_target = MinMaxScaler()\n",
    "\n",
    "\n",
    "# Skaliere y_train und y_test. Beachte, dass y_train.reshape(-1, 1) verwendet wird, da MinMaxScaler \n",
    "# erwartet, dass die Eingaben als 2D-Arrays kommen, und Ziele normalerweise als 1D-Arrays vorliegen.\n",
    "y_train_scaled = scaler_target.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test_scaled = scaler_target.transform(y_test.values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbefe631e495b483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T16:03:11.859264400Z",
     "start_time": "2024-03-14T16:03:11.579030900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.96774194, 0.58      ],\n       [0.12903226, 0.07      ],\n       [0.03225806, 0.07      ],\n       ...,\n       [0.01612903, 0.25      ],\n       [0.67741935, 0.82      ],\n       [0.5483871 , 0.65      ]])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9999999999999999"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_scaled.max()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T16:03:11.859264400Z",
     "start_time": "2024-03-14T16:03:11.588741600Z"
    }
   },
   "id": "ce04ce43aac2242f"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "163/163 [==============================] - 3s 5ms/step - loss: 0.4698 - mae: 0.2654 - val_loss: 0.3928 - val_mae: 0.1828\n",
      "Epoch 2/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.3445 - mae: 0.1145 - val_loss: 0.3082 - val_mae: 0.0538\n",
      "Epoch 3/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.2958 - mae: 0.0557 - val_loss: 0.2825 - val_mae: 0.0577\n",
      "Epoch 4/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.2683 - mae: 0.0279 - val_loss: 0.2569 - val_mae: 0.0130\n",
      "Epoch 5/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.2493 - mae: 0.0208 - val_loss: 0.2410 - val_mae: 0.0157\n",
      "Epoch 6/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.2349 - mae: 0.0187 - val_loss: 0.2306 - val_mae: 0.0397\n",
      "Epoch 7/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.2250 - mae: 0.0319 - val_loss: 0.2201 - val_mae: 0.0354\n",
      "Epoch 8/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.2151 - mae: 0.0301 - val_loss: 0.2092 - val_mae: 0.0125\n",
      "Epoch 9/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.2055 - mae: 0.0125 - val_loss: 0.2019 - val_mae: 0.0099\n",
      "Epoch 10/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1994 - mae: 0.0183 - val_loss: 0.1975 - val_mae: 0.0309\n",
      "Epoch 11/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1937 - mae: 0.0197 - val_loss: 0.1905 - val_mae: 0.0130\n",
      "Epoch 12/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1888 - mae: 0.0215 - val_loss: 0.1864 - val_mae: 0.0220\n",
      "Epoch 13/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1849 - mae: 0.0239 - val_loss: 0.1811 - val_mae: 0.0077\n",
      "Epoch 14/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1805 - mae: 0.0242 - val_loss: 0.1772 - val_mae: 0.0096\n",
      "Epoch 15/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1759 - mae: 0.0169 - val_loss: 0.1735 - val_mae: 0.0097\n",
      "Epoch 16/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1723 - mae: 0.0179 - val_loss: 0.1706 - val_mae: 0.0195\n",
      "Epoch 17/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1689 - mae: 0.0176 - val_loss: 0.1675 - val_mae: 0.0225\n",
      "Epoch 18/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1656 - mae: 0.0183 - val_loss: 0.1701 - val_mae: 0.0586\n",
      "Epoch 19/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1626 - mae: 0.0189 - val_loss: 0.1601 - val_mae: 0.0057\n",
      "Epoch 20/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1638 - mae: 0.0406 - val_loss: 0.1601 - val_mae: 0.0390\n",
      "Epoch 21/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1562 - mae: 0.0132 - val_loss: 0.1545 - val_mae: 0.0081\n",
      "Epoch 22/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1531 - mae: 0.0072 - val_loss: 0.1518 - val_mae: 0.0078\n",
      "Epoch 23/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1506 - mae: 0.0091 - val_loss: 0.1493 - val_mae: 0.0108\n",
      "Epoch 24/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1479 - mae: 0.0076 - val_loss: 0.1465 - val_mae: 0.0044\n",
      "Epoch 25/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1454 - mae: 0.0098 - val_loss: 0.1440 - val_mae: 0.0078\n",
      "Epoch 26/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1429 - mae: 0.0111 - val_loss: 0.1415 - val_mae: 0.0050\n",
      "Epoch 27/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1405 - mae: 0.0126 - val_loss: 0.1394 - val_mae: 0.0156\n",
      "Epoch 28/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1381 - mae: 0.0125 - val_loss: 0.1371 - val_mae: 0.0156\n",
      "Epoch 29/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1361 - mae: 0.0173 - val_loss: 0.1343 - val_mae: 0.0067\n",
      "Epoch 30/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1336 - mae: 0.0145 - val_loss: 0.1322 - val_mae: 0.0134\n",
      "Epoch 31/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1349 - mae: 0.0419 - val_loss: 0.1305 - val_mae: 0.0203\n",
      "Epoch 32/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1295 - mae: 0.0164 - val_loss: 0.1279 - val_mae: 0.0053\n",
      "Epoch 33/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1270 - mae: 0.0081 - val_loss: 0.1261 - val_mae: 0.0102\n",
      "Epoch 34/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1251 - mae: 0.0100 - val_loss: 0.1240 - val_mae: 0.0057\n",
      "Epoch 35/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1235 - mae: 0.0141 - val_loss: 0.1224 - val_mae: 0.0145\n",
      "Epoch 36/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1227 - mae: 0.0239 - val_loss: 0.1262 - val_mae: 0.0590\n",
      "Epoch 37/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1204 - mae: 0.0206 - val_loss: 0.1188 - val_mae: 0.0167\n",
      "Epoch 38/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1176 - mae: 0.0092 - val_loss: 0.1167 - val_mae: 0.0084\n",
      "Epoch 39/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1157 - mae: 0.0064 - val_loss: 0.1149 - val_mae: 0.0066\n",
      "Epoch 40/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1140 - mae: 0.0069 - val_loss: 0.1131 - val_mae: 0.0068\n",
      "Epoch 41/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1136 - mae: 0.0234 - val_loss: 0.1116 - val_mae: 0.0134\n",
      "Epoch 42/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1106 - mae: 0.0092 - val_loss: 0.1097 - val_mae: 0.0085\n",
      "Epoch 43/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1089 - mae: 0.0086 - val_loss: 0.1079 - val_mae: 0.0059\n",
      "Epoch 44/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.1072 - mae: 0.0077 - val_loss: 0.1064 - val_mae: 0.0100\n",
      "Epoch 45/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1055 - mae: 0.0083 - val_loss: 0.1045 - val_mae: 0.0050\n",
      "Epoch 46/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.1043 - mae: 0.0169 - val_loss: 0.1041 - val_mae: 0.0303\n",
      "Epoch 47/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.1022 - mae: 0.0092 - val_loss: 0.1018 - val_mae: 0.0181\n",
      "Epoch 48/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.1007 - mae: 0.0131 - val_loss: 0.0998 - val_mae: 0.0090\n",
      "Epoch 49/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0990 - mae: 0.0091 - val_loss: 0.0980 - val_mae: 0.0044\n",
      "Epoch 50/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0973 - mae: 0.0071 - val_loss: 0.0967 - val_mae: 0.0159\n",
      "Epoch 51/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0975 - mae: 0.0300 - val_loss: 0.0952 - val_mae: 0.0128\n",
      "Epoch 52/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0944 - mae: 0.0108 - val_loss: 0.0936 - val_mae: 0.0087\n",
      "Epoch 53/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0929 - mae: 0.0065 - val_loss: 0.0923 - val_mae: 0.0101\n",
      "Epoch 54/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0915 - mae: 0.0086 - val_loss: 0.0909 - val_mae: 0.0105\n",
      "Epoch 55/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0902 - mae: 0.0091 - val_loss: 0.0894 - val_mae: 0.0075\n",
      "Epoch 56/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0887 - mae: 0.0077 - val_loss: 0.0880 - val_mae: 0.0084\n",
      "Epoch 57/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0881 - mae: 0.0180 - val_loss: 0.0866 - val_mae: 0.0101\n",
      "Epoch 58/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0859 - mae: 0.0059 - val_loss: 0.0852 - val_mae: 0.0038\n",
      "Epoch 59/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0846 - mae: 0.0061 - val_loss: 0.0839 - val_mae: 0.0049\n",
      "Epoch 60/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0832 - mae: 0.0062 - val_loss: 0.0826 - val_mae: 0.0083\n",
      "Epoch 61/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0820 - mae: 0.0094 - val_loss: 0.0814 - val_mae: 0.0128\n",
      "Epoch 62/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0814 - mae: 0.0164 - val_loss: 0.0799 - val_mae: 0.0039\n",
      "Epoch 63/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0794 - mae: 0.0082 - val_loss: 0.0787 - val_mae: 0.0046\n",
      "Epoch 64/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0781 - mae: 0.0050 - val_loss: 0.0775 - val_mae: 0.0059\n",
      "Epoch 65/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0769 - mae: 0.0069 - val_loss: 0.0763 - val_mae: 0.0079\n",
      "Epoch 66/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0756 - mae: 0.0070 - val_loss: 0.0749 - val_mae: 0.0041\n",
      "Epoch 67/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0743 - mae: 0.0061 - val_loss: 0.0736 - val_mae: 0.0040\n",
      "Epoch 68/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0731 - mae: 0.0070 - val_loss: 0.0740 - val_mae: 0.0339\n",
      "Epoch 69/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0720 - mae: 0.0117 - val_loss: 0.0725 - val_mae: 0.0303\n",
      "Epoch 70/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0706 - mae: 0.0072 - val_loss: 0.0699 - val_mae: 0.0043\n",
      "Epoch 71/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0694 - mae: 0.0063 - val_loss: 0.0687 - val_mae: 0.0043\n",
      "Epoch 72/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0682 - mae: 0.0062 - val_loss: 0.0676 - val_mae: 0.0072\n",
      "Epoch 73/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0669 - mae: 0.0055 - val_loss: 0.0663 - val_mae: 0.0034\n",
      "Epoch 74/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0663 - mae: 0.0147 - val_loss: 0.0699 - val_mae: 0.0505\n",
      "Epoch 75/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0649 - mae: 0.0107 - val_loss: 0.0641 - val_mae: 0.0041\n",
      "Epoch 76/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0638 - mae: 0.0097 - val_loss: 0.0632 - val_mae: 0.0098\n",
      "Epoch 77/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0637 - mae: 0.0212 - val_loss: 0.0623 - val_mae: 0.0099\n",
      "Epoch 78/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0618 - mae: 0.0056 - val_loss: 0.0613 - val_mae: 0.0034\n",
      "Epoch 79/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0609 - mae: 0.0041 - val_loss: 0.0604 - val_mae: 0.0036\n",
      "Epoch 80/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0600 - mae: 0.0060 - val_loss: 0.0595 - val_mae: 0.0048\n",
      "Epoch 81/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0591 - mae: 0.0068 - val_loss: 0.0587 - val_mae: 0.0099\n",
      "Epoch 82/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0582 - mae: 0.0063 - val_loss: 0.0577 - val_mae: 0.0071\n",
      "Epoch 83/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0572 - mae: 0.0059 - val_loss: 0.0569 - val_mae: 0.0113\n",
      "Epoch 84/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0563 - mae: 0.0066 - val_loss: 0.0558 - val_mae: 0.0065\n",
      "Epoch 85/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0553 - mae: 0.0048 - val_loss: 0.0550 - val_mae: 0.0118\n",
      "Epoch 86/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0544 - mae: 0.0078 - val_loss: 0.0541 - val_mae: 0.0134\n",
      "Epoch 87/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0535 - mae: 0.0078 - val_loss: 0.0530 - val_mae: 0.0061\n",
      "Epoch 88/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0525 - mae: 0.0076 - val_loss: 0.0520 - val_mae: 0.0053\n",
      "Epoch 89/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0516 - mae: 0.0066 - val_loss: 0.0511 - val_mae: 0.0063\n",
      "Epoch 90/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0507 - mae: 0.0071 - val_loss: 0.0502 - val_mae: 0.0066\n",
      "Epoch 91/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0497 - mae: 0.0063 - val_loss: 0.0492 - val_mae: 0.0038\n",
      "Epoch 92/500\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.0488 - mae: 0.0067 - val_loss: 0.0485 - val_mae: 0.0118\n",
      "Epoch 93/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0481 - mae: 0.0117 - val_loss: 0.0474 - val_mae: 0.0052\n",
      "Epoch 94/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0478 - mae: 0.0175 - val_loss: 0.0470 - val_mae: 0.0140\n",
      "Epoch 95/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0464 - mae: 0.0061 - val_loss: 0.0460 - val_mae: 0.0045\n",
      "Epoch 96/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0456 - mae: 0.0054 - val_loss: 0.0453 - val_mae: 0.0063\n",
      "Epoch 97/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0449 - mae: 0.0058 - val_loss: 0.0446 - val_mae: 0.0092\n",
      "Epoch 98/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0442 - mae: 0.0064 - val_loss: 0.0438 - val_mae: 0.0033\n",
      "Epoch 99/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0435 - mae: 0.0047 - val_loss: 0.0431 - val_mae: 0.0056\n",
      "Epoch 100/500\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.0427 - mae: 0.0062 - val_loss: 0.0425 - val_mae: 0.0120\n",
      "Epoch 101/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0420 - mae: 0.0073 - val_loss: 0.0417 - val_mae: 0.0087\n",
      "Epoch 102/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0413 - mae: 0.0076 - val_loss: 0.0409 - val_mae: 0.0066\n",
      "Epoch 103/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0405 - mae: 0.0069 - val_loss: 0.0401 - val_mae: 0.0051\n",
      "Epoch 104/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0398 - mae: 0.0077 - val_loss: 0.0394 - val_mae: 0.0035\n",
      "Epoch 105/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0392 - mae: 0.0096 - val_loss: 0.0387 - val_mae: 0.0041\n",
      "Epoch 106/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0384 - mae: 0.0059 - val_loss: 0.0380 - val_mae: 0.0060\n",
      "Epoch 107/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0377 - mae: 0.0064 - val_loss: 0.0377 - val_mae: 0.0147\n",
      "Epoch 108/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0372 - mae: 0.0123 - val_loss: 0.0367 - val_mae: 0.0061\n",
      "Epoch 109/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0364 - mae: 0.0080 - val_loss: 0.0363 - val_mae: 0.0113\n",
      "Epoch 110/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0358 - mae: 0.0066 - val_loss: 0.0355 - val_mae: 0.0073\n",
      "Epoch 111/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0352 - mae: 0.0081 - val_loss: 0.0349 - val_mae: 0.0061\n",
      "Epoch 112/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0345 - mae: 0.0051 - val_loss: 0.0342 - val_mae: 0.0040\n",
      "Epoch 113/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0339 - mae: 0.0044 - val_loss: 0.0336 - val_mae: 0.0057\n",
      "Epoch 114/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0333 - mae: 0.0059 - val_loss: 0.0333 - val_mae: 0.0138\n",
      "Epoch 115/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0327 - mae: 0.0068 - val_loss: 0.0324 - val_mae: 0.0066\n",
      "Epoch 116/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0321 - mae: 0.0070 - val_loss: 0.0319 - val_mae: 0.0097\n",
      "Epoch 117/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0315 - mae: 0.0064 - val_loss: 0.0313 - val_mae: 0.0110\n",
      "Epoch 118/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0309 - mae: 0.0061 - val_loss: 0.0306 - val_mae: 0.0070\n",
      "Epoch 119/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0304 - mae: 0.0070 - val_loss: 0.0300 - val_mae: 0.0033\n",
      "Epoch 120/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0297 - mae: 0.0049 - val_loss: 0.0294 - val_mae: 0.0035\n",
      "Epoch 121/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0293 - mae: 0.0074 - val_loss: 0.0293 - val_mae: 0.0176\n",
      "Epoch 122/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0287 - mae: 0.0083 - val_loss: 0.0284 - val_mae: 0.0081\n",
      "Epoch 123/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0281 - mae: 0.0066 - val_loss: 0.0278 - val_mae: 0.0039\n",
      "Epoch 124/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.0058 - val_loss: 0.0273 - val_mae: 0.0037\n",
      "Epoch 125/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0271 - mae: 0.0060 - val_loss: 0.0268 - val_mae: 0.0059\n",
      "Epoch 126/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0266 - mae: 0.0055 - val_loss: 0.0263 - val_mae: 0.0038\n",
      "Epoch 127/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0261 - mae: 0.0064 - val_loss: 0.0258 - val_mae: 0.0048\n",
      "Epoch 128/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0256 - mae: 0.0071 - val_loss: 0.0253 - val_mae: 0.0054\n",
      "Epoch 129/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0250 - mae: 0.0054 - val_loss: 0.0248 - val_mae: 0.0043\n",
      "Epoch 130/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0246 - mae: 0.0054 - val_loss: 0.0243 - val_mae: 0.0051\n",
      "Epoch 131/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0241 - mae: 0.0080 - val_loss: 0.0238 - val_mae: 0.0043\n",
      "Epoch 132/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0236 - mae: 0.0056 - val_loss: 0.0234 - val_mae: 0.0047\n",
      "Epoch 133/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0232 - mae: 0.0068 - val_loss: 0.0229 - val_mae: 0.0078\n",
      "Epoch 134/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0227 - mae: 0.0072 - val_loss: 0.0225 - val_mae: 0.0046\n",
      "Epoch 135/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0223 - mae: 0.0060 - val_loss: 0.0220 - val_mae: 0.0037\n",
      "Epoch 136/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0219 - mae: 0.0073 - val_loss: 0.0216 - val_mae: 0.0046\n",
      "Epoch 137/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0215 - mae: 0.0068 - val_loss: 0.0213 - val_mae: 0.0099\n",
      "Epoch 138/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0211 - mae: 0.0069 - val_loss: 0.0209 - val_mae: 0.0076\n",
      "Epoch 139/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0206 - mae: 0.0055 - val_loss: 0.0204 - val_mae: 0.0054\n",
      "Epoch 140/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0202 - mae: 0.0058 - val_loss: 0.0200 - val_mae: 0.0062\n",
      "Epoch 141/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0199 - mae: 0.0086 - val_loss: 0.0196 - val_mae: 0.0053\n",
      "Epoch 142/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0195 - mae: 0.0060 - val_loss: 0.0193 - val_mae: 0.0068\n",
      "Epoch 143/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0191 - mae: 0.0054 - val_loss: 0.0189 - val_mae: 0.0038\n",
      "Epoch 144/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0188 - mae: 0.0063 - val_loss: 0.0186 - val_mae: 0.0066\n",
      "Epoch 145/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0184 - mae: 0.0066 - val_loss: 0.0182 - val_mae: 0.0048\n",
      "Epoch 146/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0180 - mae: 0.0049 - val_loss: 0.0179 - val_mae: 0.0089\n",
      "Epoch 147/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0177 - mae: 0.0050 - val_loss: 0.0175 - val_mae: 0.0071\n",
      "Epoch 148/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0174 - mae: 0.0071 - val_loss: 0.0173 - val_mae: 0.0097\n",
      "Epoch 149/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0170 - mae: 0.0062 - val_loss: 0.0168 - val_mae: 0.0045\n",
      "Epoch 150/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0167 - mae: 0.0055 - val_loss: 0.0166 - val_mae: 0.0077\n",
      "Epoch 151/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0165 - mae: 0.0080 - val_loss: 0.0162 - val_mae: 0.0043\n",
      "Epoch 152/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0161 - mae: 0.0056 - val_loss: 0.0159 - val_mae: 0.0069\n",
      "Epoch 153/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0044 - val_loss: 0.0156 - val_mae: 0.0047\n",
      "Epoch 154/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0155 - mae: 0.0051 - val_loss: 0.0153 - val_mae: 0.0048\n",
      "Epoch 155/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0152 - mae: 0.0058 - val_loss: 0.0150 - val_mae: 0.0056\n",
      "Epoch 156/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0149 - mae: 0.0046 - val_loss: 0.0147 - val_mae: 0.0054\n",
      "Epoch 157/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0146 - mae: 0.0072 - val_loss: 0.0145 - val_mae: 0.0064\n",
      "Epoch 158/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0143 - mae: 0.0060 - val_loss: 0.0142 - val_mae: 0.0035\n",
      "Epoch 159/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0141 - mae: 0.0082 - val_loss: 0.0141 - val_mae: 0.0116\n",
      "Epoch 160/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0056 - val_loss: 0.0136 - val_mae: 0.0033\n",
      "Epoch 161/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0136 - mae: 0.0058 - val_loss: 0.0134 - val_mae: 0.0036\n",
      "Epoch 162/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0133 - mae: 0.0045 - val_loss: 0.0132 - val_mae: 0.0057\n",
      "Epoch 163/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0131 - mae: 0.0052 - val_loss: 0.0129 - val_mae: 0.0038\n",
      "Epoch 164/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0129 - mae: 0.0069 - val_loss: 0.0128 - val_mae: 0.0086\n",
      "Epoch 165/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0065 - val_loss: 0.0125 - val_mae: 0.0079\n",
      "Epoch 166/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0052 - val_loss: 0.0123 - val_mae: 0.0043\n",
      "Epoch 167/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0081 - val_loss: 0.0121 - val_mae: 0.0041\n",
      "Epoch 168/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0052 - val_loss: 0.0119 - val_mae: 0.0096\n",
      "Epoch 169/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0118 - mae: 0.0068 - val_loss: 0.0117 - val_mae: 0.0046\n",
      "Epoch 170/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0116 - mae: 0.0051 - val_loss: 0.0114 - val_mae: 0.0028\n",
      "Epoch 171/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0114 - mae: 0.0049 - val_loss: 0.0113 - val_mae: 0.0063\n",
      "Epoch 172/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0112 - mae: 0.0047 - val_loss: 0.0111 - val_mae: 0.0051\n",
      "Epoch 173/500\n",
      "163/163 [==============================] - 1s 4ms/step - loss: 0.0110 - mae: 0.0058 - val_loss: 0.0109 - val_mae: 0.0072\n",
      "Epoch 174/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0108 - mae: 0.0048 - val_loss: 0.0107 - val_mae: 0.0069\n",
      "Epoch 175/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0107 - mae: 0.0074 - val_loss: 0.0106 - val_mae: 0.0071\n",
      "Epoch 176/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0104 - mae: 0.0050 - val_loss: 0.0103 - val_mae: 0.0041\n",
      "Epoch 177/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0103 - mae: 0.0057 - val_loss: 0.0103 - val_mae: 0.0091\n",
      "Epoch 178/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0102 - mae: 0.0093 - val_loss: 0.0107 - val_mae: 0.0248\n",
      "Epoch 179/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0100 - mae: 0.0066 - val_loss: 0.0098 - val_mae: 0.0037\n",
      "Epoch 180/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0098 - mae: 0.0044 - val_loss: 0.0097 - val_mae: 0.0039\n",
      "Epoch 181/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0040 - val_loss: 0.0095 - val_mae: 0.0035\n",
      "Epoch 182/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0095 - mae: 0.0041 - val_loss: 0.0094 - val_mae: 0.0037\n",
      "Epoch 183/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0095 - mae: 0.0090 - val_loss: 0.0092 - val_mae: 0.0036\n",
      "Epoch 184/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0049 - val_loss: 0.0091 - val_mae: 0.0058\n",
      "Epoch 185/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0049 - val_loss: 0.0090 - val_mae: 0.0032\n",
      "Epoch 186/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0045 - val_loss: 0.0088 - val_mae: 0.0041\n",
      "Epoch 187/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0050 - val_loss: 0.0087 - val_mae: 0.0058\n",
      "Epoch 188/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0045 - val_loss: 0.0085 - val_mae: 0.0033\n",
      "Epoch 189/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0053 - val_loss: 0.0084 - val_mae: 0.0031\n",
      "Epoch 190/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0059 - val_loss: 0.0083 - val_mae: 0.0059\n",
      "Epoch 191/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0051 - val_loss: 0.0082 - val_mae: 0.0064\n",
      "Epoch 192/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0055 - val_loss: 0.0080 - val_mae: 0.0037\n",
      "Epoch 193/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0080 - mae: 0.0050 - val_loss: 0.0079 - val_mae: 0.0042\n",
      "Epoch 194/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0047 - val_loss: 0.0077 - val_mae: 0.0053\n",
      "Epoch 195/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0058 - val_loss: 0.0076 - val_mae: 0.0035\n",
      "Epoch 196/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0065 - val_loss: 0.0075 - val_mae: 0.0044\n",
      "Epoch 197/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0075 - mae: 0.0052 - val_loss: 0.0074 - val_mae: 0.0047\n",
      "Epoch 198/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0073 - mae: 0.0046 - val_loss: 0.0073 - val_mae: 0.0104\n",
      "Epoch 199/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0072 - mae: 0.0052 - val_loss: 0.0071 - val_mae: 0.0053\n",
      "Epoch 200/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0072 - mae: 0.0078 - val_loss: 0.0070 - val_mae: 0.0052\n",
      "Epoch 201/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0070 - mae: 0.0052 - val_loss: 0.0070 - val_mae: 0.0066\n",
      "Epoch 202/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0069 - mae: 0.0062 - val_loss: 0.0069 - val_mae: 0.0060\n",
      "Epoch 203/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0068 - mae: 0.0049 - val_loss: 0.0068 - val_mae: 0.0064\n",
      "Epoch 204/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0067 - mae: 0.0056 - val_loss: 0.0066 - val_mae: 0.0042\n",
      "Epoch 205/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0066 - mae: 0.0069 - val_loss: 0.0066 - val_mae: 0.0076\n",
      "Epoch 206/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0065 - mae: 0.0054 - val_loss: 0.0064 - val_mae: 0.0046\n",
      "Epoch 207/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0064 - mae: 0.0058 - val_loss: 0.0064 - val_mae: 0.0051\n",
      "Epoch 208/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0064 - mae: 0.0065 - val_loss: 0.0063 - val_mae: 0.0048\n",
      "Epoch 209/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0062 - mae: 0.0042 - val_loss: 0.0062 - val_mae: 0.0028\n",
      "Epoch 210/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0062 - mae: 0.0055 - val_loss: 0.0061 - val_mae: 0.0039\n",
      "Epoch 211/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0061 - mae: 0.0057 - val_loss: 0.0060 - val_mae: 0.0043\n",
      "Epoch 212/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0060 - mae: 0.0049 - val_loss: 0.0059 - val_mae: 0.0032\n",
      "Epoch 213/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0059 - mae: 0.0048 - val_loss: 0.0058 - val_mae: 0.0040\n",
      "Epoch 214/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0058 - mae: 0.0041 - val_loss: 0.0058 - val_mae: 0.0054\n",
      "Epoch 215/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0058 - mae: 0.0060 - val_loss: 0.0057 - val_mae: 0.0051\n",
      "Epoch 216/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0056 - mae: 0.0050 - val_loss: 0.0056 - val_mae: 0.0039\n",
      "Epoch 217/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0056 - mae: 0.0040 - val_loss: 0.0055 - val_mae: 0.0032\n",
      "Epoch 218/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0055 - mae: 0.0051 - val_loss: 0.0055 - val_mae: 0.0059\n",
      "Epoch 219/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0054 - mae: 0.0055 - val_loss: 0.0054 - val_mae: 0.0087\n",
      "Epoch 220/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0053 - mae: 0.0054 - val_loss: 0.0053 - val_mae: 0.0058\n",
      "Epoch 221/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0053 - mae: 0.0050 - val_loss: 0.0052 - val_mae: 0.0056\n",
      "Epoch 222/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0052 - mae: 0.0062 - val_loss: 0.0051 - val_mae: 0.0046\n",
      "Epoch 223/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0051 - mae: 0.0060 - val_loss: 0.0051 - val_mae: 0.0050\n",
      "Epoch 224/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0051 - mae: 0.0048 - val_loss: 0.0050 - val_mae: 0.0035\n",
      "Epoch 225/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0049 - val_loss: 0.0051 - val_mae: 0.0093\n",
      "Epoch 226/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0050 - mae: 0.0065 - val_loss: 0.0049 - val_mae: 0.0070\n",
      "Epoch 227/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0050 - val_loss: 0.0049 - val_mae: 0.0090\n",
      "Epoch 228/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0058 - val_loss: 0.0048 - val_mae: 0.0030\n",
      "Epoch 229/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0048 - mae: 0.0054 - val_loss: 0.0047 - val_mae: 0.0049\n",
      "Epoch 230/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0047 - mae: 0.0042 - val_loss: 0.0046 - val_mae: 0.0047\n",
      "Epoch 231/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0046 - mae: 0.0048 - val_loss: 0.0046 - val_mae: 0.0063\n",
      "Epoch 232/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0046 - mae: 0.0043 - val_loss: 0.0045 - val_mae: 0.0037\n",
      "Epoch 233/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0047 - val_loss: 0.0045 - val_mae: 0.0065\n",
      "Epoch 234/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0050 - val_loss: 0.0044 - val_mae: 0.0062\n",
      "Epoch 235/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0048 - val_loss: 0.0045 - val_mae: 0.0116\n",
      "Epoch 236/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0054 - val_loss: 0.0044 - val_mae: 0.0091\n",
      "Epoch 237/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0062 - val_loss: 0.0043 - val_mae: 0.0068\n",
      "Epoch 238/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0048 - val_loss: 0.0042 - val_mae: 0.0031\n",
      "Epoch 239/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0065 - val_loss: 0.0042 - val_mae: 0.0075\n",
      "Epoch 240/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0048 - val_loss: 0.0041 - val_mae: 0.0048\n",
      "Epoch 241/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0048 - val_loss: 0.0041 - val_mae: 0.0038\n",
      "Epoch 242/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0050 - val_loss: 0.0041 - val_mae: 0.0090\n",
      "Epoch 243/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0046 - val_loss: 0.0040 - val_mae: 0.0045\n",
      "Epoch 244/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0040 - mae: 0.0048 - val_loss: 0.0039 - val_mae: 0.0031\n",
      "Epoch 245/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0052 - val_loss: 0.0039 - val_mae: 0.0055\n",
      "Epoch 246/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0062 - val_loss: 0.0039 - val_mae: 0.0045\n",
      "Epoch 247/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0039 - mae: 0.0057 - val_loss: 0.0038 - val_mae: 0.0037\n",
      "Epoch 248/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0051 - val_loss: 0.0038 - val_mae: 0.0053\n",
      "Epoch 249/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0047 - val_loss: 0.0038 - val_mae: 0.0087\n",
      "Epoch 250/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0042 - val_loss: 0.0037 - val_mae: 0.0030\n",
      "Epoch 251/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0050 - val_loss: 0.0037 - val_mae: 0.0035\n",
      "Epoch 252/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0057 - val_loss: 0.0036 - val_mae: 0.0043\n",
      "Epoch 253/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0050 - val_loss: 0.0036 - val_mae: 0.0058\n",
      "Epoch 254/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0051 - val_loss: 0.0036 - val_mae: 0.0059\n",
      "Epoch 255/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0042 - val_loss: 0.0035 - val_mae: 0.0031\n",
      "Epoch 256/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0044 - val_loss: 0.0035 - val_mae: 0.0052\n",
      "Epoch 257/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0056 - val_loss: 0.0035 - val_mae: 0.0092\n",
      "Epoch 258/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0045 - val_loss: 0.0034 - val_mae: 0.0032\n",
      "Epoch 259/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0070 - val_loss: 0.0035 - val_mae: 0.0098\n",
      "Epoch 260/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0047 - val_loss: 0.0033 - val_mae: 0.0043\n",
      "Epoch 261/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0039 - val_loss: 0.0033 - val_mae: 0.0030\n",
      "Epoch 262/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0041 - val_loss: 0.0033 - val_mae: 0.0036\n",
      "Epoch 263/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0046 - val_loss: 0.0033 - val_mae: 0.0052\n",
      "Epoch 264/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0068 - val_loss: 0.0032 - val_mae: 0.0063\n",
      "Epoch 265/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0032 - mae: 0.0042 - val_loss: 0.0032 - val_mae: 0.0079\n",
      "Epoch 266/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0038 - val_loss: 0.0031 - val_mae: 0.0045\n",
      "Epoch 267/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0045 - val_loss: 0.0031 - val_mae: 0.0028\n",
      "Epoch 268/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0031 - mae: 0.0053 - val_loss: 0.0032 - val_mae: 0.0092\n",
      "Epoch 269/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0057 - val_loss: 0.0031 - val_mae: 0.0042\n",
      "Epoch 270/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0044 - val_loss: 0.0031 - val_mae: 0.0061\n",
      "Epoch 271/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0054 - val_loss: 0.0030 - val_mae: 0.0040\n",
      "Epoch 272/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0058 - val_loss: 0.0030 - val_mae: 0.0042\n",
      "Epoch 273/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0048 - val_loss: 0.0030 - val_mae: 0.0048\n",
      "Epoch 274/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0055 - val_loss: 0.0029 - val_mae: 0.0040\n",
      "Epoch 275/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0051 - val_loss: 0.0029 - val_mae: 0.0035\n",
      "Epoch 276/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0043 - val_loss: 0.0029 - val_mae: 0.0034\n",
      "Epoch 277/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0051 - val_loss: 0.0029 - val_mae: 0.0038\n",
      "Epoch 278/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0046 - val_loss: 0.0030 - val_mae: 0.0127\n",
      "Epoch 279/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0048 - val_loss: 0.0028 - val_mae: 0.0026\n",
      "Epoch 280/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0061 - val_loss: 0.0028 - val_mae: 0.0034\n",
      "Epoch 281/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0051 - val_loss: 0.0028 - val_mae: 0.0036\n",
      "Epoch 282/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0053 - val_loss: 0.0027 - val_mae: 0.0032\n",
      "Epoch 283/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0042 - val_loss: 0.0027 - val_mae: 0.0029\n",
      "Epoch 284/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0044 - val_loss: 0.0027 - val_mae: 0.0037\n",
      "Epoch 285/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0038 - val_loss: 0.0027 - val_mae: 0.0040\n",
      "Epoch 286/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0064 - val_loss: 0.0027 - val_mae: 0.0046\n",
      "Epoch 287/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0044 - val_loss: 0.0027 - val_mae: 0.0056\n",
      "Epoch 288/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0050 - val_loss: 0.0026 - val_mae: 0.0028\n",
      "Epoch 289/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0047 - val_loss: 0.0026 - val_mae: 0.0047\n",
      "Epoch 290/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0046 - val_loss: 0.0026 - val_mae: 0.0044\n",
      "Epoch 291/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0041 - val_loss: 0.0026 - val_mae: 0.0066\n",
      "Epoch 292/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0042 - val_loss: 0.0025 - val_mae: 0.0045\n",
      "Epoch 293/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0053 - val_loss: 0.0025 - val_mae: 0.0055\n",
      "Epoch 294/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0076 - val_loss: 0.0025 - val_mae: 0.0064\n",
      "Epoch 295/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0040 - val_loss: 0.0026 - val_mae: 0.0101\n",
      "Epoch 296/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0049 - val_loss: 0.0025 - val_mae: 0.0036\n",
      "Epoch 297/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0051 - val_loss: 0.0024 - val_mae: 0.0035\n",
      "Epoch 298/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0045 - val_loss: 0.0025 - val_mae: 0.0064\n",
      "Epoch 299/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0051 - val_loss: 0.0024 - val_mae: 0.0035\n",
      "Epoch 300/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0044 - val_loss: 0.0024 - val_mae: 0.0034\n",
      "Epoch 301/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0055 - val_loss: 0.0024 - val_mae: 0.0052\n",
      "Epoch 302/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0039 - val_loss: 0.0024 - val_mae: 0.0048\n",
      "Epoch 303/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0046 - val_loss: 0.0023 - val_mae: 0.0038\n",
      "Epoch 304/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0053 - val_loss: 0.0024 - val_mae: 0.0080\n",
      "Epoch 305/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0044 - val_loss: 0.0023 - val_mae: 0.0037\n",
      "Epoch 306/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0042 - val_loss: 0.0023 - val_mae: 0.0035\n",
      "Epoch 307/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0041 - val_loss: 0.0024 - val_mae: 0.0113\n",
      "Epoch 308/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0058 - val_loss: 0.0023 - val_mae: 0.0029\n",
      "Epoch 309/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0047 - val_loss: 0.0023 - val_mae: 0.0038\n",
      "Epoch 310/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0042 - val_loss: 0.0022 - val_mae: 0.0033\n",
      "Epoch 311/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0050 - val_loss: 0.0023 - val_mae: 0.0053\n",
      "Epoch 312/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0048 - val_loss: 0.0022 - val_mae: 0.0062\n",
      "Epoch 313/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0051 - val_loss: 0.0022 - val_mae: 0.0042\n",
      "Epoch 314/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0048 - val_loss: 0.0022 - val_mae: 0.0051\n",
      "Epoch 315/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0049 - val_loss: 0.0022 - val_mae: 0.0059\n",
      "Epoch 316/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0045 - val_loss: 0.0022 - val_mae: 0.0042\n",
      "Epoch 317/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0051 - val_loss: 0.0022 - val_mae: 0.0062\n",
      "Epoch 318/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0044 - val_loss: 0.0021 - val_mae: 0.0039\n",
      "Epoch 319/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0051 - val_loss: 0.0021 - val_mae: 0.0044\n",
      "Epoch 320/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0047 - val_loss: 0.0021 - val_mae: 0.0039\n",
      "Epoch 321/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0057 - val_loss: 0.0021 - val_mae: 0.0039\n",
      "Epoch 322/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0050 - val_loss: 0.0021 - val_mae: 0.0032\n",
      "Epoch 323/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0056 - val_loss: 0.0021 - val_mae: 0.0034\n",
      "Epoch 324/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0040 - val_loss: 0.0021 - val_mae: 0.0033\n",
      "Epoch 325/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0053 - val_loss: 0.0021 - val_mae: 0.0069\n",
      "Epoch 326/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0051 - val_loss: 0.0021 - val_mae: 0.0063\n",
      "Epoch 327/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0043 - val_loss: 0.0020 - val_mae: 0.0028\n",
      "Epoch 328/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0041 - val_loss: 0.0021 - val_mae: 0.0062\n",
      "Epoch 329/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0041 - val_loss: 0.0020 - val_mae: 0.0032\n",
      "Epoch 330/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0051 - val_loss: 0.0020 - val_mae: 0.0051\n",
      "Epoch 331/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0053 - val_loss: 0.0020 - val_mae: 0.0046\n",
      "Epoch 332/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0048 - val_loss: 0.0020 - val_mae: 0.0036\n",
      "Epoch 333/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0046 - val_loss: 0.0020 - val_mae: 0.0037\n",
      "Epoch 334/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0051 - val_loss: 0.0020 - val_mae: 0.0049\n",
      "Epoch 335/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0040 - val_loss: 0.0020 - val_mae: 0.0037\n",
      "Epoch 336/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0055 - val_loss: 0.0019 - val_mae: 0.0035\n",
      "Epoch 337/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0054 - val_loss: 0.0020 - val_mae: 0.0051\n",
      "Epoch 338/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0049 - val_loss: 0.0019 - val_mae: 0.0035\n",
      "Epoch 339/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0051 - val_loss: 0.0019 - val_mae: 0.0040\n",
      "Epoch 340/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0052 - val_loss: 0.0019 - val_mae: 0.0036\n",
      "Epoch 341/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0042 - val_loss: 0.0019 - val_mae: 0.0040\n",
      "Epoch 342/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0048 - val_loss: 0.0019 - val_mae: 0.0035\n",
      "Epoch 343/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0040 - val_loss: 0.0019 - val_mae: 0.0046\n",
      "Epoch 344/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0055 - val_loss: 0.0019 - val_mae: 0.0061\n",
      "Epoch 345/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0049 - val_loss: 0.0019 - val_mae: 0.0030\n",
      "Epoch 346/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0051 - val_loss: 0.0019 - val_mae: 0.0095\n",
      "Epoch 347/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0057 - val_loss: 0.0019 - val_mae: 0.0064\n",
      "Epoch 348/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0051 - val_loss: 0.0018 - val_mae: 0.0031\n",
      "Epoch 349/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0053 - val_loss: 0.0019 - val_mae: 0.0091\n",
      "Epoch 350/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0043 - val_loss: 0.0018 - val_mae: 0.0041\n",
      "Epoch 351/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0060 - val_loss: 0.0019 - val_mae: 0.0089\n",
      "Epoch 352/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0041 - val_loss: 0.0018 - val_mae: 0.0030\n",
      "Epoch 353/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0052 - val_loss: 0.0018 - val_mae: 0.0038\n",
      "Epoch 354/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0047 - val_loss: 0.0018 - val_mae: 0.0027\n",
      "Epoch 355/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0038 - val_loss: 0.0018 - val_mae: 0.0030\n",
      "Epoch 356/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0045 - val_loss: 0.0018 - val_mae: 0.0052\n",
      "Epoch 357/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0046 - val_loss: 0.0018 - val_mae: 0.0036\n",
      "Epoch 358/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0043 - val_loss: 0.0018 - val_mae: 0.0034\n",
      "Epoch 359/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0055 - val_loss: 0.0018 - val_mae: 0.0040\n",
      "Epoch 360/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0018 - mae: 0.0054 - val_loss: 0.0018 - val_mae: 0.0039\n",
      "Epoch 361/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0018 - mae: 0.0045 - val_loss: 0.0018 - val_mae: 0.0042\n",
      "Epoch 362/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0055 - val_loss: 0.0018 - val_mae: 0.0055\n",
      "Epoch 363/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0063 - val_loss: 0.0018 - val_mae: 0.0066\n",
      "Epoch 364/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0048 - val_loss: 0.0017 - val_mae: 0.0039\n",
      "Epoch 365/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0045 - val_loss: 0.0017 - val_mae: 0.0048\n",
      "Epoch 366/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0041 - val_loss: 0.0017 - val_mae: 0.0042\n",
      "Epoch 367/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0049 - val_loss: 0.0017 - val_mae: 0.0038\n",
      "Epoch 368/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0040 - val_loss: 0.0017 - val_mae: 0.0028\n",
      "Epoch 369/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0053 - val_loss: 0.0017 - val_mae: 0.0057\n",
      "Epoch 370/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0047 - val_loss: 0.0017 - val_mae: 0.0033\n",
      "Epoch 371/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0045 - val_loss: 0.0017 - val_mae: 0.0037\n",
      "Epoch 372/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0056 - val_loss: 0.0017 - val_mae: 0.0049\n",
      "Epoch 373/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0052 - val_loss: 0.0017 - val_mae: 0.0036\n",
      "Epoch 374/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0050 - val_loss: 0.0017 - val_mae: 0.0069\n",
      "Epoch 375/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0046 - val_loss: 0.0017 - val_mae: 0.0044\n",
      "Epoch 376/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0042 - val_loss: 0.0017 - val_mae: 0.0078\n",
      "Epoch 377/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0049 - val_loss: 0.0017 - val_mae: 0.0077\n",
      "Epoch 378/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0045 - val_loss: 0.0016 - val_mae: 0.0029\n",
      "Epoch 379/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0041 - val_loss: 0.0016 - val_mae: 0.0033\n",
      "Epoch 380/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0047 - val_loss: 0.0017 - val_mae: 0.0047\n",
      "Epoch 381/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0077 - val_loss: 0.0016 - val_mae: 0.0035\n",
      "Epoch 382/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0048 - val_loss: 0.0017 - val_mae: 0.0060\n",
      "Epoch 383/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0060 - val_loss: 0.0016 - val_mae: 0.0039\n",
      "Epoch 384/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0056 - val_loss: 0.0016 - val_mae: 0.0053\n",
      "Epoch 385/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0042 - val_loss: 0.0017 - val_mae: 0.0061\n",
      "Epoch 386/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0050 - val_loss: 0.0016 - val_mae: 0.0036\n",
      "Epoch 387/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0047 - val_loss: 0.0016 - val_mae: 0.0063\n",
      "Epoch 388/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0046 - val_loss: 0.0016 - val_mae: 0.0037\n",
      "Epoch 389/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0048 - val_loss: 0.0016 - val_mae: 0.0046\n",
      "Epoch 390/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0065 - val_loss: 0.0016 - val_mae: 0.0041\n",
      "Epoch 391/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0039 - val_loss: 0.0016 - val_mae: 0.0057\n",
      "Epoch 392/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0043\n",
      "Epoch 393/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0058 - val_loss: 0.0016 - val_mae: 0.0050\n",
      "Epoch 394/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0045 - val_loss: 0.0016 - val_mae: 0.0036\n",
      "Epoch 395/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0037 - val_loss: 0.0016 - val_mae: 0.0026\n",
      "Epoch 396/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0051 - val_loss: 0.0018 - val_mae: 0.0108\n",
      "Epoch 397/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0065 - val_loss: 0.0016 - val_mae: 0.0032\n",
      "Epoch 398/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0043 - val_loss: 0.0016 - val_mae: 0.0047\n",
      "Epoch 399/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0044\n",
      "Epoch 400/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0050 - val_loss: 0.0017 - val_mae: 0.0108\n",
      "Epoch 401/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0046 - val_loss: 0.0016 - val_mae: 0.0037\n",
      "Epoch 402/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0055 - val_loss: 0.0016 - val_mae: 0.0048\n",
      "Epoch 403/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0046 - val_loss: 0.0016 - val_mae: 0.0068\n",
      "Epoch 404/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0043 - val_loss: 0.0016 - val_mae: 0.0047\n",
      "Epoch 405/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0054 - val_loss: 0.0016 - val_mae: 0.0065\n",
      "Epoch 406/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0053 - val_loss: 0.0015 - val_mae: 0.0036\n",
      "Epoch 407/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0060 - val_loss: 0.0016 - val_mae: 0.0100\n",
      "Epoch 408/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0041 - val_loss: 0.0015 - val_mae: 0.0044\n",
      "Epoch 409/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 0.0015 - val_mae: 0.0037\n",
      "Epoch 410/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0047 - val_loss: 0.0015 - val_mae: 0.0039\n",
      "Epoch 411/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0070 - val_loss: 0.0015 - val_mae: 0.0044\n",
      "Epoch 412/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0051 - val_loss: 0.0015 - val_mae: 0.0031\n",
      "Epoch 413/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0035\n",
      "Epoch 414/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0054 - val_loss: 0.0015 - val_mae: 0.0060\n",
      "Epoch 415/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0035\n",
      "Epoch 416/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0061\n",
      "Epoch 417/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0060\n",
      "Epoch 418/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0037\n",
      "Epoch 419/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0029\n",
      "Epoch 420/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0052 - val_loss: 0.0016 - val_mae: 0.0089\n",
      "Epoch 421/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0062\n",
      "Epoch 422/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0049 - val_loss: 0.0015 - val_mae: 0.0035\n",
      "Epoch 423/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0048 - val_loss: 0.0015 - val_mae: 0.0045\n",
      "Epoch 424/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0035\n",
      "Epoch 425/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0061 - val_loss: 0.0015 - val_mae: 0.0032\n",
      "Epoch 426/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0047\n",
      "Epoch 427/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0051 - val_loss: 0.0015 - val_mae: 0.0028\n",
      "Epoch 428/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0042\n",
      "Epoch 429/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0051 - val_loss: 0.0015 - val_mae: 0.0078\n",
      "Epoch 430/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0050\n",
      "Epoch 431/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0069 - val_loss: 0.0014 - val_mae: 0.0032\n",
      "Epoch 432/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0014 - val_mae: 0.0034\n",
      "Epoch 433/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0046\n",
      "Epoch 434/500\n",
      "163/163 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0054 - val_loss: 0.0014 - val_mae: 0.0043\n",
      "Epoch 435/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0014 - val_mae: 0.0033\n",
      "Epoch 436/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0038\n",
      "Epoch 437/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0052 - val_loss: 0.0015 - val_mae: 0.0055\n",
      "Epoch 438/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0049 - val_loss: 0.0014 - val_mae: 0.0047\n",
      "Epoch 439/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0048 - val_loss: 0.0014 - val_mae: 0.0053\n",
      "Epoch 440/500\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0051 - val_loss: 0.0014 - val_mae: 0.0048\n",
      "Epoch 441/500\n",
      "155/163 [===========================>..] - ETA: 0s - loss: 0.0015 - mae: 0.0064Restoring model weights from the end of the best epoch: 436.\n",
      "163/163 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0063 - val_loss: 0.0014 - val_mae: 0.0041\n",
      "Epoch 441: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Netzwerkarchitektur\n",
    "model = Sequential([\n",
    "\n",
    "    Dense(248, activation='relu', input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "    Dense(296, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(280, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(216, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(184, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(40, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(312, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(200, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(104, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "    Dense(1 , activation = 'linear')\n",
    "])\n",
    "\n",
    "# Optimierer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "# Modell kompilieren (Verwendung von mean_squared_error als Verlustfunktion für Regression)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])  # Metriken für Regression: Mean Absolute Error und Mean Squared Error\n",
    "\n",
    "# Early Stopping Callback\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "# Trainingsparameter\n",
    "batch_size = 25\n",
    "epochs = 500\n",
    "\n",
    "# Modell trainieren (Annahme: X_train, y_train, X_val, y_val sind vordefiniert)\n",
    "history = model.fit(X_train_scaled, y_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T16:06:59.102575500Z",
     "start_time": "2024-03-14T16:03:11.598769900Z"
    }
   },
   "id": "8b52e1a9a6ff3aeb"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 - 0s - loss: 0.0014 - mae: 0.0040 - 70ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.0014424824621528387, 0.003975548315793276]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test_scaled, y_test_scaled, verbose=2)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T16:06:59.211916200Z",
     "start_time": "2024-03-14T16:06:59.109442100Z"
    }
   },
   "id": "9050ab66ab36f169"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bsp. Predicted: [1464.0195] Actual: [1463.6] \n",
      "Durchschnittliche Abweichung (MAE): [3.7611529]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scaled_predicted_values = model.predict(X_test_scaled, verbose = 0)\n",
    "\n",
    "# Führen Sie die Rücktransformation der skalierten Werte durch\n",
    "original_predicted_values = scaler_target.inverse_transform(scaled_predicted_values)\n",
    "original_actual_values = scaler_target.inverse_transform(y_test_scaled)  # y_test sind die skalierten tatsächlichen Werte\n",
    "print(f' Bsp. Predicted: {original_predicted_values[100]} Actual: {original_actual_values[100]} ')\n",
    "\n",
    "def calculate_mae(list1, list2):\n",
    "    # Stelle sicher, dass beide Listen die gleiche Länge haben\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Listen müssen die gleiche Länge haben\")\n",
    "\n",
    "    # Berechne die absolute Differenz zwischen den Elementen der Listen\n",
    "    differences = [abs(x - y) for x, y in zip(list1, list2)]\n",
    "\n",
    "    # Berechne den Durchschnitt der absoluten Differenzen\n",
    "    mae = sum(differences) / len(differences)\n",
    "\n",
    "    return mae\n",
    "\n",
    "# Beispiel\n",
    "list1 = original_predicted_values\n",
    "list2 = original_actual_values\n",
    "\n",
    "mae = calculate_mae(list1, list2)\n",
    "print(f\"Durchschnittliche Abweichung (MAE): {mae}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T16:06:59.428550600Z",
     "start_time": "2024-03-14T16:06:59.211916200Z"
    }
   },
   "id": "10cd79ca028075dd"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: [0.99963884]\n"
     ]
    }
   ],
   "source": [
    "def calculate_r_squared(predicted, actual):\n",
    "    # Berechnung des Mittelwerts der tatsächlichen Werte\n",
    "    mean_actual = sum(actual) / len(actual)\n",
    "    \n",
    "    # Berechnung der totalen Summe der Quadrate (SST)\n",
    "    sst = sum((x - mean_actual) ** 2 for x in actual)\n",
    "    \n",
    "    # Berechnung der Summe der Quadrate der Residuen (SSE)\n",
    "    sse = sum((actual[i] - predicted[i]) ** 2 for i in range(len(actual)))\n",
    "    \n",
    "    # Berechnung des R^2-Wertes\n",
    "    r_squared = 1 - (sse / sst)\n",
    "    \n",
    "    return r_squared\n",
    "\n",
    "# Berechnung von R^2 mit den bereitgestellten Listen\n",
    "r_squared = calculate_r_squared(list1, list2)\n",
    "\n",
    "print(f\"R^2: {r_squared}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T16:06:59.439565500Z",
     "start_time": "2024-03-14T16:06:59.426029300Z"
    }
   },
   "id": "d0505d16afcbef4a"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Werte die kleiner sind: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "             Echt  Vorhergesagt  X-Koordinate  Y-Koordinate  Differenz\n733    854.609009        874.06      1.000000          0.07 -19.450991\n302    736.769287        755.11      1.000000          0.93 -18.340713\n715    875.256226        893.58      1.000000          0.08 -18.323774\n393    807.885559        824.74      0.983871          0.05 -16.854441\n183    831.831055        845.81      0.967742          0.06 -13.978945\n...           ...           ...           ...           ...        ...\n814    630.501465        612.09      1.000000          0.97  18.411465\n489   1123.743774       1105.10      1.000000          0.26  18.643774\n136    627.793518        608.88      0.806452          0.97  18.913518\n1104   691.882324        672.09      0.983871          0.00  19.792324\n354    698.818970        669.05      0.000000          0.00  29.768970\n\n[1273 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Echt</th>\n      <th>Vorhergesagt</th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Differenz</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>733</th>\n      <td>854.609009</td>\n      <td>874.06</td>\n      <td>1.000000</td>\n      <td>0.07</td>\n      <td>-19.450991</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>736.769287</td>\n      <td>755.11</td>\n      <td>1.000000</td>\n      <td>0.93</td>\n      <td>-18.340713</td>\n    </tr>\n    <tr>\n      <th>715</th>\n      <td>875.256226</td>\n      <td>893.58</td>\n      <td>1.000000</td>\n      <td>0.08</td>\n      <td>-18.323774</td>\n    </tr>\n    <tr>\n      <th>393</th>\n      <td>807.885559</td>\n      <td>824.74</td>\n      <td>0.983871</td>\n      <td>0.05</td>\n      <td>-16.854441</td>\n    </tr>\n    <tr>\n      <th>183</th>\n      <td>831.831055</td>\n      <td>845.81</td>\n      <td>0.967742</td>\n      <td>0.06</td>\n      <td>-13.978945</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>814</th>\n      <td>630.501465</td>\n      <td>612.09</td>\n      <td>1.000000</td>\n      <td>0.97</td>\n      <td>18.411465</td>\n    </tr>\n    <tr>\n      <th>489</th>\n      <td>1123.743774</td>\n      <td>1105.10</td>\n      <td>1.000000</td>\n      <td>0.26</td>\n      <td>18.643774</td>\n    </tr>\n    <tr>\n      <th>136</th>\n      <td>627.793518</td>\n      <td>608.88</td>\n      <td>0.806452</td>\n      <td>0.97</td>\n      <td>18.913518</td>\n    </tr>\n    <tr>\n      <th>1104</th>\n      <td>691.882324</td>\n      <td>672.09</td>\n      <td>0.983871</td>\n      <td>0.00</td>\n      <td>19.792324</td>\n    </tr>\n    <tr>\n      <th>354</th>\n      <td>698.818970</td>\n      <td>669.05</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>29.768970</td>\n    </tr>\n  </tbody>\n</table>\n<p>1273 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame({'Echt': [val[0] for val in list1], 'Vorhergesagt': [val[0] for val in list2]})\n",
    "df_result['X-Koordinate'] = X_test_scaled[:, 0]\n",
    "df_result['Y-Koordinate'] = X_test_scaled[:, 1]\n",
    "\n",
    "df_result['Differenz'] = df_result['Echt'] - df_result['Vorhergesagt']\n",
    "df_result['Differenz'].sort_values()\n",
    "sorted_df = df_result.sort_values(by= 'Differenz')\n",
    "Anzahl_Punkte = (sorted_df['Differenz'] < -20).sum()\n",
    "print(\"Anzahl der Werte die kleiner sind:\", Anzahl_Punkte)\n",
    "\n",
    "sorted_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T16:06:59.453574100Z",
     "start_time": "2024-03-14T16:06:59.439565500Z"
    }
   },
   "id": "47d4a39665ed1159"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mae = history.history['loss']\n",
    "val_mae = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(mae) + 1)\n",
    "\n",
    "# MAE Diagramm\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, mae, 'r', label='Training MSE')\n",
    "plt.plot(epochs, val_mae, 'b', label='Validation MSE')\n",
    "plt.title('Training and Validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T16:06:59.622217400Z",
     "start_time": "2024-03-14T16:06:59.453574100Z"
    }
   },
   "id": "3688dd7102e95baf"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f6f672a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T16:06:59.625217200Z",
     "start_time": "2024-03-14T16:06:59.622217400Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "553df6fa",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# def build_model(learning_rate=0.001, activation='relu', regularization=0.0001, dropout_rate=0.0):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(200, activation=activation, input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(448, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(352, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(320, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(256, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(416, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(128, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(96, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))    \n",
    "# \n",
    "#     model.add(Dense(32, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mae'])\n",
    "#     return model\n",
    "# \n",
    "# # Verwenden Sie eine Funktion, um das Modell zu instanziieren, für scikit-learn Wrapper\n",
    "# model = KerasRegressor(model=build_model, verbose=2)\n",
    "# \n",
    "# # Anpassung der Parameter im param_grid\n",
    "# param_grid = {\n",
    "#     'model__learning_rate': [0.01, 0.001, 0.0001],\n",
    "#     'model__regularization': [0.001, 0.0001],\n",
    "#     'fit__batch_size': [25, 50, 75, 100],\n",
    "#     'fit__epochs': [50],\n",
    "#     'model__dropout_rate' : [0.0, 0.1, 0.2]\n",
    "# }\n",
    "# \n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=2)\n",
    "# # Hinweis: Stellen Sie sicher, dass Ihre Daten (X_train_scaled, y_train_scaled) korrekt definiert sind\n",
    "# grid_result = grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "# # Beste Parameter und Score ausgeben\n",
    "# print(\"Beste Parameter:\", grid_search.best_params_)\n",
    "# print(\"Beste Genauigkeit:\", grid_search.best_score_)\n",
    "# \n",
    "# with open(\"Gridsearch_D3.txt\", \"w\") as f:\n",
    "#     f.write(f\"Beste Parameter: {grid_search.best_params_}\\n\")\n",
    "#     f.write(f\"Beste Genauigkeit: {grid_search.best_score_}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T16:06:59.628904Z",
     "start_time": "2024-03-14T16:06:59.624217100Z"
    }
   },
   "id": "578403f6e218787a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Search"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69b9aef262bcb2c3"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "492cf0ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T16:06:59.632592900Z",
     "start_time": "2024-03-14T16:06:59.628904Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Funktion zum Erstellen des Modells\n",
    "# def build_model(hp):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(hp.Int('input_units', min_value=8, max_value=328, step=16), input_shape=(2,), activation='relu'))\n",
    "#     for i in range(hp.Int('n_layers', 1, 10)):\n",
    "#         model.add(Dense(hp.Int(f'units_{i}', min_value=8, max_value=328, step=16), activation='relu'))\n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     return model\n",
    "# \n",
    "# # Durchführung der Random Search dreimal\n",
    "# for run in range(1, 4):\n",
    "#     # Anpassen des Verzeichnisses und des Projektnamens für jeden Durchlauf\n",
    "#     directory = 'random_search'\n",
    "#     project_name = f'random_search_D3_{run}'\n",
    "#     \n",
    "#     tuner = RandomSearch(\n",
    "#         build_model,\n",
    "#         objective='val_loss',\n",
    "#         max_trials=100,\n",
    "#         executions_per_trial=1,\n",
    "#         directory=directory,\n",
    "#         project_name=project_name\n",
    "#     )\n",
    "#     \n",
    "#     # Durchführung des Random Search\n",
    "#     tuner.search(X_train_scaled, y_train_scaled, epochs=50, verbose =0, batch_size=50, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "#     \n",
    "#     # Abrufen und Speichern des besten Modells\n",
    "#     best_model = tuner.get_best_models(num_models=1)[0]\n",
    "#     model_path = os.path.join(directory, project_name, 'best_model.h5') \n",
    "#     best_model.save(model_path)\n",
    "#     \n",
    "# \n",
    "#     # Optional: Abrufen und Ausgeben der besten Hyperparameter\n",
    "#     best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "#     \n",
    "#     # Konvertieren der Hyperparameter in ein DataFrame\n",
    "#     df_hyperparameters = pd.DataFrame([best_hyperparameters.values])\n",
    "#     # Speichern des DataFrame als CSV\n",
    "#     df_hyperparameters.to_csv(f'random_search_D3_{run}.csv', index=False)\n",
    "#     \n",
    "#     print(f\"Beste Hyperparameter für Lauf {run}: {best_hyperparameters.values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T16:06:59.636490900Z",
     "start_time": "2024-03-14T16:06:59.633593100Z"
    }
   },
   "id": "412f38f9b1e03d5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
