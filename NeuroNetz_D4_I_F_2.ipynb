{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94b0518e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T09:17:15.096872300Z",
     "start_time": "2024-04-02T09:16:58.090229900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense , Dropout\n",
    "from scikeras.wrappers import KerasRegressor \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T09:17:15.125871600Z",
     "start_time": "2024-04-02T09:17:14.965140900Z"
    }
   },
   "id": "ed7bebb44814d770"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ff61b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T09:17:15.197872300Z",
     "start_time": "2024-04-02T09:17:14.969485700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n42840         0.0000      -0.00200        500   6000   5000      753.54\n42841         0.0000      -0.00192        500   6000   5000      835.65\n42842         0.0000      -0.00184        500   6000   5000      919.98\n42843         0.0000      -0.00176        500   6000   5000     1007.40\n42844         0.0000      -0.00168        500   6000   5000     1097.60\n...              ...           ...        ...    ...    ...         ...\n351283        0.0024       0.00168        500   9000   5000     1365.50\n351284        0.0024       0.00176        500   9000   5000     1247.20\n351285        0.0024       0.00184        500   9000   5000     1114.10\n351286        0.0024       0.00192        500   9000   5000      983.97\n351287        0.0024       0.00200        500   9000   5000      942.84\n\n[8568 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>42840</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>500</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>753.54</td>\n    </tr>\n    <tr>\n      <th>42841</th>\n      <td>0.0000</td>\n      <td>-0.00192</td>\n      <td>500</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>835.65</td>\n    </tr>\n    <tr>\n      <th>42842</th>\n      <td>0.0000</td>\n      <td>-0.00184</td>\n      <td>500</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>919.98</td>\n    </tr>\n    <tr>\n      <th>42843</th>\n      <td>0.0000</td>\n      <td>-0.00176</td>\n      <td>500</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>1007.40</td>\n    </tr>\n    <tr>\n      <th>42844</th>\n      <td>0.0000</td>\n      <td>-0.00168</td>\n      <td>500</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>1097.60</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>351283</th>\n      <td>0.0024</td>\n      <td>0.00168</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1365.50</td>\n    </tr>\n    <tr>\n      <th>351284</th>\n      <td>0.0024</td>\n      <td>0.00176</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1247.20</td>\n    </tr>\n    <tr>\n      <th>351285</th>\n      <td>0.0024</td>\n      <td>0.00184</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1114.10</td>\n    </tr>\n    <tr>\n      <th>351286</th>\n      <td>0.0024</td>\n      <td>0.00192</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>983.97</td>\n    </tr>\n    <tr>\n      <th>351287</th>\n      <td>0.0024</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>942.84</td>\n    </tr>\n  </tbody>\n</table>\n<p>8568 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/TPath_300_finish_data.pkl')\n",
    "data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_All_D4_t_500_I_F_PKL.pkl')\n",
    "# copy = data[data['Zeitpunkt']== 500]\n",
    "# copy.to_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_All_D4_t_500_I_F_PKL.pkl')\n",
    "# copy\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "966e3c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T09:17:15.205871900Z",
     "start_time": "2024-04-02T09:17:14.994098200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n",
      "174573        0.0000      -0.00200        500   7000   6000      811.76\n",
      "174574        0.0000      -0.00192        500   7000   6000      897.57\n",
      "174575        0.0000      -0.00184        500   7000   6000      986.34\n",
      "174576        0.0000      -0.00176        500   7000   6000     1077.80\n",
      "174577        0.0000      -0.00168        500   7000   6000     1176.80\n",
      "...              ...           ...        ...    ...    ...         ...\n",
      "175639        0.0024       0.00168        500   7000   6000      942.96\n",
      "175640        0.0024       0.00176        500   7000   6000      865.10\n",
      "175641        0.0024       0.00184        500   7000   6000      786.99\n",
      "175642        0.0024       0.00192        500   7000   6000      708.11\n",
      "175643        0.0024       0.00200        500   7000   6000      690.48\n",
      "\n",
      "[1071 rows x 6 columns]\n",
      "Empty DataFrame\n",
      "Columns: [X-Koordinate, Y-Koordinate, Zeitpunkt, Strom, Kraft, Temperatur]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n174573        0.0000      -0.00200        500   7000   6000      811.76\n174574        0.0000      -0.00192        500   7000   6000      897.57\n174575        0.0000      -0.00184        500   7000   6000      986.34\n174576        0.0000      -0.00176        500   7000   6000     1077.80\n174577        0.0000      -0.00168        500   7000   6000     1176.80\n...              ...           ...        ...    ...    ...         ...\n175639        0.0024       0.00168        500   7000   6000      942.96\n175640        0.0024       0.00176        500   7000   6000      865.10\n175641        0.0024       0.00184        500   7000   6000      786.99\n175642        0.0024       0.00192        500   7000   6000      708.11\n175643        0.0024       0.00200        500   7000   6000      690.48\n\n[1071 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>174573</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>811.76</td>\n    </tr>\n    <tr>\n      <th>174574</th>\n      <td>0.0000</td>\n      <td>-0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>897.57</td>\n    </tr>\n    <tr>\n      <th>174575</th>\n      <td>0.0000</td>\n      <td>-0.00184</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>986.34</td>\n    </tr>\n    <tr>\n      <th>174576</th>\n      <td>0.0000</td>\n      <td>-0.00176</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>1077.80</td>\n    </tr>\n    <tr>\n      <th>174577</th>\n      <td>0.0000</td>\n      <td>-0.00168</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>1176.80</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>175639</th>\n      <td>0.0024</td>\n      <td>0.00168</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>942.96</td>\n    </tr>\n    <tr>\n      <th>175640</th>\n      <td>0.0024</td>\n      <td>0.00176</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>865.10</td>\n    </tr>\n    <tr>\n      <th>175641</th>\n      <td>0.0024</td>\n      <td>0.00184</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>786.99</td>\n    </tr>\n    <tr>\n      <th>175642</th>\n      <td>0.0024</td>\n      <td>0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>708.11</td>\n    </tr>\n    <tr>\n      <th>175643</th>\n      <td>0.0024</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>690.48</td>\n    </tr>\n  </tbody>\n</table>\n<p>1071 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedingung = (data['Kraft'] == 6000) & (data['Strom'] == 7000)\n",
    "df_test = data[bedingung].copy()\n",
    "print(df_test)\n",
    "#df_test.to_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_I7000_F6000_D3_500_I_F_PKL.pkl')\n",
    "data_all = data.drop(df_test.index)\n",
    "#print(data_all)\n",
    "print(data_all[(data_all['Kraft'] == 6000) & (data_all['Strom'] == 7000)])\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8783d1d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T09:17:15.206872900Z",
     "start_time": "2024-04-02T09:17:15.021017800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate  Strom  Kraft  Temperatur\n42840         0.0000      -0.00200   6000   5000      753.54\n42841         0.0000      -0.00192   6000   5000      835.65\n42842         0.0000      -0.00184   6000   5000      919.98\n42843         0.0000      -0.00176   6000   5000     1007.40\n42844         0.0000      -0.00168   6000   5000     1097.60\n...              ...           ...    ...    ...         ...\n351283        0.0024       0.00168   9000   5000     1365.50\n351284        0.0024       0.00176   9000   5000     1247.20\n351285        0.0024       0.00184   9000   5000     1114.10\n351286        0.0024       0.00192   9000   5000      983.97\n351287        0.0024       0.00200   9000   5000      942.84\n\n[7497 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>42840</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>753.54</td>\n    </tr>\n    <tr>\n      <th>42841</th>\n      <td>0.0000</td>\n      <td>-0.00192</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>835.65</td>\n    </tr>\n    <tr>\n      <th>42842</th>\n      <td>0.0000</td>\n      <td>-0.00184</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>919.98</td>\n    </tr>\n    <tr>\n      <th>42843</th>\n      <td>0.0000</td>\n      <td>-0.00176</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>1007.40</td>\n    </tr>\n    <tr>\n      <th>42844</th>\n      <td>0.0000</td>\n      <td>-0.00168</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>1097.60</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>351283</th>\n      <td>0.0024</td>\n      <td>0.00168</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1365.50</td>\n    </tr>\n    <tr>\n      <th>351284</th>\n      <td>0.0024</td>\n      <td>0.00176</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1247.20</td>\n    </tr>\n    <tr>\n      <th>351285</th>\n      <td>0.0024</td>\n      <td>0.00184</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1114.10</td>\n    </tr>\n    <tr>\n      <th>351286</th>\n      <td>0.0024</td>\n      <td>0.00192</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>983.97</td>\n    </tr>\n    <tr>\n      <th>351287</th>\n      <td>0.0024</td>\n      <td>0.00200</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>942.84</td>\n    </tr>\n  </tbody>\n</table>\n<p>7497 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data_all.drop('Zeitpunkt', axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4e72a16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T09:17:15.239872700Z",
     "start_time": "2024-04-02T09:17:15.035578600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        X-Koordinate  Y-Koordinate  Strom  Kraft  Temperatur\n",
      "307240       0.00216      -0.00072   8000   7000      1793.5\n",
      "306384       0.00012       0.00016   8000   7000      2115.6\n",
      "350367       0.00024       0.00184   9000   5000      1190.3\n",
      "351031       0.00180       0.00192   9000   5000      1008.4\n",
      "262887       0.00108       0.00064   8000   6000      2046.2\n",
      "...              ...           ...    ...    ...         ...\n",
      "263302       0.00204       0.00120   8000   6000      1600.1\n",
      "263337       0.00216      -0.00008   8000   6000      1997.7\n",
      "306341       0.00000       0.00080   8000   7000      1903.8\n",
      "43700        0.00192       0.00152   6000   5000      1077.6\n",
      "351061       0.00192       0.00024   9000   5000      2364.4\n",
      "\n",
      "[7497 rows x 5 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": "      X-Koordinate  Y-Koordinate  Strom  Kraft  Temperatur\n0          0.00216      -0.00072   8000   7000      1793.5\n1          0.00012       0.00016   8000   7000      2115.6\n2          0.00024       0.00184   9000   5000      1190.3\n3          0.00180       0.00192   9000   5000      1008.4\n4          0.00108       0.00064   8000   6000      2046.2\n...            ...           ...    ...    ...         ...\n7492       0.00204       0.00120   8000   6000      1600.1\n7493       0.00216      -0.00008   8000   6000      1997.7\n7494       0.00000       0.00080   8000   7000      1903.8\n7495       0.00192       0.00152   6000   5000      1077.6\n7496       0.00192       0.00024   9000   5000      2364.4\n\n[7497 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00216</td>\n      <td>-0.00072</td>\n      <td>8000</td>\n      <td>7000</td>\n      <td>1793.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00012</td>\n      <td>0.00016</td>\n      <td>8000</td>\n      <td>7000</td>\n      <td>2115.6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00024</td>\n      <td>0.00184</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1190.3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00180</td>\n      <td>0.00192</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1008.4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00108</td>\n      <td>0.00064</td>\n      <td>8000</td>\n      <td>6000</td>\n      <td>2046.2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7492</th>\n      <td>0.00204</td>\n      <td>0.00120</td>\n      <td>8000</td>\n      <td>6000</td>\n      <td>1600.1</td>\n    </tr>\n    <tr>\n      <th>7493</th>\n      <td>0.00216</td>\n      <td>-0.00008</td>\n      <td>8000</td>\n      <td>6000</td>\n      <td>1997.7</td>\n    </tr>\n    <tr>\n      <th>7494</th>\n      <td>0.00000</td>\n      <td>0.00080</td>\n      <td>8000</td>\n      <td>7000</td>\n      <td>1903.8</td>\n    </tr>\n    <tr>\n      <th>7495</th>\n      <td>0.00192</td>\n      <td>0.00152</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>1077.6</td>\n    </tr>\n    <tr>\n      <th>7496</th>\n      <td>0.00192</td>\n      <td>0.00024</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>2364.4</td>\n    </tr>\n  </tbody>\n</table>\n<p>7497 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.sample(frac=1, random_state=42)  # Hier wird 42 als Random State verwendet, um die Ergebnisse reproduzierbar zu machen\n",
    "\n",
    "print(df1)\n",
    "df_reset = df1.reset_index(drop=True)\n",
    "df_reset"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7fa289a50d87423"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e694a236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T09:17:15.241870200Z",
     "start_time": "2024-04-02T09:17:15.061109800Z"
    }
   },
   "outputs": [],
   "source": [
    "y = df_reset[\"Temperatur\"]\n",
    "# Korrektur: Verwenden Sie den Spaltennamen direkt, ohne Indexierung der columns-Eigenschaft\n",
    "X = df_reset.drop(\"Temperatur\", axis=1)\n",
    "\n",
    "label = df_test[\"Temperatur\"]\n",
    "# Korrektur: Verwenden Sie den Spaltennamen direkt, ohne Indexierung der columns-Eigenschaft\n",
    "X_2 = df_test.drop(\"Temperatur\", axis=1)\n",
    "X_2 = X_2.drop('Zeitpunkt', axis=1)\n",
    "X_2 = X_2.reset_index(drop=True)\n",
    "y_2 = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f3303b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T09:17:15.256871600Z",
     "start_time": "2024-04-02T09:17:15.069535700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      X-Koordinate  Y-Koordinate  Strom  Kraft\n0          0.00216      -0.00072   8000   7000\n1          0.00012       0.00016   8000   7000\n2          0.00024       0.00184   9000   5000\n3          0.00180       0.00192   9000   5000\n4          0.00108       0.00064   8000   6000\n...            ...           ...    ...    ...\n7492       0.00204       0.00120   8000   6000\n7493       0.00216      -0.00008   8000   6000\n7494       0.00000       0.00080   8000   7000\n7495       0.00192       0.00152   6000   5000\n7496       0.00192       0.00024   9000   5000\n\n[7497 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00216</td>\n      <td>-0.00072</td>\n      <td>8000</td>\n      <td>7000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00012</td>\n      <td>0.00016</td>\n      <td>8000</td>\n      <td>7000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00024</td>\n      <td>0.00184</td>\n      <td>9000</td>\n      <td>5000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00180</td>\n      <td>0.00192</td>\n      <td>9000</td>\n      <td>5000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00108</td>\n      <td>0.00064</td>\n      <td>8000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7492</th>\n      <td>0.00204</td>\n      <td>0.00120</td>\n      <td>8000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>7493</th>\n      <td>0.00216</td>\n      <td>-0.00008</td>\n      <td>8000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>7494</th>\n      <td>0.00000</td>\n      <td>0.00080</td>\n      <td>8000</td>\n      <td>7000</td>\n    </tr>\n    <tr>\n      <th>7495</th>\n      <td>0.00192</td>\n      <td>0.00152</td>\n      <td>6000</td>\n      <td>5000</td>\n    </tr>\n    <tr>\n      <th>7496</th>\n      <td>0.00192</td>\n      <td>0.00024</td>\n      <td>9000</td>\n      <td>5000</td>\n    </tr>\n  </tbody>\n</table>\n<p>7497 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c705edb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T09:17:20.438020Z",
     "start_time": "2024-04-02T09:17:20.257626400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialisiere einen MinMaxScaler fÃ¼r die Features\n",
    "scaler_features = MinMaxScaler()\n",
    "scaler_features2 = MinMaxScaler()\n",
    "# Skaliere X_train und X_test\n",
    "X_train_scaled = scaler_features.fit_transform(X)\n",
    "X_test_scaled = scaler_features.transform(X_2)  # Nutze unterschiedliche Skalierungsparameter\n",
    "\n",
    "# Initialisiere einen SEPARATEN MinMaxScaler fÃ¼r das Ziel, wenn nÃ¶tig\n",
    "scaler_target = MinMaxScaler()\n",
    "\n",
    "\n",
    "# Skaliere y_train und y_test. Beachte, dass y_train.reshape(-1, 1) verwendet wird, da MinMaxScaler \n",
    "# erwartet, dass die Eingaben als 2D-Arrays kommen, und Ziele normalerweise als 1D-Arrays vorliegen.\n",
    "y_train_scaled = scaler_target.fit_transform(y.values.reshape(-1, 1))\n",
    "y_test_scaled = scaler_target.transform(y_2.values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbefe631e495b483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T09:17:21.208718800Z",
     "start_time": "2024-04-02T09:17:20.955861500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.9       , 0.32      , 0.66666667, 0.5       ],\n       [0.05      , 0.54      , 0.66666667, 0.5       ],\n       [0.1       , 0.96      , 1.        , 0.        ],\n       ...,\n       [0.        , 0.7       , 0.66666667, 0.5       ],\n       [0.8       , 0.88      , 0.        , 0.        ],\n       [0.8       , 0.56      , 1.        , 0.        ]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_scaled.max()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T14:01:02.035006100Z",
     "start_time": "2024-04-01T14:01:01.897717200Z"
    }
   },
   "id": "ce04ce43aac2242f"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.0486 - mae: 0.1219 - val_loss: 0.0282 - val_mae: 0.0703\n",
      "Epoch 2/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0254 - mae: 0.0649 - val_loss: 0.0207 - val_mae: 0.0453\n",
      "Epoch 3/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0211 - mae: 0.0515 - val_loss: 0.0191 - val_mae: 0.0444\n",
      "Epoch 4/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0185 - mae: 0.0383 - val_loss: 0.0169 - val_mae: 0.0268\n",
      "Epoch 5/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0173 - mae: 0.0314 - val_loss: 0.0164 - val_mae: 0.0243\n",
      "Epoch 6/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0168 - mae: 0.0284 - val_loss: 0.0160 - val_mae: 0.0236\n",
      "Epoch 7/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0157 - mae: 0.0196 - val_loss: 0.0161 - val_mae: 0.0304\n",
      "Epoch 8/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0159 - mae: 0.0246 - val_loss: 0.0153 - val_mae: 0.0193\n",
      "Epoch 9/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0156 - mae: 0.0227 - val_loss: 0.0148 - val_mae: 0.0136\n",
      "Epoch 10/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0151 - mae: 0.0199 - val_loss: 0.0147 - val_mae: 0.0158\n",
      "Epoch 11/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0155 - mae: 0.0262 - val_loss: 0.0144 - val_mae: 0.0138\n",
      "Epoch 12/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0147 - mae: 0.0201 - val_loss: 0.0142 - val_mae: 0.0119\n",
      "Epoch 13/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0144 - mae: 0.0185 - val_loss: 0.0148 - val_mae: 0.0233\n",
      "Epoch 14/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0142 - mae: 0.0182 - val_loss: 0.0142 - val_mae: 0.0191\n",
      "Epoch 15/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0141 - mae: 0.0186 - val_loss: 0.0140 - val_mae: 0.0196\n",
      "Epoch 16/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0140 - mae: 0.0204 - val_loss: 0.0133 - val_mae: 0.0099\n",
      "Epoch 17/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0137 - mae: 0.0192 - val_loss: 0.0135 - val_mae: 0.0178\n",
      "Epoch 18/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0134 - mae: 0.0184 - val_loss: 0.0130 - val_mae: 0.0126\n",
      "Epoch 19/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0133 - mae: 0.0180 - val_loss: 0.0133 - val_mae: 0.0199\n",
      "Epoch 20/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0131 - mae: 0.0194 - val_loss: 0.0140 - val_mae: 0.0287\n",
      "Epoch 21/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0128 - mae: 0.0174 - val_loss: 0.0125 - val_mae: 0.0139\n",
      "Epoch 22/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0127 - mae: 0.0187 - val_loss: 0.0124 - val_mae: 0.0170\n",
      "Epoch 23/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0124 - mae: 0.0167 - val_loss: 0.0122 - val_mae: 0.0156\n",
      "Epoch 24/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0121 - mae: 0.0152 - val_loss: 0.0119 - val_mae: 0.0125\n",
      "Epoch 25/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0120 - mae: 0.0164 - val_loss: 0.0117 - val_mae: 0.0128\n",
      "Epoch 26/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0115 - val_mae: 0.0110\n",
      "Epoch 27/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0121 - mae: 0.0202 - val_loss: 0.0116 - val_mae: 0.0170\n",
      "Epoch 28/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0113 - mae: 0.0126 - val_loss: 0.0111 - val_mae: 0.0099\n",
      "Epoch 29/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0112 - val_mae: 0.0158\n",
      "Epoch 30/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0113 - mae: 0.0167 - val_loss: 0.0113 - val_mae: 0.0210\n",
      "Epoch 31/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0109 - mae: 0.0142 - val_loss: 0.0114 - val_mae: 0.0247\n",
      "Epoch 32/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0108 - mae: 0.0150 - val_loss: 0.0104 - val_mae: 0.0082\n",
      "Epoch 33/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0104 - mae: 0.0108 - val_loss: 0.0103 - val_mae: 0.0087\n",
      "Epoch 34/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0106 - mae: 0.0163 - val_loss: 0.0119 - val_mae: 0.0354\n",
      "Epoch 35/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0108 - mae: 0.0183 - val_loss: 0.0099 - val_mae: 0.0067\n",
      "Epoch 36/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0101 - mae: 0.0123 - val_loss: 0.0101 - val_mae: 0.0147\n",
      "Epoch 37/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0098 - mae: 0.0096 - val_loss: 0.0097 - val_mae: 0.0099\n",
      "Epoch 38/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0097 - mae: 0.0111 - val_loss: 0.0100 - val_mae: 0.0193\n",
      "Epoch 39/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0097 - mae: 0.0127 - val_loss: 0.0096 - val_mae: 0.0150\n",
      "Epoch 40/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0097 - mae: 0.0161 - val_loss: 0.0096 - val_mae: 0.0183\n",
      "Epoch 41/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0093 - mae: 0.0095 - val_loss: 0.0091 - val_mae: 0.0071\n",
      "Epoch 42/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0092 - mae: 0.0122 - val_loss: 0.0090 - val_mae: 0.0079\n",
      "Epoch 43/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0090 - mae: 0.0091 - val_loss: 0.0089 - val_mae: 0.0111\n",
      "Epoch 44/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0090 - mae: 0.0125 - val_loss: 0.0090 - val_mae: 0.0145\n",
      "Epoch 45/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0088 - mae: 0.0106 - val_loss: 0.0086 - val_mae: 0.0083\n",
      "Epoch 46/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0089 - mae: 0.0153 - val_loss: 0.0088 - val_mae: 0.0174\n",
      "Epoch 47/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0085 - mae: 0.0088 - val_loss: 0.0088 - val_mae: 0.0189\n",
      "Epoch 48/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0084 - mae: 0.0113 - val_loss: 0.0084 - val_mae: 0.0115\n",
      "Epoch 49/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0084 - mae: 0.0127 - val_loss: 0.0082 - val_mae: 0.0099\n",
      "Epoch 50/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0081 - mae: 0.0100 - val_loss: 0.0081 - val_mae: 0.0089\n",
      "Epoch 51/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0080 - mae: 0.0093 - val_loss: 0.0078 - val_mae: 0.0061\n",
      "Epoch 52/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0080 - mae: 0.0119 - val_loss: 0.0079 - val_mae: 0.0112\n",
      "Epoch 53/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0078 - mae: 0.0101 - val_loss: 0.0078 - val_mae: 0.0111\n",
      "Epoch 54/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0078 - mae: 0.0114 - val_loss: 0.0075 - val_mae: 0.0061\n",
      "Epoch 55/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0075 - mae: 0.0087 - val_loss: 0.0077 - val_mae: 0.0149\n",
      "Epoch 56/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0074 - mae: 0.0095 - val_loss: 0.0073 - val_mae: 0.0056\n",
      "Epoch 57/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0074 - mae: 0.0107 - val_loss: 0.0073 - val_mae: 0.0116\n",
      "Epoch 58/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0072 - mae: 0.0088 - val_loss: 0.0071 - val_mae: 0.0077\n",
      "Epoch 59/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0073 - mae: 0.0133 - val_loss: 0.0070 - val_mae: 0.0076\n",
      "Epoch 60/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0070 - mae: 0.0077 - val_loss: 0.0069 - val_mae: 0.0080\n",
      "Epoch 61/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0069 - mae: 0.0090 - val_loss: 0.0070 - val_mae: 0.0137\n",
      "Epoch 62/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0068 - mae: 0.0075 - val_loss: 0.0069 - val_mae: 0.0108\n",
      "Epoch 63/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0067 - mae: 0.0101 - val_loss: 0.0066 - val_mae: 0.0066\n",
      "Epoch 64/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0066 - mae: 0.0080 - val_loss: 0.0066 - val_mae: 0.0109\n",
      "Epoch 65/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0065 - mae: 0.0095 - val_loss: 0.0064 - val_mae: 0.0076\n",
      "Epoch 66/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0066 - mae: 0.0128 - val_loss: 0.0064 - val_mae: 0.0093\n",
      "Epoch 67/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0063 - mae: 0.0072 - val_loss: 0.0062 - val_mae: 0.0044\n",
      "Epoch 68/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0062 - mae: 0.0078 - val_loss: 0.0061 - val_mae: 0.0054\n",
      "Epoch 69/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0061 - mae: 0.0084 - val_loss: 0.0064 - val_mae: 0.0165\n",
      "Epoch 70/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0061 - mae: 0.0087 - val_loss: 0.0066 - val_mae: 0.0224\n",
      "Epoch 71/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0060 - mae: 0.0100 - val_loss: 0.0058 - val_mae: 0.0055\n",
      "Epoch 72/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0059 - mae: 0.0086 - val_loss: 0.0067 - val_mae: 0.0233\n",
      "Epoch 73/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0058 - mae: 0.0096 - val_loss: 0.0058 - val_mae: 0.0104\n",
      "Epoch 74/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0057 - mae: 0.0076 - val_loss: 0.0058 - val_mae: 0.0127\n",
      "Epoch 75/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0056 - mae: 0.0059 - val_loss: 0.0055 - val_mae: 0.0052\n",
      "Epoch 76/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0056 - mae: 0.0096 - val_loss: 0.0056 - val_mae: 0.0119\n",
      "Epoch 77/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0055 - mae: 0.0083 - val_loss: 0.0054 - val_mae: 0.0057\n",
      "Epoch 78/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0053 - mae: 0.0066 - val_loss: 0.0053 - val_mae: 0.0046\n",
      "Epoch 79/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0053 - mae: 0.0062 - val_loss: 0.0053 - val_mae: 0.0116\n",
      "Epoch 80/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0053 - mae: 0.0099 - val_loss: 0.0051 - val_mae: 0.0064\n",
      "Epoch 81/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0051 - mae: 0.0071 - val_loss: 0.0051 - val_mae: 0.0084\n",
      "Epoch 82/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0050 - mae: 0.0067 - val_loss: 0.0050 - val_mae: 0.0090\n",
      "Epoch 83/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0050 - mae: 0.0078 - val_loss: 0.0049 - val_mae: 0.0059\n",
      "Epoch 84/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0050 - mae: 0.0087 - val_loss: 0.0049 - val_mae: 0.0082\n",
      "Epoch 85/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0049 - mae: 0.0081 - val_loss: 0.0048 - val_mae: 0.0085\n",
      "Epoch 86/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0048 - mae: 0.0072 - val_loss: 0.0047 - val_mae: 0.0073\n",
      "Epoch 87/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0047 - mae: 0.0056 - val_loss: 0.0046 - val_mae: 0.0062\n",
      "Epoch 88/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0047 - mae: 0.0085 - val_loss: 0.0045 - val_mae: 0.0039\n",
      "Epoch 89/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0046 - mae: 0.0064 - val_loss: 0.0045 - val_mae: 0.0051\n",
      "Epoch 90/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0045 - mae: 0.0066 - val_loss: 0.0044 - val_mae: 0.0042\n",
      "Epoch 91/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0045 - mae: 0.0080 - val_loss: 0.0044 - val_mae: 0.0058\n",
      "Epoch 92/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0044 - mae: 0.0073 - val_loss: 0.0044 - val_mae: 0.0089\n",
      "Epoch 93/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0043 - mae: 0.0065 - val_loss: 0.0043 - val_mae: 0.0101\n",
      "Epoch 94/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0043 - mae: 0.0091 - val_loss: 0.0045 - val_mae: 0.0128\n",
      "Epoch 95/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0042 - mae: 0.0068 - val_loss: 0.0041 - val_mae: 0.0035\n",
      "Epoch 96/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0041 - mae: 0.0052 - val_loss: 0.0042 - val_mae: 0.0100\n",
      "Epoch 97/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0041 - mae: 0.0064 - val_loss: 0.0040 - val_mae: 0.0030\n",
      "Epoch 98/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0041 - mae: 0.0078 - val_loss: 0.0041 - val_mae: 0.0104\n",
      "Epoch 99/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0040 - mae: 0.0067 - val_loss: 0.0039 - val_mae: 0.0069\n",
      "Epoch 100/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0040 - mae: 0.0084 - val_loss: 0.0039 - val_mae: 0.0063\n",
      "Epoch 101/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0039 - mae: 0.0058 - val_loss: 0.0038 - val_mae: 0.0038\n",
      "Epoch 102/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0038 - mae: 0.0056 - val_loss: 0.0038 - val_mae: 0.0057\n",
      "Epoch 103/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0038 - mae: 0.0066 - val_loss: 0.0038 - val_mae: 0.0085\n",
      "Epoch 104/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0037 - mae: 0.0076 - val_loss: 0.0038 - val_mae: 0.0105\n",
      "Epoch 105/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0037 - mae: 0.0064 - val_loss: 0.0036 - val_mae: 0.0061\n",
      "Epoch 106/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0036 - mae: 0.0066 - val_loss: 0.0035 - val_mae: 0.0051\n",
      "Epoch 107/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0036 - mae: 0.0080 - val_loss: 0.0035 - val_mae: 0.0058\n",
      "Epoch 108/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0035 - mae: 0.0049 - val_loss: 0.0034 - val_mae: 0.0044\n",
      "Epoch 109/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0034 - mae: 0.0058 - val_loss: 0.0034 - val_mae: 0.0053\n",
      "Epoch 110/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0034 - mae: 0.0062 - val_loss: 0.0033 - val_mae: 0.0041\n",
      "Epoch 111/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0034 - mae: 0.0061 - val_loss: 0.0033 - val_mae: 0.0050\n",
      "Epoch 112/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0034 - mae: 0.0076 - val_loss: 0.0033 - val_mae: 0.0046\n",
      "Epoch 113/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0033 - mae: 0.0061 - val_loss: 0.0032 - val_mae: 0.0042\n",
      "Epoch 114/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0032 - mae: 0.0052 - val_loss: 0.0032 - val_mae: 0.0064\n",
      "Epoch 115/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0032 - mae: 0.0078 - val_loss: 0.0031 - val_mae: 0.0047\n",
      "Epoch 116/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0031 - mae: 0.0052 - val_loss: 0.0031 - val_mae: 0.0041\n",
      "Epoch 117/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0031 - mae: 0.0067 - val_loss: 0.0030 - val_mae: 0.0043\n",
      "Epoch 118/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0031 - mae: 0.0059 - val_loss: 0.0030 - val_mae: 0.0035\n",
      "Epoch 119/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0030 - mae: 0.0064 - val_loss: 0.0030 - val_mae: 0.0054\n",
      "Epoch 120/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0030 - mae: 0.0055 - val_loss: 0.0029 - val_mae: 0.0045\n",
      "Epoch 121/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0029 - mae: 0.0053 - val_loss: 0.0029 - val_mae: 0.0043\n",
      "Epoch 122/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0029 - mae: 0.0049 - val_loss: 0.0028 - val_mae: 0.0041\n",
      "Epoch 123/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0028 - mae: 0.0051 - val_loss: 0.0028 - val_mae: 0.0061\n",
      "Epoch 124/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0028 - mae: 0.0061 - val_loss: 0.0029 - val_mae: 0.0102\n",
      "Epoch 125/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0028 - mae: 0.0061 - val_loss: 0.0028 - val_mae: 0.0086\n",
      "Epoch 126/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0027 - mae: 0.0058 - val_loss: 0.0027 - val_mae: 0.0058\n",
      "Epoch 127/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0027 - mae: 0.0063 - val_loss: 0.0027 - val_mae: 0.0054\n",
      "Epoch 128/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0026 - mae: 0.0051 - val_loss: 0.0026 - val_mae: 0.0056\n",
      "Epoch 129/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0026 - mae: 0.0054 - val_loss: 0.0026 - val_mae: 0.0068\n",
      "Epoch 130/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0026 - mae: 0.0053 - val_loss: 0.0025 - val_mae: 0.0033\n",
      "Epoch 131/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0025 - mae: 0.0051 - val_loss: 0.0025 - val_mae: 0.0039\n",
      "Epoch 132/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0025 - mae: 0.0045 - val_loss: 0.0025 - val_mae: 0.0083\n",
      "Epoch 133/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0026 - mae: 0.0081 - val_loss: 0.0024 - val_mae: 0.0034\n",
      "Epoch 134/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0050 - val_loss: 0.0024 - val_mae: 0.0033\n",
      "Epoch 135/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0054 - val_loss: 0.0024 - val_mae: 0.0035\n",
      "Epoch 136/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0024 - mae: 0.0047 - val_loss: 0.0024 - val_mae: 0.0049\n",
      "Epoch 137/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0024 - mae: 0.0059 - val_loss: 0.0023 - val_mae: 0.0053\n",
      "Epoch 138/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0023 - mae: 0.0059 - val_loss: 0.0023 - val_mae: 0.0056\n",
      "Epoch 139/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0023 - mae: 0.0048 - val_loss: 0.0023 - val_mae: 0.0036\n",
      "Epoch 140/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0023 - mae: 0.0052 - val_loss: 0.0022 - val_mae: 0.0045\n",
      "Epoch 141/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0022 - mae: 0.0054 - val_loss: 0.0022 - val_mae: 0.0048\n",
      "Epoch 142/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0022 - mae: 0.0046 - val_loss: 0.0022 - val_mae: 0.0040\n",
      "Epoch 143/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0022 - mae: 0.0049 - val_loss: 0.0021 - val_mae: 0.0039\n",
      "Epoch 144/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0022 - mae: 0.0058 - val_loss: 0.0022 - val_mae: 0.0069\n",
      "Epoch 145/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0021 - mae: 0.0056 - val_loss: 0.0021 - val_mae: 0.0044\n",
      "Epoch 146/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0021 - mae: 0.0050 - val_loss: 0.0021 - val_mae: 0.0041\n",
      "Epoch 147/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0049 - val_loss: 0.0020 - val_mae: 0.0036\n",
      "Epoch 148/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0054 - val_loss: 0.0020 - val_mae: 0.0048\n",
      "Epoch 149/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0044 - val_loss: 0.0020 - val_mae: 0.0049\n",
      "Epoch 150/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0050 - val_loss: 0.0019 - val_mae: 0.0032\n",
      "Epoch 151/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0054 - val_loss: 0.0021 - val_mae: 0.0126\n",
      "Epoch 152/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0053 - val_loss: 0.0019 - val_mae: 0.0028\n",
      "Epoch 153/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0047 - val_loss: 0.0019 - val_mae: 0.0043\n",
      "Epoch 154/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0047 - val_loss: 0.0019 - val_mae: 0.0054\n",
      "Epoch 155/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0018 - mae: 0.0040 - val_loss: 0.0018 - val_mae: 0.0048\n",
      "Epoch 156/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0018 - mae: 0.0056 - val_loss: 0.0018 - val_mae: 0.0034\n",
      "Epoch 157/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0018 - mae: 0.0056 - val_loss: 0.0018 - val_mae: 0.0037\n",
      "Epoch 158/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0018 - mae: 0.0050 - val_loss: 0.0018 - val_mae: 0.0038\n",
      "Epoch 159/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0018 - mae: 0.0041 - val_loss: 0.0017 - val_mae: 0.0047\n",
      "Epoch 160/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0017 - mae: 0.0042 - val_loss: 0.0017 - val_mae: 0.0042\n",
      "Epoch 161/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0017 - mae: 0.0054 - val_loss: 0.0017 - val_mae: 0.0030\n",
      "Epoch 162/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0017 - mae: 0.0047 - val_loss: 0.0017 - val_mae: 0.0048\n",
      "Epoch 163/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0017 - mae: 0.0043 - val_loss: 0.0016 - val_mae: 0.0038\n",
      "Epoch 164/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0017 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0035\n",
      "Epoch 165/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0040 - val_loss: 0.0017 - val_mae: 0.0077\n",
      "Epoch 166/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0056 - val_loss: 0.0016 - val_mae: 0.0031\n",
      "Epoch 167/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0048 - val_loss: 0.0016 - val_mae: 0.0047\n",
      "Epoch 168/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0045 - val_loss: 0.0016 - val_mae: 0.0041\n",
      "Epoch 169/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0040 - val_loss: 0.0015 - val_mae: 0.0032\n",
      "Epoch 170/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0054\n",
      "Epoch 171/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0053 - val_loss: 0.0015 - val_mae: 0.0054\n",
      "Epoch 172/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0033\n",
      "Epoch 173/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 0.0015 - val_mae: 0.0066\n",
      "Epoch 174/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0056 - val_loss: 0.0014 - val_mae: 0.0040\n",
      "Epoch 175/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0054 - val_loss: 0.0014 - val_mae: 0.0035\n",
      "Epoch 176/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0038 - val_loss: 0.0014 - val_mae: 0.0027\n",
      "Epoch 177/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0041 - val_loss: 0.0015 - val_mae: 0.0068\n",
      "Epoch 178/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0036\n",
      "Epoch 179/2000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0052 - val_loss: 0.0018 - val_mae: 0.0182\n",
      "Epoch 180/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0051 - val_loss: 0.0014 - val_mae: 0.0040\n",
      "Epoch 181/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0047 - val_loss: 0.0013 - val_mae: 0.0038\n",
      "Epoch 182/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0039 - val_loss: 0.0013 - val_mae: 0.0049\n",
      "Epoch 183/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0050\n",
      "Epoch 184/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0049\n",
      "Epoch 185/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0054 - val_loss: 0.0013 - val_mae: 0.0062\n",
      "Epoch 186/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0041 - val_loss: 0.0013 - val_mae: 0.0027\n",
      "Epoch 187/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0012 - val_mae: 0.0034\n",
      "Epoch 188/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0012 - val_mae: 0.0025\n",
      "Epoch 189/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0063\n",
      "Epoch 190/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0039 - val_loss: 0.0012 - val_mae: 0.0031\n",
      "Epoch 191/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0045 - val_loss: 0.0012 - val_mae: 0.0029\n",
      "Epoch 192/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0053 - val_loss: 0.0012 - val_mae: 0.0042\n",
      "Epoch 193/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0042 - val_loss: 0.0012 - val_mae: 0.0035\n",
      "Epoch 194/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0040 - val_loss: 0.0012 - val_mae: 0.0057\n",
      "Epoch 195/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0040 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 196/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0012 - val_mae: 0.0067\n",
      "Epoch 197/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0047 - val_loss: 0.0011 - val_mae: 0.0033\n",
      "Epoch 198/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0046\n",
      "Epoch 199/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0037 - val_loss: 0.0011 - val_mae: 0.0027\n",
      "Epoch 200/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0044\n",
      "Epoch 201/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0046 - val_loss: 0.0011 - val_mae: 0.0048\n",
      "Epoch 202/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0038 - val_loss: 0.0010 - val_mae: 0.0028\n",
      "Epoch 203/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0045 - val_loss: 0.0010 - val_mae: 0.0039\n",
      "Epoch 204/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0050 - val_loss: 0.0010 - val_mae: 0.0051\n",
      "Epoch 205/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0042 - val_loss: 0.0010 - val_mae: 0.0041\n",
      "Epoch 206/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0039 - val_loss: 0.0010 - val_mae: 0.0030\n",
      "Epoch 207/2000\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0010 - mae: 0.0048 - val_loss: 9.8585e-04 - val_mae: 0.0026\n",
      "Epoch 208/2000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 9.9403e-04 - mae: 0.0036 - val_loss: 9.7596e-04 - val_mae: 0.0028\n",
      "Epoch 209/2000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 9.8698e-04 - mae: 0.0040 - val_loss: 9.8490e-04 - val_mae: 0.0044\n",
      "Epoch 210/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 9.7653e-04 - mae: 0.0041 - val_loss: 9.5083e-04 - val_mae: 0.0022\n",
      "Epoch 211/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 9.6421e-04 - mae: 0.0039 - val_loss: 9.5599e-04 - val_mae: 0.0039\n",
      "Epoch 212/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 9.5474e-04 - mae: 0.0040 - val_loss: 9.3796e-04 - val_mae: 0.0030\n",
      "Epoch 213/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 9.4870e-04 - mae: 0.0043 - val_loss: 9.2916e-04 - val_mae: 0.0031\n",
      "Epoch 214/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 9.4823e-04 - mae: 0.0048 - val_loss: 9.3169e-04 - val_mae: 0.0046\n",
      "Epoch 215/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 9.2175e-04 - mae: 0.0037 - val_loss: 9.3104e-04 - val_mae: 0.0057\n",
      "Epoch 216/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 9.1162e-04 - mae: 0.0038 - val_loss: 9.0219e-04 - val_mae: 0.0036\n",
      "Epoch 217/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 9.1378e-04 - mae: 0.0044 - val_loss: 9.1296e-04 - val_mae: 0.0051\n",
      "Epoch 218/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.9396e-04 - mae: 0.0038 - val_loss: 8.7950e-04 - val_mae: 0.0029\n",
      "Epoch 219/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.8472e-04 - mae: 0.0039 - val_loss: 8.7696e-04 - val_mae: 0.0038\n",
      "Epoch 220/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.8898e-04 - mae: 0.0046 - val_loss: 8.6010e-04 - val_mae: 0.0030\n",
      "Epoch 221/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.6860e-04 - mae: 0.0039 - val_loss: 9.3187e-04 - val_mae: 0.0069\n",
      "Epoch 222/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.6688e-04 - mae: 0.0042 - val_loss: 8.4375e-04 - val_mae: 0.0033\n",
      "Epoch 223/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.5637e-04 - mae: 0.0042 - val_loss: 8.4011e-04 - val_mae: 0.0036\n",
      "Epoch 224/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.3925e-04 - mae: 0.0036 - val_loss: 8.4315e-04 - val_mae: 0.0048\n",
      "Epoch 225/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.3235e-04 - mae: 0.0038 - val_loss: 8.2109e-04 - val_mae: 0.0035\n",
      "Epoch 226/2000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 8.2261e-04 - mae: 0.0037 - val_loss: 8.0724e-04 - val_mae: 0.0030\n",
      "Epoch 227/2000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 8.1947e-04 - mae: 0.0040 - val_loss: 8.0711e-04 - val_mae: 0.0033\n",
      "Epoch 228/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.0937e-04 - mae: 0.0038 - val_loss: 7.8724e-04 - val_mae: 0.0024\n",
      "Epoch 229/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.0068e-04 - mae: 0.0038 - val_loss: 7.9885e-04 - val_mae: 0.0049\n",
      "Epoch 230/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.8362e-04 - mae: 0.0033 - val_loss: 7.7018e-04 - val_mae: 0.0024\n",
      "Epoch 231/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.8607e-04 - mae: 0.0040 - val_loss: 7.9276e-04 - val_mae: 0.0048\n",
      "Epoch 232/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.7220e-04 - mae: 0.0036 - val_loss: 7.7671e-04 - val_mae: 0.0045\n",
      "Epoch 233/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.7427e-04 - mae: 0.0043 - val_loss: 7.4966e-04 - val_mae: 0.0028\n",
      "Epoch 234/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.7326e-04 - mae: 0.0047 - val_loss: 7.4433e-04 - val_mae: 0.0030\n",
      "Epoch 235/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.4848e-04 - mae: 0.0034 - val_loss: 7.5270e-04 - val_mae: 0.0047\n",
      "Epoch 236/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.4383e-04 - mae: 0.0037 - val_loss: 7.9418e-04 - val_mae: 0.0065\n",
      "Epoch 237/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.3700e-04 - mae: 0.0037 - val_loss: 7.5292e-04 - val_mae: 0.0046\n",
      "Epoch 238/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.3105e-04 - mae: 0.0037 - val_loss: 7.1654e-04 - val_mae: 0.0031\n",
      "Epoch 239/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.1745e-04 - mae: 0.0034 - val_loss: 7.0852e-04 - val_mae: 0.0031\n",
      "Epoch 240/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.1603e-04 - mae: 0.0038 - val_loss: 7.0662e-04 - val_mae: 0.0035\n",
      "Epoch 241/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.0954e-04 - mae: 0.0038 - val_loss: 7.3619e-04 - val_mae: 0.0066\n",
      "Epoch 242/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.0736e-04 - mae: 0.0041 - val_loss: 7.0236e-04 - val_mae: 0.0045\n",
      "Epoch 243/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.9164e-04 - mae: 0.0036 - val_loss: 6.7721e-04 - val_mae: 0.0024\n",
      "Epoch 244/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.8802e-04 - mae: 0.0037 - val_loss: 6.7146e-04 - val_mae: 0.0027\n",
      "Epoch 245/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.9398e-04 - mae: 0.0042 - val_loss: 6.7428e-04 - val_mae: 0.0035\n",
      "Epoch 246/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.6782e-04 - mae: 0.0032 - val_loss: 6.6364e-04 - val_mae: 0.0032\n",
      "Epoch 247/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.6298e-04 - mae: 0.0033 - val_loss: 6.8465e-04 - val_mae: 0.0052\n",
      "Epoch 248/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.6167e-04 - mae: 0.0037 - val_loss: 6.9587e-04 - val_mae: 0.0065\n",
      "Epoch 249/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.5456e-04 - mae: 0.0036 - val_loss: 6.3990e-04 - val_mae: 0.0025\n",
      "Epoch 250/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.4193e-04 - mae: 0.0031 - val_loss: 6.9615e-04 - val_mae: 0.0065\n",
      "Epoch 251/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.4564e-04 - mae: 0.0039 - val_loss: 6.2682e-04 - val_mae: 0.0026\n",
      "Epoch 252/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.3826e-04 - mae: 0.0038 - val_loss: 6.2589e-04 - val_mae: 0.0031\n",
      "Epoch 253/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.3825e-04 - mae: 0.0042 - val_loss: 6.1577e-04 - val_mae: 0.0026\n",
      "Epoch 254/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.2216e-04 - mae: 0.0034 - val_loss: 6.1266e-04 - val_mae: 0.0033\n",
      "Epoch 255/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.1314e-04 - mae: 0.0032 - val_loss: 6.1685e-04 - val_mae: 0.0036\n",
      "Epoch 256/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.2401e-04 - mae: 0.0044 - val_loss: 6.0618e-04 - val_mae: 0.0035\n",
      "Epoch 257/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.0830e-04 - mae: 0.0037 - val_loss: 6.0442e-04 - val_mae: 0.0040\n",
      "Epoch 258/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.1015e-04 - mae: 0.0041 - val_loss: 5.8785e-04 - val_mae: 0.0027\n",
      "Epoch 259/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.9253e-04 - mae: 0.0033 - val_loss: 5.8452e-04 - val_mae: 0.0029\n",
      "Epoch 260/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.9188e-04 - mae: 0.0035 - val_loss: 5.7820e-04 - val_mae: 0.0028\n",
      "Epoch 261/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.9187e-04 - mae: 0.0039 - val_loss: 5.8687e-04 - val_mae: 0.0037\n",
      "Epoch 262/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.7790e-04 - mae: 0.0033 - val_loss: 5.6781e-04 - val_mae: 0.0027\n",
      "Epoch 263/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.8403e-04 - mae: 0.0038 - val_loss: 5.6241e-04 - val_mae: 0.0026\n",
      "Epoch 264/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.6823e-04 - mae: 0.0033 - val_loss: 5.5649e-04 - val_mae: 0.0024\n",
      "Epoch 265/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.6562e-04 - mae: 0.0035 - val_loss: 5.7124e-04 - val_mae: 0.0039\n",
      "Epoch 266/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.6447e-04 - mae: 0.0037 - val_loss: 5.5783e-04 - val_mae: 0.0034\n",
      "Epoch 267/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.5480e-04 - mae: 0.0034 - val_loss: 5.4288e-04 - val_mae: 0.0026\n",
      "Epoch 268/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.4838e-04 - mae: 0.0033 - val_loss: 5.3772e-04 - val_mae: 0.0025\n",
      "Epoch 269/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.4592e-04 - mae: 0.0034 - val_loss: 5.4247e-04 - val_mae: 0.0037\n",
      "Epoch 270/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.4425e-04 - mae: 0.0037 - val_loss: 5.3592e-04 - val_mae: 0.0032\n",
      "Epoch 271/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.3279e-04 - mae: 0.0032 - val_loss: 5.2435e-04 - val_mae: 0.0027\n",
      "Epoch 272/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.3263e-04 - mae: 0.0035 - val_loss: 5.2666e-04 - val_mae: 0.0030\n",
      "Epoch 273/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.3005e-04 - mae: 0.0037 - val_loss: 5.1762e-04 - val_mae: 0.0031\n",
      "Epoch 274/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.2025e-04 - mae: 0.0033 - val_loss: 5.3477e-04 - val_mae: 0.0050\n",
      "Epoch 275/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.1814e-04 - mae: 0.0035 - val_loss: 5.2872e-04 - val_mae: 0.0051\n",
      "Epoch 276/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.1720e-04 - mae: 0.0037 - val_loss: 5.0954e-04 - val_mae: 0.0036\n",
      "Epoch 277/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.0976e-04 - mae: 0.0035 - val_loss: 4.9780e-04 - val_mae: 0.0028\n",
      "Epoch 278/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.0807e-04 - mae: 0.0036 - val_loss: 5.0138e-04 - val_mae: 0.0036\n",
      "Epoch 279/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.0177e-04 - mae: 0.0034 - val_loss: 4.8557e-04 - val_mae: 0.0021\n",
      "Epoch 280/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.9517e-04 - mae: 0.0033 - val_loss: 4.8800e-04 - val_mae: 0.0031\n",
      "Epoch 281/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.9436e-04 - mae: 0.0036 - val_loss: 4.9802e-04 - val_mae: 0.0043\n",
      "Epoch 282/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.9163e-04 - mae: 0.0037 - val_loss: 4.9351e-04 - val_mae: 0.0040\n",
      "Epoch 283/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.8505e-04 - mae: 0.0034 - val_loss: 4.7292e-04 - val_mae: 0.0025\n",
      "Epoch 284/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.7958e-04 - mae: 0.0033 - val_loss: 6.0675e-04 - val_mae: 0.0085\n",
      "Epoch 285/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.8961e-04 - mae: 0.0039 - val_loss: 4.6326e-04 - val_mae: 0.0021\n",
      "Epoch 286/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.7241e-04 - mae: 0.0033 - val_loss: 4.7322e-04 - val_mae: 0.0035\n",
      "Epoch 287/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.6571e-04 - mae: 0.0030 - val_loss: 4.7124e-04 - val_mae: 0.0037\n",
      "Epoch 288/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.7147e-04 - mae: 0.0036 - val_loss: 4.8820e-04 - val_mae: 0.0054\n",
      "Epoch 289/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.5968e-04 - mae: 0.0031 - val_loss: 4.5750e-04 - val_mae: 0.0029\n",
      "Epoch 290/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.5647e-04 - mae: 0.0032 - val_loss: 4.5296e-04 - val_mae: 0.0032\n",
      "Epoch 291/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.5320e-04 - mae: 0.0032 - val_loss: 4.5769e-04 - val_mae: 0.0038\n",
      "Epoch 292/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.5326e-04 - mae: 0.0035 - val_loss: 5.0921e-04 - val_mae: 0.0064\n",
      "Epoch 293/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.5324e-04 - mae: 0.0037 - val_loss: 4.3805e-04 - val_mae: 0.0025\n",
      "Epoch 294/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.4437e-04 - mae: 0.0033 - val_loss: 4.3375e-04 - val_mae: 0.0026\n",
      "Epoch 295/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.5156e-04 - mae: 0.0038 - val_loss: 4.5488e-04 - val_mae: 0.0046\n",
      "Epoch 296/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.3467e-04 - mae: 0.0030 - val_loss: 4.4176e-04 - val_mae: 0.0043\n",
      "Epoch 297/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.3499e-04 - mae: 0.0033 - val_loss: 4.3476e-04 - val_mae: 0.0038\n",
      "Epoch 298/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.2773e-04 - mae: 0.0030 - val_loss: 4.3627e-04 - val_mae: 0.0044\n",
      "Epoch 299/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.3032e-04 - mae: 0.0035 - val_loss: 4.2030e-04 - val_mae: 0.0026\n",
      "Epoch 300/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.2524e-04 - mae: 0.0033 - val_loss: 4.2075e-04 - val_mae: 0.0031\n",
      "Epoch 301/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.2368e-04 - mae: 0.0034 - val_loss: 4.1728e-04 - val_mae: 0.0034\n",
      "Epoch 302/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.1348e-04 - mae: 0.0028 - val_loss: 4.4381e-04 - val_mae: 0.0055\n",
      "Epoch 303/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.1838e-04 - mae: 0.0035 - val_loss: 4.0706e-04 - val_mae: 0.0026\n",
      "Epoch 304/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.1392e-04 - mae: 0.0034 - val_loss: 4.0182e-04 - val_mae: 0.0024\n",
      "Epoch 305/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.0620e-04 - mae: 0.0030 - val_loss: 4.0049e-04 - val_mae: 0.0027\n",
      "Epoch 306/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.0329e-04 - mae: 0.0030 - val_loss: 3.9771e-04 - val_mae: 0.0027\n",
      "Epoch 307/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.1090e-04 - mae: 0.0036 - val_loss: 3.9951e-04 - val_mae: 0.0033\n",
      "Epoch 308/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.0198e-04 - mae: 0.0032 - val_loss: 3.9602e-04 - val_mae: 0.0033\n",
      "Epoch 309/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.9548e-04 - mae: 0.0030 - val_loss: 3.8773e-04 - val_mae: 0.0025\n",
      "Epoch 310/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.9345e-04 - mae: 0.0031 - val_loss: 3.8208e-04 - val_mae: 0.0021\n",
      "Epoch 311/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.9752e-04 - mae: 0.0036 - val_loss: 3.8731e-04 - val_mae: 0.0031\n",
      "Epoch 312/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.8561e-04 - mae: 0.0029 - val_loss: 3.7875e-04 - val_mae: 0.0024\n",
      "Epoch 313/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.8744e-04 - mae: 0.0033 - val_loss: 3.8893e-04 - val_mae: 0.0040\n",
      "Epoch 314/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.8360e-04 - mae: 0.0032 - val_loss: 3.7380e-04 - val_mae: 0.0024\n",
      "Epoch 315/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.7962e-04 - mae: 0.0031 - val_loss: 3.9210e-04 - val_mae: 0.0040\n",
      "Epoch 316/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.7956e-04 - mae: 0.0033 - val_loss: 3.7184e-04 - val_mae: 0.0029\n",
      "Epoch 317/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.7376e-04 - mae: 0.0030 - val_loss: 3.6570e-04 - val_mae: 0.0026\n",
      "Epoch 318/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.7240e-04 - mae: 0.0032 - val_loss: 3.6040e-04 - val_mae: 0.0020\n",
      "Epoch 319/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.6747e-04 - mae: 0.0030 - val_loss: 3.6069e-04 - val_mae: 0.0024\n",
      "Epoch 320/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.6687e-04 - mae: 0.0031 - val_loss: 3.6619e-04 - val_mae: 0.0036\n",
      "Epoch 321/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.6915e-04 - mae: 0.0034 - val_loss: 3.5605e-04 - val_mae: 0.0025\n",
      "Epoch 322/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.7030e-04 - mae: 0.0037 - val_loss: 3.5264e-04 - val_mae: 0.0023\n",
      "Epoch 323/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.5869e-04 - mae: 0.0030 - val_loss: 3.5922e-04 - val_mae: 0.0036\n",
      "Epoch 324/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.6140e-04 - mae: 0.0034 - val_loss: 3.5185e-04 - val_mae: 0.0027\n",
      "Epoch 325/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.5229e-04 - mae: 0.0029 - val_loss: 3.5596e-04 - val_mae: 0.0033\n",
      "Epoch 326/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.4920e-04 - mae: 0.0028 - val_loss: 3.4837e-04 - val_mae: 0.0030\n",
      "Epoch 327/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.4730e-04 - mae: 0.0029 - val_loss: 3.4080e-04 - val_mae: 0.0023\n",
      "Epoch 328/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.4898e-04 - mae: 0.0032 - val_loss: 3.4336e-04 - val_mae: 0.0029\n",
      "Epoch 329/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.4825e-04 - mae: 0.0032 - val_loss: 3.8089e-04 - val_mae: 0.0049\n",
      "Epoch 330/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.4208e-04 - mae: 0.0030 - val_loss: 3.5305e-04 - val_mae: 0.0046\n",
      "Epoch 331/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.4018e-04 - mae: 0.0030 - val_loss: 3.3131e-04 - val_mae: 0.0023\n",
      "Epoch 332/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.3771e-04 - mae: 0.0030 - val_loss: 3.7904e-04 - val_mae: 0.0053\n",
      "Epoch 333/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.3965e-04 - mae: 0.0033 - val_loss: 3.4353e-04 - val_mae: 0.0038\n",
      "Epoch 334/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.3234e-04 - mae: 0.0029 - val_loss: 3.2555e-04 - val_mae: 0.0023\n",
      "Epoch 335/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.2896e-04 - mae: 0.0028 - val_loss: 3.2505e-04 - val_mae: 0.0026\n",
      "Epoch 336/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.3505e-04 - mae: 0.0034 - val_loss: 3.2194e-04 - val_mae: 0.0022\n",
      "Epoch 337/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.2715e-04 - mae: 0.0030 - val_loss: 3.2467e-04 - val_mae: 0.0029\n",
      "Epoch 338/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.2481e-04 - mae: 0.0030 - val_loss: 3.1703e-04 - val_mae: 0.0024\n",
      "Epoch 339/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.2214e-04 - mae: 0.0029 - val_loss: 3.6649e-04 - val_mae: 0.0068\n",
      "Epoch 340/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.2435e-04 - mae: 0.0033 - val_loss: 3.1849e-04 - val_mae: 0.0030\n",
      "Epoch 341/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.1920e-04 - mae: 0.0030 - val_loss: 3.1276e-04 - val_mae: 0.0027\n",
      "Epoch 342/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.1535e-04 - mae: 0.0029 - val_loss: 3.1056e-04 - val_mae: 0.0025\n",
      "Epoch 343/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.1700e-04 - mae: 0.0032 - val_loss: 3.9699e-04 - val_mae: 0.0070\n",
      "Epoch 344/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.1840e-04 - mae: 0.0033 - val_loss: 3.2024e-04 - val_mae: 0.0039\n",
      "Epoch 345/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.0830e-04 - mae: 0.0027 - val_loss: 3.0225e-04 - val_mae: 0.0021\n",
      "Epoch 346/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.1198e-04 - mae: 0.0031 - val_loss: 3.0397e-04 - val_mae: 0.0027\n",
      "Epoch 347/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.0849e-04 - mae: 0.0031 - val_loss: 3.0649e-04 - val_mae: 0.0030\n",
      "Epoch 348/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.1415e-04 - mae: 0.0036 - val_loss: 2.9654e-04 - val_mae: 0.0021\n",
      "Epoch 349/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.0336e-04 - mae: 0.0029 - val_loss: 2.9821e-04 - val_mae: 0.0027\n",
      "Epoch 350/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.9770e-04 - mae: 0.0025 - val_loss: 3.0415e-04 - val_mae: 0.0034\n",
      "Epoch 351/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.0120e-04 - mae: 0.0031 - val_loss: 2.9612e-04 - val_mae: 0.0029\n",
      "Epoch 352/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.9819e-04 - mae: 0.0029 - val_loss: 2.8966e-04 - val_mae: 0.0021\n",
      "Epoch 353/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.9661e-04 - mae: 0.0029 - val_loss: 3.0633e-04 - val_mae: 0.0044\n",
      "Epoch 354/2000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.9448e-04 - mae: 0.0029 - val_loss: 3.0580e-04 - val_mae: 0.0044\n",
      "Epoch 355/2000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.9092e-04 - mae: 0.0027 - val_loss: 2.8852e-04 - val_mae: 0.0025\n",
      "Epoch 356/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.9685e-04 - mae: 0.0033 - val_loss: 2.8350e-04 - val_mae: 0.0022\n",
      "Epoch 357/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.8915e-04 - mae: 0.0029 - val_loss: 3.1130e-04 - val_mae: 0.0050\n",
      "Epoch 358/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.8709e-04 - mae: 0.0028 - val_loss: 2.8054e-04 - val_mae: 0.0023\n",
      "Epoch 359/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.8912e-04 - mae: 0.0032 - val_loss: 2.8515e-04 - val_mae: 0.0030\n",
      "Epoch 360/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.8979e-04 - mae: 0.0033 - val_loss: 2.8133e-04 - val_mae: 0.0027\n",
      "Epoch 361/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.8420e-04 - mae: 0.0030 - val_loss: 2.7997e-04 - val_mae: 0.0029\n",
      "Epoch 362/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.8152e-04 - mae: 0.0028 - val_loss: 3.0064e-04 - val_mae: 0.0046\n",
      "Epoch 363/2000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.7952e-04 - mae: 0.0029 - val_loss: 2.7581e-04 - val_mae: 0.0027\n",
      "Epoch 364/2000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.7688e-04 - mae: 0.0027 - val_loss: 3.2235e-04 - val_mae: 0.0062\n",
      "Epoch 365/2000\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.8048e-04 - mae: 0.0032 - val_loss: 2.8170e-04 - val_mae: 0.0036\n",
      "Epoch 366/2000\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.7611e-04 - mae: 0.0030 - val_loss: 2.7370e-04 - val_mae: 0.0028\n",
      "Epoch 367/2000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.7474e-04 - mae: 0.0030 - val_loss: 2.6969e-04 - val_mae: 0.0026\n",
      "Epoch 368/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.7068e-04 - mae: 0.0027 - val_loss: 2.6377e-04 - val_mae: 0.0021\n",
      "Epoch 369/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.7069e-04 - mae: 0.0028 - val_loss: 2.6496e-04 - val_mae: 0.0024\n",
      "Epoch 370/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.6786e-04 - mae: 0.0027 - val_loss: 2.6758e-04 - val_mae: 0.0028\n",
      "Epoch 371/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.6789e-04 - mae: 0.0029 - val_loss: 2.7312e-04 - val_mae: 0.0038\n",
      "Epoch 372/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.7191e-04 - mae: 0.0033 - val_loss: 2.6008e-04 - val_mae: 0.0023\n",
      "Epoch 373/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.6398e-04 - mae: 0.0028 - val_loss: 2.5690e-04 - val_mae: 0.0020\n",
      "Epoch 374/2000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.6835e-04 - mae: 0.0032 - val_loss: 2.5520e-04 - val_mae: 0.0020\n",
      "Epoch 375/2000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.6198e-04 - mae: 0.0028 - val_loss: 2.8162e-04 - val_mae: 0.0041\n",
      "Epoch 376/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.6272e-04 - mae: 0.0030 - val_loss: 2.6926e-04 - val_mae: 0.0034\n",
      "Epoch 377/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.5919e-04 - mae: 0.0027 - val_loss: 2.5189e-04 - val_mae: 0.0021\n",
      "Epoch 378/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.5585e-04 - mae: 0.0026 - val_loss: 2.4997e-04 - val_mae: 0.0020\n",
      "Epoch 379/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.6221e-04 - mae: 0.0032 - val_loss: 2.4918e-04 - val_mae: 0.0020\n",
      "Epoch 380/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.5448e-04 - mae: 0.0027 - val_loss: 2.4922e-04 - val_mae: 0.0022\n",
      "Epoch 381/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.6057e-04 - mae: 0.0032 - val_loss: 2.4635e-04 - val_mae: 0.0020\n",
      "Epoch 382/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.5137e-04 - mae: 0.0026 - val_loss: 2.4829e-04 - val_mae: 0.0026\n",
      "Epoch 383/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.5082e-04 - mae: 0.0027 - val_loss: 2.5746e-04 - val_mae: 0.0038\n",
      "Epoch 384/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.4874e-04 - mae: 0.0026 - val_loss: 2.4474e-04 - val_mae: 0.0024\n",
      "Epoch 385/2000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.4919e-04 - mae: 0.0028 - val_loss: 2.5670e-04 - val_mae: 0.0036\n",
      "Epoch 386/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.4706e-04 - mae: 0.0027 - val_loss: 2.4121e-04 - val_mae: 0.0021\n",
      "Epoch 387/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.4837e-04 - mae: 0.0029 - val_loss: 2.4669e-04 - val_mae: 0.0030\n",
      "Epoch 388/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.4482e-04 - mae: 0.0027 - val_loss: 2.4270e-04 - val_mae: 0.0025\n",
      "Epoch 389/2000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.4611e-04 - mae: 0.0030 - val_loss: 2.5676e-04 - val_mae: 0.0043\n",
      "Epoch 390/2000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.4512e-04 - mae: 0.0030 - val_loss: 2.3435e-04 - val_mae: 0.0019\n",
      "Epoch 391/2000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.4156e-04 - mae: 0.0027 - val_loss: 2.4021e-04 - val_mae: 0.0026\n",
      "Epoch 392/2000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.4372e-04 - mae: 0.0030 - val_loss: 2.3480e-04 - val_mae: 0.0023\n",
      "Epoch 393/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3967e-04 - mae: 0.0028 - val_loss: 2.3166e-04 - val_mae: 0.0020\n",
      "Epoch 394/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3714e-04 - mae: 0.0027 - val_loss: 2.3257e-04 - val_mae: 0.0022\n",
      "Epoch 395/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.4070e-04 - mae: 0.0030 - val_loss: 2.3197e-04 - val_mae: 0.0022\n",
      "Epoch 396/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3637e-04 - mae: 0.0028 - val_loss: 2.3455e-04 - val_mae: 0.0028\n",
      "Epoch 397/2000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3726e-04 - mae: 0.0030 - val_loss: 2.3109e-04 - val_mae: 0.0025\n",
      "Epoch 398/2000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3381e-04 - mae: 0.0027 - val_loss: 2.2655e-04 - val_mae: 0.0020\n",
      "Epoch 399/2000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3324e-04 - mae: 0.0028 - val_loss: 2.6429e-04 - val_mae: 0.0046\n",
      "Epoch 400/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3593e-04 - mae: 0.0030 - val_loss: 2.2743e-04 - val_mae: 0.0023\n",
      "Epoch 401/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3164e-04 - mae: 0.0028 - val_loss: 2.2644e-04 - val_mae: 0.0024\n",
      "Epoch 402/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2887e-04 - mae: 0.0026 - val_loss: 2.2548e-04 - val_mae: 0.0023\n",
      "Epoch 403/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2639e-04 - mae: 0.0025 - val_loss: 2.2829e-04 - val_mae: 0.0027\n",
      "Epoch 404/2000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2933e-04 - mae: 0.0029 - val_loss: 2.3015e-04 - val_mae: 0.0028\n",
      "Epoch 405/2000\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2568e-04 - mae: 0.0026 - val_loss: 2.2936e-04 - val_mae: 0.0034\n",
      "Epoch 406/2000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2385e-04 - mae: 0.0026 - val_loss: 2.2166e-04 - val_mae: 0.0024\n",
      "Epoch 407/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2675e-04 - mae: 0.0029 - val_loss: 2.3535e-04 - val_mae: 0.0037\n",
      "Epoch 408/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2773e-04 - mae: 0.0031 - val_loss: 2.2548e-04 - val_mae: 0.0032\n",
      "Epoch 409/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2095e-04 - mae: 0.0026 - val_loss: 2.1614e-04 - val_mae: 0.0021\n",
      "Epoch 410/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2137e-04 - mae: 0.0027 - val_loss: 2.1989e-04 - val_mae: 0.0027\n",
      "Epoch 411/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2000e-04 - mae: 0.0027 - val_loss: 2.2096e-04 - val_mae: 0.0028\n",
      "Epoch 412/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2234e-04 - mae: 0.0030 - val_loss: 2.1238e-04 - val_mae: 0.0020\n",
      "Epoch 413/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.1845e-04 - mae: 0.0026 - val_loss: 2.1577e-04 - val_mae: 0.0027\n",
      "Epoch 414/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.1926e-04 - mae: 0.0028 - val_loss: 2.1688e-04 - val_mae: 0.0028\n",
      "Epoch 415/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.1606e-04 - mae: 0.0026 - val_loss: 2.2507e-04 - val_mae: 0.0035\n",
      "Epoch 416/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.1494e-04 - mae: 0.0026 - val_loss: 2.1870e-04 - val_mae: 0.0034\n",
      "Epoch 417/2000\n",
      "371/375 [============================>.] - ETA: 0s - loss: 2.2068e-04 - mae: 0.0032Restoring model weights from the end of the best epoch: 412.\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2073e-04 - mae: 0.0033 - val_loss: 2.1968e-04 - val_mae: 0.0029\n",
      "Epoch 417: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Netzwerkarchitektur\n",
    "model = Sequential([\n",
    "\n",
    "    Dense(328, activation='relu', input_shape=(4,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)), \n",
    "    \n",
    "    Dense(328, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(248, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(104, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(1 , activation = 'linear')\n",
    "])\n",
    "\n",
    "# Optimierer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "# Modell kompilieren (Verwendung von mean_squared_error als Verlustfunktion fÃ¼r Regression)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])  # Metriken fÃ¼r Regression: Mean Absolute Error und Mean Squared Error\n",
    "\n",
    "# Early Stopping Callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "# Trainingsparameter\n",
    "batch_size = 16\n",
    "epochs = 2000\n",
    "\n",
    "# Modell trainieren (Annahme: X_train, y_train, X_val, y_val sind vordefiniert)\n",
    "history = model.fit(X_train_scaled, y_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "model.save('D4_I_F_2.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T10:06:46.955997200Z",
     "start_time": "2024-04-02T09:58:20.434367900Z"
    }
   },
   "id": "8b52e1a9a6ff3aeb"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "Training fÃ¼r Fold 1...\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "375/375 [==============================] - 5s 5ms/step - loss: 0.0702 - mae: 0.1457 - val_loss: 0.0348 - val_mae: 0.0878\n",
      "Epoch 2/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0284 - mae: 0.0707 - val_loss: 0.0237 - val_mae: 0.0501\n",
      "Epoch 3/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0212 - mae: 0.0475 - val_loss: 0.0212 - val_mae: 0.0559\n",
      "Epoch 4/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0188 - mae: 0.0373 - val_loss: 0.0174 - val_mae: 0.0262\n",
      "Epoch 5/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0172 - mae: 0.0286 - val_loss: 0.0165 - val_mae: 0.0209\n",
      "Epoch 6/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0164 - mae: 0.0225 - val_loss: 0.0159 - val_mae: 0.0174\n",
      "Epoch 7/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0162 - mae: 0.0225 - val_loss: 0.0159 - val_mae: 0.0203\n",
      "Epoch 8/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0161 - mae: 0.0236 - val_loss: 0.0159 - val_mae: 0.0236\n",
      "Epoch 9/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0160 - mae: 0.0247 - val_loss: 0.0188 - val_mae: 0.0558\n",
      "Epoch 10/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0155 - mae: 0.0197 - val_loss: 0.0155 - val_mae: 0.0236\n",
      "Epoch 11/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0152 - mae: 0.0197 - val_loss: 0.0150 - val_mae: 0.0181\n",
      "Epoch 12/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0150 - mae: 0.0185 - val_loss: 0.0147 - val_mae: 0.0155\n",
      "Epoch 13/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0150 - mae: 0.0215 - val_loss: 0.0146 - val_mae: 0.0181\n",
      "Epoch 14/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0146 - mae: 0.0188 - val_loss: 0.0144 - val_mae: 0.0169\n",
      "Epoch 15/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0151 - mae: 0.0269 - val_loss: 0.0143 - val_mae: 0.0189\n",
      "Epoch 16/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0141 - mae: 0.0157 - val_loss: 0.0145 - val_mae: 0.0266\n",
      "Epoch 17/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0142 - mae: 0.0206 - val_loss: 0.0142 - val_mae: 0.0214\n",
      "Epoch 18/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0142 - mae: 0.0212 - val_loss: 0.0137 - val_mae: 0.0162\n",
      "Epoch 19/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0136 - mae: 0.0154 - val_loss: 0.0133 - val_mae: 0.0109\n",
      "Epoch 20/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0136 - mae: 0.0180 - val_loss: 0.0135 - val_mae: 0.0188\n",
      "Epoch 21/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0133 - mae: 0.0156 - val_loss: 0.0131 - val_mae: 0.0146\n",
      "Epoch 22/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0135 - mae: 0.0207 - val_loss: 0.0128 - val_mae: 0.0117\n",
      "Epoch 23/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0129 - mae: 0.0150 - val_loss: 0.0126 - val_mae: 0.0101\n",
      "Epoch 24/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0127 - mae: 0.0149 - val_loss: 0.0142 - val_mae: 0.0344\n",
      "Epoch 25/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0129 - mae: 0.0201 - val_loss: 0.0124 - val_mae: 0.0145\n",
      "Epoch 26/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0125 - mae: 0.0171 - val_loss: 0.0123 - val_mae: 0.0133\n",
      "Epoch 27/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0121 - mae: 0.0124 - val_loss: 0.0119 - val_mae: 0.0100\n",
      "Epoch 28/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0124 - mae: 0.0185 - val_loss: 0.0122 - val_mae: 0.0191\n",
      "Epoch 29/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0121 - mae: 0.0174 - val_loss: 0.0117 - val_mae: 0.0118\n",
      "Epoch 30/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0116 - mae: 0.0098 - val_loss: 0.0114 - val_mae: 0.0070\n",
      "Epoch 31/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0116 - mae: 0.0135 - val_loss: 0.0130 - val_mae: 0.0341\n",
      "Epoch 32/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0118 - mae: 0.0179 - val_loss: 0.0112 - val_mae: 0.0120\n",
      "Epoch 33/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0111 - mae: 0.0092 - val_loss: 0.0110 - val_mae: 0.0100\n",
      "Epoch 34/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0116 - mae: 0.0199 - val_loss: 0.0112 - val_mae: 0.0172\n",
      "Epoch 35/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0111 - mae: 0.0159 - val_loss: 0.0107 - val_mae: 0.0104\n",
      "Epoch 36/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0107 - mae: 0.0096 - val_loss: 0.0105 - val_mae: 0.0064\n",
      "Epoch 37/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0107 - mae: 0.0129 - val_loss: 0.0104 - val_mae: 0.0073\n",
      "Epoch 38/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0104 - mae: 0.0109 - val_loss: 0.0104 - val_mae: 0.0127\n",
      "Epoch 39/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0104 - mae: 0.0130 - val_loss: 0.0102 - val_mae: 0.0100\n",
      "Epoch 40/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0101 - mae: 0.0099 - val_loss: 0.0101 - val_mae: 0.0117\n",
      "Epoch 41/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0102 - mae: 0.0148 - val_loss: 0.0100 - val_mae: 0.0144\n",
      "Epoch 42/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0100 - mae: 0.0126 - val_loss: 0.0104 - val_mae: 0.0217\n",
      "Epoch 43/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0097 - mae: 0.0107 - val_loss: 0.0097 - val_mae: 0.0117\n",
      "Epoch 44/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0096 - mae: 0.0121 - val_loss: 0.0094 - val_mae: 0.0084\n",
      "Epoch 45/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0094 - mae: 0.0099 - val_loss: 0.0094 - val_mae: 0.0117\n",
      "Epoch 46/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0094 - mae: 0.0137 - val_loss: 0.0092 - val_mae: 0.0107\n",
      "Epoch 47/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0091 - mae: 0.0098 - val_loss: 0.0089 - val_mae: 0.0059\n",
      "Epoch 48/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0090 - mae: 0.0108 - val_loss: 0.0093 - val_mae: 0.0174\n",
      "Epoch 49/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0089 - mae: 0.0113 - val_loss: 0.0087 - val_mae: 0.0090\n",
      "Epoch 50/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0087 - mae: 0.0097 - val_loss: 0.0086 - val_mae: 0.0091\n",
      "Epoch 51/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0086 - mae: 0.0105 - val_loss: 0.0085 - val_mae: 0.0080\n",
      "Epoch 52/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0084 - mae: 0.0094 - val_loss: 0.0084 - val_mae: 0.0097\n",
      "Epoch 53/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0083 - mae: 0.0102 - val_loss: 0.0084 - val_mae: 0.0131\n",
      "Epoch 54/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0082 - mae: 0.0102 - val_loss: 0.0080 - val_mae: 0.0059\n",
      "Epoch 55/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0081 - mae: 0.0100 - val_loss: 0.0079 - val_mae: 0.0063\n",
      "Epoch 56/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0079 - mae: 0.0094 - val_loss: 0.0079 - val_mae: 0.0101\n",
      "Epoch 57/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0078 - mae: 0.0091 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 58/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0078 - mae: 0.0117 - val_loss: 0.0076 - val_mae: 0.0086\n",
      "Epoch 59/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0075 - mae: 0.0079 - val_loss: 0.0077 - val_mae: 0.0133\n",
      "Epoch 60/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0075 - mae: 0.0091 - val_loss: 0.0073 - val_mae: 0.0075\n",
      "Epoch 61/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0073 - mae: 0.0077 - val_loss: 0.0073 - val_mae: 0.0100\n",
      "Epoch 62/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0073 - mae: 0.0100 - val_loss: 0.0072 - val_mae: 0.0097\n",
      "Epoch 63/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0071 - mae: 0.0077 - val_loss: 0.0070 - val_mae: 0.0070\n",
      "Epoch 64/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0070 - mae: 0.0094 - val_loss: 0.0071 - val_mae: 0.0132\n",
      "Epoch 65/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0069 - mae: 0.0107 - val_loss: 0.0068 - val_mae: 0.0081\n",
      "Epoch 66/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0067 - mae: 0.0068 - val_loss: 0.0066 - val_mae: 0.0052\n",
      "Epoch 67/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0066 - mae: 0.0083 - val_loss: 0.0066 - val_mae: 0.0096\n",
      "Epoch 68/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0065 - mae: 0.0085 - val_loss: 0.0073 - val_mae: 0.0232\n",
      "Epoch 69/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0066 - mae: 0.0125 - val_loss: 0.0071 - val_mae: 0.0210\n",
      "Epoch 70/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0063 - mae: 0.0078 - val_loss: 0.0062 - val_mae: 0.0064\n",
      "Epoch 71/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0062 - mae: 0.0054 - val_loss: 0.0061 - val_mae: 0.0047\n",
      "Epoch 72/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0061 - mae: 0.0072 - val_loss: 0.0060 - val_mae: 0.0051\n",
      "Epoch 73/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0060 - mae: 0.0077 - val_loss: 0.0059 - val_mae: 0.0057\n",
      "Epoch 74/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0060 - mae: 0.0090 - val_loss: 0.0060 - val_mae: 0.0113\n",
      "Epoch 75/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0058 - mae: 0.0072 - val_loss: 0.0058 - val_mae: 0.0089\n",
      "Epoch 76/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0057 - mae: 0.0078 - val_loss: 0.0058 - val_mae: 0.0089\n",
      "Epoch 77/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0057 - mae: 0.0093 - val_loss: 0.0056 - val_mae: 0.0083\n",
      "Epoch 78/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0056 - mae: 0.0082 - val_loss: 0.0060 - val_mae: 0.0180\n",
      "Epoch 79/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0055 - mae: 0.0087 - val_loss: 0.0056 - val_mae: 0.0131\n",
      "Epoch 80/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0054 - mae: 0.0067 - val_loss: 0.0053 - val_mae: 0.0071\n",
      "Epoch 81/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0053 - mae: 0.0068 - val_loss: 0.0052 - val_mae: 0.0060\n",
      "Epoch 82/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0053 - mae: 0.0098 - val_loss: 0.0051 - val_mae: 0.0047\n",
      "Epoch 83/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0052 - mae: 0.0087 - val_loss: 0.0051 - val_mae: 0.0077\n",
      "Epoch 84/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0051 - mae: 0.0063 - val_loss: 0.0050 - val_mae: 0.0050\n",
      "Epoch 85/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0050 - mae: 0.0056 - val_loss: 0.0051 - val_mae: 0.0113\n",
      "Epoch 86/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0050 - mae: 0.0089 - val_loss: 0.0049 - val_mae: 0.0055\n",
      "Epoch 87/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0049 - mae: 0.0072 - val_loss: 0.0049 - val_mae: 0.0101\n",
      "Epoch 88/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0048 - mae: 0.0075 - val_loss: 0.0047 - val_mae: 0.0064\n",
      "Epoch 89/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0047 - mae: 0.0060 - val_loss: 0.0046 - val_mae: 0.0051\n",
      "Epoch 90/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0046 - mae: 0.0065 - val_loss: 0.0046 - val_mae: 0.0047\n",
      "Epoch 91/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0046 - mae: 0.0085 - val_loss: 0.0045 - val_mae: 0.0058\n",
      "Epoch 92/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0045 - mae: 0.0060 - val_loss: 0.0046 - val_mae: 0.0107\n",
      "Epoch 93/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0045 - mae: 0.0072 - val_loss: 0.0044 - val_mae: 0.0041\n",
      "Epoch 94/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0044 - mae: 0.0059 - val_loss: 0.0043 - val_mae: 0.0050\n",
      "Epoch 95/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0043 - mae: 0.0067 - val_loss: 0.0043 - val_mae: 0.0064\n",
      "Epoch 96/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0043 - mae: 0.0068 - val_loss: 0.0042 - val_mae: 0.0071\n",
      "Epoch 97/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0042 - mae: 0.0067 - val_loss: 0.0042 - val_mae: 0.0069\n",
      "Epoch 98/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0042 - mae: 0.0078 - val_loss: 0.0041 - val_mae: 0.0052\n",
      "Epoch 99/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0041 - mae: 0.0059 - val_loss: 0.0040 - val_mae: 0.0054\n",
      "Epoch 100/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0041 - mae: 0.0078 - val_loss: 0.0041 - val_mae: 0.0100\n",
      "Epoch 101/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0040 - mae: 0.0054 - val_loss: 0.0039 - val_mae: 0.0046\n",
      "Epoch 102/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0039 - mae: 0.0063 - val_loss: 0.0038 - val_mae: 0.0034\n",
      "Epoch 103/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0039 - mae: 0.0057 - val_loss: 0.0038 - val_mae: 0.0052\n",
      "Epoch 104/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0038 - mae: 0.0066 - val_loss: 0.0038 - val_mae: 0.0074\n",
      "Epoch 105/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0037 - mae: 0.0060 - val_loss: 0.0037 - val_mae: 0.0066\n",
      "Epoch 106/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0037 - mae: 0.0070 - val_loss: 0.0038 - val_mae: 0.0095\n",
      "Epoch 107/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0075 - val_loss: 0.0041 - val_mae: 0.0168\n",
      "Epoch 108/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0062 - val_loss: 0.0035 - val_mae: 0.0043\n",
      "Epoch 109/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0035 - mae: 0.0057 - val_loss: 0.0035 - val_mae: 0.0052\n",
      "Epoch 110/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0035 - mae: 0.0063 - val_loss: 0.0034 - val_mae: 0.0039\n",
      "Epoch 111/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0034 - mae: 0.0046 - val_loss: 0.0035 - val_mae: 0.0081\n",
      "Epoch 112/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0034 - mae: 0.0061 - val_loss: 0.0034 - val_mae: 0.0084\n",
      "Epoch 113/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0034 - mae: 0.0064 - val_loss: 0.0033 - val_mae: 0.0038\n",
      "Epoch 114/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0033 - mae: 0.0061 - val_loss: 0.0033 - val_mae: 0.0046\n",
      "Epoch 115/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0033 - mae: 0.0059 - val_loss: 0.0033 - val_mae: 0.0072\n",
      "Epoch 116/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0032 - mae: 0.0052 - val_loss: 0.0032 - val_mae: 0.0039\n",
      "Epoch 117/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0032 - mae: 0.0061 - val_loss: 0.0034 - val_mae: 0.0139\n",
      "Epoch 118/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0031 - mae: 0.0061 - val_loss: 0.0031 - val_mae: 0.0051\n",
      "Epoch 119/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0031 - mae: 0.0047 - val_loss: 0.0031 - val_mae: 0.0067\n",
      "Epoch 120/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0031 - mae: 0.0060 - val_loss: 0.0031 - val_mae: 0.0111\n",
      "Epoch 121/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0030 - mae: 0.0056 - val_loss: 0.0029 - val_mae: 0.0037\n",
      "Epoch 122/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0029 - mae: 0.0049 - val_loss: 0.0030 - val_mae: 0.0088\n",
      "Epoch 123/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0029 - mae: 0.0066 - val_loss: 0.0029 - val_mae: 0.0055\n",
      "Epoch 124/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0029 - mae: 0.0049 - val_loss: 0.0028 - val_mae: 0.0039\n",
      "Epoch 125/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0028 - mae: 0.0054 - val_loss: 0.0028 - val_mae: 0.0048\n",
      "Epoch 126/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0028 - mae: 0.0056 - val_loss: 0.0028 - val_mae: 0.0064\n",
      "Epoch 127/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0028 - mae: 0.0062 - val_loss: 0.0028 - val_mae: 0.0075\n",
      "Epoch 128/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0027 - mae: 0.0057 - val_loss: 0.0027 - val_mae: 0.0038\n",
      "Epoch 129/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0027 - mae: 0.0045 - val_loss: 0.0028 - val_mae: 0.0087\n",
      "Epoch 130/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0027 - mae: 0.0055 - val_loss: 0.0026 - val_mae: 0.0037\n",
      "Epoch 131/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0026 - mae: 0.0048 - val_loss: 0.0026 - val_mae: 0.0044\n",
      "Epoch 132/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0026 - mae: 0.0060 - val_loss: 0.0025 - val_mae: 0.0037\n",
      "Epoch 133/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0025 - mae: 0.0045 - val_loss: 0.0025 - val_mae: 0.0037\n",
      "Epoch 134/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0025 - mae: 0.0049 - val_loss: 0.0025 - val_mae: 0.0044\n",
      "Epoch 135/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0025 - mae: 0.0050 - val_loss: 0.0025 - val_mae: 0.0066\n",
      "Epoch 136/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0024 - mae: 0.0052 - val_loss: 0.0025 - val_mae: 0.0089\n",
      "Epoch 137/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0024 - mae: 0.0050 - val_loss: 0.0024 - val_mae: 0.0047\n",
      "Epoch 138/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0024 - mae: 0.0048 - val_loss: 0.0023 - val_mae: 0.0037\n",
      "Epoch 139/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0023 - mae: 0.0052 - val_loss: 0.0024 - val_mae: 0.0087\n",
      "Epoch 140/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0023 - mae: 0.0056 - val_loss: 0.0023 - val_mae: 0.0033\n",
      "Epoch 141/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0023 - mae: 0.0045 - val_loss: 0.0022 - val_mae: 0.0036\n",
      "Epoch 142/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0023 - mae: 0.0050 - val_loss: 0.0022 - val_mae: 0.0034\n",
      "Epoch 143/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0022 - mae: 0.0045 - val_loss: 0.0022 - val_mae: 0.0046\n",
      "Epoch 144/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0022 - mae: 0.0047 - val_loss: 0.0022 - val_mae: 0.0040\n",
      "Epoch 145/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0022 - mae: 0.0063 - val_loss: 0.0021 - val_mae: 0.0038\n",
      "Epoch 146/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0021 - mae: 0.0054 - val_loss: 0.0022 - val_mae: 0.0075\n",
      "Epoch 147/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0021 - mae: 0.0042 - val_loss: 0.0021 - val_mae: 0.0039\n",
      "Epoch 148/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0021 - mae: 0.0046 - val_loss: 0.0020 - val_mae: 0.0035\n",
      "Epoch 149/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0021 - mae: 0.0047 - val_loss: 0.0020 - val_mae: 0.0041\n",
      "Epoch 150/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0021 - mae: 0.0060 - val_loss: 0.0020 - val_mae: 0.0048\n",
      "Epoch 151/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0042 - val_loss: 0.0020 - val_mae: 0.0038\n",
      "Epoch 152/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0041 - val_loss: 0.0020 - val_mae: 0.0053\n",
      "Epoch 153/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0047 - val_loss: 0.0019 - val_mae: 0.0029\n",
      "Epoch 154/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0052 - val_loss: 0.0019 - val_mae: 0.0061\n",
      "Epoch 155/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0048 - val_loss: 0.0019 - val_mae: 0.0041\n",
      "Epoch 156/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0043 - val_loss: 0.0019 - val_mae: 0.0041\n",
      "Epoch 157/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0061 - val_loss: 0.0020 - val_mae: 0.0114\n",
      "Epoch 158/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0018 - mae: 0.0046 - val_loss: 0.0018 - val_mae: 0.0037\n",
      "Epoch 159/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0018 - mae: 0.0039 - val_loss: 0.0018 - val_mae: 0.0037\n",
      "Epoch 160/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0018 - mae: 0.0051 - val_loss: 0.0018 - val_mae: 0.0036\n",
      "Epoch 161/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0018 - mae: 0.0048 - val_loss: 0.0017 - val_mae: 0.0033\n",
      "Epoch 162/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0044 - val_loss: 0.0018 - val_mae: 0.0069\n",
      "Epoch 163/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0018 - mae: 0.0062 - val_loss: 0.0018 - val_mae: 0.0078\n",
      "Epoch 164/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0034 - val_loss: 0.0017 - val_mae: 0.0058\n",
      "Epoch 165/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0041 - val_loss: 0.0017 - val_mae: 0.0047\n",
      "Epoch 166/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0046 - val_loss: 0.0017 - val_mae: 0.0069\n",
      "Epoch 167/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0041 - val_loss: 0.0017 - val_mae: 0.0052\n",
      "Epoch 168/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0052 - val_loss: 0.0017 - val_mae: 0.0064\n",
      "Epoch 169/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0053 - val_loss: 0.0016 - val_mae: 0.0039\n",
      "Epoch 170/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0039 - val_loss: 0.0016 - val_mae: 0.0075\n",
      "Epoch 171/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0037\n",
      "Epoch 172/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0041 - val_loss: 0.0016 - val_mae: 0.0060\n",
      "Epoch 173/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0037 - val_loss: 0.0015 - val_mae: 0.0032\n",
      "Epoch 174/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0035\n",
      "Epoch 175/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0047 - val_loss: 0.0016 - val_mae: 0.0084\n",
      "Epoch 176/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0049\n",
      "Epoch 177/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0032\n",
      "Epoch 178/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0044\n",
      "Epoch 179/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0048 - val_loss: 0.0014 - val_mae: 0.0067\n",
      "Epoch 180/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0027\n",
      "Epoch 181/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0058\n",
      "Epoch 182/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0052\n",
      "Epoch 183/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0037 - val_loss: 0.0014 - val_mae: 0.0053\n",
      "Epoch 184/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0035\n",
      "Epoch 185/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0040 - val_loss: 0.0013 - val_mae: 0.0054\n",
      "Epoch 186/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0040 - val_loss: 0.0013 - val_mae: 0.0038\n",
      "Epoch 187/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0013 - mae: 0.0041 - val_loss: 0.0013 - val_mae: 0.0037\n",
      "Epoch 188/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0051 - val_loss: 0.0013 - val_mae: 0.0053\n",
      "Epoch 189/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0039 - val_loss: 0.0013 - val_mae: 0.0062\n",
      "Epoch 190/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0042 - val_loss: 0.0012 - val_mae: 0.0033\n",
      "Epoch 191/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0034\n",
      "Epoch 192/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0051 - val_loss: 0.0012 - val_mae: 0.0032\n",
      "Epoch 193/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0031 - val_loss: 0.0012 - val_mae: 0.0043\n",
      "Epoch 194/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0038 - val_loss: 0.0012 - val_mae: 0.0031\n",
      "Epoch 195/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0041 - val_loss: 0.0012 - val_mae: 0.0032\n",
      "Epoch 196/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0041 - val_loss: 0.0012 - val_mae: 0.0069\n",
      "Epoch 197/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0038 - val_loss: 0.0012 - val_mae: 0.0054\n",
      "Epoch 198/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0044 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 199/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0040 - val_loss: 0.0011 - val_mae: 0.0034\n",
      "Epoch 200/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0050 - val_loss: 0.0012 - val_mae: 0.0063\n",
      "Epoch 201/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0042\n",
      "Epoch 202/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0040 - val_loss: 0.0011 - val_mae: 0.0038\n",
      "Epoch 203/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0024\n",
      "Epoch 204/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0036 - val_loss: 0.0011 - val_mae: 0.0046\n",
      "Epoch 205/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0045 - val_loss: 0.0011 - val_mae: 0.0041\n",
      "Epoch 206/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0038 - val_loss: 0.0010 - val_mae: 0.0038\n",
      "Epoch 207/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0037 - val_loss: 0.0010 - val_mae: 0.0042\n",
      "Epoch 208/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0041 - val_loss: 0.0010 - val_mae: 0.0029\n",
      "Epoch 209/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0045 - val_loss: 0.0010 - val_mae: 0.0057\n",
      "Epoch 210/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0039 - val_loss: 0.0010 - val_mae: 0.0058\n",
      "Epoch 211/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 9.9409e-04 - mae: 0.0041 - val_loss: 9.7680e-04 - val_mae: 0.0030\n",
      "Epoch 212/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 9.9645e-04 - mae: 0.0047 - val_loss: 9.8784e-04 - val_mae: 0.0053\n",
      "Epoch 213/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 9.6915e-04 - mae: 0.0036 - val_loss: 9.5841e-04 - val_mae: 0.0033\n",
      "Epoch 214/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 9.6424e-04 - mae: 0.0040 - val_loss: 0.0010 - val_mae: 0.0073\n",
      "Epoch 215/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 9.4627e-04 - mae: 0.0034 - val_loss: 9.4188e-04 - val_mae: 0.0037\n",
      "Epoch 216/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 9.4876e-04 - mae: 0.0043 - val_loss: 9.2406e-04 - val_mae: 0.0028\n",
      "Epoch 217/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 9.2970e-04 - mae: 0.0037 - val_loss: 9.1224e-04 - val_mae: 0.0024\n",
      "Epoch 218/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 9.4092e-04 - mae: 0.0049 - val_loss: 9.2867e-04 - val_mae: 0.0045\n",
      "Epoch 219/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 9.1359e-04 - mae: 0.0037 - val_loss: 9.1733e-04 - val_mae: 0.0042\n",
      "Epoch 220/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 9.0075e-04 - mae: 0.0036 - val_loss: 8.9888e-04 - val_mae: 0.0037\n",
      "Epoch 221/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 9.0418e-04 - mae: 0.0044 - val_loss: 9.0884e-04 - val_mae: 0.0056\n",
      "Epoch 222/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 9.0435e-04 - mae: 0.0047 - val_loss: 8.7310e-04 - val_mae: 0.0029\n",
      "Epoch 223/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.7740e-04 - mae: 0.0036 - val_loss: 8.8022e-04 - val_mae: 0.0041\n",
      "Epoch 224/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.7014e-04 - mae: 0.0037 - val_loss: 8.6215e-04 - val_mae: 0.0036\n",
      "Epoch 225/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.6100e-04 - mae: 0.0036 - val_loss: 8.4581e-04 - val_mae: 0.0027\n",
      "Epoch 226/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.5763e-04 - mae: 0.0040 - val_loss: 8.4444e-04 - val_mae: 0.0033\n",
      "Epoch 227/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.4486e-04 - mae: 0.0038 - val_loss: 8.3096e-04 - val_mae: 0.0028\n",
      "Epoch 228/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.4410e-04 - mae: 0.0043 - val_loss: 8.4819e-04 - val_mae: 0.0051\n",
      "Epoch 229/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.2763e-04 - mae: 0.0037 - val_loss: 8.1491e-04 - val_mae: 0.0027\n",
      "Epoch 230/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.2617e-04 - mae: 0.0041 - val_loss: 8.1340e-04 - val_mae: 0.0037\n",
      "Epoch 231/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.1109e-04 - mae: 0.0036 - val_loss: 7.9559e-04 - val_mae: 0.0025\n",
      "Epoch 232/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.0619e-04 - mae: 0.0039 - val_loss: 8.1795e-04 - val_mae: 0.0054\n",
      "Epoch 233/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.9373e-04 - mae: 0.0036 - val_loss: 7.9316e-04 - val_mae: 0.0036\n",
      "Epoch 234/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.9534e-04 - mae: 0.0041 - val_loss: 7.9700e-04 - val_mae: 0.0052\n",
      "Epoch 235/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.8113e-04 - mae: 0.0038 - val_loss: 7.7574e-04 - val_mae: 0.0034\n",
      "Epoch 236/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.8094e-04 - mae: 0.0041 - val_loss: 7.6360e-04 - val_mae: 0.0030\n",
      "Epoch 237/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.6407e-04 - mae: 0.0036 - val_loss: 7.6067e-04 - val_mae: 0.0036\n",
      "Epoch 238/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.6553e-04 - mae: 0.0041 - val_loss: 7.5329e-04 - val_mae: 0.0036\n",
      "Epoch 239/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.5099e-04 - mae: 0.0037 - val_loss: 7.4587e-04 - val_mae: 0.0036\n",
      "Epoch 240/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.4455e-04 - mae: 0.0037 - val_loss: 7.3367e-04 - val_mae: 0.0033\n",
      "Epoch 241/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.4015e-04 - mae: 0.0039 - val_loss: 7.2735e-04 - val_mae: 0.0031\n",
      "Epoch 242/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.3885e-04 - mae: 0.0043 - val_loss: 7.2394e-04 - val_mae: 0.0033\n",
      "Epoch 243/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.2510e-04 - mae: 0.0037 - val_loss: 7.0875e-04 - val_mae: 0.0026\n",
      "Epoch 244/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.2024e-04 - mae: 0.0040 - val_loss: 7.0673e-04 - val_mae: 0.0030\n",
      "Epoch 245/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.0836e-04 - mae: 0.0034 - val_loss: 7.1497e-04 - val_mae: 0.0039\n",
      "Epoch 246/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.1071e-04 - mae: 0.0040 - val_loss: 6.9935e-04 - val_mae: 0.0037\n",
      "Epoch 247/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.9837e-04 - mae: 0.0037 - val_loss: 6.9592e-04 - val_mae: 0.0042\n",
      "Epoch 248/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.8953e-04 - mae: 0.0034 - val_loss: 6.9562e-04 - val_mae: 0.0041\n",
      "Epoch 249/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.8818e-04 - mae: 0.0038 - val_loss: 6.8389e-04 - val_mae: 0.0041\n",
      "Epoch 250/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.8013e-04 - mae: 0.0038 - val_loss: 6.8069e-04 - val_mae: 0.0046\n",
      "Epoch 251/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.8274e-04 - mae: 0.0042 - val_loss: 6.6166e-04 - val_mae: 0.0025\n",
      "Epoch 252/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.7603e-04 - mae: 0.0042 - val_loss: 6.6648e-04 - val_mae: 0.0034\n",
      "Epoch 253/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.5871e-04 - mae: 0.0034 - val_loss: 6.5649e-04 - val_mae: 0.0037\n",
      "Epoch 254/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.6552e-04 - mae: 0.0040 - val_loss: 6.4051e-04 - val_mae: 0.0024\n",
      "Epoch 255/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.4777e-04 - mae: 0.0034 - val_loss: 6.4529e-04 - val_mae: 0.0036\n",
      "Epoch 256/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.4918e-04 - mae: 0.0037 - val_loss: 6.2916e-04 - val_mae: 0.0024\n",
      "Epoch 257/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.4143e-04 - mae: 0.0038 - val_loss: 6.3693e-04 - val_mae: 0.0032\n",
      "Epoch 258/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.3465e-04 - mae: 0.0036 - val_loss: 6.8820e-04 - val_mae: 0.0073\n",
      "Epoch 259/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.3237e-04 - mae: 0.0038 - val_loss: 6.1388e-04 - val_mae: 0.0022\n",
      "Epoch 260/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.1948e-04 - mae: 0.0033 - val_loss: 6.0802e-04 - val_mae: 0.0025\n",
      "Epoch 261/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.1643e-04 - mae: 0.0034 - val_loss: 6.0519e-04 - val_mae: 0.0025\n",
      "Epoch 262/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.1440e-04 - mae: 0.0036 - val_loss: 6.1472e-04 - val_mae: 0.0037\n",
      "Epoch 263/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.0566e-04 - mae: 0.0035 - val_loss: 5.9199e-04 - val_mae: 0.0024\n",
      "Epoch 264/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.9943e-04 - mae: 0.0035 - val_loss: 5.9088e-04 - val_mae: 0.0031\n",
      "Epoch 265/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.9580e-04 - mae: 0.0035 - val_loss: 6.0453e-04 - val_mae: 0.0043\n",
      "Epoch 266/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.8858e-04 - mae: 0.0034 - val_loss: 5.8727e-04 - val_mae: 0.0040\n",
      "Epoch 267/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 5.8896e-04 - mae: 0.0039 - val_loss: 5.7987e-04 - val_mae: 0.0030\n",
      "Epoch 268/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.8657e-04 - mae: 0.0040 - val_loss: 5.8558e-04 - val_mae: 0.0042\n",
      "Epoch 269/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.7160e-04 - mae: 0.0032 - val_loss: 5.8831e-04 - val_mae: 0.0042\n",
      "Epoch 270/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.7248e-04 - mae: 0.0037 - val_loss: 5.6251e-04 - val_mae: 0.0029\n",
      "Epoch 271/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.7825e-04 - mae: 0.0043 - val_loss: 5.7257e-04 - val_mae: 0.0042\n",
      "Epoch 272/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.5971e-04 - mae: 0.0034 - val_loss: 5.5219e-04 - val_mae: 0.0029\n",
      "Epoch 273/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.6137e-04 - mae: 0.0038 - val_loss: 5.6505e-04 - val_mae: 0.0046\n",
      "Epoch 274/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.4814e-04 - mae: 0.0032 - val_loss: 5.5187e-04 - val_mae: 0.0033\n",
      "Epoch 275/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.4514e-04 - mae: 0.0033 - val_loss: 5.3712e-04 - val_mae: 0.0028\n",
      "Epoch 276/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.3901e-04 - mae: 0.0032 - val_loss: 5.5729e-04 - val_mae: 0.0045\n",
      "Epoch 277/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.3950e-04 - mae: 0.0036 - val_loss: 5.3005e-04 - val_mae: 0.0029\n",
      "Epoch 278/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.3826e-04 - mae: 0.0039 - val_loss: 5.2416e-04 - val_mae: 0.0029\n",
      "Epoch 279/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.2942e-04 - mae: 0.0034 - val_loss: 5.1691e-04 - val_mae: 0.0026\n",
      "Epoch 280/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.1984e-04 - mae: 0.0030 - val_loss: 5.2646e-04 - val_mae: 0.0040\n",
      "Epoch 281/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.2288e-04 - mae: 0.0036 - val_loss: 5.0566e-04 - val_mae: 0.0022\n",
      "Epoch 282/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.2065e-04 - mae: 0.0038 - val_loss: 5.1378e-04 - val_mae: 0.0035\n",
      "Epoch 283/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.0829e-04 - mae: 0.0032 - val_loss: 5.0368e-04 - val_mae: 0.0030\n",
      "Epoch 284/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.0783e-04 - mae: 0.0035 - val_loss: 5.2414e-04 - val_mae: 0.0047\n",
      "Epoch 285/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.1009e-04 - mae: 0.0038 - val_loss: 5.0547e-04 - val_mae: 0.0038\n",
      "Epoch 286/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.9697e-04 - mae: 0.0033 - val_loss: 5.0393e-04 - val_mae: 0.0042\n",
      "Epoch 287/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.0308e-04 - mae: 0.0039 - val_loss: 4.8197e-04 - val_mae: 0.0023\n",
      "Epoch 288/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.9093e-04 - mae: 0.0033 - val_loss: 5.0445e-04 - val_mae: 0.0044\n",
      "Epoch 289/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.8920e-04 - mae: 0.0035 - val_loss: 4.7826e-04 - val_mae: 0.0024\n",
      "Epoch 290/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.8104e-04 - mae: 0.0032 - val_loss: 4.7778e-04 - val_mae: 0.0027\n",
      "Epoch 291/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.7650e-04 - mae: 0.0031 - val_loss: 4.7905e-04 - val_mae: 0.0037\n",
      "Epoch 292/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.7804e-04 - mae: 0.0035 - val_loss: 4.6918e-04 - val_mae: 0.0028\n",
      "Epoch 293/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.7368e-04 - mae: 0.0035 - val_loss: 4.7390e-04 - val_mae: 0.0039\n",
      "Epoch 294/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.6921e-04 - mae: 0.0035 - val_loss: 4.7408e-04 - val_mae: 0.0036\n",
      "Epoch 295/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.7900e-04 - mae: 0.0040 - val_loss: 4.5689e-04 - val_mae: 0.0028\n",
      "Epoch 296/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.6079e-04 - mae: 0.0033 - val_loss: 4.5144e-04 - val_mae: 0.0027\n",
      "Epoch 297/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.5644e-04 - mae: 0.0032 - val_loss: 4.7134e-04 - val_mae: 0.0045\n",
      "Epoch 298/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.5053e-04 - mae: 0.0030 - val_loss: 4.4948e-04 - val_mae: 0.0034\n",
      "Epoch 299/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.4958e-04 - mae: 0.0032 - val_loss: 4.5327e-04 - val_mae: 0.0036\n",
      "Epoch 300/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.5819e-04 - mae: 0.0041 - val_loss: 4.4526e-04 - val_mae: 0.0033\n",
      "Epoch 301/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.5310e-04 - mae: 0.0038 - val_loss: 4.4816e-04 - val_mae: 0.0041\n",
      "Epoch 302/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.4276e-04 - mae: 0.0034 - val_loss: 4.3912e-04 - val_mae: 0.0034\n",
      "Epoch 303/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.3700e-04 - mae: 0.0032 - val_loss: 4.2722e-04 - val_mae: 0.0024\n",
      "Epoch 304/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.3378e-04 - mae: 0.0033 - val_loss: 4.4405e-04 - val_mae: 0.0036\n",
      "Epoch 305/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 4.2832e-04 - mae: 0.0031 - val_loss: 4.6028e-04 - val_mae: 0.0047\n",
      "Epoch 306/1000\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 4.2797e-04 - mae: 0.0033 - val_loss: 4.2046e-04 - val_mae: 0.0026\n",
      "Epoch 307/1000\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 4.2714e-04 - mae: 0.0035 - val_loss: 4.2773e-04 - val_mae: 0.0040\n",
      "Epoch 308/1000\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 4.2328e-04 - mae: 0.0034 - val_loss: 4.1245e-04 - val_mae: 0.0026\n",
      "Epoch 309/1000\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 4.2148e-04 - mae: 0.0035 - val_loss: 4.1314e-04 - val_mae: 0.0030\n",
      "Epoch 310/1000\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 4.1447e-04 - mae: 0.0032 - val_loss: 4.0468e-04 - val_mae: 0.0023\n",
      "Epoch 311/1000\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 4.1126e-04 - mae: 0.0032 - val_loss: 4.0921e-04 - val_mae: 0.0032\n",
      "Epoch 312/1000\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 4.0782e-04 - mae: 0.0031 - val_loss: 4.0898e-04 - val_mae: 0.0034\n",
      "Epoch 313/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 4.0539e-04 - mae: 0.0032 - val_loss: 4.0591e-04 - val_mae: 0.0036\n",
      "Epoch 314/1000\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 4.0900e-04 - mae: 0.0037 - val_loss: 3.9601e-04 - val_mae: 0.0025\n",
      "Epoch 315/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 4.0350e-04 - mae: 0.0035 - val_loss: 4.0597e-04 - val_mae: 0.0039\n",
      "Epoch 316/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 3.9892e-04 - mae: 0.0034 - val_loss: 3.8586e-04 - val_mae: 0.0021\n",
      "Epoch 317/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 3.9373e-04 - mae: 0.0032 - val_loss: 3.9102e-04 - val_mae: 0.0031\n",
      "Epoch 318/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 3.9170e-04 - mae: 0.0032 - val_loss: 4.1271e-04 - val_mae: 0.0056\n",
      "Epoch 319/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 3.8975e-04 - mae: 0.0033 - val_loss: 3.8149e-04 - val_mae: 0.0025\n",
      "Epoch 320/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 3.8618e-04 - mae: 0.0032 - val_loss: 3.8078e-04 - val_mae: 0.0031\n",
      "Epoch 321/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 3.8249e-04 - mae: 0.0031 - val_loss: 3.7313e-04 - val_mae: 0.0022\n",
      "Epoch 322/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.8686e-04 - mae: 0.0037 - val_loss: 3.8186e-04 - val_mae: 0.0035\n",
      "Epoch 323/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 3.7466e-04 - mae: 0.0029 - val_loss: 3.6994e-04 - val_mae: 0.0025\n",
      "Epoch 324/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.7597e-04 - mae: 0.0033 - val_loss: 3.7312e-04 - val_mae: 0.0032\n",
      "Epoch 325/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.7351e-04 - mae: 0.0032 - val_loss: 4.4367e-04 - val_mae: 0.0090\n",
      "Epoch 326/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.6880e-04 - mae: 0.0030 - val_loss: 3.7633e-04 - val_mae: 0.0040\n",
      "Epoch 327/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.6904e-04 - mae: 0.0033 - val_loss: 3.7040e-04 - val_mae: 0.0034\n",
      "Epoch 328/1000\n",
      "372/375 [============================>.] - ETA: 0s - loss: 3.7941e-04 - mae: 0.0041Restoring model weights from the end of the best epoch: 323.\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 3.8021e-04 - mae: 0.0041 - val_loss: 3.8170e-04 - val_mae: 0.0048\n",
      "Epoch 328: early stopping\n",
      "Training fÃ¼r Fold 2...\n",
      "Epoch 1/1000\n",
      "375/375 [==============================] - 4s 5ms/step - loss: 0.0846 - mae: 0.1600 - val_loss: 0.0360 - val_mae: 0.0900\n",
      "Epoch 2/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0319 - mae: 0.0796 - val_loss: 0.0275 - val_mae: 0.0812\n",
      "Epoch 3/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0238 - mae: 0.0569 - val_loss: 0.0201 - val_mae: 0.0409\n",
      "Epoch 4/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0200 - mae: 0.0429 - val_loss: 0.0179 - val_mae: 0.0306\n",
      "Epoch 5/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0178 - mae: 0.0301 - val_loss: 0.0173 - val_mae: 0.0273\n",
      "Epoch 6/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0172 - mae: 0.0289 - val_loss: 0.0172 - val_mae: 0.0340\n",
      "Epoch 7/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0164 - mae: 0.0217 - val_loss: 0.0161 - val_mae: 0.0200\n",
      "Epoch 8/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0160 - mae: 0.0202 - val_loss: 0.0157 - val_mae: 0.0170\n",
      "Epoch 9/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0161 - mae: 0.0238 - val_loss: 0.0156 - val_mae: 0.0198\n",
      "Epoch 10/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0155 - mae: 0.0179 - val_loss: 0.0157 - val_mae: 0.0218\n",
      "Epoch 11/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0156 - mae: 0.0215 - val_loss: 0.0155 - val_mae: 0.0230\n",
      "Epoch 12/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0152 - mae: 0.0190 - val_loss: 0.0147 - val_mae: 0.0105\n",
      "Epoch 13/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0152 - mae: 0.0211 - val_loss: 0.0155 - val_mae: 0.0287\n",
      "Epoch 14/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0152 - mae: 0.0238 - val_loss: 0.0143 - val_mae: 0.0120\n",
      "Epoch 15/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0145 - mae: 0.0158 - val_loss: 0.0166 - val_mae: 0.0429\n",
      "Epoch 16/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0144 - mae: 0.0164 - val_loss: 0.0139 - val_mae: 0.0096\n",
      "Epoch 17/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0142 - mae: 0.0173 - val_loss: 0.0138 - val_mae: 0.0113\n",
      "Epoch 18/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0138 - mae: 0.0141 - val_loss: 0.0138 - val_mae: 0.0163\n",
      "Epoch 19/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0140 - mae: 0.0194 - val_loss: 0.0135 - val_mae: 0.0143\n",
      "Epoch 20/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0137 - mae: 0.0170 - val_loss: 0.0136 - val_mae: 0.0195\n",
      "Epoch 21/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0135 - mae: 0.0177 - val_loss: 0.0131 - val_mae: 0.0126\n",
      "Epoch 22/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0132 - mae: 0.0166 - val_loss: 0.0136 - val_mae: 0.0251\n",
      "Epoch 23/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0137 - mae: 0.0231 - val_loss: 0.0136 - val_mae: 0.0254\n",
      "Epoch 24/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0128 - mae: 0.0141 - val_loss: 0.0124 - val_mae: 0.0093\n",
      "Epoch 25/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0125 - mae: 0.0129 - val_loss: 0.0125 - val_mae: 0.0148\n",
      "Epoch 26/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0124 - mae: 0.0145 - val_loss: 0.0121 - val_mae: 0.0108\n",
      "Epoch 27/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0122 - mae: 0.0147 - val_loss: 0.0123 - val_mae: 0.0199\n",
      "Epoch 28/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0122 - mae: 0.0163 - val_loss: 0.0118 - val_mae: 0.0120\n",
      "Epoch 29/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0118 - mae: 0.0121 - val_loss: 0.0121 - val_mae: 0.0192\n",
      "Epoch 30/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0116 - mae: 0.0130 - val_loss: 0.0115 - val_mae: 0.0129\n",
      "Epoch 31/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0115 - mae: 0.0141 - val_loss: 0.0113 - val_mae: 0.0118\n",
      "Epoch 32/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0113 - mae: 0.0144 - val_loss: 0.0110 - val_mae: 0.0094\n",
      "Epoch 33/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0110 - mae: 0.0112 - val_loss: 0.0113 - val_mae: 0.0161\n",
      "Epoch 34/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0110 - mae: 0.0134 - val_loss: 0.0116 - val_mae: 0.0257\n",
      "Epoch 35/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0110 - mae: 0.0160 - val_loss: 0.0105 - val_mae: 0.0093\n",
      "Epoch 36/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0105 - mae: 0.0109 - val_loss: 0.0103 - val_mae: 0.0095\n",
      "Epoch 37/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0103 - mae: 0.0104 - val_loss: 0.0102 - val_mae: 0.0091\n",
      "Epoch 38/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0103 - mae: 0.0129 - val_loss: 0.0102 - val_mae: 0.0127\n",
      "Epoch 39/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0101 - mae: 0.0131 - val_loss: 0.0098 - val_mae: 0.0081\n",
      "Epoch 40/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0099 - mae: 0.0108 - val_loss: 0.0096 - val_mae: 0.0076\n",
      "Epoch 41/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0098 - mae: 0.0124 - val_loss: 0.0096 - val_mae: 0.0121\n",
      "Epoch 42/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0097 - mae: 0.0131 - val_loss: 0.0093 - val_mae: 0.0067\n",
      "Epoch 43/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0093 - mae: 0.0092 - val_loss: 0.0092 - val_mae: 0.0074\n",
      "Epoch 44/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0094 - mae: 0.0141 - val_loss: 0.0091 - val_mae: 0.0080\n",
      "Epoch 45/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0091 - mae: 0.0107 - val_loss: 0.0089 - val_mae: 0.0087\n",
      "Epoch 46/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0089 - mae: 0.0092 - val_loss: 0.0089 - val_mae: 0.0134\n",
      "Epoch 47/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0090 - mae: 0.0139 - val_loss: 0.0087 - val_mae: 0.0091\n",
      "Epoch 48/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0087 - mae: 0.0120 - val_loss: 0.0091 - val_mae: 0.0201\n",
      "Epoch 49/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0085 - mae: 0.0100 - val_loss: 0.0084 - val_mae: 0.0088\n",
      "Epoch 50/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0083 - mae: 0.0081 - val_loss: 0.0083 - val_mae: 0.0089\n",
      "Epoch 51/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0084 - mae: 0.0120 - val_loss: 0.0081 - val_mae: 0.0087\n",
      "Epoch 52/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0081 - mae: 0.0094 - val_loss: 0.0080 - val_mae: 0.0097\n",
      "Epoch 53/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0081 - mae: 0.0120 - val_loss: 0.0079 - val_mae: 0.0085\n",
      "Epoch 54/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0078 - mae: 0.0085 - val_loss: 0.0081 - val_mae: 0.0147\n",
      "Epoch 55/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0078 - mae: 0.0098 - val_loss: 0.0076 - val_mae: 0.0069\n",
      "Epoch 56/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0078 - mae: 0.0123 - val_loss: 0.0075 - val_mae: 0.0077\n",
      "Epoch 57/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0075 - mae: 0.0077 - val_loss: 0.0075 - val_mae: 0.0108\n",
      "Epoch 58/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0074 - mae: 0.0087 - val_loss: 0.0072 - val_mae: 0.0054\n",
      "Epoch 59/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0072 - mae: 0.0069 - val_loss: 0.0071 - val_mae: 0.0063\n",
      "Epoch 60/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0072 - mae: 0.0091 - val_loss: 0.0072 - val_mae: 0.0140\n",
      "Epoch 61/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0072 - mae: 0.0126 - val_loss: 0.0070 - val_mae: 0.0091\n",
      "Epoch 62/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0069 - mae: 0.0082 - val_loss: 0.0068 - val_mae: 0.0073\n",
      "Epoch 63/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0069 - mae: 0.0098 - val_loss: 0.0070 - val_mae: 0.0153\n",
      "Epoch 64/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0067 - mae: 0.0077 - val_loss: 0.0066 - val_mae: 0.0083\n",
      "Epoch 65/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0066 - mae: 0.0076 - val_loss: 0.0065 - val_mae: 0.0080\n",
      "Epoch 66/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0065 - mae: 0.0090 - val_loss: 0.0064 - val_mae: 0.0072\n",
      "Epoch 67/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0065 - mae: 0.0109 - val_loss: 0.0065 - val_mae: 0.0142\n",
      "Epoch 68/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0063 - mae: 0.0074 - val_loss: 0.0062 - val_mae: 0.0063\n",
      "Epoch 69/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0062 - mae: 0.0082 - val_loss: 0.0061 - val_mae: 0.0065\n",
      "Epoch 70/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0061 - mae: 0.0079 - val_loss: 0.0060 - val_mae: 0.0049\n",
      "Epoch 71/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0060 - mae: 0.0077 - val_loss: 0.0059 - val_mae: 0.0067\n",
      "Epoch 72/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0059 - mae: 0.0064 - val_loss: 0.0059 - val_mae: 0.0083\n",
      "Epoch 73/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0060 - mae: 0.0105 - val_loss: 0.0059 - val_mae: 0.0101\n",
      "Epoch 74/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0058 - mae: 0.0079 - val_loss: 0.0057 - val_mae: 0.0063\n",
      "Epoch 75/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0057 - mae: 0.0072 - val_loss: 0.0056 - val_mae: 0.0090\n",
      "Epoch 76/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0056 - mae: 0.0081 - val_loss: 0.0057 - val_mae: 0.0143\n",
      "Epoch 77/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0055 - mae: 0.0069 - val_loss: 0.0056 - val_mae: 0.0109\n",
      "Epoch 78/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0054 - mae: 0.0075 - val_loss: 0.0054 - val_mae: 0.0081\n",
      "Epoch 79/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0054 - mae: 0.0093 - val_loss: 0.0053 - val_mae: 0.0066\n",
      "Epoch 80/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0053 - mae: 0.0070 - val_loss: 0.0052 - val_mae: 0.0038\n",
      "Epoch 81/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0052 - mae: 0.0075 - val_loss: 0.0055 - val_mae: 0.0145\n",
      "Epoch 82/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0051 - mae: 0.0077 - val_loss: 0.0051 - val_mae: 0.0063\n",
      "Epoch 83/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0051 - mae: 0.0085 - val_loss: 0.0050 - val_mae: 0.0074\n",
      "Epoch 84/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0049 - mae: 0.0063 - val_loss: 0.0049 - val_mae: 0.0048\n",
      "Epoch 85/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0049 - mae: 0.0061 - val_loss: 0.0048 - val_mae: 0.0062\n",
      "Epoch 86/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0050 - mae: 0.0097 - val_loss: 0.0047 - val_mae: 0.0050\n",
      "Epoch 87/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0047 - mae: 0.0065 - val_loss: 0.0047 - val_mae: 0.0046\n",
      "Epoch 88/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0047 - mae: 0.0059 - val_loss: 0.0047 - val_mae: 0.0087\n",
      "Epoch 89/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0046 - mae: 0.0074 - val_loss: 0.0045 - val_mae: 0.0050\n",
      "Epoch 90/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0046 - mae: 0.0076 - val_loss: 0.0045 - val_mae: 0.0068\n",
      "Epoch 91/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0045 - mae: 0.0075 - val_loss: 0.0045 - val_mae: 0.0087\n",
      "Epoch 92/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0044 - mae: 0.0066 - val_loss: 0.0045 - val_mae: 0.0096\n",
      "Epoch 93/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0044 - mae: 0.0077 - val_loss: 0.0044 - val_mae: 0.0084\n",
      "Epoch 94/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0043 - mae: 0.0066 - val_loss: 0.0043 - val_mae: 0.0087\n",
      "Epoch 95/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0043 - mae: 0.0067 - val_loss: 0.0042 - val_mae: 0.0051\n",
      "Epoch 96/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0042 - mae: 0.0075 - val_loss: 0.0042 - val_mae: 0.0067\n",
      "Epoch 97/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0041 - mae: 0.0061 - val_loss: 0.0041 - val_mae: 0.0077\n",
      "Epoch 98/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0041 - mae: 0.0062 - val_loss: 0.0042 - val_mae: 0.0111\n",
      "Epoch 99/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0041 - mae: 0.0078 - val_loss: 0.0040 - val_mae: 0.0092\n",
      "Epoch 100/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0040 - mae: 0.0080 - val_loss: 0.0040 - val_mae: 0.0072\n",
      "Epoch 101/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0039 - mae: 0.0060 - val_loss: 0.0038 - val_mae: 0.0038\n",
      "Epoch 102/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0038 - mae: 0.0055 - val_loss: 0.0039 - val_mae: 0.0086\n",
      "Epoch 103/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0038 - mae: 0.0064 - val_loss: 0.0037 - val_mae: 0.0044\n",
      "Epoch 104/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0037 - mae: 0.0053 - val_loss: 0.0037 - val_mae: 0.0051\n",
      "Epoch 105/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0037 - mae: 0.0064 - val_loss: 0.0037 - val_mae: 0.0086\n",
      "Epoch 106/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0036 - mae: 0.0055 - val_loss: 0.0039 - val_mae: 0.0146\n",
      "Epoch 107/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0037 - mae: 0.0087 - val_loss: 0.0035 - val_mae: 0.0038\n",
      "Epoch 108/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0035 - mae: 0.0054 - val_loss: 0.0035 - val_mae: 0.0043\n",
      "Epoch 109/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0035 - mae: 0.0062 - val_loss: 0.0034 - val_mae: 0.0046\n",
      "Epoch 110/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0034 - mae: 0.0044 - val_loss: 0.0034 - val_mae: 0.0033\n",
      "Epoch 111/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0034 - mae: 0.0059 - val_loss: 0.0033 - val_mae: 0.0046\n",
      "Epoch 112/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0033 - mae: 0.0056 - val_loss: 0.0034 - val_mae: 0.0072\n",
      "Epoch 113/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0033 - mae: 0.0059 - val_loss: 0.0033 - val_mae: 0.0068\n",
      "Epoch 114/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0033 - mae: 0.0061 - val_loss: 0.0034 - val_mae: 0.0131\n",
      "Epoch 115/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0032 - mae: 0.0064 - val_loss: 0.0033 - val_mae: 0.0098\n",
      "Epoch 116/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0032 - mae: 0.0060 - val_loss: 0.0031 - val_mae: 0.0034\n",
      "Epoch 117/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0031 - mae: 0.0058 - val_loss: 0.0031 - val_mae: 0.0040\n",
      "Epoch 118/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0031 - mae: 0.0077 - val_loss: 0.0031 - val_mae: 0.0068\n",
      "Epoch 119/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0030 - mae: 0.0049 - val_loss: 0.0030 - val_mae: 0.0032\n",
      "Epoch 120/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0030 - mae: 0.0068 - val_loss: 0.0030 - val_mae: 0.0080\n",
      "Epoch 121/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0030 - mae: 0.0055 - val_loss: 0.0029 - val_mae: 0.0035\n",
      "Epoch 122/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0029 - mae: 0.0048 - val_loss: 0.0029 - val_mae: 0.0044\n",
      "Epoch 123/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0029 - mae: 0.0057 - val_loss: 0.0028 - val_mae: 0.0047\n",
      "Epoch 124/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0028 - mae: 0.0047 - val_loss: 0.0028 - val_mae: 0.0056\n",
      "Epoch 125/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0028 - mae: 0.0067 - val_loss: 0.0028 - val_mae: 0.0057\n",
      "Epoch 126/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0027 - mae: 0.0045 - val_loss: 0.0027 - val_mae: 0.0040\n",
      "Epoch 127/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0027 - mae: 0.0056 - val_loss: 0.0029 - val_mae: 0.0100\n",
      "Epoch 128/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0027 - mae: 0.0050 - val_loss: 0.0026 - val_mae: 0.0042\n",
      "Epoch 129/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0026 - mae: 0.0048 - val_loss: 0.0026 - val_mae: 0.0037\n",
      "Epoch 130/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0026 - mae: 0.0058 - val_loss: 0.0026 - val_mae: 0.0039\n",
      "Epoch 131/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0026 - mae: 0.0061 - val_loss: 0.0025 - val_mae: 0.0041\n",
      "Epoch 132/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0025 - mae: 0.0046 - val_loss: 0.0027 - val_mae: 0.0111\n",
      "Epoch 133/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0025 - mae: 0.0055 - val_loss: 0.0026 - val_mae: 0.0079\n",
      "Epoch 134/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0025 - mae: 0.0042 - val_loss: 0.0025 - val_mae: 0.0072\n",
      "Epoch 135/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0025 - mae: 0.0056 - val_loss: 0.0025 - val_mae: 0.0063\n",
      "Epoch 136/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0025 - mae: 0.0069 - val_loss: 0.0024 - val_mae: 0.0045\n",
      "Epoch 137/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0024 - mae: 0.0048 - val_loss: 0.0024 - val_mae: 0.0051\n",
      "Epoch 138/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0045 - val_loss: 0.0023 - val_mae: 0.0047\n",
      "Epoch 139/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0057 - val_loss: 0.0025 - val_mae: 0.0124\n",
      "Epoch 140/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0051 - val_loss: 0.0023 - val_mae: 0.0033\n",
      "Epoch 141/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0023 - mae: 0.0053 - val_loss: 0.0022 - val_mae: 0.0046\n",
      "Epoch 142/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0022 - mae: 0.0041 - val_loss: 0.0022 - val_mae: 0.0034\n",
      "Epoch 143/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0052 - val_loss: 0.0022 - val_mae: 0.0045\n",
      "Epoch 144/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0022 - mae: 0.0058 - val_loss: 0.0022 - val_mae: 0.0054\n",
      "Epoch 145/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0022 - mae: 0.0052 - val_loss: 0.0021 - val_mae: 0.0044\n",
      "Epoch 146/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0021 - mae: 0.0049 - val_loss: 0.0021 - val_mae: 0.0053\n",
      "Epoch 147/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0021 - mae: 0.0047 - val_loss: 0.0021 - val_mae: 0.0043\n",
      "Epoch 148/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0021 - mae: 0.0059 - val_loss: 0.0023 - val_mae: 0.0123\n",
      "Epoch 149/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0021 - mae: 0.0045 - val_loss: 0.0020 - val_mae: 0.0038\n",
      "Epoch 150/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0046 - val_loss: 0.0020 - val_mae: 0.0055\n",
      "Epoch 151/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0020 - mae: 0.0054 - val_loss: 0.0020 - val_mae: 0.0029\n",
      "Epoch 152/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0038 - val_loss: 0.0019 - val_mae: 0.0030\n",
      "Epoch 153/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0050 - val_loss: 0.0020 - val_mae: 0.0060\n",
      "Epoch 154/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0045 - val_loss: 0.0019 - val_mae: 0.0034\n",
      "Epoch 155/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0052 - val_loss: 0.0019 - val_mae: 0.0031\n",
      "Epoch 156/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0044 - val_loss: 0.0019 - val_mae: 0.0047\n",
      "Epoch 157/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0048 - val_loss: 0.0018 - val_mae: 0.0028\n",
      "Epoch 158/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0018 - mae: 0.0045 - val_loss: 0.0018 - val_mae: 0.0036\n",
      "Epoch 159/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0018 - mae: 0.0041 - val_loss: 0.0018 - val_mae: 0.0037\n",
      "Epoch 160/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0018 - mae: 0.0054 - val_loss: 0.0020 - val_mae: 0.0114\n",
      "Epoch 161/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0018 - mae: 0.0053 - val_loss: 0.0017 - val_mae: 0.0035\n",
      "Epoch 162/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0038 - val_loss: 0.0017 - val_mae: 0.0047\n",
      "Epoch 163/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0046 - val_loss: 0.0017 - val_mae: 0.0036\n",
      "Epoch 164/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0017 - mae: 0.0044 - val_loss: 0.0017 - val_mae: 0.0046\n",
      "Epoch 165/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0017 - mae: 0.0057 - val_loss: 0.0017 - val_mae: 0.0037\n",
      "Epoch 166/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0040 - val_loss: 0.0017 - val_mae: 0.0048\n",
      "Epoch 167/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0051 - val_loss: 0.0017 - val_mae: 0.0063\n",
      "Epoch 168/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0043 - val_loss: 0.0016 - val_mae: 0.0047\n",
      "Epoch 169/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0037 - val_loss: 0.0016 - val_mae: 0.0030\n",
      "Epoch 170/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0016 - mae: 0.0040 - val_loss: 0.0016 - val_mae: 0.0034\n",
      "Epoch 171/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0046 - val_loss: 0.0016 - val_mae: 0.0040\n",
      "Epoch 172/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0047 - val_loss: 0.0015 - val_mae: 0.0033\n",
      "Epoch 173/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0027\n",
      "Epoch 174/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0040 - val_loss: 0.0015 - val_mae: 0.0039\n",
      "Epoch 175/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0039 - val_loss: 0.0015 - val_mae: 0.0060\n",
      "Epoch 176/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0048 - val_loss: 0.0015 - val_mae: 0.0051\n",
      "Epoch 177/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0032\n",
      "Epoch 178/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0014 - val_mae: 0.0042\n",
      "Epoch 179/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0038 - val_loss: 0.0014 - val_mae: 0.0053\n",
      "Epoch 180/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0027\n",
      "Epoch 181/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0041 - val_loss: 0.0014 - val_mae: 0.0059\n",
      "Epoch 182/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0049 - val_loss: 0.0014 - val_mae: 0.0031\n",
      "Epoch 183/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0036 - val_loss: 0.0014 - val_mae: 0.0050\n",
      "Epoch 184/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0040 - val_loss: 0.0013 - val_mae: 0.0035\n",
      "Epoch 185/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0038 - val_loss: 0.0013 - val_mae: 0.0033\n",
      "Epoch 186/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0013 - mae: 0.0041 - val_loss: 0.0013 - val_mae: 0.0041\n",
      "Epoch 187/1000\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0027\n",
      "Epoch 188/1000\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0051\n",
      "Epoch 189/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0038\n",
      "Epoch 190/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0030\n",
      "Epoch 191/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0012 - mae: 0.0039 - val_loss: 0.0012 - val_mae: 0.0034\n",
      "Epoch 192/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0012 - mae: 0.0039 - val_loss: 0.0012 - val_mae: 0.0031\n",
      "Epoch 193/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0012 - mae: 0.0036 - val_loss: 0.0012 - val_mae: 0.0021\n",
      "Epoch 194/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0049 - val_loss: 0.0012 - val_mae: 0.0028\n",
      "Epoch 195/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0041 - val_loss: 0.0012 - val_mae: 0.0031\n",
      "Epoch 196/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0039 - val_loss: 0.0012 - val_mae: 0.0034\n",
      "Epoch 197/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0012 - mae: 0.0047 - val_loss: 0.0011 - val_mae: 0.0025\n",
      "Epoch 198/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0037 - val_loss: 0.0011 - val_mae: 0.0026\n",
      "Epoch 199/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0041\n",
      "Epoch 200/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0036 - val_loss: 0.0011 - val_mae: 0.0039\n",
      "Epoch 201/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0038 - val_loss: 0.0011 - val_mae: 0.0031\n",
      "Epoch 202/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0040 - val_loss: 0.0011 - val_mae: 0.0040\n",
      "Epoch 203/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0011 - mae: 0.0038 - val_loss: 0.0011 - val_mae: 0.0028\n",
      "Epoch 204/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0011 - mae: 0.0040 - val_loss: 0.0011 - val_mae: 0.0039\n",
      "Epoch 205/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0011 - mae: 0.0049 - val_loss: 0.0011 - val_mae: 0.0074\n",
      "Epoch 206/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0011 - mae: 0.0036 - val_loss: 0.0011 - val_mae: 0.0079\n",
      "Epoch 207/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0010 - mae: 0.0036 - val_loss: 0.0010 - val_mae: 0.0024\n",
      "Epoch 208/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0010 - mae: 0.0041 - val_loss: 0.0010 - val_mae: 0.0026\n",
      "Epoch 209/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0010 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0087\n",
      "Epoch 210/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0010 - mae: 0.0040 - val_loss: 9.9758e-04 - val_mae: 0.0030\n",
      "Epoch 211/1000\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0010 - mae: 0.0038 - val_loss: 9.8429e-04 - val_mae: 0.0025\n",
      "Epoch 212/1000\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 9.9090e-04 - mae: 0.0035 - val_loss: 9.7488e-04 - val_mae: 0.0028\n",
      "Epoch 213/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 9.8625e-04 - mae: 0.0040 - val_loss: 9.8087e-04 - val_mae: 0.0046\n",
      "Epoch 214/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 9.7219e-04 - mae: 0.0037 - val_loss: 9.5069e-04 - val_mae: 0.0023\n",
      "Epoch 215/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 9.6403e-04 - mae: 0.0039 - val_loss: 9.4602e-04 - val_mae: 0.0029\n",
      "Epoch 216/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 9.4728e-04 - mae: 0.0033 - val_loss: 9.4889e-04 - val_mae: 0.0044\n",
      "Epoch 217/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 9.3768e-04 - mae: 0.0035 - val_loss: 9.2596e-04 - val_mae: 0.0029\n",
      "Epoch 218/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 9.3949e-04 - mae: 0.0043 - val_loss: 9.1458e-04 - val_mae: 0.0029\n",
      "Epoch 219/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 9.2386e-04 - mae: 0.0038 - val_loss: 9.0799e-04 - val_mae: 0.0029\n",
      "Epoch 220/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 9.1980e-04 - mae: 0.0042 - val_loss: 9.1459e-04 - val_mae: 0.0042\n",
      "Epoch 221/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 9.1030e-04 - mae: 0.0042 - val_loss: 9.0410e-04 - val_mae: 0.0045\n",
      "Epoch 222/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.9519e-04 - mae: 0.0037 - val_loss: 9.0588e-04 - val_mae: 0.0048\n",
      "Epoch 223/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.8410e-04 - mae: 0.0035 - val_loss: 8.8232e-04 - val_mae: 0.0039\n",
      "Epoch 224/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.7432e-04 - mae: 0.0035 - val_loss: 8.7079e-04 - val_mae: 0.0039\n",
      "Epoch 225/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.7646e-04 - mae: 0.0043 - val_loss: 8.6231e-04 - val_mae: 0.0039\n",
      "Epoch 226/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.6197e-04 - mae: 0.0039 - val_loss: 8.5868e-04 - val_mae: 0.0043\n",
      "Epoch 227/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.5768e-04 - mae: 0.0041 - val_loss: 8.4179e-04 - val_mae: 0.0031\n",
      "Epoch 228/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.4007e-04 - mae: 0.0034 - val_loss: 8.4860e-04 - val_mae: 0.0045\n",
      "Epoch 229/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.3307e-04 - mae: 0.0036 - val_loss: 8.2036e-04 - val_mae: 0.0028\n",
      "Epoch 230/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.3266e-04 - mae: 0.0040 - val_loss: 8.1753e-04 - val_mae: 0.0033\n",
      "Epoch 231/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.3785e-04 - mae: 0.0047 - val_loss: 8.0502e-04 - val_mae: 0.0030\n",
      "Epoch 232/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.1291e-04 - mae: 0.0036 - val_loss: 8.1056e-04 - val_mae: 0.0039\n",
      "Epoch 233/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.9873e-04 - mae: 0.0032 - val_loss: 7.9568e-04 - val_mae: 0.0032\n",
      "Epoch 234/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.0151e-04 - mae: 0.0039 - val_loss: 7.9088e-04 - val_mae: 0.0038\n",
      "Epoch 235/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.9746e-04 - mae: 0.0042 - val_loss: 7.8839e-04 - val_mae: 0.0043\n",
      "Epoch 236/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.8481e-04 - mae: 0.0038 - val_loss: 7.6839e-04 - val_mae: 0.0029\n",
      "Epoch 237/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.7198e-04 - mae: 0.0033 - val_loss: 7.6508e-04 - val_mae: 0.0033\n",
      "Epoch 238/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.6534e-04 - mae: 0.0034 - val_loss: 7.7916e-04 - val_mae: 0.0046\n",
      "Epoch 239/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.7041e-04 - mae: 0.0042 - val_loss: 7.6173e-04 - val_mae: 0.0043\n",
      "Epoch 240/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.5461e-04 - mae: 0.0035 - val_loss: 7.3505e-04 - val_mae: 0.0021\n",
      "Epoch 241/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.5404e-04 - mae: 0.0038 - val_loss: 7.3213e-04 - val_mae: 0.0027\n",
      "Epoch 242/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.3958e-04 - mae: 0.0035 - val_loss: 7.4876e-04 - val_mae: 0.0053\n",
      "Epoch 243/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.3193e-04 - mae: 0.0033 - val_loss: 7.3742e-04 - val_mae: 0.0045\n",
      "Epoch 244/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.3406e-04 - mae: 0.0040 - val_loss: 7.3654e-04 - val_mae: 0.0047\n",
      "Epoch 245/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.1769e-04 - mae: 0.0033 - val_loss: 7.0754e-04 - val_mae: 0.0029\n",
      "Epoch 246/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.1016e-04 - mae: 0.0032 - val_loss: 7.0087e-04 - val_mae: 0.0029\n",
      "Epoch 247/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.1068e-04 - mae: 0.0038 - val_loss: 7.0010e-04 - val_mae: 0.0034\n",
      "Epoch 248/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.9843e-04 - mae: 0.0033 - val_loss: 7.7290e-04 - val_mae: 0.0074\n",
      "Epoch 249/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.0619e-04 - mae: 0.0043 - val_loss: 7.0232e-04 - val_mae: 0.0046\n",
      "Epoch 250/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.8964e-04 - mae: 0.0036 - val_loss: 6.7335e-04 - val_mae: 0.0026\n",
      "Epoch 251/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.9743e-04 - mae: 0.0042 - val_loss: 6.6865e-04 - val_mae: 0.0026\n",
      "Epoch 252/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 6.7325e-04 - mae: 0.0032 - val_loss: 6.7124e-04 - val_mae: 0.0036\n",
      "Epoch 253/1000\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 6.6698e-04 - mae: 0.0032 - val_loss: 6.5674e-04 - val_mae: 0.0027\n",
      "Epoch 254/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 6.7228e-04 - mae: 0.0041 - val_loss: 6.5421e-04 - val_mae: 0.0029\n",
      "Epoch 255/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.5643e-04 - mae: 0.0033 - val_loss: 6.4861e-04 - val_mae: 0.0030\n",
      "Epoch 256/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 6.5157e-04 - mae: 0.0034 - val_loss: 6.4129e-04 - val_mae: 0.0030\n",
      "Epoch 257/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 6.4716e-04 - mae: 0.0035 - val_loss: 6.3936e-04 - val_mae: 0.0031\n",
      "Epoch 258/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.4648e-04 - mae: 0.0039 - val_loss: 6.3249e-04 - val_mae: 0.0034\n",
      "Epoch 259/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.4692e-04 - mae: 0.0041 - val_loss: 6.2653e-04 - val_mae: 0.0031\n",
      "Epoch 260/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.3412e-04 - mae: 0.0036 - val_loss: 6.7479e-04 - val_mae: 0.0059\n",
      "Epoch 261/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.2341e-04 - mae: 0.0033 - val_loss: 6.1115e-04 - val_mae: 0.0026\n",
      "Epoch 262/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.1643e-04 - mae: 0.0032 - val_loss: 6.0731e-04 - val_mae: 0.0028\n",
      "Epoch 263/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.1532e-04 - mae: 0.0035 - val_loss: 5.9937e-04 - val_mae: 0.0023\n",
      "Epoch 264/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.0915e-04 - mae: 0.0035 - val_loss: 6.0849e-04 - val_mae: 0.0039\n",
      "Epoch 265/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 6.0384e-04 - mae: 0.0035 - val_loss: 5.9892e-04 - val_mae: 0.0033\n",
      "Epoch 266/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 5.9784e-04 - mae: 0.0033 - val_loss: 6.0681e-04 - val_mae: 0.0048\n",
      "Epoch 267/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 5.9972e-04 - mae: 0.0037 - val_loss: 5.7668e-04 - val_mae: 0.0020\n",
      "Epoch 268/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 5.8990e-04 - mae: 0.0035 - val_loss: 6.3818e-04 - val_mae: 0.0078\n",
      "Epoch 269/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 5.8586e-04 - mae: 0.0036 - val_loss: 5.6791e-04 - val_mae: 0.0022\n",
      "Epoch 270/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 5.8781e-04 - mae: 0.0039 - val_loss: 5.6856e-04 - val_mae: 0.0028\n",
      "Epoch 271/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 5.7902e-04 - mae: 0.0036 - val_loss: 5.5898e-04 - val_mae: 0.0023\n",
      "Epoch 272/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.7220e-04 - mae: 0.0035 - val_loss: 5.9257e-04 - val_mae: 0.0049\n",
      "Epoch 273/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.6444e-04 - mae: 0.0033 - val_loss: 5.5510e-04 - val_mae: 0.0029\n",
      "Epoch 274/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.5750e-04 - mae: 0.0032 - val_loss: 5.5155e-04 - val_mae: 0.0030\n",
      "Epoch 275/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 5.5713e-04 - mae: 0.0035 - val_loss: 5.7227e-04 - val_mae: 0.0044\n",
      "Epoch 276/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.5541e-04 - mae: 0.0036 - val_loss: 5.4479e-04 - val_mae: 0.0034\n",
      "Epoch 277/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.4862e-04 - mae: 0.0035 - val_loss: 5.5606e-04 - val_mae: 0.0047\n",
      "Epoch 278/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.4441e-04 - mae: 0.0035 - val_loss: 5.4484e-04 - val_mae: 0.0039\n",
      "Epoch 279/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.3822e-04 - mae: 0.0034 - val_loss: 5.2401e-04 - val_mae: 0.0022\n",
      "Epoch 280/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.3489e-04 - mae: 0.0034 - val_loss: 5.2772e-04 - val_mae: 0.0034\n",
      "Epoch 281/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.3537e-04 - mae: 0.0039 - val_loss: 5.2530e-04 - val_mae: 0.0033\n",
      "Epoch 282/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 5.2352e-04 - mae: 0.0032 - val_loss: 5.1353e-04 - val_mae: 0.0026\n",
      "Epoch 283/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.2594e-04 - mae: 0.0037 - val_loss: 5.1948e-04 - val_mae: 0.0033\n",
      "Epoch 284/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.1681e-04 - mae: 0.0033 - val_loss: 5.0373e-04 - val_mae: 0.0023\n",
      "Epoch 285/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.1342e-04 - mae: 0.0033 - val_loss: 5.4977e-04 - val_mae: 0.0054\n",
      "Epoch 286/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.0631e-04 - mae: 0.0030 - val_loss: 4.9773e-04 - val_mae: 0.0026\n",
      "Epoch 287/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 5.0464e-04 - mae: 0.0033 - val_loss: 4.9925e-04 - val_mae: 0.0030\n",
      "Epoch 288/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 5.0059e-04 - mae: 0.0033 - val_loss: 4.9188e-04 - val_mae: 0.0028\n",
      "Epoch 289/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.9578e-04 - mae: 0.0033 - val_loss: 5.2163e-04 - val_mae: 0.0060\n",
      "Epoch 290/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 4.9522e-04 - mae: 0.0035 - val_loss: 4.9165e-04 - val_mae: 0.0036\n",
      "Epoch 291/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.9545e-04 - mae: 0.0038 - val_loss: 4.8295e-04 - val_mae: 0.0032\n",
      "Epoch 292/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 4.8259e-04 - mae: 0.0031 - val_loss: 4.8349e-04 - val_mae: 0.0031\n",
      "Epoch 293/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.8698e-04 - mae: 0.0038 - val_loss: 4.7020e-04 - val_mae: 0.0023\n",
      "Epoch 294/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 4.7995e-04 - mae: 0.0035 - val_loss: 4.6508e-04 - val_mae: 0.0022\n",
      "Epoch 295/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.7582e-04 - mae: 0.0034 - val_loss: 4.7304e-04 - val_mae: 0.0037\n",
      "Epoch 296/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.6985e-04 - mae: 0.0033 - val_loss: 4.6058e-04 - val_mae: 0.0026\n",
      "Epoch 297/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 4.7335e-04 - mae: 0.0036 - val_loss: 4.6877e-04 - val_mae: 0.0036\n",
      "Epoch 298/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.6530e-04 - mae: 0.0034 - val_loss: 5.2345e-04 - val_mae: 0.0073\n",
      "Epoch 299/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.6721e-04 - mae: 0.0037 - val_loss: 4.4877e-04 - val_mae: 0.0023\n",
      "Epoch 300/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.7476e-04 - mae: 0.0042 - val_loss: 4.5155e-04 - val_mae: 0.0028\n",
      "Epoch 301/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 4.5426e-04 - mae: 0.0032 - val_loss: 4.4700e-04 - val_mae: 0.0028\n",
      "Epoch 302/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 4.5540e-04 - mae: 0.0034 - val_loss: 4.4730e-04 - val_mae: 0.0033\n",
      "Epoch 303/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.5382e-04 - mae: 0.0035 - val_loss: 4.4030e-04 - val_mae: 0.0028\n",
      "Epoch 304/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.4463e-04 - mae: 0.0031 - val_loss: 4.3839e-04 - val_mae: 0.0028\n",
      "Epoch 305/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.4224e-04 - mae: 0.0032 - val_loss: 4.5596e-04 - val_mae: 0.0053\n",
      "Epoch 306/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 4.3765e-04 - mae: 0.0030 - val_loss: 4.2683e-04 - val_mae: 0.0021\n",
      "Epoch 307/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.4886e-04 - mae: 0.0038 - val_loss: 4.2464e-04 - val_mae: 0.0023\n",
      "Epoch 308/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.2988e-04 - mae: 0.0029 - val_loss: 4.2627e-04 - val_mae: 0.0028\n",
      "Epoch 309/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.2821e-04 - mae: 0.0030 - val_loss: 4.3906e-04 - val_mae: 0.0041\n",
      "Epoch 310/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.2538e-04 - mae: 0.0031 - val_loss: 4.1654e-04 - val_mae: 0.0023\n",
      "Epoch 311/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.2968e-04 - mae: 0.0037 - val_loss: 4.1116e-04 - val_mae: 0.0020\n",
      "Epoch 312/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.2466e-04 - mae: 0.0036 - val_loss: 4.2395e-04 - val_mae: 0.0041\n",
      "Epoch 313/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.1819e-04 - mae: 0.0031 - val_loss: 4.0797e-04 - val_mae: 0.0024\n",
      "Epoch 314/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.1499e-04 - mae: 0.0032 - val_loss: 4.0819e-04 - val_mae: 0.0029\n",
      "Epoch 315/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 4.1691e-04 - mae: 0.0035 - val_loss: 4.0276e-04 - val_mae: 0.0025\n",
      "Epoch 316/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.0859e-04 - mae: 0.0031 - val_loss: 3.9694e-04 - val_mae: 0.0020\n",
      "Epoch 317/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 4.0616e-04 - mae: 0.0032 - val_loss: 4.0358e-04 - val_mae: 0.0032\n",
      "Epoch 318/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.0572e-04 - mae: 0.0033 - val_loss: 4.0372e-04 - val_mae: 0.0037\n",
      "Epoch 319/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.0565e-04 - mae: 0.0036 - val_loss: 3.9109e-04 - val_mae: 0.0024\n",
      "Epoch 320/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.0068e-04 - mae: 0.0033 - val_loss: 3.9343e-04 - val_mae: 0.0030\n",
      "Epoch 321/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.9421e-04 - mae: 0.0031 - val_loss: 3.8732e-04 - val_mae: 0.0026\n",
      "Epoch 322/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 3.9753e-04 - mae: 0.0035 - val_loss: 3.9837e-04 - val_mae: 0.0041\n",
      "Epoch 323/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.9154e-04 - mae: 0.0033 - val_loss: 3.8731e-04 - val_mae: 0.0031\n",
      "Epoch 324/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.9191e-04 - mae: 0.0035 - val_loss: 3.8177e-04 - val_mae: 0.0030\n",
      "Epoch 325/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 3.9283e-04 - mae: 0.0038 - val_loss: 3.7379e-04 - val_mae: 0.0021\n",
      "Epoch 326/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.7850e-04 - mae: 0.0028 - val_loss: 4.0177e-04 - val_mae: 0.0053\n",
      "Epoch 327/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.7829e-04 - mae: 0.0030 - val_loss: 3.7133e-04 - val_mae: 0.0025\n",
      "Epoch 328/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.7912e-04 - mae: 0.0032 - val_loss: 3.6666e-04 - val_mae: 0.0022\n",
      "Epoch 329/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.7559e-04 - mae: 0.0032 - val_loss: 3.7289e-04 - val_mae: 0.0033\n",
      "Epoch 330/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.7268e-04 - mae: 0.0031 - val_loss: 3.7417e-04 - val_mae: 0.0035\n",
      "Epoch 331/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.7309e-04 - mae: 0.0034 - val_loss: 3.6352e-04 - val_mae: 0.0029\n",
      "Epoch 332/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.6839e-04 - mae: 0.0032 - val_loss: 3.6148e-04 - val_mae: 0.0028\n",
      "Epoch 333/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 3.6439e-04 - mae: 0.0031 - val_loss: 3.7842e-04 - val_mae: 0.0044\n",
      "Epoch 334/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.6199e-04 - mae: 0.0030 - val_loss: 3.5923e-04 - val_mae: 0.0028\n",
      "Epoch 335/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.6186e-04 - mae: 0.0033 - val_loss: 3.5398e-04 - val_mae: 0.0027\n",
      "Epoch 336/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.6158e-04 - mae: 0.0034 - val_loss: 3.5089e-04 - val_mae: 0.0026\n",
      "Epoch 337/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.5284e-04 - mae: 0.0028 - val_loss: 3.5643e-04 - val_mae: 0.0035\n",
      "Epoch 338/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.5165e-04 - mae: 0.0029 - val_loss: 3.4172e-04 - val_mae: 0.0020\n",
      "Epoch 339/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.5338e-04 - mae: 0.0033 - val_loss: 3.5566e-04 - val_mae: 0.0041\n",
      "Epoch 340/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 3.5198e-04 - mae: 0.0034 - val_loss: 3.4187e-04 - val_mae: 0.0026\n",
      "Epoch 341/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.5374e-04 - mae: 0.0036 - val_loss: 3.4033e-04 - val_mae: 0.0026\n",
      "Epoch 342/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.4297e-04 - mae: 0.0030 - val_loss: 3.4048e-04 - val_mae: 0.0030\n",
      "Epoch 343/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 3.4705e-04 - mae: 0.0035 - val_loss: 3.4089e-04 - val_mae: 0.0031\n",
      "Epoch 344/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.3945e-04 - mae: 0.0030 - val_loss: 3.3273e-04 - val_mae: 0.0024\n",
      "Epoch 345/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 3.3847e-04 - mae: 0.0031 - val_loss: 3.3960e-04 - val_mae: 0.0037\n",
      "Epoch 346/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.3561e-04 - mae: 0.0030 - val_loss: 3.3287e-04 - val_mae: 0.0027\n",
      "Epoch 347/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.4089e-04 - mae: 0.0034 - val_loss: 3.6329e-04 - val_mae: 0.0058\n",
      "Epoch 348/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.2929e-04 - mae: 0.0028 - val_loss: 3.2996e-04 - val_mae: 0.0030\n",
      "Epoch 349/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 3.3249e-04 - mae: 0.0033 - val_loss: 3.4475e-04 - val_mae: 0.0045\n",
      "Epoch 350/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.3403e-04 - mae: 0.0035 - val_loss: 3.3006e-04 - val_mae: 0.0032\n",
      "Epoch 351/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 3.2459e-04 - mae: 0.0029 - val_loss: 3.1745e-04 - val_mae: 0.0022\n",
      "Epoch 352/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.2315e-04 - mae: 0.0029 - val_loss: 3.1457e-04 - val_mae: 0.0021\n",
      "Epoch 353/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.2603e-04 - mae: 0.0032 - val_loss: 3.1407e-04 - val_mae: 0.0024\n",
      "Epoch 354/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.2574e-04 - mae: 0.0035 - val_loss: 3.1098e-04 - val_mae: 0.0021\n",
      "Epoch 355/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.1551e-04 - mae: 0.0027 - val_loss: 3.3743e-04 - val_mae: 0.0052\n",
      "Epoch 356/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 3.2297e-04 - mae: 0.0034 - val_loss: 3.1406e-04 - val_mae: 0.0030\n",
      "Epoch 357/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.1627e-04 - mae: 0.0030 - val_loss: 3.0675e-04 - val_mae: 0.0023\n",
      "Epoch 358/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.1671e-04 - mae: 0.0031 - val_loss: 3.1134e-04 - val_mae: 0.0029\n",
      "Epoch 359/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 3.0973e-04 - mae: 0.0029 - val_loss: 3.0379e-04 - val_mae: 0.0024\n",
      "Epoch 360/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 3.1204e-04 - mae: 0.0031 - val_loss: 3.0743e-04 - val_mae: 0.0032\n",
      "Epoch 361/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.0702e-04 - mae: 0.0029 - val_loss: 3.0339e-04 - val_mae: 0.0027\n",
      "Epoch 362/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.0532e-04 - mae: 0.0029 - val_loss: 3.0480e-04 - val_mae: 0.0032\n",
      "Epoch 363/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.0406e-04 - mae: 0.0030 - val_loss: 3.0733e-04 - val_mae: 0.0035\n",
      "Epoch 364/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.0563e-04 - mae: 0.0033 - val_loss: 3.0051e-04 - val_mae: 0.0030\n",
      "Epoch 365/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 3.0007e-04 - mae: 0.0029 - val_loss: 2.9302e-04 - val_mae: 0.0023\n",
      "Epoch 366/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 3.0208e-04 - mae: 0.0032 - val_loss: 2.9996e-04 - val_mae: 0.0031\n",
      "Epoch 367/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.0287e-04 - mae: 0.0034 - val_loss: 3.0563e-04 - val_mae: 0.0040\n",
      "Epoch 368/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.9726e-04 - mae: 0.0031 - val_loss: 2.9506e-04 - val_mae: 0.0031\n",
      "Epoch 369/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.9389e-04 - mae: 0.0029 - val_loss: 3.0169e-04 - val_mae: 0.0041\n",
      "Epoch 370/1000\n",
      "366/375 [============================>.] - ETA: 0s - loss: 2.9793e-04 - mae: 0.0035Restoring model weights from the end of the best epoch: 365.\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.9786e-04 - mae: 0.0035 - val_loss: 3.0491e-04 - val_mae: 0.0038\n",
      "Epoch 370: early stopping\n",
      "Training fÃ¼r Fold 3...\n",
      "Epoch 1/1000\n",
      "375/375 [==============================] - 5s 5ms/step - loss: 0.0576 - mae: 0.1327 - val_loss: 0.0335 - val_mae: 0.0846\n",
      "Epoch 2/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0284 - mae: 0.0696 - val_loss: 0.0234 - val_mae: 0.0515\n",
      "Epoch 3/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0217 - mae: 0.0471 - val_loss: 0.0199 - val_mae: 0.0329\n",
      "Epoch 4/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0191 - mae: 0.0344 - val_loss: 0.0186 - val_mae: 0.0353\n",
      "Epoch 5/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0181 - mae: 0.0310 - val_loss: 0.0174 - val_mae: 0.0234\n",
      "Epoch 6/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0170 - mae: 0.0224 - val_loss: 0.0167 - val_mae: 0.0169\n",
      "Epoch 7/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0166 - mae: 0.0201 - val_loss: 0.0163 - val_mae: 0.0171\n",
      "Epoch 8/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0164 - mae: 0.0200 - val_loss: 0.0160 - val_mae: 0.0170\n",
      "Epoch 9/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0160 - mae: 0.0169 - val_loss: 0.0156 - val_mae: 0.0119\n",
      "Epoch 10/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0157 - mae: 0.0168 - val_loss: 0.0155 - val_mae: 0.0144\n",
      "Epoch 11/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0160 - mae: 0.0235 - val_loss: 0.0155 - val_mae: 0.0183\n",
      "Epoch 12/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0154 - mae: 0.0187 - val_loss: 0.0150 - val_mae: 0.0139\n",
      "Epoch 13/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0155 - mae: 0.0215 - val_loss: 0.0158 - val_mae: 0.0308\n",
      "Epoch 14/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0152 - mae: 0.0210 - val_loss: 0.0146 - val_mae: 0.0152\n",
      "Epoch 15/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0145 - mae: 0.0134 - val_loss: 0.0146 - val_mae: 0.0160\n",
      "Epoch 16/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0146 - mae: 0.0191 - val_loss: 0.0143 - val_mae: 0.0163\n",
      "Epoch 17/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0144 - mae: 0.0181 - val_loss: 0.0142 - val_mae: 0.0155\n",
      "Epoch 18/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0141 - mae: 0.0163 - val_loss: 0.0171 - val_mae: 0.0470\n",
      "Epoch 19/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0145 - mae: 0.0234 - val_loss: 0.0137 - val_mae: 0.0152\n",
      "Epoch 20/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0135 - mae: 0.0131 - val_loss: 0.0135 - val_mae: 0.0180\n",
      "Epoch 21/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0135 - mae: 0.0157 - val_loss: 0.0133 - val_mae: 0.0141\n",
      "Epoch 22/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0130 - mae: 0.0121 - val_loss: 0.0128 - val_mae: 0.0105\n",
      "Epoch 23/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0131 - mae: 0.0163 - val_loss: 0.0132 - val_mae: 0.0171\n",
      "Epoch 24/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0129 - mae: 0.0167 - val_loss: 0.0124 - val_mae: 0.0086\n",
      "Epoch 25/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0126 - mae: 0.0150 - val_loss: 0.0133 - val_mae: 0.0286\n",
      "Epoch 26/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0127 - mae: 0.0186 - val_loss: 0.0122 - val_mae: 0.0149\n",
      "Epoch 27/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0122 - mae: 0.0147 - val_loss: 0.0121 - val_mae: 0.0160\n",
      "Epoch 28/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0120 - mae: 0.0142 - val_loss: 0.0121 - val_mae: 0.0154\n",
      "Epoch 29/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0118 - mae: 0.0142 - val_loss: 0.0115 - val_mae: 0.0098\n",
      "Epoch 30/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0118 - mae: 0.0173 - val_loss: 0.0116 - val_mae: 0.0179\n",
      "Epoch 31/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0112 - mae: 0.0093 - val_loss: 0.0111 - val_mae: 0.0096\n",
      "Epoch 32/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0110 - mae: 0.0096 - val_loss: 0.0109 - val_mae: 0.0067\n",
      "Epoch 33/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0111 - mae: 0.0131 - val_loss: 0.0109 - val_mae: 0.0109\n",
      "Epoch 34/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0109 - mae: 0.0139 - val_loss: 0.0109 - val_mae: 0.0177\n",
      "Epoch 35/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0107 - mae: 0.0141 - val_loss: 0.0105 - val_mae: 0.0117\n",
      "Epoch 36/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0104 - mae: 0.0101 - val_loss: 0.0102 - val_mae: 0.0072\n",
      "Epoch 37/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0102 - mae: 0.0106 - val_loss: 0.0102 - val_mae: 0.0116\n",
      "Epoch 38/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0101 - mae: 0.0115 - val_loss: 0.0101 - val_mae: 0.0127\n",
      "Epoch 39/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0101 - mae: 0.0153 - val_loss: 0.0097 - val_mae: 0.0081\n",
      "Epoch 40/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0097 - mae: 0.0100 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 41/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0097 - mae: 0.0132 - val_loss: 0.0094 - val_mae: 0.0086\n",
      "Epoch 42/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0094 - val_mae: 0.0143\n",
      "Epoch 43/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0093 - mae: 0.0112 - val_loss: 0.0091 - val_mae: 0.0070\n",
      "Epoch 44/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0096 - mae: 0.0182 - val_loss: 0.0092 - val_mae: 0.0151\n",
      "Epoch 45/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0089 - mae: 0.0077 - val_loss: 0.0088 - val_mae: 0.0081\n",
      "Epoch 46/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0087 - mae: 0.0070 - val_loss: 0.0086 - val_mae: 0.0057\n",
      "Epoch 47/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0086 - mae: 0.0100 - val_loss: 0.0088 - val_mae: 0.0123\n",
      "Epoch 48/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0086 - mae: 0.0120 - val_loss: 0.0083 - val_mae: 0.0062\n",
      "Epoch 49/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0083 - mae: 0.0074 - val_loss: 0.0082 - val_mae: 0.0085\n",
      "Epoch 50/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0081 - mae: 0.0078 - val_loss: 0.0081 - val_mae: 0.0070\n",
      "Epoch 51/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0081 - mae: 0.0111 - val_loss: 0.0080 - val_mae: 0.0099\n",
      "Epoch 52/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0079 - mae: 0.0094 - val_loss: 0.0080 - val_mae: 0.0115\n",
      "Epoch 53/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0078 - mae: 0.0101 - val_loss: 0.0078 - val_mae: 0.0105\n",
      "Epoch 54/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0078 - mae: 0.0117 - val_loss: 0.0076 - val_mae: 0.0084\n",
      "Epoch 55/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0075 - mae: 0.0084 - val_loss: 0.0074 - val_mae: 0.0066\n",
      "Epoch 56/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0073 - mae: 0.0068 - val_loss: 0.0073 - val_mae: 0.0068\n",
      "Epoch 57/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0073 - mae: 0.0097 - val_loss: 0.0072 - val_mae: 0.0072\n",
      "Epoch 58/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0072 - mae: 0.0103 - val_loss: 0.0070 - val_mae: 0.0073\n",
      "Epoch 59/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0070 - mae: 0.0070 - val_loss: 0.0069 - val_mae: 0.0064\n",
      "Epoch 60/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0070 - mae: 0.0095 - val_loss: 0.0068 - val_mae: 0.0062\n",
      "Epoch 61/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0068 - mae: 0.0073 - val_loss: 0.0071 - val_mae: 0.0154\n",
      "Epoch 62/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0067 - mae: 0.0097 - val_loss: 0.0066 - val_mae: 0.0093\n",
      "Epoch 63/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0066 - mae: 0.0098 - val_loss: 0.0065 - val_mae: 0.0068\n",
      "Epoch 64/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0064 - mae: 0.0077 - val_loss: 0.0064 - val_mae: 0.0070\n",
      "Epoch 65/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0063 - mae: 0.0062 - val_loss: 0.0063 - val_mae: 0.0092\n",
      "Epoch 66/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0063 - mae: 0.0089 - val_loss: 0.0062 - val_mae: 0.0076\n",
      "Epoch 67/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0061 - mae: 0.0079 - val_loss: 0.0060 - val_mae: 0.0052\n",
      "Epoch 68/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0060 - mae: 0.0078 - val_loss: 0.0060 - val_mae: 0.0070\n",
      "Epoch 69/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0060 - mae: 0.0094 - val_loss: 0.0059 - val_mae: 0.0096\n",
      "Epoch 70/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0059 - mae: 0.0102 - val_loss: 0.0057 - val_mae: 0.0061\n",
      "Epoch 71/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0058 - mae: 0.0078 - val_loss: 0.0059 - val_mae: 0.0135\n",
      "Epoch 72/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0057 - mae: 0.0073 - val_loss: 0.0058 - val_mae: 0.0123\n",
      "Epoch 73/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0055 - mae: 0.0062 - val_loss: 0.0056 - val_mae: 0.0097\n",
      "Epoch 74/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0056 - mae: 0.0097 - val_loss: 0.0055 - val_mae: 0.0105\n",
      "Epoch 75/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0054 - mae: 0.0067 - val_loss: 0.0053 - val_mae: 0.0075\n",
      "Epoch 76/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0053 - mae: 0.0080 - val_loss: 0.0053 - val_mae: 0.0079\n",
      "Epoch 77/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0052 - mae: 0.0063 - val_loss: 0.0052 - val_mae: 0.0080\n",
      "Epoch 78/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0053 - mae: 0.0101 - val_loss: 0.0051 - val_mae: 0.0064\n",
      "Epoch 79/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0051 - mae: 0.0067 - val_loss: 0.0050 - val_mae: 0.0062\n",
      "Epoch 80/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0050 - mae: 0.0071 - val_loss: 0.0049 - val_mae: 0.0045\n",
      "Epoch 81/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0049 - mae: 0.0060 - val_loss: 0.0049 - val_mae: 0.0073\n",
      "Epoch 82/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0048 - mae: 0.0069 - val_loss: 0.0047 - val_mae: 0.0049\n",
      "Epoch 83/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0048 - mae: 0.0090 - val_loss: 0.0047 - val_mae: 0.0079\n",
      "Epoch 84/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0047 - mae: 0.0069 - val_loss: 0.0046 - val_mae: 0.0050\n",
      "Epoch 85/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0047 - mae: 0.0084 - val_loss: 0.0046 - val_mae: 0.0078\n",
      "Epoch 86/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0045 - mae: 0.0055 - val_loss: 0.0046 - val_mae: 0.0108\n",
      "Epoch 87/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0045 - mae: 0.0069 - val_loss: 0.0045 - val_mae: 0.0087\n",
      "Epoch 88/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0044 - mae: 0.0072 - val_loss: 0.0043 - val_mae: 0.0041\n",
      "Epoch 89/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0043 - mae: 0.0068 - val_loss: 0.0043 - val_mae: 0.0064\n",
      "Epoch 90/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0043 - mae: 0.0074 - val_loss: 0.0042 - val_mae: 0.0051\n",
      "Epoch 91/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0042 - mae: 0.0062 - val_loss: 0.0041 - val_mae: 0.0042\n",
      "Epoch 92/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0042 - mae: 0.0079 - val_loss: 0.0042 - val_mae: 0.0097\n",
      "Epoch 93/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0041 - mae: 0.0063 - val_loss: 0.0042 - val_mae: 0.0106\n",
      "Epoch 94/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0040 - mae: 0.0064 - val_loss: 0.0040 - val_mae: 0.0055\n",
      "Epoch 95/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0039 - mae: 0.0057 - val_loss: 0.0039 - val_mae: 0.0038\n",
      "Epoch 96/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0039 - mae: 0.0064 - val_loss: 0.0039 - val_mae: 0.0090\n",
      "Epoch 97/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0039 - mae: 0.0073 - val_loss: 0.0038 - val_mae: 0.0042\n",
      "Epoch 98/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0038 - mae: 0.0065 - val_loss: 0.0037 - val_mae: 0.0039\n",
      "Epoch 99/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0037 - mae: 0.0055 - val_loss: 0.0037 - val_mae: 0.0054\n",
      "Epoch 100/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0037 - mae: 0.0071 - val_loss: 0.0036 - val_mae: 0.0052\n",
      "Epoch 101/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0070 - val_loss: 0.0038 - val_mae: 0.0127\n",
      "Epoch 102/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0035 - mae: 0.0057 - val_loss: 0.0035 - val_mae: 0.0047\n",
      "Epoch 103/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0046 - val_loss: 0.0035 - val_mae: 0.0077\n",
      "Epoch 104/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0060 - val_loss: 0.0034 - val_mae: 0.0066\n",
      "Epoch 105/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0034 - mae: 0.0062 - val_loss: 0.0034 - val_mae: 0.0069\n",
      "Epoch 106/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0033 - mae: 0.0061 - val_loss: 0.0033 - val_mae: 0.0054\n",
      "Epoch 107/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0032 - mae: 0.0045 - val_loss: 0.0033 - val_mae: 0.0091\n",
      "Epoch 108/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0084 - val_loss: 0.0032 - val_mae: 0.0030\n",
      "Epoch 109/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0032 - mae: 0.0056 - val_loss: 0.0032 - val_mae: 0.0051\n",
      "Epoch 110/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0031 - mae: 0.0045 - val_loss: 0.0031 - val_mae: 0.0043\n",
      "Epoch 111/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0031 - mae: 0.0050 - val_loss: 0.0031 - val_mae: 0.0054\n",
      "Epoch 112/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0055 - val_loss: 0.0030 - val_mae: 0.0069\n",
      "Epoch 113/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0063 - val_loss: 0.0030 - val_mae: 0.0056\n",
      "Epoch 114/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0030 - mae: 0.0062 - val_loss: 0.0029 - val_mae: 0.0063\n",
      "Epoch 115/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0029 - mae: 0.0049 - val_loss: 0.0029 - val_mae: 0.0049\n",
      "Epoch 116/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0029 - mae: 0.0059 - val_loss: 0.0028 - val_mae: 0.0051\n",
      "Epoch 117/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0028 - mae: 0.0049 - val_loss: 0.0028 - val_mae: 0.0044\n",
      "Epoch 118/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0028 - mae: 0.0053 - val_loss: 0.0027 - val_mae: 0.0052\n",
      "Epoch 119/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0027 - mae: 0.0052 - val_loss: 0.0027 - val_mae: 0.0044\n",
      "Epoch 120/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0027 - mae: 0.0053 - val_loss: 0.0027 - val_mae: 0.0081\n",
      "Epoch 121/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0052 - val_loss: 0.0026 - val_mae: 0.0040\n",
      "Epoch 122/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0026 - mae: 0.0048 - val_loss: 0.0026 - val_mae: 0.0042\n",
      "Epoch 123/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0050 - val_loss: 0.0025 - val_mae: 0.0044\n",
      "Epoch 124/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0050 - val_loss: 0.0025 - val_mae: 0.0049\n",
      "Epoch 125/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0025 - mae: 0.0050 - val_loss: 0.0024 - val_mae: 0.0036\n",
      "Epoch 126/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0043 - val_loss: 0.0024 - val_mae: 0.0039\n",
      "Epoch 127/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0024 - mae: 0.0064 - val_loss: 0.0024 - val_mae: 0.0057\n",
      "Epoch 128/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0048 - val_loss: 0.0024 - val_mae: 0.0075\n",
      "Epoch 129/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0023 - mae: 0.0050 - val_loss: 0.0023 - val_mae: 0.0034\n",
      "Epoch 130/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0023 - mae: 0.0043 - val_loss: 0.0023 - val_mae: 0.0070\n",
      "Epoch 131/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0053 - val_loss: 0.0022 - val_mae: 0.0049\n",
      "Epoch 132/1000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0044 - val_loss: 0.0022 - val_mae: 0.0049\n",
      "Epoch 133/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0046 - val_loss: 0.0022 - val_mae: 0.0058\n",
      "Epoch 134/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0022 - mae: 0.0043 - val_loss: 0.0022 - val_mae: 0.0067\n",
      "Epoch 135/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0053 - val_loss: 0.0021 - val_mae: 0.0039\n",
      "Epoch 136/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0021 - mae: 0.0046 - val_loss: 0.0021 - val_mae: 0.0047\n",
      "Epoch 137/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0051 - val_loss: 0.0022 - val_mae: 0.0100\n",
      "Epoch 138/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0051 - val_loss: 0.0020 - val_mae: 0.0039\n",
      "Epoch 139/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0049 - val_loss: 0.0020 - val_mae: 0.0042\n",
      "Epoch 140/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0045 - val_loss: 0.0019 - val_mae: 0.0034\n",
      "Epoch 141/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0055 - val_loss: 0.0020 - val_mae: 0.0073\n",
      "Epoch 142/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0047 - val_loss: 0.0019 - val_mae: 0.0049\n",
      "Epoch 143/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0046 - val_loss: 0.0020 - val_mae: 0.0101\n",
      "Epoch 144/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0046 - val_loss: 0.0018 - val_mae: 0.0030\n",
      "Epoch 145/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0018 - mae: 0.0045 - val_loss: 0.0018 - val_mae: 0.0041\n",
      "Epoch 146/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0018 - mae: 0.0048 - val_loss: 0.0019 - val_mae: 0.0068\n",
      "Epoch 147/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0018 - mae: 0.0046 - val_loss: 0.0018 - val_mae: 0.0036\n",
      "Epoch 148/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0018 - mae: 0.0050 - val_loss: 0.0018 - val_mae: 0.0053\n",
      "Epoch 149/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0043 - val_loss: 0.0017 - val_mae: 0.0043\n",
      "Epoch 150/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0051 - val_loss: 0.0017 - val_mae: 0.0037\n",
      "Epoch 151/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0047 - val_loss: 0.0017 - val_mae: 0.0041\n",
      "Epoch 152/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0041 - val_loss: 0.0017 - val_mae: 0.0045\n",
      "Epoch 153/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0052 - val_loss: 0.0016 - val_mae: 0.0047\n",
      "Epoch 154/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0041 - val_loss: 0.0016 - val_mae: 0.0034\n",
      "Epoch 155/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0035\n",
      "Epoch 156/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0042 - val_loss: 0.0016 - val_mae: 0.0043\n",
      "Epoch 157/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0056 - val_loss: 0.0015 - val_mae: 0.0039\n",
      "Epoch 158/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0039 - val_loss: 0.0015 - val_mae: 0.0037\n",
      "Epoch 159/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0041 - val_loss: 0.0015 - val_mae: 0.0030\n",
      "Epoch 160/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0048 - val_loss: 0.0015 - val_mae: 0.0037\n",
      "Epoch 161/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0064\n",
      "Epoch 162/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0039\n",
      "Epoch 163/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0038 - val_loss: 0.0014 - val_mae: 0.0032\n",
      "Epoch 164/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0014 - val_mae: 0.0049\n",
      "Epoch 165/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0041\n",
      "Epoch 166/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0031\n",
      "Epoch 167/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0073\n",
      "Epoch 168/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0061\n",
      "Epoch 169/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0035\n",
      "Epoch 170/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0051 - val_loss: 0.0013 - val_mae: 0.0050\n",
      "Epoch 171/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0042 - val_loss: 0.0013 - val_mae: 0.0050\n",
      "Epoch 172/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0040 - val_loss: 0.0013 - val_mae: 0.0034\n",
      "Epoch 173/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0038 - val_loss: 0.0013 - val_mae: 0.0033\n",
      "Epoch 174/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0038 - val_loss: 0.0013 - val_mae: 0.0063\n",
      "Epoch 175/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0031\n",
      "Epoch 176/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0039 - val_loss: 0.0012 - val_mae: 0.0048\n",
      "Epoch 177/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0039 - val_loss: 0.0012 - val_mae: 0.0036\n",
      "Epoch 178/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0037 - val_loss: 0.0012 - val_mae: 0.0035\n",
      "Epoch 179/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0048 - val_loss: 0.0012 - val_mae: 0.0060\n",
      "Epoch 180/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0036 - val_loss: 0.0012 - val_mae: 0.0039\n",
      "Epoch 181/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0037 - val_loss: 0.0011 - val_mae: 0.0034\n",
      "Epoch 182/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0037 - val_loss: 0.0011 - val_mae: 0.0030\n",
      "Epoch 183/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0040 - val_loss: 0.0011 - val_mae: 0.0032\n",
      "Epoch 184/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0037 - val_loss: 0.0011 - val_mae: 0.0037\n",
      "Epoch 185/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0046 - val_loss: 0.0011 - val_mae: 0.0043\n",
      "Epoch 186/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0036 - val_loss: 0.0011 - val_mae: 0.0032\n",
      "Epoch 187/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0040\n",
      "Epoch 188/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0040 - val_loss: 0.0011 - val_mae: 0.0043\n",
      "Epoch 189/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0048 - val_loss: 0.0010 - val_mae: 0.0039\n",
      "Epoch 190/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0050\n",
      "Epoch 191/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0040 - val_loss: 0.0011 - val_mae: 0.0054\n",
      "Epoch 192/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0041 - val_loss: 9.9923e-04 - val_mae: 0.0031\n",
      "Epoch 193/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0036 - val_loss: 9.8859e-04 - val_mae: 0.0031\n",
      "Epoch 194/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0043 - val_loss: 0.0010 - val_mae: 0.0054\n",
      "Epoch 195/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 9.8133e-04 - mae: 0.0037 - val_loss: 9.7517e-04 - val_mae: 0.0036\n",
      "Epoch 196/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 9.7188e-04 - mae: 0.0037 - val_loss: 9.7731e-04 - val_mae: 0.0043\n",
      "Epoch 197/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 9.6593e-04 - mae: 0.0039 - val_loss: 9.3970e-04 - val_mae: 0.0024\n",
      "Epoch 198/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 9.5030e-04 - mae: 0.0037 - val_loss: 9.3615e-04 - val_mae: 0.0029\n",
      "Epoch 199/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 9.3893e-04 - mae: 0.0037 - val_loss: 9.4084e-04 - val_mae: 0.0045\n",
      "Epoch 200/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 9.4287e-04 - mae: 0.0046 - val_loss: 9.2854e-04 - val_mae: 0.0041\n",
      "Epoch 201/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 9.1279e-04 - mae: 0.0033 - val_loss: 9.0217e-04 - val_mae: 0.0029\n",
      "Epoch 202/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 9.1643e-04 - mae: 0.0041 - val_loss: 8.9254e-04 - val_mae: 0.0027\n",
      "Epoch 203/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 8.9606e-04 - mae: 0.0036 - val_loss: 9.0471e-04 - val_mae: 0.0045\n",
      "Epoch 204/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 8.9054e-04 - mae: 0.0038 - val_loss: 9.2036e-04 - val_mae: 0.0057\n",
      "Epoch 205/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.7729e-04 - mae: 0.0036 - val_loss: 8.8173e-04 - val_mae: 0.0044\n",
      "Epoch 206/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 8.7060e-04 - mae: 0.0038 - val_loss: 8.6833e-04 - val_mae: 0.0045\n",
      "Epoch 207/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.6733e-04 - mae: 0.0043 - val_loss: 8.6729e-04 - val_mae: 0.0044\n",
      "Epoch 208/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 8.4891e-04 - mae: 0.0036 - val_loss: 8.3492e-04 - val_mae: 0.0028\n",
      "Epoch 209/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.4185e-04 - mae: 0.0038 - val_loss: 8.3032e-04 - val_mae: 0.0032\n",
      "Epoch 210/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.3301e-04 - mae: 0.0037 - val_loss: 8.2281e-04 - val_mae: 0.0034\n",
      "Epoch 211/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.2316e-04 - mae: 0.0036 - val_loss: 8.0941e-04 - val_mae: 0.0031\n",
      "Epoch 212/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.1694e-04 - mae: 0.0039 - val_loss: 8.7133e-04 - val_mae: 0.0086\n",
      "Epoch 213/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.0322e-04 - mae: 0.0035 - val_loss: 7.9327e-04 - val_mae: 0.0031\n",
      "Epoch 214/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 8.1276e-04 - mae: 0.0046 - val_loss: 8.0333e-04 - val_mae: 0.0047\n",
      "Epoch 215/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.9289e-04 - mae: 0.0039 - val_loss: 7.7940e-04 - val_mae: 0.0034\n",
      "Epoch 216/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.9217e-04 - mae: 0.0040 - val_loss: 7.6603e-04 - val_mae: 0.0026\n",
      "Epoch 217/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.8163e-04 - mae: 0.0042 - val_loss: 7.7456e-04 - val_mae: 0.0038\n",
      "Epoch 218/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.6544e-04 - mae: 0.0036 - val_loss: 7.8057e-04 - val_mae: 0.0056\n",
      "Epoch 219/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.5642e-04 - mae: 0.0035 - val_loss: 7.4565e-04 - val_mae: 0.0028\n",
      "Epoch 220/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.4867e-04 - mae: 0.0034 - val_loss: 7.6081e-04 - val_mae: 0.0052\n",
      "Epoch 221/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.4906e-04 - mae: 0.0040 - val_loss: 7.5457e-04 - val_mae: 0.0053\n",
      "Epoch 222/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.5254e-04 - mae: 0.0044 - val_loss: 7.3555e-04 - val_mae: 0.0035\n",
      "Epoch 223/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.3424e-04 - mae: 0.0038 - val_loss: 7.2372e-04 - val_mae: 0.0032\n",
      "Epoch 224/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.2493e-04 - mae: 0.0037 - val_loss: 7.3341e-04 - val_mae: 0.0053\n",
      "Epoch 225/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.1599e-04 - mae: 0.0035 - val_loss: 7.0759e-04 - val_mae: 0.0032\n",
      "Epoch 226/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.1365e-04 - mae: 0.0038 - val_loss: 7.0718e-04 - val_mae: 0.0037\n",
      "Epoch 227/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.0110e-04 - mae: 0.0035 - val_loss: 6.8807e-04 - val_mae: 0.0028\n",
      "Epoch 228/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.9580e-04 - mae: 0.0036 - val_loss: 6.8326e-04 - val_mae: 0.0029\n",
      "Epoch 229/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.9308e-04 - mae: 0.0039 - val_loss: 6.7722e-04 - val_mae: 0.0030\n",
      "Epoch 230/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.8010e-04 - mae: 0.0034 - val_loss: 6.7782e-04 - val_mae: 0.0033\n",
      "Epoch 231/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.8067e-04 - mae: 0.0038 - val_loss: 6.6365e-04 - val_mae: 0.0030\n",
      "Epoch 232/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.6541e-04 - mae: 0.0033 - val_loss: 6.7695e-04 - val_mae: 0.0048\n",
      "Epoch 233/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.5933e-04 - mae: 0.0033 - val_loss: 6.5236e-04 - val_mae: 0.0033\n",
      "Epoch 234/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.5448e-04 - mae: 0.0035 - val_loss: 6.4945e-04 - val_mae: 0.0036\n",
      "Epoch 235/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.4875e-04 - mae: 0.0036 - val_loss: 6.4408e-04 - val_mae: 0.0035\n",
      "Epoch 236/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.4260e-04 - mae: 0.0035 - val_loss: 6.3750e-04 - val_mae: 0.0036\n",
      "Epoch 237/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.3667e-04 - mae: 0.0036 - val_loss: 6.3562e-04 - val_mae: 0.0038\n",
      "Epoch 238/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.3895e-04 - mae: 0.0041 - val_loss: 6.1964e-04 - val_mae: 0.0030\n",
      "Epoch 239/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.2430e-04 - mae: 0.0036 - val_loss: 6.3171e-04 - val_mae: 0.0038\n",
      "Epoch 240/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.2489e-04 - mae: 0.0039 - val_loss: 6.1645e-04 - val_mae: 0.0038\n",
      "Epoch 241/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.1411e-04 - mae: 0.0036 - val_loss: 6.1567e-04 - val_mae: 0.0040\n",
      "Epoch 242/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.0580e-04 - mae: 0.0034 - val_loss: 5.9262e-04 - val_mae: 0.0023\n",
      "Epoch 243/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.0109e-04 - mae: 0.0035 - val_loss: 6.0825e-04 - val_mae: 0.0037\n",
      "Epoch 244/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 6.0389e-04 - mae: 0.0039 - val_loss: 5.8911e-04 - val_mae: 0.0034\n",
      "Epoch 245/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.9089e-04 - mae: 0.0035 - val_loss: 6.0718e-04 - val_mae: 0.0050\n",
      "Epoch 246/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.8405e-04 - mae: 0.0034 - val_loss: 5.8118e-04 - val_mae: 0.0035\n",
      "Epoch 247/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.7883e-04 - mae: 0.0034 - val_loss: 5.7397e-04 - val_mae: 0.0033\n",
      "Epoch 248/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.7622e-04 - mae: 0.0036 - val_loss: 5.8788e-04 - val_mae: 0.0047\n",
      "Epoch 249/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.6547e-04 - mae: 0.0032 - val_loss: 5.7164e-04 - val_mae: 0.0043\n",
      "Epoch 250/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.7143e-04 - mae: 0.0040 - val_loss: 5.5518e-04 - val_mae: 0.0032\n",
      "Epoch 251/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.6425e-04 - mae: 0.0038 - val_loss: 5.4555e-04 - val_mae: 0.0023\n",
      "Epoch 252/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.5277e-04 - mae: 0.0033 - val_loss: 5.4788e-04 - val_mae: 0.0033\n",
      "Epoch 253/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.5454e-04 - mae: 0.0036 - val_loss: 5.4449e-04 - val_mae: 0.0032\n",
      "Epoch 254/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.4491e-04 - mae: 0.0033 - val_loss: 5.5039e-04 - val_mae: 0.0040\n",
      "Epoch 255/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.3944e-04 - mae: 0.0034 - val_loss: 5.3145e-04 - val_mae: 0.0028\n",
      "Epoch 256/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.3568e-04 - mae: 0.0034 - val_loss: 6.3726e-04 - val_mae: 0.0091\n",
      "Epoch 257/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.3943e-04 - mae: 0.0039 - val_loss: 5.2429e-04 - val_mae: 0.0028\n",
      "Epoch 258/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.2799e-04 - mae: 0.0034 - val_loss: 5.1465e-04 - val_mae: 0.0024\n",
      "Epoch 259/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.2154e-04 - mae: 0.0033 - val_loss: 5.5123e-04 - val_mae: 0.0053\n",
      "Epoch 260/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.1945e-04 - mae: 0.0035 - val_loss: 5.0812e-04 - val_mae: 0.0028\n",
      "Epoch 261/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.1180e-04 - mae: 0.0033 - val_loss: 5.0681e-04 - val_mae: 0.0033\n",
      "Epoch 262/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.0956e-04 - mae: 0.0034 - val_loss: 5.0167e-04 - val_mae: 0.0029\n",
      "Epoch 263/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.0832e-04 - mae: 0.0037 - val_loss: 4.9256e-04 - val_mae: 0.0024\n",
      "Epoch 264/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 5.0085e-04 - mae: 0.0033 - val_loss: 5.2882e-04 - val_mae: 0.0059\n",
      "Epoch 265/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.0306e-04 - mae: 0.0039 - val_loss: 4.8882e-04 - val_mae: 0.0030\n",
      "Epoch 266/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.9228e-04 - mae: 0.0033 - val_loss: 4.8789e-04 - val_mae: 0.0033\n",
      "Epoch 267/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.8254e-04 - mae: 0.0028 - val_loss: 4.8018e-04 - val_mae: 0.0031\n",
      "Epoch 268/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.8356e-04 - mae: 0.0033 - val_loss: 4.7192e-04 - val_mae: 0.0024\n",
      "Epoch 269/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.7998e-04 - mae: 0.0034 - val_loss: 4.9142e-04 - val_mae: 0.0049\n",
      "Epoch 270/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.7629e-04 - mae: 0.0033 - val_loss: 4.6894e-04 - val_mae: 0.0028\n",
      "Epoch 271/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.7100e-04 - mae: 0.0033 - val_loss: 5.1167e-04 - val_mae: 0.0062\n",
      "Epoch 272/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.7678e-04 - mae: 0.0039 - val_loss: 5.0475e-04 - val_mae: 0.0064\n",
      "Epoch 273/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.6753e-04 - mae: 0.0035 - val_loss: 4.6488e-04 - val_mae: 0.0037\n",
      "Epoch 274/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.5807e-04 - mae: 0.0031 - val_loss: 4.5665e-04 - val_mae: 0.0035\n",
      "Epoch 275/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.5445e-04 - mae: 0.0031 - val_loss: 4.5518e-04 - val_mae: 0.0033\n",
      "Epoch 276/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.5750e-04 - mae: 0.0035 - val_loss: 4.4683e-04 - val_mae: 0.0030\n",
      "Epoch 277/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.4826e-04 - mae: 0.0032 - val_loss: 4.5861e-04 - val_mae: 0.0047\n",
      "Epoch 278/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.4363e-04 - mae: 0.0030 - val_loss: 4.6637e-04 - val_mae: 0.0052\n",
      "Epoch 279/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.4900e-04 - mae: 0.0036 - val_loss: 4.3192e-04 - val_mae: 0.0023\n",
      "Epoch 280/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.4273e-04 - mae: 0.0035 - val_loss: 4.4034e-04 - val_mae: 0.0035\n",
      "Epoch 281/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.3135e-04 - mae: 0.0028 - val_loss: 4.3178e-04 - val_mae: 0.0035\n",
      "Epoch 282/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.3663e-04 - mae: 0.0036 - val_loss: 4.4152e-04 - val_mae: 0.0042\n",
      "Epoch 283/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.3201e-04 - mae: 0.0034 - val_loss: 4.3662e-04 - val_mae: 0.0044\n",
      "Epoch 284/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.2908e-04 - mae: 0.0035 - val_loss: 4.1343e-04 - val_mae: 0.0019\n",
      "Epoch 285/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.2587e-04 - mae: 0.0035 - val_loss: 4.2187e-04 - val_mae: 0.0033\n",
      "Epoch 286/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.1746e-04 - mae: 0.0030 - val_loss: 4.1457e-04 - val_mae: 0.0031\n",
      "Epoch 287/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.1590e-04 - mae: 0.0031 - val_loss: 4.2501e-04 - val_mae: 0.0040\n",
      "Epoch 288/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.2247e-04 - mae: 0.0040 - val_loss: 4.0644e-04 - val_mae: 0.0028\n",
      "Epoch 289/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.1163e-04 - mae: 0.0034 - val_loss: 4.0352e-04 - val_mae: 0.0029\n",
      "Epoch 290/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.0965e-04 - mae: 0.0034 - val_loss: 4.0492e-04 - val_mae: 0.0032\n",
      "Epoch 291/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.0151e-04 - mae: 0.0029 - val_loss: 3.9809e-04 - val_mae: 0.0029\n",
      "Epoch 292/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.0128e-04 - mae: 0.0032 - val_loss: 3.9294e-04 - val_mae: 0.0024\n",
      "Epoch 293/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.9990e-04 - mae: 0.0033 - val_loss: 3.9096e-04 - val_mae: 0.0027\n",
      "Epoch 294/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.9696e-04 - mae: 0.0033 - val_loss: 3.8513e-04 - val_mae: 0.0024\n",
      "Epoch 295/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.9628e-04 - mae: 0.0034 - val_loss: 3.8515e-04 - val_mae: 0.0026\n",
      "Epoch 296/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.9317e-04 - mae: 0.0035 - val_loss: 3.7850e-04 - val_mae: 0.0021\n",
      "Epoch 297/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.8730e-04 - mae: 0.0032 - val_loss: 3.8567e-04 - val_mae: 0.0032\n",
      "Epoch 298/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.8572e-04 - mae: 0.0033 - val_loss: 3.8498e-04 - val_mae: 0.0037\n",
      "Epoch 299/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.8111e-04 - mae: 0.0031 - val_loss: 3.7345e-04 - val_mae: 0.0025\n",
      "Epoch 300/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.7960e-04 - mae: 0.0032 - val_loss: 3.7859e-04 - val_mae: 0.0031\n",
      "Epoch 301/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.7448e-04 - mae: 0.0030 - val_loss: 3.7303e-04 - val_mae: 0.0032\n",
      "Epoch 302/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.7277e-04 - mae: 0.0031 - val_loss: 3.8671e-04 - val_mae: 0.0043\n",
      "Epoch 303/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.7026e-04 - mae: 0.0031 - val_loss: 3.6478e-04 - val_mae: 0.0025\n",
      "Epoch 304/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.6906e-04 - mae: 0.0032 - val_loss: 3.6152e-04 - val_mae: 0.0027\n",
      "Epoch 305/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.6432e-04 - mae: 0.0030 - val_loss: 3.6451e-04 - val_mae: 0.0033\n",
      "Epoch 306/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.6712e-04 - mae: 0.0035 - val_loss: 3.5867e-04 - val_mae: 0.0028\n",
      "Epoch 307/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.6151e-04 - mae: 0.0033 - val_loss: 3.8616e-04 - val_mae: 0.0050\n",
      "Epoch 308/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.6464e-04 - mae: 0.0036 - val_loss: 3.5611e-04 - val_mae: 0.0030\n",
      "Epoch 309/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.5593e-04 - mae: 0.0031 - val_loss: 3.4858e-04 - val_mae: 0.0027\n",
      "Epoch 310/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.5549e-04 - mae: 0.0033 - val_loss: 3.6667e-04 - val_mae: 0.0040\n",
      "Epoch 311/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.4967e-04 - mae: 0.0030 - val_loss: 3.4468e-04 - val_mae: 0.0027\n",
      "Epoch 312/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.4868e-04 - mae: 0.0031 - val_loss: 3.4731e-04 - val_mae: 0.0033\n",
      "Epoch 313/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.4495e-04 - mae: 0.0030 - val_loss: 3.4345e-04 - val_mae: 0.0031\n",
      "Epoch 314/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.4616e-04 - mae: 0.0032 - val_loss: 3.5551e-04 - val_mae: 0.0046\n",
      "Epoch 315/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.4242e-04 - mae: 0.0032 - val_loss: 3.3372e-04 - val_mae: 0.0024\n",
      "Epoch 316/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.3617e-04 - mae: 0.0028 - val_loss: 3.4252e-04 - val_mae: 0.0037\n",
      "Epoch 317/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.3923e-04 - mae: 0.0033 - val_loss: 3.4119e-04 - val_mae: 0.0040\n",
      "Epoch 318/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.3767e-04 - mae: 0.0034 - val_loss: 3.3072e-04 - val_mae: 0.0028\n",
      "Epoch 319/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.3234e-04 - mae: 0.0031 - val_loss: 3.4940e-04 - val_mae: 0.0046\n",
      "Epoch 320/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.3438e-04 - mae: 0.0035 - val_loss: 3.3017e-04 - val_mae: 0.0036\n",
      "Epoch 321/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.2786e-04 - mae: 0.0031 - val_loss: 3.4822e-04 - val_mae: 0.0042\n",
      "Epoch 322/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.2760e-04 - mae: 0.0032 - val_loss: 3.2966e-04 - val_mae: 0.0038\n",
      "Epoch 323/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.2368e-04 - mae: 0.0030 - val_loss: 3.2506e-04 - val_mae: 0.0035\n",
      "Epoch 324/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.2518e-04 - mae: 0.0034 - val_loss: 3.3179e-04 - val_mae: 0.0042\n",
      "Epoch 325/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.2251e-04 - mae: 0.0033 - val_loss: 3.1537e-04 - val_mae: 0.0027\n",
      "Epoch 326/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.1772e-04 - mae: 0.0030 - val_loss: 3.0858e-04 - val_mae: 0.0022\n",
      "Epoch 327/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.2039e-04 - mae: 0.0034 - val_loss: 3.1044e-04 - val_mae: 0.0027\n",
      "Epoch 328/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.1470e-04 - mae: 0.0031 - val_loss: 3.2040e-04 - val_mae: 0.0037\n",
      "Epoch 329/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.1031e-04 - mae: 0.0029 - val_loss: 3.1548e-04 - val_mae: 0.0036\n",
      "Epoch 330/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.2012e-04 - mae: 0.0038 - val_loss: 3.0770e-04 - val_mae: 0.0030\n",
      "Epoch 331/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.0784e-04 - mae: 0.0030 - val_loss: 3.0228e-04 - val_mae: 0.0024\n",
      "Epoch 332/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.0494e-04 - mae: 0.0029 - val_loss: 3.0647e-04 - val_mae: 0.0032\n",
      "Epoch 333/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.0658e-04 - mae: 0.0032 - val_loss: 3.0148e-04 - val_mae: 0.0031\n",
      "Epoch 334/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.0336e-04 - mae: 0.0031 - val_loss: 3.0676e-04 - val_mae: 0.0033\n",
      "Epoch 335/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.0147e-04 - mae: 0.0031 - val_loss: 2.9267e-04 - val_mae: 0.0022\n",
      "Epoch 336/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.0023e-04 - mae: 0.0031 - val_loss: 2.9975e-04 - val_mae: 0.0033\n",
      "Epoch 337/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.9437e-04 - mae: 0.0027 - val_loss: 2.8843e-04 - val_mae: 0.0021\n",
      "Epoch 338/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.9538e-04 - mae: 0.0030 - val_loss: 2.8724e-04 - val_mae: 0.0022\n",
      "Epoch 339/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.9767e-04 - mae: 0.0033 - val_loss: 2.8509e-04 - val_mae: 0.0021\n",
      "Epoch 340/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.9638e-04 - mae: 0.0033 - val_loss: 3.0401e-04 - val_mae: 0.0044\n",
      "Epoch 341/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.8986e-04 - mae: 0.0030 - val_loss: 2.8878e-04 - val_mae: 0.0031\n",
      "Epoch 342/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.9630e-04 - mae: 0.0036 - val_loss: 2.8445e-04 - val_mae: 0.0027\n",
      "Epoch 343/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.8701e-04 - mae: 0.0030 - val_loss: 2.8924e-04 - val_mae: 0.0031\n",
      "Epoch 344/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.9284e-04 - mae: 0.0034 - val_loss: 2.8048e-04 - val_mae: 0.0026\n",
      "Epoch 345/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.8371e-04 - mae: 0.0029 - val_loss: 2.8848e-04 - val_mae: 0.0036\n",
      "Epoch 346/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.8344e-04 - mae: 0.0031 - val_loss: 2.8368e-04 - val_mae: 0.0034\n",
      "Epoch 347/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.8660e-04 - mae: 0.0034 - val_loss: 2.7596e-04 - val_mae: 0.0026\n",
      "Epoch 348/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.7786e-04 - mae: 0.0029 - val_loss: 2.7507e-04 - val_mae: 0.0027\n",
      "Epoch 349/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.8860e-04 - mae: 0.0037 - val_loss: 2.7967e-04 - val_mae: 0.0031\n",
      "Epoch 350/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.7784e-04 - mae: 0.0031 - val_loss: 2.7119e-04 - val_mae: 0.0024\n",
      "Epoch 351/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.7630e-04 - mae: 0.0031 - val_loss: 2.7379e-04 - val_mae: 0.0030\n",
      "Epoch 352/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.7082e-04 - mae: 0.0027 - val_loss: 2.6971e-04 - val_mae: 0.0026\n",
      "Epoch 353/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.7056e-04 - mae: 0.0028 - val_loss: 2.7306e-04 - val_mae: 0.0030\n",
      "Epoch 354/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.7539e-04 - mae: 0.0033 - val_loss: 2.6300e-04 - val_mae: 0.0022\n",
      "Epoch 355/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.7756e-04 - mae: 0.0033 - val_loss: 2.6271e-04 - val_mae: 0.0023\n",
      "Epoch 356/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.6835e-04 - mae: 0.0030 - val_loss: 2.6029e-04 - val_mae: 0.0021\n",
      "Epoch 357/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.6756e-04 - mae: 0.0031 - val_loss: 2.7254e-04 - val_mae: 0.0039\n",
      "Epoch 358/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.6419e-04 - mae: 0.0029 - val_loss: 2.6065e-04 - val_mae: 0.0025\n",
      "Epoch 359/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.6678e-04 - mae: 0.0032 - val_loss: 2.6995e-04 - val_mae: 0.0038\n",
      "Epoch 360/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.6395e-04 - mae: 0.0030 - val_loss: 2.6654e-04 - val_mae: 0.0031\n",
      "Epoch 361/1000\n",
      "369/375 [============================>.] - ETA: 0s - loss: 2.6045e-04 - mae: 0.0029Restoring model weights from the end of the best epoch: 356.\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.6041e-04 - mae: 0.0029 - val_loss: 2.6452e-04 - val_mae: 0.0036\n",
      "Epoch 361: early stopping\n",
      "Training fÃ¼r Fold 4...\n",
      "Epoch 1/1000\n",
      "375/375 [==============================] - 3s 4ms/step - loss: 0.0463 - mae: 0.1155 - val_loss: 0.0289 - val_mae: 0.0699\n",
      "Epoch 2/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0253 - mae: 0.0633 - val_loss: 0.0217 - val_mae: 0.0502\n",
      "Epoch 3/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0197 - mae: 0.0416 - val_loss: 0.0178 - val_mae: 0.0305\n",
      "Epoch 4/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0181 - mae: 0.0364 - val_loss: 0.0170 - val_mae: 0.0312\n",
      "Epoch 5/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0167 - mae: 0.0286 - val_loss: 0.0161 - val_mae: 0.0216\n",
      "Epoch 6/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0164 - mae: 0.0268 - val_loss: 0.0153 - val_mae: 0.0163\n",
      "Epoch 7/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0155 - mae: 0.0205 - val_loss: 0.0157 - val_mae: 0.0255\n",
      "Epoch 8/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0152 - mae: 0.0193 - val_loss: 0.0150 - val_mae: 0.0195\n",
      "Epoch 9/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0154 - mae: 0.0239 - val_loss: 0.0150 - val_mae: 0.0217\n",
      "Epoch 10/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0148 - mae: 0.0191 - val_loss: 0.0147 - val_mae: 0.0209\n",
      "Epoch 11/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0144 - mae: 0.0164 - val_loss: 0.0149 - val_mae: 0.0283\n",
      "Epoch 12/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0142 - mae: 0.0181 - val_loss: 0.0138 - val_mae: 0.0116\n",
      "Epoch 13/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0140 - mae: 0.0182 - val_loss: 0.0136 - val_mae: 0.0111\n",
      "Epoch 14/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0137 - mae: 0.0159 - val_loss: 0.0137 - val_mae: 0.0172\n",
      "Epoch 15/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0143 - mae: 0.0240 - val_loss: 0.0139 - val_mae: 0.0223\n",
      "Epoch 16/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0133 - mae: 0.0163 - val_loss: 0.0135 - val_mae: 0.0215\n",
      "Epoch 17/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0133 - mae: 0.0178 - val_loss: 0.0129 - val_mae: 0.0149\n",
      "Epoch 18/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0130 - mae: 0.0172 - val_loss: 0.0130 - val_mae: 0.0189\n",
      "Epoch 19/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0126 - mae: 0.0125 - val_loss: 0.0124 - val_mae: 0.0115\n",
      "Epoch 20/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0124 - mae: 0.0129 - val_loss: 0.0122 - val_mae: 0.0100\n",
      "Epoch 21/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0126 - mae: 0.0194 - val_loss: 0.0133 - val_mae: 0.0357\n",
      "Epoch 22/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0123 - mae: 0.0168 - val_loss: 0.0118 - val_mae: 0.0116\n",
      "Epoch 23/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0118 - mae: 0.0123 - val_loss: 0.0119 - val_mae: 0.0170\n",
      "Epoch 24/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0120 - mae: 0.0180 - val_loss: 0.0118 - val_mae: 0.0175\n",
      "Epoch 25/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0116 - mae: 0.0145 - val_loss: 0.0114 - val_mae: 0.0138\n",
      "Epoch 26/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0114 - mae: 0.0135 - val_loss: 0.0110 - val_mae: 0.0086\n",
      "Epoch 27/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0112 - mae: 0.0146 - val_loss: 0.0112 - val_mae: 0.0169\n",
      "Epoch 28/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0110 - mae: 0.0123 - val_loss: 0.0111 - val_mae: 0.0162\n",
      "Epoch 29/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0109 - mae: 0.0130 - val_loss: 0.0108 - val_mae: 0.0162\n",
      "Epoch 30/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0107 - mae: 0.0141 - val_loss: 0.0119 - val_mae: 0.0292\n",
      "Epoch 31/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0106 - mae: 0.0140 - val_loss: 0.0104 - val_mae: 0.0137\n",
      "Epoch 32/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0102 - mae: 0.0099 - val_loss: 0.0103 - val_mae: 0.0151\n",
      "Epoch 33/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0103 - mae: 0.0144 - val_loss: 0.0103 - val_mae: 0.0169\n",
      "Epoch 34/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0099 - mae: 0.0106 - val_loss: 0.0098 - val_mae: 0.0093\n",
      "Epoch 35/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0099 - mae: 0.0133 - val_loss: 0.0103 - val_mae: 0.0233\n",
      "Epoch 36/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0099 - mae: 0.0153 - val_loss: 0.0095 - val_mae: 0.0103\n",
      "Epoch 37/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0098 - mae: 0.0151 - val_loss: 0.0094 - val_mae: 0.0089\n",
      "Epoch 38/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0093 - mae: 0.0096 - val_loss: 0.0093 - val_mae: 0.0105\n",
      "Epoch 39/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0093 - mae: 0.0116 - val_loss: 0.0090 - val_mae: 0.0067\n",
      "Epoch 40/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0090 - mae: 0.0079 - val_loss: 0.0089 - val_mae: 0.0074\n",
      "Epoch 41/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0089 - mae: 0.0096 - val_loss: 0.0088 - val_mae: 0.0082\n",
      "Epoch 42/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0088 - mae: 0.0098 - val_loss: 0.0087 - val_mae: 0.0084\n",
      "Epoch 43/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0089 - mae: 0.0135 - val_loss: 0.0089 - val_mae: 0.0159\n",
      "Epoch 44/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0086 - mae: 0.0102 - val_loss: 0.0084 - val_mae: 0.0085\n",
      "Epoch 45/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0085 - mae: 0.0115 - val_loss: 0.0085 - val_mae: 0.0130\n",
      "Epoch 46/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0086 - mae: 0.0143 - val_loss: 0.0084 - val_mae: 0.0135\n",
      "Epoch 47/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0081 - mae: 0.0078 - val_loss: 0.0081 - val_mae: 0.0096\n",
      "Epoch 48/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0081 - mae: 0.0093 - val_loss: 0.0080 - val_mae: 0.0088\n",
      "Epoch 49/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0079 - mae: 0.0090 - val_loss: 0.0080 - val_mae: 0.0118\n",
      "Epoch 50/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0078 - mae: 0.0093 - val_loss: 0.0077 - val_mae: 0.0068\n",
      "Epoch 51/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0081 - mae: 0.0148 - val_loss: 0.0075 - val_mae: 0.0051\n",
      "Epoch 52/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0076 - mae: 0.0079 - val_loss: 0.0077 - val_mae: 0.0121\n",
      "Epoch 53/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0075 - mae: 0.0076 - val_loss: 0.0076 - val_mae: 0.0146\n",
      "Epoch 54/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0074 - mae: 0.0101 - val_loss: 0.0073 - val_mae: 0.0081\n",
      "Epoch 55/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0073 - mae: 0.0097 - val_loss: 0.0072 - val_mae: 0.0081\n",
      "Epoch 56/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0072 - mae: 0.0093 - val_loss: 0.0071 - val_mae: 0.0077\n",
      "Epoch 57/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0071 - mae: 0.0102 - val_loss: 0.0070 - val_mae: 0.0095\n",
      "Epoch 58/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0070 - mae: 0.0085 - val_loss: 0.0069 - val_mae: 0.0081\n",
      "Epoch 59/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0068 - mae: 0.0070 - val_loss: 0.0068 - val_mae: 0.0081\n",
      "Epoch 60/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0068 - mae: 0.0099 - val_loss: 0.0067 - val_mae: 0.0079\n",
      "Epoch 61/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0066 - mae: 0.0070 - val_loss: 0.0066 - val_mae: 0.0091\n",
      "Epoch 62/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0067 - mae: 0.0105 - val_loss: 0.0065 - val_mae: 0.0077\n",
      "Epoch 63/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0064 - mae: 0.0068 - val_loss: 0.0063 - val_mae: 0.0060\n",
      "Epoch 64/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0063 - mae: 0.0082 - val_loss: 0.0065 - val_mae: 0.0144\n",
      "Epoch 65/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0063 - mae: 0.0090 - val_loss: 0.0061 - val_mae: 0.0056\n",
      "Epoch 66/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0061 - mae: 0.0072 - val_loss: 0.0060 - val_mae: 0.0057\n",
      "Epoch 67/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0061 - mae: 0.0090 - val_loss: 0.0061 - val_mae: 0.0114\n",
      "Epoch 68/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0061 - mae: 0.0103 - val_loss: 0.0062 - val_mae: 0.0160\n",
      "Epoch 69/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0059 - mae: 0.0076 - val_loss: 0.0058 - val_mae: 0.0073\n",
      "Epoch 70/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0058 - mae: 0.0071 - val_loss: 0.0059 - val_mae: 0.0118\n",
      "Epoch 71/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0057 - mae: 0.0074 - val_loss: 0.0057 - val_mae: 0.0080\n",
      "Epoch 72/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0056 - mae: 0.0067 - val_loss: 0.0056 - val_mae: 0.0071\n",
      "Epoch 73/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0056 - mae: 0.0086 - val_loss: 0.0055 - val_mae: 0.0066\n",
      "Epoch 74/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0055 - mae: 0.0068 - val_loss: 0.0057 - val_mae: 0.0163\n",
      "Epoch 75/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0054 - mae: 0.0086 - val_loss: 0.0053 - val_mae: 0.0075\n",
      "Epoch 76/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0053 - mae: 0.0070 - val_loss: 0.0054 - val_mae: 0.0106\n",
      "Epoch 77/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0053 - mae: 0.0091 - val_loss: 0.0051 - val_mae: 0.0046\n",
      "Epoch 78/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0052 - mae: 0.0076 - val_loss: 0.0051 - val_mae: 0.0067\n",
      "Epoch 79/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0051 - mae: 0.0066 - val_loss: 0.0050 - val_mae: 0.0080\n",
      "Epoch 80/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0050 - mae: 0.0066 - val_loss: 0.0050 - val_mae: 0.0072\n",
      "Epoch 81/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0049 - mae: 0.0068 - val_loss: 0.0049 - val_mae: 0.0083\n",
      "Epoch 82/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0049 - mae: 0.0073 - val_loss: 0.0048 - val_mae: 0.0052\n",
      "Epoch 83/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0048 - mae: 0.0080 - val_loss: 0.0047 - val_mae: 0.0067\n",
      "Epoch 84/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0047 - mae: 0.0055 - val_loss: 0.0046 - val_mae: 0.0046\n",
      "Epoch 85/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0047 - mae: 0.0092 - val_loss: 0.0046 - val_mae: 0.0060\n",
      "Epoch 86/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0045 - mae: 0.0054 - val_loss: 0.0045 - val_mae: 0.0057\n",
      "Epoch 87/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0045 - mae: 0.0063 - val_loss: 0.0045 - val_mae: 0.0075\n",
      "Epoch 88/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0044 - mae: 0.0048 - val_loss: 0.0044 - val_mae: 0.0056\n",
      "Epoch 89/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0044 - mae: 0.0078 - val_loss: 0.0043 - val_mae: 0.0059\n",
      "Epoch 90/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0043 - mae: 0.0061 - val_loss: 0.0042 - val_mae: 0.0034\n",
      "Epoch 91/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0043 - mae: 0.0074 - val_loss: 0.0042 - val_mae: 0.0061\n",
      "Epoch 92/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0042 - mae: 0.0063 - val_loss: 0.0043 - val_mae: 0.0133\n",
      "Epoch 93/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0041 - mae: 0.0061 - val_loss: 0.0041 - val_mae: 0.0077\n",
      "Epoch 94/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0041 - mae: 0.0074 - val_loss: 0.0041 - val_mae: 0.0088\n",
      "Epoch 95/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0040 - mae: 0.0062 - val_loss: 0.0040 - val_mae: 0.0060\n",
      "Epoch 96/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0040 - mae: 0.0073 - val_loss: 0.0039 - val_mae: 0.0047\n",
      "Epoch 97/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0039 - mae: 0.0059 - val_loss: 0.0040 - val_mae: 0.0105\n",
      "Epoch 98/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0039 - mae: 0.0083 - val_loss: 0.0038 - val_mae: 0.0055\n",
      "Epoch 99/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0038 - mae: 0.0044 - val_loss: 0.0038 - val_mae: 0.0061\n",
      "Epoch 100/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0038 - mae: 0.0064 - val_loss: 0.0037 - val_mae: 0.0043\n",
      "Epoch 101/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0051 - val_loss: 0.0036 - val_mae: 0.0048\n",
      "Epoch 102/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0056 - val_loss: 0.0036 - val_mae: 0.0058\n",
      "Epoch 103/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0053 - val_loss: 0.0035 - val_mae: 0.0042\n",
      "Epoch 104/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0060 - val_loss: 0.0036 - val_mae: 0.0083\n",
      "Epoch 105/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0063 - val_loss: 0.0034 - val_mae: 0.0044\n",
      "Epoch 106/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0060 - val_loss: 0.0034 - val_mae: 0.0051\n",
      "Epoch 107/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0056 - val_loss: 0.0036 - val_mae: 0.0141\n",
      "Epoch 108/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0071 - val_loss: 0.0033 - val_mae: 0.0052\n",
      "Epoch 109/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0057 - val_loss: 0.0033 - val_mae: 0.0077\n",
      "Epoch 110/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0032 - mae: 0.0056 - val_loss: 0.0032 - val_mae: 0.0047\n",
      "Epoch 111/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0032 - mae: 0.0066 - val_loss: 0.0032 - val_mae: 0.0078\n",
      "Epoch 112/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0032 - mae: 0.0057 - val_loss: 0.0031 - val_mae: 0.0053\n",
      "Epoch 113/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0031 - mae: 0.0049 - val_loss: 0.0031 - val_mae: 0.0033\n",
      "Epoch 114/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0031 - mae: 0.0052 - val_loss: 0.0030 - val_mae: 0.0051\n",
      "Epoch 115/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0062 - val_loss: 0.0030 - val_mae: 0.0076\n",
      "Epoch 116/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0057 - val_loss: 0.0030 - val_mae: 0.0045\n",
      "Epoch 117/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0058 - val_loss: 0.0029 - val_mae: 0.0047\n",
      "Epoch 118/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0029 - mae: 0.0045 - val_loss: 0.0029 - val_mae: 0.0044\n",
      "Epoch 119/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0029 - mae: 0.0053 - val_loss: 0.0028 - val_mae: 0.0055\n",
      "Epoch 120/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0028 - mae: 0.0055 - val_loss: 0.0028 - val_mae: 0.0073\n",
      "Epoch 121/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0028 - mae: 0.0059 - val_loss: 0.0029 - val_mae: 0.0112\n",
      "Epoch 122/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0028 - mae: 0.0063 - val_loss: 0.0027 - val_mae: 0.0053\n",
      "Epoch 123/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0027 - mae: 0.0055 - val_loss: 0.0027 - val_mae: 0.0052\n",
      "Epoch 124/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0027 - mae: 0.0050 - val_loss: 0.0026 - val_mae: 0.0045\n",
      "Epoch 125/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0053 - val_loss: 0.0026 - val_mae: 0.0049\n",
      "Epoch 126/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0047 - val_loss: 0.0026 - val_mae: 0.0042\n",
      "Epoch 127/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0050 - val_loss: 0.0025 - val_mae: 0.0059\n",
      "Epoch 128/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0056 - val_loss: 0.0025 - val_mae: 0.0039\n",
      "Epoch 129/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0047 - val_loss: 0.0025 - val_mae: 0.0049\n",
      "Epoch 130/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0055 - val_loss: 0.0024 - val_mae: 0.0032\n",
      "Epoch 131/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0047 - val_loss: 0.0024 - val_mae: 0.0036\n",
      "Epoch 132/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0049 - val_loss: 0.0025 - val_mae: 0.0103\n",
      "Epoch 133/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0056 - val_loss: 0.0024 - val_mae: 0.0065\n",
      "Epoch 134/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0059 - val_loss: 0.0023 - val_mae: 0.0060\n",
      "Epoch 135/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0043 - val_loss: 0.0023 - val_mae: 0.0049\n",
      "Epoch 136/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0048 - val_loss: 0.0022 - val_mae: 0.0047\n",
      "Epoch 137/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0061 - val_loss: 0.0022 - val_mae: 0.0032\n",
      "Epoch 138/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0048 - val_loss: 0.0022 - val_mae: 0.0043\n",
      "Epoch 139/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0040 - val_loss: 0.0021 - val_mae: 0.0033\n",
      "Epoch 140/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0051 - val_loss: 0.0021 - val_mae: 0.0040\n",
      "Epoch 141/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0049 - val_loss: 0.0021 - val_mae: 0.0032\n",
      "Epoch 142/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0039 - val_loss: 0.0021 - val_mae: 0.0086\n",
      "Epoch 143/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0048 - val_loss: 0.0020 - val_mae: 0.0041\n",
      "Epoch 144/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0041 - val_loss: 0.0020 - val_mae: 0.0046\n",
      "Epoch 145/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0041 - val_loss: 0.0020 - val_mae: 0.0054\n",
      "Epoch 146/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0066 - val_loss: 0.0022 - val_mae: 0.0133\n",
      "Epoch 147/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0045 - val_loss: 0.0020 - val_mae: 0.0101\n",
      "Epoch 148/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0047 - val_loss: 0.0019 - val_mae: 0.0035\n",
      "Epoch 149/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0040 - val_loss: 0.0019 - val_mae: 0.0039\n",
      "Epoch 150/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0044 - val_loss: 0.0019 - val_mae: 0.0078\n",
      "Epoch 151/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0053 - val_loss: 0.0018 - val_mae: 0.0035\n",
      "Epoch 152/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0018 - mae: 0.0055 - val_loss: 0.0018 - val_mae: 0.0051\n",
      "Epoch 153/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0018 - mae: 0.0051 - val_loss: 0.0018 - val_mae: 0.0039\n",
      "Epoch 154/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0018 - mae: 0.0043 - val_loss: 0.0018 - val_mae: 0.0058\n",
      "Epoch 155/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0018 - mae: 0.0041 - val_loss: 0.0017 - val_mae: 0.0042\n",
      "Epoch 156/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0017 - mae: 0.0045 - val_loss: 0.0017 - val_mae: 0.0036\n",
      "Epoch 157/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0017 - mae: 0.0038 - val_loss: 0.0017 - val_mae: 0.0039\n",
      "Epoch 158/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0017 - mae: 0.0044 - val_loss: 0.0017 - val_mae: 0.0035\n",
      "Epoch 159/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0017 - mae: 0.0044 - val_loss: 0.0017 - val_mae: 0.0043\n",
      "Epoch 160/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0040 - val_loss: 0.0016 - val_mae: 0.0031\n",
      "Epoch 161/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0048 - val_loss: 0.0016 - val_mae: 0.0057\n",
      "Epoch 162/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0039 - val_loss: 0.0016 - val_mae: 0.0029\n",
      "Epoch 163/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0050 - val_loss: 0.0016 - val_mae: 0.0047\n",
      "Epoch 164/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0058 - val_loss: 0.0016 - val_mae: 0.0053\n",
      "Epoch 165/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0038 - val_loss: 0.0015 - val_mae: 0.0044\n",
      "Epoch 166/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 0.0015 - val_mae: 0.0058\n",
      "Epoch 167/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0040 - val_loss: 0.0015 - val_mae: 0.0039\n",
      "Epoch 168/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0048 - val_loss: 0.0015 - val_mae: 0.0042\n",
      "Epoch 169/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0043\n",
      "Epoch 170/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0039 - val_loss: 0.0015 - val_mae: 0.0081\n",
      "Epoch 171/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0051 - val_loss: 0.0014 - val_mae: 0.0029\n",
      "Epoch 172/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0038\n",
      "Epoch 173/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0038 - val_loss: 0.0014 - val_mae: 0.0030\n",
      "Epoch 174/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0036 - val_loss: 0.0014 - val_mae: 0.0041\n",
      "Epoch 175/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0028\n",
      "Epoch 176/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0039\n",
      "Epoch 177/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0040 - val_loss: 0.0013 - val_mae: 0.0039\n",
      "Epoch 178/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0035\n",
      "Epoch 179/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0038 - val_loss: 0.0013 - val_mae: 0.0030\n",
      "Epoch 180/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0072 - val_loss: 0.0013 - val_mae: 0.0048\n",
      "Epoch 181/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0035 - val_loss: 0.0013 - val_mae: 0.0025\n",
      "Epoch 182/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0036 - val_loss: 0.0013 - val_mae: 0.0053\n",
      "Epoch 183/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0034 - val_loss: 0.0012 - val_mae: 0.0043\n",
      "Epoch 184/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0040 - val_loss: 0.0012 - val_mae: 0.0032\n",
      "Epoch 185/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0048 - val_loss: 0.0012 - val_mae: 0.0042\n",
      "Epoch 186/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0044 - val_loss: 0.0012 - val_mae: 0.0034\n",
      "Epoch 187/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0039 - val_loss: 0.0012 - val_mae: 0.0037\n",
      "Epoch 188/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0040 - val_loss: 0.0012 - val_mae: 0.0032\n",
      "Epoch 189/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0033\n",
      "Epoch 190/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0034 - val_loss: 0.0011 - val_mae: 0.0042\n",
      "Epoch 191/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0042\n",
      "Epoch 192/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0032\n",
      "Epoch 193/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0051 - val_loss: 0.0011 - val_mae: 0.0049\n",
      "Epoch 194/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0044\n",
      "Epoch 195/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0037 - val_loss: 0.0011 - val_mae: 0.0038\n",
      "Epoch 196/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0035 - val_loss: 0.0011 - val_mae: 0.0042\n",
      "Epoch 197/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 198/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0048\n",
      "Epoch 199/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0037 - val_loss: 0.0010 - val_mae: 0.0033\n",
      "Epoch 200/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0042 - val_loss: 0.0010 - val_mae: 0.0030\n",
      "Epoch 201/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0041 - val_loss: 0.0010 - val_mae: 0.0039\n",
      "Epoch 202/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0038 - val_loss: 9.9547e-04 - val_mae: 0.0038\n",
      "Epoch 203/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 9.9363e-04 - mae: 0.0037 - val_loss: 9.8527e-04 - val_mae: 0.0037\n",
      "Epoch 204/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 9.8881e-04 - mae: 0.0042 - val_loss: 9.6615e-04 - val_mae: 0.0028\n",
      "Epoch 205/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 9.8079e-04 - mae: 0.0042 - val_loss: 9.8389e-04 - val_mae: 0.0053\n",
      "Epoch 206/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 9.5922e-04 - mae: 0.0036 - val_loss: 9.4948e-04 - val_mae: 0.0033\n",
      "Epoch 207/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 9.5207e-04 - mae: 0.0038 - val_loss: 9.4479e-04 - val_mae: 0.0038\n",
      "Epoch 208/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 9.3980e-04 - mae: 0.0037 - val_loss: 9.4040e-04 - val_mae: 0.0039\n",
      "Epoch 209/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 9.2958e-04 - mae: 0.0037 - val_loss: 9.2021e-04 - val_mae: 0.0031\n",
      "Epoch 210/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 9.1955e-04 - mae: 0.0037 - val_loss: 9.0550e-04 - val_mae: 0.0029\n",
      "Epoch 211/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 9.3367e-04 - mae: 0.0050 - val_loss: 8.9709e-04 - val_mae: 0.0031\n",
      "Epoch 212/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 8.9603e-04 - mae: 0.0033 - val_loss: 8.8873e-04 - val_mae: 0.0033\n",
      "Epoch 213/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 9.1046e-04 - mae: 0.0046 - val_loss: 8.7590e-04 - val_mae: 0.0026\n",
      "Epoch 214/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 8.7869e-04 - mae: 0.0033 - val_loss: 8.7378e-04 - val_mae: 0.0032\n",
      "Epoch 215/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 8.8196e-04 - mae: 0.0041 - val_loss: 8.5846e-04 - val_mae: 0.0025\n",
      "Epoch 216/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 8.6798e-04 - mae: 0.0038 - val_loss: 8.9049e-04 - val_mae: 0.0057\n",
      "Epoch 217/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 8.5334e-04 - mae: 0.0033 - val_loss: 8.6220e-04 - val_mae: 0.0043\n",
      "Epoch 218/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 8.5538e-04 - mae: 0.0040 - val_loss: 8.5818e-04 - val_mae: 0.0045\n",
      "Epoch 219/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 8.3844e-04 - mae: 0.0035 - val_loss: 8.2712e-04 - val_mae: 0.0027\n",
      "Epoch 220/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 8.3746e-04 - mae: 0.0040 - val_loss: 8.1458e-04 - val_mae: 0.0024\n",
      "Epoch 221/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 8.2391e-04 - mae: 0.0036 - val_loss: 8.1999e-04 - val_mae: 0.0040\n",
      "Epoch 222/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 8.1914e-04 - mae: 0.0040 - val_loss: 8.1266e-04 - val_mae: 0.0035\n",
      "Epoch 223/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 8.0576e-04 - mae: 0.0036 - val_loss: 8.1312e-04 - val_mae: 0.0045\n",
      "Epoch 224/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 8.1461e-04 - mae: 0.0046 - val_loss: 8.1599e-04 - val_mae: 0.0051\n",
      "Epoch 225/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.9061e-04 - mae: 0.0036 - val_loss: 7.8000e-04 - val_mae: 0.0030\n",
      "Epoch 226/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.8711e-04 - mae: 0.0038 - val_loss: 7.8410e-04 - val_mae: 0.0041\n",
      "Epoch 227/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.7974e-04 - mae: 0.0039 - val_loss: 7.8064e-04 - val_mae: 0.0044\n",
      "Epoch 228/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.7081e-04 - mae: 0.0037 - val_loss: 7.7179e-04 - val_mae: 0.0044\n",
      "Epoch 229/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.6402e-04 - mae: 0.0038 - val_loss: 7.6985e-04 - val_mae: 0.0048\n",
      "Epoch 230/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.5741e-04 - mae: 0.0037 - val_loss: 7.4460e-04 - val_mae: 0.0029\n",
      "Epoch 231/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.4821e-04 - mae: 0.0036 - val_loss: 7.4514e-04 - val_mae: 0.0039\n",
      "Epoch 232/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.5042e-04 - mae: 0.0041 - val_loss: 7.3862e-04 - val_mae: 0.0037\n",
      "Epoch 233/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.3443e-04 - mae: 0.0035 - val_loss: 7.9521e-04 - val_mae: 0.0065\n",
      "Epoch 234/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.3000e-04 - mae: 0.0038 - val_loss: 7.4315e-04 - val_mae: 0.0050\n",
      "Epoch 235/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.2430e-04 - mae: 0.0038 - val_loss: 7.2291e-04 - val_mae: 0.0037\n",
      "Epoch 236/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.1595e-04 - mae: 0.0036 - val_loss: 7.2417e-04 - val_mae: 0.0040\n",
      "Epoch 237/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.0411e-04 - mae: 0.0033 - val_loss: 6.9490e-04 - val_mae: 0.0027\n",
      "Epoch 238/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.0360e-04 - mae: 0.0037 - val_loss: 6.9120e-04 - val_mae: 0.0033\n",
      "Epoch 239/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.9387e-04 - mae: 0.0036 - val_loss: 6.8555e-04 - val_mae: 0.0033\n",
      "Epoch 240/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.9356e-04 - mae: 0.0039 - val_loss: 6.8053e-04 - val_mae: 0.0035\n",
      "Epoch 241/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.9550e-04 - mae: 0.0043 - val_loss: 6.7441e-04 - val_mae: 0.0034\n",
      "Epoch 242/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.9060e-04 - mae: 0.0045 - val_loss: 6.6235e-04 - val_mae: 0.0025\n",
      "Epoch 243/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.6321e-04 - mae: 0.0030 - val_loss: 6.6003e-04 - val_mae: 0.0028\n",
      "Epoch 244/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.6229e-04 - mae: 0.0034 - val_loss: 6.5403e-04 - val_mae: 0.0030\n",
      "Epoch 245/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.5549e-04 - mae: 0.0033 - val_loss: 6.5050e-04 - val_mae: 0.0033\n",
      "Epoch 246/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.6548e-04 - mae: 0.0042 - val_loss: 6.5971e-04 - val_mae: 0.0042\n",
      "Epoch 247/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.4501e-04 - mae: 0.0034 - val_loss: 6.3806e-04 - val_mae: 0.0032\n",
      "Epoch 248/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.4411e-04 - mae: 0.0036 - val_loss: 6.3798e-04 - val_mae: 0.0038\n",
      "Epoch 249/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.3030e-04 - mae: 0.0031 - val_loss: 6.2532e-04 - val_mae: 0.0031\n",
      "Epoch 250/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.3143e-04 - mae: 0.0037 - val_loss: 6.2020e-04 - val_mae: 0.0028\n",
      "Epoch 251/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.2243e-04 - mae: 0.0034 - val_loss: 6.4832e-04 - val_mae: 0.0057\n",
      "Epoch 252/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.2529e-04 - mae: 0.0039 - val_loss: 6.0583e-04 - val_mae: 0.0025\n",
      "Epoch 253/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.1429e-04 - mae: 0.0036 - val_loss: 6.3185e-04 - val_mae: 0.0056\n",
      "Epoch 254/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.0712e-04 - mae: 0.0034 - val_loss: 6.1152e-04 - val_mae: 0.0041\n",
      "Epoch 255/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.0131e-04 - mae: 0.0033 - val_loss: 5.8910e-04 - val_mae: 0.0024\n",
      "Epoch 256/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.9496e-04 - mae: 0.0033 - val_loss: 5.9121e-04 - val_mae: 0.0032\n",
      "Epoch 257/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.8630e-04 - mae: 0.0030 - val_loss: 5.7807e-04 - val_mae: 0.0023\n",
      "Epoch 258/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.8664e-04 - mae: 0.0035 - val_loss: 5.7837e-04 - val_mae: 0.0029\n",
      "Epoch 259/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.9144e-04 - mae: 0.0043 - val_loss: 5.8892e-04 - val_mae: 0.0045\n",
      "Epoch 260/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.8348e-04 - mae: 0.0039 - val_loss: 5.9084e-04 - val_mae: 0.0045\n",
      "Epoch 261/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.7696e-04 - mae: 0.0038 - val_loss: 6.1583e-04 - val_mae: 0.0062\n",
      "Epoch 262/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.6575e-04 - mae: 0.0033 - val_loss: 5.5666e-04 - val_mae: 0.0028\n",
      "Epoch 263/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.6532e-04 - mae: 0.0036 - val_loss: 5.5071e-04 - val_mae: 0.0024\n",
      "Epoch 264/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.6478e-04 - mae: 0.0038 - val_loss: 5.8346e-04 - val_mae: 0.0050\n",
      "Epoch 265/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.5366e-04 - mae: 0.0034 - val_loss: 5.5121e-04 - val_mae: 0.0031\n",
      "Epoch 266/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.5242e-04 - mae: 0.0035 - val_loss: 6.1199e-04 - val_mae: 0.0081\n",
      "Epoch 267/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.4602e-04 - mae: 0.0033 - val_loss: 5.5483e-04 - val_mae: 0.0042\n",
      "Epoch 268/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.4079e-04 - mae: 0.0034 - val_loss: 5.3506e-04 - val_mae: 0.0029\n",
      "Epoch 269/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.4111e-04 - mae: 0.0038 - val_loss: 5.4106e-04 - val_mae: 0.0045\n",
      "Epoch 270/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.3036e-04 - mae: 0.0032 - val_loss: 5.2771e-04 - val_mae: 0.0034\n",
      "Epoch 271/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.2535e-04 - mae: 0.0032 - val_loss: 5.1860e-04 - val_mae: 0.0025\n",
      "Epoch 272/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.2196e-04 - mae: 0.0032 - val_loss: 5.1517e-04 - val_mae: 0.0029\n",
      "Epoch 273/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.2206e-04 - mae: 0.0036 - val_loss: 5.2719e-04 - val_mae: 0.0042\n",
      "Epoch 274/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.2203e-04 - mae: 0.0039 - val_loss: 5.2700e-04 - val_mae: 0.0049\n",
      "Epoch 275/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.1365e-04 - mae: 0.0035 - val_loss: 5.1099e-04 - val_mae: 0.0038\n",
      "Epoch 276/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.0548e-04 - mae: 0.0033 - val_loss: 5.1670e-04 - val_mae: 0.0044\n",
      "Epoch 277/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.1265e-04 - mae: 0.0040 - val_loss: 4.9291e-04 - val_mae: 0.0026\n",
      "Epoch 278/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.0237e-04 - mae: 0.0036 - val_loss: 5.0011e-04 - val_mae: 0.0038\n",
      "Epoch 279/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.9301e-04 - mae: 0.0031 - val_loss: 4.9138e-04 - val_mae: 0.0031\n",
      "Epoch 280/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.1119e-04 - mae: 0.0047 - val_loss: 4.9493e-04 - val_mae: 0.0037\n",
      "Epoch 281/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.8838e-04 - mae: 0.0032 - val_loss: 4.7927e-04 - val_mae: 0.0025\n",
      "Epoch 282/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.8351e-04 - mae: 0.0031 - val_loss: 4.7548e-04 - val_mae: 0.0025\n",
      "Epoch 283/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.8374e-04 - mae: 0.0034 - val_loss: 5.1173e-04 - val_mae: 0.0056\n",
      "Epoch 284/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.7777e-04 - mae: 0.0033 - val_loss: 4.7186e-04 - val_mae: 0.0029\n",
      "Epoch 285/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.7914e-04 - mae: 0.0037 - val_loss: 4.9725e-04 - val_mae: 0.0059\n",
      "Epoch 286/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.6762e-04 - mae: 0.0030 - val_loss: 4.6281e-04 - val_mae: 0.0026\n",
      "Epoch 287/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.8189e-04 - mae: 0.0040 - val_loss: 7.0977e-04 - val_mae: 0.0134\n",
      "Epoch 288/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.6802e-04 - mae: 0.0034 - val_loss: 4.5472e-04 - val_mae: 0.0025\n",
      "Epoch 289/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.5849e-04 - mae: 0.0030 - val_loss: 4.6589e-04 - val_mae: 0.0036\n",
      "Epoch 290/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.6176e-04 - mae: 0.0036 - val_loss: 4.5395e-04 - val_mae: 0.0032\n",
      "Epoch 291/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.5409e-04 - mae: 0.0032 - val_loss: 4.5984e-04 - val_mae: 0.0035\n",
      "Epoch 292/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.5005e-04 - mae: 0.0032 - val_loss: 4.4402e-04 - val_mae: 0.0028\n",
      "Epoch 293/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.4579e-04 - mae: 0.0031 - val_loss: 4.4721e-04 - val_mae: 0.0034\n",
      "Epoch 294/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.4725e-04 - mae: 0.0034 - val_loss: 4.6584e-04 - val_mae: 0.0053\n",
      "Epoch 295/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.4307e-04 - mae: 0.0034 - val_loss: 4.3698e-04 - val_mae: 0.0029\n",
      "Epoch 296/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.4114e-04 - mae: 0.0036 - val_loss: 4.6304e-04 - val_mae: 0.0059\n",
      "Epoch 297/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.4313e-04 - mae: 0.0038 - val_loss: 4.8852e-04 - val_mae: 0.0067\n",
      "Epoch 298/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.3707e-04 - mae: 0.0035 - val_loss: 4.2513e-04 - val_mae: 0.0027\n",
      "Epoch 299/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.3385e-04 - mae: 0.0035 - val_loss: 4.3586e-04 - val_mae: 0.0039\n",
      "Epoch 300/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.2778e-04 - mae: 0.0033 - val_loss: 4.2919e-04 - val_mae: 0.0038\n",
      "Epoch 301/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.2502e-04 - mae: 0.0034 - val_loss: 4.1687e-04 - val_mae: 0.0027\n",
      "Epoch 302/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.2295e-04 - mae: 0.0034 - val_loss: 4.1644e-04 - val_mae: 0.0030\n",
      "Epoch 303/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.1677e-04 - mae: 0.0031 - val_loss: 4.3151e-04 - val_mae: 0.0039\n",
      "Epoch 304/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.1695e-04 - mae: 0.0034 - val_loss: 4.1416e-04 - val_mae: 0.0034\n",
      "Epoch 305/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.1041e-04 - mae: 0.0031 - val_loss: 4.0680e-04 - val_mae: 0.0029\n",
      "Epoch 306/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.1473e-04 - mae: 0.0036 - val_loss: 4.0306e-04 - val_mae: 0.0028\n",
      "Epoch 307/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.1184e-04 - mae: 0.0037 - val_loss: 3.9911e-04 - val_mae: 0.0026\n",
      "Epoch 308/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.0795e-04 - mae: 0.0036 - val_loss: 4.2309e-04 - val_mae: 0.0049\n",
      "Epoch 309/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.0391e-04 - mae: 0.0034 - val_loss: 4.3056e-04 - val_mae: 0.0062\n",
      "Epoch 310/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.9772e-04 - mae: 0.0031 - val_loss: 3.8974e-04 - val_mae: 0.0023\n",
      "Epoch 311/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.9448e-04 - mae: 0.0030 - val_loss: 3.8788e-04 - val_mae: 0.0026\n",
      "Epoch 312/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.9471e-04 - mae: 0.0032 - val_loss: 3.8793e-04 - val_mae: 0.0028\n",
      "Epoch 313/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.9190e-04 - mae: 0.0033 - val_loss: 3.9517e-04 - val_mae: 0.0036\n",
      "Epoch 314/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.9001e-04 - mae: 0.0032 - val_loss: 3.8458e-04 - val_mae: 0.0028\n",
      "Epoch 315/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.9201e-04 - mae: 0.0037 - val_loss: 3.7635e-04 - val_mae: 0.0022\n",
      "Epoch 316/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.8066e-04 - mae: 0.0029 - val_loss: 3.7813e-04 - val_mae: 0.0025\n",
      "Epoch 317/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.8194e-04 - mae: 0.0033 - val_loss: 3.7950e-04 - val_mae: 0.0030\n",
      "Epoch 318/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.8037e-04 - mae: 0.0034 - val_loss: 3.7514e-04 - val_mae: 0.0032\n",
      "Epoch 319/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.7892e-04 - mae: 0.0035 - val_loss: 3.8727e-04 - val_mae: 0.0042\n",
      "Epoch 320/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.7344e-04 - mae: 0.0032 - val_loss: 3.7256e-04 - val_mae: 0.0030\n",
      "Epoch 321/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.7222e-04 - mae: 0.0032 - val_loss: 3.6528e-04 - val_mae: 0.0027\n",
      "Epoch 322/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.7181e-04 - mae: 0.0034 - val_loss: 3.6617e-04 - val_mae: 0.0032\n",
      "Epoch 323/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.7018e-04 - mae: 0.0034 - val_loss: 3.6093e-04 - val_mae: 0.0028\n",
      "Epoch 324/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.6257e-04 - mae: 0.0030 - val_loss: 3.8050e-04 - val_mae: 0.0048\n",
      "Epoch 325/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.6610e-04 - mae: 0.0035 - val_loss: 3.7979e-04 - val_mae: 0.0047\n",
      "Epoch 326/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.6551e-04 - mae: 0.0035 - val_loss: 3.5481e-04 - val_mae: 0.0028\n",
      "Epoch 327/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.5932e-04 - mae: 0.0033 - val_loss: 3.5893e-04 - val_mae: 0.0032\n",
      "Epoch 328/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.5667e-04 - mae: 0.0032 - val_loss: 3.5713e-04 - val_mae: 0.0032\n",
      "Epoch 329/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.5392e-04 - mae: 0.0032 - val_loss: 3.4352e-04 - val_mae: 0.0020\n",
      "Epoch 330/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.5487e-04 - mae: 0.0034 - val_loss: 3.4433e-04 - val_mae: 0.0024\n",
      "Epoch 331/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.5393e-04 - mae: 0.0034 - val_loss: 3.7454e-04 - val_mae: 0.0052\n",
      "Epoch 332/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.5543e-04 - mae: 0.0036 - val_loss: 3.4198e-04 - val_mae: 0.0026\n",
      "Epoch 333/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.4377e-04 - mae: 0.0029 - val_loss: 3.3642e-04 - val_mae: 0.0022\n",
      "Epoch 334/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.4385e-04 - mae: 0.0031 - val_loss: 3.3801e-04 - val_mae: 0.0024\n",
      "Epoch 335/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.4241e-04 - mae: 0.0031 - val_loss: 3.4552e-04 - val_mae: 0.0038\n",
      "Epoch 336/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.3892e-04 - mae: 0.0030 - val_loss: 3.4187e-04 - val_mae: 0.0035\n",
      "Epoch 337/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.4256e-04 - mae: 0.0034 - val_loss: 3.3227e-04 - val_mae: 0.0027\n",
      "Epoch 338/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.3739e-04 - mae: 0.0032 - val_loss: 3.6017e-04 - val_mae: 0.0046\n",
      "Epoch 339/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.3525e-04 - mae: 0.0032 - val_loss: 3.3550e-04 - val_mae: 0.0032\n",
      "Epoch 340/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.4243e-04 - mae: 0.0038 - val_loss: 3.3469e-04 - val_mae: 0.0034\n",
      "Epoch 341/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.3128e-04 - mae: 0.0032 - val_loss: 3.2575e-04 - val_mae: 0.0028\n",
      "Epoch 342/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.3097e-04 - mae: 0.0033 - val_loss: 3.2515e-04 - val_mae: 0.0030\n",
      "Epoch 343/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.2578e-04 - mae: 0.0030 - val_loss: 3.2051e-04 - val_mae: 0.0026\n",
      "Epoch 344/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.2948e-04 - mae: 0.0034 - val_loss: 3.1968e-04 - val_mae: 0.0025\n",
      "Epoch 345/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.2631e-04 - mae: 0.0033 - val_loss: 3.1510e-04 - val_mae: 0.0023\n",
      "Epoch 346/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.1885e-04 - mae: 0.0028 - val_loss: 3.1911e-04 - val_mae: 0.0030\n",
      "Epoch 347/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.2467e-04 - mae: 0.0033 - val_loss: 3.2710e-04 - val_mae: 0.0038\n",
      "Epoch 348/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.2006e-04 - mae: 0.0032 - val_loss: 3.1298e-04 - val_mae: 0.0026\n",
      "Epoch 349/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.2038e-04 - mae: 0.0034 - val_loss: 3.2327e-04 - val_mae: 0.0037\n",
      "Epoch 350/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.2059e-04 - mae: 0.0035 - val_loss: 3.2968e-04 - val_mae: 0.0049\n",
      "Epoch 351/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.1395e-04 - mae: 0.0031 - val_loss: 3.1089e-04 - val_mae: 0.0030\n",
      "Epoch 352/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.1534e-04 - mae: 0.0033 - val_loss: 3.1242e-04 - val_mae: 0.0034\n",
      "Epoch 353/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.0938e-04 - mae: 0.0030 - val_loss: 3.2426e-04 - val_mae: 0.0047\n",
      "Epoch 354/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.1276e-04 - mae: 0.0033 - val_loss: 3.0840e-04 - val_mae: 0.0030\n",
      "Epoch 355/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.0485e-04 - mae: 0.0029 - val_loss: 3.0922e-04 - val_mae: 0.0034\n",
      "Epoch 356/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.1191e-04 - mae: 0.0035 - val_loss: 3.0914e-04 - val_mae: 0.0039\n",
      "Epoch 357/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.0749e-04 - mae: 0.0034 - val_loss: 3.0896e-04 - val_mae: 0.0037\n",
      "Epoch 358/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.9935e-04 - mae: 0.0028 - val_loss: 2.9737e-04 - val_mae: 0.0027\n",
      "Epoch 359/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.0284e-04 - mae: 0.0032 - val_loss: 2.9953e-04 - val_mae: 0.0032\n",
      "Epoch 360/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.9822e-04 - mae: 0.0030 - val_loss: 2.9522e-04 - val_mae: 0.0030\n",
      "Epoch 361/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.9767e-04 - mae: 0.0030 - val_loss: 2.9308e-04 - val_mae: 0.0027\n",
      "Epoch 362/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.9628e-04 - mae: 0.0031 - val_loss: 2.9341e-04 - val_mae: 0.0030\n",
      "Epoch 363/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.9589e-04 - mae: 0.0032 - val_loss: 2.8958e-04 - val_mae: 0.0028\n",
      "Epoch 364/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.9765e-04 - mae: 0.0035 - val_loss: 2.9638e-04 - val_mae: 0.0038\n",
      "Epoch 365/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.9437e-04 - mae: 0.0033 - val_loss: 2.8580e-04 - val_mae: 0.0026\n",
      "Epoch 366/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.9115e-04 - mae: 0.0032 - val_loss: 3.0295e-04 - val_mae: 0.0045\n",
      "Epoch 367/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.8663e-04 - mae: 0.0029 - val_loss: 2.9507e-04 - val_mae: 0.0038\n",
      "Epoch 368/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.8915e-04 - mae: 0.0031 - val_loss: 3.0019e-04 - val_mae: 0.0042\n",
      "Epoch 369/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.8773e-04 - mae: 0.0032 - val_loss: 2.9414e-04 - val_mae: 0.0032\n",
      "Epoch 370/1000\n",
      "368/375 [============================>.] - ETA: 0s - loss: 2.8353e-04 - mae: 0.0030Restoring model weights from the end of the best epoch: 365.\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.8363e-04 - mae: 0.0030 - val_loss: 3.0776e-04 - val_mae: 0.0050\n",
      "Epoch 370: early stopping\n",
      "Training fÃ¼r Fold 5...\n",
      "Epoch 1/1000\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.0616 - mae: 0.1375 - val_loss: 0.0363 - val_mae: 0.0889\n",
      "Epoch 2/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0273 - mae: 0.0677 - val_loss: 0.0225 - val_mae: 0.0489\n",
      "Epoch 3/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0206 - mae: 0.0431 - val_loss: 0.0193 - val_mae: 0.0412\n",
      "Epoch 4/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0186 - mae: 0.0359 - val_loss: 0.0179 - val_mae: 0.0343\n",
      "Epoch 5/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0177 - mae: 0.0311 - val_loss: 0.0174 - val_mae: 0.0315\n",
      "Epoch 6/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0167 - mae: 0.0238 - val_loss: 0.0163 - val_mae: 0.0176\n",
      "Epoch 7/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0165 - mae: 0.0238 - val_loss: 0.0177 - val_mae: 0.0361\n",
      "Epoch 8/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0161 - mae: 0.0214 - val_loss: 0.0163 - val_mae: 0.0286\n",
      "Epoch 9/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0158 - mae: 0.0201 - val_loss: 0.0152 - val_mae: 0.0127\n",
      "Epoch 10/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0167 - mae: 0.0296 - val_loss: 0.0171 - val_mae: 0.0411\n",
      "Epoch 11/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0153 - mae: 0.0184 - val_loss: 0.0153 - val_mae: 0.0204\n",
      "Epoch 12/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0152 - mae: 0.0200 - val_loss: 0.0154 - val_mae: 0.0229\n",
      "Epoch 13/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0150 - mae: 0.0187 - val_loss: 0.0158 - val_mae: 0.0292\n",
      "Epoch 14/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0151 - mae: 0.0234 - val_loss: 0.0143 - val_mae: 0.0122\n",
      "Epoch 15/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0144 - mae: 0.0153 - val_loss: 0.0142 - val_mae: 0.0137\n",
      "Epoch 16/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0146 - mae: 0.0210 - val_loss: 0.0141 - val_mae: 0.0166\n",
      "Epoch 17/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0141 - mae: 0.0159 - val_loss: 0.0137 - val_mae: 0.0105\n",
      "Epoch 18/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0141 - mae: 0.0192 - val_loss: 0.0139 - val_mae: 0.0197\n",
      "Epoch 19/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0138 - mae: 0.0173 - val_loss: 0.0132 - val_mae: 0.0079\n",
      "Epoch 20/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0139 - mae: 0.0203 - val_loss: 0.0133 - val_mae: 0.0157\n",
      "Epoch 21/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0134 - mae: 0.0169 - val_loss: 0.0130 - val_mae: 0.0106\n",
      "Epoch 22/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0129 - mae: 0.0123 - val_loss: 0.0129 - val_mae: 0.0140\n",
      "Epoch 23/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0129 - mae: 0.0154 - val_loss: 0.0129 - val_mae: 0.0177\n",
      "Epoch 24/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0130 - mae: 0.0168 - val_loss: 0.0153 - val_mae: 0.0419\n",
      "Epoch 25/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0127 - mae: 0.0161 - val_loss: 0.0122 - val_mae: 0.0091\n",
      "Epoch 26/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0124 - mae: 0.0150 - val_loss: 0.0128 - val_mae: 0.0240\n",
      "Epoch 27/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0125 - mae: 0.0190 - val_loss: 0.0127 - val_mae: 0.0261\n",
      "Epoch 28/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0119 - mae: 0.0136 - val_loss: 0.0117 - val_mae: 0.0094\n",
      "Epoch 29/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0118 - mae: 0.0125 - val_loss: 0.0123 - val_mae: 0.0236\n",
      "Epoch 30/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0117 - mae: 0.0151 - val_loss: 0.0116 - val_mae: 0.0141\n",
      "Epoch 31/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0115 - mae: 0.0139 - val_loss: 0.0116 - val_mae: 0.0181\n",
      "Epoch 32/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0113 - mae: 0.0148 - val_loss: 0.0111 - val_mae: 0.0112\n",
      "Epoch 33/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0111 - mae: 0.0135 - val_loss: 0.0109 - val_mae: 0.0105\n",
      "Epoch 34/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0112 - mae: 0.0174 - val_loss: 0.0111 - val_mae: 0.0161\n",
      "Epoch 35/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0108 - mae: 0.0137 - val_loss: 0.0105 - val_mae: 0.0082\n",
      "Epoch 36/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0104 - mae: 0.0087 - val_loss: 0.0104 - val_mae: 0.0097\n",
      "Epoch 37/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0104 - mae: 0.0122 - val_loss: 0.0102 - val_mae: 0.0097\n",
      "Epoch 38/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0105 - mae: 0.0150 - val_loss: 0.0120 - val_mae: 0.0338\n",
      "Epoch 39/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0102 - mae: 0.0138 - val_loss: 0.0098 - val_mae: 0.0069\n",
      "Epoch 40/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0098 - mae: 0.0087 - val_loss: 0.0098 - val_mae: 0.0099\n",
      "Epoch 41/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0098 - mae: 0.0107 - val_loss: 0.0096 - val_mae: 0.0078\n",
      "Epoch 42/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0098 - mae: 0.0142 - val_loss: 0.0096 - val_mae: 0.0138\n",
      "Epoch 43/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0094 - mae: 0.0101 - val_loss: 0.0094 - val_mae: 0.0111\n",
      "Epoch 44/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0093 - mae: 0.0105 - val_loss: 0.0094 - val_mae: 0.0148\n",
      "Epoch 45/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0092 - mae: 0.0113 - val_loss: 0.0093 - val_mae: 0.0141\n",
      "Epoch 46/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0090 - mae: 0.0106 - val_loss: 0.0089 - val_mae: 0.0088\n",
      "Epoch 47/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0092 - mae: 0.0161 - val_loss: 0.0087 - val_mae: 0.0073\n",
      "Epoch 48/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0088 - mae: 0.0115 - val_loss: 0.0086 - val_mae: 0.0088\n",
      "Epoch 49/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0086 - mae: 0.0102 - val_loss: 0.0086 - val_mae: 0.0120\n",
      "Epoch 50/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0085 - mae: 0.0097 - val_loss: 0.0084 - val_mae: 0.0100\n",
      "Epoch 51/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0084 - mae: 0.0097 - val_loss: 0.0082 - val_mae: 0.0069\n",
      "Epoch 52/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0082 - mae: 0.0097 - val_loss: 0.0083 - val_mae: 0.0147\n",
      "Epoch 53/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0086 - mae: 0.0179 - val_loss: 0.0080 - val_mae: 0.0084\n",
      "Epoch 54/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0079 - mae: 0.0070 - val_loss: 0.0079 - val_mae: 0.0075\n",
      "Epoch 55/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0079 - mae: 0.0091 - val_loss: 0.0077 - val_mae: 0.0082\n",
      "Epoch 56/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0077 - mae: 0.0082 - val_loss: 0.0077 - val_mae: 0.0081\n",
      "Epoch 57/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0076 - mae: 0.0083 - val_loss: 0.0075 - val_mae: 0.0059\n",
      "Epoch 58/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0076 - mae: 0.0111 - val_loss: 0.0074 - val_mae: 0.0082\n",
      "Epoch 59/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0074 - mae: 0.0083 - val_loss: 0.0073 - val_mae: 0.0080\n",
      "Epoch 60/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0072 - mae: 0.0081 - val_loss: 0.0073 - val_mae: 0.0122\n",
      "Epoch 61/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0072 - mae: 0.0094 - val_loss: 0.0070 - val_mae: 0.0063\n",
      "Epoch 62/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0072 - mae: 0.0109 - val_loss: 0.0069 - val_mae: 0.0070\n",
      "Epoch 63/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0069 - mae: 0.0085 - val_loss: 0.0068 - val_mae: 0.0058\n",
      "Epoch 64/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0068 - mae: 0.0081 - val_loss: 0.0071 - val_mae: 0.0152\n",
      "Epoch 65/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0069 - mae: 0.0120 - val_loss: 0.0066 - val_mae: 0.0075\n",
      "Epoch 66/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0066 - mae: 0.0079 - val_loss: 0.0066 - val_mae: 0.0105\n",
      "Epoch 67/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0067 - mae: 0.0117 - val_loss: 0.0064 - val_mae: 0.0053\n",
      "Epoch 68/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0063 - mae: 0.0055 - val_loss: 0.0063 - val_mae: 0.0064\n",
      "Epoch 69/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0063 - mae: 0.0076 - val_loss: 0.0063 - val_mae: 0.0095\n",
      "Epoch 70/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0062 - mae: 0.0081 - val_loss: 0.0063 - val_mae: 0.0110\n",
      "Epoch 71/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0061 - mae: 0.0089 - val_loss: 0.0061 - val_mae: 0.0089\n",
      "Epoch 72/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0061 - mae: 0.0102 - val_loss: 0.0060 - val_mae: 0.0083\n",
      "Epoch 73/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0059 - mae: 0.0057 - val_loss: 0.0058 - val_mae: 0.0048\n",
      "Epoch 74/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0059 - mae: 0.0097 - val_loss: 0.0062 - val_mae: 0.0161\n",
      "Epoch 75/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0058 - mae: 0.0087 - val_loss: 0.0062 - val_mae: 0.0169\n",
      "Epoch 76/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0057 - mae: 0.0081 - val_loss: 0.0056 - val_mae: 0.0060\n",
      "Epoch 77/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0055 - mae: 0.0056 - val_loss: 0.0055 - val_mae: 0.0088\n",
      "Epoch 78/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0055 - mae: 0.0078 - val_loss: 0.0054 - val_mae: 0.0050\n",
      "Epoch 79/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0053 - mae: 0.0065 - val_loss: 0.0053 - val_mae: 0.0050\n",
      "Epoch 80/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0054 - mae: 0.0100 - val_loss: 0.0053 - val_mae: 0.0086\n",
      "Epoch 81/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0052 - mae: 0.0066 - val_loss: 0.0051 - val_mae: 0.0045\n",
      "Epoch 82/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0051 - mae: 0.0073 - val_loss: 0.0051 - val_mae: 0.0077\n",
      "Epoch 83/1000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0050 - mae: 0.0072 - val_loss: 0.0050 - val_mae: 0.0067\n",
      "Epoch 84/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0049 - mae: 0.0066 - val_loss: 0.0049 - val_mae: 0.0050\n",
      "Epoch 85/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0049 - mae: 0.0076 - val_loss: 0.0049 - val_mae: 0.0089\n",
      "Epoch 86/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0048 - mae: 0.0060 - val_loss: 0.0047 - val_mae: 0.0049\n",
      "Epoch 87/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0047 - mae: 0.0077 - val_loss: 0.0050 - val_mae: 0.0148\n",
      "Epoch 88/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0046 - mae: 0.0071 - val_loss: 0.0046 - val_mae: 0.0055\n",
      "Epoch 89/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0045 - mae: 0.0061 - val_loss: 0.0045 - val_mae: 0.0062\n",
      "Epoch 90/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0045 - mae: 0.0077 - val_loss: 0.0044 - val_mae: 0.0045\n",
      "Epoch 91/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0044 - mae: 0.0065 - val_loss: 0.0044 - val_mae: 0.0067\n",
      "Epoch 92/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0044 - mae: 0.0088 - val_loss: 0.0043 - val_mae: 0.0041\n",
      "Epoch 93/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0043 - mae: 0.0057 - val_loss: 0.0043 - val_mae: 0.0068\n",
      "Epoch 94/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0042 - mae: 0.0057 - val_loss: 0.0042 - val_mae: 0.0074\n",
      "Epoch 95/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0042 - mae: 0.0072 - val_loss: 0.0042 - val_mae: 0.0104\n",
      "Epoch 96/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0041 - mae: 0.0065 - val_loss: 0.0040 - val_mae: 0.0068\n",
      "Epoch 97/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0041 - mae: 0.0077 - val_loss: 0.0039 - val_mae: 0.0041\n",
      "Epoch 98/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0040 - mae: 0.0061 - val_loss: 0.0040 - val_mae: 0.0076\n",
      "Epoch 99/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0039 - mae: 0.0058 - val_loss: 0.0039 - val_mae: 0.0081\n",
      "Epoch 100/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0038 - mae: 0.0058 - val_loss: 0.0042 - val_mae: 0.0167\n",
      "Epoch 101/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0038 - mae: 0.0067 - val_loss: 0.0037 - val_mae: 0.0051\n",
      "Epoch 102/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0055 - val_loss: 0.0037 - val_mae: 0.0047\n",
      "Epoch 103/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0069 - val_loss: 0.0038 - val_mae: 0.0128\n",
      "Epoch 104/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0082 - val_loss: 0.0035 - val_mae: 0.0043\n",
      "Epoch 105/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0047 - val_loss: 0.0035 - val_mae: 0.0039\n",
      "Epoch 106/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0061 - val_loss: 0.0035 - val_mae: 0.0070\n",
      "Epoch 107/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0051 - val_loss: 0.0034 - val_mae: 0.0055\n",
      "Epoch 108/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0066 - val_loss: 0.0034 - val_mae: 0.0057\n",
      "Epoch 109/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0053 - val_loss: 0.0033 - val_mae: 0.0054\n",
      "Epoch 110/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0053 - val_loss: 0.0033 - val_mae: 0.0054\n",
      "Epoch 111/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0032 - mae: 0.0057 - val_loss: 0.0032 - val_mae: 0.0081\n",
      "Epoch 112/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0032 - mae: 0.0061 - val_loss: 0.0031 - val_mae: 0.0050\n",
      "Epoch 113/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0031 - mae: 0.0049 - val_loss: 0.0031 - val_mae: 0.0044\n",
      "Epoch 114/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0032 - mae: 0.0083 - val_loss: 0.0030 - val_mae: 0.0043\n",
      "Epoch 115/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0055 - val_loss: 0.0031 - val_mae: 0.0075\n",
      "Epoch 116/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0049 - val_loss: 0.0030 - val_mae: 0.0038\n",
      "Epoch 117/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0029 - mae: 0.0045 - val_loss: 0.0029 - val_mae: 0.0049\n",
      "Epoch 118/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0029 - mae: 0.0063 - val_loss: 0.0030 - val_mae: 0.0108\n",
      "Epoch 119/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0029 - mae: 0.0057 - val_loss: 0.0029 - val_mae: 0.0062\n",
      "Epoch 120/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0028 - mae: 0.0057 - val_loss: 0.0029 - val_mae: 0.0097\n",
      "Epoch 121/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0028 - mae: 0.0055 - val_loss: 0.0030 - val_mae: 0.0113\n",
      "Epoch 122/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0028 - mae: 0.0056 - val_loss: 0.0027 - val_mae: 0.0043\n",
      "Epoch 123/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0027 - mae: 0.0058 - val_loss: 0.0027 - val_mae: 0.0078\n",
      "Epoch 124/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0027 - mae: 0.0050 - val_loss: 0.0026 - val_mae: 0.0043\n",
      "Epoch 125/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0056 - val_loss: 0.0026 - val_mae: 0.0038\n",
      "Epoch 126/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0053 - val_loss: 0.0026 - val_mae: 0.0051\n",
      "Epoch 127/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0054 - val_loss: 0.0025 - val_mae: 0.0069\n",
      "Epoch 128/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0058 - val_loss: 0.0025 - val_mae: 0.0041\n",
      "Epoch 129/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0058 - val_loss: 0.0024 - val_mae: 0.0040\n",
      "Epoch 130/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0056 - val_loss: 0.0024 - val_mae: 0.0053\n",
      "Epoch 131/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0063 - val_loss: 0.0024 - val_mae: 0.0045\n",
      "Epoch 132/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0042 - val_loss: 0.0024 - val_mae: 0.0072\n",
      "Epoch 133/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0049 - val_loss: 0.0023 - val_mae: 0.0049\n",
      "Epoch 134/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0050 - val_loss: 0.0023 - val_mae: 0.0043\n",
      "Epoch 135/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0063 - val_loss: 0.0022 - val_mae: 0.0036\n",
      "Epoch 136/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0045 - val_loss: 0.0023 - val_mae: 0.0060\n",
      "Epoch 137/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0042 - val_loss: 0.0022 - val_mae: 0.0043\n",
      "Epoch 138/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0045 - val_loss: 0.0022 - val_mae: 0.0058\n",
      "Epoch 139/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0053 - val_loss: 0.0021 - val_mae: 0.0044\n",
      "Epoch 140/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0045 - val_loss: 0.0021 - val_mae: 0.0056\n",
      "Epoch 141/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0051 - val_loss: 0.0021 - val_mae: 0.0075\n",
      "Epoch 142/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0056 - val_loss: 0.0021 - val_mae: 0.0052\n",
      "Epoch 143/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0054 - val_loss: 0.0020 - val_mae: 0.0047\n",
      "Epoch 144/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0044 - val_loss: 0.0020 - val_mae: 0.0041\n",
      "Epoch 145/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0043 - val_loss: 0.0019 - val_mae: 0.0031\n",
      "Epoch 146/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0052 - val_loss: 0.0019 - val_mae: 0.0040\n",
      "Epoch 147/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0043 - val_loss: 0.0019 - val_mae: 0.0054\n",
      "Epoch 148/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0043 - val_loss: 0.0019 - val_mae: 0.0041\n",
      "Epoch 149/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0044 - val_loss: 0.0018 - val_mae: 0.0032\n",
      "Epoch 150/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0050 - val_loss: 0.0019 - val_mae: 0.0063\n",
      "Epoch 151/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0018 - mae: 0.0053 - val_loss: 0.0018 - val_mae: 0.0039\n",
      "Epoch 152/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0018 - mae: 0.0042 - val_loss: 0.0018 - val_mae: 0.0036\n",
      "Epoch 153/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0018 - mae: 0.0041 - val_loss: 0.0018 - val_mae: 0.0047\n",
      "Epoch 154/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0017 - mae: 0.0041 - val_loss: 0.0017 - val_mae: 0.0038\n",
      "Epoch 155/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0017 - mae: 0.0054 - val_loss: 0.0017 - val_mae: 0.0033\n",
      "Epoch 156/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0017 - mae: 0.0049 - val_loss: 0.0017 - val_mae: 0.0043\n",
      "Epoch 157/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0017 - mae: 0.0046 - val_loss: 0.0017 - val_mae: 0.0050\n",
      "Epoch 158/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0017 - mae: 0.0053 - val_loss: 0.0018 - val_mae: 0.0110\n",
      "Epoch 159/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0017 - mae: 0.0050 - val_loss: 0.0017 - val_mae: 0.0065\n",
      "Epoch 160/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0050 - val_loss: 0.0016 - val_mae: 0.0047\n",
      "Epoch 161/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0016 - mae: 0.0043 - val_loss: 0.0016 - val_mae: 0.0034\n",
      "Epoch 162/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0016 - mae: 0.0039 - val_loss: 0.0016 - val_mae: 0.0067\n",
      "Epoch 163/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0016 - mae: 0.0048 - val_loss: 0.0016 - val_mae: 0.0047\n",
      "Epoch 164/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 0.0016 - val_mae: 0.0067\n",
      "Epoch 165/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0039 - val_loss: 0.0015 - val_mae: 0.0058\n",
      "Epoch 166/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0033\n",
      "Epoch 167/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0047\n",
      "Epoch 168/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0050 - val_loss: 0.0015 - val_mae: 0.0063\n",
      "Epoch 169/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0014 - mae: 0.0037 - val_loss: 0.0014 - val_mae: 0.0033\n",
      "Epoch 170/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0049 - val_loss: 0.0014 - val_mae: 0.0030\n",
      "Epoch 171/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0014 - mae: 0.0043 - val_loss: 0.0014 - val_mae: 0.0046\n",
      "Epoch 172/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0045\n",
      "Epoch 173/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0014 - mae: 0.0040 - val_loss: 0.0014 - val_mae: 0.0027\n",
      "Epoch 174/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0014 - mae: 0.0038 - val_loss: 0.0014 - val_mae: 0.0056\n",
      "Epoch 175/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0013 - mae: 0.0036 - val_loss: 0.0013 - val_mae: 0.0032\n",
      "Epoch 176/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0051 - val_loss: 0.0015 - val_mae: 0.0109\n",
      "Epoch 177/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0013 - mae: 0.0043 - val_loss: 0.0013 - val_mae: 0.0048\n",
      "Epoch 178/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0013 - mae: 0.0040 - val_loss: 0.0013 - val_mae: 0.0060\n",
      "Epoch 179/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0013 - mae: 0.0044 - val_loss: 0.0013 - val_mae: 0.0032\n",
      "Epoch 180/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0013 - mae: 0.0038 - val_loss: 0.0013 - val_mae: 0.0031\n",
      "Epoch 181/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0013 - mae: 0.0049 - val_loss: 0.0013 - val_mae: 0.0064\n",
      "Epoch 182/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0012 - mae: 0.0040 - val_loss: 0.0012 - val_mae: 0.0034\n",
      "Epoch 183/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0012 - mae: 0.0049 - val_loss: 0.0012 - val_mae: 0.0054\n",
      "Epoch 184/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0012 - mae: 0.0040 - val_loss: 0.0012 - val_mae: 0.0046\n",
      "Epoch 185/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0012 - mae: 0.0039 - val_loss: 0.0012 - val_mae: 0.0041\n",
      "Epoch 186/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0012 - mae: 0.0036 - val_loss: 0.0012 - val_mae: 0.0039\n",
      "Epoch 187/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0044 - val_loss: 0.0012 - val_mae: 0.0035\n",
      "Epoch 188/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0012 - mae: 0.0040 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 189/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0043 - val_loss: 0.0012 - val_mae: 0.0063\n",
      "Epoch 190/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0043 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 191/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0043\n",
      "Epoch 192/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0037 - val_loss: 0.0011 - val_mae: 0.0038\n",
      "Epoch 193/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0044\n",
      "Epoch 194/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0042 - val_loss: 0.0011 - val_mae: 0.0059\n",
      "Epoch 195/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0034\n",
      "Epoch 196/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 0.0011 - val_mae: 0.0041\n",
      "Epoch 197/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0039 - val_loss: 0.0010 - val_mae: 0.0038\n",
      "Epoch 198/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0036 - val_loss: 0.0010 - val_mae: 0.0036\n",
      "Epoch 199/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0039 - val_loss: 0.0010 - val_mae: 0.0047\n",
      "Epoch 200/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0042 - val_loss: 0.0010 - val_mae: 0.0048\n",
      "Epoch 201/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0036 - val_loss: 0.0010 - val_mae: 0.0058\n",
      "Epoch 202/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0042 - val_loss: 9.9206e-04 - val_mae: 0.0039\n",
      "Epoch 203/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 9.9531e-04 - mae: 0.0042 - val_loss: 9.8985e-04 - val_mae: 0.0046\n",
      "Epoch 204/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 9.9313e-04 - mae: 0.0047 - val_loss: 9.7765e-04 - val_mae: 0.0039\n",
      "Epoch 205/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 9.6657e-04 - mae: 0.0035 - val_loss: 9.6490e-04 - val_mae: 0.0039\n",
      "Epoch 206/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 9.5823e-04 - mae: 0.0036 - val_loss: 9.6976e-04 - val_mae: 0.0049\n",
      "Epoch 207/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 9.5633e-04 - mae: 0.0041 - val_loss: 9.4471e-04 - val_mae: 0.0037\n",
      "Epoch 208/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 9.4100e-04 - mae: 0.0037 - val_loss: 9.3340e-04 - val_mae: 0.0035\n",
      "Epoch 209/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 9.2891e-04 - mae: 0.0037 - val_loss: 9.1624e-04 - val_mae: 0.0030\n",
      "Epoch 210/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 9.3404e-04 - mae: 0.0045 - val_loss: 9.3329e-04 - val_mae: 0.0046\n",
      "Epoch 211/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 9.1463e-04 - mae: 0.0039 - val_loss: 9.3014e-04 - val_mae: 0.0060\n",
      "Epoch 212/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 8.9865e-04 - mae: 0.0033 - val_loss: 9.0717e-04 - val_mae: 0.0043\n",
      "Epoch 213/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 8.9111e-04 - mae: 0.0035 - val_loss: 0.0010 - val_mae: 0.0115\n",
      "Epoch 214/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 9.1566e-04 - mae: 0.0048 - val_loss: 8.7740e-04 - val_mae: 0.0032\n",
      "Epoch 215/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 8.7449e-04 - mae: 0.0034 - val_loss: 8.7771e-04 - val_mae: 0.0041\n",
      "Epoch 216/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 8.6738e-04 - mae: 0.0036 - val_loss: 8.5663e-04 - val_mae: 0.0031\n",
      "Epoch 217/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 8.6013e-04 - mae: 0.0036 - val_loss: 8.9020e-04 - val_mae: 0.0066\n",
      "Epoch 218/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 8.5131e-04 - mae: 0.0036 - val_loss: 8.3659e-04 - val_mae: 0.0025\n",
      "Epoch 219/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 8.5175e-04 - mae: 0.0042 - val_loss: 8.3223e-04 - val_mae: 0.0033\n",
      "Epoch 220/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 8.3737e-04 - mae: 0.0037 - val_loss: 8.3864e-04 - val_mae: 0.0046\n",
      "Epoch 221/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 8.2654e-04 - mae: 0.0036 - val_loss: 8.1625e-04 - val_mae: 0.0030\n",
      "Epoch 222/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 8.1147e-04 - mae: 0.0031 - val_loss: 8.1314e-04 - val_mae: 0.0034\n",
      "Epoch 223/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 8.2104e-04 - mae: 0.0043 - val_loss: 8.1980e-04 - val_mae: 0.0049\n",
      "Epoch 224/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 8.0051e-04 - mae: 0.0035 - val_loss: 7.8981e-04 - val_mae: 0.0027\n",
      "Epoch 225/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 7.9832e-04 - mae: 0.0038 - val_loss: 7.9211e-04 - val_mae: 0.0043\n",
      "Epoch 226/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 7.9525e-04 - mae: 0.0041 - val_loss: 7.8190e-04 - val_mae: 0.0035\n",
      "Epoch 227/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 7.7662e-04 - mae: 0.0032 - val_loss: 7.6792e-04 - val_mae: 0.0026\n",
      "Epoch 228/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 7.7846e-04 - mae: 0.0040 - val_loss: 7.6421e-04 - val_mae: 0.0033\n",
      "Epoch 229/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 7.7598e-04 - mae: 0.0042 - val_loss: 7.5551e-04 - val_mae: 0.0030\n",
      "Epoch 230/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 7.5382e-04 - mae: 0.0032 - val_loss: 7.5221e-04 - val_mae: 0.0037\n",
      "Epoch 231/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 7.5113e-04 - mae: 0.0036 - val_loss: 7.4565e-04 - val_mae: 0.0037\n",
      "Epoch 232/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 7.4683e-04 - mae: 0.0038 - val_loss: 7.4748e-04 - val_mae: 0.0042\n",
      "Epoch 233/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 7.4278e-04 - mae: 0.0040 - val_loss: 7.3274e-04 - val_mae: 0.0035\n",
      "Epoch 234/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.2680e-04 - mae: 0.0033 - val_loss: 7.2445e-04 - val_mae: 0.0034\n",
      "Epoch 235/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.3393e-04 - mae: 0.0041 - val_loss: 7.1300e-04 - val_mae: 0.0028\n",
      "Epoch 236/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.4449e-04 - mae: 0.0047 - val_loss: 7.1597e-04 - val_mae: 0.0041\n",
      "Epoch 237/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.0684e-04 - mae: 0.0032 - val_loss: 7.0683e-04 - val_mae: 0.0034\n",
      "Epoch 238/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.0641e-04 - mae: 0.0036 - val_loss: 7.0794e-04 - val_mae: 0.0042\n",
      "Epoch 239/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 7.0309e-04 - mae: 0.0037 - val_loss: 6.8876e-04 - val_mae: 0.0026\n",
      "Epoch 240/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.9232e-04 - mae: 0.0034 - val_loss: 6.8553e-04 - val_mae: 0.0030\n",
      "Epoch 241/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 6.8689e-04 - mae: 0.0035 - val_loss: 6.9875e-04 - val_mae: 0.0048\n",
      "Epoch 242/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 6.8429e-04 - mae: 0.0038 - val_loss: 7.0229e-04 - val_mae: 0.0061\n",
      "Epoch 243/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 6.7677e-04 - mae: 0.0036 - val_loss: 6.6903e-04 - val_mae: 0.0032\n",
      "Epoch 244/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 6.7177e-04 - mae: 0.0037 - val_loss: 6.6186e-04 - val_mae: 0.0034\n",
      "Epoch 245/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 6.7511e-04 - mae: 0.0041 - val_loss: 6.7745e-04 - val_mae: 0.0051\n",
      "Epoch 246/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 6.5623e-04 - mae: 0.0035 - val_loss: 6.6254e-04 - val_mae: 0.0043\n",
      "Epoch 247/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 6.5094e-04 - mae: 0.0035 - val_loss: 6.5985e-04 - val_mae: 0.0051\n",
      "Epoch 248/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 6.4862e-04 - mae: 0.0037 - val_loss: 6.4222e-04 - val_mae: 0.0036\n",
      "Epoch 249/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 6.4422e-04 - mae: 0.0038 - val_loss: 6.3453e-04 - val_mae: 0.0032\n",
      "Epoch 250/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 6.3193e-04 - mae: 0.0033 - val_loss: 6.3208e-04 - val_mae: 0.0034\n",
      "Epoch 251/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.3469e-04 - mae: 0.0039 - val_loss: 6.4504e-04 - val_mae: 0.0054\n",
      "Epoch 252/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.2744e-04 - mae: 0.0037 - val_loss: 6.3303e-04 - val_mae: 0.0041\n",
      "Epoch 253/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.1918e-04 - mae: 0.0035 - val_loss: 6.1326e-04 - val_mae: 0.0032\n",
      "Epoch 254/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.1121e-04 - mae: 0.0033 - val_loss: 6.4105e-04 - val_mae: 0.0060\n",
      "Epoch 255/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 6.1079e-04 - mae: 0.0037 - val_loss: 6.3719e-04 - val_mae: 0.0054\n",
      "Epoch 256/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 6.0120e-04 - mae: 0.0033 - val_loss: 5.9997e-04 - val_mae: 0.0036\n",
      "Epoch 257/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 6.0676e-04 - mae: 0.0039 - val_loss: 5.9202e-04 - val_mae: 0.0034\n",
      "Epoch 258/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 5.8793e-04 - mae: 0.0030 - val_loss: 5.8303e-04 - val_mae: 0.0028\n",
      "Epoch 259/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 5.9892e-04 - mae: 0.0041 - val_loss: 5.9083e-04 - val_mae: 0.0036\n",
      "Epoch 260/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 5.7917e-04 - mae: 0.0031 - val_loss: 5.8612e-04 - val_mae: 0.0041\n",
      "Epoch 261/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 5.8227e-04 - mae: 0.0038 - val_loss: 5.7446e-04 - val_mae: 0.0033\n",
      "Epoch 262/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 5.7424e-04 - mae: 0.0034 - val_loss: 5.8927e-04 - val_mae: 0.0046\n",
      "Epoch 263/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 5.7081e-04 - mae: 0.0036 - val_loss: 5.6386e-04 - val_mae: 0.0034\n",
      "Epoch 264/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 5.6706e-04 - mae: 0.0037 - val_loss: 6.0147e-04 - val_mae: 0.0067\n",
      "Epoch 265/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 5.5781e-04 - mae: 0.0032 - val_loss: 5.5330e-04 - val_mae: 0.0029\n",
      "Epoch 266/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 5.6133e-04 - mae: 0.0037 - val_loss: 5.6818e-04 - val_mae: 0.0053\n",
      "Epoch 267/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 5.4888e-04 - mae: 0.0032 - val_loss: 5.4343e-04 - val_mae: 0.0029\n",
      "Epoch 268/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 5.4160e-04 - mae: 0.0030 - val_loss: 5.9617e-04 - val_mae: 0.0054\n",
      "Epoch 269/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 5.4466e-04 - mae: 0.0036 - val_loss: 5.3996e-04 - val_mae: 0.0033\n",
      "Epoch 270/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 5.4534e-04 - mae: 0.0039 - val_loss: 5.4162e-04 - val_mae: 0.0041\n",
      "Epoch 271/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 5.3478e-04 - mae: 0.0035 - val_loss: 5.4521e-04 - val_mae: 0.0046\n",
      "Epoch 272/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 5.2667e-04 - mae: 0.0032 - val_loss: 5.2319e-04 - val_mae: 0.0027\n",
      "Epoch 273/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 5.2620e-04 - mae: 0.0035 - val_loss: 5.2058e-04 - val_mae: 0.0029\n",
      "Epoch 274/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.2309e-04 - mae: 0.0035 - val_loss: 5.8405e-04 - val_mae: 0.0081\n",
      "Epoch 275/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.1876e-04 - mae: 0.0035 - val_loss: 5.2168e-04 - val_mae: 0.0036\n",
      "Epoch 276/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 5.1777e-04 - mae: 0.0036 - val_loss: 5.7949e-04 - val_mae: 0.0082\n",
      "Epoch 277/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 5.0545e-04 - mae: 0.0031 - val_loss: 5.0057e-04 - val_mae: 0.0026\n",
      "Epoch 278/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 5.0978e-04 - mae: 0.0038 - val_loss: 4.9879e-04 - val_mae: 0.0029\n",
      "Epoch 279/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 5.0389e-04 - mae: 0.0036 - val_loss: 4.9507e-04 - val_mae: 0.0032\n",
      "Epoch 280/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.9776e-04 - mae: 0.0033 - val_loss: 5.1112e-04 - val_mae: 0.0044\n",
      "Epoch 281/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 5.0441e-04 - mae: 0.0040 - val_loss: 4.9155e-04 - val_mae: 0.0032\n",
      "Epoch 282/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.8804e-04 - mae: 0.0032 - val_loss: 4.8843e-04 - val_mae: 0.0032\n",
      "Epoch 283/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.9345e-04 - mae: 0.0038 - val_loss: 4.9434e-04 - val_mae: 0.0047\n",
      "Epoch 284/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.8120e-04 - mae: 0.0031 - val_loss: 5.0977e-04 - val_mae: 0.0047\n",
      "Epoch 285/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.7729e-04 - mae: 0.0031 - val_loss: 4.6936e-04 - val_mae: 0.0025\n",
      "Epoch 286/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.7107e-04 - mae: 0.0029 - val_loss: 4.7373e-04 - val_mae: 0.0030\n",
      "Epoch 287/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.6911e-04 - mae: 0.0030 - val_loss: 5.2632e-04 - val_mae: 0.0077\n",
      "Epoch 288/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.7105e-04 - mae: 0.0036 - val_loss: 4.7338e-04 - val_mae: 0.0044\n",
      "Epoch 289/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.6914e-04 - mae: 0.0036 - val_loss: 4.6812e-04 - val_mae: 0.0036\n",
      "Epoch 290/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.6085e-04 - mae: 0.0032 - val_loss: 4.5865e-04 - val_mae: 0.0034\n",
      "Epoch 291/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.6009e-04 - mae: 0.0034 - val_loss: 4.4843e-04 - val_mae: 0.0022\n",
      "Epoch 292/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.5074e-04 - mae: 0.0029 - val_loss: 4.5083e-04 - val_mae: 0.0029\n",
      "Epoch 293/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.5471e-04 - mae: 0.0036 - val_loss: 4.8039e-04 - val_mae: 0.0057\n",
      "Epoch 294/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.4613e-04 - mae: 0.0031 - val_loss: 4.4583e-04 - val_mae: 0.0031\n",
      "Epoch 295/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.4380e-04 - mae: 0.0032 - val_loss: 4.3554e-04 - val_mae: 0.0024\n",
      "Epoch 296/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.3962e-04 - mae: 0.0032 - val_loss: 4.3279e-04 - val_mae: 0.0026\n",
      "Epoch 297/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.4125e-04 - mae: 0.0036 - val_loss: 4.3168e-04 - val_mae: 0.0026\n",
      "Epoch 298/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.3825e-04 - mae: 0.0035 - val_loss: 4.2935e-04 - val_mae: 0.0030\n",
      "Epoch 299/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.2902e-04 - mae: 0.0031 - val_loss: 4.2938e-04 - val_mae: 0.0033\n",
      "Epoch 300/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.2741e-04 - mae: 0.0032 - val_loss: 4.3256e-04 - val_mae: 0.0036\n",
      "Epoch 301/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.2573e-04 - mae: 0.0034 - val_loss: 4.1924e-04 - val_mae: 0.0027\n",
      "Epoch 302/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.2486e-04 - mae: 0.0035 - val_loss: 4.1278e-04 - val_mae: 0.0023\n",
      "Epoch 303/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.2273e-04 - mae: 0.0035 - val_loss: 4.2552e-04 - val_mae: 0.0036\n",
      "Epoch 304/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.2257e-04 - mae: 0.0038 - val_loss: 4.3259e-04 - val_mae: 0.0046\n",
      "Epoch 305/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.1323e-04 - mae: 0.0032 - val_loss: 4.0627e-04 - val_mae: 0.0026\n",
      "Epoch 306/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.0712e-04 - mae: 0.0029 - val_loss: 4.0623e-04 - val_mae: 0.0025\n",
      "Epoch 307/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.0594e-04 - mae: 0.0031 - val_loss: 4.2596e-04 - val_mae: 0.0038\n",
      "Epoch 308/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.0921e-04 - mae: 0.0035 - val_loss: 4.4021e-04 - val_mae: 0.0064\n",
      "Epoch 309/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.0421e-04 - mae: 0.0034 - val_loss: 3.9627e-04 - val_mae: 0.0026\n",
      "Epoch 310/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.9869e-04 - mae: 0.0031 - val_loss: 3.9017e-04 - val_mae: 0.0022\n",
      "Epoch 311/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.9288e-04 - mae: 0.0029 - val_loss: 3.8816e-04 - val_mae: 0.0025\n",
      "Epoch 312/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.9094e-04 - mae: 0.0029 - val_loss: 3.8577e-04 - val_mae: 0.0024\n",
      "Epoch 313/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.9195e-04 - mae: 0.0032 - val_loss: 3.8896e-04 - val_mae: 0.0028\n",
      "Epoch 314/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.9833e-04 - mae: 0.0039 - val_loss: 4.1041e-04 - val_mae: 0.0053\n",
      "Epoch 315/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.8803e-04 - mae: 0.0033 - val_loss: 3.8071e-04 - val_mae: 0.0030\n",
      "Epoch 316/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.8515e-04 - mae: 0.0032 - val_loss: 3.9065e-04 - val_mae: 0.0032\n",
      "Epoch 317/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.8279e-04 - mae: 0.0033 - val_loss: 3.8966e-04 - val_mae: 0.0040\n",
      "Epoch 318/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.8340e-04 - mae: 0.0035 - val_loss: 3.7183e-04 - val_mae: 0.0025\n",
      "Epoch 319/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.7580e-04 - mae: 0.0031 - val_loss: 3.6855e-04 - val_mae: 0.0024\n",
      "Epoch 320/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.8075e-04 - mae: 0.0036 - val_loss: 3.6678e-04 - val_mae: 0.0023\n",
      "Epoch 321/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.6778e-04 - mae: 0.0028 - val_loss: 3.7208e-04 - val_mae: 0.0032\n",
      "Epoch 322/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.7143e-04 - mae: 0.0032 - val_loss: 3.7058e-04 - val_mae: 0.0033\n",
      "Epoch 323/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.6862e-04 - mae: 0.0033 - val_loss: 3.8680e-04 - val_mae: 0.0052\n",
      "Epoch 324/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.8060e-04 - mae: 0.0040 - val_loss: 3.5731e-04 - val_mae: 0.0024\n",
      "Epoch 325/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.5804e-04 - mae: 0.0027 - val_loss: 3.5677e-04 - val_mae: 0.0027\n",
      "Epoch 326/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.5840e-04 - mae: 0.0030 - val_loss: 3.5840e-04 - val_mae: 0.0030\n",
      "Epoch 327/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.5991e-04 - mae: 0.0032 - val_loss: 3.8248e-04 - val_mae: 0.0054\n",
      "Epoch 328/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.6377e-04 - mae: 0.0037 - val_loss: 3.7440e-04 - val_mae: 0.0047\n",
      "Epoch 329/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.5336e-04 - mae: 0.0030 - val_loss: 3.4863e-04 - val_mae: 0.0027\n",
      "Epoch 330/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.4893e-04 - mae: 0.0028 - val_loss: 3.4642e-04 - val_mae: 0.0026\n",
      "Epoch 331/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.5292e-04 - mae: 0.0033 - val_loss: 3.4909e-04 - val_mae: 0.0032\n",
      "Epoch 332/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.5629e-04 - mae: 0.0035 - val_loss: 3.4205e-04 - val_mae: 0.0025\n",
      "Epoch 333/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.4596e-04 - mae: 0.0031 - val_loss: 3.4368e-04 - val_mae: 0.0028\n",
      "Epoch 334/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.4357e-04 - mae: 0.0031 - val_loss: 3.4071e-04 - val_mae: 0.0030\n",
      "Epoch 335/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.4131e-04 - mae: 0.0030 - val_loss: 3.4112e-04 - val_mae: 0.0033\n",
      "Epoch 336/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.4385e-04 - mae: 0.0035 - val_loss: 3.3778e-04 - val_mae: 0.0030\n",
      "Epoch 337/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.3510e-04 - mae: 0.0029 - val_loss: 3.3902e-04 - val_mae: 0.0032\n",
      "Epoch 338/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.4033e-04 - mae: 0.0035 - val_loss: 3.3450e-04 - val_mae: 0.0030\n",
      "Epoch 339/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.3093e-04 - mae: 0.0028 - val_loss: 3.3204e-04 - val_mae: 0.0030\n",
      "Epoch 340/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.3199e-04 - mae: 0.0031 - val_loss: 3.5204e-04 - val_mae: 0.0044\n",
      "Epoch 341/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.3934e-04 - mae: 0.0038 - val_loss: 3.2846e-04 - val_mae: 0.0030\n",
      "Epoch 342/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.2666e-04 - mae: 0.0029 - val_loss: 3.2189e-04 - val_mae: 0.0023\n",
      "Epoch 343/1000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 3.2645e-04 - mae: 0.0031 - val_loss: 3.2194e-04 - val_mae: 0.0027\n",
      "Epoch 344/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.2472e-04 - mae: 0.0031 - val_loss: 3.2010e-04 - val_mae: 0.0026\n",
      "Epoch 345/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.2237e-04 - mae: 0.0031 - val_loss: 3.1847e-04 - val_mae: 0.0028\n",
      "Epoch 346/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.1991e-04 - mae: 0.0030 - val_loss: 3.1387e-04 - val_mae: 0.0023\n",
      "Epoch 347/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.1690e-04 - mae: 0.0029 - val_loss: 3.1720e-04 - val_mae: 0.0028\n",
      "Epoch 348/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.2405e-04 - mae: 0.0036 - val_loss: 3.1880e-04 - val_mae: 0.0030\n",
      "Epoch 349/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.1399e-04 - mae: 0.0030 - val_loss: 3.2116e-04 - val_mae: 0.0037\n",
      "Epoch 350/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.1750e-04 - mae: 0.0033 - val_loss: 3.3941e-04 - val_mae: 0.0049\n",
      "Epoch 351/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.0921e-04 - mae: 0.0028 - val_loss: 3.1360e-04 - val_mae: 0.0037\n",
      "Epoch 352/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.0747e-04 - mae: 0.0029 - val_loss: 3.3063e-04 - val_mae: 0.0055\n",
      "Epoch 353/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.1032e-04 - mae: 0.0032 - val_loss: 3.0523e-04 - val_mae: 0.0028\n",
      "Epoch 354/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.1074e-04 - mae: 0.0034 - val_loss: 3.0540e-04 - val_mae: 0.0030\n",
      "Epoch 355/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.0538e-04 - mae: 0.0032 - val_loss: 2.9745e-04 - val_mae: 0.0023\n",
      "Epoch 356/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.0046e-04 - mae: 0.0028 - val_loss: 3.0242e-04 - val_mae: 0.0032\n",
      "Epoch 357/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.0204e-04 - mae: 0.0031 - val_loss: 3.0292e-04 - val_mae: 0.0035\n",
      "Epoch 358/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.0046e-04 - mae: 0.0032 - val_loss: 2.9656e-04 - val_mae: 0.0031\n",
      "Epoch 359/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.9901e-04 - mae: 0.0032 - val_loss: 2.9888e-04 - val_mae: 0.0034\n",
      "Epoch 360/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.9635e-04 - mae: 0.0031 - val_loss: 2.9783e-04 - val_mae: 0.0034\n",
      "Epoch 361/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.9448e-04 - mae: 0.0031 - val_loss: 2.9024e-04 - val_mae: 0.0025\n",
      "Epoch 362/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.9282e-04 - mae: 0.0030 - val_loss: 2.9417e-04 - val_mae: 0.0030\n",
      "Epoch 363/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.9121e-04 - mae: 0.0030 - val_loss: 2.9090e-04 - val_mae: 0.0031\n",
      "Epoch 364/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.9489e-04 - mae: 0.0033 - val_loss: 2.9610e-04 - val_mae: 0.0039\n",
      "Epoch 365/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.8711e-04 - mae: 0.0029 - val_loss: 2.8554e-04 - val_mae: 0.0028\n",
      "Epoch 366/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.8917e-04 - mae: 0.0032 - val_loss: 2.8108e-04 - val_mae: 0.0024\n",
      "Epoch 367/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.8504e-04 - mae: 0.0030 - val_loss: 3.0998e-04 - val_mae: 0.0046\n",
      "Epoch 368/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.8976e-04 - mae: 0.0035 - val_loss: 2.8062e-04 - val_mae: 0.0025\n",
      "Epoch 369/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.8757e-04 - mae: 0.0034 - val_loss: 2.7959e-04 - val_mae: 0.0026\n",
      "Epoch 370/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.8118e-04 - mae: 0.0029 - val_loss: 2.7929e-04 - val_mae: 0.0027\n",
      "Epoch 371/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.7690e-04 - mae: 0.0027 - val_loss: 2.7469e-04 - val_mae: 0.0023\n",
      "Epoch 372/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.7987e-04 - mae: 0.0031 - val_loss: 2.7599e-04 - val_mae: 0.0029\n",
      "Epoch 373/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.7696e-04 - mae: 0.0031 - val_loss: 2.7558e-04 - val_mae: 0.0027\n",
      "Epoch 374/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.7323e-04 - mae: 0.0028 - val_loss: 2.7547e-04 - val_mae: 0.0031\n",
      "Epoch 375/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.8194e-04 - mae: 0.0036 - val_loss: 2.6929e-04 - val_mae: 0.0023\n",
      "Epoch 376/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.7076e-04 - mae: 0.0028 - val_loss: 2.8502e-04 - val_mae: 0.0037\n",
      "Epoch 377/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.7227e-04 - mae: 0.0031 - val_loss: 2.7180e-04 - val_mae: 0.0031\n",
      "Epoch 378/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.7200e-04 - mae: 0.0032 - val_loss: 2.6489e-04 - val_mae: 0.0023\n",
      "Epoch 379/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.6862e-04 - mae: 0.0029 - val_loss: 2.7300e-04 - val_mae: 0.0031\n",
      "Epoch 380/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.7040e-04 - mae: 0.0033 - val_loss: 2.6378e-04 - val_mae: 0.0028\n",
      "Epoch 381/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.6490e-04 - mae: 0.0028 - val_loss: 2.6618e-04 - val_mae: 0.0031\n",
      "Epoch 382/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.7351e-04 - mae: 0.0036 - val_loss: 2.6709e-04 - val_mae: 0.0034\n",
      "Epoch 383/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.6537e-04 - mae: 0.0031 - val_loss: 2.5996e-04 - val_mae: 0.0026\n",
      "Epoch 384/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.6457e-04 - mae: 0.0032 - val_loss: 2.8419e-04 - val_mae: 0.0049\n",
      "Epoch 385/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.6526e-04 - mae: 0.0033 - val_loss: 2.5879e-04 - val_mae: 0.0025\n",
      "Epoch 386/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.5826e-04 - mae: 0.0028 - val_loss: 2.5697e-04 - val_mae: 0.0026\n",
      "Epoch 387/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.6295e-04 - mae: 0.0033 - val_loss: 2.6032e-04 - val_mae: 0.0028\n",
      "Epoch 388/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.5874e-04 - mae: 0.0030 - val_loss: 2.5681e-04 - val_mae: 0.0029\n",
      "Epoch 389/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.5484e-04 - mae: 0.0028 - val_loss: 2.5087e-04 - val_mae: 0.0023\n",
      "Epoch 390/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.5570e-04 - mae: 0.0030 - val_loss: 2.5148e-04 - val_mae: 0.0025\n",
      "Epoch 391/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.5401e-04 - mae: 0.0029 - val_loss: 2.6441e-04 - val_mae: 0.0039\n",
      "Epoch 392/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.5206e-04 - mae: 0.0029 - val_loss: 2.5241e-04 - val_mae: 0.0030\n",
      "Epoch 393/1000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.5290e-04 - mae: 0.0031 - val_loss: 2.7078e-04 - val_mae: 0.0048\n",
      "Epoch 394/1000\n",
      "354/375 [===========================>..] - ETA: 0s - loss: 2.5335e-04 - mae: 0.0032Restoring model weights from the end of the best epoch: 389.\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.5331e-04 - mae: 0.0032 - val_loss: 2.5633e-04 - val_mae: 0.0031\n",
      "Epoch 394: early stopping\n",
      "Durchschnittlicher Validation Loss: 0.000291985971853137\n",
      "Durchschnittlicher Validation MAE: 0.0020399115746840835\n"
     ]
    }
   ],
   "source": [
    "# Initialisiere Listen, um Ergebnisse zu speichern\n",
    "val_loss_results = []\n",
    "val_mae_results = []\n",
    "\n",
    "# Funktion, um das Modell zu erstellen\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "                Dense(328, activation='relu', input_shape=(4,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)), \n",
    "                \n",
    "                Dense(328, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "                \n",
    "                Dense(248, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "                \n",
    "                Dense(104, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "                \n",
    "                Dense(1 , activation = 'linear')\n",
    "\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# K-Fold Cross-Validation Konfiguration\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# LeistungsÃ¼berwachung\n",
    "fold_no = 1\n",
    "for train_index, val_index in kf.split(X_train_scaled):\n",
    "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_scaled[train_index], y_train_scaled[val_index]\n",
    "\n",
    "    model = create_model()\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "    print(f'Training fÃ¼r Fold {fold_no}...')\n",
    "    history = model.fit(X_train_fold, y_train_fold, batch_size=16, epochs=1000, validation_data=(X_val_fold, y_val_fold), callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "    # Speichere die Ergebnisse des aktuellen Folds\n",
    "    val_loss_results.append(min(history.history['val_loss']))\n",
    "    val_mae_results.append(min(history.history['val_mae']))\n",
    "\n",
    "    fold_no += 1\n",
    "\n",
    "# Berechne den Durchschnitt Ã¼ber alle Folds\n",
    "average_val_loss = np.mean(val_loss_results)\n",
    "average_val_mae = np.mean(val_mae_results)\n",
    "\n",
    "# Umwandeln der Listen in Pandas DataFrames\n",
    "val_loss_df = pd.DataFrame(val_loss_results, columns=['Validation Loss'])\n",
    "val_mae_df = pd.DataFrame(val_mae_results, columns=['Validation MAE'])\n",
    "\n",
    "# Speichern der DataFrames in CSV-Dateien\n",
    "val_loss_df.to_csv('val_loss_results_D4_I_F_2.csv', index=False)\n",
    "val_mae_df.to_csv('val_mae_results_D4_I_F_2.csv', index=False)\n",
    "\n",
    "# Gib die durchschnittlichen Ergebnisse aus\n",
    "print(f'Durchschnittlicher Validation Loss: {average_val_loss}')\n",
    "print(f'Durchschnittlicher Validation MAE: {average_val_mae}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T09:55:34.374211800Z",
     "start_time": "2024-04-02T09:17:33.772216500Z"
    }
   },
   "id": "929336b1a7ac475d"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 - 0s - loss: 2.7900e-04 - mae: 0.0051 - 56ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.0002789987192954868, 0.005051739513874054]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test_scaled, y_test_scaled, verbose=2)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T09:56:23.979874800Z",
     "start_time": "2024-04-02T09:56:23.843749400Z"
    }
   },
   "id": "4b02697cbcecd185"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bsp. Predicted: [761.60394] Actual: [754.68] \n",
      "Durchschnittliche Abweichung (MAE): [9.58234117]\n",
      "0.6724385251128935\n"
     ]
    }
   ],
   "source": [
    "scaled_predicted_values = model.predict(X_test_scaled, verbose = 0)\n",
    "\n",
    "# FÃ¼hren Sie die RÃ¼cktransformation der skalierten Werte durch\n",
    "original_predicted_values = scaler_target.inverse_transform(scaled_predicted_values)\n",
    "original_actual_values = scaler_target.inverse_transform(y_test_scaled)  # y_test sind die skalierten tatsÃ¤chlichen Werte\n",
    "print(f' Bsp. Predicted: {original_predicted_values[100]} Actual: {original_actual_values[100]} ')\n",
    "\n",
    "def calculate_mae(list1, list2):\n",
    "    # Stelle sicher, dass beide Listen die gleiche LÃ¤nge haben\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Listen mÃ¼ssen die gleiche LÃ¤nge haben\")\n",
    "\n",
    "    # Berechne die absolute Differenz zwischen den Elementen der Listen\n",
    "    differences = [abs(x - y) for x, y in zip(list1, list2)]\n",
    "\n",
    "    # Berechne den Durchschnitt der absoluten Differenzen\n",
    "    mae = sum(differences) / len(differences)\n",
    "\n",
    "    return mae\n",
    "\n",
    "# Beispiel\n",
    "list1 = original_predicted_values\n",
    "list2 = original_actual_values\n",
    "\n",
    "mae = calculate_mae(list1, list2)\n",
    "print(f\"Durchschnittliche Abweichung (MAE): {mae}\")\n",
    "\n",
    "errors = np.abs((original_actual_values - original_predicted_values) / original_actual_values)\n",
    "mape = np.mean(errors) * 100\n",
    "print(mape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T10:10:16.667203600Z",
     "start_time": "2024-04-02T10:10:16.232551800Z"
    }
   },
   "id": "a402d28abbd82f60"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: [0.99895532]\n"
     ]
    }
   ],
   "source": [
    "#Berechnung der AuswertungsgrÃ¶ÃŸe R^2\n",
    "\n",
    "def calculate_r_squared(predicted, actual):\n",
    "    # Berechnung des Mittelwerts der tatsÃ¤chlichen Werte\n",
    "    mean_actual = sum(actual) / len(actual)\n",
    "    \n",
    "    # Berechnung der totalen Summe der Quadrate (SST)\n",
    "    sst = sum((x - mean_actual) ** 2 for x in actual)\n",
    "    \n",
    "    # Berechnung der Summe der Quadrate der Residuen (SSE)\n",
    "    sse = sum((actual[i] - predicted[i]) ** 2 for i in range(len(actual)))\n",
    "    \n",
    "    # Berechnung des R^2-Wertes\n",
    "    r_squared = 1 - (sse / sst)\n",
    "    \n",
    "    return r_squared\n",
    "\n",
    "# Berechnung von R^2 mit den bereitgestellten Listen\n",
    "r_squared = calculate_r_squared(list1, list2)\n",
    "\n",
    "print(f\"R^2: {r_squared}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T10:10:59.009890Z",
     "start_time": "2024-04-02T10:10:58.853800700Z"
    }
   },
   "id": "1a7520320695272d"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Werte die kleiner sind: 131\n"
     ]
    },
    {
     "data": {
      "text/plain": "            Echt  Vorhergesagt  X-Koordinate  Y-Koordinate  Zeitpunkt  \\\n5913  649.919800        673.72          1.00          0.94      0.700   \n6769  520.552734        543.98          1.00          0.94      0.225   \n2678  738.266052        759.01          1.00          0.90      0.700   \n1950  512.838440        533.12          1.00          0.94      0.200   \n1837  628.636475        648.25          1.00          0.94      0.625   \n...          ...           ...           ...           ...        ...   \n573   428.385986        409.84          1.00          0.98      0.125   \n6539  582.942627        563.29          0.95          0.98      0.875   \n991   560.379883        538.83          0.95          0.98      0.750   \n7585  450.709320        428.07          1.00          0.98      0.200   \n1032  567.015930        537.98          1.00          0.98      0.750   \n\n      Differenz  \n5913 -23.800200  \n6769 -23.427266  \n2678 -20.743948  \n1950 -20.281560  \n1837 -19.613525  \n...         ...  \n573   18.545986  \n6539  19.652627  \n991   21.549883  \n7585  22.639320  \n1032  29.035930  \n\n[8783 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Echt</th>\n      <th>Vorhergesagt</th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Differenz</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5913</th>\n      <td>649.919800</td>\n      <td>673.72</td>\n      <td>1.00</td>\n      <td>0.94</td>\n      <td>0.700</td>\n      <td>-23.800200</td>\n    </tr>\n    <tr>\n      <th>6769</th>\n      <td>520.552734</td>\n      <td>543.98</td>\n      <td>1.00</td>\n      <td>0.94</td>\n      <td>0.225</td>\n      <td>-23.427266</td>\n    </tr>\n    <tr>\n      <th>2678</th>\n      <td>738.266052</td>\n      <td>759.01</td>\n      <td>1.00</td>\n      <td>0.90</td>\n      <td>0.700</td>\n      <td>-20.743948</td>\n    </tr>\n    <tr>\n      <th>1950</th>\n      <td>512.838440</td>\n      <td>533.12</td>\n      <td>1.00</td>\n      <td>0.94</td>\n      <td>0.200</td>\n      <td>-20.281560</td>\n    </tr>\n    <tr>\n      <th>1837</th>\n      <td>628.636475</td>\n      <td>648.25</td>\n      <td>1.00</td>\n      <td>0.94</td>\n      <td>0.625</td>\n      <td>-19.613525</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>573</th>\n      <td>428.385986</td>\n      <td>409.84</td>\n      <td>1.00</td>\n      <td>0.98</td>\n      <td>0.125</td>\n      <td>18.545986</td>\n    </tr>\n    <tr>\n      <th>6539</th>\n      <td>582.942627</td>\n      <td>563.29</td>\n      <td>0.95</td>\n      <td>0.98</td>\n      <td>0.875</td>\n      <td>19.652627</td>\n    </tr>\n    <tr>\n      <th>991</th>\n      <td>560.379883</td>\n      <td>538.83</td>\n      <td>0.95</td>\n      <td>0.98</td>\n      <td>0.750</td>\n      <td>21.549883</td>\n    </tr>\n    <tr>\n      <th>7585</th>\n      <td>450.709320</td>\n      <td>428.07</td>\n      <td>1.00</td>\n      <td>0.98</td>\n      <td>0.200</td>\n      <td>22.639320</td>\n    </tr>\n    <tr>\n      <th>1032</th>\n      <td>567.015930</td>\n      <td>537.98</td>\n      <td>1.00</td>\n      <td>0.98</td>\n      <td>0.750</td>\n      <td>29.035930</td>\n    </tr>\n  </tbody>\n</table>\n<p>8783 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame({'Echt': [val[0] for val in list1], 'Vorhergesagt': [val[0] for val in list2]})\n",
    "df_result['X-Koordinate'] = X_test_scaled[:, 0]\n",
    "df_result['Y-Koordinate'] = X_test_scaled[:, 1]\n",
    "df_result['Zeitpunkt'] = X_test_scaled[:, 2]\n",
    "\n",
    "df_result['Differenz'] = df_result['Echt'] - df_result['Vorhergesagt']\n",
    "df_result['Differenz'].sort_values()\n",
    "sorted_df = df_result.sort_values(by= 'Differenz')\n",
    "Anzahl_Punkte = (sorted_df['Differenz'] < -5).sum()\n",
    "print(\"Anzahl der Werte die kleiner sind:\", Anzahl_Punkte)\n",
    "\n",
    "sorted_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T11:49:44.770359400Z",
     "start_time": "2024-03-13T11:49:44.728753200Z"
    }
   },
   "id": "7ffe8ddf2200f429"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mae = history.history['loss']\n",
    "val_mae = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(mae) + 1)\n",
    "\n",
    "# MAE Diagramm\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, mae, 'r', label='Training MSE')\n",
    "plt.plot(epochs, val_mae, 'b', label='Validation MSE')\n",
    "plt.title('Training and Validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T11:49:52.022730Z",
     "start_time": "2024-03-13T11:49:51.909538100Z"
    }
   },
   "id": "3688dd7102e95baf"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mae = history.history['mae']\n",
    "val_mae = history.history['val_mae']\n",
    "\n",
    "epochs = range(1, len(mae) + 1)\n",
    "\n",
    "# MAE Diagramm\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, mae, 'r', label='Training MSE')\n",
    "plt.plot(epochs, val_mae, 'b', label='Validation MSE')\n",
    "plt.title('Training and Validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "#plt.ylim(0.00, 0.01)\n",
    "\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T11:49:52.858394100Z",
     "start_time": "2024-03-13T11:49:52.734440Z"
    }
   },
   "id": "b8d71e5c44c48bef"
  },
  {
   "cell_type": "markdown",
   "id": "553df6fa",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def build_model(learning_rate=0.001, activation='relu', regularization=0.0001, dropout_rate=0.0):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(448, activation=activation, input_shape=(3,), kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(384, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(96, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(128, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(320, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(416, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(416, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(256, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))    \n",
    "# \n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mae'])\n",
    "#     return model\n",
    "# \n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "# \n",
    "# # Verwenden Sie eine Funktion, um das Modell zu instanziieren, fÃ¼r scikit-learn Wrapper\n",
    "# model = KerasRegressor(model=build_model, verbose=2, callbacks=[early_stopping])\n",
    "# \n",
    "# # Anpassung der Parameter im param_grid\n",
    "# param_grid = {\n",
    "#     'model__learning_rate': [0.001, 0.0001],\n",
    "#     'model__regularization': [0.001, 0.0001],\n",
    "#     'fit__batch_size': [10, 25, 50, 75],\n",
    "#     'fit__epochs': [50],\n",
    "#     'model__dropout_rate' : [0.0, 0.1, 0.2]\n",
    "# }\n",
    "# \n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=2)\n",
    "# # Hinweis: Stellen Sie sicher, dass Ihre Daten (X_train_scaled, y_train_scaled) korrekt definiert sind\n",
    "# grid_result = grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "# # Beste Parameter und Score ausgeben\n",
    "# print(\"Beste Parameter:\", grid_search.best_params_)\n",
    "# print(\"Beste Genauigkeit:\", grid_search.best_score_)\n",
    "# \n",
    "# with open(\"Gridsearch_D4.txt\", \"w\") as f:\n",
    "#     f.write(f\"Beste Parameter: {grid_search.best_params_}\\n\")\n",
    "#     f.write(f\"Beste Genauigkeit: {grid_search.best_score_}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T10:03:46.648219700Z"
    }
   },
   "id": "7464a951f44a07ee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Funktion zum Erstellen des Modells\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hp.Int('input_units', min_value=8, max_value=328, step=16), input_shape=(3,), activation='relu'))\n",
    "    for i in range(hp.Int('n_layers', 1, 10)):\n",
    "        model.add(Dense(hp.Int(f'units_{i}', min_value=8, max_value=656, step=16), activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# DurchfÃ¼hrung der Random Search dreimal\n",
    "for run in range(1, 4):\n",
    "    # Anpassen des Verzeichnisses und des Projektnamens fÃ¼r jeden Durchlauf\n",
    "    directory = 'random_search'\n",
    "    project_name = f'random_search_D4_t_2_{run}'\n",
    "\n",
    "    tuner = RandomSearch(\n",
    "        build_model,\n",
    "        objective='val_loss',\n",
    "        max_trials=100,\n",
    "        executions_per_trial=2,\n",
    "        directory=directory,\n",
    "        project_name=project_name\n",
    "    )\n",
    "\n",
    "    # DurchfÃ¼hrung des Random Search\n",
    "    tuner.search(X_train_scaled, y_train_scaled, epochs=50, verbose =0, batch_size=50, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "\n",
    "    # Abrufen und Speichern des besten Modells\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "    model_path = os.path.join(directory, project_name, 'best_model.h5') \n",
    "    best_model.save(model_path)\n",
    "\n",
    "\n",
    "    # Optional: Abrufen und Ausgeben der besten Hyperparameter\n",
    "    best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "    # Konvertieren der Hyperparameter in ein DataFrame\n",
    "    df_hyperparameters = pd.DataFrame([best_hyperparameters.values])\n",
    "    # Speichern des DataFrame als CSV\n",
    "    df_hyperparameters.to_csv(f'random_search_D4_t_2_{run}.csv', index=False)\n",
    "\n",
    "    print(f\"Beste Hyperparameter fÃ¼r Lauf {run}: {best_hyperparameters.values}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T10:03:46.649218900Z"
    }
   },
   "id": "d0f02feb42b652f5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T10:03:46.650224Z"
    }
   },
   "id": "3e35d5ebef369658"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
