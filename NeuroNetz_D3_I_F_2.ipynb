{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94b0518e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T11:44:00.220025100Z",
     "start_time": "2024-04-01T11:43:53.923249800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense , Dropout\n",
    "from scikeras.wrappers import KerasRegressor \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4ff61b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T11:44:00.240348300Z",
     "start_time": "2024-04-01T11:44:00.220025100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft    Temperatur\n254520        0.00000      -0.00200        500   6000   5000  7.535400e+02\n254521        0.00000      -0.00196        500   6000   5000  7.936300e+02\n254522        0.00000      -0.00192        500   6000   5000  8.356500e+02\n254523        0.00000      -0.00188        500   6000   5000  8.775000e+02\n254524        0.00000      -0.00184        500   6000   5000  9.199800e+02\n...               ...           ...        ...    ...    ...           ...\n2087059       0.00248       0.00184        500   9000   5000  1.110600e+03\n2087060       0.00248       0.00188        500   9000   5000  1.046600e+03\n2087061       0.00248       0.00192        500   9000   5000  9.810900e+02\n2087062       0.00248       0.00196        500   9000   5000  7.888600e-31\n2087063       0.00248       0.00200        500   9000   5000  9.403500e+02\n\n[50904 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>254520</th>\n      <td>0.00000</td>\n      <td>-0.00200</td>\n      <td>500</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>7.535400e+02</td>\n    </tr>\n    <tr>\n      <th>254521</th>\n      <td>0.00000</td>\n      <td>-0.00196</td>\n      <td>500</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>7.936300e+02</td>\n    </tr>\n    <tr>\n      <th>254522</th>\n      <td>0.00000</td>\n      <td>-0.00192</td>\n      <td>500</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>8.356500e+02</td>\n    </tr>\n    <tr>\n      <th>254523</th>\n      <td>0.00000</td>\n      <td>-0.00188</td>\n      <td>500</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>8.775000e+02</td>\n    </tr>\n    <tr>\n      <th>254524</th>\n      <td>0.00000</td>\n      <td>-0.00184</td>\n      <td>500</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>9.199800e+02</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2087059</th>\n      <td>0.00248</td>\n      <td>0.00184</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1.110600e+03</td>\n    </tr>\n    <tr>\n      <th>2087060</th>\n      <td>0.00248</td>\n      <td>0.00188</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1.046600e+03</td>\n    </tr>\n    <tr>\n      <th>2087061</th>\n      <td>0.00248</td>\n      <td>0.00192</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>9.810900e+02</td>\n    </tr>\n    <tr>\n      <th>2087062</th>\n      <td>0.00248</td>\n      <td>0.00196</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>7.888600e-31</td>\n    </tr>\n    <tr>\n      <th>2087063</th>\n      <td>0.00248</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>9.403500e+02</td>\n    </tr>\n  </tbody>\n</table>\n<p>50904 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/TPath_300_finish_data.pkl')\n",
    "data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_ALL_D3_500_I_F_PKL.pkl')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "966e3c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T11:44:00.279051300Z",
     "start_time": "2024-04-01T11:44:00.238349300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n",
      "1037169       0.00000      -0.00200        500   7000   6000      811.76\n",
      "1037170       0.00000      -0.00196        500   7000   6000      853.27\n",
      "1037171       0.00000      -0.00192        500   7000   6000      897.57\n",
      "1037172       0.00000      -0.00188        500   7000   6000      941.21\n",
      "1037173       0.00000      -0.00184        500   7000   6000      986.34\n",
      "...               ...           ...        ...    ...    ...         ...\n",
      "1043527       0.00248       0.00184        500   7000   6000      784.55\n",
      "1043528       0.00248       0.00188        500   7000   6000      745.87\n",
      "1043529       0.00248       0.00192        500   7000   6000      706.17\n",
      "1043530       0.00248       0.00196        500   7000   6000      693.28\n",
      "1043531       0.00248       0.00200        500   7000   6000      687.80\n",
      "\n",
      "[6363 rows x 6 columns]\n",
      "Empty DataFrame\n",
      "Columns: [X-Koordinate, Y-Koordinate, Zeitpunkt, Strom, Kraft, Temperatur]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/plain": "         X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n1037169       0.00000      -0.00200        500   7000   6000      811.76\n1037170       0.00000      -0.00196        500   7000   6000      853.27\n1037171       0.00000      -0.00192        500   7000   6000      897.57\n1037172       0.00000      -0.00188        500   7000   6000      941.21\n1037173       0.00000      -0.00184        500   7000   6000      986.34\n...               ...           ...        ...    ...    ...         ...\n1043527       0.00248       0.00184        500   7000   6000      784.55\n1043528       0.00248       0.00188        500   7000   6000      745.87\n1043529       0.00248       0.00192        500   7000   6000      706.17\n1043530       0.00248       0.00196        500   7000   6000      693.28\n1043531       0.00248       0.00200        500   7000   6000      687.80\n\n[6363 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1037169</th>\n      <td>0.00000</td>\n      <td>-0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>811.76</td>\n    </tr>\n    <tr>\n      <th>1037170</th>\n      <td>0.00000</td>\n      <td>-0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>853.27</td>\n    </tr>\n    <tr>\n      <th>1037171</th>\n      <td>0.00000</td>\n      <td>-0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>897.57</td>\n    </tr>\n    <tr>\n      <th>1037172</th>\n      <td>0.00000</td>\n      <td>-0.00188</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>941.21</td>\n    </tr>\n    <tr>\n      <th>1037173</th>\n      <td>0.00000</td>\n      <td>-0.00184</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>986.34</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1043527</th>\n      <td>0.00248</td>\n      <td>0.00184</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>784.55</td>\n    </tr>\n    <tr>\n      <th>1043528</th>\n      <td>0.00248</td>\n      <td>0.00188</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>745.87</td>\n    </tr>\n    <tr>\n      <th>1043529</th>\n      <td>0.00248</td>\n      <td>0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>706.17</td>\n    </tr>\n    <tr>\n      <th>1043530</th>\n      <td>0.00248</td>\n      <td>0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>693.28</td>\n    </tr>\n    <tr>\n      <th>1043531</th>\n      <td>0.00248</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>687.80</td>\n    </tr>\n  </tbody>\n</table>\n<p>6363 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedingung = (data['Kraft'] == 6000) & (data['Strom'] == 7000)\n",
    "df_test = data[bedingung].copy()\n",
    "print(df_test)\n",
    "#df_test.to_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_I7000_F6000_D3_500_I_F_PKL.pkl')\n",
    "data_all = data.drop(df_test.index)\n",
    "#print(data_all)\n",
    "print(data_all[(data_all['Kraft'] == 6000) & (data_all['Strom'] == 7000)])\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "         X-Koordinate  Y-Koordinate  Strom  Kraft    Temperatur\n254520        0.00000      -0.00200   6000   5000  7.535400e+02\n254521        0.00000      -0.00196   6000   5000  7.936300e+02\n254522        0.00000      -0.00192   6000   5000  8.356500e+02\n254523        0.00000      -0.00188   6000   5000  8.775000e+02\n254524        0.00000      -0.00184   6000   5000  9.199800e+02\n...               ...           ...    ...    ...           ...\n2087059       0.00248       0.00184   9000   5000  1.110600e+03\n2087060       0.00248       0.00188   9000   5000  1.046600e+03\n2087061       0.00248       0.00192   9000   5000  9.810900e+02\n2087062       0.00248       0.00196   9000   5000  7.888600e-31\n2087063       0.00248       0.00200   9000   5000  9.403500e+02\n\n[44541 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>254520</th>\n      <td>0.00000</td>\n      <td>-0.00200</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>7.535400e+02</td>\n    </tr>\n    <tr>\n      <th>254521</th>\n      <td>0.00000</td>\n      <td>-0.00196</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>7.936300e+02</td>\n    </tr>\n    <tr>\n      <th>254522</th>\n      <td>0.00000</td>\n      <td>-0.00192</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>8.356500e+02</td>\n    </tr>\n    <tr>\n      <th>254523</th>\n      <td>0.00000</td>\n      <td>-0.00188</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>8.775000e+02</td>\n    </tr>\n    <tr>\n      <th>254524</th>\n      <td>0.00000</td>\n      <td>-0.00184</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>9.199800e+02</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2087059</th>\n      <td>0.00248</td>\n      <td>0.00184</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1.110600e+03</td>\n    </tr>\n    <tr>\n      <th>2087060</th>\n      <td>0.00248</td>\n      <td>0.00188</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1.046600e+03</td>\n    </tr>\n    <tr>\n      <th>2087061</th>\n      <td>0.00248</td>\n      <td>0.00192</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>9.810900e+02</td>\n    </tr>\n    <tr>\n      <th>2087062</th>\n      <td>0.00248</td>\n      <td>0.00196</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>7.888600e-31</td>\n    </tr>\n    <tr>\n      <th>2087063</th>\n      <td>0.00248</td>\n      <td>0.00200</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>9.403500e+02</td>\n    </tr>\n  </tbody>\n</table>\n<p>44541 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all = data_all.drop('Zeitpunkt', axis = 1)\n",
    "data_all"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T11:44:00.345395900Z",
     "start_time": "2024-04-01T11:44:00.256768800Z"
    }
   },
   "id": "467c96c6df4a7dc9"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8783d1d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T11:44:00.351396Z",
     "start_time": "2024-04-01T11:44:00.266501Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       X-Koordinate  Y-Koordinate  Strom  Kraft  Temperatur\n0           0.00112      -0.00064   6000   6000     1617.10\n1           0.00108      -0.00036   8000   7000     2058.20\n2           0.00136       0.00096   6000   6000     1420.30\n3           0.00064       0.00028   6000   5000     1829.90\n4           0.00048       0.00188   6000   6000      693.83\n...             ...           ...    ...    ...         ...\n44536       0.00248      -0.00188   6000   5000      842.80\n44537       0.00192       0.00092   6000   6000     1342.80\n44538       0.00248       0.00124   8000   7000     1434.90\n44539       0.00032       0.00008   6000   5000     1873.40\n44540       0.00120      -0.00044   7000   5000     2010.50\n\n[44541 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00112</td>\n      <td>-0.00064</td>\n      <td>6000</td>\n      <td>6000</td>\n      <td>1617.10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00108</td>\n      <td>-0.00036</td>\n      <td>8000</td>\n      <td>7000</td>\n      <td>2058.20</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00136</td>\n      <td>0.00096</td>\n      <td>6000</td>\n      <td>6000</td>\n      <td>1420.30</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00064</td>\n      <td>0.00028</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>1829.90</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00048</td>\n      <td>0.00188</td>\n      <td>6000</td>\n      <td>6000</td>\n      <td>693.83</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>44536</th>\n      <td>0.00248</td>\n      <td>-0.00188</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>842.80</td>\n    </tr>\n    <tr>\n      <th>44537</th>\n      <td>0.00192</td>\n      <td>0.00092</td>\n      <td>6000</td>\n      <td>6000</td>\n      <td>1342.80</td>\n    </tr>\n    <tr>\n      <th>44538</th>\n      <td>0.00248</td>\n      <td>0.00124</td>\n      <td>8000</td>\n      <td>7000</td>\n      <td>1434.90</td>\n    </tr>\n    <tr>\n      <th>44539</th>\n      <td>0.00032</td>\n      <td>0.00008</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>1873.40</td>\n    </tr>\n    <tr>\n      <th>44540</th>\n      <td>0.00120</td>\n      <td>-0.00044</td>\n      <td>7000</td>\n      <td>5000</td>\n      <td>2010.50</td>\n    </tr>\n  </tbody>\n</table>\n<p>44541 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all = data_all.sample(frac=1, random_state=42)  # Hier wird 42 als Random State verwendet, um die Ergebnisse reproduzierbar zu machen\n",
    "df_reset = data_all.reset_index(drop=True)\n",
    "df_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4e72a16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T11:44:00.438051400Z",
     "start_time": "2024-04-01T11:44:00.282063100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [X-Koordinate, Y-Koordinate, Strom, Kraft]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "y = df_reset[\"Temperatur\"]\n",
    "# Korrektur: Verwenden Sie den Spaltennamen direkt, ohne Indexierung der columns-Eigenschaft\n",
    "X = df_reset.drop(\"Temperatur\", axis=1)\n",
    "\n",
    "print(X[(X['Kraft'] == 6000) & (X['Strom'] == 7000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "label = df_test[\"Temperatur\"]\n",
    "# Korrektur: Verwenden Sie den Spaltennamen direkt, ohne Indexierung der columns-Eigenschaft\n",
    "X_2 = df_test.drop(\"Temperatur\", axis=1)\n",
    "X_2 = X_2.drop('Zeitpunkt',axis =1)\n",
    "X_2 = X_2.reset_index(drop=True)\n",
    "y_2 = label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T11:44:00.439051600Z",
     "start_time": "2024-04-01T11:44:00.288919500Z"
    }
   },
   "id": "2920a35d3f81234d"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7fa289a50d87423"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e694a236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T11:44:00.504051200Z",
     "start_time": "2024-04-01T11:44:00.293065100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      X-Koordinate  Y-Koordinate  Strom  Kraft\n0          0.00000      -0.00200   7000   6000\n1          0.00000      -0.00196   7000   6000\n2          0.00000      -0.00192   7000   6000\n3          0.00000      -0.00188   7000   6000\n4          0.00000      -0.00184   7000   6000\n...            ...           ...    ...    ...\n6358       0.00248       0.00184   7000   6000\n6359       0.00248       0.00188   7000   6000\n6360       0.00248       0.00192   7000   6000\n6361       0.00248       0.00196   7000   6000\n6362       0.00248       0.00200   7000   6000\n\n[6363 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00000</td>\n      <td>-0.00200</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00000</td>\n      <td>-0.00196</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00000</td>\n      <td>-0.00192</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00000</td>\n      <td>-0.00188</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00000</td>\n      <td>-0.00184</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6358</th>\n      <td>0.00248</td>\n      <td>0.00184</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>6359</th>\n      <td>0.00248</td>\n      <td>0.00188</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>6360</th>\n      <td>0.00248</td>\n      <td>0.00192</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>6361</th>\n      <td>0.00248</td>\n      <td>0.00196</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>6362</th>\n      <td>0.00248</td>\n      <td>0.00200</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n  </tbody>\n</table>\n<p>6363 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f3303b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T11:44:00.505051700Z",
     "start_time": "2024-04-01T11:44:00.302198600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0        1617.10\n1        2058.20\n2        1420.30\n3        1829.90\n4         693.83\n          ...   \n44536     842.80\n44537    1342.80\n44538    1434.90\n44539    1873.40\n44540    2010.50\nName: Temperatur, Length: 44541, dtype: float64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3ad8da0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T11:44:00.505051700Z",
     "start_time": "2024-04-01T11:44:00.308878200Z"
    }
   },
   "outputs": [],
   "source": [
    " # train_df enthÃ¤lt 80% der Daten, test_df enthÃ¤lt 20% der Daten\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T11:44:00.519051400Z",
     "start_time": "2024-04-01T11:44:00.387039900Z"
    }
   },
   "id": "b78be1fe68aa0b4a"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c705edb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T11:44:01.026338Z",
     "start_time": "2024-04-01T11:44:00.797864800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialisiere einen MinMaxScaler fÃ¼r die Features\n",
    "scaler_features = MinMaxScaler()\n",
    "scaler_features2 = MinMaxScaler()\n",
    "# Skaliere X_train und X_test\n",
    "X_train_scaled = scaler_features.fit_transform(X)\n",
    "#X_test_scaled = scaler_features.transform(X_test)  # Nutze gleiche Skalierungsparameter ohne das X_Test Informationen einflieÃŸen\n",
    "X_test_scaled_2 = scaler_features.transform(X_2)  # Nutze gleiche Skalierungsparameter ohne das X_Test Informationen einflieÃŸen\n",
    "\n",
    "# Initialisiere einen SEPARATEN MinMaxScaler fÃ¼r das Ziel, wenn nÃ¶tig\n",
    "scaler_target = MinMaxScaler()\n",
    "\n",
    "\n",
    "# Skaliere y_train und y_test. Beachte, dass y_train.reshape(-1, 1) verwendet wird, da MinMaxScaler \n",
    "# erwartet, dass die Eingaben als 2D-Arrays kommen, und Ziele normalerweise als 1D-Arrays vorliegen.\n",
    "y_train_scaled = scaler_target.fit_transform(y.values.reshape(-1, 1))\n",
    "#y_test_scaled = scaler_target.transform(y_test.values.reshape(-1, 1))\n",
    "y_test_scaled_2 = scaler_target.transform(y_2.values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbefe631e495b483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T18:45:43.538562500Z",
     "start_time": "2024-03-31T18:45:43.356182500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.        , 0.        , 0.33333333, 0.25      ],\n       [0.        , 0.01      , 0.33333333, 0.25      ],\n       [0.        , 0.02      , 0.33333333, 0.25      ],\n       ...,\n       [1.        , 0.98      , 0.33333333, 0.25      ],\n       [1.        , 0.99      , 0.33333333, 0.25      ],\n       [1.        , 1.        , 0.33333333, 0.25      ]])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_scaled.max()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T18:45:43.539562300Z",
     "start_time": "2024-03-31T18:45:43.362016200Z"
    }
   },
   "id": "ce04ce43aac2242f"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1426/1426 [==============================] - 5s 3ms/step - loss: 0.0243 - mae: 0.0434 - val_loss: 0.0160 - val_mae: 0.0154\n",
      "Epoch 2/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0152 - mae: 0.0176 - val_loss: 0.0140 - val_mae: 0.0125\n",
      "Epoch 3/1000\n",
      "1426/1426 [==============================] - 5s 3ms/step - loss: 0.0135 - mae: 0.0123 - val_loss: 0.0130 - val_mae: 0.0120\n",
      "Epoch 4/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0128 - mae: 0.0152 - val_loss: 0.0121 - val_mae: 0.0081\n",
      "Epoch 5/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0119 - mae: 0.0117 - val_loss: 0.0114 - val_mae: 0.0103\n",
      "Epoch 6/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0111 - mae: 0.0119 - val_loss: 0.0107 - val_mae: 0.0117\n",
      "Epoch 7/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0104 - mae: 0.0106 - val_loss: 0.0100 - val_mae: 0.0073\n",
      "Epoch 8/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0098 - mae: 0.0108 - val_loss: 0.0094 - val_mae: 0.0058\n",
      "Epoch 9/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0092 - mae: 0.0097 - val_loss: 0.0089 - val_mae: 0.0070\n",
      "Epoch 10/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0087 - mae: 0.0089 - val_loss: 0.0087 - val_mae: 0.0188\n",
      "Epoch 11/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0082 - mae: 0.0088 - val_loss: 0.0081 - val_mae: 0.0117\n",
      "Epoch 12/1000\n",
      "1426/1426 [==============================] - 5s 3ms/step - loss: 0.0077 - mae: 0.0075 - val_loss: 0.0083 - val_mae: 0.0260\n",
      "Epoch 13/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0073 - mae: 0.0081 - val_loss: 0.0072 - val_mae: 0.0122\n",
      "Epoch 14/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0068 - mae: 0.0072 - val_loss: 0.0065 - val_mae: 0.0043\n",
      "Epoch 15/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0064 - mae: 0.0067 - val_loss: 0.0061 - val_mae: 0.0043\n",
      "Epoch 16/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0060 - mae: 0.0068 - val_loss: 0.0057 - val_mae: 0.0041\n",
      "Epoch 17/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0056 - mae: 0.0062 - val_loss: 0.0054 - val_mae: 0.0047\n",
      "Epoch 18/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0053 - mae: 0.0067 - val_loss: 0.0050 - val_mae: 0.0053\n",
      "Epoch 19/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0049 - mae: 0.0056 - val_loss: 0.0047 - val_mae: 0.0039\n",
      "Epoch 20/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0046 - mae: 0.0057 - val_loss: 0.0047 - val_mae: 0.0142\n",
      "Epoch 21/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0044 - mae: 0.0059 - val_loss: 0.0043 - val_mae: 0.0105\n",
      "Epoch 22/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0041 - mae: 0.0053 - val_loss: 0.0040 - val_mae: 0.0068\n",
      "Epoch 23/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0038 - mae: 0.0056 - val_loss: 0.0037 - val_mae: 0.0032\n",
      "Epoch 24/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0036 - mae: 0.0053 - val_loss: 0.0035 - val_mae: 0.0064\n",
      "Epoch 25/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0034 - mae: 0.0050 - val_loss: 0.0032 - val_mae: 0.0027\n",
      "Epoch 26/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0032 - mae: 0.0048 - val_loss: 0.0030 - val_mae: 0.0025\n",
      "Epoch 27/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0030 - mae: 0.0047 - val_loss: 0.0029 - val_mae: 0.0031\n",
      "Epoch 28/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0028 - mae: 0.0044 - val_loss: 0.0027 - val_mae: 0.0025\n",
      "Epoch 29/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0026 - mae: 0.0045 - val_loss: 0.0025 - val_mae: 0.0032\n",
      "Epoch 30/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0025 - mae: 0.0046 - val_loss: 0.0024 - val_mae: 0.0035\n",
      "Epoch 31/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0024 - mae: 0.0044 - val_loss: 0.0023 - val_mae: 0.0042\n",
      "Epoch 32/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0022 - mae: 0.0040 - val_loss: 0.0021 - val_mae: 0.0023\n",
      "Epoch 33/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0021 - mae: 0.0042 - val_loss: 0.0020 - val_mae: 0.0025\n",
      "Epoch 34/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0020 - mae: 0.0043 - val_loss: 0.0019 - val_mae: 0.0042\n",
      "Epoch 35/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0019 - mae: 0.0043 - val_loss: 0.0018 - val_mae: 0.0034\n",
      "Epoch 36/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0018 - mae: 0.0040 - val_loss: 0.0017 - val_mae: 0.0037\n",
      "Epoch 37/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0017 - mae: 0.0039 - val_loss: 0.0017 - val_mae: 0.0031\n",
      "Epoch 38/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0016 - mae: 0.0041 - val_loss: 0.0016 - val_mae: 0.0029\n",
      "Epoch 39/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0016 - mae: 0.0040 - val_loss: 0.0015 - val_mae: 0.0025\n",
      "Epoch 40/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0015 - mae: 0.0041 - val_loss: 0.0014 - val_mae: 0.0027\n",
      "Epoch 41/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0014 - mae: 0.0036 - val_loss: 0.0014 - val_mae: 0.0061\n",
      "Epoch 42/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0014 - mae: 0.0040 - val_loss: 0.0013 - val_mae: 0.0027\n",
      "Epoch 43/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0013 - mae: 0.0038 - val_loss: 0.0013 - val_mae: 0.0031\n",
      "Epoch 44/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0013 - mae: 0.0036 - val_loss: 0.0012 - val_mae: 0.0020\n",
      "Epoch 45/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0012 - mae: 0.0039 - val_loss: 0.0012 - val_mae: 0.0025\n",
      "Epoch 46/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0012 - mae: 0.0037 - val_loss: 0.0011 - val_mae: 0.0026\n",
      "Epoch 47/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0011 - mae: 0.0035 - val_loss: 0.0011 - val_mae: 0.0060\n",
      "Epoch 48/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0011 - mae: 0.0038 - val_loss: 0.0011 - val_mae: 0.0029\n",
      "Epoch 49/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0011 - mae: 0.0038 - val_loss: 0.0010 - val_mae: 0.0022\n",
      "Epoch 50/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0010 - mae: 0.0035 - val_loss: 9.8750e-04 - val_mae: 0.0029\n",
      "Epoch 51/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 9.9716e-04 - mae: 0.0037 - val_loss: 9.5017e-04 - val_mae: 0.0022\n",
      "Epoch 52/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 9.6158e-04 - mae: 0.0036 - val_loss: 9.5447e-04 - val_mae: 0.0052\n",
      "Epoch 53/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 9.2724e-04 - mae: 0.0034 - val_loss: 8.9491e-04 - val_mae: 0.0029\n",
      "Epoch 54/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 8.9751e-04 - mae: 0.0034 - val_loss: 8.6630e-04 - val_mae: 0.0029\n",
      "Epoch 55/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 8.7534e-04 - mae: 0.0035 - val_loss: 8.3563e-04 - val_mae: 0.0021\n",
      "Epoch 56/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 8.4395e-04 - mae: 0.0033 - val_loss: 8.1330e-04 - val_mae: 0.0026\n",
      "Epoch 57/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 8.2283e-04 - mae: 0.0035 - val_loss: 8.2273e-04 - val_mae: 0.0057\n",
      "Epoch 58/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 7.9734e-04 - mae: 0.0034 - val_loss: 8.5825e-04 - val_mae: 0.0084\n",
      "Epoch 59/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 7.7801e-04 - mae: 0.0034 - val_loss: 7.6328e-04 - val_mae: 0.0040\n",
      "Epoch 60/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 7.6472e-04 - mae: 0.0036 - val_loss: 7.2931e-04 - val_mae: 0.0025\n",
      "Epoch 61/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 7.3592e-04 - mae: 0.0032 - val_loss: 7.2047e-04 - val_mae: 0.0038\n",
      "Epoch 62/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 7.2007e-04 - mae: 0.0034 - val_loss: 6.9264e-04 - val_mae: 0.0027\n",
      "Epoch 63/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 7.0373e-04 - mae: 0.0034 - val_loss: 6.8193e-04 - val_mae: 0.0035\n",
      "Epoch 64/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 6.8939e-04 - mae: 0.0035 - val_loss: 6.6120e-04 - val_mae: 0.0029\n",
      "Epoch 65/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 6.6816e-04 - mae: 0.0033 - val_loss: 6.5782e-04 - val_mae: 0.0042\n",
      "Epoch 66/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 6.5348e-04 - mae: 0.0033 - val_loss: 6.2493e-04 - val_mae: 0.0021\n",
      "Epoch 67/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 6.4344e-04 - mae: 0.0034 - val_loss: 6.1406e-04 - val_mae: 0.0024\n",
      "Epoch 68/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 6.2682e-04 - mae: 0.0033 - val_loss: 5.9926e-04 - val_mae: 0.0023\n",
      "Epoch 69/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 6.0985e-04 - mae: 0.0033 - val_loss: 5.8499e-04 - val_mae: 0.0024\n",
      "Epoch 70/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 5.9825e-04 - mae: 0.0032 - val_loss: 5.7112e-04 - val_mae: 0.0022\n",
      "Epoch 71/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 5.8608e-04 - mae: 0.0033 - val_loss: 5.5819e-04 - val_mae: 0.0020\n",
      "Epoch 72/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 5.6819e-04 - mae: 0.0031 - val_loss: 6.0876e-04 - val_mae: 0.0054\n",
      "Epoch 73/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 5.6779e-04 - mae: 0.0033 - val_loss: 5.3540e-04 - val_mae: 0.0020\n",
      "Epoch 74/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 5.5251e-04 - mae: 0.0032 - val_loss: 5.2750e-04 - val_mae: 0.0025\n",
      "Epoch 75/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 5.4434e-04 - mae: 0.0034 - val_loss: 5.1765e-04 - val_mae: 0.0024\n",
      "Epoch 76/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 5.2929e-04 - mae: 0.0031 - val_loss: 5.0641e-04 - val_mae: 0.0023\n",
      "Epoch 77/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 5.2213e-04 - mae: 0.0032 - val_loss: 4.9707e-04 - val_mae: 0.0023\n",
      "Epoch 78/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 5.1054e-04 - mae: 0.0031 - val_loss: 4.9487e-04 - val_mae: 0.0033\n",
      "Epoch 79/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 5.0358e-04 - mae: 0.0031 - val_loss: 4.7668e-04 - val_mae: 0.0019\n",
      "Epoch 80/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.9296e-04 - mae: 0.0031 - val_loss: 4.7096e-04 - val_mae: 0.0023\n",
      "Epoch 81/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.8428e-04 - mae: 0.0030 - val_loss: 4.6290e-04 - val_mae: 0.0023\n",
      "Epoch 82/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.8376e-04 - mae: 0.0033 - val_loss: 4.5634e-04 - val_mae: 0.0024\n",
      "Epoch 83/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.6799e-04 - mae: 0.0030 - val_loss: 4.8702e-04 - val_mae: 0.0059\n",
      "Epoch 84/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.6410e-04 - mae: 0.0031 - val_loss: 4.4177e-04 - val_mae: 0.0024\n",
      "Epoch 85/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.5302e-04 - mae: 0.0030 - val_loss: 4.3340e-04 - val_mae: 0.0022\n",
      "Epoch 86/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.4885e-04 - mae: 0.0030 - val_loss: 4.2644e-04 - val_mae: 0.0022\n",
      "Epoch 87/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.4143e-04 - mae: 0.0030 - val_loss: 4.1863e-04 - val_mae: 0.0019\n",
      "Epoch 88/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.3448e-04 - mae: 0.0031 - val_loss: 4.3291e-04 - val_mae: 0.0046\n",
      "Epoch 89/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.3150e-04 - mae: 0.0032 - val_loss: 4.0900e-04 - val_mae: 0.0025\n",
      "Epoch 90/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.2605e-04 - mae: 0.0032 - val_loss: 4.0362e-04 - val_mae: 0.0026\n",
      "Epoch 91/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.1600e-04 - mae: 0.0029 - val_loss: 3.9736e-04 - val_mae: 0.0023\n",
      "Epoch 92/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.1325e-04 - mae: 0.0031 - val_loss: 3.8905e-04 - val_mae: 0.0019\n",
      "Epoch 93/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.0142e-04 - mae: 0.0028 - val_loss: 3.8713e-04 - val_mae: 0.0025\n",
      "Epoch 94/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.9925e-04 - mae: 0.0030 - val_loss: 3.8596e-04 - val_mae: 0.0033\n",
      "Epoch 95/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.9387e-04 - mae: 0.0029 - val_loss: 3.7852e-04 - val_mae: 0.0027\n",
      "Epoch 96/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.9053e-04 - mae: 0.0031 - val_loss: 3.7399e-04 - val_mae: 0.0031\n",
      "Epoch 97/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.8290e-04 - mae: 0.0030 - val_loss: 3.7086e-04 - val_mae: 0.0029\n",
      "Epoch 98/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.7789e-04 - mae: 0.0030 - val_loss: 3.6798e-04 - val_mae: 0.0028\n",
      "Epoch 99/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.7505e-04 - mae: 0.0030 - val_loss: 5.6248e-04 - val_mae: 0.0112\n",
      "Epoch 100/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.7152e-04 - mae: 0.0030 - val_loss: 3.5414e-04 - val_mae: 0.0028\n",
      "Epoch 101/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.6485e-04 - mae: 0.0030 - val_loss: 3.5029e-04 - val_mae: 0.0029\n",
      "Epoch 102/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.5854e-04 - mae: 0.0029 - val_loss: 3.4556e-04 - val_mae: 0.0027\n",
      "Epoch 103/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.5842e-04 - mae: 0.0030 - val_loss: 3.3513e-04 - val_mae: 0.0018\n",
      "Epoch 104/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.5052e-04 - mae: 0.0029 - val_loss: 3.3643e-04 - val_mae: 0.0025\n",
      "Epoch 105/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.4549e-04 - mae: 0.0029 - val_loss: 3.3029e-04 - val_mae: 0.0023\n",
      "Epoch 106/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.4576e-04 - mae: 0.0031 - val_loss: 3.2531e-04 - val_mae: 0.0023\n",
      "Epoch 107/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.3668e-04 - mae: 0.0028 - val_loss: 3.1897e-04 - val_mae: 0.0018\n",
      "Epoch 108/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.3380e-04 - mae: 0.0028 - val_loss: 3.3169e-04 - val_mae: 0.0038\n",
      "Epoch 109/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.2995e-04 - mae: 0.0029 - val_loss: 3.1146e-04 - val_mae: 0.0018\n",
      "Epoch 110/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.2713e-04 - mae: 0.0028 - val_loss: 3.0923e-04 - val_mae: 0.0020\n",
      "Epoch 111/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.2547e-04 - mae: 0.0030 - val_loss: 3.0489e-04 - val_mae: 0.0019\n",
      "Epoch 112/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.2007e-04 - mae: 0.0029 - val_loss: 3.0219e-04 - val_mae: 0.0020\n",
      "Epoch 113/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.1755e-04 - mae: 0.0029 - val_loss: 2.9789e-04 - val_mae: 0.0018\n",
      "Epoch 114/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.1407e-04 - mae: 0.0029 - val_loss: 2.9682e-04 - val_mae: 0.0022\n",
      "Epoch 115/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.1216e-04 - mae: 0.0029 - val_loss: 2.9301e-04 - val_mae: 0.0021\n",
      "Epoch 116/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.0626e-04 - mae: 0.0028 - val_loss: 2.9458e-04 - val_mae: 0.0026\n",
      "Epoch 117/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.0463e-04 - mae: 0.0029 - val_loss: 2.8982e-04 - val_mae: 0.0025\n",
      "Epoch 118/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.0070e-04 - mae: 0.0029 - val_loss: 2.8251e-04 - val_mae: 0.0018\n",
      "Epoch 119/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.9753e-04 - mae: 0.0028 - val_loss: 2.8008e-04 - val_mae: 0.0019\n",
      "Epoch 120/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.9857e-04 - mae: 0.0030 - val_loss: 2.7715e-04 - val_mae: 0.0019\n",
      "Epoch 121/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.8954e-04 - mae: 0.0027 - val_loss: 2.7412e-04 - val_mae: 0.0018\n",
      "Epoch 122/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.8902e-04 - mae: 0.0028 - val_loss: 2.8822e-04 - val_mae: 0.0041\n",
      "Epoch 123/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.8802e-04 - mae: 0.0029 - val_loss: 2.7029e-04 - val_mae: 0.0022\n",
      "Epoch 124/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.8399e-04 - mae: 0.0028 - val_loss: 2.6631e-04 - val_mae: 0.0019\n",
      "Epoch 125/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.8003e-04 - mae: 0.0027 - val_loss: 2.6563e-04 - val_mae: 0.0023\n",
      "Epoch 126/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.7942e-04 - mae: 0.0029 - val_loss: 2.6594e-04 - val_mae: 0.0025\n",
      "Epoch 127/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.7726e-04 - mae: 0.0029 - val_loss: 2.5885e-04 - val_mae: 0.0018\n",
      "Epoch 128/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.7618e-04 - mae: 0.0029 - val_loss: 2.5850e-04 - val_mae: 0.0022\n",
      "Epoch 129/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.6959e-04 - mae: 0.0026 - val_loss: 5.0963e-04 - val_mae: 0.0109\n",
      "Epoch 130/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.7357e-04 - mae: 0.0030 - val_loss: 2.5319e-04 - val_mae: 0.0019\n",
      "Epoch 131/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.6462e-04 - mae: 0.0026 - val_loss: 2.4981e-04 - val_mae: 0.0018\n",
      "Epoch 132/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.6549e-04 - mae: 0.0028 - val_loss: 2.4760e-04 - val_mae: 0.0018\n",
      "Epoch 133/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.6579e-04 - mae: 0.0030 - val_loss: 2.4586e-04 - val_mae: 0.0019\n",
      "Epoch 134/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.5864e-04 - mae: 0.0026 - val_loss: 2.4748e-04 - val_mae: 0.0024\n",
      "Epoch 135/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.6054e-04 - mae: 0.0028 - val_loss: 2.4115e-04 - val_mae: 0.0018\n",
      "Epoch 136/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.5722e-04 - mae: 0.0028 - val_loss: 2.4441e-04 - val_mae: 0.0025\n",
      "Epoch 137/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.5257e-04 - mae: 0.0027 - val_loss: 2.3876e-04 - val_mae: 0.0021\n",
      "Epoch 138/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.5075e-04 - mae: 0.0027 - val_loss: 2.3478e-04 - val_mae: 0.0017\n",
      "Epoch 139/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.5061e-04 - mae: 0.0027 - val_loss: 2.3504e-04 - val_mae: 0.0020\n",
      "Epoch 140/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.4846e-04 - mae: 0.0028 - val_loss: 2.4456e-04 - val_mae: 0.0035\n",
      "Epoch 141/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.4857e-04 - mae: 0.0029 - val_loss: 2.5578e-04 - val_mae: 0.0045\n",
      "Epoch 142/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.4544e-04 - mae: 0.0027 - val_loss: 2.3321e-04 - val_mae: 0.0025\n",
      "Epoch 143/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.4472e-04 - mae: 0.0028 - val_loss: 2.2639e-04 - val_mae: 0.0018\n",
      "Epoch 144/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.4246e-04 - mae: 0.0028 - val_loss: 2.3232e-04 - val_mae: 0.0029\n",
      "Epoch 145/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.4063e-04 - mae: 0.0027 - val_loss: 2.2723e-04 - val_mae: 0.0026\n",
      "Epoch 146/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.3852e-04 - mae: 0.0028 - val_loss: 2.2691e-04 - val_mae: 0.0025\n",
      "Epoch 147/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.3705e-04 - mae: 0.0028 - val_loss: 2.1979e-04 - val_mae: 0.0018\n",
      "Epoch 148/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.3587e-04 - mae: 0.0027 - val_loss: 2.1905e-04 - val_mae: 0.0019\n",
      "Epoch 149/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.3150e-04 - mae: 0.0027 - val_loss: 3.2634e-04 - val_mae: 0.0099\n",
      "Epoch 150/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.3292e-04 - mae: 0.0028 - val_loss: 2.4619e-04 - val_mae: 0.0048\n",
      "Epoch 151/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.3156e-04 - mae: 0.0028 - val_loss: 2.1457e-04 - val_mae: 0.0020\n",
      "Epoch 152/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.2845e-04 - mae: 0.0027 - val_loss: 2.1545e-04 - val_mae: 0.0024\n",
      "Epoch 153/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.2576e-04 - mae: 0.0027 - val_loss: 2.1198e-04 - val_mae: 0.0020\n",
      "Epoch 154/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.2437e-04 - mae: 0.0026 - val_loss: 2.2031e-04 - val_mae: 0.0035\n",
      "Epoch 155/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.2202e-04 - mae: 0.0026 - val_loss: 2.8053e-04 - val_mae: 0.0070\n",
      "Epoch 156/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.2288e-04 - mae: 0.0028 - val_loss: 2.2096e-04 - val_mae: 0.0033\n",
      "Epoch 157/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.2367e-04 - mae: 0.0029 - val_loss: 2.2057e-04 - val_mae: 0.0036\n",
      "Epoch 158/1000\n",
      "1423/1426 [============================>.] - ETA: 0s - loss: 2.1813e-04 - mae: 0.0026Restoring model weights from the end of the best epoch: 153.\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.1829e-04 - mae: 0.0026 - val_loss: 2.7723e-04 - val_mae: 0.0074\n",
      "Epoch 158: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Netzwerkarchitektur\n",
    "model = Sequential([\n",
    "\n",
    "    Dense(56, activation='relu', input_shape=(4,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(200, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(120, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(296, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(280, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(232, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(1 , activation = 'linear')\n",
    "])\n",
    "\n",
    "# Optimierer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "# Modell kompilieren (Verwendung von mean_squared_error als Verlustfunktion fÃ¼r Regression)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])  # Metriken fÃ¼r Regression: Mean Absolute Error und Mean Squared Error\n",
    "\n",
    "# Early Stopping Callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "# Trainingsparameter\n",
    "batch_size = 25\n",
    "epochs = 1000\n",
    "\n",
    "# Modell trainieren (Annahme: X_train, y_train, X_val, y_val sind vordefiniert)\n",
    "history = model.fit(X_train_scaled, y_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:35:30.076931600Z",
     "start_time": "2024-03-31T20:25:38.005573700Z"
    }
   },
   "id": "8b52e1a9a6ff3aeb"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "Training fÃ¼r Fold 1...\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "1426/1426 [==============================] - 5s 2ms/step - loss: 0.0250 - mae: 0.0441 - val_loss: 0.0164 - val_mae: 0.0149\n",
      "Epoch 2/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0155 - mae: 0.0158 - val_loss: 0.0178 - val_mae: 0.0462\n",
      "Epoch 3/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0142 - mae: 0.0136 - val_loss: 0.0138 - val_mae: 0.0179\n",
      "Epoch 4/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0132 - mae: 0.0140 - val_loss: 0.0125 - val_mae: 0.0082\n",
      "Epoch 5/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0122 - mae: 0.0109 - val_loss: 0.0116 - val_mae: 0.0048\n",
      "Epoch 6/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0114 - mae: 0.0112 - val_loss: 0.0108 - val_mae: 0.0050\n",
      "Epoch 7/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0106 - mae: 0.0102 - val_loss: 0.0112 - val_mae: 0.0278\n",
      "Epoch 8/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0100 - mae: 0.0099 - val_loss: 0.0096 - val_mae: 0.0119\n",
      "Epoch 9/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0088 - val_mae: 0.0068\n",
      "Epoch 10/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0086 - mae: 0.0085 - val_loss: 0.0084 - val_mae: 0.0110\n",
      "Epoch 11/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0077 - val_mae: 0.0054\n",
      "Epoch 12/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0075 - mae: 0.0078 - val_loss: 0.0072 - val_mae: 0.0074\n",
      "Epoch 13/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0070 - mae: 0.0074 - val_loss: 0.0067 - val_mae: 0.0055\n",
      "Epoch 14/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0065 - mae: 0.0068 - val_loss: 0.0062 - val_mae: 0.0055\n",
      "Epoch 15/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0061 - mae: 0.0064 - val_loss: 0.0062 - val_mae: 0.0156\n",
      "Epoch 16/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0057 - mae: 0.0067 - val_loss: 0.0054 - val_mae: 0.0054\n",
      "Epoch 17/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0053 - mae: 0.0059 - val_loss: 0.0052 - val_mae: 0.0103\n",
      "Epoch 18/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0050 - mae: 0.0062 - val_loss: 0.0047 - val_mae: 0.0056\n",
      "Epoch 19/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0046 - mae: 0.0057 - val_loss: 0.0044 - val_mae: 0.0044\n",
      "Epoch 20/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0043 - mae: 0.0054 - val_loss: 0.0043 - val_mae: 0.0106\n",
      "Epoch 21/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0040 - mae: 0.0054 - val_loss: 0.0038 - val_mae: 0.0045\n",
      "Epoch 22/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0038 - mae: 0.0056 - val_loss: 0.0036 - val_mae: 0.0046\n",
      "Epoch 23/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0036 - mae: 0.0051 - val_loss: 0.0034 - val_mae: 0.0037\n",
      "Epoch 24/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0033 - mae: 0.0050 - val_loss: 0.0032 - val_mae: 0.0060\n",
      "Epoch 25/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0031 - mae: 0.0048 - val_loss: 0.0030 - val_mae: 0.0038\n",
      "Epoch 26/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0030 - mae: 0.0047 - val_loss: 0.0028 - val_mae: 0.0050\n",
      "Epoch 27/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0028 - mae: 0.0046 - val_loss: 0.0027 - val_mae: 0.0033\n",
      "Epoch 28/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0026 - mae: 0.0043 - val_loss: 0.0025 - val_mae: 0.0035\n",
      "Epoch 29/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0025 - mae: 0.0046 - val_loss: 0.0024 - val_mae: 0.0037\n",
      "Epoch 30/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0024 - mae: 0.0044 - val_loss: 0.0023 - val_mae: 0.0038\n",
      "Epoch 31/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0022 - mae: 0.0044 - val_loss: 0.0021 - val_mae: 0.0040\n",
      "Epoch 32/1000\n",
      "1426/1426 [==============================] - 5s 3ms/step - loss: 0.0021 - mae: 0.0044 - val_loss: 0.0021 - val_mae: 0.0083\n",
      "Epoch 33/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0020 - mae: 0.0042 - val_loss: 0.0019 - val_mae: 0.0025\n",
      "Epoch 34/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0019 - mae: 0.0042 - val_loss: 0.0018 - val_mae: 0.0025\n",
      "Epoch 35/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0018 - mae: 0.0040 - val_loss: 0.0017 - val_mae: 0.0021\n",
      "Epoch 36/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0018 - mae: 0.0042 - val_loss: 0.0017 - val_mae: 0.0035\n",
      "Epoch 37/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0017 - mae: 0.0039 - val_loss: 0.0016 - val_mae: 0.0027\n",
      "Epoch 38/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0016 - mae: 0.0038 - val_loss: 0.0015 - val_mae: 0.0021\n",
      "Epoch 39/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0015 - mae: 0.0038 - val_loss: 0.0015 - val_mae: 0.0028\n",
      "Epoch 40/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0015 - mae: 0.0038 - val_loss: 0.0014 - val_mae: 0.0024\n",
      "Epoch 41/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0014 - mae: 0.0037 - val_loss: 0.0017 - val_mae: 0.0163\n",
      "Epoch 42/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0013 - mae: 0.0036 - val_loss: 0.0013 - val_mae: 0.0074\n",
      "Epoch 43/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0013 - mae: 0.0040 - val_loss: 0.0012 - val_mae: 0.0021\n",
      "Epoch 44/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0013 - mae: 0.0040 - val_loss: 0.0012 - val_mae: 0.0037\n",
      "Epoch 45/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0012 - mae: 0.0036 - val_loss: 0.0011 - val_mae: 0.0030\n",
      "Epoch 46/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0012 - mae: 0.0035 - val_loss: 0.0011 - val_mae: 0.0029\n",
      "Epoch 47/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0011 - mae: 0.0037 - val_loss: 0.0011 - val_mae: 0.0036\n",
      "Epoch 48/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0011 - mae: 0.0036 - val_loss: 0.0010 - val_mae: 0.0018\n",
      "Epoch 49/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0011 - mae: 0.0036 - val_loss: 9.8786e-04 - val_mae: 0.0021\n",
      "Epoch 50/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0010 - mae: 0.0032 - val_loss: 9.5788e-04 - val_mae: 0.0023\n",
      "Epoch 51/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 9.9199e-04 - mae: 0.0037 - val_loss: 0.0010 - val_mae: 0.0071\n",
      "Epoch 52/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 9.5611e-04 - mae: 0.0035 - val_loss: 9.8612e-04 - val_mae: 0.0077\n",
      "Epoch 53/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 9.2424e-04 - mae: 0.0033 - val_loss: 8.7857e-04 - val_mae: 0.0033\n",
      "Epoch 54/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 9.0168e-04 - mae: 0.0035 - val_loss: 8.4591e-04 - val_mae: 0.0025\n",
      "Epoch 55/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 8.7704e-04 - mae: 0.0033 - val_loss: 8.2214e-04 - val_mae: 0.0024\n",
      "Epoch 56/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 8.4828e-04 - mae: 0.0030 - val_loss: 7.9709e-04 - val_mae: 0.0020\n",
      "Epoch 57/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 8.2658e-04 - mae: 0.0034 - val_loss: 7.7455e-04 - val_mae: 0.0021\n",
      "Epoch 58/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 8.1660e-04 - mae: 0.0037 - val_loss: 7.5148e-04 - val_mae: 0.0018\n",
      "Epoch 59/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.8452e-04 - mae: 0.0032 - val_loss: 7.3997e-04 - val_mae: 0.0029\n",
      "Epoch 60/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.6299e-04 - mae: 0.0033 - val_loss: 7.1367e-04 - val_mae: 0.0022\n",
      "Epoch 61/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.4774e-04 - mae: 0.0035 - val_loss: 6.9637e-04 - val_mae: 0.0024\n",
      "Epoch 62/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.2607e-04 - mae: 0.0033 - val_loss: 6.8306e-04 - val_mae: 0.0028\n",
      "Epoch 63/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.1209e-04 - mae: 0.0034 - val_loss: 6.5808e-04 - val_mae: 0.0018\n",
      "Epoch 64/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.9232e-04 - mae: 0.0032 - val_loss: 6.4196e-04 - val_mae: 0.0019\n",
      "Epoch 65/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 6.7535e-04 - mae: 0.0032 - val_loss: 6.7053e-04 - val_mae: 0.0055\n",
      "Epoch 66/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 6.6316e-04 - mae: 0.0034 - val_loss: 6.1575e-04 - val_mae: 0.0026\n",
      "Epoch 67/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.5012e-04 - mae: 0.0034 - val_loss: 5.9785e-04 - val_mae: 0.0021\n",
      "Epoch 68/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.3363e-04 - mae: 0.0033 - val_loss: 6.0800e-04 - val_mae: 0.0042\n",
      "Epoch 69/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.1390e-04 - mae: 0.0030 - val_loss: 5.7190e-04 - val_mae: 0.0022\n",
      "Epoch 70/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.0479e-04 - mae: 0.0032 - val_loss: 5.5839e-04 - val_mae: 0.0020\n",
      "Epoch 71/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.9241e-04 - mae: 0.0032 - val_loss: 6.1588e-04 - val_mae: 0.0067\n",
      "Epoch 72/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 5.8031e-04 - mae: 0.0032 - val_loss: 8.0151e-04 - val_mae: 0.0136\n",
      "Epoch 73/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 5.7194e-04 - mae: 0.0034 - val_loss: 5.2280e-04 - val_mae: 0.0020\n",
      "Epoch 74/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 5.5604e-04 - mae: 0.0033 - val_loss: 5.1381e-04 - val_mae: 0.0023\n",
      "Epoch 75/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.4401e-04 - mae: 0.0031 - val_loss: 5.0454e-04 - val_mae: 0.0025\n",
      "Epoch 76/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.3282e-04 - mae: 0.0031 - val_loss: 4.9048e-04 - val_mae: 0.0021\n",
      "Epoch 77/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.2254e-04 - mae: 0.0030 - val_loss: 4.8572e-04 - val_mae: 0.0025\n",
      "Epoch 78/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.2116e-04 - mae: 0.0034 - val_loss: 4.8131e-04 - val_mae: 0.0034\n",
      "Epoch 79/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.0561e-04 - mae: 0.0031 - val_loss: 4.6443e-04 - val_mae: 0.0025\n",
      "Epoch 80/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.9813e-04 - mae: 0.0030 - val_loss: 4.5615e-04 - val_mae: 0.0024\n",
      "Epoch 81/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.8979e-04 - mae: 0.0031 - val_loss: 4.5387e-04 - val_mae: 0.0029\n",
      "Epoch 82/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 4.8322e-04 - mae: 0.0031 - val_loss: 4.3966e-04 - val_mae: 0.0022\n",
      "Epoch 83/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.7677e-04 - mae: 0.0032 - val_loss: 4.3598e-04 - val_mae: 0.0026\n",
      "Epoch 84/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 4.6232e-04 - mae: 0.0029 - val_loss: 4.2318e-04 - val_mae: 0.0018\n",
      "Epoch 85/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 4.5945e-04 - mae: 0.0031 - val_loss: 4.3327e-04 - val_mae: 0.0036\n",
      "Epoch 86/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.5161e-04 - mae: 0.0031 - val_loss: 4.0927e-04 - val_mae: 0.0020\n",
      "Epoch 87/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.4448e-04 - mae: 0.0030 - val_loss: 4.0292e-04 - val_mae: 0.0020\n",
      "Epoch 88/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.4040e-04 - mae: 0.0031 - val_loss: 4.0443e-04 - val_mae: 0.0029\n",
      "Epoch 89/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.3441e-04 - mae: 0.0031 - val_loss: 4.1251e-04 - val_mae: 0.0045\n",
      "Epoch 90/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.2644e-04 - mae: 0.0031 - val_loss: 3.8701e-04 - val_mae: 0.0023\n",
      "Epoch 91/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.1984e-04 - mae: 0.0030 - val_loss: 6.3141e-04 - val_mae: 0.0139\n",
      "Epoch 92/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.1696e-04 - mae: 0.0030 - val_loss: 4.6629e-04 - val_mae: 0.0074\n",
      "Epoch 93/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.1098e-04 - mae: 0.0030 - val_loss: 3.7471e-04 - val_mae: 0.0030\n",
      "Epoch 94/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.0688e-04 - mae: 0.0032 - val_loss: 3.6208e-04 - val_mae: 0.0017\n",
      "Epoch 95/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.9970e-04 - mae: 0.0029 - val_loss: 3.5865e-04 - val_mae: 0.0019\n",
      "Epoch 96/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 3.9256e-04 - mae: 0.0029 - val_loss: 3.5265e-04 - val_mae: 0.0018\n",
      "Epoch 97/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.8953e-04 - mae: 0.0030 - val_loss: 3.4900e-04 - val_mae: 0.0020\n",
      "Epoch 98/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 3.8225e-04 - mae: 0.0029 - val_loss: 3.4288e-04 - val_mae: 0.0018\n",
      "Epoch 99/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 3.7884e-04 - mae: 0.0029 - val_loss: 3.4088e-04 - val_mae: 0.0023\n",
      "Epoch 100/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.7503e-04 - mae: 0.0030 - val_loss: 3.3530e-04 - val_mae: 0.0022\n",
      "Epoch 101/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.7197e-04 - mae: 0.0031 - val_loss: 3.2898e-04 - val_mae: 0.0016\n",
      "Epoch 102/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.6554e-04 - mae: 0.0029 - val_loss: 3.2799e-04 - val_mae: 0.0022\n",
      "Epoch 103/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.6095e-04 - mae: 0.0030 - val_loss: 3.2634e-04 - val_mae: 0.0027\n",
      "Epoch 104/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 3.5675e-04 - mae: 0.0029 - val_loss: 3.2273e-04 - val_mae: 0.0026\n",
      "Epoch 105/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.5682e-04 - mae: 0.0031 - val_loss: 3.2333e-04 - val_mae: 0.0030\n",
      "Epoch 106/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.4789e-04 - mae: 0.0028 - val_loss: 3.3268e-04 - val_mae: 0.0041\n",
      "Epoch 107/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.4850e-04 - mae: 0.0031 - val_loss: 3.0555e-04 - val_mae: 0.0018\n",
      "Epoch 108/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.3979e-04 - mae: 0.0029 - val_loss: 3.1180e-04 - val_mae: 0.0031\n",
      "Epoch 109/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.4235e-04 - mae: 0.0031 - val_loss: 3.0251e-04 - val_mae: 0.0021\n",
      "Epoch 110/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.3510e-04 - mae: 0.0030 - val_loss: 2.9546e-04 - val_mae: 0.0019\n",
      "Epoch 111/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.2986e-04 - mae: 0.0028 - val_loss: 2.9238e-04 - val_mae: 0.0019\n",
      "Epoch 112/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.2785e-04 - mae: 0.0029 - val_loss: 2.9870e-04 - val_mae: 0.0029\n",
      "Epoch 113/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.2543e-04 - mae: 0.0031 - val_loss: 2.8835e-04 - val_mae: 0.0024\n",
      "Epoch 114/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.1970e-04 - mae: 0.0029 - val_loss: 2.8273e-04 - val_mae: 0.0020\n",
      "Epoch 115/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 3.1704e-04 - mae: 0.0028 - val_loss: 3.0916e-04 - val_mae: 0.0047\n",
      "Epoch 116/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.1399e-04 - mae: 0.0029 - val_loss: 2.7462e-04 - val_mae: 0.0016\n",
      "Epoch 117/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.1166e-04 - mae: 0.0029 - val_loss: 2.7246e-04 - val_mae: 0.0018\n",
      "Epoch 118/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.0857e-04 - mae: 0.0028 - val_loss: 2.8495e-04 - val_mae: 0.0040\n",
      "Epoch 119/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.0792e-04 - mae: 0.0028 - val_loss: 2.6731e-04 - val_mae: 0.0018\n",
      "Epoch 120/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.0242e-04 - mae: 0.0028 - val_loss: 2.7771e-04 - val_mae: 0.0033\n",
      "Epoch 121/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.9985e-04 - mae: 0.0029 - val_loss: 2.6310e-04 - val_mae: 0.0021\n",
      "Epoch 122/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.9431e-04 - mae: 0.0027 - val_loss: 2.5855e-04 - val_mae: 0.0019\n",
      "Epoch 123/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.9583e-04 - mae: 0.0029 - val_loss: 2.5636e-04 - val_mae: 0.0018\n",
      "Epoch 124/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.9492e-04 - mae: 0.0029 - val_loss: 2.6406e-04 - val_mae: 0.0029\n",
      "Epoch 125/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.8728e-04 - mae: 0.0027 - val_loss: 2.5162e-04 - val_mae: 0.0019\n",
      "Epoch 126/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.8930e-04 - mae: 0.0029 - val_loss: 2.4937e-04 - val_mae: 0.0019\n",
      "Epoch 127/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.8240e-04 - mae: 0.0028 - val_loss: 2.4763e-04 - val_mae: 0.0021\n",
      "Epoch 128/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.8309e-04 - mae: 0.0028 - val_loss: 2.4578e-04 - val_mae: 0.0021\n",
      "Epoch 129/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.7647e-04 - mae: 0.0027 - val_loss: 2.4905e-04 - val_mae: 0.0029\n",
      "Epoch 130/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.7557e-04 - mae: 0.0028 - val_loss: 2.4309e-04 - val_mae: 0.0027\n",
      "Epoch 131/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.7365e-04 - mae: 0.0027 - val_loss: 2.4693e-04 - val_mae: 0.0031\n",
      "Epoch 132/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.7190e-04 - mae: 0.0029 - val_loss: 2.4117e-04 - val_mae: 0.0030\n",
      "Epoch 133/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.7213e-04 - mae: 0.0028 - val_loss: 2.9425e-04 - val_mae: 0.0066\n",
      "Epoch 134/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.7053e-04 - mae: 0.0029 - val_loss: 2.4013e-04 - val_mae: 0.0032\n",
      "Epoch 135/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.6448e-04 - mae: 0.0028 - val_loss: 2.2798e-04 - val_mae: 0.0018\n",
      "Epoch 136/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.6632e-04 - mae: 0.0030 - val_loss: 2.2544e-04 - val_mae: 0.0017\n",
      "Epoch 137/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.5979e-04 - mae: 0.0027 - val_loss: 2.2969e-04 - val_mae: 0.0028\n",
      "Epoch 138/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.5924e-04 - mae: 0.0028 - val_loss: 2.2256e-04 - val_mae: 0.0019\n",
      "Epoch 139/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.5534e-04 - mae: 0.0027 - val_loss: 2.2114e-04 - val_mae: 0.0019\n",
      "Epoch 140/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.5647e-04 - mae: 0.0029 - val_loss: 2.1785e-04 - val_mae: 0.0017\n",
      "Epoch 141/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.5267e-04 - mae: 0.0027 - val_loss: 2.4941e-04 - val_mae: 0.0049\n",
      "Epoch 142/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.5012e-04 - mae: 0.0028 - val_loss: 2.2037e-04 - val_mae: 0.0027\n",
      "Epoch 143/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.4790e-04 - mae: 0.0027 - val_loss: 2.1842e-04 - val_mae: 0.0029\n",
      "Epoch 144/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.4614e-04 - mae: 0.0027 - val_loss: 2.1072e-04 - val_mae: 0.0018\n",
      "Epoch 145/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.4264e-04 - mae: 0.0026 - val_loss: 2.2381e-04 - val_mae: 0.0037\n",
      "Epoch 146/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.4219e-04 - mae: 0.0028 - val_loss: 2.1156e-04 - val_mae: 0.0023\n",
      "Epoch 147/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.4673e-04 - mae: 0.0030 - val_loss: 2.2680e-04 - val_mae: 0.0038\n",
      "Epoch 148/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.3893e-04 - mae: 0.0027 - val_loss: 2.0370e-04 - val_mae: 0.0018\n",
      "Epoch 149/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.3659e-04 - mae: 0.0027 - val_loss: 2.0960e-04 - val_mae: 0.0028\n",
      "Epoch 150/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.3579e-04 - mae: 0.0026 - val_loss: 1.9980e-04 - val_mae: 0.0017\n",
      "Epoch 151/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.3371e-04 - mae: 0.0027 - val_loss: 1.9925e-04 - val_mae: 0.0019\n",
      "Epoch 152/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3176e-04 - mae: 0.0026 - val_loss: 2.0530e-04 - val_mae: 0.0028\n",
      "Epoch 153/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3197e-04 - mae: 0.0028 - val_loss: 2.1957e-04 - val_mae: 0.0037\n",
      "Epoch 154/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3170e-04 - mae: 0.0028 - val_loss: 1.9398e-04 - val_mae: 0.0017\n",
      "Epoch 155/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2731e-04 - mae: 0.0026 - val_loss: 1.9651e-04 - val_mae: 0.0022\n",
      "Epoch 156/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2687e-04 - mae: 0.0027 - val_loss: 2.2435e-04 - val_mae: 0.0055\n",
      "Epoch 157/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2632e-04 - mae: 0.0027 - val_loss: 1.9623e-04 - val_mae: 0.0025\n",
      "Epoch 158/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.2588e-04 - mae: 0.0028 - val_loss: 1.9172e-04 - val_mae: 0.0021\n",
      "Epoch 159/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.2273e-04 - mae: 0.0028 - val_loss: 1.9264e-04 - val_mae: 0.0028\n",
      "Epoch 160/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.2224e-04 - mae: 0.0027 - val_loss: 2.2716e-04 - val_mae: 0.0049\n",
      "Epoch 161/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2058e-04 - mae: 0.0028 - val_loss: 1.8515e-04 - val_mae: 0.0018\n",
      "Epoch 162/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1905e-04 - mae: 0.0027 - val_loss: 1.8806e-04 - val_mae: 0.0027\n",
      "Epoch 163/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1925e-04 - mae: 0.0028 - val_loss: 1.9900e-04 - val_mae: 0.0038\n",
      "Epoch 164/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1457e-04 - mae: 0.0026 - val_loss: 1.8125e-04 - val_mae: 0.0018\n",
      "Epoch 165/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1398e-04 - mae: 0.0026 - val_loss: 2.0958e-04 - val_mae: 0.0053\n",
      "Epoch 166/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1425e-04 - mae: 0.0028 - val_loss: 1.7814e-04 - val_mae: 0.0016\n",
      "Epoch 167/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.1388e-04 - mae: 0.0028 - val_loss: 1.7699e-04 - val_mae: 0.0017\n",
      "Epoch 168/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.1152e-04 - mae: 0.0028 - val_loss: 1.8297e-04 - val_mae: 0.0027\n",
      "Epoch 169/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0833e-04 - mae: 0.0026 - val_loss: 2.7960e-04 - val_mae: 0.0084\n",
      "Epoch 170/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1062e-04 - mae: 0.0028 - val_loss: 2.2859e-04 - val_mae: 0.0072\n",
      "Epoch 171/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0637e-04 - mae: 0.0026 - val_loss: 1.7258e-04 - val_mae: 0.0017\n",
      "Epoch 172/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.0799e-04 - mae: 0.0027 - val_loss: 1.7288e-04 - val_mae: 0.0020\n",
      "Epoch 173/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0496e-04 - mae: 0.0027 - val_loss: 1.7225e-04 - val_mae: 0.0020\n",
      "Epoch 174/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.0737e-04 - mae: 0.0028 - val_loss: 1.9092e-04 - val_mae: 0.0042\n",
      "Epoch 175/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.0326e-04 - mae: 0.0027 - val_loss: 1.6843e-04 - val_mae: 0.0017\n",
      "Epoch 176/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.0299e-04 - mae: 0.0027 - val_loss: 4.5528e-04 - val_mae: 0.0118\n",
      "Epoch 177/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.0263e-04 - mae: 0.0028 - val_loss: 1.6626e-04 - val_mae: 0.0017\n",
      "Epoch 178/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.0135e-04 - mae: 0.0028 - val_loss: 1.6674e-04 - val_mae: 0.0019\n",
      "Epoch 179/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9950e-04 - mae: 0.0027 - val_loss: 1.7406e-04 - val_mae: 0.0029\n",
      "Epoch 180/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9908e-04 - mae: 0.0028 - val_loss: 1.6390e-04 - val_mae: 0.0018\n",
      "Epoch 181/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.9824e-04 - mae: 0.0027 - val_loss: 1.9465e-04 - val_mae: 0.0055\n",
      "Epoch 182/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.9765e-04 - mae: 0.0028 - val_loss: 1.6340e-04 - val_mae: 0.0020\n",
      "Epoch 183/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9694e-04 - mae: 0.0028 - val_loss: 1.6253e-04 - val_mae: 0.0019\n",
      "Epoch 184/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9399e-04 - mae: 0.0026 - val_loss: 1.6139e-04 - val_mae: 0.0019\n",
      "Epoch 185/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9312e-04 - mae: 0.0026 - val_loss: 1.6000e-04 - val_mae: 0.0019\n",
      "Epoch 186/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9603e-04 - mae: 0.0028 - val_loss: 1.5965e-04 - val_mae: 0.0019\n",
      "Epoch 187/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9281e-04 - mae: 0.0027 - val_loss: 1.5882e-04 - val_mae: 0.0019\n",
      "Epoch 188/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9249e-04 - mae: 0.0028 - val_loss: 1.6357e-04 - val_mae: 0.0026\n",
      "Epoch 189/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9121e-04 - mae: 0.0027 - val_loss: 1.5975e-04 - val_mae: 0.0023\n",
      "Epoch 190/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.8981e-04 - mae: 0.0027 - val_loss: 1.5640e-04 - val_mae: 0.0019\n",
      "Epoch 191/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.8934e-04 - mae: 0.0027 - val_loss: 1.5506e-04 - val_mae: 0.0019\n",
      "Epoch 192/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.8727e-04 - mae: 0.0027 - val_loss: 1.6218e-04 - val_mae: 0.0030\n",
      "Epoch 193/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.8629e-04 - mae: 0.0026 - val_loss: 1.6200e-04 - val_mae: 0.0031\n",
      "Epoch 194/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.8680e-04 - mae: 0.0026 - val_loss: 1.7736e-04 - val_mae: 0.0047\n",
      "Epoch 195/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.8598e-04 - mae: 0.0028 - val_loss: 1.5658e-04 - val_mae: 0.0028\n",
      "Epoch 196/1000\n",
      "1414/1426 [============================>.] - ETA: 0s - loss: 1.8189e-04 - mae: 0.0026Restoring model weights from the end of the best epoch: 191.\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.8352e-04 - mae: 0.0026 - val_loss: 1.7379e-04 - val_mae: 0.0040\n",
      "Epoch 196: early stopping\n",
      "Training fÃ¼r Fold 2...\n",
      "Epoch 1/1000\n",
      "1426/1426 [==============================] - 5s 3ms/step - loss: 0.0247 - mae: 0.0470 - val_loss: 0.0155 - val_mae: 0.0214\n",
      "Epoch 2/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0142 - mae: 0.0158 - val_loss: 0.0135 - val_mae: 0.0150\n",
      "Epoch 3/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0131 - mae: 0.0150 - val_loss: 0.0124 - val_mae: 0.0082\n",
      "Epoch 4/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0123 - mae: 0.0139 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 5/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0115 - mae: 0.0120 - val_loss: 0.0110 - val_mae: 0.0090\n",
      "Epoch 6/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0109 - mae: 0.0114 - val_loss: 0.0106 - val_mae: 0.0131\n",
      "Epoch 7/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0103 - mae: 0.0111 - val_loss: 0.0098 - val_mae: 0.0058\n",
      "Epoch 8/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0097 - mae: 0.0093 - val_loss: 0.0096 - val_mae: 0.0143\n",
      "Epoch 9/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0091 - mae: 0.0098 - val_loss: 0.0087 - val_mae: 0.0053\n",
      "Epoch 10/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0086 - mae: 0.0087 - val_loss: 0.0082 - val_mae: 0.0069\n",
      "Epoch 11/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0081 - mae: 0.0086 - val_loss: 0.0080 - val_mae: 0.0142\n",
      "Epoch 12/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0076 - mae: 0.0076 - val_loss: 0.0074 - val_mae: 0.0087\n",
      "Epoch 13/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0072 - mae: 0.0071 - val_loss: 0.0079 - val_mae: 0.0239\n",
      "Epoch 14/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0068 - mae: 0.0070 - val_loss: 0.0065 - val_mae: 0.0049\n",
      "Epoch 15/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0064 - mae: 0.0071 - val_loss: 0.0061 - val_mae: 0.0042\n",
      "Epoch 16/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0060 - mae: 0.0072 - val_loss: 0.0059 - val_mae: 0.0095\n",
      "Epoch 17/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0057 - mae: 0.0058 - val_loss: 0.0055 - val_mae: 0.0053\n",
      "Epoch 18/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0054 - mae: 0.0065 - val_loss: 0.0051 - val_mae: 0.0038\n",
      "Epoch 19/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0050 - mae: 0.0053 - val_loss: 0.0049 - val_mae: 0.0043\n",
      "Epoch 20/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0047 - mae: 0.0058 - val_loss: 0.0046 - val_mae: 0.0052\n",
      "Epoch 21/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0044 - mae: 0.0051 - val_loss: 0.0043 - val_mae: 0.0034\n",
      "Epoch 22/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0042 - mae: 0.0053 - val_loss: 0.0040 - val_mae: 0.0045\n",
      "Epoch 23/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0039 - mae: 0.0050 - val_loss: 0.0043 - val_mae: 0.0203\n",
      "Epoch 24/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0037 - mae: 0.0050 - val_loss: 0.0037 - val_mae: 0.0103\n",
      "Epoch 25/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0035 - mae: 0.0051 - val_loss: 0.0036 - val_mae: 0.0108\n",
      "Epoch 26/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0033 - mae: 0.0046 - val_loss: 0.0032 - val_mae: 0.0058\n",
      "Epoch 27/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0031 - mae: 0.0048 - val_loss: 0.0030 - val_mae: 0.0043\n",
      "Epoch 28/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0029 - mae: 0.0044 - val_loss: 0.0028 - val_mae: 0.0028\n",
      "Epoch 29/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0028 - mae: 0.0044 - val_loss: 0.0027 - val_mae: 0.0034\n",
      "Epoch 30/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0026 - mae: 0.0046 - val_loss: 0.0025 - val_mae: 0.0028\n",
      "Epoch 31/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0025 - mae: 0.0038 - val_loss: 0.0024 - val_mae: 0.0026\n",
      "Epoch 32/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0023 - mae: 0.0041 - val_loss: 0.0037 - val_mae: 0.0251\n",
      "Epoch 33/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0022 - mae: 0.0043 - val_loss: 0.0022 - val_mae: 0.0047\n",
      "Epoch 34/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0021 - mae: 0.0041 - val_loss: 0.0021 - val_mae: 0.0028\n",
      "Epoch 35/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0020 - mae: 0.0040 - val_loss: 0.0020 - val_mae: 0.0032\n",
      "Epoch 36/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0019 - mae: 0.0036 - val_loss: 0.0025 - val_mae: 0.0172\n",
      "Epoch 37/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0018 - mae: 0.0041 - val_loss: 0.0018 - val_mae: 0.0023\n",
      "Epoch 38/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0017 - mae: 0.0036 - val_loss: 0.0017 - val_mae: 0.0039\n",
      "Epoch 39/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0017 - mae: 0.0041 - val_loss: 0.0016 - val_mae: 0.0026\n",
      "Epoch 40/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0016 - mae: 0.0036 - val_loss: 0.0016 - val_mae: 0.0038\n",
      "Epoch 41/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0015 - mae: 0.0034 - val_loss: 0.0015 - val_mae: 0.0025\n",
      "Epoch 42/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0015 - mae: 0.0039 - val_loss: 0.0014 - val_mae: 0.0029\n",
      "Epoch 43/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0014 - mae: 0.0035 - val_loss: 0.0014 - val_mae: 0.0027\n",
      "Epoch 44/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0014 - mae: 0.0035 - val_loss: 0.0014 - val_mae: 0.0049\n",
      "Epoch 45/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0013 - mae: 0.0035 - val_loss: 0.0013 - val_mae: 0.0032\n",
      "Epoch 46/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0013 - mae: 0.0037 - val_loss: 0.0012 - val_mae: 0.0024\n",
      "Epoch 47/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0012 - mae: 0.0034 - val_loss: 0.0012 - val_mae: 0.0022\n",
      "Epoch 48/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0012 - mae: 0.0038 - val_loss: 0.0012 - val_mae: 0.0025\n",
      "Epoch 49/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0011 - mae: 0.0035 - val_loss: 0.0011 - val_mae: 0.0024\n",
      "Epoch 50/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0011 - mae: 0.0034 - val_loss: 0.0011 - val_mae: 0.0025\n",
      "Epoch 51/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0011 - mae: 0.0033 - val_loss: 0.0011 - val_mae: 0.0029\n",
      "Epoch 52/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0010 - mae: 0.0032 - val_loss: 0.0010 - val_mae: 0.0032\n",
      "Epoch 53/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0010 - mae: 0.0036 - val_loss: 9.8904e-04 - val_mae: 0.0032\n",
      "Epoch 54/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 9.6911e-04 - mae: 0.0034 - val_loss: 9.5080e-04 - val_mae: 0.0025\n",
      "Epoch 55/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 9.3457e-04 - mae: 0.0031 - val_loss: 9.2186e-04 - val_mae: 0.0023\n",
      "Epoch 56/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 9.0793e-04 - mae: 0.0033 - val_loss: 9.3684e-04 - val_mae: 0.0065\n",
      "Epoch 57/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 8.8751e-04 - mae: 0.0035 - val_loss: 8.6939e-04 - val_mae: 0.0026\n",
      "Epoch 58/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 8.5358e-04 - mae: 0.0032 - val_loss: 8.4239e-04 - val_mae: 0.0021\n",
      "Epoch 59/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 8.4170e-04 - mae: 0.0034 - val_loss: 8.2167e-04 - val_mae: 0.0024\n",
      "Epoch 60/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 8.0780e-04 - mae: 0.0031 - val_loss: 8.0633e-04 - val_mae: 0.0032\n",
      "Epoch 61/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 7.8563e-04 - mae: 0.0032 - val_loss: 7.7588e-04 - val_mae: 0.0023\n",
      "Epoch 62/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 7.6551e-04 - mae: 0.0032 - val_loss: 7.5494e-04 - val_mae: 0.0022\n",
      "Epoch 63/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 7.5029e-04 - mae: 0.0034 - val_loss: 7.3956e-04 - val_mae: 0.0032\n",
      "Epoch 64/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 7.2858e-04 - mae: 0.0031 - val_loss: 7.1575e-04 - val_mae: 0.0019\n",
      "Epoch 65/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 7.1075e-04 - mae: 0.0032 - val_loss: 7.0302e-04 - val_mae: 0.0026\n",
      "Epoch 66/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 6.8605e-04 - mae: 0.0028 - val_loss: 0.0025 - val_mae: 0.0335\n",
      "Epoch 67/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.0895e-04 - mae: 0.0035 - val_loss: 6.7114e-04 - val_mae: 0.0022\n",
      "Epoch 68/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 6.6572e-04 - mae: 0.0032 - val_loss: 6.6467e-04 - val_mae: 0.0037\n",
      "Epoch 69/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 6.4316e-04 - mae: 0.0029 - val_loss: 6.4838e-04 - val_mae: 0.0033\n",
      "Epoch 70/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 6.3510e-04 - mae: 0.0032 - val_loss: 6.2708e-04 - val_mae: 0.0024\n",
      "Epoch 71/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 6.2066e-04 - mae: 0.0030 - val_loss: 6.1333e-04 - val_mae: 0.0023\n",
      "Epoch 72/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 6.0331e-04 - mae: 0.0029 - val_loss: 6.0225e-04 - val_mae: 0.0026\n",
      "Epoch 73/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 5.8806e-04 - mae: 0.0030 - val_loss: 5.8501e-04 - val_mae: 0.0022\n",
      "Epoch 74/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.7594e-04 - mae: 0.0030 - val_loss: 5.7421e-04 - val_mae: 0.0025\n",
      "Epoch 75/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.6648e-04 - mae: 0.0032 - val_loss: 5.6169e-04 - val_mae: 0.0027\n",
      "Epoch 76/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.5207e-04 - mae: 0.0031 - val_loss: 5.4734e-04 - val_mae: 0.0022\n",
      "Epoch 77/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 5.3874e-04 - mae: 0.0030 - val_loss: 5.4150e-04 - val_mae: 0.0030\n",
      "Epoch 78/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.2698e-04 - mae: 0.0029 - val_loss: 5.2471e-04 - val_mae: 0.0022\n",
      "Epoch 79/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.1538e-04 - mae: 0.0029 - val_loss: 5.1505e-04 - val_mae: 0.0024\n",
      "Epoch 80/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.0696e-04 - mae: 0.0030 - val_loss: 5.1237e-04 - val_mae: 0.0033\n",
      "Epoch 81/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.9774e-04 - mae: 0.0030 - val_loss: 4.9367e-04 - val_mae: 0.0021\n",
      "Epoch 82/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.8778e-04 - mae: 0.0030 - val_loss: 4.8418e-04 - val_mae: 0.0019\n",
      "Epoch 83/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 4.7837e-04 - mae: 0.0029 - val_loss: 4.8205e-04 - val_mae: 0.0028\n",
      "Epoch 84/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 4.6955e-04 - mae: 0.0030 - val_loss: 4.6742e-04 - val_mae: 0.0020\n",
      "Epoch 85/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 4.6281e-04 - mae: 0.0030 - val_loss: 4.6019e-04 - val_mae: 0.0023\n",
      "Epoch 86/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.4943e-04 - mae: 0.0028 - val_loss: 4.5071e-04 - val_mae: 0.0022\n",
      "Epoch 87/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.3757e-04 - mae: 0.0026 - val_loss: 4.4350e-04 - val_mae: 0.0024\n",
      "Epoch 88/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.3446e-04 - mae: 0.0029 - val_loss: 4.3735e-04 - val_mae: 0.0026\n",
      "Epoch 89/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 4.2616e-04 - mae: 0.0029 - val_loss: 4.2927e-04 - val_mae: 0.0026\n",
      "Epoch 90/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 4.1845e-04 - mae: 0.0029 - val_loss: 4.1960e-04 - val_mae: 0.0021\n",
      "Epoch 91/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.1189e-04 - mae: 0.0029 - val_loss: 4.1154e-04 - val_mae: 0.0019\n",
      "Epoch 92/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.1022e-04 - mae: 0.0031 - val_loss: 4.2283e-04 - val_mae: 0.0039\n",
      "Epoch 93/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.9614e-04 - mae: 0.0027 - val_loss: 4.0124e-04 - val_mae: 0.0025\n",
      "Epoch 94/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.9155e-04 - mae: 0.0029 - val_loss: 3.9474e-04 - val_mae: 0.0025\n",
      "Epoch 95/1000\n",
      "1426/1426 [==============================] - 5s 3ms/step - loss: 3.8837e-04 - mae: 0.0029 - val_loss: 3.8761e-04 - val_mae: 0.0023\n",
      "Epoch 96/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.7724e-04 - mae: 0.0027 - val_loss: 3.8046e-04 - val_mae: 0.0020\n",
      "Epoch 97/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.7335e-04 - mae: 0.0028 - val_loss: 3.7859e-04 - val_mae: 0.0025\n",
      "Epoch 98/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 3.6649e-04 - mae: 0.0027 - val_loss: 3.7128e-04 - val_mae: 0.0022\n",
      "Epoch 99/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.6272e-04 - mae: 0.0028 - val_loss: 3.6660e-04 - val_mae: 0.0025\n",
      "Epoch 100/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.5514e-04 - mae: 0.0028 - val_loss: 3.5760e-04 - val_mae: 0.0019\n",
      "Epoch 101/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.5012e-04 - mae: 0.0027 - val_loss: 3.5632e-04 - val_mae: 0.0024\n",
      "Epoch 102/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.4359e-04 - mae: 0.0027 - val_loss: 4.3748e-04 - val_mae: 0.0090\n",
      "Epoch 103/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.3825e-04 - mae: 0.0028 - val_loss: 3.4625e-04 - val_mae: 0.0026\n",
      "Epoch 104/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 3.3361e-04 - mae: 0.0027 - val_loss: 3.4131e-04 - val_mae: 0.0025\n",
      "Epoch 105/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.3028e-04 - mae: 0.0026 - val_loss: 3.3536e-04 - val_mae: 0.0023\n",
      "Epoch 106/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 3.2464e-04 - mae: 0.0027 - val_loss: 3.5142e-04 - val_mae: 0.0044\n",
      "Epoch 107/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.1878e-04 - mae: 0.0026 - val_loss: 3.2622e-04 - val_mae: 0.0023\n",
      "Epoch 108/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.1885e-04 - mae: 0.0028 - val_loss: 3.2386e-04 - val_mae: 0.0024\n",
      "Epoch 109/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.1054e-04 - mae: 0.0027 - val_loss: 3.2330e-04 - val_mae: 0.0030\n",
      "Epoch 110/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.0798e-04 - mae: 0.0027 - val_loss: 3.1251e-04 - val_mae: 0.0020\n",
      "Epoch 111/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.0475e-04 - mae: 0.0026 - val_loss: 3.0889e-04 - val_mae: 0.0020\n",
      "Epoch 112/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 3.0303e-04 - mae: 0.0028 - val_loss: 3.0819e-04 - val_mae: 0.0024\n",
      "Epoch 113/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.9607e-04 - mae: 0.0026 - val_loss: 3.0596e-04 - val_mae: 0.0026\n",
      "Epoch 114/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.9377e-04 - mae: 0.0027 - val_loss: 2.9991e-04 - val_mae: 0.0022\n",
      "Epoch 115/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.8902e-04 - mae: 0.0027 - val_loss: 2.9734e-04 - val_mae: 0.0026\n",
      "Epoch 116/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.8597e-04 - mae: 0.0027 - val_loss: 2.9324e-04 - val_mae: 0.0024\n",
      "Epoch 117/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.8123e-04 - mae: 0.0026 - val_loss: 2.9079e-04 - val_mae: 0.0024\n",
      "Epoch 118/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.7966e-04 - mae: 0.0027 - val_loss: 2.8694e-04 - val_mae: 0.0025\n",
      "Epoch 119/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.7821e-04 - mae: 0.0027 - val_loss: 2.8814e-04 - val_mae: 0.0028\n",
      "Epoch 120/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.7188e-04 - mae: 0.0025 - val_loss: 2.8236e-04 - val_mae: 0.0025\n",
      "Epoch 121/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.7169e-04 - mae: 0.0027 - val_loss: 2.7574e-04 - val_mae: 0.0019\n",
      "Epoch 122/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.6606e-04 - mae: 0.0026 - val_loss: 2.7479e-04 - val_mae: 0.0023\n",
      "Epoch 123/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.6631e-04 - mae: 0.0027 - val_loss: 3.5729e-04 - val_mae: 0.0086\n",
      "Epoch 124/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.6340e-04 - mae: 0.0027 - val_loss: 2.6999e-04 - val_mae: 0.0024\n",
      "Epoch 125/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.5944e-04 - mae: 0.0027 - val_loss: 2.6776e-04 - val_mae: 0.0024\n",
      "Epoch 126/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.5830e-04 - mae: 0.0027 - val_loss: 2.6542e-04 - val_mae: 0.0023\n",
      "Epoch 127/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.5491e-04 - mae: 0.0027 - val_loss: 2.6239e-04 - val_mae: 0.0024\n",
      "Epoch 128/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.5173e-04 - mae: 0.0026 - val_loss: 2.6013e-04 - val_mae: 0.0022\n",
      "Epoch 129/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.4998e-04 - mae: 0.0026 - val_loss: 2.5782e-04 - val_mae: 0.0022\n",
      "Epoch 130/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.4870e-04 - mae: 0.0027 - val_loss: 2.5643e-04 - val_mae: 0.0024\n",
      "Epoch 131/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.4359e-04 - mae: 0.0026 - val_loss: 2.5419e-04 - val_mae: 0.0023\n",
      "Epoch 132/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.4376e-04 - mae: 0.0027 - val_loss: 2.4850e-04 - val_mae: 0.0018\n",
      "Epoch 133/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3934e-04 - mae: 0.0025 - val_loss: 2.5748e-04 - val_mae: 0.0034\n",
      "Epoch 134/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3857e-04 - mae: 0.0026 - val_loss: 2.5301e-04 - val_mae: 0.0031\n",
      "Epoch 135/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3883e-04 - mae: 0.0027 - val_loss: 2.4280e-04 - val_mae: 0.0019\n",
      "Epoch 136/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3561e-04 - mae: 0.0027 - val_loss: 2.6310e-04 - val_mae: 0.0049\n",
      "Epoch 137/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3462e-04 - mae: 0.0026 - val_loss: 2.4027e-04 - val_mae: 0.0021\n",
      "Epoch 138/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3009e-04 - mae: 0.0026 - val_loss: 2.3998e-04 - val_mae: 0.0023\n",
      "Epoch 139/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2977e-04 - mae: 0.0026 - val_loss: 2.8682e-04 - val_mae: 0.0062\n",
      "Epoch 140/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2876e-04 - mae: 0.0027 - val_loss: 2.3454e-04 - val_mae: 0.0022\n",
      "Epoch 141/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2783e-04 - mae: 0.0027 - val_loss: 2.3345e-04 - val_mae: 0.0020\n",
      "Epoch 142/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2367e-04 - mae: 0.0026 - val_loss: 2.3039e-04 - val_mae: 0.0018\n",
      "Epoch 143/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.2111e-04 - mae: 0.0026 - val_loss: 2.4318e-04 - val_mae: 0.0039\n",
      "Epoch 144/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2214e-04 - mae: 0.0028 - val_loss: 3.0633e-04 - val_mae: 0.0088\n",
      "Epoch 145/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2267e-04 - mae: 0.0026 - val_loss: 2.2577e-04 - val_mae: 0.0019\n",
      "Epoch 146/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1660e-04 - mae: 0.0025 - val_loss: 2.2531e-04 - val_mae: 0.0021\n",
      "Epoch 147/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1594e-04 - mae: 0.0026 - val_loss: 2.2394e-04 - val_mae: 0.0020\n",
      "Epoch 148/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1660e-04 - mae: 0.0027 - val_loss: 2.2207e-04 - val_mae: 0.0020\n",
      "Epoch 149/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1336e-04 - mae: 0.0026 - val_loss: 5.6120e-04 - val_mae: 0.0158\n",
      "Epoch 150/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1258e-04 - mae: 0.0027 - val_loss: 2.2141e-04 - val_mae: 0.0024\n",
      "Epoch 151/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.1021e-04 - mae: 0.0026 - val_loss: 2.2142e-04 - val_mae: 0.0025\n",
      "Epoch 152/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1024e-04 - mae: 0.0028 - val_loss: 2.1783e-04 - val_mae: 0.0023\n",
      "Epoch 153/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1064e-04 - mae: 0.0028 - val_loss: 2.1438e-04 - val_mae: 0.0018\n",
      "Epoch 154/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0656e-04 - mae: 0.0026 - val_loss: 2.1284e-04 - val_mae: 0.0018\n",
      "Epoch 155/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0440e-04 - mae: 0.0025 - val_loss: 2.1908e-04 - val_mae: 0.0029\n",
      "Epoch 156/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0369e-04 - mae: 0.0026 - val_loss: 2.1059e-04 - val_mae: 0.0019\n",
      "Epoch 157/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0377e-04 - mae: 0.0027 - val_loss: 2.1294e-04 - val_mae: 0.0026\n",
      "Epoch 158/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9943e-04 - mae: 0.0025 - val_loss: 2.0863e-04 - val_mae: 0.0019\n",
      "Epoch 159/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9866e-04 - mae: 0.0026 - val_loss: 2.0818e-04 - val_mae: 0.0022\n",
      "Epoch 160/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9880e-04 - mae: 0.0026 - val_loss: 2.1211e-04 - val_mae: 0.0029\n",
      "Epoch 161/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9808e-04 - mae: 0.0026 - val_loss: 2.0738e-04 - val_mae: 0.0024\n",
      "Epoch 162/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9574e-04 - mae: 0.0025 - val_loss: 2.0475e-04 - val_mae: 0.0023\n",
      "Epoch 163/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9468e-04 - mae: 0.0026 - val_loss: 2.0776e-04 - val_mae: 0.0025\n",
      "Epoch 164/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9415e-04 - mae: 0.0026 - val_loss: 2.1636e-04 - val_mae: 0.0041\n",
      "Epoch 165/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9838e-04 - mae: 0.0029 - val_loss: 2.1418e-04 - val_mae: 0.0037\n",
      "Epoch 166/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9026e-04 - mae: 0.0025 - val_loss: 4.1071e-04 - val_mae: 0.0134\n",
      "Epoch 167/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9262e-04 - mae: 0.0027 - val_loss: 1.9866e-04 - val_mae: 0.0019\n",
      "Epoch 168/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.8936e-04 - mae: 0.0025 - val_loss: 1.9993e-04 - val_mae: 0.0024\n",
      "Epoch 169/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9032e-04 - mae: 0.0027 - val_loss: 1.9579e-04 - val_mae: 0.0020\n",
      "Epoch 170/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.8461e-04 - mae: 0.0024 - val_loss: 1.9882e-04 - val_mae: 0.0027\n",
      "Epoch 171/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8862e-04 - mae: 0.0027 - val_loss: 2.0508e-04 - val_mae: 0.0038\n",
      "Epoch 172/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8781e-04 - mae: 0.0027 - val_loss: 1.9631e-04 - val_mae: 0.0026\n",
      "Epoch 173/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8382e-04 - mae: 0.0025 - val_loss: 2.2288e-04 - val_mae: 0.0046\n",
      "Epoch 174/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8523e-04 - mae: 0.0027 - val_loss: 1.9097e-04 - val_mae: 0.0019\n",
      "Epoch 175/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8157e-04 - mae: 0.0025 - val_loss: 1.9374e-04 - val_mae: 0.0024\n",
      "Epoch 176/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8301e-04 - mae: 0.0025 - val_loss: 1.8943e-04 - val_mae: 0.0020\n",
      "Epoch 177/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8234e-04 - mae: 0.0026 - val_loss: 1.9101e-04 - val_mae: 0.0024\n",
      "Epoch 178/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.8222e-04 - mae: 0.0026 - val_loss: 1.8742e-04 - val_mae: 0.0018\n",
      "Epoch 179/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.7726e-04 - mae: 0.0024 - val_loss: 1.9337e-04 - val_mae: 0.0029\n",
      "Epoch 180/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7824e-04 - mae: 0.0026 - val_loss: 1.8780e-04 - val_mae: 0.0023\n",
      "Epoch 181/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7870e-04 - mae: 0.0026 - val_loss: 1.8913e-04 - val_mae: 0.0024\n",
      "Epoch 182/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7525e-04 - mae: 0.0025 - val_loss: 1.8635e-04 - val_mae: 0.0024\n",
      "Epoch 183/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.7553e-04 - mae: 0.0025 - val_loss: 1.8613e-04 - val_mae: 0.0022\n",
      "Epoch 184/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7356e-04 - mae: 0.0024 - val_loss: 1.9047e-04 - val_mae: 0.0030\n",
      "Epoch 185/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7416e-04 - mae: 0.0026 - val_loss: 1.8604e-04 - val_mae: 0.0025\n",
      "Epoch 186/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.7417e-04 - mae: 0.0026 - val_loss: 1.8091e-04 - val_mae: 0.0018\n",
      "Epoch 187/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.7351e-04 - mae: 0.0025 - val_loss: 1.9458e-04 - val_mae: 0.0039\n",
      "Epoch 188/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.7221e-04 - mae: 0.0025 - val_loss: 1.8849e-04 - val_mae: 0.0031\n",
      "Epoch 189/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7096e-04 - mae: 0.0026 - val_loss: 1.7911e-04 - val_mae: 0.0019\n",
      "Epoch 190/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.6918e-04 - mae: 0.0025 - val_loss: 1.8398e-04 - val_mae: 0.0029\n",
      "Epoch 191/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6866e-04 - mae: 0.0025 - val_loss: 2.3591e-04 - val_mae: 0.0066\n",
      "Epoch 192/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7203e-04 - mae: 0.0028 - val_loss: 1.7711e-04 - val_mae: 0.0019\n",
      "Epoch 193/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6671e-04 - mae: 0.0025 - val_loss: 1.8463e-04 - val_mae: 0.0032\n",
      "Epoch 194/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6760e-04 - mae: 0.0025 - val_loss: 1.7713e-04 - val_mae: 0.0022\n",
      "Epoch 195/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.6663e-04 - mae: 0.0025 - val_loss: 1.7763e-04 - val_mae: 0.0023\n",
      "Epoch 196/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.6735e-04 - mae: 0.0025 - val_loss: 2.1386e-04 - val_mae: 0.0062\n",
      "Epoch 197/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6517e-04 - mae: 0.0025 - val_loss: 1.7425e-04 - val_mae: 0.0019\n",
      "Epoch 198/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6543e-04 - mae: 0.0026 - val_loss: 1.9842e-04 - val_mae: 0.0048\n",
      "Epoch 199/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6433e-04 - mae: 0.0025 - val_loss: 1.7185e-04 - val_mae: 0.0018\n",
      "Epoch 200/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.6400e-04 - mae: 0.0026 - val_loss: 1.7382e-04 - val_mae: 0.0022\n",
      "Epoch 201/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6346e-04 - mae: 0.0025 - val_loss: 1.7520e-04 - val_mae: 0.0026\n",
      "Epoch 202/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6430e-04 - mae: 0.0026 - val_loss: 1.7698e-04 - val_mae: 0.0028\n",
      "Epoch 203/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6279e-04 - mae: 0.0026 - val_loss: 1.7575e-04 - val_mae: 0.0030\n",
      "Epoch 204/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.6129e-04 - mae: 0.0025 - val_loss: 1.7058e-04 - val_mae: 0.0019\n",
      "Epoch 205/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.6052e-04 - mae: 0.0025 - val_loss: 1.7243e-04 - val_mae: 0.0024\n",
      "Epoch 206/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6099e-04 - mae: 0.0026 - val_loss: 1.7796e-04 - val_mae: 0.0036\n",
      "Epoch 207/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.6006e-04 - mae: 0.0024 - val_loss: 2.2235e-04 - val_mae: 0.0069\n",
      "Epoch 208/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.5875e-04 - mae: 0.0025 - val_loss: 1.6761e-04 - val_mae: 0.0019\n",
      "Epoch 209/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6002e-04 - mae: 0.0025 - val_loss: 1.6779e-04 - val_mae: 0.0022\n",
      "Epoch 210/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5749e-04 - mae: 0.0025 - val_loss: 1.6676e-04 - val_mae: 0.0020\n",
      "Epoch 211/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.5685e-04 - mae: 0.0025 - val_loss: 1.7456e-04 - val_mae: 0.0028\n",
      "Epoch 212/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5749e-04 - mae: 0.0025 - val_loss: 1.6867e-04 - val_mae: 0.0026\n",
      "Epoch 213/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5617e-04 - mae: 0.0025 - val_loss: 1.7917e-04 - val_mae: 0.0038\n",
      "Epoch 214/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5672e-04 - mae: 0.0025 - val_loss: 1.6439e-04 - val_mae: 0.0018\n",
      "Epoch 215/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.5693e-04 - mae: 0.0026 - val_loss: 1.6358e-04 - val_mae: 0.0019\n",
      "Epoch 216/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5524e-04 - mae: 0.0025 - val_loss: 1.6421e-04 - val_mae: 0.0021\n",
      "Epoch 217/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5490e-04 - mae: 0.0025 - val_loss: 1.6884e-04 - val_mae: 0.0029\n",
      "Epoch 218/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.5488e-04 - mae: 0.0026 - val_loss: 1.6791e-04 - val_mae: 0.0025\n",
      "Epoch 219/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5550e-04 - mae: 0.0026 - val_loss: 1.7027e-04 - val_mae: 0.0029\n",
      "Epoch 220/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5185e-04 - mae: 0.0025 - val_loss: 1.6343e-04 - val_mae: 0.0021\n",
      "Epoch 221/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5283e-04 - mae: 0.0026 - val_loss: 1.6334e-04 - val_mae: 0.0022\n",
      "Epoch 222/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5316e-04 - mae: 0.0026 - val_loss: 1.6111e-04 - val_mae: 0.0020\n",
      "Epoch 223/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5241e-04 - mae: 0.0026 - val_loss: 1.6116e-04 - val_mae: 0.0020\n",
      "Epoch 224/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.5235e-04 - mae: 0.0026 - val_loss: 1.8022e-04 - val_mae: 0.0046\n",
      "Epoch 225/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.4981e-04 - mae: 0.0024 - val_loss: 1.6011e-04 - val_mae: 0.0019\n",
      "Epoch 226/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4925e-04 - mae: 0.0025 - val_loss: 1.6186e-04 - val_mae: 0.0025\n",
      "Epoch 227/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5083e-04 - mae: 0.0026 - val_loss: 1.5865e-04 - val_mae: 0.0020\n",
      "Epoch 228/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.4922e-04 - mae: 0.0025 - val_loss: 1.6109e-04 - val_mae: 0.0025\n",
      "Epoch 229/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.4924e-04 - mae: 0.0026 - val_loss: 1.5986e-04 - val_mae: 0.0022\n",
      "Epoch 230/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.4885e-04 - mae: 0.0025 - val_loss: 1.5887e-04 - val_mae: 0.0021\n",
      "Epoch 231/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4869e-04 - mae: 0.0025 - val_loss: 1.6574e-04 - val_mae: 0.0032\n",
      "Epoch 232/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.4811e-04 - mae: 0.0026 - val_loss: 1.5743e-04 - val_mae: 0.0021\n",
      "Epoch 233/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4659e-04 - mae: 0.0025 - val_loss: 1.5550e-04 - val_mae: 0.0020\n",
      "Epoch 234/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.4792e-04 - mae: 0.0026 - val_loss: 1.5582e-04 - val_mae: 0.0019\n",
      "Epoch 235/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.4717e-04 - mae: 0.0026 - val_loss: 1.5747e-04 - val_mae: 0.0022\n",
      "Epoch 236/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.4725e-04 - mae: 0.0026 - val_loss: 1.5584e-04 - val_mae: 0.0021\n",
      "Epoch 237/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.4490e-04 - mae: 0.0025 - val_loss: 1.5594e-04 - val_mae: 0.0020\n",
      "Epoch 238/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.4647e-04 - mae: 0.0026 - val_loss: 1.5415e-04 - val_mae: 0.0018\n",
      "Epoch 239/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.4589e-04 - mae: 0.0026 - val_loss: 1.6125e-04 - val_mae: 0.0030\n",
      "Epoch 240/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.4580e-04 - mae: 0.0026 - val_loss: 1.5351e-04 - val_mae: 0.0019\n",
      "Epoch 241/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.4543e-04 - mae: 0.0026 - val_loss: 1.5581e-04 - val_mae: 0.0023\n",
      "Epoch 242/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.4235e-04 - mae: 0.0024 - val_loss: 1.5439e-04 - val_mae: 0.0022\n",
      "Epoch 243/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.4387e-04 - mae: 0.0026 - val_loss: 2.4574e-04 - val_mae: 0.0082\n",
      "Epoch 244/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.4368e-04 - mae: 0.0026 - val_loss: 1.5523e-04 - val_mae: 0.0025\n",
      "Epoch 245/1000\n",
      "1415/1426 [============================>.] - ETA: 0s - loss: 1.4335e-04 - mae: 0.0025Restoring model weights from the end of the best epoch: 240.\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.4323e-04 - mae: 0.0025 - val_loss: 1.5990e-04 - val_mae: 0.0032\n",
      "Epoch 245: early stopping\n",
      "Training fÃ¼r Fold 3...\n",
      "Epoch 1/1000\n",
      "1426/1426 [==============================] - 5s 3ms/step - loss: 0.0340 - mae: 0.0617 - val_loss: 0.0179 - val_mae: 0.0138\n",
      "Epoch 2/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0170 - mae: 0.0146 - val_loss: 0.0162 - val_mae: 0.0115\n",
      "Epoch 3/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0158 - mae: 0.0146 - val_loss: 0.0160 - val_mae: 0.0256\n",
      "Epoch 4/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0147 - mae: 0.0135 - val_loss: 0.0142 - val_mae: 0.0131\n",
      "Epoch 5/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0138 - mae: 0.0135 - val_loss: 0.0131 - val_mae: 0.0078\n",
      "Epoch 6/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0128 - mae: 0.0113 - val_loss: 0.0123 - val_mae: 0.0130\n",
      "Epoch 7/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0119 - mae: 0.0115 - val_loss: 0.0112 - val_mae: 0.0048\n",
      "Epoch 8/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0110 - mae: 0.0101 - val_loss: 0.0104 - val_mae: 0.0075\n",
      "Epoch 9/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0101 - mae: 0.0088 - val_loss: 0.0096 - val_mae: 0.0049\n",
      "Epoch 10/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0090 - val_mae: 0.0107\n",
      "Epoch 11/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0087 - mae: 0.0084 - val_loss: 0.0082 - val_mae: 0.0035\n",
      "Epoch 12/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0080 - mae: 0.0075 - val_loss: 0.0076 - val_mae: 0.0065\n",
      "Epoch 13/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0074 - mae: 0.0071 - val_loss: 0.0070 - val_mae: 0.0068\n",
      "Epoch 14/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0068 - mae: 0.0071 - val_loss: 0.0065 - val_mae: 0.0056\n",
      "Epoch 15/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0063 - mae: 0.0067 - val_loss: 0.0060 - val_mae: 0.0034\n",
      "Epoch 16/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0058 - mae: 0.0064 - val_loss: 0.0056 - val_mae: 0.0058\n",
      "Epoch 17/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0054 - mae: 0.0060 - val_loss: 0.0051 - val_mae: 0.0051\n",
      "Epoch 18/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0050 - mae: 0.0061 - val_loss: 0.0048 - val_mae: 0.0054\n",
      "Epoch 19/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0046 - mae: 0.0057 - val_loss: 0.0046 - val_mae: 0.0100\n",
      "Epoch 20/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0043 - mae: 0.0059 - val_loss: 0.0041 - val_mae: 0.0047\n",
      "Epoch 21/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0040 - mae: 0.0053 - val_loss: 0.0039 - val_mae: 0.0046\n",
      "Epoch 22/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0038 - mae: 0.0054 - val_loss: 0.0036 - val_mae: 0.0034\n",
      "Epoch 23/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0035 - mae: 0.0050 - val_loss: 0.0034 - val_mae: 0.0055\n",
      "Epoch 24/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0033 - mae: 0.0056 - val_loss: 0.0031 - val_mae: 0.0036\n",
      "Epoch 25/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0031 - mae: 0.0046 - val_loss: 0.0029 - val_mae: 0.0037\n",
      "Epoch 26/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0029 - mae: 0.0045 - val_loss: 0.0028 - val_mae: 0.0063\n",
      "Epoch 27/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0027 - mae: 0.0044 - val_loss: 0.0027 - val_mae: 0.0086\n",
      "Epoch 28/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0025 - mae: 0.0050 - val_loss: 0.0024 - val_mae: 0.0049\n",
      "Epoch 29/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0024 - mae: 0.0047 - val_loss: 0.0023 - val_mae: 0.0031\n",
      "Epoch 30/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0022 - mae: 0.0043 - val_loss: 0.0021 - val_mae: 0.0028\n",
      "Epoch 31/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0021 - mae: 0.0043 - val_loss: 0.0020 - val_mae: 0.0024\n",
      "Epoch 32/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0020 - mae: 0.0040 - val_loss: 0.0019 - val_mae: 0.0029\n",
      "Epoch 33/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0019 - mae: 0.0041 - val_loss: 0.0018 - val_mae: 0.0025\n",
      "Epoch 34/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0018 - mae: 0.0041 - val_loss: 0.0017 - val_mae: 0.0025\n",
      "Epoch 35/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0017 - mae: 0.0044 - val_loss: 0.0017 - val_mae: 0.0037\n",
      "Epoch 36/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0017 - mae: 0.0040 - val_loss: 0.0016 - val_mae: 0.0033\n",
      "Epoch 37/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0016 - mae: 0.0039 - val_loss: 0.0016 - val_mae: 0.0066\n",
      "Epoch 38/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0015 - mae: 0.0039 - val_loss: 0.0015 - val_mae: 0.0030\n",
      "Epoch 39/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0032\n",
      "Epoch 40/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0014 - mae: 0.0038 - val_loss: 0.0013 - val_mae: 0.0027\n",
      "Epoch 41/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0013 - mae: 0.0039 - val_loss: 0.0013 - val_mae: 0.0029\n",
      "Epoch 42/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0013 - mae: 0.0039 - val_loss: 0.0012 - val_mae: 0.0026\n",
      "Epoch 43/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0012 - mae: 0.0038 - val_loss: 0.0013 - val_mae: 0.0076\n",
      "Epoch 44/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0012 - mae: 0.0038 - val_loss: 0.0012 - val_mae: 0.0024\n",
      "Epoch 45/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0012 - mae: 0.0036 - val_loss: 0.0011 - val_mae: 0.0021\n",
      "Epoch 46/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0011 - mae: 0.0038 - val_loss: 0.0011 - val_mae: 0.0060\n",
      "Epoch 47/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0011 - mae: 0.0036 - val_loss: 0.0011 - val_mae: 0.0036\n",
      "Epoch 48/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0011 - mae: 0.0037 - val_loss: 0.0010 - val_mae: 0.0021\n",
      "Epoch 49/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0010 - mae: 0.0036 - val_loss: 9.8274e-04 - val_mae: 0.0024\n",
      "Epoch 50/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 9.9533e-04 - mae: 0.0036 - val_loss: 9.5427e-04 - val_mae: 0.0025\n",
      "Epoch 51/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 9.6121e-04 - mae: 0.0036 - val_loss: 9.5188e-04 - val_mae: 0.0047\n",
      "Epoch 52/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 9.3496e-04 - mae: 0.0037 - val_loss: 8.9478e-04 - val_mae: 0.0022\n",
      "Epoch 53/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 9.0977e-04 - mae: 0.0037 - val_loss: 8.7639e-04 - val_mae: 0.0032\n",
      "Epoch 54/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 8.8488e-04 - mae: 0.0036 - val_loss: 8.4964e-04 - val_mae: 0.0026\n",
      "Epoch 55/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 8.5753e-04 - mae: 0.0035 - val_loss: 8.2202e-04 - val_mae: 0.0023\n",
      "Epoch 56/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 8.3312e-04 - mae: 0.0035 - val_loss: 8.0114e-04 - val_mae: 0.0026\n",
      "Epoch 57/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 8.0802e-04 - mae: 0.0034 - val_loss: 7.8894e-04 - val_mae: 0.0034\n",
      "Epoch 58/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 7.9186e-04 - mae: 0.0035 - val_loss: 7.6627e-04 - val_mae: 0.0033\n",
      "Epoch 59/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 7.7345e-04 - mae: 0.0036 - val_loss: 7.3909e-04 - val_mae: 0.0026\n",
      "Epoch 60/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 7.4687e-04 - mae: 0.0033 - val_loss: 7.3620e-04 - val_mae: 0.0044\n",
      "Epoch 61/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.2848e-04 - mae: 0.0033 - val_loss: 7.0567e-04 - val_mae: 0.0029\n",
      "Epoch 62/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 7.1407e-04 - mae: 0.0033 - val_loss: 6.8339e-04 - val_mae: 0.0023\n",
      "Epoch 63/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 7.0028e-04 - mae: 0.0035 - val_loss: 6.6684e-04 - val_mae: 0.0023\n",
      "Epoch 64/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 6.7921e-04 - mae: 0.0034 - val_loss: 6.5952e-04 - val_mae: 0.0035\n",
      "Epoch 65/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 6.6849e-04 - mae: 0.0035 - val_loss: 8.2754e-04 - val_mae: 0.0112\n",
      "Epoch 66/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 6.5003e-04 - mae: 0.0034 - val_loss: 6.2264e-04 - val_mae: 0.0026\n",
      "Epoch 67/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 6.3450e-04 - mae: 0.0032 - val_loss: 6.1722e-04 - val_mae: 0.0033\n",
      "Epoch 68/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 6.1679e-04 - mae: 0.0032 - val_loss: 6.5881e-04 - val_mae: 0.0066\n",
      "Epoch 69/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.0929e-04 - mae: 0.0034 - val_loss: 5.8357e-04 - val_mae: 0.0030\n",
      "Epoch 70/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 5.9495e-04 - mae: 0.0033 - val_loss: 5.7030e-04 - val_mae: 0.0027\n",
      "Epoch 71/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 5.8217e-04 - mae: 0.0033 - val_loss: 5.5806e-04 - val_mae: 0.0025\n",
      "Epoch 72/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 5.6934e-04 - mae: 0.0032 - val_loss: 5.4464e-04 - val_mae: 0.0025\n",
      "Epoch 73/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 5.5459e-04 - mae: 0.0031 - val_loss: 5.3514e-04 - val_mae: 0.0027\n",
      "Epoch 74/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 5.4827e-04 - mae: 0.0032 - val_loss: 5.2565e-04 - val_mae: 0.0028\n",
      "Epoch 75/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 5.3147e-04 - mae: 0.0031 - val_loss: 5.0785e-04 - val_mae: 0.0022\n",
      "Epoch 76/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 5.2234e-04 - mae: 0.0033 - val_loss: 4.9603e-04 - val_mae: 0.0020\n",
      "Epoch 77/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 5.1315e-04 - mae: 0.0032 - val_loss: 4.8617e-04 - val_mae: 0.0021\n",
      "Epoch 78/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 5.0118e-04 - mae: 0.0031 - val_loss: 4.7677e-04 - val_mae: 0.0021\n",
      "Epoch 79/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.9124e-04 - mae: 0.0032 - val_loss: 4.9241e-04 - val_mae: 0.0040\n",
      "Epoch 80/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 4.8517e-04 - mae: 0.0033 - val_loss: 4.5886e-04 - val_mae: 0.0021\n",
      "Epoch 81/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 4.7494e-04 - mae: 0.0032 - val_loss: 4.5545e-04 - val_mae: 0.0030\n",
      "Epoch 82/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 4.6773e-04 - mae: 0.0032 - val_loss: 4.4339e-04 - val_mae: 0.0024\n",
      "Epoch 83/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.5461e-04 - mae: 0.0030 - val_loss: 4.5100e-04 - val_mae: 0.0043\n",
      "Epoch 84/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.4994e-04 - mae: 0.0032 - val_loss: 4.4618e-04 - val_mae: 0.0043\n",
      "Epoch 85/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.4137e-04 - mae: 0.0031 - val_loss: 4.1747e-04 - val_mae: 0.0021\n",
      "Epoch 86/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 4.3187e-04 - mae: 0.0030 - val_loss: 4.3962e-04 - val_mae: 0.0045\n",
      "Epoch 87/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.2449e-04 - mae: 0.0031 - val_loss: 4.0354e-04 - val_mae: 0.0022\n",
      "Epoch 88/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 4.1876e-04 - mae: 0.0031 - val_loss: 3.9435e-04 - val_mae: 0.0019\n",
      "Epoch 89/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 4.0911e-04 - mae: 0.0030 - val_loss: 3.8787e-04 - val_mae: 0.0020\n",
      "Epoch 90/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 4.0520e-04 - mae: 0.0031 - val_loss: 3.8150e-04 - val_mae: 0.0020\n",
      "Epoch 91/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.9778e-04 - mae: 0.0030 - val_loss: 3.7864e-04 - val_mae: 0.0025\n",
      "Epoch 92/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.9102e-04 - mae: 0.0030 - val_loss: 4.4528e-04 - val_mae: 0.0077\n",
      "Epoch 93/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.8458e-04 - mae: 0.0030 - val_loss: 3.6792e-04 - val_mae: 0.0029\n",
      "Epoch 94/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.7866e-04 - mae: 0.0031 - val_loss: 5.1895e-04 - val_mae: 0.0090\n",
      "Epoch 95/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.7331e-04 - mae: 0.0031 - val_loss: 3.5338e-04 - val_mae: 0.0023\n",
      "Epoch 96/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 3.6391e-04 - mae: 0.0028 - val_loss: 3.5026e-04 - val_mae: 0.0026\n",
      "Epoch 97/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.6353e-04 - mae: 0.0031 - val_loss: 3.4042e-04 - val_mae: 0.0021\n",
      "Epoch 98/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.5372e-04 - mae: 0.0029 - val_loss: 3.4024e-04 - val_mae: 0.0030\n",
      "Epoch 99/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 3.5206e-04 - mae: 0.0031 - val_loss: 3.3709e-04 - val_mae: 0.0027\n",
      "Epoch 100/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.4444e-04 - mae: 0.0029 - val_loss: 3.2387e-04 - val_mae: 0.0018\n",
      "Epoch 101/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.3748e-04 - mae: 0.0029 - val_loss: 3.2339e-04 - val_mae: 0.0024\n",
      "Epoch 102/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.3554e-04 - mae: 0.0030 - val_loss: 3.1839e-04 - val_mae: 0.0026\n",
      "Epoch 103/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.2843e-04 - mae: 0.0029 - val_loss: 3.1088e-04 - val_mae: 0.0021\n",
      "Epoch 104/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 3.2579e-04 - mae: 0.0030 - val_loss: 3.2084e-04 - val_mae: 0.0032\n",
      "Epoch 105/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.2248e-04 - mae: 0.0030 - val_loss: 3.0120e-04 - val_mae: 0.0019\n",
      "Epoch 106/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 3.1634e-04 - mae: 0.0029 - val_loss: 2.9820e-04 - val_mae: 0.0020\n",
      "Epoch 107/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 3.1404e-04 - mae: 0.0030 - val_loss: 3.5384e-04 - val_mae: 0.0069\n",
      "Epoch 108/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.0546e-04 - mae: 0.0027 - val_loss: 2.8982e-04 - val_mae: 0.0020\n",
      "Epoch 109/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.0560e-04 - mae: 0.0029 - val_loss: 2.9019e-04 - val_mae: 0.0026\n",
      "Epoch 110/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.9994e-04 - mae: 0.0029 - val_loss: 2.8325e-04 - val_mae: 0.0020\n",
      "Epoch 111/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.9584e-04 - mae: 0.0028 - val_loss: 2.7774e-04 - val_mae: 0.0017\n",
      "Epoch 112/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.9119e-04 - mae: 0.0028 - val_loss: 2.7441e-04 - val_mae: 0.0020\n",
      "Epoch 113/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.9105e-04 - mae: 0.0029 - val_loss: 2.7036e-04 - val_mae: 0.0018\n",
      "Epoch 114/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.8514e-04 - mae: 0.0029 - val_loss: 2.6716e-04 - val_mae: 0.0019\n",
      "Epoch 115/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.8196e-04 - mae: 0.0028 - val_loss: 2.6960e-04 - val_mae: 0.0027\n",
      "Epoch 116/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.7886e-04 - mae: 0.0029 - val_loss: 2.7582e-04 - val_mae: 0.0041\n",
      "Epoch 117/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.7477e-04 - mae: 0.0029 - val_loss: 2.5916e-04 - val_mae: 0.0021\n",
      "Epoch 118/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.7068e-04 - mae: 0.0027 - val_loss: 2.5612e-04 - val_mae: 0.0022\n",
      "Epoch 119/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.6837e-04 - mae: 0.0028 - val_loss: 2.5677e-04 - val_mae: 0.0028\n",
      "Epoch 120/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.6477e-04 - mae: 0.0028 - val_loss: 2.4969e-04 - val_mae: 0.0022\n",
      "Epoch 121/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.6168e-04 - mae: 0.0028 - val_loss: 2.4590e-04 - val_mae: 0.0020\n",
      "Epoch 122/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.5827e-04 - mae: 0.0027 - val_loss: 2.4519e-04 - val_mae: 0.0021\n",
      "Epoch 123/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.5716e-04 - mae: 0.0028 - val_loss: 2.4180e-04 - val_mae: 0.0023\n",
      "Epoch 124/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.5341e-04 - mae: 0.0027 - val_loss: 2.4431e-04 - val_mae: 0.0029\n",
      "Epoch 125/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.4953e-04 - mae: 0.0026 - val_loss: 2.3382e-04 - val_mae: 0.0017\n",
      "Epoch 126/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.5010e-04 - mae: 0.0028 - val_loss: 2.3213e-04 - val_mae: 0.0020\n",
      "Epoch 127/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.4424e-04 - mae: 0.0027 - val_loss: 2.3437e-04 - val_mae: 0.0025\n",
      "Epoch 128/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.4378e-04 - mae: 0.0028 - val_loss: 2.2733e-04 - val_mae: 0.0019\n",
      "Epoch 129/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.3862e-04 - mae: 0.0026 - val_loss: 2.2574e-04 - val_mae: 0.0022\n",
      "Epoch 130/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.3877e-04 - mae: 0.0028 - val_loss: 2.6214e-04 - val_mae: 0.0054\n",
      "Epoch 131/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.3689e-04 - mae: 0.0028 - val_loss: 2.1924e-04 - val_mae: 0.0018\n",
      "Epoch 132/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.3254e-04 - mae: 0.0027 - val_loss: 2.1678e-04 - val_mae: 0.0017\n",
      "Epoch 133/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3091e-04 - mae: 0.0027 - val_loss: 2.2572e-04 - val_mae: 0.0032\n",
      "Epoch 134/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.2875e-04 - mae: 0.0027 - val_loss: 2.1937e-04 - val_mae: 0.0030\n",
      "Epoch 135/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.2710e-04 - mae: 0.0027 - val_loss: 2.1209e-04 - val_mae: 0.0020\n",
      "Epoch 136/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2236e-04 - mae: 0.0026 - val_loss: 2.0872e-04 - val_mae: 0.0018\n",
      "Epoch 137/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.2373e-04 - mae: 0.0027 - val_loss: 2.2728e-04 - val_mae: 0.0044\n",
      "Epoch 138/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.2134e-04 - mae: 0.0027 - val_loss: 2.0503e-04 - val_mae: 0.0019\n",
      "Epoch 139/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.1813e-04 - mae: 0.0027 - val_loss: 2.0279e-04 - val_mae: 0.0018\n",
      "Epoch 140/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.1697e-04 - mae: 0.0027 - val_loss: 2.0098e-04 - val_mae: 0.0018\n",
      "Epoch 141/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.1693e-04 - mae: 0.0028 - val_loss: 1.9988e-04 - val_mae: 0.0020\n",
      "Epoch 142/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.1086e-04 - mae: 0.0025 - val_loss: 1.9874e-04 - val_mae: 0.0020\n",
      "Epoch 143/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.1056e-04 - mae: 0.0026 - val_loss: 2.0322e-04 - val_mae: 0.0030\n",
      "Epoch 144/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0810e-04 - mae: 0.0026 - val_loss: 1.9458e-04 - val_mae: 0.0019\n",
      "Epoch 145/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0887e-04 - mae: 0.0027 - val_loss: 2.1073e-04 - val_mae: 0.0041\n",
      "Epoch 146/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.0626e-04 - mae: 0.0027 - val_loss: 1.9093e-04 - val_mae: 0.0019\n",
      "Epoch 147/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0243e-04 - mae: 0.0025 - val_loss: 1.8923e-04 - val_mae: 0.0018\n",
      "Epoch 148/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.0298e-04 - mae: 0.0027 - val_loss: 1.8863e-04 - val_mae: 0.0020\n",
      "Epoch 149/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0255e-04 - mae: 0.0028 - val_loss: 1.9650e-04 - val_mae: 0.0033\n",
      "Epoch 150/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.0006e-04 - mae: 0.0027 - val_loss: 1.8704e-04 - val_mae: 0.0020\n",
      "Epoch 151/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9644e-04 - mae: 0.0025 - val_loss: 1.8524e-04 - val_mae: 0.0022\n",
      "Epoch 152/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9744e-04 - mae: 0.0027 - val_loss: 1.8341e-04 - val_mae: 0.0020\n",
      "Epoch 153/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9500e-04 - mae: 0.0026 - val_loss: 1.8120e-04 - val_mae: 0.0019\n",
      "Epoch 154/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.9468e-04 - mae: 0.0027 - val_loss: 1.7891e-04 - val_mae: 0.0017\n",
      "Epoch 155/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.9363e-04 - mae: 0.0027 - val_loss: 1.9208e-04 - val_mae: 0.0034\n",
      "Epoch 156/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9117e-04 - mae: 0.0026 - val_loss: 1.8011e-04 - val_mae: 0.0023\n",
      "Epoch 157/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9497e-04 - mae: 0.0027 - val_loss: 1.7611e-04 - val_mae: 0.0018\n",
      "Epoch 158/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.8772e-04 - mae: 0.0025 - val_loss: 1.7461e-04 - val_mae: 0.0017\n",
      "Epoch 159/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.8888e-04 - mae: 0.0026 - val_loss: 3.4808e-04 - val_mae: 0.0124\n",
      "Epoch 160/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.8855e-04 - mae: 0.0027 - val_loss: 1.7694e-04 - val_mae: 0.0023\n",
      "Epoch 161/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.8581e-04 - mae: 0.0026 - val_loss: 1.7236e-04 - val_mae: 0.0020\n",
      "Epoch 162/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.8493e-04 - mae: 0.0027 - val_loss: 1.7005e-04 - val_mae: 0.0018\n",
      "Epoch 163/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8577e-04 - mae: 0.0026 - val_loss: 1.7357e-04 - val_mae: 0.0025\n",
      "Epoch 164/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8607e-04 - mae: 0.0028 - val_loss: 1.8761e-04 - val_mae: 0.0039\n",
      "Epoch 165/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8075e-04 - mae: 0.0025 - val_loss: 1.7149e-04 - val_mae: 0.0024\n",
      "Epoch 166/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.8322e-04 - mae: 0.0027 - val_loss: 1.6672e-04 - val_mae: 0.0018\n",
      "Epoch 167/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.8030e-04 - mae: 0.0026 - val_loss: 1.8188e-04 - val_mae: 0.0037\n",
      "Epoch 168/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.8095e-04 - mae: 0.0026 - val_loss: 1.8079e-04 - val_mae: 0.0039\n",
      "Epoch 169/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.7851e-04 - mae: 0.0025 - val_loss: 1.6851e-04 - val_mae: 0.0027\n",
      "Epoch 170/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7827e-04 - mae: 0.0026 - val_loss: 1.6363e-04 - val_mae: 0.0019\n",
      "Epoch 171/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7713e-04 - mae: 0.0027 - val_loss: 2.7177e-04 - val_mae: 0.0089\n",
      "Epoch 172/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7572e-04 - mae: 0.0026 - val_loss: 1.6047e-04 - val_mae: 0.0017\n",
      "Epoch 173/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7497e-04 - mae: 0.0026 - val_loss: 1.7626e-04 - val_mae: 0.0039\n",
      "Epoch 174/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.7566e-04 - mae: 0.0027 - val_loss: 1.6128e-04 - val_mae: 0.0019\n",
      "Epoch 175/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7361e-04 - mae: 0.0027 - val_loss: 1.7401e-04 - val_mae: 0.0040\n",
      "Epoch 176/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.7361e-04 - mae: 0.0026 - val_loss: 1.7436e-04 - val_mae: 0.0039\n",
      "Epoch 177/1000\n",
      "1424/1426 [============================>.] - ETA: 0s - loss: 1.7065e-04 - mae: 0.0026Restoring model weights from the end of the best epoch: 172.\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.7064e-04 - mae: 0.0026 - val_loss: 1.6503e-04 - val_mae: 0.0028\n",
      "Epoch 177: early stopping\n",
      "Training fÃ¼r Fold 4...\n",
      "Epoch 1/1000\n",
      "1426/1426 [==============================] - 5s 3ms/step - loss: 0.0253 - mae: 0.0440 - val_loss: 0.0170 - val_mae: 0.0226\n",
      "Epoch 2/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0157 - mae: 0.0169 - val_loss: 0.0152 - val_mae: 0.0233\n",
      "Epoch 3/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0144 - mae: 0.0150 - val_loss: 0.0137 - val_mae: 0.0124\n",
      "Epoch 4/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0132 - mae: 0.0124 - val_loss: 0.0127 - val_mae: 0.0106\n",
      "Epoch 5/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0124 - mae: 0.0122 - val_loss: 0.0126 - val_mae: 0.0224\n",
      "Epoch 6/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0114 - mae: 0.0104 - val_loss: 0.0111 - val_mae: 0.0129\n",
      "Epoch 7/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0107 - mae: 0.0109 - val_loss: 0.0101 - val_mae: 0.0057\n",
      "Epoch 8/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0099 - mae: 0.0093 - val_loss: 0.0094 - val_mae: 0.0050\n",
      "Epoch 9/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0092 - mae: 0.0085 - val_loss: 0.0088 - val_mae: 0.0081\n",
      "Epoch 10/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0082 - val_mae: 0.0084\n",
      "Epoch 11/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0079 - mae: 0.0078 - val_loss: 0.0075 - val_mae: 0.0062\n",
      "Epoch 12/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0074 - mae: 0.0079 - val_loss: 0.0070 - val_mae: 0.0046\n",
      "Epoch 13/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0068 - mae: 0.0066 - val_loss: 0.0067 - val_mae: 0.0096\n",
      "Epoch 14/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0064 - mae: 0.0070 - val_loss: 0.0061 - val_mae: 0.0083\n",
      "Epoch 15/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0059 - mae: 0.0064 - val_loss: 0.0056 - val_mae: 0.0031\n",
      "Epoch 16/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0055 - mae: 0.0064 - val_loss: 0.0052 - val_mae: 0.0048\n",
      "Epoch 17/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0051 - mae: 0.0061 - val_loss: 0.0049 - val_mae: 0.0033\n",
      "Epoch 18/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0047 - mae: 0.0057 - val_loss: 0.0045 - val_mae: 0.0031\n",
      "Epoch 19/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0044 - mae: 0.0056 - val_loss: 0.0042 - val_mae: 0.0029\n",
      "Epoch 20/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0041 - mae: 0.0051 - val_loss: 0.0040 - val_mae: 0.0076\n",
      "Epoch 21/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0038 - mae: 0.0049 - val_loss: 0.0037 - val_mae: 0.0033\n",
      "Epoch 22/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0036 - mae: 0.0053 - val_loss: 0.0034 - val_mae: 0.0025\n",
      "Epoch 23/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0034 - mae: 0.0047 - val_loss: 0.0032 - val_mae: 0.0032\n",
      "Epoch 24/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0031 - mae: 0.0049 - val_loss: 0.0030 - val_mae: 0.0046\n",
      "Epoch 25/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0029 - mae: 0.0044 - val_loss: 0.0028 - val_mae: 0.0027\n",
      "Epoch 26/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0028 - mae: 0.0049 - val_loss: 0.0026 - val_mae: 0.0036\n",
      "Epoch 27/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0026 - mae: 0.0044 - val_loss: 0.0025 - val_mae: 0.0035\n",
      "Epoch 28/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0025 - mae: 0.0044 - val_loss: 0.0023 - val_mae: 0.0025\n",
      "Epoch 29/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0023 - mae: 0.0045 - val_loss: 0.0022 - val_mae: 0.0047\n",
      "Epoch 30/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0022 - mae: 0.0045 - val_loss: 0.0021 - val_mae: 0.0062\n",
      "Epoch 31/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0021 - mae: 0.0041 - val_loss: 0.0020 - val_mae: 0.0042\n",
      "Epoch 32/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0020 - mae: 0.0042 - val_loss: 0.0019 - val_mae: 0.0054\n",
      "Epoch 33/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0019 - mae: 0.0043 - val_loss: 0.0018 - val_mae: 0.0026\n",
      "Epoch 34/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0018 - mae: 0.0041 - val_loss: 0.0017 - val_mae: 0.0030\n",
      "Epoch 35/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0017 - mae: 0.0040 - val_loss: 0.0016 - val_mae: 0.0025\n",
      "Epoch 36/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0016 - mae: 0.0040 - val_loss: 0.0015 - val_mae: 0.0026\n",
      "Epoch 37/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0015 - mae: 0.0037 - val_loss: 0.0014 - val_mae: 0.0024\n",
      "Epoch 38/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0015 - mae: 0.0041 - val_loss: 0.0014 - val_mae: 0.0023\n",
      "Epoch 39/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0014 - mae: 0.0039 - val_loss: 0.0013 - val_mae: 0.0028\n",
      "Epoch 40/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0013 - mae: 0.0038 - val_loss: 0.0013 - val_mae: 0.0028\n",
      "Epoch 41/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0013 - mae: 0.0036 - val_loss: 0.0012 - val_mae: 0.0026\n",
      "Epoch 42/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0012 - mae: 0.0036 - val_loss: 0.0012 - val_mae: 0.0040\n",
      "Epoch 43/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0012 - mae: 0.0038 - val_loss: 0.0011 - val_mae: 0.0027\n",
      "Epoch 44/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0011 - mae: 0.0035 - val_loss: 0.0011 - val_mae: 0.0022\n",
      "Epoch 45/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0011 - mae: 0.0038 - val_loss: 0.0010 - val_mae: 0.0031\n",
      "Epoch 46/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0010 - mae: 0.0036 - val_loss: 9.9436e-04 - val_mae: 0.0026\n",
      "Epoch 47/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0010 - mae: 0.0035 - val_loss: 9.5620e-04 - val_mae: 0.0021\n",
      "Epoch 48/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 9.6910e-04 - mae: 0.0037 - val_loss: 9.2359e-04 - val_mae: 0.0022\n",
      "Epoch 49/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 9.3776e-04 - mae: 0.0036 - val_loss: 8.9493e-04 - val_mae: 0.0024\n",
      "Epoch 50/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 9.1178e-04 - mae: 0.0037 - val_loss: 8.6953e-04 - val_mae: 0.0028\n",
      "Epoch 51/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 8.7695e-04 - mae: 0.0034 - val_loss: 8.3694e-04 - val_mae: 0.0022\n",
      "Epoch 52/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 8.5395e-04 - mae: 0.0037 - val_loss: 8.0933e-04 - val_mae: 0.0021\n",
      "Epoch 53/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 8.2295e-04 - mae: 0.0034 - val_loss: 9.1270e-04 - val_mae: 0.0094\n",
      "Epoch 54/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 8.0329e-04 - mae: 0.0036 - val_loss: 7.6305e-04 - val_mae: 0.0023\n",
      "Epoch 55/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 7.7417e-04 - mae: 0.0033 - val_loss: 7.4247e-04 - val_mae: 0.0026\n",
      "Epoch 56/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 7.5409e-04 - mae: 0.0034 - val_loss: 7.1701e-04 - val_mae: 0.0019\n",
      "Epoch 57/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 7.3619e-04 - mae: 0.0033 - val_loss: 7.0149e-04 - val_mae: 0.0025\n",
      "Epoch 58/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 7.1752e-04 - mae: 0.0033 - val_loss: 6.8095e-04 - val_mae: 0.0024\n",
      "Epoch 59/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 6.9655e-04 - mae: 0.0034 - val_loss: 6.6086e-04 - val_mae: 0.0022\n",
      "Epoch 60/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.7288e-04 - mae: 0.0031 - val_loss: 6.4693e-04 - val_mae: 0.0026\n",
      "Epoch 61/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 6.6192e-04 - mae: 0.0036 - val_loss: 6.2829e-04 - val_mae: 0.0023\n",
      "Epoch 62/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 6.4430e-04 - mae: 0.0033 - val_loss: 6.5402e-04 - val_mae: 0.0056\n",
      "Epoch 63/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 6.2692e-04 - mae: 0.0031 - val_loss: 5.9557e-04 - val_mae: 0.0019\n",
      "Epoch 64/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 6.1164e-04 - mae: 0.0031 - val_loss: 5.8435e-04 - val_mae: 0.0024\n",
      "Epoch 65/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 5.9750e-04 - mae: 0.0031 - val_loss: 5.7234e-04 - val_mae: 0.0027\n",
      "Epoch 66/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 5.8288e-04 - mae: 0.0032 - val_loss: 5.6414e-04 - val_mae: 0.0033\n",
      "Epoch 67/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.7231e-04 - mae: 0.0034 - val_loss: 5.4766e-04 - val_mae: 0.0028\n",
      "Epoch 68/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 5.6499e-04 - mae: 0.0032 - val_loss: 5.3102e-04 - val_mae: 0.0021\n",
      "Epoch 69/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 5.4514e-04 - mae: 0.0030 - val_loss: 5.1917e-04 - val_mae: 0.0019\n",
      "Epoch 70/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 5.3865e-04 - mae: 0.0033 - val_loss: 5.0989e-04 - val_mae: 0.0022\n",
      "Epoch 71/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 5.3227e-04 - mae: 0.0033 - val_loss: 5.0159e-04 - val_mae: 0.0024\n",
      "Epoch 72/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 5.1340e-04 - mae: 0.0031 - val_loss: 4.9532e-04 - val_mae: 0.0030\n",
      "Epoch 73/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 5.0544e-04 - mae: 0.0031 - val_loss: 4.7813e-04 - val_mae: 0.0019\n",
      "Epoch 74/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.9618e-04 - mae: 0.0031 - val_loss: 4.7686e-04 - val_mae: 0.0030\n",
      "Epoch 75/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 4.8369e-04 - mae: 0.0030 - val_loss: 4.6228e-04 - val_mae: 0.0023\n",
      "Epoch 76/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.7810e-04 - mae: 0.0032 - val_loss: 4.4998e-04 - val_mae: 0.0019\n",
      "Epoch 77/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 4.6757e-04 - mae: 0.0030 - val_loss: 4.4925e-04 - val_mae: 0.0029\n",
      "Epoch 78/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.5958e-04 - mae: 0.0031 - val_loss: 4.3631e-04 - val_mae: 0.0023\n",
      "Epoch 79/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 4.4865e-04 - mae: 0.0030 - val_loss: 4.8453e-04 - val_mae: 0.0057\n",
      "Epoch 80/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.4172e-04 - mae: 0.0031 - val_loss: 4.1746e-04 - val_mae: 0.0019\n",
      "Epoch 81/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.3524e-04 - mae: 0.0030 - val_loss: 4.1565e-04 - val_mae: 0.0027\n",
      "Epoch 82/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.2813e-04 - mae: 0.0030 - val_loss: 4.0418e-04 - val_mae: 0.0020\n",
      "Epoch 83/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.2366e-04 - mae: 0.0031 - val_loss: 4.0961e-04 - val_mae: 0.0038\n",
      "Epoch 84/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.1669e-04 - mae: 0.0031 - val_loss: 4.0262e-04 - val_mae: 0.0034\n",
      "Epoch 85/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.0625e-04 - mae: 0.0029 - val_loss: 3.8771e-04 - val_mae: 0.0024\n",
      "Epoch 86/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 4.0207e-04 - mae: 0.0029 - val_loss: 3.7753e-04 - val_mae: 0.0019\n",
      "Epoch 87/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 4.0211e-04 - mae: 0.0031 - val_loss: 3.7846e-04 - val_mae: 0.0027\n",
      "Epoch 88/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 3.9096e-04 - mae: 0.0030 - val_loss: 3.6718e-04 - val_mae: 0.0021\n",
      "Epoch 89/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 3.8404e-04 - mae: 0.0030 - val_loss: 3.6621e-04 - val_mae: 0.0027\n",
      "Epoch 90/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.7862e-04 - mae: 0.0030 - val_loss: 3.5558e-04 - val_mae: 0.0019\n",
      "Epoch 91/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.7154e-04 - mae: 0.0029 - val_loss: 3.5092e-04 - val_mae: 0.0020\n",
      "Epoch 92/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 3.6296e-04 - mae: 0.0028 - val_loss: 3.4960e-04 - val_mae: 0.0028\n",
      "Epoch 93/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.6451e-04 - mae: 0.0031 - val_loss: 3.4088e-04 - val_mae: 0.0022\n",
      "Epoch 94/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.5594e-04 - mae: 0.0029 - val_loss: 3.3708e-04 - val_mae: 0.0022\n",
      "Epoch 95/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 3.5129e-04 - mae: 0.0029 - val_loss: 4.1502e-04 - val_mae: 0.0071\n",
      "Epoch 96/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 3.4549e-04 - mae: 0.0029 - val_loss: 3.2534e-04 - val_mae: 0.0018\n",
      "Epoch 97/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 3.5101e-04 - mae: 0.0032 - val_loss: 3.2086e-04 - val_mae: 0.0018\n",
      "Epoch 98/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.3553e-04 - mae: 0.0027 - val_loss: 3.1654e-04 - val_mae: 0.0018\n",
      "Epoch 99/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.3327e-04 - mae: 0.0029 - val_loss: 3.1362e-04 - val_mae: 0.0019\n",
      "Epoch 100/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 3.3173e-04 - mae: 0.0030 - val_loss: 3.1043e-04 - val_mae: 0.0022\n",
      "Epoch 101/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.2459e-04 - mae: 0.0029 - val_loss: 3.0389e-04 - val_mae: 0.0018\n",
      "Epoch 102/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.2337e-04 - mae: 0.0028 - val_loss: 3.0109e-04 - val_mae: 0.0020\n",
      "Epoch 103/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 3.1980e-04 - mae: 0.0029 - val_loss: 2.9784e-04 - val_mae: 0.0020\n",
      "Epoch 104/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.1151e-04 - mae: 0.0027 - val_loss: 2.9326e-04 - val_mae: 0.0019\n",
      "Epoch 105/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.1191e-04 - mae: 0.0030 - val_loss: 3.1207e-04 - val_mae: 0.0045\n",
      "Epoch 106/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.0440e-04 - mae: 0.0028 - val_loss: 2.8870e-04 - val_mae: 0.0022\n",
      "Epoch 107/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 3.0391e-04 - mae: 0.0029 - val_loss: 2.9753e-04 - val_mae: 0.0035\n",
      "Epoch 108/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.9707e-04 - mae: 0.0027 - val_loss: 2.8280e-04 - val_mae: 0.0025\n",
      "Epoch 109/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.9959e-04 - mae: 0.0030 - val_loss: 2.7575e-04 - val_mae: 0.0018\n",
      "Epoch 110/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.9129e-04 - mae: 0.0027 - val_loss: 2.7252e-04 - val_mae: 0.0018\n",
      "Epoch 111/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.9438e-04 - mae: 0.0029 - val_loss: 2.7054e-04 - val_mae: 0.0020\n",
      "Epoch 112/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.8530e-04 - mae: 0.0027 - val_loss: 2.7094e-04 - val_mae: 0.0023\n",
      "Epoch 113/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.8120e-04 - mae: 0.0027 - val_loss: 2.6975e-04 - val_mae: 0.0027\n",
      "Epoch 114/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.8168e-04 - mae: 0.0028 - val_loss: 2.6113e-04 - val_mae: 0.0019\n",
      "Epoch 115/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.7905e-04 - mae: 0.0028 - val_loss: 2.5958e-04 - val_mae: 0.0020\n",
      "Epoch 116/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.7571e-04 - mae: 0.0028 - val_loss: 2.5716e-04 - val_mae: 0.0021\n",
      "Epoch 117/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.7487e-04 - mae: 0.0028 - val_loss: 2.7351e-04 - val_mae: 0.0039\n",
      "Epoch 118/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.6936e-04 - mae: 0.0028 - val_loss: 2.5273e-04 - val_mae: 0.0021\n",
      "Epoch 119/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.6635e-04 - mae: 0.0027 - val_loss: 2.4839e-04 - val_mae: 0.0020\n",
      "Epoch 120/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.6617e-04 - mae: 0.0028 - val_loss: 2.4594e-04 - val_mae: 0.0019\n",
      "Epoch 121/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.6413e-04 - mae: 0.0029 - val_loss: 4.6399e-04 - val_mae: 0.0120\n",
      "Epoch 122/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.6118e-04 - mae: 0.0028 - val_loss: 2.4239e-04 - val_mae: 0.0019\n",
      "Epoch 123/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.5734e-04 - mae: 0.0026 - val_loss: 2.4016e-04 - val_mae: 0.0020\n",
      "Epoch 124/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.5313e-04 - mae: 0.0026 - val_loss: 2.3877e-04 - val_mae: 0.0022\n",
      "Epoch 125/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.5616e-04 - mae: 0.0029 - val_loss: 2.3397e-04 - val_mae: 0.0017\n",
      "Epoch 126/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.5115e-04 - mae: 0.0028 - val_loss: 2.3476e-04 - val_mae: 0.0023\n",
      "Epoch 127/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.5100e-04 - mae: 0.0028 - val_loss: 2.3230e-04 - val_mae: 0.0021\n",
      "Epoch 128/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.4663e-04 - mae: 0.0027 - val_loss: 2.3049e-04 - val_mae: 0.0021\n",
      "Epoch 129/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.4418e-04 - mae: 0.0027 - val_loss: 2.2843e-04 - val_mae: 0.0022\n",
      "Epoch 130/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.4271e-04 - mae: 0.0027 - val_loss: 2.2514e-04 - val_mae: 0.0019\n",
      "Epoch 131/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.3946e-04 - mae: 0.0027 - val_loss: 2.2224e-04 - val_mae: 0.0018\n",
      "Epoch 132/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.3893e-04 - mae: 0.0028 - val_loss: 2.1982e-04 - val_mae: 0.0018\n",
      "Epoch 133/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.3626e-04 - mae: 0.0027 - val_loss: 2.2175e-04 - val_mae: 0.0023\n",
      "Epoch 134/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.3930e-04 - mae: 0.0029 - val_loss: 2.2620e-04 - val_mae: 0.0031\n",
      "Epoch 135/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.3015e-04 - mae: 0.0026 - val_loss: 2.2239e-04 - val_mae: 0.0032\n",
      "Epoch 136/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.3139e-04 - mae: 0.0027 - val_loss: 2.1934e-04 - val_mae: 0.0029\n",
      "Epoch 137/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.2863e-04 - mae: 0.0026 - val_loss: 2.2786e-04 - val_mae: 0.0034\n",
      "Epoch 138/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.2832e-04 - mae: 0.0027 - val_loss: 2.1588e-04 - val_mae: 0.0027\n",
      "Epoch 139/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.3051e-04 - mae: 0.0029 - val_loss: 2.0898e-04 - val_mae: 0.0019\n",
      "Epoch 140/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.2211e-04 - mae: 0.0025 - val_loss: 2.0625e-04 - val_mae: 0.0017\n",
      "Epoch 141/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.2249e-04 - mae: 0.0026 - val_loss: 2.1072e-04 - val_mae: 0.0027\n",
      "Epoch 142/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.2016e-04 - mae: 0.0026 - val_loss: 2.0434e-04 - val_mae: 0.0020\n",
      "Epoch 143/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.2087e-04 - mae: 0.0028 - val_loss: 2.1048e-04 - val_mae: 0.0032\n",
      "Epoch 144/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.1781e-04 - mae: 0.0026 - val_loss: 2.0121e-04 - val_mae: 0.0018\n",
      "Epoch 145/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.1509e-04 - mae: 0.0026 - val_loss: 2.0789e-04 - val_mae: 0.0031\n",
      "Epoch 146/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.1668e-04 - mae: 0.0028 - val_loss: 2.2797e-04 - val_mae: 0.0049\n",
      "Epoch 147/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.1152e-04 - mae: 0.0025 - val_loss: 2.1961e-04 - val_mae: 0.0043\n",
      "Epoch 148/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.1217e-04 - mae: 0.0027 - val_loss: 1.9561e-04 - val_mae: 0.0020\n",
      "Epoch 149/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.1015e-04 - mae: 0.0026 - val_loss: 1.9500e-04 - val_mae: 0.0022\n",
      "Epoch 150/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.0905e-04 - mae: 0.0027 - val_loss: 1.9314e-04 - val_mae: 0.0019\n",
      "Epoch 151/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.0675e-04 - mae: 0.0026 - val_loss: 1.9041e-04 - val_mae: 0.0018\n",
      "Epoch 152/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.0671e-04 - mae: 0.0027 - val_loss: 1.8960e-04 - val_mae: 0.0019\n",
      "Epoch 153/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0617e-04 - mae: 0.0026 - val_loss: 1.8859e-04 - val_mae: 0.0020\n",
      "Epoch 154/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.0532e-04 - mae: 0.0027 - val_loss: 1.8828e-04 - val_mae: 0.0020\n",
      "Epoch 155/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.0269e-04 - mae: 0.0026 - val_loss: 1.8584e-04 - val_mae: 0.0019\n",
      "Epoch 156/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9959e-04 - mae: 0.0025 - val_loss: 1.8669e-04 - val_mae: 0.0020\n",
      "Epoch 157/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.0005e-04 - mae: 0.0026 - val_loss: 1.8268e-04 - val_mae: 0.0016\n",
      "Epoch 158/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9809e-04 - mae: 0.0025 - val_loss: 1.9411e-04 - val_mae: 0.0034\n",
      "Epoch 159/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.9744e-04 - mae: 0.0026 - val_loss: 1.8123e-04 - val_mae: 0.0019\n",
      "Epoch 160/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9550e-04 - mae: 0.0026 - val_loss: 1.7903e-04 - val_mae: 0.0016\n",
      "Epoch 161/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9458e-04 - mae: 0.0026 - val_loss: 1.8056e-04 - val_mae: 0.0020\n",
      "Epoch 162/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9595e-04 - mae: 0.0027 - val_loss: 1.8421e-04 - val_mae: 0.0028\n",
      "Epoch 163/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9117e-04 - mae: 0.0025 - val_loss: 1.8705e-04 - val_mae: 0.0034\n",
      "Epoch 164/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9051e-04 - mae: 0.0025 - val_loss: 1.7699e-04 - val_mae: 0.0020\n",
      "Epoch 165/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9064e-04 - mae: 0.0026 - val_loss: 1.7330e-04 - val_mae: 0.0016\n",
      "Epoch 166/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.8960e-04 - mae: 0.0026 - val_loss: 1.7908e-04 - val_mae: 0.0026\n",
      "Epoch 167/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.8857e-04 - mae: 0.0026 - val_loss: 1.7944e-04 - val_mae: 0.0028\n",
      "Epoch 168/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.8593e-04 - mae: 0.0025 - val_loss: 1.7288e-04 - val_mae: 0.0021\n",
      "Epoch 169/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.8722e-04 - mae: 0.0026 - val_loss: 2.0778e-04 - val_mae: 0.0056\n",
      "Epoch 170/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.8389e-04 - mae: 0.0025 - val_loss: 1.6948e-04 - val_mae: 0.0019\n",
      "Epoch 171/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8525e-04 - mae: 0.0026 - val_loss: 1.6780e-04 - val_mae: 0.0017\n",
      "Epoch 172/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8251e-04 - mae: 0.0025 - val_loss: 1.7005e-04 - val_mae: 0.0024\n",
      "Epoch 173/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8234e-04 - mae: 0.0026 - val_loss: 1.6566e-04 - val_mae: 0.0016\n",
      "Epoch 174/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.7969e-04 - mae: 0.0025 - val_loss: 3.5780e-04 - val_mae: 0.0098\n",
      "Epoch 175/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.8070e-04 - mae: 0.0026 - val_loss: 1.6407e-04 - val_mae: 0.0017\n",
      "Epoch 176/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.8106e-04 - mae: 0.0027 - val_loss: 1.6569e-04 - val_mae: 0.0020\n",
      "Epoch 177/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.7669e-04 - mae: 0.0025 - val_loss: 2.2236e-04 - val_mae: 0.0071\n",
      "Epoch 178/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7684e-04 - mae: 0.0026 - val_loss: 1.6346e-04 - val_mae: 0.0019\n",
      "Epoch 179/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.7549e-04 - mae: 0.0025 - val_loss: 2.1960e-04 - val_mae: 0.0071\n",
      "Epoch 180/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.7558e-04 - mae: 0.0025 - val_loss: 2.1355e-04 - val_mae: 0.0063\n",
      "Epoch 181/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.7429e-04 - mae: 0.0026 - val_loss: 1.5977e-04 - val_mae: 0.0019\n",
      "Epoch 182/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.7320e-04 - mae: 0.0025 - val_loss: 1.5721e-04 - val_mae: 0.0016\n",
      "Epoch 183/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.7230e-04 - mae: 0.0026 - val_loss: 1.5703e-04 - val_mae: 0.0018\n",
      "Epoch 184/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7206e-04 - mae: 0.0026 - val_loss: 2.0751e-04 - val_mae: 0.0057\n",
      "Epoch 185/1000\n",
      "1426/1426 [==============================] - 5s 3ms/step - loss: 1.7007e-04 - mae: 0.0025 - val_loss: 1.8662e-04 - val_mae: 0.0053\n",
      "Epoch 186/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.7036e-04 - mae: 0.0026 - val_loss: 1.6100e-04 - val_mae: 0.0028\n",
      "Epoch 187/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.6985e-04 - mae: 0.0026 - val_loss: 1.5477e-04 - val_mae: 0.0019\n",
      "Epoch 188/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.6896e-04 - mae: 0.0025 - val_loss: 1.5256e-04 - val_mae: 0.0016\n",
      "Epoch 189/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.6695e-04 - mae: 0.0025 - val_loss: 1.5705e-04 - val_mae: 0.0025\n",
      "Epoch 190/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.6969e-04 - mae: 0.0026 - val_loss: 1.5213e-04 - val_mae: 0.0017\n",
      "Epoch 191/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.6412e-04 - mae: 0.0024 - val_loss: 2.5401e-04 - val_mae: 0.0089\n",
      "Epoch 192/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.6663e-04 - mae: 0.0026 - val_loss: 1.5431e-04 - val_mae: 0.0024\n",
      "Epoch 193/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6450e-04 - mae: 0.0026 - val_loss: 1.4932e-04 - val_mae: 0.0017\n",
      "Epoch 194/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6398e-04 - mae: 0.0025 - val_loss: 1.5886e-04 - val_mae: 0.0031\n",
      "Epoch 195/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6323e-04 - mae: 0.0026 - val_loss: 1.4911e-04 - val_mae: 0.0019\n",
      "Epoch 196/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6475e-04 - mae: 0.0026 - val_loss: 1.4863e-04 - val_mae: 0.0019\n",
      "Epoch 197/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6363e-04 - mae: 0.0026 - val_loss: 1.5015e-04 - val_mae: 0.0023\n",
      "Epoch 198/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6003e-04 - mae: 0.0024 - val_loss: 1.4592e-04 - val_mae: 0.0016\n",
      "Epoch 199/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6033e-04 - mae: 0.0024 - val_loss: 1.4615e-04 - val_mae: 0.0017\n",
      "Epoch 200/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6059e-04 - mae: 0.0025 - val_loss: 1.5582e-04 - val_mae: 0.0035\n",
      "Epoch 201/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6067e-04 - mae: 0.0025 - val_loss: 1.4554e-04 - val_mae: 0.0018\n",
      "Epoch 202/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.6027e-04 - mae: 0.0026 - val_loss: 1.4611e-04 - val_mae: 0.0021\n",
      "Epoch 203/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5930e-04 - mae: 0.0025 - val_loss: 1.4403e-04 - val_mae: 0.0018\n",
      "Epoch 204/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5767e-04 - mae: 0.0024 - val_loss: 1.4310e-04 - val_mae: 0.0018\n",
      "Epoch 205/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5867e-04 - mae: 0.0026 - val_loss: 1.4626e-04 - val_mae: 0.0021\n",
      "Epoch 206/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5562e-04 - mae: 0.0024 - val_loss: 1.4390e-04 - val_mae: 0.0020\n",
      "Epoch 207/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5649e-04 - mae: 0.0025 - val_loss: 1.4164e-04 - val_mae: 0.0017\n",
      "Epoch 208/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5816e-04 - mae: 0.0026 - val_loss: 1.4125e-04 - val_mae: 0.0018\n",
      "Epoch 209/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5505e-04 - mae: 0.0024 - val_loss: 1.4066e-04 - val_mae: 0.0017\n",
      "Epoch 210/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5561e-04 - mae: 0.0025 - val_loss: 1.3993e-04 - val_mae: 0.0016\n",
      "Epoch 211/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5380e-04 - mae: 0.0025 - val_loss: 1.4992e-04 - val_mae: 0.0034\n",
      "Epoch 212/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5305e-04 - mae: 0.0025 - val_loss: 1.3872e-04 - val_mae: 0.0016\n",
      "Epoch 213/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5467e-04 - mae: 0.0025 - val_loss: 1.4119e-04 - val_mae: 0.0018\n",
      "Epoch 214/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5467e-04 - mae: 0.0025 - val_loss: 1.9166e-04 - val_mae: 0.0070\n",
      "Epoch 215/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5183e-04 - mae: 0.0024 - val_loss: 1.3769e-04 - val_mae: 0.0016\n",
      "Epoch 216/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5295e-04 - mae: 0.0025 - val_loss: 1.3988e-04 - val_mae: 0.0021\n",
      "Epoch 217/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5314e-04 - mae: 0.0025 - val_loss: 1.3632e-04 - val_mae: 0.0016\n",
      "Epoch 218/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5205e-04 - mae: 0.0025 - val_loss: 1.3851e-04 - val_mae: 0.0022\n",
      "Epoch 219/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5282e-04 - mae: 0.0026 - val_loss: 1.4791e-04 - val_mae: 0.0036\n",
      "Epoch 220/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5056e-04 - mae: 0.0025 - val_loss: 1.3524e-04 - val_mae: 0.0015\n",
      "Epoch 221/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5002e-04 - mae: 0.0025 - val_loss: 1.3474e-04 - val_mae: 0.0016\n",
      "Epoch 222/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5150e-04 - mae: 0.0026 - val_loss: 1.4080e-04 - val_mae: 0.0029\n",
      "Epoch 223/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.4983e-04 - mae: 0.0024 - val_loss: 1.3416e-04 - val_mae: 0.0016\n",
      "Epoch 224/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4884e-04 - mae: 0.0025 - val_loss: 1.4734e-04 - val_mae: 0.0032\n",
      "Epoch 225/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5034e-04 - mae: 0.0026 - val_loss: 1.3811e-04 - val_mae: 0.0026\n",
      "Epoch 226/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4808e-04 - mae: 0.0024 - val_loss: 1.3520e-04 - val_mae: 0.0020\n",
      "Epoch 227/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5042e-04 - mae: 0.0026 - val_loss: 1.3509e-04 - val_mae: 0.0022\n",
      "Epoch 228/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4703e-04 - mae: 0.0024 - val_loss: 1.3307e-04 - val_mae: 0.0017\n",
      "Epoch 229/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4748e-04 - mae: 0.0025 - val_loss: 1.3252e-04 - val_mae: 0.0017\n",
      "Epoch 230/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4585e-04 - mae: 0.0024 - val_loss: 1.3549e-04 - val_mae: 0.0024\n",
      "Epoch 231/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4638e-04 - mae: 0.0025 - val_loss: 1.3410e-04 - val_mae: 0.0023\n",
      "Epoch 232/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4833e-04 - mae: 0.0026 - val_loss: 1.3141e-04 - val_mae: 0.0017\n",
      "Epoch 233/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4430e-04 - mae: 0.0024 - val_loss: 1.3015e-04 - val_mae: 0.0015\n",
      "Epoch 234/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4417e-04 - mae: 0.0024 - val_loss: 1.6265e-04 - val_mae: 0.0051\n",
      "Epoch 235/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.4534e-04 - mae: 0.0025 - val_loss: 1.2951e-04 - val_mae: 0.0015\n",
      "Epoch 236/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.4475e-04 - mae: 0.0025 - val_loss: 1.3494e-04 - val_mae: 0.0025\n",
      "Epoch 237/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.4657e-04 - mae: 0.0026 - val_loss: 1.3070e-04 - val_mae: 0.0020\n",
      "Epoch 238/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.4463e-04 - mae: 0.0025 - val_loss: 1.3128e-04 - val_mae: 0.0020\n",
      "Epoch 239/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4283e-04 - mae: 0.0024 - val_loss: 1.3246e-04 - val_mae: 0.0023\n",
      "Epoch 240/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4250e-04 - mae: 0.0025 - val_loss: 1.2879e-04 - val_mae: 0.0017\n",
      "Epoch 241/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4521e-04 - mae: 0.0026 - val_loss: 1.4248e-04 - val_mae: 0.0035\n",
      "Epoch 242/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4309e-04 - mae: 0.0025 - val_loss: 1.3120e-04 - val_mae: 0.0022\n",
      "Epoch 243/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4004e-04 - mae: 0.0024 - val_loss: 1.3382e-04 - val_mae: 0.0027\n",
      "Epoch 244/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4381e-04 - mae: 0.0025 - val_loss: 1.4374e-04 - val_mae: 0.0038\n",
      "Epoch 245/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4157e-04 - mae: 0.0025 - val_loss: 1.2831e-04 - val_mae: 0.0020\n",
      "Epoch 246/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4211e-04 - mae: 0.0025 - val_loss: 2.4733e-04 - val_mae: 0.0101\n",
      "Epoch 247/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4202e-04 - mae: 0.0026 - val_loss: 1.3599e-04 - val_mae: 0.0032\n",
      "Epoch 248/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4182e-04 - mae: 0.0026 - val_loss: 1.2877e-04 - val_mae: 0.0021\n",
      "Epoch 249/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.4200e-04 - mae: 0.0026 - val_loss: 1.2602e-04 - val_mae: 0.0017\n",
      "Epoch 250/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.4020e-04 - mae: 0.0025 - val_loss: 1.2612e-04 - val_mae: 0.0018\n",
      "Epoch 251/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4178e-04 - mae: 0.0027 - val_loss: 1.4094e-04 - val_mae: 0.0041\n",
      "Epoch 252/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.4023e-04 - mae: 0.0025 - val_loss: 1.2629e-04 - val_mae: 0.0019\n",
      "Epoch 253/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4080e-04 - mae: 0.0026 - val_loss: 1.2725e-04 - val_mae: 0.0022\n",
      "Epoch 254/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3948e-04 - mae: 0.0025 - val_loss: 1.2454e-04 - val_mae: 0.0017\n",
      "Epoch 255/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4065e-04 - mae: 0.0025 - val_loss: 1.3056e-04 - val_mae: 0.0026\n",
      "Epoch 256/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3875e-04 - mae: 0.0025 - val_loss: 1.2403e-04 - val_mae: 0.0016\n",
      "Epoch 257/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3848e-04 - mae: 0.0025 - val_loss: 1.2408e-04 - val_mae: 0.0016\n",
      "Epoch 258/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3894e-04 - mae: 0.0025 - val_loss: 1.2555e-04 - val_mae: 0.0020\n",
      "Epoch 259/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3810e-04 - mae: 0.0025 - val_loss: 1.2574e-04 - val_mae: 0.0022\n",
      "Epoch 260/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3993e-04 - mae: 0.0025 - val_loss: 1.2962e-04 - val_mae: 0.0026\n",
      "Epoch 261/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3834e-04 - mae: 0.0025 - val_loss: 1.2370e-04 - val_mae: 0.0018\n",
      "Epoch 262/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3777e-04 - mae: 0.0025 - val_loss: 1.2292e-04 - val_mae: 0.0017\n",
      "Epoch 263/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3849e-04 - mae: 0.0025 - val_loss: 1.3615e-04 - val_mae: 0.0038\n",
      "Epoch 264/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3697e-04 - mae: 0.0025 - val_loss: 1.2228e-04 - val_mae: 0.0017\n",
      "Epoch 265/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3601e-04 - mae: 0.0025 - val_loss: 1.2184e-04 - val_mae: 0.0016\n",
      "Epoch 266/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3795e-04 - mae: 0.0025 - val_loss: 1.6304e-04 - val_mae: 0.0054\n",
      "Epoch 267/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3756e-04 - mae: 0.0026 - val_loss: 1.2172e-04 - val_mae: 0.0017\n",
      "Epoch 268/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3750e-04 - mae: 0.0025 - val_loss: 1.2251e-04 - val_mae: 0.0019\n",
      "Epoch 269/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3682e-04 - mae: 0.0025 - val_loss: 1.2305e-04 - val_mae: 0.0020\n",
      "Epoch 270/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3614e-04 - mae: 0.0026 - val_loss: 1.3189e-04 - val_mae: 0.0033\n",
      "Epoch 271/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3636e-04 - mae: 0.0026 - val_loss: 1.2291e-04 - val_mae: 0.0020\n",
      "Epoch 272/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3686e-04 - mae: 0.0026 - val_loss: 1.2136e-04 - val_mae: 0.0018\n",
      "Epoch 273/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3615e-04 - mae: 0.0025 - val_loss: 1.2793e-04 - val_mae: 0.0028\n",
      "Epoch 274/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3686e-04 - mae: 0.0026 - val_loss: 1.2408e-04 - val_mae: 0.0025\n",
      "Epoch 275/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3668e-04 - mae: 0.0026 - val_loss: 1.1964e-04 - val_mae: 0.0016\n",
      "Epoch 276/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3609e-04 - mae: 0.0026 - val_loss: 1.2069e-04 - val_mae: 0.0018\n",
      "Epoch 277/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3485e-04 - mae: 0.0025 - val_loss: 1.2313e-04 - val_mae: 0.0023\n",
      "Epoch 278/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3588e-04 - mae: 0.0026 - val_loss: 1.2129e-04 - val_mae: 0.0020\n",
      "Epoch 279/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3519e-04 - mae: 0.0025 - val_loss: 1.2476e-04 - val_mae: 0.0027\n",
      "Epoch 280/1000\n",
      "1399/1426 [============================>.] - ETA: 0s - loss: 1.3431e-04 - mae: 0.0025Restoring model weights from the end of the best epoch: 275.\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3406e-04 - mae: 0.0025 - val_loss: 1.3943e-04 - val_mae: 0.0044\n",
      "Epoch 280: early stopping\n",
      "Training fÃ¼r Fold 5...\n",
      "Epoch 1/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0256 - mae: 0.0464 - val_loss: 0.0164 - val_mae: 0.0166\n",
      "Epoch 2/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0153 - mae: 0.0148 - val_loss: 0.0147 - val_mae: 0.0186\n",
      "Epoch 3/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0141 - mae: 0.0147 - val_loss: 0.0134 - val_mae: 0.0087\n",
      "Epoch 4/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0133 - mae: 0.0154 - val_loss: 0.0126 - val_mae: 0.0092\n",
      "Epoch 5/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0122 - mae: 0.0109 - val_loss: 0.0119 - val_mae: 0.0135\n",
      "Epoch 6/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0115 - mae: 0.0116 - val_loss: 0.0110 - val_mae: 0.0085\n",
      "Epoch 7/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0107 - mae: 0.0099 - val_loss: 0.0102 - val_mae: 0.0069\n",
      "Epoch 8/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0099 - mae: 0.0086 - val_loss: 0.0095 - val_mae: 0.0046\n",
      "Epoch 9/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0093 - mae: 0.0086 - val_loss: 0.0091 - val_mae: 0.0139\n",
      "Epoch 10/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0086 - mae: 0.0085 - val_loss: 0.0082 - val_mae: 0.0069\n",
      "Epoch 11/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0080 - mae: 0.0079 - val_loss: 0.0077 - val_mae: 0.0049\n",
      "Epoch 12/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0074 - mae: 0.0078 - val_loss: 0.0071 - val_mae: 0.0049\n",
      "Epoch 13/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0069 - mae: 0.0064 - val_loss: 0.0067 - val_mae: 0.0068\n",
      "Epoch 14/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0064 - mae: 0.0066 - val_loss: 0.0062 - val_mae: 0.0034\n",
      "Epoch 15/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0060 - mae: 0.0063 - val_loss: 0.0058 - val_mae: 0.0070\n",
      "Epoch 16/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0055 - mae: 0.0065 - val_loss: 0.0053 - val_mae: 0.0059\n",
      "Epoch 17/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0051 - mae: 0.0057 - val_loss: 0.0049 - val_mae: 0.0041\n",
      "Epoch 18/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0048 - mae: 0.0054 - val_loss: 0.0046 - val_mae: 0.0044\n",
      "Epoch 19/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0045 - mae: 0.0055 - val_loss: 0.0043 - val_mae: 0.0052\n",
      "Epoch 20/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0042 - mae: 0.0057 - val_loss: 0.0040 - val_mae: 0.0040\n",
      "Epoch 21/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0039 - mae: 0.0051 - val_loss: 0.0038 - val_mae: 0.0079\n",
      "Epoch 22/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0036 - mae: 0.0052 - val_loss: 0.0035 - val_mae: 0.0035\n",
      "Epoch 23/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0034 - mae: 0.0047 - val_loss: 0.0033 - val_mae: 0.0066\n",
      "Epoch 24/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0032 - mae: 0.0046 - val_loss: 0.0031 - val_mae: 0.0042\n",
      "Epoch 25/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0030 - mae: 0.0045 - val_loss: 0.0030 - val_mae: 0.0104\n",
      "Epoch 26/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0028 - mae: 0.0043 - val_loss: 0.0027 - val_mae: 0.0030\n",
      "Epoch 27/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0026 - mae: 0.0048 - val_loss: 0.0029 - val_mae: 0.0167\n",
      "Epoch 28/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0025 - mae: 0.0041 - val_loss: 0.0024 - val_mae: 0.0034\n",
      "Epoch 29/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0023 - mae: 0.0043 - val_loss: 0.0023 - val_mae: 0.0024\n",
      "Epoch 30/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0022 - mae: 0.0043 - val_loss: 0.0022 - val_mae: 0.0073\n",
      "Epoch 31/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0021 - mae: 0.0040 - val_loss: 0.0020 - val_mae: 0.0043\n",
      "Epoch 32/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0020 - mae: 0.0041 - val_loss: 0.0019 - val_mae: 0.0043\n",
      "Epoch 33/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0019 - mae: 0.0039 - val_loss: 0.0018 - val_mae: 0.0042\n",
      "Epoch 34/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0018 - mae: 0.0042 - val_loss: 0.0017 - val_mae: 0.0035\n",
      "Epoch 35/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0017 - mae: 0.0037 - val_loss: 0.0016 - val_mae: 0.0027\n",
      "Epoch 36/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0016 - mae: 0.0040 - val_loss: 0.0016 - val_mae: 0.0027\n",
      "Epoch 37/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0015 - mae: 0.0036 - val_loss: 0.0015 - val_mae: 0.0046\n",
      "Epoch 38/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0015 - mae: 0.0039 - val_loss: 0.0014 - val_mae: 0.0025\n",
      "Epoch 39/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0014 - mae: 0.0036 - val_loss: 0.0014 - val_mae: 0.0045\n",
      "Epoch 40/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0013 - mae: 0.0037 - val_loss: 0.0014 - val_mae: 0.0088\n",
      "Epoch 41/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0013 - mae: 0.0038 - val_loss: 0.0012 - val_mae: 0.0025\n",
      "Epoch 42/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0012 - mae: 0.0037 - val_loss: 0.0012 - val_mae: 0.0026\n",
      "Epoch 43/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0012 - mae: 0.0035 - val_loss: 0.0011 - val_mae: 0.0029\n",
      "Epoch 44/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0035 - val_loss: 0.0011 - val_mae: 0.0038\n",
      "Epoch 45/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0035 - val_loss: 0.0011 - val_mae: 0.0031\n",
      "Epoch 46/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0010 - mae: 0.0035 - val_loss: 0.0010 - val_mae: 0.0031\n",
      "Epoch 47/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 9.9094e-04 - mae: 0.0037 - val_loss: 9.7821e-04 - val_mae: 0.0026\n",
      "Epoch 48/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 9.5124e-04 - mae: 0.0035 - val_loss: 9.4114e-04 - val_mae: 0.0021\n",
      "Epoch 49/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 9.1739e-04 - mae: 0.0033 - val_loss: 9.1190e-04 - val_mae: 0.0027\n",
      "Epoch 50/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 8.8856e-04 - mae: 0.0035 - val_loss: 8.8285e-04 - val_mae: 0.0029\n",
      "Epoch 51/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 8.5866e-04 - mae: 0.0034 - val_loss: 8.5277e-04 - val_mae: 0.0023\n",
      "Epoch 52/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 8.3069e-04 - mae: 0.0035 - val_loss: 8.4839e-04 - val_mae: 0.0049\n",
      "Epoch 53/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 7.9541e-04 - mae: 0.0031 - val_loss: 8.6264e-04 - val_mae: 0.0078\n",
      "Epoch 54/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 7.7314e-04 - mae: 0.0034 - val_loss: 7.7255e-04 - val_mae: 0.0028\n",
      "Epoch 55/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 7.4904e-04 - mae: 0.0034 - val_loss: 7.5259e-04 - val_mae: 0.0034\n",
      "Epoch 56/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 7.1844e-04 - mae: 0.0030 - val_loss: 7.3071e-04 - val_mae: 0.0033\n",
      "Epoch 57/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 6.9845e-04 - mae: 0.0031 - val_loss: 7.0440e-04 - val_mae: 0.0029\n",
      "Epoch 58/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 6.7775e-04 - mae: 0.0032 - val_loss: 6.9430e-04 - val_mae: 0.0039\n",
      "Epoch 59/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 6.5742e-04 - mae: 0.0032 - val_loss: 6.5960e-04 - val_mae: 0.0024\n",
      "Epoch 60/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 6.4539e-04 - mae: 0.0034 - val_loss: 6.4063e-04 - val_mae: 0.0022\n",
      "Epoch 61/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 6.1976e-04 - mae: 0.0029 - val_loss: 6.4087e-04 - val_mae: 0.0038\n",
      "Epoch 62/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 6.0298e-04 - mae: 0.0030 - val_loss: 6.1342e-04 - val_mae: 0.0030\n",
      "Epoch 63/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 5.9115e-04 - mae: 0.0032 - val_loss: 5.9463e-04 - val_mae: 0.0027\n",
      "Epoch 64/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 5.6763e-04 - mae: 0.0028 - val_loss: 5.7768e-04 - val_mae: 0.0024\n",
      "Epoch 65/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 5.5860e-04 - mae: 0.0033 - val_loss: 5.6124e-04 - val_mae: 0.0021\n",
      "Epoch 66/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 5.4136e-04 - mae: 0.0030 - val_loss: 5.5175e-04 - val_mae: 0.0027\n",
      "Epoch 67/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 5.2637e-04 - mae: 0.0031 - val_loss: 5.3942e-04 - val_mae: 0.0029\n",
      "Epoch 68/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 5.1074e-04 - mae: 0.0029 - val_loss: 0.0021 - val_mae: 0.0312\n",
      "Epoch 69/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 5.1620e-04 - mae: 0.0031 - val_loss: 5.1926e-04 - val_mae: 0.0034\n",
      "Epoch 70/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 4.9165e-04 - mae: 0.0028 - val_loss: 5.0642e-04 - val_mae: 0.0031\n",
      "Epoch 71/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 4.8219e-04 - mae: 0.0031 - val_loss: 4.8915e-04 - val_mae: 0.0026\n",
      "Epoch 72/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 4.6859e-04 - mae: 0.0029 - val_loss: 4.8338e-04 - val_mae: 0.0030\n",
      "Epoch 73/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 4.6038e-04 - mae: 0.0031 - val_loss: 4.6803e-04 - val_mae: 0.0022\n",
      "Epoch 74/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 4.5049e-04 - mae: 0.0031 - val_loss: 4.6289e-04 - val_mae: 0.0027\n",
      "Epoch 75/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 4.3852e-04 - mae: 0.0028 - val_loss: 4.4885e-04 - val_mae: 0.0023\n",
      "Epoch 76/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 4.2716e-04 - mae: 0.0027 - val_loss: 4.3809e-04 - val_mae: 0.0021\n",
      "Epoch 77/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 4.2055e-04 - mae: 0.0029 - val_loss: 4.4163e-04 - val_mae: 0.0037\n",
      "Epoch 78/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 4.1244e-04 - mae: 0.0030 - val_loss: 4.4190e-04 - val_mae: 0.0043\n",
      "Epoch 79/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 4.0308e-04 - mae: 0.0029 - val_loss: 4.1815e-04 - val_mae: 0.0031\n",
      "Epoch 80/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.9362e-04 - mae: 0.0028 - val_loss: 4.0764e-04 - val_mae: 0.0025\n",
      "Epoch 81/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.8740e-04 - mae: 0.0029 - val_loss: 3.9855e-04 - val_mae: 0.0024\n",
      "Epoch 82/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.8116e-04 - mae: 0.0028 - val_loss: 3.9092e-04 - val_mae: 0.0021\n",
      "Epoch 83/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.7289e-04 - mae: 0.0027 - val_loss: 3.8621e-04 - val_mae: 0.0023\n",
      "Epoch 84/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.6892e-04 - mae: 0.0029 - val_loss: 3.7748e-04 - val_mae: 0.0022\n",
      "Epoch 85/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.5917e-04 - mae: 0.0028 - val_loss: 3.7231e-04 - val_mae: 0.0022\n",
      "Epoch 86/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.5306e-04 - mae: 0.0029 - val_loss: 3.6824e-04 - val_mae: 0.0024\n",
      "Epoch 87/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.4675e-04 - mae: 0.0028 - val_loss: 3.5984e-04 - val_mae: 0.0023\n",
      "Epoch 88/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.4197e-04 - mae: 0.0028 - val_loss: 3.5288e-04 - val_mae: 0.0020\n",
      "Epoch 89/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.3757e-04 - mae: 0.0029 - val_loss: 3.4884e-04 - val_mae: 0.0022\n",
      "Epoch 90/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.3089e-04 - mae: 0.0028 - val_loss: 3.4263e-04 - val_mae: 0.0019\n",
      "Epoch 91/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.2583e-04 - mae: 0.0028 - val_loss: 3.6230e-04 - val_mae: 0.0049\n",
      "Epoch 92/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.1751e-04 - mae: 0.0026 - val_loss: 3.3230e-04 - val_mae: 0.0022\n",
      "Epoch 93/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.1631e-04 - mae: 0.0029 - val_loss: 4.5459e-04 - val_mae: 0.0093\n",
      "Epoch 94/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.0937e-04 - mae: 0.0028 - val_loss: 3.2924e-04 - val_mae: 0.0029\n",
      "Epoch 95/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.0501e-04 - mae: 0.0027 - val_loss: 3.2226e-04 - val_mae: 0.0025\n",
      "Epoch 96/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.0108e-04 - mae: 0.0028 - val_loss: 3.1365e-04 - val_mae: 0.0021\n",
      "Epoch 97/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.9738e-04 - mae: 0.0027 - val_loss: 3.0893e-04 - val_mae: 0.0019\n",
      "Epoch 98/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.9086e-04 - mae: 0.0028 - val_loss: 3.0758e-04 - val_mae: 0.0026\n",
      "Epoch 99/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.8881e-04 - mae: 0.0028 - val_loss: 3.0073e-04 - val_mae: 0.0019\n",
      "Epoch 100/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.8643e-04 - mae: 0.0028 - val_loss: 3.0572e-04 - val_mae: 0.0032\n",
      "Epoch 101/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.8214e-04 - mae: 0.0027 - val_loss: 2.9443e-04 - val_mae: 0.0022\n",
      "Epoch 102/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.7663e-04 - mae: 0.0027 - val_loss: 2.9267e-04 - val_mae: 0.0022\n",
      "Epoch 103/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.7346e-04 - mae: 0.0026 - val_loss: 2.9266e-04 - val_mae: 0.0028\n",
      "Epoch 104/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.7029e-04 - mae: 0.0027 - val_loss: 2.8504e-04 - val_mae: 0.0022\n",
      "Epoch 105/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.6578e-04 - mae: 0.0027 - val_loss: 2.8416e-04 - val_mae: 0.0025\n",
      "Epoch 106/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.6469e-04 - mae: 0.0027 - val_loss: 2.8530e-04 - val_mae: 0.0032\n",
      "Epoch 107/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.6090e-04 - mae: 0.0028 - val_loss: 2.8419e-04 - val_mae: 0.0035\n",
      "Epoch 108/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.5766e-04 - mae: 0.0028 - val_loss: 2.7441e-04 - val_mae: 0.0024\n",
      "Epoch 109/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.5511e-04 - mae: 0.0027 - val_loss: 2.6842e-04 - val_mae: 0.0019\n",
      "Epoch 110/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.5071e-04 - mae: 0.0027 - val_loss: 2.6592e-04 - val_mae: 0.0020\n",
      "Epoch 111/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.4782e-04 - mae: 0.0027 - val_loss: 2.6370e-04 - val_mae: 0.0021\n",
      "Epoch 112/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.4420e-04 - mae: 0.0027 - val_loss: 2.6129e-04 - val_mae: 0.0023\n",
      "Epoch 113/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.4064e-04 - mae: 0.0025 - val_loss: 2.5676e-04 - val_mae: 0.0019\n",
      "Epoch 114/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.3878e-04 - mae: 0.0026 - val_loss: 2.6368e-04 - val_mae: 0.0031\n",
      "Epoch 115/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.3578e-04 - mae: 0.0026 - val_loss: 2.5952e-04 - val_mae: 0.0029\n",
      "Epoch 116/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.3391e-04 - mae: 0.0027 - val_loss: 2.9439e-04 - val_mae: 0.0063\n",
      "Epoch 117/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.3126e-04 - mae: 0.0027 - val_loss: 2.4914e-04 - val_mae: 0.0022\n",
      "Epoch 118/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.3292e-04 - mae: 0.0027 - val_loss: 2.4413e-04 - val_mae: 0.0019\n",
      "Epoch 119/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2547e-04 - mae: 0.0025 - val_loss: 2.5585e-04 - val_mae: 0.0037\n",
      "Epoch 120/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2680e-04 - mae: 0.0027 - val_loss: 2.6727e-04 - val_mae: 0.0045\n",
      "Epoch 121/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2169e-04 - mae: 0.0026 - val_loss: 2.4296e-04 - val_mae: 0.0029\n",
      "Epoch 122/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2096e-04 - mae: 0.0027 - val_loss: 2.3618e-04 - val_mae: 0.0021\n",
      "Epoch 123/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1778e-04 - mae: 0.0026 - val_loss: 2.3873e-04 - val_mae: 0.0026\n",
      "Epoch 124/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1744e-04 - mae: 0.0027 - val_loss: 2.3492e-04 - val_mae: 0.0023\n",
      "Epoch 125/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.1789e-04 - mae: 0.0027 - val_loss: 2.2978e-04 - val_mae: 0.0021\n",
      "Epoch 126/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.1098e-04 - mae: 0.0025 - val_loss: 2.3015e-04 - val_mae: 0.0023\n",
      "Epoch 127/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1332e-04 - mae: 0.0027 - val_loss: 2.2633e-04 - val_mae: 0.0019\n",
      "Epoch 128/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.0724e-04 - mae: 0.0025 - val_loss: 2.2425e-04 - val_mae: 0.0020\n",
      "Epoch 129/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0466e-04 - mae: 0.0024 - val_loss: 2.2227e-04 - val_mae: 0.0018\n",
      "Epoch 130/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.0382e-04 - mae: 0.0025 - val_loss: 2.3107e-04 - val_mae: 0.0037\n",
      "Epoch 131/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.0376e-04 - mae: 0.0026 - val_loss: 2.1892e-04 - val_mae: 0.0019\n",
      "Epoch 132/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.0245e-04 - mae: 0.0026 - val_loss: 2.1805e-04 - val_mae: 0.0020\n",
      "Epoch 133/1000\n",
      "1426/1426 [==============================] - 6s 4ms/step - loss: 1.9884e-04 - mae: 0.0025 - val_loss: 2.4066e-04 - val_mae: 0.0044\n",
      "Epoch 134/1000\n",
      "1426/1426 [==============================] - 7s 5ms/step - loss: 1.9828e-04 - mae: 0.0026 - val_loss: 2.1602e-04 - val_mae: 0.0021\n",
      "Epoch 135/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9535e-04 - mae: 0.0025 - val_loss: 2.1565e-04 - val_mae: 0.0025\n",
      "Epoch 136/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9522e-04 - mae: 0.0026 - val_loss: 2.1531e-04 - val_mae: 0.0028\n",
      "Epoch 137/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9135e-04 - mae: 0.0024 - val_loss: 2.0928e-04 - val_mae: 0.0020\n",
      "Epoch 138/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9411e-04 - mae: 0.0026 - val_loss: 2.0782e-04 - val_mae: 0.0019\n",
      "Epoch 139/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9052e-04 - mae: 0.0025 - val_loss: 2.1042e-04 - val_mae: 0.0024\n",
      "Epoch 140/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.8780e-04 - mae: 0.0024 - val_loss: 2.0619e-04 - val_mae: 0.0022\n",
      "Epoch 141/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.8721e-04 - mae: 0.0025 - val_loss: 2.0538e-04 - val_mae: 0.0020\n",
      "Epoch 142/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.8569e-04 - mae: 0.0025 - val_loss: 2.4143e-04 - val_mae: 0.0054\n",
      "Epoch 143/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.8660e-04 - mae: 0.0027 - val_loss: 2.0155e-04 - val_mae: 0.0020\n",
      "Epoch 144/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.8087e-04 - mae: 0.0023 - val_loss: 2.0307e-04 - val_mae: 0.0025\n",
      "Epoch 145/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.8481e-04 - mae: 0.0026 - val_loss: 1.9805e-04 - val_mae: 0.0017\n",
      "Epoch 146/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.7933e-04 - mae: 0.0023 - val_loss: 2.0201e-04 - val_mae: 0.0027\n",
      "Epoch 147/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.8087e-04 - mae: 0.0025 - val_loss: 1.9645e-04 - val_mae: 0.0020\n",
      "Epoch 148/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.7974e-04 - mae: 0.0026 - val_loss: 1.9653e-04 - val_mae: 0.0022\n",
      "Epoch 149/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.7659e-04 - mae: 0.0024 - val_loss: 1.9722e-04 - val_mae: 0.0024\n",
      "Epoch 150/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.7633e-04 - mae: 0.0024 - val_loss: 2.0485e-04 - val_mae: 0.0035\n",
      "Epoch 151/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.7384e-04 - mae: 0.0024 - val_loss: 1.9663e-04 - val_mae: 0.0025\n",
      "Epoch 152/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.7445e-04 - mae: 0.0025 - val_loss: 1.9216e-04 - val_mae: 0.0022\n",
      "Epoch 153/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.7398e-04 - mae: 0.0025 - val_loss: 1.9114e-04 - val_mae: 0.0023\n",
      "Epoch 154/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.7120e-04 - mae: 0.0024 - val_loss: 2.1986e-04 - val_mae: 0.0055\n",
      "Epoch 155/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.7094e-04 - mae: 0.0024 - val_loss: 1.9188e-04 - val_mae: 0.0025\n",
      "Epoch 156/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.7025e-04 - mae: 0.0025 - val_loss: 1.8696e-04 - val_mae: 0.0018\n",
      "Epoch 157/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.6905e-04 - mae: 0.0024 - val_loss: 1.8589e-04 - val_mae: 0.0017\n",
      "Epoch 158/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.6862e-04 - mae: 0.0025 - val_loss: 1.8413e-04 - val_mae: 0.0018\n",
      "Epoch 159/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.6725e-04 - mae: 0.0025 - val_loss: 1.8438e-04 - val_mae: 0.0018\n",
      "Epoch 160/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.6626e-04 - mae: 0.0025 - val_loss: 1.9579e-04 - val_mae: 0.0036\n",
      "Epoch 161/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.6534e-04 - mae: 0.0025 - val_loss: 1.8226e-04 - val_mae: 0.0019\n",
      "Epoch 162/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.6896e-04 - mae: 0.0027 - val_loss: 1.8079e-04 - val_mae: 0.0016\n",
      "Epoch 163/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.6232e-04 - mae: 0.0023 - val_loss: 1.8095e-04 - val_mae: 0.0018\n",
      "Epoch 164/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.6466e-04 - mae: 0.0024 - val_loss: 1.7992e-04 - val_mae: 0.0019\n",
      "Epoch 165/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.6284e-04 - mae: 0.0025 - val_loss: 1.7888e-04 - val_mae: 0.0017\n",
      "Epoch 166/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.6331e-04 - mae: 0.0025 - val_loss: 1.7909e-04 - val_mae: 0.0018\n",
      "Epoch 167/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.6131e-04 - mae: 0.0025 - val_loss: 2.0124e-04 - val_mae: 0.0049\n",
      "Epoch 168/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.6153e-04 - mae: 0.0024 - val_loss: 1.7818e-04 - val_mae: 0.0020\n",
      "Epoch 169/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5990e-04 - mae: 0.0025 - val_loss: 1.7624e-04 - val_mae: 0.0018\n",
      "Epoch 170/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5856e-04 - mae: 0.0024 - val_loss: 1.8459e-04 - val_mae: 0.0028\n",
      "Epoch 171/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5834e-04 - mae: 0.0024 - val_loss: 1.7401e-04 - val_mae: 0.0017\n",
      "Epoch 172/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5856e-04 - mae: 0.0025 - val_loss: 1.8286e-04 - val_mae: 0.0028\n",
      "Epoch 173/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5646e-04 - mae: 0.0023 - val_loss: 1.7739e-04 - val_mae: 0.0027\n",
      "Epoch 174/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5966e-04 - mae: 0.0026 - val_loss: 2.3028e-04 - val_mae: 0.0077\n",
      "Epoch 175/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5395e-04 - mae: 0.0023 - val_loss: 1.7287e-04 - val_mae: 0.0021\n",
      "Epoch 176/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5639e-04 - mae: 0.0024 - val_loss: 1.7417e-04 - val_mae: 0.0021\n",
      "Epoch 177/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5456e-04 - mae: 0.0024 - val_loss: 1.7212e-04 - val_mae: 0.0020\n",
      "Epoch 178/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5409e-04 - mae: 0.0025 - val_loss: 1.7124e-04 - val_mae: 0.0021\n",
      "Epoch 179/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5422e-04 - mae: 0.0024 - val_loss: 1.6925e-04 - val_mae: 0.0017\n",
      "Epoch 180/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5152e-04 - mae: 0.0024 - val_loss: 1.7308e-04 - val_mae: 0.0023\n",
      "Epoch 181/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5338e-04 - mae: 0.0025 - val_loss: 1.7339e-04 - val_mae: 0.0026\n",
      "Epoch 182/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5014e-04 - mae: 0.0023 - val_loss: 1.7515e-04 - val_mae: 0.0029\n",
      "Epoch 183/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5048e-04 - mae: 0.0024 - val_loss: 1.8076e-04 - val_mae: 0.0038\n",
      "Epoch 184/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5140e-04 - mae: 0.0025 - val_loss: 1.6585e-04 - val_mae: 0.0016\n",
      "Epoch 185/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.4947e-04 - mae: 0.0024 - val_loss: 1.7047e-04 - val_mae: 0.0027\n",
      "Epoch 186/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5113e-04 - mae: 0.0024 - val_loss: 1.7081e-04 - val_mae: 0.0027\n",
      "Epoch 187/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.4868e-04 - mae: 0.0024 - val_loss: 1.6480e-04 - val_mae: 0.0018\n",
      "Epoch 188/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.4872e-04 - mae: 0.0024 - val_loss: 1.7506e-04 - val_mae: 0.0033\n",
      "Epoch 189/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5063e-04 - mae: 0.0025 - val_loss: 1.6307e-04 - val_mae: 0.0016\n",
      "Epoch 190/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.4863e-04 - mae: 0.0025 - val_loss: 1.6573e-04 - val_mae: 0.0022\n",
      "Epoch 191/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.4891e-04 - mae: 0.0024 - val_loss: 1.7976e-04 - val_mae: 0.0037\n",
      "Epoch 192/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.4483e-04 - mae: 0.0023 - val_loss: 1.6787e-04 - val_mae: 0.0024\n",
      "Epoch 193/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.4505e-04 - mae: 0.0024 - val_loss: 1.6555e-04 - val_mae: 0.0022\n",
      "Epoch 194/1000\n",
      "1413/1426 [============================>.] - ETA: 0s - loss: 1.4742e-04 - mae: 0.0026Restoring model weights from the end of the best epoch: 189.\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.4722e-04 - mae: 0.0026 - val_loss: 1.6373e-04 - val_mae: 0.0020\n",
      "Epoch 194: early stopping\n",
      "Durchschnittlicher Validation Loss: 0.000150350846524816\n",
      "Durchschnittlicher Validation MAE: 0.0016338419169187545\n"
     ]
    }
   ],
   "source": [
    "# Initialisiere Listen, um Ergebnisse zu speichern\n",
    "val_loss_results = []\n",
    "val_mae_results = []\n",
    "\n",
    "# Funktion, um das Modell zu erstellen\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "            \n",
    "            Dense(56, activation='relu', input_shape=(4,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "        \n",
    "            Dense(200, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "            \n",
    "            Dense(120, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "            \n",
    "            Dense(296, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "            \n",
    "            Dense(280, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "            \n",
    "            Dense(232, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "            \n",
    "            Dense(1 , activation = 'linear')\n",
    "\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# K-Fold Cross-Validation Konfiguration\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# LeistungsÃ¼berwachung\n",
    "fold_no = 1\n",
    "for train_index, val_index in kf.split(X_train_scaled):\n",
    "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_scaled[train_index], y_train_scaled[val_index]\n",
    "\n",
    "    model = create_model()\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "    print(f'Training fÃ¼r Fold {fold_no}...')\n",
    "    history = model.fit(X_train_fold, y_train_fold, batch_size=25, epochs=1000, validation_data=(X_val_fold, y_val_fold), callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "    # Speichere die Ergebnisse des aktuellen Folds\n",
    "    val_loss_results.append(min(history.history['val_loss']))\n",
    "    val_mae_results.append(min(history.history['val_mae']))\n",
    "\n",
    "    fold_no += 1\n",
    "\n",
    "# Berechne den Durchschnitt Ã¼ber alle Folds\n",
    "average_val_loss = np.mean(val_loss_results)\n",
    "average_val_mae = np.mean(val_mae_results)\n",
    "\n",
    "# Umwandeln der Listen in Pandas DataFrames\n",
    "val_loss_df = pd.DataFrame(val_loss_results, columns=['Validation Loss'])\n",
    "val_mae_df = pd.DataFrame(val_mae_results, columns=['Validation MAE'])\n",
    "\n",
    "# Speichern der DataFrames in CSV-Dateien\n",
    "val_loss_df.to_csv('val_loss_results_D3_I_F_2.csv', index=False)\n",
    "val_mae_df.to_csv('val_mae_results_D3_I_F_2.csv', index=False)\n",
    "\n",
    "# Gib die durchschnittlichen Ergebnisse aus\n",
    "print(f'Durchschnittlicher Validation Loss: {average_val_loss}')\n",
    "print(f'Durchschnittlicher Validation MAE: {average_val_mae}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T12:46:49.634664400Z",
     "start_time": "2024-04-01T11:44:04.187493600Z"
    }
   },
   "id": "7ff728388210d66b"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 - 0s - loss: 1.4115e-04 - mae: 0.0034 - 189ms/epoch - 950us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.00014115248632151634, 0.0034039642196148634]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test_scaled_2, y_test_scaled_2, verbose=2)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T12:50:50.899858700Z",
     "start_time": "2024-04-01T12:50:50.671429400Z"
    }
   },
   "id": "9050ab66ab36f169"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bsp. Predicted: [722.7445] Actual: [735.96] \n",
      "Durchschnittliche Abweichung (MAE): [8.77269619]\n",
      "0.6346777724420171\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scaled_predicted_values = model.predict(X_test_scaled_2, verbose = 0)\n",
    "\n",
    "# FÃ¼hren Sie die RÃ¼cktransformation der skalierten Werte durch\n",
    "original_predicted_values = scaler_target.inverse_transform(scaled_predicted_values)\n",
    "original_actual_values = scaler_target.inverse_transform(y_test_scaled_2)  # y_test sind die skalierten tatsÃ¤chlichen Werte\n",
    "print(f' Bsp. Predicted: {original_predicted_values[100]} Actual: {original_actual_values[100]} ')\n",
    "\n",
    "def calculate_mae(list1, list2):\n",
    "    # Stelle sicher, dass beide Listen die gleiche LÃ¤nge haben\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Listen mÃ¼ssen die gleiche LÃ¤nge haben\")\n",
    "\n",
    "    # Berechne die absolute Differenz zwischen den Elementen der Listen\n",
    "    differences = [abs(x - y) for x, y in zip(list1, list2)]\n",
    "\n",
    "    # Berechne den Durchschnitt der absoluten Differenzen\n",
    "    mae = sum(differences) / len(differences)\n",
    "\n",
    "    return mae\n",
    "\n",
    "# Beispiel\n",
    "list1 = original_predicted_values\n",
    "list2 = original_actual_values\n",
    "\n",
    "mae = calculate_mae(list1, list2)\n",
    "print(f\"Durchschnittliche Abweichung (MAE): {mae}\")\n",
    "\n",
    "\n",
    "# Beispiel\n",
    "list1 = original_predicted_values\n",
    "list2 = original_actual_values\n",
    "\n",
    "errors = np.abs((original_actual_values - original_predicted_values) / original_actual_values)\n",
    "mape = np.mean(errors) * 100\n",
    "print(mape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T12:50:53.234925100Z",
     "start_time": "2024-04-01T12:50:52.726987100Z"
    }
   },
   "id": "10cd79ca028075dd"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: [0.99897072]\n"
     ]
    }
   ],
   "source": [
    "def calculate_r_squared(predicted, actual):\n",
    "    # Berechnung des Mittelwerts der tatsÃ¤chlichen Werte\n",
    "    mean_actual = sum(actual) / len(actual)\n",
    "    \n",
    "    # Berechnung der totalen Summe der Quadrate (SST)\n",
    "    sst = sum((x - mean_actual) ** 2 for x in actual)\n",
    "    \n",
    "    # Berechnung der Summe der Quadrate der Residuen (SSE)\n",
    "    sse = sum((actual[i] - predicted[i]) ** 2 for i in range(len(actual)))\n",
    "    \n",
    "    # Berechnung des R^2-Wertes\n",
    "    r_squared = 1 - (sse / sst)\n",
    "    \n",
    "    return r_squared\n",
    "\n",
    "# Berechnung von R^2 mit den bereitgestellten Listen\n",
    "r_squared = calculate_r_squared(list1, list2)\n",
    "\n",
    "print(f\"R^2: {r_squared}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T12:50:55.724990100Z",
     "start_time": "2024-04-01T12:50:55.679472100Z"
    }
   },
   "id": "d0505d16afcbef4a"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Werte die kleiner sind: 485\n"
     ]
    },
    {
     "data": {
      "text/plain": "         Echt   Temperatur  X-Koordinate  Y-Koordinate  Differenz\n1923   978.14  1003.075684      0.306452          0.04 -24.935684\n1822   978.95  1003.799500      0.290323          0.04 -24.849500\n2127  1066.10  1090.582031      0.338710          0.06 -24.482031\n2026  1067.10  1091.457520      0.322581          0.06 -24.357520\n2025  1022.50  1046.828857      0.322581          0.05 -24.328857\n...       ...          ...           ...           ...        ...\n6323  1632.80  1589.738525      1.000000          0.61  43.061475\n6319  1664.30  1620.503296      1.000000          0.57  43.796704\n6322  1641.70  1597.803345      1.000000          0.60  43.896655\n6321  1649.90  1605.704468      1.000000          0.59  44.195532\n6320  1657.50  1613.128540      1.000000          0.58  44.371460\n\n[6363 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Echt</th>\n      <th>Temperatur</th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Differenz</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1923</th>\n      <td>978.14</td>\n      <td>1003.075684</td>\n      <td>0.306452</td>\n      <td>0.04</td>\n      <td>-24.935684</td>\n    </tr>\n    <tr>\n      <th>1822</th>\n      <td>978.95</td>\n      <td>1003.799500</td>\n      <td>0.290323</td>\n      <td>0.04</td>\n      <td>-24.849500</td>\n    </tr>\n    <tr>\n      <th>2127</th>\n      <td>1066.10</td>\n      <td>1090.582031</td>\n      <td>0.338710</td>\n      <td>0.06</td>\n      <td>-24.482031</td>\n    </tr>\n    <tr>\n      <th>2026</th>\n      <td>1067.10</td>\n      <td>1091.457520</td>\n      <td>0.322581</td>\n      <td>0.06</td>\n      <td>-24.357520</td>\n    </tr>\n    <tr>\n      <th>2025</th>\n      <td>1022.50</td>\n      <td>1046.828857</td>\n      <td>0.322581</td>\n      <td>0.05</td>\n      <td>-24.328857</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6323</th>\n      <td>1632.80</td>\n      <td>1589.738525</td>\n      <td>1.000000</td>\n      <td>0.61</td>\n      <td>43.061475</td>\n    </tr>\n    <tr>\n      <th>6319</th>\n      <td>1664.30</td>\n      <td>1620.503296</td>\n      <td>1.000000</td>\n      <td>0.57</td>\n      <td>43.796704</td>\n    </tr>\n    <tr>\n      <th>6322</th>\n      <td>1641.70</td>\n      <td>1597.803345</td>\n      <td>1.000000</td>\n      <td>0.60</td>\n      <td>43.896655</td>\n    </tr>\n    <tr>\n      <th>6321</th>\n      <td>1649.90</td>\n      <td>1605.704468</td>\n      <td>1.000000</td>\n      <td>0.59</td>\n      <td>44.195532</td>\n    </tr>\n    <tr>\n      <th>6320</th>\n      <td>1657.50</td>\n      <td>1613.128540</td>\n      <td>1.000000</td>\n      <td>0.58</td>\n      <td>44.371460</td>\n    </tr>\n  </tbody>\n</table>\n<p>6363 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame({'Echt': [val[0] for val in list2], 'Temperatur': [val[0] for val in list1]})\n",
    "df_result['X-Koordinate'] = X_test_scaled_2[:, 0]\n",
    "df_result['Y-Koordinate'] = X_test_scaled_2[:, 1]\n",
    "\n",
    "df_result['Differenz'] = df_result['Echt'] - df_result['Temperatur']\n",
    "df_result['Differenz'].sort_values()\n",
    "sorted_df = df_result.sort_values(by= 'Differenz')\n",
    "Anzahl_Punkte = (sorted_df['Differenz'] > 20).sum()\n",
    "print(\"Anzahl der Werte die kleiner sind:\", Anzahl_Punkte)\n",
    "\n",
    "sorted_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T12:50:56.478801800Z",
     "start_time": "2024-04-01T12:50:56.433645100Z"
    }
   },
   "id": "47d4a39665ed1159"
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "df_test['Vorhergesagt'] = list1\n",
    "df_test.to_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_I7000_F6000_D3_500_I_F_PKL_Prediction.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T15:32:21.241594100Z",
     "start_time": "2024-03-29T15:32:21.192942700Z"
    }
   },
   "id": "73defb2e4e9a45da"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mae = history.history['loss']\n",
    "val_mae = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(mae) + 1)\n",
    "\n",
    "# MAE Diagramm\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, mae, 'r', label='Training MSE')\n",
    "plt.plot(epochs, val_mae, 'b', label='Validation MSE')\n",
    "plt.title('Training and Validation MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.savefig('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Bilder Diplomarbeit/MSE_NeuroNetz/MSE_NeuroNetz_D3_2')\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T14:43:33.453659500Z",
     "start_time": "2024-03-29T14:43:33.154886700Z"
    }
   },
   "id": "3688dd7102e95baf"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f6f672a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T10:01:02.439200700Z",
     "start_time": "2024-03-15T10:01:02.436683600Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "553df6fa",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# def build_model(learning_rate=0.001, activation='relu', regularization=0.0001, dropout_rate=0.0):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(200, activation=activation, input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(448, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(352, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(320, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(256, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(416, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(128, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(96, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))    \n",
    "# \n",
    "#     model.add(Dense(32, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mae'])\n",
    "#     return model\n",
    "# \n",
    "# # Verwenden Sie eine Funktion, um das Modell zu instanziieren, fÃ¼r scikit-learn Wrapper\n",
    "# model = KerasRegressor(model=build_model, verbose=2)\n",
    "# \n",
    "# # Anpassung der Parameter im param_grid\n",
    "# param_grid = {\n",
    "#     'model__learning_rate': [0.01, 0.001, 0.0001],\n",
    "#     'model__regularization': [0.001, 0.0001, 0.00001],\n",
    "#     'fit__batch_size': [25, 50, 75, 100],\n",
    "#     'fit__epochs': [50],\n",
    "#     'model__dropout_rate' : [0.0, 0.1, 0.2]\n",
    "# }\n",
    "# \n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=2)\n",
    "# # Hinweis: Stellen Sie sicher, dass Ihre Daten (X_train_scaled, y_train_scaled) korrekt definiert sind\n",
    "# grid_result = grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "# # Beste Parameter und Score ausgeben\n",
    "# print(\"Beste Parameter:\", grid_search.best_params_)\n",
    "# print(\"Beste Genauigkeit:\", grid_search.best_score_)\n",
    "# \n",
    "# with open(\"Gridsearch_D3.txt\", \"w\") as f:\n",
    "#     f.write(f\"Beste Parameter: {grid_search.best_params_}\\n\")\n",
    "#     f.write(f\"Beste Genauigkeit: {grid_search.best_score_}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:01:02.450167100Z",
     "start_time": "2024-03-15T10:01:02.439200700Z"
    }
   },
   "id": "578403f6e218787a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
