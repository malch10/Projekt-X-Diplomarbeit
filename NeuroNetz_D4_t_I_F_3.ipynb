{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94b0518e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T14:36:41.992636400Z",
     "start_time": "2024-03-28T14:36:31.279731500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense , Dropout\n",
    "from scikeras.wrappers import KerasRegressor \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ff61b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T14:36:42.049774600Z",
     "start_time": "2024-03-28T14:36:41.993636800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n0           0.0000      -0.00200        298   8000   5000      803.83\n1           0.0000      -0.00192        298   8000   5000      909.88\n2           0.0000      -0.00184        298   8000   5000     1020.90\n3           0.0000      -0.00176        298   8000   5000     1137.00\n4           0.0000      -0.00168        298   8000   5000     1252.30\n...            ...           ...        ...    ...    ...         ...\n1066        0.0024       0.00168        298   8000   5000     1154.30\n1067        0.0024       0.00176        298   8000   5000     1058.10\n1068        0.0024       0.00184        298   8000   5000      956.50\n1069        0.0024       0.00192        298   8000   5000      850.84\n1070        0.0024       0.00200        298   8000   5000      740.15\n\n[1071 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>298</td>\n      <td>8000</td>\n      <td>5000</td>\n      <td>803.83</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0000</td>\n      <td>-0.00192</td>\n      <td>298</td>\n      <td>8000</td>\n      <td>5000</td>\n      <td>909.88</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0000</td>\n      <td>-0.00184</td>\n      <td>298</td>\n      <td>8000</td>\n      <td>5000</td>\n      <td>1020.90</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0000</td>\n      <td>-0.00176</td>\n      <td>298</td>\n      <td>8000</td>\n      <td>5000</td>\n      <td>1137.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0000</td>\n      <td>-0.00168</td>\n      <td>298</td>\n      <td>8000</td>\n      <td>5000</td>\n      <td>1252.30</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1066</th>\n      <td>0.0024</td>\n      <td>0.00168</td>\n      <td>298</td>\n      <td>8000</td>\n      <td>5000</td>\n      <td>1154.30</td>\n    </tr>\n    <tr>\n      <th>1067</th>\n      <td>0.0024</td>\n      <td>0.00176</td>\n      <td>298</td>\n      <td>8000</td>\n      <td>5000</td>\n      <td>1058.10</td>\n    </tr>\n    <tr>\n      <th>1068</th>\n      <td>0.0024</td>\n      <td>0.00184</td>\n      <td>298</td>\n      <td>8000</td>\n      <td>5000</td>\n      <td>956.50</td>\n    </tr>\n    <tr>\n      <th>1069</th>\n      <td>0.0024</td>\n      <td>0.00192</td>\n      <td>298</td>\n      <td>8000</td>\n      <td>5000</td>\n      <td>850.84</td>\n    </tr>\n    <tr>\n      <th>1070</th>\n      <td>0.0024</td>\n      <td>0.00200</td>\n      <td>298</td>\n      <td>8000</td>\n      <td>5000</td>\n      <td>740.15</td>\n    </tr>\n  </tbody>\n</table>\n<p>1071 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/TPath_300_finish_data.pkl')\n",
    "data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_ALL_D4_t_I_F_PKL.pkl')\n",
    "data2 = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_D4_t_I8000_F5000_Vorhersage/TPathI8000F5000_298_finish_data_D4.pkl')\n",
    "data2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "966e3c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T14:36:42.167644300Z",
     "start_time": "2024-03-28T14:36:42.043775500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate      Zeitpunkt          Strom  \\\ncount  351288.000000  3.512880e+05  351288.000000  351288.000000   \nmean        0.001200  8.187503e-20     300.000000    7250.000000   \nstd         0.000727  1.177570e-03     118.321764     968.247215   \nmin         0.000000 -2.000000e-03     100.000000    6000.000000   \n25%         0.000600 -1.040000e-03     200.000000    6750.000000   \n50%         0.001200  4.529900e-18     300.000000    7000.000000   \n75%         0.001800  1.040000e-03     400.000000    8000.000000   \nmax         0.002400  2.000000e-03     500.000000    9000.000000   \n\n               Kraft     Temperatur  \ncount  351288.000000  351288.000000  \nmean     6125.000000    1223.062798  \nstd      1268.613251     481.699573  \nmin      5000.000000     359.280000  \n25%      5000.000000     815.900000  \n50%      6000.000000    1136.800000  \n75%      6250.000000    1617.400000  \nmax      9000.000000    2577.200000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>351288.000000</td>\n      <td>3.512880e+05</td>\n      <td>351288.000000</td>\n      <td>351288.000000</td>\n      <td>351288.000000</td>\n      <td>351288.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.001200</td>\n      <td>8.187503e-20</td>\n      <td>300.000000</td>\n      <td>7250.000000</td>\n      <td>6125.000000</td>\n      <td>1223.062798</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.000727</td>\n      <td>1.177570e-03</td>\n      <td>118.321764</td>\n      <td>968.247215</td>\n      <td>1268.613251</td>\n      <td>481.699573</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-2.000000e-03</td>\n      <td>100.000000</td>\n      <td>6000.000000</td>\n      <td>5000.000000</td>\n      <td>359.280000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000600</td>\n      <td>-1.040000e-03</td>\n      <td>200.000000</td>\n      <td>6750.000000</td>\n      <td>5000.000000</td>\n      <td>815.900000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.001200</td>\n      <td>4.529900e-18</td>\n      <td>300.000000</td>\n      <td>7000.000000</td>\n      <td>6000.000000</td>\n      <td>1136.800000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.001800</td>\n      <td>1.040000e-03</td>\n      <td>400.000000</td>\n      <td>8000.000000</td>\n      <td>6250.000000</td>\n      <td>1617.400000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.002400</td>\n      <td>2.000000e-03</td>\n      <td>500.000000</td>\n      <td>9000.000000</td>\n      <td>9000.000000</td>\n      <td>2577.200000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8783d1d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T14:36:42.168644700Z",
     "start_time": "2024-03-28T14:36:42.109615400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n0             0.0000      -0.00200        100   6000   5000      449.80\n1             0.0000      -0.00192        100   6000   5000      479.76\n2             0.0000      -0.00184        100   6000   5000      506.60\n3             0.0000      -0.00176        100   6000   5000      530.80\n4             0.0000      -0.00168        100   6000   5000      552.15\n...              ...           ...        ...    ...    ...         ...\n351283        0.0024       0.00168        500   9000   5000     1365.50\n351284        0.0024       0.00176        500   9000   5000     1247.20\n351285        0.0024       0.00184        500   9000   5000     1114.10\n351286        0.0024       0.00192        500   9000   5000      983.97\n351287        0.0024       0.00200        500   9000   5000      942.84\n\n[351288 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>449.80</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0000</td>\n      <td>-0.00192</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>479.76</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0000</td>\n      <td>-0.00184</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>506.60</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0000</td>\n      <td>-0.00176</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>530.80</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0000</td>\n      <td>-0.00168</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>552.15</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>351283</th>\n      <td>0.0024</td>\n      <td>0.00168</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1365.50</td>\n    </tr>\n    <tr>\n      <th>351284</th>\n      <td>0.0024</td>\n      <td>0.00176</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1247.20</td>\n    </tr>\n    <tr>\n      <th>351285</th>\n      <td>0.0024</td>\n      <td>0.00184</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1114.10</td>\n    </tr>\n    <tr>\n      <th>351286</th>\n      <td>0.0024</td>\n      <td>0.00192</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>983.97</td>\n    </tr>\n    <tr>\n      <th>351287</th>\n      <td>0.0024</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>942.84</td>\n    </tr>\n  </tbody>\n</table>\n<p>351288 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = data.sample(frac=1, random_state=42)  # Hier wird 42 als Random State verwendet, um die Ergebnisse reproduzierbar zu machen\n",
    "df_reset = data.reset_index(drop=True)\n",
    "df_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "      X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n0           0.0000      -0.00200        298   8000   5000      803.83\n1           0.0000      -0.00192        298   8000   5000      909.88\n2           0.0000      -0.00184        298   8000   5000     1020.90\n3           0.0000      -0.00176        298   8000   5000     1137.00\n4           0.0000      -0.00168        298   8000   5000     1252.30\n...            ...           ...        ...    ...    ...         ...\n1066        0.0024       0.00168        298   8000   5000     1154.30\n1067        0.0024       0.00176        298   8000   5000     1058.10\n1068        0.0024       0.00184        298   8000   5000      956.50\n1069        0.0024       0.00192        298   8000   5000      850.84\n1070        0.0024       0.00200        298   8000   5000      740.15\n\n[1071 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>298</td>\n      <td>8000</td>\n      <td>5000</td>\n      <td>803.83</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0000</td>\n      <td>-0.00192</td>\n      <td>298</td>\n      <td>8000</td>\n      <td>5000</td>\n      <td>909.88</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0000</td>\n      <td>-0.00184</td>\n      <td>298</td>\n      <td>8000</td>\n      <td>5000</td>\n      <td>1020.90</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0000</td>\n      <td>-0.00176</td>\n      <td>298</td>\n      <td>8000</td>\n      <td>5000</td>\n      <td>1137.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0000</td>\n      <td>-0.00168</td>\n      <td>298</td>\n      <td>8000</td>\n      <td>5000</td>\n      <td>1252.30</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1066</th>\n      <td>0.0024</td>\n      <td>0.00168</td>\n      <td>298</td>\n      <td>8000</td>\n      <td>5000</td>\n      <td>1154.30</td>\n    </tr>\n    <tr>\n      <th>1067</th>\n      <td>0.0024</td>\n      <td>0.00176</td>\n      <td>298</td>\n      <td>8000</td>\n      <td>5000</td>\n      <td>1058.10</td>\n    </tr>\n    <tr>\n      <th>1068</th>\n      <td>0.0024</td>\n      <td>0.00184</td>\n      <td>298</td>\n      <td>8000</td>\n      <td>5000</td>\n      <td>956.50</td>\n    </tr>\n    <tr>\n      <th>1069</th>\n      <td>0.0024</td>\n      <td>0.00192</td>\n      <td>298</td>\n      <td>8000</td>\n      <td>5000</td>\n      <td>850.84</td>\n    </tr>\n    <tr>\n      <th>1070</th>\n      <td>0.0024</td>\n      <td>0.00200</td>\n      <td>298</td>\n      <td>8000</td>\n      <td>5000</td>\n      <td>740.15</td>\n    </tr>\n  </tbody>\n</table>\n<p>1071 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reset2 = data2.reset_index(drop=True)\n",
    "df_reset2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T17:50:37.984336700Z",
     "start_time": "2024-03-27T17:50:37.847336900Z"
    }
   },
   "id": "c8a749ffc1e06f84"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a4e72a16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T17:50:38.523689800Z",
     "start_time": "2024-03-27T17:50:38.308404600Z"
    }
   },
   "outputs": [],
   "source": [
    "label = df_reset[\"Temperatur\"]\n",
    "# Korrektur: Verwenden Sie den Spaltennamen direkt, ohne Indexierung der columns-Eigenschaft\n",
    "df = df_reset.drop(\"Temperatur\", axis=1)\n",
    "X = df\n",
    "y = label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "label2 = df_reset2[\"Temperatur\"]\n",
    "# Korrektur: Verwenden Sie den Spaltennamen direkt, ohne Indexierung der columns-Eigenschaft\n",
    "df2 = df_reset2.drop(\"Temperatur\", axis=1)\n",
    "X2 = df2\n",
    "y2 = label2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T17:50:38.720689700Z",
     "start_time": "2024-03-27T17:50:38.503643100Z"
    }
   },
   "id": "7002e1eef1d029c7"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7fa289a50d87423"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e694a236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T17:50:39.316167100Z",
     "start_time": "2024-03-27T17:50:39.247001400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft\n0           0.0000      -0.00200        298   8000   5000\n1           0.0000      -0.00192        298   8000   5000\n2           0.0000      -0.00184        298   8000   5000\n3           0.0000      -0.00176        298   8000   5000\n4           0.0000      -0.00168        298   8000   5000\n...            ...           ...        ...    ...    ...\n1066        0.0024       0.00168        298   8000   5000\n1067        0.0024       0.00176        298   8000   5000\n1068        0.0024       0.00184        298   8000   5000\n1069        0.0024       0.00192        298   8000   5000\n1070        0.0024       0.00200        298   8000   5000\n\n[1071 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>298</td>\n      <td>8000</td>\n      <td>5000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0000</td>\n      <td>-0.00192</td>\n      <td>298</td>\n      <td>8000</td>\n      <td>5000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0000</td>\n      <td>-0.00184</td>\n      <td>298</td>\n      <td>8000</td>\n      <td>5000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0000</td>\n      <td>-0.00176</td>\n      <td>298</td>\n      <td>8000</td>\n      <td>5000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0000</td>\n      <td>-0.00168</td>\n      <td>298</td>\n      <td>8000</td>\n      <td>5000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1066</th>\n      <td>0.0024</td>\n      <td>0.00168</td>\n      <td>298</td>\n      <td>8000</td>\n      <td>5000</td>\n    </tr>\n    <tr>\n      <th>1067</th>\n      <td>0.0024</td>\n      <td>0.00176</td>\n      <td>298</td>\n      <td>8000</td>\n      <td>5000</td>\n    </tr>\n    <tr>\n      <th>1068</th>\n      <td>0.0024</td>\n      <td>0.00184</td>\n      <td>298</td>\n      <td>8000</td>\n      <td>5000</td>\n    </tr>\n    <tr>\n      <th>1069</th>\n      <td>0.0024</td>\n      <td>0.00192</td>\n      <td>298</td>\n      <td>8000</td>\n      <td>5000</td>\n    </tr>\n    <tr>\n      <th>1070</th>\n      <td>0.0024</td>\n      <td>0.00200</td>\n      <td>298</td>\n      <td>8000</td>\n      <td>5000</td>\n    </tr>\n  </tbody>\n</table>\n<p>1071 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3f3303b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T17:50:39.588590Z",
     "start_time": "2024-03-27T17:50:39.449183600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0        803.83\n1        909.88\n2       1020.90\n3       1137.00\n4       1252.30\n         ...   \n1066    1154.30\n1067    1058.10\n1068     956.50\n1069     850.84\n1070     740.15\nName: Temperatur, Length: 1071, dtype: float64"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e3ad8da0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T17:50:39.869763200Z",
     "start_time": "2024-03-27T17:50:39.635590700Z"
    }
   },
   "outputs": [],
   "source": [
    " # train_df enthält 80% der Daten, test_df enthält 20% der Daten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9c705edb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T17:50:39.946764200Z",
     "start_time": "2024-03-27T17:50:39.778907Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialisiere einen MinMaxScaler für die Features\n",
    "scaler_features = MinMaxScaler()\n",
    "# Skaliere X_train und X_test\n",
    "X_train_scaled = scaler_features.fit_transform(X_train)\n",
    "X_test_scaled = scaler_features.transform(X_test)  # Nutze unterschiedliche Skalierungsparameter\n",
    "X_test_scaled_2 = scaler_features.transform(X2)\n",
    "# Initialisiere einen SEPARATEN MinMaxScaler für das Ziel, wenn nötig\n",
    "scaler_target = MinMaxScaler()\n",
    "# Skaliere y_train und y_test. Beachte, dass y_train.reshape(-1, 1) verwendet wird, da MinMaxScaler \n",
    "# erwartet, dass die Eingaben als 2D-Arrays kommen, und Ziele normalerweise als 1D-Arrays vorliegen.\n",
    "y_train_scaled = scaler_target.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test_scaled = scaler_target.transform(y_test.values.reshape(-1, 1))\n",
    "y_test_scaled_2 = scaler_target.transform(y2.values.reshape(-1, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bbefe631e495b483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T17:50:41.731355300Z",
     "start_time": "2024-03-27T17:50:41.719505400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.        , 0.        , 0.495     , 0.66666667, 0.        ],\n       [0.        , 0.02      , 0.495     , 0.66666667, 0.        ],\n       [0.        , 0.04      , 0.495     , 0.66666667, 0.        ],\n       ...,\n       [1.        , 0.96      , 0.495     , 0.66666667, 0.        ],\n       [1.        , 0.98      , 0.495     , 0.66666667, 0.        ],\n       [1.        , 1.        , 0.495     , 0.66666667, 0.        ]])"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.20043554],\n       [0.24825061],\n       [0.29830652],\n       ...,\n       [0.26927031],\n       [0.22163108],\n       [0.17172396]])"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_scaled_2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T17:50:42.337878300Z",
     "start_time": "2024-03-27T17:50:42.325973500Z"
    }
   },
   "id": "ce04ce43aac2242f"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "1125/1125 [==============================] - 6s 4ms/step - loss: 0.0138 - mae: 0.0740 - val_loss: 0.0079 - val_mae: 0.0503\n",
      "Epoch 2/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0063 - mae: 0.0421 - val_loss: 0.0052 - val_mae: 0.0369\n",
      "Epoch 3/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0045 - mae: 0.0318 - val_loss: 0.0040 - val_mae: 0.0282\n",
      "Epoch 4/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0036 - mae: 0.0250 - val_loss: 0.0033 - val_mae: 0.0226\n",
      "Epoch 5/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0031 - mae: 0.0203 - val_loss: 0.0030 - val_mae: 0.0191\n",
      "Epoch 6/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0028 - mae: 0.0169 - val_loss: 0.0027 - val_mae: 0.0158\n",
      "Epoch 7/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0026 - mae: 0.0146 - val_loss: 0.0025 - val_mae: 0.0138\n",
      "Epoch 8/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0024 - mae: 0.0129 - val_loss: 0.0024 - val_mae: 0.0122\n",
      "Epoch 9/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0023 - mae: 0.0116 - val_loss: 0.0023 - val_mae: 0.0112\n",
      "Epoch 10/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0023 - mae: 0.0107 - val_loss: 0.0022 - val_mae: 0.0102\n",
      "Epoch 11/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0022 - mae: 0.0099 - val_loss: 0.0022 - val_mae: 0.0095\n",
      "Epoch 12/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0021 - mae: 0.0093 - val_loss: 0.0021 - val_mae: 0.0090\n",
      "Epoch 13/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0021 - mae: 0.0089 - val_loss: 0.0021 - val_mae: 0.0087\n",
      "Epoch 14/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0021 - mae: 0.0085 - val_loss: 0.0020 - val_mae: 0.0085\n",
      "Epoch 15/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0020 - mae: 0.0082 - val_loss: 0.0020 - val_mae: 0.0082\n",
      "Epoch 16/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0020 - mae: 0.0079 - val_loss: 0.0020 - val_mae: 0.0078\n",
      "Epoch 17/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0020 - mae: 0.0076 - val_loss: 0.0020 - val_mae: 0.0081\n",
      "Epoch 18/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0019 - mae: 0.0074 - val_loss: 0.0019 - val_mae: 0.0072\n",
      "Epoch 19/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0019 - mae: 0.0071 - val_loss: 0.0019 - val_mae: 0.0072\n",
      "Epoch 20/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0019 - mae: 0.0070 - val_loss: 0.0019 - val_mae: 0.0068\n",
      "Epoch 21/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0019 - mae: 0.0068 - val_loss: 0.0019 - val_mae: 0.0069\n",
      "Epoch 22/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0019 - mae: 0.0067 - val_loss: 0.0018 - val_mae: 0.0070\n",
      "Epoch 23/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0018 - mae: 0.0066 - val_loss: 0.0018 - val_mae: 0.0069\n",
      "Epoch 24/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0018 - mae: 0.0065 - val_loss: 0.0018 - val_mae: 0.0065\n",
      "Epoch 25/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0018 - mae: 0.0063 - val_loss: 0.0018 - val_mae: 0.0064\n",
      "Epoch 26/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0018 - mae: 0.0062 - val_loss: 0.0018 - val_mae: 0.0063\n",
      "Epoch 27/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0018 - mae: 0.0061 - val_loss: 0.0018 - val_mae: 0.0066\n",
      "Epoch 28/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0018 - mae: 0.0060 - val_loss: 0.0018 - val_mae: 0.0062\n",
      "Epoch 29/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0018 - mae: 0.0059 - val_loss: 0.0018 - val_mae: 0.0069\n",
      "Epoch 30/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0017 - mae: 0.0059 - val_loss: 0.0017 - val_mae: 0.0061\n",
      "Epoch 31/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0017 - mae: 0.0058 - val_loss: 0.0017 - val_mae: 0.0058\n",
      "Epoch 32/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0017 - mae: 0.0057 - val_loss: 0.0017 - val_mae: 0.0058\n",
      "Epoch 33/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0017 - mae: 0.0056 - val_loss: 0.0017 - val_mae: 0.0062\n",
      "Epoch 34/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0017 - mae: 0.0056 - val_loss: 0.0017 - val_mae: 0.0055\n",
      "Epoch 35/2000\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 0.0017 - mae: 0.0055 - val_loss: 0.0017 - val_mae: 0.0054\n",
      "Epoch 36/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0017 - mae: 0.0054 - val_loss: 0.0017 - val_mae: 0.0060\n",
      "Epoch 37/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0017 - mae: 0.0054 - val_loss: 0.0017 - val_mae: 0.0066\n",
      "Epoch 38/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0017 - mae: 0.0054 - val_loss: 0.0017 - val_mae: 0.0054\n",
      "Epoch 39/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0017 - mae: 0.0053 - val_loss: 0.0017 - val_mae: 0.0054\n",
      "Epoch 40/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0017 - mae: 0.0052 - val_loss: 0.0017 - val_mae: 0.0051\n",
      "Epoch 41/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0017 - mae: 0.0052 - val_loss: 0.0017 - val_mae: 0.0063\n",
      "Epoch 42/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0016 - mae: 0.0051 - val_loss: 0.0017 - val_mae: 0.0069\n",
      "Epoch 43/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0016 - mae: 0.0051 - val_loss: 0.0016 - val_mae: 0.0051\n",
      "Epoch 44/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0016 - mae: 0.0051 - val_loss: 0.0016 - val_mae: 0.0050\n",
      "Epoch 45/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0016 - mae: 0.0050 - val_loss: 0.0016 - val_mae: 0.0059\n",
      "Epoch 46/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0016 - mae: 0.0050 - val_loss: 0.0016 - val_mae: 0.0067\n",
      "Epoch 47/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0016 - mae: 0.0049 - val_loss: 0.0016 - val_mae: 0.0052\n",
      "Epoch 48/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0016 - mae: 0.0049 - val_loss: 0.0016 - val_mae: 0.0048\n",
      "Epoch 49/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0016 - mae: 0.0049 - val_loss: 0.0016 - val_mae: 0.0047\n",
      "Epoch 50/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0016 - mae: 0.0048 - val_loss: 0.0016 - val_mae: 0.0069\n",
      "Epoch 51/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0016 - mae: 0.0048 - val_loss: 0.0016 - val_mae: 0.0048\n",
      "Epoch 52/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0016 - mae: 0.0048 - val_loss: 0.0016 - val_mae: 0.0048\n",
      "Epoch 53/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0016 - mae: 0.0047 - val_loss: 0.0016 - val_mae: 0.0048\n",
      "Epoch 54/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0016 - mae: 0.0047 - val_loss: 0.0016 - val_mae: 0.0058\n",
      "Epoch 55/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0016 - mae: 0.0047 - val_loss: 0.0016 - val_mae: 0.0050\n",
      "Epoch 56/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0016 - mae: 0.0046 - val_loss: 0.0016 - val_mae: 0.0047\n",
      "Epoch 57/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0016 - mae: 0.0046 - val_loss: 0.0016 - val_mae: 0.0051\n",
      "Epoch 58/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0015 - mae: 0.0046 - val_loss: 0.0015 - val_mae: 0.0045\n",
      "Epoch 59/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0015 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0051\n",
      "Epoch 60/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0015 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0044\n",
      "Epoch 61/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0015 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0047\n",
      "Epoch 62/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0015 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0057\n",
      "Epoch 63/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0015 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0047\n",
      "Epoch 64/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 0.0015 - val_mae: 0.0046\n",
      "Epoch 65/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 0.0015 - val_mae: 0.0049\n",
      "Epoch 66/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 0.0015 - val_mae: 0.0051\n",
      "Epoch 67/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 0.0015 - val_mae: 0.0046\n",
      "Epoch 68/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 0.0015 - val_mae: 0.0056\n",
      "Epoch 69/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 0.0015 - val_mae: 0.0050\n",
      "Epoch 70/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0015 - mae: 0.0044 - val_loss: 0.0015 - val_mae: 0.0044\n",
      "Epoch 71/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0042\n",
      "Epoch 72/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0042\n",
      "Epoch 73/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0045\n",
      "Epoch 74/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0041\n",
      "Epoch 75/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0015 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0048\n",
      "Epoch 76/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0044\n",
      "Epoch 77/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0015 - mae: 0.0042 - val_loss: 0.0015 - val_mae: 0.0046\n",
      "Epoch 78/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0044\n",
      "Epoch 79/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0043\n",
      "Epoch 80/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0042\n",
      "Epoch 81/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0014 - mae: 0.0042 - val_loss: 0.0014 - val_mae: 0.0043\n",
      "Epoch 82/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0014 - mae: 0.0041 - val_loss: 0.0015 - val_mae: 0.0058\n",
      "Epoch 83/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0014 - mae: 0.0041 - val_loss: 0.0014 - val_mae: 0.0047\n",
      "Epoch 84/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0014 - mae: 0.0041 - val_loss: 0.0014 - val_mae: 0.0043\n",
      "Epoch 85/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0014 - mae: 0.0041 - val_loss: 0.0014 - val_mae: 0.0046\n",
      "Epoch 86/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0014 - mae: 0.0041 - val_loss: 0.0014 - val_mae: 0.0040\n",
      "Epoch 87/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0014 - mae: 0.0041 - val_loss: 0.0014 - val_mae: 0.0049\n",
      "Epoch 88/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0014 - mae: 0.0041 - val_loss: 0.0014 - val_mae: 0.0046\n",
      "Epoch 89/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0014 - mae: 0.0040 - val_loss: 0.0014 - val_mae: 0.0043\n",
      "Epoch 90/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0014 - mae: 0.0040 - val_loss: 0.0014 - val_mae: 0.0048\n",
      "Epoch 91/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0014 - mae: 0.0040 - val_loss: 0.0014 - val_mae: 0.0041\n",
      "Epoch 92/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0014 - mae: 0.0040 - val_loss: 0.0014 - val_mae: 0.0038\n",
      "Epoch 93/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0014 - mae: 0.0040 - val_loss: 0.0014 - val_mae: 0.0047\n",
      "Epoch 94/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0014 - mae: 0.0040 - val_loss: 0.0014 - val_mae: 0.0041\n",
      "Epoch 95/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0014 - mae: 0.0040 - val_loss: 0.0014 - val_mae: 0.0040\n",
      "Epoch 96/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0014 - mae: 0.0039 - val_loss: 0.0014 - val_mae: 0.0039\n",
      "Epoch 97/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0014 - mae: 0.0039 - val_loss: 0.0014 - val_mae: 0.0040\n",
      "Epoch 98/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0014 - mae: 0.0039 - val_loss: 0.0014 - val_mae: 0.0054\n",
      "Epoch 99/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0014 - mae: 0.0039 - val_loss: 0.0014 - val_mae: 0.0039\n",
      "Epoch 100/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0014 - mae: 0.0039 - val_loss: 0.0014 - val_mae: 0.0040\n",
      "Epoch 101/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0014 - mae: 0.0039 - val_loss: 0.0014 - val_mae: 0.0038\n",
      "Epoch 102/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0014 - mae: 0.0039 - val_loss: 0.0014 - val_mae: 0.0061\n",
      "Epoch 103/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0013 - mae: 0.0039 - val_loss: 0.0013 - val_mae: 0.0039\n",
      "Epoch 104/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0013 - mae: 0.0039 - val_loss: 0.0013 - val_mae: 0.0040\n",
      "Epoch 105/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0013 - mae: 0.0038 - val_loss: 0.0013 - val_mae: 0.0037\n",
      "Epoch 106/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0013 - mae: 0.0038 - val_loss: 0.0013 - val_mae: 0.0039\n",
      "Epoch 107/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0013 - mae: 0.0038 - val_loss: 0.0013 - val_mae: 0.0044\n",
      "Epoch 108/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0013 - mae: 0.0038 - val_loss: 0.0013 - val_mae: 0.0040\n",
      "Epoch 109/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0013 - mae: 0.0038 - val_loss: 0.0013 - val_mae: 0.0037\n",
      "Epoch 110/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0013 - mae: 0.0038 - val_loss: 0.0013 - val_mae: 0.0038\n",
      "Epoch 111/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0013 - mae: 0.0038 - val_loss: 0.0013 - val_mae: 0.0038\n",
      "Epoch 112/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0013 - mae: 0.0038 - val_loss: 0.0013 - val_mae: 0.0039\n",
      "Epoch 113/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0013 - mae: 0.0038 - val_loss: 0.0013 - val_mae: 0.0038\n",
      "Epoch 114/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0013 - mae: 0.0038 - val_loss: 0.0013 - val_mae: 0.0044\n",
      "Epoch 115/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0013 - mae: 0.0037 - val_loss: 0.0013 - val_mae: 0.0038\n",
      "Epoch 116/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0013 - mae: 0.0038 - val_loss: 0.0013 - val_mae: 0.0040\n",
      "Epoch 117/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0013 - mae: 0.0037 - val_loss: 0.0013 - val_mae: 0.0037\n",
      "Epoch 118/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0013 - mae: 0.0037 - val_loss: 0.0013 - val_mae: 0.0038\n",
      "Epoch 119/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0013 - mae: 0.0037 - val_loss: 0.0013 - val_mae: 0.0040\n",
      "Epoch 120/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0013 - mae: 0.0037 - val_loss: 0.0013 - val_mae: 0.0036\n",
      "Epoch 121/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0013 - mae: 0.0037 - val_loss: 0.0013 - val_mae: 0.0037\n",
      "Epoch 122/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0013 - mae: 0.0037 - val_loss: 0.0013 - val_mae: 0.0038\n",
      "Epoch 123/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0013 - mae: 0.0037 - val_loss: 0.0013 - val_mae: 0.0037\n",
      "Epoch 124/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0013 - mae: 0.0037 - val_loss: 0.0013 - val_mae: 0.0038\n",
      "Epoch 125/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0013 - mae: 0.0036 - val_loss: 0.0013 - val_mae: 0.0038\n",
      "Epoch 126/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0013 - mae: 0.0037 - val_loss: 0.0013 - val_mae: 0.0036\n",
      "Epoch 127/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0013 - mae: 0.0037 - val_loss: 0.0013 - val_mae: 0.0035\n",
      "Epoch 128/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0013 - mae: 0.0036 - val_loss: 0.0013 - val_mae: 0.0040\n",
      "Epoch 129/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0013 - mae: 0.0036 - val_loss: 0.0013 - val_mae: 0.0042\n",
      "Epoch 130/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0013 - mae: 0.0036 - val_loss: 0.0013 - val_mae: 0.0037\n",
      "Epoch 131/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0013 - mae: 0.0036 - val_loss: 0.0013 - val_mae: 0.0036\n",
      "Epoch 132/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0013 - mae: 0.0036 - val_loss: 0.0013 - val_mae: 0.0039\n",
      "Epoch 133/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0036 - val_loss: 0.0012 - val_mae: 0.0036\n",
      "Epoch 134/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0036 - val_loss: 0.0012 - val_mae: 0.0039\n",
      "Epoch 135/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0036 - val_loss: 0.0013 - val_mae: 0.0044\n",
      "Epoch 136/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0036 - val_loss: 0.0012 - val_mae: 0.0038\n",
      "Epoch 137/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0036 - val_loss: 0.0012 - val_mae: 0.0034\n",
      "Epoch 138/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0036 - val_loss: 0.0012 - val_mae: 0.0037\n",
      "Epoch 139/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0035 - val_loss: 0.0012 - val_mae: 0.0038\n",
      "Epoch 140/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0035 - val_loss: 0.0012 - val_mae: 0.0037\n",
      "Epoch 141/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0036 - val_loss: 0.0012 - val_mae: 0.0035\n",
      "Epoch 142/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0035 - val_loss: 0.0012 - val_mae: 0.0037\n",
      "Epoch 143/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0036 - val_loss: 0.0012 - val_mae: 0.0039\n",
      "Epoch 144/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0035 - val_loss: 0.0012 - val_mae: 0.0045\n",
      "Epoch 145/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0035 - val_loss: 0.0012 - val_mae: 0.0036\n",
      "Epoch 146/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0035 - val_loss: 0.0012 - val_mae: 0.0035\n",
      "Epoch 147/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0035 - val_loss: 0.0012 - val_mae: 0.0036\n",
      "Epoch 148/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0035 - val_loss: 0.0012 - val_mae: 0.0037\n",
      "Epoch 149/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0035 - val_loss: 0.0012 - val_mae: 0.0057\n",
      "Epoch 150/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0035 - val_loss: 0.0012 - val_mae: 0.0039\n",
      "Epoch 151/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0035 - val_loss: 0.0012 - val_mae: 0.0034\n",
      "Epoch 152/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0035 - val_loss: 0.0012 - val_mae: 0.0037\n",
      "Epoch 153/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0035 - val_loss: 0.0012 - val_mae: 0.0038\n",
      "Epoch 154/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0012 - mae: 0.0035 - val_loss: 0.0012 - val_mae: 0.0034\n",
      "Epoch 155/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0035 - val_loss: 0.0012 - val_mae: 0.0037\n",
      "Epoch 156/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0034 - val_loss: 0.0012 - val_mae: 0.0036\n",
      "Epoch 157/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0012 - mae: 0.0035 - val_loss: 0.0012 - val_mae: 0.0036\n",
      "Epoch 158/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0034 - val_loss: 0.0012 - val_mae: 0.0033\n",
      "Epoch 159/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0035 - val_loss: 0.0012 - val_mae: 0.0034\n",
      "Epoch 160/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0034 - val_loss: 0.0012 - val_mae: 0.0040\n",
      "Epoch 161/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0012 - mae: 0.0034 - val_loss: 0.0012 - val_mae: 0.0033\n",
      "Epoch 162/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0034 - val_loss: 0.0012 - val_mae: 0.0033\n",
      "Epoch 163/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0034 - val_loss: 0.0012 - val_mae: 0.0033\n",
      "Epoch 164/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0034 - val_loss: 0.0012 - val_mae: 0.0038\n",
      "Epoch 165/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0034 - val_loss: 0.0012 - val_mae: 0.0032\n",
      "Epoch 166/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0012 - mae: 0.0034 - val_loss: 0.0012 - val_mae: 0.0035\n",
      "Epoch 167/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0012 - mae: 0.0034 - val_loss: 0.0012 - val_mae: 0.0040\n",
      "Epoch 168/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0012 - mae: 0.0034 - val_loss: 0.0012 - val_mae: 0.0041\n",
      "Epoch 169/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0011 - mae: 0.0034 - val_loss: 0.0012 - val_mae: 0.0039\n",
      "Epoch 170/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0011 - mae: 0.0034 - val_loss: 0.0011 - val_mae: 0.0036\n",
      "Epoch 171/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0011 - mae: 0.0033 - val_loss: 0.0011 - val_mae: 0.0033\n",
      "Epoch 172/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0011 - mae: 0.0034 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 173/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0011 - mae: 0.0033 - val_loss: 0.0011 - val_mae: 0.0037\n",
      "Epoch 174/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0011 - mae: 0.0033 - val_loss: 0.0011 - val_mae: 0.0036\n",
      "Epoch 175/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0011 - mae: 0.0034 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 176/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0011 - mae: 0.0033 - val_loss: 0.0011 - val_mae: 0.0032\n",
      "Epoch 177/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0011 - mae: 0.0033 - val_loss: 0.0011 - val_mae: 0.0036\n",
      "Epoch 178/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0011 - mae: 0.0033 - val_loss: 0.0011 - val_mae: 0.0036\n",
      "Epoch 179/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0011 - mae: 0.0033 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 180/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0011 - mae: 0.0033 - val_loss: 0.0011 - val_mae: 0.0034\n",
      "Epoch 181/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0011 - mae: 0.0034 - val_loss: 0.0011 - val_mae: 0.0037\n",
      "Epoch 182/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0011 - mae: 0.0033 - val_loss: 0.0011 - val_mae: 0.0050\n",
      "Epoch 183/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0011 - mae: 0.0033 - val_loss: 0.0011 - val_mae: 0.0036\n",
      "Epoch 184/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0011 - mae: 0.0033 - val_loss: 0.0011 - val_mae: 0.0035\n",
      "Epoch 185/2000\n",
      "1125/1125 [==============================] - 5s 4ms/step - loss: 0.0011 - mae: 0.0033 - val_loss: 0.0011 - val_mae: 0.0032\n",
      "Epoch 186/2000\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 0.0011 - mae: 0.0033 - val_loss: 0.0011 - val_mae: 0.0032\n",
      "Epoch 187/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0011 - mae: 0.0033 - val_loss: 0.0011 - val_mae: 0.0034\n",
      "Epoch 188/2000\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 0.0011 - mae: 0.0033 - val_loss: 0.0011 - val_mae: 0.0033\n",
      "Epoch 189/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0011 - mae: 0.0033 - val_loss: 0.0011 - val_mae: 0.0034\n",
      "Epoch 190/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0011 - mae: 0.0033 - val_loss: 0.0011 - val_mae: 0.0034\n",
      "Epoch 191/2000\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 0.0011 - mae: 0.0033 - val_loss: 0.0011 - val_mae: 0.0032\n",
      "Epoch 192/2000\n",
      "1125/1125 [==============================] - 4s 3ms/step - loss: 0.0011 - mae: 0.0032 - val_loss: 0.0011 - val_mae: 0.0032\n",
      "Epoch 193/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0011 - mae: 0.0033 - val_loss: 0.0011 - val_mae: 0.0032\n",
      "Epoch 194/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0011 - mae: 0.0032 - val_loss: 0.0011 - val_mae: 0.0038\n",
      "Epoch 195/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0011 - mae: 0.0033 - val_loss: 0.0011 - val_mae: 0.0033\n",
      "Epoch 196/2000\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 0.0011 - mae: 0.0032 - val_loss: 0.0011 - val_mae: 0.0032\n",
      "Epoch 197/2000\n",
      " 283/1125 [======>.......................] - ETA: 2s - loss: 0.0011 - mae: 0.0032"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_20632\\4275732300.py\u001B[0m in \u001B[0;36m?\u001B[1;34m()\u001B[0m\n\u001B[0;32m     35\u001B[0m \u001B[0mbatch_size\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m200\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[0mepochs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m2000\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     37\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[1;31m# Modell trainieren (Annahme: X_train, y_train, X_val, y_val sind vordefiniert)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 39\u001B[1;33m history = model.fit(X_train_scaled, y_train_scaled,\n\u001B[0m\u001B[0;32m     40\u001B[0m                     \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     41\u001B[0m                     \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mepochs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     42\u001B[0m                     \u001B[0mvalidation_split\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.2\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     68\u001B[0m             \u001B[1;31m# To get the full stack trace, call:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m             \u001B[1;31m# `tf.debugging.disable_traceback_filtering()`\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     70\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     71\u001B[0m         \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 72\u001B[1;33m             \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1794\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0mepoch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0miterator\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0menumerate_epochs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1795\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreset_metrics\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1796\u001B[0m                 \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_epoch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mepoch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1797\u001B[0m                 \u001B[1;32mwith\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcatch_stop_iteration\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1798\u001B[1;33m                     \u001B[1;32mfor\u001B[0m \u001B[0mstep\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msteps\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1799\u001B[0m                         with tf.profiler.experimental.Trace(\n\u001B[0;32m   1800\u001B[0m                             \u001B[1;34m\"train\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1801\u001B[0m                             \u001B[0mepoch_num\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mepoch\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1407\u001B[0m             \u001B[1;32mor\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_current_step\u001B[0m \u001B[1;33m<\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_inferred_steps\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1408\u001B[0m         ):\n\u001B[0;32m   1409\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_insufficient_data\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# Set by `catch_stop_iteration`.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1410\u001B[0m                 \u001B[1;32mbreak\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1411\u001B[1;33m             \u001B[0moriginal_spe\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_steps_per_execution\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1412\u001B[0m             can_run_full_execution = (\n\u001B[0;32m   1413\u001B[0m                 \u001B[0moriginal_spe\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1414\u001B[0m                 \u001B[1;32mor\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_inferred_steps\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    687\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    688\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexecuting_eagerly\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 689\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_value\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    690\u001B[0m     raise NotImplementedError(\n\u001B[0;32m    691\u001B[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    838\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname_scope\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Read\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    839\u001B[0m       \u001B[0mvalue\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_read_variable_op\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    840\u001B[0m     \u001B[1;31m# Return an identity so it can get placed on whatever device the context\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    841\u001B[0m     \u001B[1;31m# specifies instead of the device where the variable is.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 842\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0marray_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0midentity\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     86\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     87\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_auto_dtype_conversion_enabled\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 88\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     89\u001B[0m     \u001B[0mbound_arguments\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msignature\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbind\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     90\u001B[0m     \u001B[0mbound_arguments\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_defaults\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     91\u001B[0m     \u001B[0mbound_kwargs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbound_arguments\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marguments\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    153\u001B[0m       \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    154\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 155\u001B[1;33m       \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1257\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1258\u001B[0m       \u001B[1;31m# Fallback dispatch system (dispatch v1):\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1259\u001B[0m       \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1260\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mdispatch_target\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1261\u001B[1;33m       \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1262\u001B[0m         \u001B[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1263\u001B[0m         \u001B[1;31m# TypeError, when given unexpected types.  So we need to catch both.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1264\u001B[0m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdispatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mop_dispatch_handler\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(input, name)\u001B[0m\n\u001B[0;32m    308\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexecuting_eagerly\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"graph\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    309\u001B[0m     \u001B[1;31m# Make sure we get an input with handle data attached from resource\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    310\u001B[0m     \u001B[1;31m# variables. Variables have correct handle data when graph building.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    311\u001B[0m     \u001B[0minput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconvert_to_tensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 312\u001B[1;33m   \u001B[0mret\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgen_array_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0midentity\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    313\u001B[0m   \u001B[1;31m# Propagate handle data for happier shape inference for resource variables.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    314\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"_handle_data\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    315\u001B[0m     \u001B[0mret\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_handle_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_handle_data\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(input, name)\u001B[0m\n\u001B[0;32m   4185\u001B[0m         _ctx, \"Identity\", name, input)\n\u001B[0;32m   4186\u001B[0m       \u001B[1;32mreturn\u001B[0m \u001B[0m_result\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4187\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4188\u001B[0m       \u001B[0m_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mraise_from_not_ok_status\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 4189\u001B[1;33m     \u001B[1;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_FallbackException\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   4190\u001B[0m       \u001B[1;32mpass\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4191\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4192\u001B[0m       return identity_eager_fallback(\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Netzwerkarchitektur\n",
    "model = Sequential([\n",
    "\n",
    "    Dense(200, activation='relu', input_shape=(5,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.000001)),\n",
    "    \n",
    "    Dense(232, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.000001)),\n",
    "    \n",
    "    Dense(88, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.000001)),\n",
    "    \n",
    "    Dense(216, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.000001)),\n",
    "    \n",
    "    Dense(280, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.000001)),\n",
    "    \n",
    "    Dense(88, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.000001)),\n",
    "    \n",
    "    Dense(88, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.000001)),\n",
    "    \n",
    "    Dense(88, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.000001)),\n",
    "    \n",
    "    Dense(1 , activation = 'linear')\n",
    "])\n",
    "\n",
    "# Optimierer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001) #0.00001\n",
    "\n",
    "# Modell kompilieren (Verwendung von mean_squared_error als Verlustfunktion für Regression)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])  # Metriken für Regression: Mean Absolute Error und Mean Squared Error\n",
    "\n",
    "# Early Stopping Callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "# Trainingsparameter\n",
    "batch_size = 200\n",
    "epochs = 2000\n",
    "\n",
    "# Modell trainieren (Annahme: X_train, y_train, X_val, y_val sind vordefiniert)\n",
    "history = model.fit(X_train_scaled, y_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "model.save('D4_t_I_F_3.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T18:05:34.682676800Z",
     "start_time": "2024-03-27T17:50:43.046394600Z"
    }
   },
   "id": "8b52e1a9a6ff3aeb"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "Training für Fold 1...\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "1757/1757 [==============================] - 3s 1ms/step - loss: 0.1269 - mae: 0.1721 - val_loss: 0.0220 - val_mae: 0.0781\n",
      "Epoch 2/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0202 - mae: 0.0701 - val_loss: 0.0183 - val_mae: 0.0633\n",
      "Epoch 3/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0173 - mae: 0.0597 - val_loss: 0.0162 - val_mae: 0.0569\n",
      "Epoch 4/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0155 - mae: 0.0533 - val_loss: 0.0149 - val_mae: 0.0516\n",
      "Epoch 5/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0144 - mae: 0.0490 - val_loss: 0.0139 - val_mae: 0.0480\n",
      "Epoch 6/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0135 - mae: 0.0452 - val_loss: 0.0131 - val_mae: 0.0421\n",
      "Epoch 7/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0128 - mae: 0.0417 - val_loss: 0.0125 - val_mae: 0.0415\n",
      "Epoch 8/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0122 - mae: 0.0387 - val_loss: 0.0118 - val_mae: 0.0365\n",
      "Epoch 9/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0117 - mae: 0.0359 - val_loss: 0.0115 - val_mae: 0.0376\n",
      "Epoch 10/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0112 - mae: 0.0336 - val_loss: 0.0111 - val_mae: 0.0318\n",
      "Epoch 11/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0108 - mae: 0.0312 - val_loss: 0.0108 - val_mae: 0.0322\n",
      "Epoch 12/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0105 - mae: 0.0290 - val_loss: 0.0104 - val_mae: 0.0293\n",
      "Epoch 13/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0102 - mae: 0.0269 - val_loss: 0.0101 - val_mae: 0.0272\n",
      "Epoch 14/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0099 - mae: 0.0244 - val_loss: 0.0098 - val_mae: 0.0231\n",
      "Epoch 15/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0096 - mae: 0.0222 - val_loss: 0.0095 - val_mae: 0.0209\n",
      "Epoch 16/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0094 - mae: 0.0201 - val_loss: 0.0093 - val_mae: 0.0200\n",
      "Epoch 17/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0092 - mae: 0.0183 - val_loss: 0.0091 - val_mae: 0.0164\n",
      "Epoch 18/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0090 - mae: 0.0164 - val_loss: 0.0089 - val_mae: 0.0152\n",
      "Epoch 19/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0089 - mae: 0.0149 - val_loss: 0.0088 - val_mae: 0.0134\n",
      "Epoch 20/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0088 - mae: 0.0136 - val_loss: 0.0087 - val_mae: 0.0122\n",
      "Epoch 21/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0086 - mae: 0.0124 - val_loss: 0.0086 - val_mae: 0.0118\n",
      "Epoch 22/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0085 - mae: 0.0115 - val_loss: 0.0086 - val_mae: 0.0134\n",
      "Epoch 23/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0084 - mae: 0.0108 - val_loss: 0.0084 - val_mae: 0.0103\n",
      "Epoch 24/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0083 - mae: 0.0102 - val_loss: 0.0083 - val_mae: 0.0090\n",
      "Epoch 25/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0083 - mae: 0.0096 - val_loss: 0.0082 - val_mae: 0.0092\n",
      "Epoch 26/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0082 - mae: 0.0091 - val_loss: 0.0081 - val_mae: 0.0082\n",
      "Epoch 27/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0081 - mae: 0.0088 - val_loss: 0.0080 - val_mae: 0.0079\n",
      "Epoch 28/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0080 - mae: 0.0084 - val_loss: 0.0080 - val_mae: 0.0075\n",
      "Epoch 29/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 30/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0079 - mae: 0.0077 - val_loss: 0.0078 - val_mae: 0.0071\n",
      "Epoch 31/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0078 - mae: 0.0073 - val_loss: 0.0078 - val_mae: 0.0076\n",
      "Epoch 32/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0077 - mae: 0.0073 - val_loss: 0.0077 - val_mae: 0.0084\n",
      "Epoch 33/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0077 - mae: 0.0070 - val_loss: 0.0077 - val_mae: 0.0091\n",
      "Epoch 34/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0076 - mae: 0.0069 - val_loss: 0.0076 - val_mae: 0.0067\n",
      "Epoch 35/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0076 - mae: 0.0068 - val_loss: 0.0075 - val_mae: 0.0074\n",
      "Epoch 36/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0075 - mae: 0.0065 - val_loss: 0.0075 - val_mae: 0.0070\n",
      "Epoch 37/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0074 - mae: 0.0065 - val_loss: 0.0074 - val_mae: 0.0060\n",
      "Epoch 38/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0074 - mae: 0.0064 - val_loss: 0.0074 - val_mae: 0.0063\n",
      "Epoch 39/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0073 - mae: 0.0063 - val_loss: 0.0073 - val_mae: 0.0057\n",
      "Epoch 40/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0073 - mae: 0.0062 - val_loss: 0.0072 - val_mae: 0.0061\n",
      "Epoch 41/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0072 - mae: 0.0062 - val_loss: 0.0072 - val_mae: 0.0055\n",
      "Epoch 42/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0072 - mae: 0.0063 - val_loss: 0.0071 - val_mae: 0.0058\n",
      "Epoch 43/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0071 - mae: 0.0060 - val_loss: 0.0071 - val_mae: 0.0069\n",
      "Epoch 44/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0071 - mae: 0.0060 - val_loss: 0.0071 - val_mae: 0.0069\n",
      "Epoch 45/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0070 - mae: 0.0059 - val_loss: 0.0070 - val_mae: 0.0055\n",
      "Epoch 46/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0070 - mae: 0.0058 - val_loss: 0.0069 - val_mae: 0.0058\n",
      "Epoch 47/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0069 - mae: 0.0058 - val_loss: 0.0069 - val_mae: 0.0061\n",
      "Epoch 48/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0069 - mae: 0.0057 - val_loss: 0.0069 - val_mae: 0.0057\n",
      "Epoch 49/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0068 - mae: 0.0057 - val_loss: 0.0068 - val_mae: 0.0054\n",
      "Epoch 50/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0068 - mae: 0.0056 - val_loss: 0.0068 - val_mae: 0.0078\n",
      "Epoch 51/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0067 - mae: 0.0056 - val_loss: 0.0067 - val_mae: 0.0053\n",
      "Epoch 52/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0067 - mae: 0.0056 - val_loss: 0.0067 - val_mae: 0.0050\n",
      "Epoch 53/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0066 - mae: 0.0055 - val_loss: 0.0066 - val_mae: 0.0049\n",
      "Epoch 54/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0066 - mae: 0.0056 - val_loss: 0.0066 - val_mae: 0.0060\n",
      "Epoch 55/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0066 - mae: 0.0054 - val_loss: 0.0066 - val_mae: 0.0068\n",
      "Epoch 56/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0065 - mae: 0.0054 - val_loss: 0.0065 - val_mae: 0.0049\n",
      "Epoch 57/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0065 - mae: 0.0055 - val_loss: 0.0065 - val_mae: 0.0050\n",
      "Epoch 58/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0064 - mae: 0.0053 - val_loss: 0.0064 - val_mae: 0.0058\n",
      "Epoch 59/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0064 - mae: 0.0054 - val_loss: 0.0064 - val_mae: 0.0053\n",
      "Epoch 60/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0064 - mae: 0.0053 - val_loss: 0.0063 - val_mae: 0.0055\n",
      "Epoch 61/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0063 - mae: 0.0053 - val_loss: 0.0063 - val_mae: 0.0051\n",
      "Epoch 62/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0063 - mae: 0.0052 - val_loss: 0.0063 - val_mae: 0.0063\n",
      "Epoch 63/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0062 - mae: 0.0052 - val_loss: 0.0062 - val_mae: 0.0052\n",
      "Epoch 64/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0062 - mae: 0.0052 - val_loss: 0.0062 - val_mae: 0.0053\n",
      "Epoch 65/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0062 - mae: 0.0052 - val_loss: 0.0062 - val_mae: 0.0047\n",
      "Epoch 66/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0061 - mae: 0.0052 - val_loss: 0.0061 - val_mae: 0.0053\n",
      "Epoch 67/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0061 - mae: 0.0050 - val_loss: 0.0061 - val_mae: 0.0045\n",
      "Epoch 68/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0061 - mae: 0.0051 - val_loss: 0.0061 - val_mae: 0.0058\n",
      "Epoch 69/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0060 - mae: 0.0051 - val_loss: 0.0060 - val_mae: 0.0045\n",
      "Epoch 70/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0060 - mae: 0.0051 - val_loss: 0.0060 - val_mae: 0.0048\n",
      "Epoch 71/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0060 - mae: 0.0050 - val_loss: 0.0059 - val_mae: 0.0044\n",
      "Epoch 72/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0059 - mae: 0.0050 - val_loss: 0.0059 - val_mae: 0.0049\n",
      "Epoch 73/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0059 - mae: 0.0050 - val_loss: 0.0059 - val_mae: 0.0046\n",
      "Epoch 74/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0059 - mae: 0.0050 - val_loss: 0.0059 - val_mae: 0.0047\n",
      "Epoch 75/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0058 - mae: 0.0049 - val_loss: 0.0058 - val_mae: 0.0044\n",
      "Epoch 76/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0058 - mae: 0.0049 - val_loss: 0.0058 - val_mae: 0.0044\n",
      "Epoch 77/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0058 - mae: 0.0049 - val_loss: 0.0058 - val_mae: 0.0044\n",
      "Epoch 78/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0057 - mae: 0.0049 - val_loss: 0.0057 - val_mae: 0.0045\n",
      "Epoch 79/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0057 - mae: 0.0049 - val_loss: 0.0057 - val_mae: 0.0045\n",
      "Epoch 80/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0057 - mae: 0.0048 - val_loss: 0.0057 - val_mae: 0.0062\n",
      "Epoch 81/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0057 - mae: 0.0049 - val_loss: 0.0056 - val_mae: 0.0041\n",
      "Epoch 82/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0056 - mae: 0.0048 - val_loss: 0.0056 - val_mae: 0.0043\n",
      "Epoch 83/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0056 - mae: 0.0047 - val_loss: 0.0056 - val_mae: 0.0044\n",
      "Epoch 84/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0056 - mae: 0.0047 - val_loss: 0.0055 - val_mae: 0.0042\n",
      "Epoch 85/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0055 - mae: 0.0047 - val_loss: 0.0055 - val_mae: 0.0042\n",
      "Epoch 86/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0055 - mae: 0.0047 - val_loss: 0.0055 - val_mae: 0.0044\n",
      "Epoch 87/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0055 - mae: 0.0047 - val_loss: 0.0055 - val_mae: 0.0059\n",
      "Epoch 88/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0054 - mae: 0.0046 - val_loss: 0.0054 - val_mae: 0.0043\n",
      "Epoch 89/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0054 - mae: 0.0047 - val_loss: 0.0054 - val_mae: 0.0046\n",
      "Epoch 90/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0054 - mae: 0.0047 - val_loss: 0.0054 - val_mae: 0.0040\n",
      "Epoch 91/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0054 - mae: 0.0046 - val_loss: 0.0053 - val_mae: 0.0042\n",
      "Epoch 92/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0053 - mae: 0.0045 - val_loss: 0.0053 - val_mae: 0.0043\n",
      "Epoch 93/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0053 - mae: 0.0046 - val_loss: 0.0053 - val_mae: 0.0042\n",
      "Epoch 94/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0053 - mae: 0.0045 - val_loss: 0.0053 - val_mae: 0.0044\n",
      "Epoch 95/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0053 - mae: 0.0046 - val_loss: 0.0052 - val_mae: 0.0043\n",
      "Epoch 96/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0052 - mae: 0.0045 - val_loss: 0.0052 - val_mae: 0.0048\n",
      "Epoch 97/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0052 - mae: 0.0046 - val_loss: 0.0052 - val_mae: 0.0039\n",
      "Epoch 98/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0052 - mae: 0.0044 - val_loss: 0.0052 - val_mae: 0.0047\n",
      "Epoch 99/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0051 - mae: 0.0045 - val_loss: 0.0051 - val_mae: 0.0040\n",
      "Epoch 100/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0051 - mae: 0.0044 - val_loss: 0.0051 - val_mae: 0.0041\n",
      "Epoch 101/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0051 - mae: 0.0045 - val_loss: 0.0051 - val_mae: 0.0046\n",
      "Epoch 102/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0051 - mae: 0.0044 - val_loss: 0.0051 - val_mae: 0.0043\n",
      "Epoch 103/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0050 - mae: 0.0045 - val_loss: 0.0050 - val_mae: 0.0041\n",
      "Epoch 104/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0050 - mae: 0.0044 - val_loss: 0.0050 - val_mae: 0.0045\n",
      "Epoch 105/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0050 - mae: 0.0044 - val_loss: 0.0050 - val_mae: 0.0041\n",
      "Epoch 106/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0050 - mae: 0.0044 - val_loss: 0.0050 - val_mae: 0.0039\n",
      "Epoch 107/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0049 - mae: 0.0044 - val_loss: 0.0049 - val_mae: 0.0043\n",
      "Epoch 108/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0049 - mae: 0.0044 - val_loss: 0.0049 - val_mae: 0.0050\n",
      "Epoch 109/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0049 - mae: 0.0044 - val_loss: 0.0049 - val_mae: 0.0045\n",
      "Epoch 110/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0049 - mae: 0.0044 - val_loss: 0.0049 - val_mae: 0.0054\n",
      "Epoch 111/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0048 - mae: 0.0043 - val_loss: 0.0048 - val_mae: 0.0041\n",
      "Epoch 112/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0048 - mae: 0.0043 - val_loss: 0.0048 - val_mae: 0.0048\n",
      "Epoch 113/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0048 - mae: 0.0044 - val_loss: 0.0048 - val_mae: 0.0040\n",
      "Epoch 114/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0048 - mae: 0.0043 - val_loss: 0.0048 - val_mae: 0.0037\n",
      "Epoch 115/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0048 - mae: 0.0043 - val_loss: 0.0047 - val_mae: 0.0043\n",
      "Epoch 116/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0047 - mae: 0.0043 - val_loss: 0.0047 - val_mae: 0.0052\n",
      "Epoch 117/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0047 - mae: 0.0043 - val_loss: 0.0047 - val_mae: 0.0042\n",
      "Epoch 118/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0047 - mae: 0.0043 - val_loss: 0.0047 - val_mae: 0.0061\n",
      "Epoch 119/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0047 - mae: 0.0043 - val_loss: 0.0046 - val_mae: 0.0045\n",
      "Epoch 120/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0046 - mae: 0.0042 - val_loss: 0.0046 - val_mae: 0.0037\n",
      "Epoch 121/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0046 - mae: 0.0042 - val_loss: 0.0046 - val_mae: 0.0040\n",
      "Epoch 122/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0046 - mae: 0.0042 - val_loss: 0.0046 - val_mae: 0.0039\n",
      "Epoch 123/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0046 - mae: 0.0042 - val_loss: 0.0046 - val_mae: 0.0040\n",
      "Epoch 124/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0045 - mae: 0.0042 - val_loss: 0.0045 - val_mae: 0.0041\n",
      "Epoch 125/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0045 - mae: 0.0042 - val_loss: 0.0045 - val_mae: 0.0037\n",
      "Epoch 126/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0045 - mae: 0.0041 - val_loss: 0.0045 - val_mae: 0.0063\n",
      "Epoch 127/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0045 - mae: 0.0041 - val_loss: 0.0045 - val_mae: 0.0049\n",
      "Epoch 128/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0045 - mae: 0.0041 - val_loss: 0.0044 - val_mae: 0.0038\n",
      "Epoch 129/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0044 - mae: 0.0041 - val_loss: 0.0044 - val_mae: 0.0055\n",
      "Epoch 130/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0044 - mae: 0.0041 - val_loss: 0.0044 - val_mae: 0.0037\n",
      "Epoch 131/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0044 - mae: 0.0041 - val_loss: 0.0044 - val_mae: 0.0056\n",
      "Epoch 132/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0044 - mae: 0.0041 - val_loss: 0.0044 - val_mae: 0.0037\n",
      "Epoch 133/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0043 - mae: 0.0040 - val_loss: 0.0043 - val_mae: 0.0037\n",
      "Epoch 134/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0043 - mae: 0.0040 - val_loss: 0.0043 - val_mae: 0.0049\n",
      "Epoch 135/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0043 - mae: 0.0041 - val_loss: 0.0043 - val_mae: 0.0042\n",
      "Epoch 136/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0043 - mae: 0.0040 - val_loss: 0.0043 - val_mae: 0.0038\n",
      "Epoch 137/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0043 - mae: 0.0040 - val_loss: 0.0043 - val_mae: 0.0040\n",
      "Epoch 138/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0042 - mae: 0.0040 - val_loss: 0.0042 - val_mae: 0.0037\n",
      "Epoch 139/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0042 - mae: 0.0039 - val_loss: 0.0042 - val_mae: 0.0036\n",
      "Epoch 140/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0042 - mae: 0.0041 - val_loss: 0.0042 - val_mae: 0.0038\n",
      "Epoch 141/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0042 - mae: 0.0040 - val_loss: 0.0042 - val_mae: 0.0037\n",
      "Epoch 142/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0042 - mae: 0.0040 - val_loss: 0.0041 - val_mae: 0.0036\n",
      "Epoch 143/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0041 - mae: 0.0039 - val_loss: 0.0041 - val_mae: 0.0036\n",
      "Epoch 144/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0041 - mae: 0.0039 - val_loss: 0.0041 - val_mae: 0.0036\n",
      "Epoch 145/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0041 - mae: 0.0039 - val_loss: 0.0041 - val_mae: 0.0049\n",
      "Epoch 146/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0041 - mae: 0.0040 - val_loss: 0.0041 - val_mae: 0.0038\n",
      "Epoch 147/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0041 - mae: 0.0039 - val_loss: 0.0040 - val_mae: 0.0033\n",
      "Epoch 148/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0040 - mae: 0.0039 - val_loss: 0.0040 - val_mae: 0.0037\n",
      "Epoch 149/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0040 - mae: 0.0039 - val_loss: 0.0040 - val_mae: 0.0039\n",
      "Epoch 150/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0040 - mae: 0.0040 - val_loss: 0.0040 - val_mae: 0.0044\n",
      "Epoch 151/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0040 - mae: 0.0039 - val_loss: 0.0040 - val_mae: 0.0038\n",
      "Epoch 152/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0040 - mae: 0.0039 - val_loss: 0.0039 - val_mae: 0.0037\n",
      "Epoch 153/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0039 - mae: 0.0039 - val_loss: 0.0039 - val_mae: 0.0048\n",
      "Epoch 154/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0039 - mae: 0.0039 - val_loss: 0.0039 - val_mae: 0.0034\n",
      "Epoch 155/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0039 - mae: 0.0039 - val_loss: 0.0039 - val_mae: 0.0037\n",
      "Epoch 156/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0039 - mae: 0.0039 - val_loss: 0.0039 - val_mae: 0.0034\n",
      "Epoch 157/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0039 - mae: 0.0038 - val_loss: 0.0038 - val_mae: 0.0035\n",
      "Epoch 158/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0038 - mae: 0.0039 - val_loss: 0.0038 - val_mae: 0.0036\n",
      "Epoch 159/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0038 - mae: 0.0038 - val_loss: 0.0038 - val_mae: 0.0045\n",
      "Epoch 160/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0038 - mae: 0.0038 - val_loss: 0.0038 - val_mae: 0.0035\n",
      "Epoch 161/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0038 - mae: 0.0037 - val_loss: 0.0038 - val_mae: 0.0037\n",
      "Epoch 162/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0038 - mae: 0.0038 - val_loss: 0.0038 - val_mae: 0.0034\n",
      "Epoch 163/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0037 - mae: 0.0037 - val_loss: 0.0038 - val_mae: 0.0058\n",
      "Epoch 164/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0037 - mae: 0.0038 - val_loss: 0.0037 - val_mae: 0.0039\n",
      "Epoch 165/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0037 - mae: 0.0038 - val_loss: 0.0037 - val_mae: 0.0033\n",
      "Epoch 166/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0037 - mae: 0.0038 - val_loss: 0.0037 - val_mae: 0.0034\n",
      "Epoch 167/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0037 - mae: 0.0038 - val_loss: 0.0037 - val_mae: 0.0043\n",
      "Epoch 168/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0037 - mae: 0.0038 - val_loss: 0.0037 - val_mae: 0.0055\n",
      "Epoch 169/1000\n",
      "1757/1757 [==============================] - 3s 1ms/step - loss: 0.0036 - mae: 0.0038 - val_loss: 0.0036 - val_mae: 0.0039\n",
      "Epoch 170/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0036 - mae: 0.0037 - val_loss: 0.0036 - val_mae: 0.0031\n",
      "Epoch 171/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0036 - mae: 0.0037 - val_loss: 0.0036 - val_mae: 0.0037\n",
      "Epoch 172/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0036 - mae: 0.0037 - val_loss: 0.0036 - val_mae: 0.0033\n",
      "Epoch 173/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0036 - mae: 0.0038 - val_loss: 0.0036 - val_mae: 0.0035\n",
      "Epoch 174/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0035 - mae: 0.0038 - val_loss: 0.0035 - val_mae: 0.0033\n",
      "Epoch 175/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0035 - mae: 0.0036 - val_loss: 0.0035 - val_mae: 0.0041\n",
      "Epoch 176/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0035 - mae: 0.0037 - val_loss: 0.0035 - val_mae: 0.0036\n",
      "Epoch 177/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0035 - mae: 0.0037 - val_loss: 0.0035 - val_mae: 0.0032\n",
      "Epoch 178/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0035 - mae: 0.0037 - val_loss: 0.0035 - val_mae: 0.0033\n",
      "Epoch 179/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0035 - mae: 0.0037 - val_loss: 0.0035 - val_mae: 0.0035\n",
      "Epoch 180/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0034 - mae: 0.0037 - val_loss: 0.0034 - val_mae: 0.0036\n",
      "Epoch 181/1000\n",
      "1757/1757 [==============================] - 2s 1ms/step - loss: 0.0034 - mae: 0.0036 - val_loss: 0.0034 - val_mae: 0.0042\n",
      "Epoch 182/1000\n",
      "1695/1757 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0036"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 36\u001B[0m\n\u001B[0;32m     33\u001B[0m early_stopping \u001B[38;5;241m=\u001B[39m EarlyStopping(monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m, patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmin\u001B[39m\u001B[38;5;124m'\u001B[39m, restore_best_weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTraining für Fold \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfold_no\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m...\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 36\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_fold\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train_fold\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m16\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX_val_fold\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_val_fold\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mearly_stopping\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m# Speichere die Ergebnisse des aktuellen Folds\u001B[39;00m\n\u001B[0;32m     39\u001B[0m val_loss_results\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mmin\u001B[39m(history\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m]))\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:1856\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1840\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_eval_data_handler\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1841\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_eval_data_handler \u001B[38;5;241m=\u001B[39m data_adapter\u001B[38;5;241m.\u001B[39mget_data_handler(\n\u001B[0;32m   1842\u001B[0m         x\u001B[38;5;241m=\u001B[39mval_x,\n\u001B[0;32m   1843\u001B[0m         y\u001B[38;5;241m=\u001B[39mval_y,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1854\u001B[0m         pss_evaluation_shards\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pss_evaluation_shards,\n\u001B[0;32m   1855\u001B[0m     )\n\u001B[1;32m-> 1856\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1857\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_x\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1858\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_y\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1859\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_sample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1860\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1861\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1862\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1863\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1864\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1865\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1866\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1867\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_use_cached_eval_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1868\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1869\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m   1870\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval_\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name: val \u001B[38;5;28;01mfor\u001B[39;00m name, val \u001B[38;5;129;01min\u001B[39;00m val_logs\u001B[38;5;241m.\u001B[39mitems()\n\u001B[0;32m   1871\u001B[0m }\n\u001B[0;32m   1872\u001B[0m epoch_logs\u001B[38;5;241m.\u001B[39mupdate(val_logs)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:2296\u001B[0m, in \u001B[0;36mModel.evaluate\u001B[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001B[0m\n\u001B[0;32m   2292\u001B[0m             \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   2293\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m\"\u001B[39m, step_num\u001B[38;5;241m=\u001B[39mstep, _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   2294\u001B[0m             ):\n\u001B[0;32m   2295\u001B[0m                 callbacks\u001B[38;5;241m.\u001B[39mon_test_batch_begin(step)\n\u001B[1;32m-> 2296\u001B[0m                 logs \u001B[38;5;241m=\u001B[39m \u001B[43mtest_function_runner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_step\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2297\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mdataset_or_iterator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2298\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mdata_handler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2299\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2300\u001B[0m \u001B[43m                    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_pss_evaluation_shards\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2301\u001B[0m \u001B[43m                \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2303\u001B[0m logs \u001B[38;5;241m=\u001B[39m tf_utils\u001B[38;5;241m.\u001B[39msync_to_numpy_or_python_type(logs)\n\u001B[0;32m   2304\u001B[0m \u001B[38;5;66;03m# Override with model metrics instead of last step logs\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:4108\u001B[0m, in \u001B[0;36m_TestFunction.run_step\u001B[1;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001B[0m\n\u001B[0;32m   4107\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_step\u001B[39m(\u001B[38;5;28mself\u001B[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001B[1;32m-> 4108\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_or_iterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4109\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   4110\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    829\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    831\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 832\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    834\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    835\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:877\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    874\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    875\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[0;32m    876\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[1;32m--> 877\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    878\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[0;32m    879\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    880\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables:\n\u001B[0;32m    881\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    882\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[1;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[0;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[1;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[0;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[0;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[0;32m   1319\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1320\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1321\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1322\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1323\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1324\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1325\u001B[0m     args,\n\u001B[0;32m   1326\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1327\u001B[0m     executing_eagerly)\n\u001B[0;32m   1328\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[1;34m(self, args)\u001B[0m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[0;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[1;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[0;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[0;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[0;32m    261\u001B[0m     )\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001B[0m, in \u001B[0;36mContext.call_function\u001B[1;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[0;32m   1484\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[0;32m   1485\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1486\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1487\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1488\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1489\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1490\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1491\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1492\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1493\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1494\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m   1495\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1496\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1500\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[0;32m   1501\u001B[0m   )\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    " # # Initialisiere Listen, um Ergebnisse zu speichern\n",
    "# val_loss_results = []\n",
    "# val_mae_results = []\n",
    "# \n",
    "# # Funktion, um das Modell zu erstellen\n",
    "# def create_model():\n",
    "#     model = Sequential([\n",
    "#                 Dense(232, activation='relu', input_shape=(3,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "#                 \n",
    "#                 Dense(152, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "#                 \n",
    "#                 Dense(232, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "#                 \n",
    "#                 Dense(1 , activation = 'linear')\n",
    "# \n",
    "#     ])\n",
    "#     optimizer = Adam(learning_rate=0.00001)\n",
    "#     model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "#     return model\n",
    "# \n",
    "# # K-Fold Cross-Validation Konfiguration\n",
    "# n_splits = 5\n",
    "# kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "# \n",
    "# # Leistungsüberwachung\n",
    "# fold_no = 1\n",
    "# for train_index, val_index in kf.split(X_train_scaled):\n",
    "#     X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "#     y_train_fold, y_val_fold = y_train_scaled[train_index], y_train_scaled[val_index]\n",
    "# \n",
    "#     model = create_model()\n",
    "# \n",
    "#     early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "# \n",
    "#     print(f'Training für Fold {fold_no}...')\n",
    "#     history = model.fit(X_train_fold, y_train_fold, batch_size=16, epochs=1000, validation_data=(X_val_fold, y_val_fold), callbacks=[early_stopping], verbose=1)\n",
    "# \n",
    "#     # Speichere die Ergebnisse des aktuellen Folds\n",
    "#     val_loss_results.append(min(history.history['val_loss']))\n",
    "#     val_mae_results.append(min(history.history['val_mae']))\n",
    "# \n",
    "#     fold_no += 1\n",
    "# \n",
    "# # Berechne den Durchschnitt über alle Folds\n",
    "# average_val_loss = np.mean(val_loss_results)\n",
    "# average_val_mae = np.mean(val_mae_results)\n",
    "# \n",
    "# # Gib die durchschnittlichen Ergebnisse aus\n",
    "# print(f'Durchschnittlicher Validation Loss: {average_val_loss}')\n",
    "# print(f'Durchschnittlicher Validation MAE: {average_val_mae}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T13:07:25.049745600Z",
     "start_time": "2024-03-18T13:01:03.563514Z"
    }
   },
   "id": "929336b1a7ac475d"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2196/2196 - 2s - loss: 0.0011 - mae: 0.0036 - 2s/epoch - 909us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.0010846683289855719, 0.0036120929289609194]"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test_scaled, y_test_scaled, verbose=2)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T18:05:40.743134700Z",
     "start_time": "2024-03-27T18:05:38.707768400Z"
    }
   },
   "id": "4b02697cbcecd185"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bsp. Predicted: [746.82074] Actual: [909.24] \n",
      "Durchschnittliche Abweichung (MAE): [299.35676438]\n",
      "19.27452589062743\n"
     ]
    }
   ],
   "source": [
    "scaled_predicted_values = model.predict(X_test_scaled_2, verbose = 0)\n",
    "\n",
    "# Führen Sie die Rücktransformation der skalierten Werte durch\n",
    "original_predicted_values = scaler_target.inverse_transform(scaled_predicted_values)\n",
    "original_actual_values = scaler_target.inverse_transform(y_test_scaled_2)  # y_test sind die skalierten tatsächlichen Werte\n",
    "print(f' Bsp. Predicted: {original_predicted_values[100]} Actual: {original_actual_values[100]} ')\n",
    "\n",
    "def calculate_mae(list1, list2):\n",
    "    # Stelle sicher, dass beide Listen die gleiche Länge haben\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Listen müssen die gleiche Länge haben\")\n",
    "\n",
    "    # Berechne die absolute Differenz zwischen den Elementen der Listen\n",
    "    differences = [abs(x - y) for x, y in zip(list1, list2)]\n",
    "\n",
    "    # Berechne den Durchschnitt der absoluten Differenzen\n",
    "    mae = sum(differences) / len(differences)\n",
    "\n",
    "    return mae\n",
    "\n",
    "# Beispiel\n",
    "list1 = original_predicted_values\n",
    "list2 = original_actual_values\n",
    "\n",
    "mae = calculate_mae(list1, list2)\n",
    "print(f\"Durchschnittliche Abweichung (MAE): {mae}\")\n",
    "\n",
    "errors = np.abs((original_actual_values - original_predicted_values) / original_actual_values)\n",
    "mape = np.mean(errors) * 100\n",
    "print(mape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T18:06:05.619343Z",
     "start_time": "2024-03-27T18:06:05.514906900Z"
    }
   },
   "id": "a402d28abbd82f60"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (70258) does not match length of index (1071)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[50], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m df_result \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEcht\u001B[39m\u001B[38;5;124m'\u001B[39m: [val[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m val \u001B[38;5;129;01min\u001B[39;00m list1], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVorhergesagt\u001B[39m\u001B[38;5;124m'\u001B[39m: [val[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m val \u001B[38;5;129;01min\u001B[39;00m list2]})\n\u001B[1;32m----> 2\u001B[0m \u001B[43mdf_result\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mX-Koordinate\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m X_test_scaled[:, \u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m      3\u001B[0m df_result[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mY-Koordinate\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m X_test_scaled[:, \u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m      4\u001B[0m df_result[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mZeitpunkt\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m X_test_scaled[:, \u001B[38;5;241m2\u001B[39m]\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4299\u001B[0m, in \u001B[0;36mDataFrame.__setitem__\u001B[1;34m(self, key, value)\u001B[0m\n\u001B[0;32m   4296\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_setitem_array([key], value)\n\u001B[0;32m   4297\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   4298\u001B[0m     \u001B[38;5;66;03m# set column\u001B[39;00m\n\u001B[1;32m-> 4299\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_set_item\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4512\u001B[0m, in \u001B[0;36mDataFrame._set_item\u001B[1;34m(self, key, value)\u001B[0m\n\u001B[0;32m   4502\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_set_item\u001B[39m(\u001B[38;5;28mself\u001B[39m, key, value) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   4503\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   4504\u001B[0m \u001B[38;5;124;03m    Add series to DataFrame in specified column.\u001B[39;00m\n\u001B[0;32m   4505\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4510\u001B[0m \u001B[38;5;124;03m    ensure homogeneity.\u001B[39;00m\n\u001B[0;32m   4511\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 4512\u001B[0m     value, refs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sanitize_column\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4514\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   4515\u001B[0m         key \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\n\u001B[0;32m   4516\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m value\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   4517\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value\u001B[38;5;241m.\u001B[39mdtype, ExtensionDtype)\n\u001B[0;32m   4518\u001B[0m     ):\n\u001B[0;32m   4519\u001B[0m         \u001B[38;5;66;03m# broadcast across multiple columns if necessary\u001B[39;00m\n\u001B[0;32m   4520\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mis_unique \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns, MultiIndex):\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:5253\u001B[0m, in \u001B[0;36mDataFrame._sanitize_column\u001B[1;34m(self, value)\u001B[0m\n\u001B[0;32m   5250\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _reindex_for_setitem(value, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex)\n\u001B[0;32m   5252\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_list_like(value):\n\u001B[1;32m-> 5253\u001B[0m     \u001B[43mcom\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequire_length_match\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   5254\u001B[0m arr \u001B[38;5;241m=\u001B[39m sanitize_array(value, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, allow_2d\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m   5255\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   5256\u001B[0m     \u001B[38;5;28misinstance\u001B[39m(value, Index)\n\u001B[0;32m   5257\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m value\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobject\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   5260\u001B[0m     \u001B[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001B[39;00m\n\u001B[0;32m   5261\u001B[0m     \u001B[38;5;66;03m# this deprecation\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\pandas\\core\\common.py:573\u001B[0m, in \u001B[0;36mrequire_length_match\u001B[1;34m(data, index)\u001B[0m\n\u001B[0;32m    569\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    570\u001B[0m \u001B[38;5;124;03mCheck the length of data matches the length of the index.\u001B[39;00m\n\u001B[0;32m    571\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    572\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(data) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(index):\n\u001B[1;32m--> 573\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    574\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLength of values \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    575\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(data)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    576\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdoes not match length of index \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    577\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(index)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    578\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: Length of values (70258) does not match length of index (1071)"
     ]
    }
   ],
   "source": [
    "df_result = pd.DataFrame({'Echt': [val[0] for val in list1], 'Vorhergesagt': [val[0] for val in list2]})\n",
    "df_result['X-Koordinate'] = X_test_scaled[:, 0]\n",
    "df_result['Y-Koordinate'] = X_test_scaled[:, 1]\n",
    "df_result['Zeitpunkt'] = X_test_scaled[:, 2]\n",
    "df_result['Strom'] = X_test_scaled[:, 3]\n",
    "df_result['Kraft'] = X_test_scaled[:, 4]\n",
    "\n",
    "df_result['Differenz'] = df_result['Echt'] - df_result['Vorhergesagt']\n",
    "df_result['Differenz'].sort_values()\n",
    "sorted_df = df_result.sort_values(by= 'Differenz')\n",
    "Anzahl_Punkte = (sorted_df['Differenz'] < -20).sum()\n",
    "print(\"Anzahl der Werte die kleiner sind:\", Anzahl_Punkte)\n",
    "\n",
    "sorted_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T14:36:26.731073200Z",
     "start_time": "2024-03-27T14:36:26.166977200Z"
    }
   },
   "id": "7ffe8ddf2200f429"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: [0.9998956]\n"
     ]
    }
   ],
   "source": [
    "#Berechnung der Auswertungsgröße R^2\n",
    "\n",
    "def calculate_r_squared(predicted, actual):\n",
    "    # Berechnung des Mittelwerts der tatsächlichen Werte\n",
    "    mean_actual = sum(actual) / len(actual)\n",
    "    \n",
    "    # Berechnung der totalen Summe der Quadrate (SST)\n",
    "    sst = sum((x - mean_actual) ** 2 for x in actual)\n",
    "    \n",
    "    # Berechnung der Summe der Quadrate der Residuen (SSE)\n",
    "    sse = sum((actual[i] - predicted[i]) ** 2 for i in range(len(actual)))\n",
    "    \n",
    "    # Berechnung des R^2-Wertes\n",
    "    r_squared = 1 - (sse / sst)\n",
    "    \n",
    "    return r_squared\n",
    "\n",
    "# Berechnung von R^2 mit den bereitgestellten Listen\n",
    "r_squared = calculate_r_squared(list1, list2)\n",
    "\n",
    "print(f\"R^2: {r_squared}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T16:43:48.477335800Z",
     "start_time": "2024-03-26T16:43:48.128237500Z"
    }
   },
   "id": "4c350477801f0961"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mae = history.history['loss']\n",
    "val_mae = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(mae) + 1)\n",
    "\n",
    "# MAE Diagramm\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, mae, 'r', label='Training MSE')\n",
    "plt.plot(epochs, val_mae, 'b', label='Validation MSE')\n",
    "plt.title('Training and Validation MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T13:19:36.804139100Z",
     "start_time": "2024-03-20T13:19:36.515474400Z"
    }
   },
   "id": "3688dd7102e95baf"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mae = history.history['mae']\n",
    "val_mae = history.history['val_mae']\n",
    "\n",
    "epochs = range(1, len(mae) + 1)\n",
    "\n",
    "# MAE Diagramm\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, mae, 'r', label='Training MAE')\n",
    "plt.plot(epochs, val_mae, 'b', label='Validation MAE')\n",
    "plt.title('Training and Validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "#plt.ylim(0.00, 0.01)\n",
    "\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T13:19:49.232762600Z",
     "start_time": "2024-03-20T13:19:49.099626600Z"
    }
   },
   "id": "b8d71e5c44c48bef"
  },
  {
   "cell_type": "markdown",
   "id": "553df6fa",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x000001B625802E50>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 770, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 47\u001B[0m\n\u001B[0;32m     45\u001B[0m grid_search \u001B[38;5;241m=\u001B[39m GridSearchCV(estimator\u001B[38;5;241m=\u001B[39mmodel, param_grid\u001B[38;5;241m=\u001B[39mparam_grid, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m     46\u001B[0m \u001B[38;5;66;03m# Hinweis: Stellen Sie sicher, dass Ihre Daten (X_train_scaled, y_train_scaled) korrekt definiert sind\u001B[39;00m\n\u001B[1;32m---> 47\u001B[0m grid_result \u001B[38;5;241m=\u001B[39m \u001B[43mgrid_search\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_scaled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train_scaled\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;66;03m# Beste Parameter und Score ausgeben\u001B[39;00m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBeste Parameter:\u001B[39m\u001B[38;5;124m\"\u001B[39m, grid_search\u001B[38;5;241m.\u001B[39mbest_params_)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\base.py:1351\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1344\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1346\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1347\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1348\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1349\u001B[0m     )\n\u001B[0;32m   1350\u001B[0m ):\n\u001B[1;32m-> 1351\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, **params)\u001B[0m\n\u001B[0;32m    964\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m    965\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m    966\u001B[0m     )\n\u001B[0;32m    968\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m--> 970\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    972\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m    973\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m    974\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1525\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1526\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1527\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    908\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    909\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m    910\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    911\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    912\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[0;32m    913\u001B[0m         )\n\u001B[0;32m    914\u001B[0m     )\n\u001B[1;32m--> 916\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    917\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    918\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    919\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    920\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    921\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    922\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    923\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    924\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    925\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    926\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    927\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    928\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    929\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    930\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrouted_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplitter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    931\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    932\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    934\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    935\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    936\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    937\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    938\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    939\u001B[0m     )\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     62\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     63\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     64\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     66\u001B[0m )\n\u001B[1;32m---> 67\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\joblib\\parallel.py:1952\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1946\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[0;32m   1947\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[0;32m   1948\u001B[0m \u001B[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001B[39;00m\n\u001B[0;32m   1949\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[0;32m   1950\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 1952\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\joblib\\parallel.py:1595\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[1;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[0;32m   1592\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[0;32m   1594\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[1;32m-> 1595\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[0;32m   1597\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[0;32m   1598\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[0;32m   1599\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[0;32m   1600\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[0;32m   1601\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\joblib\\parallel.py:1707\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1702\u001B[0m \u001B[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001B[39;00m\n\u001B[0;32m   1703\u001B[0m \u001B[38;5;66;03m# async callbacks to progress.\u001B[39;00m\n\u001B[0;32m   1704\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ((\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m   1705\u001B[0m     (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mget_status(\n\u001B[0;32m   1706\u001B[0m         timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout) \u001B[38;5;241m==\u001B[39m TASK_PENDING)):\n\u001B[1;32m-> 1707\u001B[0m     time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m0.01\u001B[39m)\n\u001B[0;32m   1708\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m   1710\u001B[0m \u001B[38;5;66;03m# We need to be careful: the job list can be filling up as\u001B[39;00m\n\u001B[0;32m   1711\u001B[0m \u001B[38;5;66;03m# we empty it and Python list are not thread-safe by\u001B[39;00m\n\u001B[0;32m   1712\u001B[0m \u001B[38;5;66;03m# default hence the use of the lock\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def build_model(learning_rate=0.00001, activation='relu', regularization=0.00001, dropout_rate=0.0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(232, activation=activation, input_shape=(3,), kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(152, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(232, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Verwenden Sie eine Funktion, um das Modell zu instanziieren, für scikit-learn Wrapper\n",
    "model = KerasRegressor(model=build_model, verbose=2, callbacks=[early_stopping])\n",
    "\n",
    "# Anpassung der Parameter im param_grid\n",
    "param_grid = {\n",
    "    'model__learning_rate': [0.00001],\n",
    "    'model__regularization': [0.00001],\n",
    "    'fit__batch_size': [16, 32, 64, 100],\n",
    "    'fit__epochs': [100],\n",
    "    'model__dropout_rate' : [0.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=2)\n",
    "# Hinweis: Stellen Sie sicher, dass Ihre Daten (X_train_scaled, y_train_scaled) korrekt definiert sind\n",
    "grid_result = grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "# Beste Parameter und Score ausgeben\n",
    "print(\"Beste Parameter:\", grid_search.best_params_)\n",
    "print(\"Beste Genauigkeit:\", grid_search.best_score_)\n",
    "\n",
    "with open(\"Gridsearch_D4_t_1.txt\", \"w\") as f:\n",
    "    f.write(f\"Beste Parameter: {grid_search.best_params_}\\n\")\n",
    "    f.write(f\"Beste Genauigkeit: {grid_search.best_score_}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T12:15:54.960082300Z",
     "start_time": "2024-03-18T11:56:34.729533600Z"
    }
   },
   "id": "7464a951f44a07ee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Funktion zum Erstellen des Modells\n",
    "# def build_model(hp):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(hp.Int('input_units', min_value=8, max_value=328, step=16), input_shape=(3,), activation='relu'))\n",
    "#     for i in range(hp.Int('n_layers', 1, 10)):\n",
    "#         model.add(Dense(hp.Int(f'units_{i}', min_value=8, max_value=328, step=16), activation='relu'))\n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     return model\n",
    "# \n",
    "# # Durchführung der Random Search dreimal\n",
    "# for run in range(1, 4):\n",
    "#     # Anpassen des Verzeichnisses und des Projektnamens für jeden Durchlauf\n",
    "#     directory = 'random_search'\n",
    "#     project_name = f'random_search_D4_t_1_{run}'\n",
    "# \n",
    "#     tuner = RandomSearch(\n",
    "#         build_model,\n",
    "#         objective='val_loss',\n",
    "#         max_trials=100,\n",
    "#         executions_per_trial=2,\n",
    "#         directory=directory,\n",
    "#         project_name=project_name\n",
    "#     )\n",
    "# \n",
    "#     # Durchführung des Random Search\n",
    "#     tuner.search(X_train_scaled, y_train_scaled, epochs=50, verbose =0, batch_size=50, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "# \n",
    "#     # Abrufen und Speichern des besten Modells\n",
    "#     best_model = tuner.get_best_models(num_models=1)[0]\n",
    "#     model_path = os.path.join(directory, project_name, 'best_model.h5') \n",
    "#     best_model.save(model_path)\n",
    "# \n",
    "# \n",
    "#     # Optional: Abrufen und Ausgeben der besten Hyperparameter\n",
    "#     best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "# \n",
    "#     # Konvertieren der Hyperparameter in ein DataFrame\n",
    "#     df_hyperparameters = pd.DataFrame([best_hyperparameters.values])\n",
    "#     # Speichern des DataFrame als CSV\n",
    "#     df_hyperparameters.to_csv(f'random_search_D4_t_1_{run}.csv', index=False)\n",
    "# \n",
    "#     print(f\"Beste Hyperparameter für Lauf {run}: {best_hyperparameters.values}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T10:03:46.649218900Z"
    }
   },
   "id": "d0f02feb42b652f5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-13T10:03:46.650224Z"
    }
   },
   "id": "3e35d5ebef369658"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
