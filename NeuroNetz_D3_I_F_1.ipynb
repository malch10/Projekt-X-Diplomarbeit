{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94b0518e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T21:12:52.861576900Z",
     "start_time": "2024-05-15T21:12:42.156164900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense , Dropout\n",
    "from scikeras.wrappers import KerasRegressor \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Einlesen der Pickle-Dateien und Vorverarbeitung des Inhaltes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfbb781c4e0db05a"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4ff61b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T21:12:52.905006400Z",
     "start_time": "2024-05-15T21:12:52.861576900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft    Temperatur\n254520        0.00000      -0.00200        500   6000   5000  7.535400e+02\n254521        0.00000      -0.00196        500   6000   5000  7.936300e+02\n254522        0.00000      -0.00192        500   6000   5000  8.356500e+02\n254523        0.00000      -0.00188        500   6000   5000  8.775000e+02\n254524        0.00000      -0.00184        500   6000   5000  9.199800e+02\n...               ...           ...        ...    ...    ...           ...\n2087059       0.00248       0.00184        500   9000   5000  1.110600e+03\n2087060       0.00248       0.00188        500   9000   5000  1.046600e+03\n2087061       0.00248       0.00192        500   9000   5000  9.810900e+02\n2087062       0.00248       0.00196        500   9000   5000  7.888600e-31\n2087063       0.00248       0.00200        500   9000   5000  9.403500e+02\n\n[50904 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>254520</th>\n      <td>0.00000</td>\n      <td>-0.00200</td>\n      <td>500</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>7.535400e+02</td>\n    </tr>\n    <tr>\n      <th>254521</th>\n      <td>0.00000</td>\n      <td>-0.00196</td>\n      <td>500</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>7.936300e+02</td>\n    </tr>\n    <tr>\n      <th>254522</th>\n      <td>0.00000</td>\n      <td>-0.00192</td>\n      <td>500</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>8.356500e+02</td>\n    </tr>\n    <tr>\n      <th>254523</th>\n      <td>0.00000</td>\n      <td>-0.00188</td>\n      <td>500</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>8.775000e+02</td>\n    </tr>\n    <tr>\n      <th>254524</th>\n      <td>0.00000</td>\n      <td>-0.00184</td>\n      <td>500</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>9.199800e+02</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2087059</th>\n      <td>0.00248</td>\n      <td>0.00184</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1.110600e+03</td>\n    </tr>\n    <tr>\n      <th>2087060</th>\n      <td>0.00248</td>\n      <td>0.00188</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1.046600e+03</td>\n    </tr>\n    <tr>\n      <th>2087061</th>\n      <td>0.00248</td>\n      <td>0.00192</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>9.810900e+02</td>\n    </tr>\n    <tr>\n      <th>2087062</th>\n      <td>0.00248</td>\n      <td>0.00196</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>7.888600e-31</td>\n    </tr>\n    <tr>\n      <th>2087063</th>\n      <td>0.00248</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>9.403500e+02</td>\n    </tr>\n  </tbody>\n</table>\n<p>50904 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_ALL_D3_500_I_F_PKL.pkl')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "966e3c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T21:12:52.923309500Z",
     "start_time": "2024-05-15T21:12:52.892006600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n",
      "1037169       0.00000      -0.00200        500   7000   6000      811.76\n",
      "1037170       0.00000      -0.00196        500   7000   6000      853.27\n",
      "1037171       0.00000      -0.00192        500   7000   6000      897.57\n",
      "1037172       0.00000      -0.00188        500   7000   6000      941.21\n",
      "1037173       0.00000      -0.00184        500   7000   6000      986.34\n",
      "...               ...           ...        ...    ...    ...         ...\n",
      "1043527       0.00248       0.00184        500   7000   6000      784.55\n",
      "1043528       0.00248       0.00188        500   7000   6000      745.87\n",
      "1043529       0.00248       0.00192        500   7000   6000      706.17\n",
      "1043530       0.00248       0.00196        500   7000   6000      693.28\n",
      "1043531       0.00248       0.00200        500   7000   6000      687.80\n",
      "\n",
      "[6363 rows x 6 columns]\n",
      "Empty DataFrame\n",
      "Columns: [X-Koordinate, Y-Koordinate, Zeitpunkt, Strom, Kraft, Temperatur]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/plain": "         X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n1037169       0.00000      -0.00200        500   7000   6000      811.76\n1037170       0.00000      -0.00196        500   7000   6000      853.27\n1037171       0.00000      -0.00192        500   7000   6000      897.57\n1037172       0.00000      -0.00188        500   7000   6000      941.21\n1037173       0.00000      -0.00184        500   7000   6000      986.34\n...               ...           ...        ...    ...    ...         ...\n1043527       0.00248       0.00184        500   7000   6000      784.55\n1043528       0.00248       0.00188        500   7000   6000      745.87\n1043529       0.00248       0.00192        500   7000   6000      706.17\n1043530       0.00248       0.00196        500   7000   6000      693.28\n1043531       0.00248       0.00200        500   7000   6000      687.80\n\n[6363 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1037169</th>\n      <td>0.00000</td>\n      <td>-0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>811.76</td>\n    </tr>\n    <tr>\n      <th>1037170</th>\n      <td>0.00000</td>\n      <td>-0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>853.27</td>\n    </tr>\n    <tr>\n      <th>1037171</th>\n      <td>0.00000</td>\n      <td>-0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>897.57</td>\n    </tr>\n    <tr>\n      <th>1037172</th>\n      <td>0.00000</td>\n      <td>-0.00188</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>941.21</td>\n    </tr>\n    <tr>\n      <th>1037173</th>\n      <td>0.00000</td>\n      <td>-0.00184</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>986.34</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1043527</th>\n      <td>0.00248</td>\n      <td>0.00184</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>784.55</td>\n    </tr>\n    <tr>\n      <th>1043528</th>\n      <td>0.00248</td>\n      <td>0.00188</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>745.87</td>\n    </tr>\n    <tr>\n      <th>1043529</th>\n      <td>0.00248</td>\n      <td>0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>706.17</td>\n    </tr>\n    <tr>\n      <th>1043530</th>\n      <td>0.00248</td>\n      <td>0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>693.28</td>\n    </tr>\n    <tr>\n      <th>1043531</th>\n      <td>0.00248</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>687.80</td>\n    </tr>\n  </tbody>\n</table>\n<p>6363 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mit der Bedingung wird die Simulationsdatei I7000 F6000 ausgewählt.\n",
    "bedingung = (data['Kraft'] == 6000) & (data['Strom'] == 7000)\n",
    "df_test = data[bedingung].copy()\n",
    "\n",
    "print(df_test)\n",
    "\n",
    "data_all = data.drop(df_test.index) #Simualtionsdatei aus den Trainingsdaten löschen\n",
    "\n",
    "print(data_all[(data_all['Kraft'] == 6000) & (data_all['Strom'] == 7000)]) #Kontrolle, ob Simulationsdatei wirklich gelöscht ist\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "         X-Koordinate  Y-Koordinate  Strom  Kraft    Temperatur\n254520        0.00000      -0.00200   6000   5000  7.535400e+02\n254521        0.00000      -0.00196   6000   5000  7.936300e+02\n254522        0.00000      -0.00192   6000   5000  8.356500e+02\n254523        0.00000      -0.00188   6000   5000  8.775000e+02\n254524        0.00000      -0.00184   6000   5000  9.199800e+02\n...               ...           ...    ...    ...           ...\n2087059       0.00248       0.00184   9000   5000  1.110600e+03\n2087060       0.00248       0.00188   9000   5000  1.046600e+03\n2087061       0.00248       0.00192   9000   5000  9.810900e+02\n2087062       0.00248       0.00196   9000   5000  7.888600e-31\n2087063       0.00248       0.00200   9000   5000  9.403500e+02\n\n[44541 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>254520</th>\n      <td>0.00000</td>\n      <td>-0.00200</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>7.535400e+02</td>\n    </tr>\n    <tr>\n      <th>254521</th>\n      <td>0.00000</td>\n      <td>-0.00196</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>7.936300e+02</td>\n    </tr>\n    <tr>\n      <th>254522</th>\n      <td>0.00000</td>\n      <td>-0.00192</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>8.356500e+02</td>\n    </tr>\n    <tr>\n      <th>254523</th>\n      <td>0.00000</td>\n      <td>-0.00188</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>8.775000e+02</td>\n    </tr>\n    <tr>\n      <th>254524</th>\n      <td>0.00000</td>\n      <td>-0.00184</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>9.199800e+02</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2087059</th>\n      <td>0.00248</td>\n      <td>0.00184</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1.110600e+03</td>\n    </tr>\n    <tr>\n      <th>2087060</th>\n      <td>0.00248</td>\n      <td>0.00188</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1.046600e+03</td>\n    </tr>\n    <tr>\n      <th>2087061</th>\n      <td>0.00248</td>\n      <td>0.00192</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>9.810900e+02</td>\n    </tr>\n    <tr>\n      <th>2087062</th>\n      <td>0.00248</td>\n      <td>0.00196</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>7.888600e-31</td>\n    </tr>\n    <tr>\n      <th>2087063</th>\n      <td>0.00248</td>\n      <td>0.00200</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>9.403500e+02</td>\n    </tr>\n  </tbody>\n</table>\n<p>44541 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all = data_all.drop('Zeitpunkt', axis = 1) #Zeitpunkt löschen, weil immer 500ms \n",
    "data_all"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T21:12:52.926309900Z",
     "start_time": "2024-05-15T21:12:52.911024Z"
    }
   },
   "id": "467c96c6df4a7dc9"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8783d1d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T21:12:52.973913900Z",
     "start_time": "2024-05-15T21:12:52.921309900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       X-Koordinate  Y-Koordinate  Strom  Kraft  Temperatur\n0           0.00112      -0.00064   6000   6000     1617.10\n1           0.00108      -0.00036   8000   7000     2058.20\n2           0.00136       0.00096   6000   6000     1420.30\n3           0.00064       0.00028   6000   5000     1829.90\n4           0.00048       0.00188   6000   6000      693.83\n...             ...           ...    ...    ...         ...\n44536       0.00248      -0.00188   6000   5000      842.80\n44537       0.00192       0.00092   6000   6000     1342.80\n44538       0.00248       0.00124   8000   7000     1434.90\n44539       0.00032       0.00008   6000   5000     1873.40\n44540       0.00120      -0.00044   7000   5000     2010.50\n\n[44541 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00112</td>\n      <td>-0.00064</td>\n      <td>6000</td>\n      <td>6000</td>\n      <td>1617.10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00108</td>\n      <td>-0.00036</td>\n      <td>8000</td>\n      <td>7000</td>\n      <td>2058.20</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00136</td>\n      <td>0.00096</td>\n      <td>6000</td>\n      <td>6000</td>\n      <td>1420.30</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00064</td>\n      <td>0.00028</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>1829.90</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00048</td>\n      <td>0.00188</td>\n      <td>6000</td>\n      <td>6000</td>\n      <td>693.83</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>44536</th>\n      <td>0.00248</td>\n      <td>-0.00188</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>842.80</td>\n    </tr>\n    <tr>\n      <th>44537</th>\n      <td>0.00192</td>\n      <td>0.00092</td>\n      <td>6000</td>\n      <td>6000</td>\n      <td>1342.80</td>\n    </tr>\n    <tr>\n      <th>44538</th>\n      <td>0.00248</td>\n      <td>0.00124</td>\n      <td>8000</td>\n      <td>7000</td>\n      <td>1434.90</td>\n    </tr>\n    <tr>\n      <th>44539</th>\n      <td>0.00032</td>\n      <td>0.00008</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>1873.40</td>\n    </tr>\n    <tr>\n      <th>44540</th>\n      <td>0.00120</td>\n      <td>-0.00044</td>\n      <td>7000</td>\n      <td>5000</td>\n      <td>2010.50</td>\n    </tr>\n  </tbody>\n</table>\n<p>44541 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shufflen der Daten\n",
    "data_all = data_all.sample(frac=1, random_state=42)  # Hier wird 42 als Random State verwendet, um die Ergebnisse reproduzierbar zu machen\n",
    "df_reset = data_all.reset_index(drop=True)\n",
    "df_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4e72a16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T21:12:53.006913500Z",
     "start_time": "2024-05-15T21:12:52.934215300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [X-Koordinate, Y-Koordinate, Strom, Kraft]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#Zuweisung der Trainingsdaten\n",
    "y = df_reset[\"Temperatur\"]\n",
    "\n",
    "X = df_reset.drop(\"Temperatur\", axis=1)\n",
    "\n",
    "print(X[(X['Kraft'] == 6000) & (X['Strom'] == 7000)]) # Erneute Kontrolle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#Zuweisung der Testdaten\n",
    "label = df_test[\"Temperatur\"]\n",
    "\n",
    "X_2 = df_test.drop(\"Temperatur\", axis=1)\n",
    "X_2 = X_2.drop('Zeitpunkt',axis =1)\n",
    "X_2 = X_2.reset_index(drop=True)\n",
    "y_2 = label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T21:12:53.035913600Z",
     "start_time": "2024-05-15T21:12:52.939568300Z"
    }
   },
   "id": "2920a35d3f81234d"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7fa289a50d87423"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e694a236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T21:12:53.105913800Z",
     "start_time": "2024-05-15T21:12:52.944794700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      X-Koordinate  Y-Koordinate  Strom  Kraft\n0          0.00000      -0.00200   7000   6000\n1          0.00000      -0.00196   7000   6000\n2          0.00000      -0.00192   7000   6000\n3          0.00000      -0.00188   7000   6000\n4          0.00000      -0.00184   7000   6000\n...            ...           ...    ...    ...\n6358       0.00248       0.00184   7000   6000\n6359       0.00248       0.00188   7000   6000\n6360       0.00248       0.00192   7000   6000\n6361       0.00248       0.00196   7000   6000\n6362       0.00248       0.00200   7000   6000\n\n[6363 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00000</td>\n      <td>-0.00200</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00000</td>\n      <td>-0.00196</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00000</td>\n      <td>-0.00192</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00000</td>\n      <td>-0.00188</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00000</td>\n      <td>-0.00184</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6358</th>\n      <td>0.00248</td>\n      <td>0.00184</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>6359</th>\n      <td>0.00248</td>\n      <td>0.00188</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>6360</th>\n      <td>0.00248</td>\n      <td>0.00192</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>6361</th>\n      <td>0.00248</td>\n      <td>0.00196</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>6362</th>\n      <td>0.00248</td>\n      <td>0.00200</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n  </tbody>\n</table>\n<p>6363 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f3303b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T21:12:53.166914400Z",
     "start_time": "2024-05-15T21:12:52.953465100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0        1617.10\n1        2058.20\n2        1420.30\n3        1829.90\n4         693.83\n          ...   \n44536     842.80\n44537    1342.80\n44538    1434.90\n44539    1873.40\n44540    2010.50\nName: Temperatur, Length: 44541, dtype: float64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c705edb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T21:12:53.166914400Z",
     "start_time": "2024-05-15T21:12:52.960173200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialisiere einen MinMaxScaler für die Features\n",
    "scaler_features = MinMaxScaler()\n",
    "# Skaliere X_train und X_test\n",
    "X_train_scaled = scaler_features.fit_transform(X)\n",
    "X_test_scaled = scaler_features.transform(X_2)  # Nutze gleiche Skalierungsparameter ohne das X_Test Informationen einfließen\n",
    "\n",
    "# Initialisiere einen SEPARATEN MinMaxScaler für das Ziel\n",
    "scaler_target = MinMaxScaler()\n",
    "# Skaliere y_train und y_test. Beachte, dass y_train.reshape(-1, 1) verwendet wird, da MinMaxScaler \n",
    "# erwartet, dass die Eingaben als 2D-Arrays kommen, und Ziele normalerweise als 1D-Arrays vorliegen.\n",
    "y_train_scaled = scaler_target.fit_transform(y.values.reshape(-1, 1))\n",
    "y_test_scaled = scaler_target.transform(y_2.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbefe631e495b483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T21:12:58.269434700Z",
     "start_time": "2024-05-15T21:12:58.224012400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.        , 0.        , 0.33333333, 0.25      ],\n       [0.        , 0.01      , 0.33333333, 0.25      ],\n       [0.        , 0.02      , 0.33333333, 0.25      ],\n       ...,\n       [1.        , 0.98      , 0.33333333, 0.25      ],\n       [1.        , 0.99      , 0.33333333, 0.25      ],\n       [1.        , 1.        , 0.33333333, 0.25      ]])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_scaled.max()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T12:13:56.711875Z",
     "start_time": "2024-05-07T12:13:56.658947Z"
    }
   },
   "id": "ce04ce43aac2242f"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:0.14308\n",
      "[1]\teval-rmse:0.14296\n",
      "[2]\teval-rmse:0.14284\n",
      "[3]\teval-rmse:0.14273\n",
      "[4]\teval-rmse:0.14261\n",
      "[5]\teval-rmse:0.14250\n",
      "[6]\teval-rmse:0.14239\n",
      "[7]\teval-rmse:0.14227\n",
      "[8]\teval-rmse:0.14216\n",
      "[9]\teval-rmse:0.14204\n",
      "[10]\teval-rmse:0.14193\n",
      "[11]\teval-rmse:0.14182\n",
      "[12]\teval-rmse:0.14170\n",
      "[13]\teval-rmse:0.14159\n",
      "[14]\teval-rmse:0.14148\n",
      "[15]\teval-rmse:0.14137\n",
      "[16]\teval-rmse:0.14126\n",
      "[17]\teval-rmse:0.14114\n",
      "[18]\teval-rmse:0.14103\n",
      "[19]\teval-rmse:0.14092\n",
      "[20]\teval-rmse:0.14081\n",
      "[21]\teval-rmse:0.14070\n",
      "[22]\teval-rmse:0.14059\n",
      "[23]\teval-rmse:0.14048\n",
      "[24]\teval-rmse:0.14037\n",
      "[25]\teval-rmse:0.14026\n",
      "[26]\teval-rmse:0.14015\n",
      "[27]\teval-rmse:0.14004\n",
      "[28]\teval-rmse:0.13994\n",
      "[29]\teval-rmse:0.13983\n",
      "[30]\teval-rmse:0.13972\n",
      "[31]\teval-rmse:0.13961\n",
      "[32]\teval-rmse:0.13950\n",
      "[33]\teval-rmse:0.13940\n",
      "[34]\teval-rmse:0.13929\n",
      "[35]\teval-rmse:0.13918\n",
      "[36]\teval-rmse:0.13908\n",
      "[37]\teval-rmse:0.13897\n",
      "[38]\teval-rmse:0.13886\n",
      "[39]\teval-rmse:0.13876\n",
      "[40]\teval-rmse:0.13865\n",
      "[41]\teval-rmse:0.13855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [23:13:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42]\teval-rmse:0.13844\n",
      "[43]\teval-rmse:0.13834\n",
      "[44]\teval-rmse:0.13823\n",
      "[45]\teval-rmse:0.13813\n",
      "[46]\teval-rmse:0.13802\n",
      "[47]\teval-rmse:0.13792\n",
      "[48]\teval-rmse:0.13782\n",
      "[49]\teval-rmse:0.13771\n",
      "[50]\teval-rmse:0.13761\n",
      "[51]\teval-rmse:0.13751\n",
      "[52]\teval-rmse:0.13740\n",
      "[53]\teval-rmse:0.13730\n",
      "[54]\teval-rmse:0.13720\n",
      "[55]\teval-rmse:0.13710\n",
      "[56]\teval-rmse:0.13700\n",
      "[57]\teval-rmse:0.13690\n",
      "[58]\teval-rmse:0.13679\n",
      "[59]\teval-rmse:0.13669\n",
      "[60]\teval-rmse:0.13659\n",
      "[61]\teval-rmse:0.13649\n",
      "[62]\teval-rmse:0.13639\n",
      "[63]\teval-rmse:0.13629\n",
      "[64]\teval-rmse:0.13619\n",
      "[65]\teval-rmse:0.13609\n",
      "[66]\teval-rmse:0.13600\n",
      "[67]\teval-rmse:0.13590\n",
      "[68]\teval-rmse:0.13580\n",
      "[69]\teval-rmse:0.13570\n",
      "[70]\teval-rmse:0.13560\n",
      "[71]\teval-rmse:0.13550\n",
      "[72]\teval-rmse:0.13541\n",
      "[73]\teval-rmse:0.13531\n",
      "[74]\teval-rmse:0.13521\n",
      "[75]\teval-rmse:0.13511\n",
      "[76]\teval-rmse:0.13502\n",
      "[77]\teval-rmse:0.13492\n",
      "[78]\teval-rmse:0.13483\n",
      "[79]\teval-rmse:0.13473\n",
      "[80]\teval-rmse:0.13463\n",
      "[81]\teval-rmse:0.13454\n",
      "[82]\teval-rmse:0.13444\n",
      "[83]\teval-rmse:0.13435\n",
      "[84]\teval-rmse:0.13425\n",
      "[85]\teval-rmse:0.13416\n",
      "[86]\teval-rmse:0.13407\n",
      "[87]\teval-rmse:0.13397\n",
      "[88]\teval-rmse:0.13388\n",
      "[89]\teval-rmse:0.13378\n",
      "[90]\teval-rmse:0.13369\n",
      "[91]\teval-rmse:0.13360\n",
      "[92]\teval-rmse:0.13351\n",
      "[93]\teval-rmse:0.13341\n",
      "[94]\teval-rmse:0.13332\n",
      "[95]\teval-rmse:0.13323\n",
      "[96]\teval-rmse:0.13314\n",
      "[97]\teval-rmse:0.13305\n",
      "[98]\teval-rmse:0.13296\n",
      "[99]\teval-rmse:0.13286\n",
      "[100]\teval-rmse:0.13277\n",
      "[101]\teval-rmse:0.13268\n",
      "[102]\teval-rmse:0.13259\n",
      "[103]\teval-rmse:0.13250\n",
      "[104]\teval-rmse:0.13241\n",
      "[105]\teval-rmse:0.13232\n",
      "[106]\teval-rmse:0.13223\n",
      "[107]\teval-rmse:0.13215\n",
      "[108]\teval-rmse:0.13206\n",
      "[109]\teval-rmse:0.13197\n",
      "[110]\teval-rmse:0.13188\n",
      "[111]\teval-rmse:0.13179\n",
      "[112]\teval-rmse:0.13170\n",
      "[113]\teval-rmse:0.13162\n",
      "[114]\teval-rmse:0.13153\n",
      "[115]\teval-rmse:0.13144\n",
      "[116]\teval-rmse:0.13135\n",
      "[117]\teval-rmse:0.13127\n",
      "[118]\teval-rmse:0.13118\n",
      "[119]\teval-rmse:0.13110\n",
      "[120]\teval-rmse:0.13101\n",
      "[121]\teval-rmse:0.13092\n",
      "[122]\teval-rmse:0.13084\n",
      "[123]\teval-rmse:0.13075\n",
      "[124]\teval-rmse:0.13067\n",
      "[125]\teval-rmse:0.13058\n",
      "[126]\teval-rmse:0.13050\n",
      "[127]\teval-rmse:0.13041\n",
      "[128]\teval-rmse:0.13033\n",
      "[129]\teval-rmse:0.13025\n",
      "[130]\teval-rmse:0.13016\n",
      "[131]\teval-rmse:0.13008\n",
      "[132]\teval-rmse:0.13000\n",
      "[133]\teval-rmse:0.12991\n",
      "[134]\teval-rmse:0.12983\n",
      "[135]\teval-rmse:0.12975\n",
      "[136]\teval-rmse:0.12967\n",
      "[137]\teval-rmse:0.12958\n",
      "[138]\teval-rmse:0.12950\n",
      "[139]\teval-rmse:0.12942\n",
      "[140]\teval-rmse:0.12934\n",
      "[141]\teval-rmse:0.12926\n",
      "[142]\teval-rmse:0.12918\n",
      "[143]\teval-rmse:0.12910\n",
      "[144]\teval-rmse:0.12902\n",
      "[145]\teval-rmse:0.12894\n",
      "[146]\teval-rmse:0.12886\n",
      "[147]\teval-rmse:0.12878\n",
      "[148]\teval-rmse:0.12870\n",
      "[149]\teval-rmse:0.12862\n",
      "[150]\teval-rmse:0.12854\n",
      "[151]\teval-rmse:0.12846\n",
      "[152]\teval-rmse:0.12838\n",
      "[153]\teval-rmse:0.12830\n",
      "[154]\teval-rmse:0.12823\n",
      "[155]\teval-rmse:0.12815\n",
      "[156]\teval-rmse:0.12807\n",
      "[157]\teval-rmse:0.12799\n",
      "[158]\teval-rmse:0.12792\n",
      "[159]\teval-rmse:0.12784\n",
      "[160]\teval-rmse:0.12776\n",
      "[161]\teval-rmse:0.12769\n",
      "[162]\teval-rmse:0.12761\n",
      "[163]\teval-rmse:0.12753\n",
      "[164]\teval-rmse:0.12746\n",
      "[165]\teval-rmse:0.12738\n",
      "[166]\teval-rmse:0.12731\n",
      "[167]\teval-rmse:0.12723\n",
      "[168]\teval-rmse:0.12716\n",
      "[169]\teval-rmse:0.12708\n",
      "[170]\teval-rmse:0.12701\n",
      "[171]\teval-rmse:0.12693\n",
      "[172]\teval-rmse:0.12686\n",
      "[173]\teval-rmse:0.12679\n",
      "[174]\teval-rmse:0.12671\n",
      "[175]\teval-rmse:0.12664\n",
      "[176]\teval-rmse:0.12657\n",
      "[177]\teval-rmse:0.12649\n",
      "[178]\teval-rmse:0.12642\n",
      "[179]\teval-rmse:0.12635\n",
      "[180]\teval-rmse:0.12628\n",
      "[181]\teval-rmse:0.12620\n",
      "[182]\teval-rmse:0.12613\n",
      "[183]\teval-rmse:0.12606\n",
      "[184]\teval-rmse:0.12599\n",
      "[185]\teval-rmse:0.12592\n",
      "[186]\teval-rmse:0.12585\n",
      "[187]\teval-rmse:0.12578\n",
      "[188]\teval-rmse:0.12571\n",
      "[189]\teval-rmse:0.12564\n",
      "[190]\teval-rmse:0.12557\n",
      "[191]\teval-rmse:0.12550\n",
      "[192]\teval-rmse:0.12543\n",
      "[193]\teval-rmse:0.12536\n",
      "[194]\teval-rmse:0.12529\n",
      "[195]\teval-rmse:0.12522\n",
      "[196]\teval-rmse:0.12515\n",
      "[197]\teval-rmse:0.12508\n",
      "[198]\teval-rmse:0.12501\n",
      "[199]\teval-rmse:0.12495\n",
      "[200]\teval-rmse:0.12488\n",
      "[201]\teval-rmse:0.12481\n",
      "[202]\teval-rmse:0.12474\n",
      "[203]\teval-rmse:0.12468\n",
      "[204]\teval-rmse:0.12461\n",
      "[205]\teval-rmse:0.12454\n",
      "[206]\teval-rmse:0.12447\n",
      "[207]\teval-rmse:0.12441\n",
      "[208]\teval-rmse:0.12434\n",
      "[209]\teval-rmse:0.12428\n",
      "[210]\teval-rmse:0.12421\n",
      "[211]\teval-rmse:0.12414\n",
      "[212]\teval-rmse:0.12408\n",
      "[213]\teval-rmse:0.12401\n",
      "[214]\teval-rmse:0.12395\n",
      "[215]\teval-rmse:0.12389\n",
      "[216]\teval-rmse:0.12382\n",
      "[217]\teval-rmse:0.12376\n",
      "[218]\teval-rmse:0.12369\n",
      "[219]\teval-rmse:0.12363\n",
      "[220]\teval-rmse:0.12356\n",
      "[221]\teval-rmse:0.12350\n",
      "[222]\teval-rmse:0.12344\n",
      "[223]\teval-rmse:0.12337\n",
      "[224]\teval-rmse:0.12331\n",
      "[225]\teval-rmse:0.12325\n",
      "[226]\teval-rmse:0.12319\n",
      "[227]\teval-rmse:0.12313\n",
      "[228]\teval-rmse:0.12306\n",
      "[229]\teval-rmse:0.12300\n",
      "[230]\teval-rmse:0.12294\n",
      "[231]\teval-rmse:0.12288\n",
      "[232]\teval-rmse:0.12282\n",
      "[233]\teval-rmse:0.12276\n",
      "[234]\teval-rmse:0.12270\n",
      "[235]\teval-rmse:0.12264\n",
      "[236]\teval-rmse:0.12257\n",
      "[237]\teval-rmse:0.12251\n",
      "[238]\teval-rmse:0.12245\n",
      "[239]\teval-rmse:0.12240\n",
      "[240]\teval-rmse:0.12234\n",
      "[241]\teval-rmse:0.12228\n",
      "[242]\teval-rmse:0.12222\n",
      "[243]\teval-rmse:0.12216\n",
      "[244]\teval-rmse:0.12210\n",
      "[245]\teval-rmse:0.12204\n",
      "[246]\teval-rmse:0.12198\n",
      "[247]\teval-rmse:0.12193\n",
      "[248]\teval-rmse:0.12187\n",
      "[249]\teval-rmse:0.12181\n",
      "[250]\teval-rmse:0.12175\n",
      "[251]\teval-rmse:0.12169\n",
      "[252]\teval-rmse:0.12164\n",
      "[253]\teval-rmse:0.12158\n",
      "[254]\teval-rmse:0.12152\n",
      "[255]\teval-rmse:0.12147\n",
      "[256]\teval-rmse:0.12141\n",
      "[257]\teval-rmse:0.12136\n",
      "[258]\teval-rmse:0.12130\n",
      "[259]\teval-rmse:0.12124\n",
      "[260]\teval-rmse:0.12119\n",
      "[261]\teval-rmse:0.12113\n",
      "[262]\teval-rmse:0.12108\n",
      "[263]\teval-rmse:0.12102\n",
      "[264]\teval-rmse:0.12097\n",
      "[265]\teval-rmse:0.12091\n",
      "[266]\teval-rmse:0.12086\n",
      "[267]\teval-rmse:0.12081\n",
      "[268]\teval-rmse:0.12075\n",
      "[269]\teval-rmse:0.12070\n",
      "[270]\teval-rmse:0.12064\n",
      "[271]\teval-rmse:0.12059\n",
      "[272]\teval-rmse:0.12054\n",
      "[273]\teval-rmse:0.12048\n",
      "[274]\teval-rmse:0.12043\n",
      "[275]\teval-rmse:0.12038\n",
      "[276]\teval-rmse:0.12033\n",
      "[277]\teval-rmse:0.12028\n",
      "[278]\teval-rmse:0.12022\n",
      "[279]\teval-rmse:0.12017\n",
      "[280]\teval-rmse:0.12012\n",
      "[281]\teval-rmse:0.12007\n",
      "[282]\teval-rmse:0.12002\n",
      "[283]\teval-rmse:0.11997\n",
      "[284]\teval-rmse:0.11992\n",
      "[285]\teval-rmse:0.11987\n",
      "[286]\teval-rmse:0.11982\n",
      "[287]\teval-rmse:0.11977\n",
      "[288]\teval-rmse:0.11972\n",
      "[289]\teval-rmse:0.11967\n",
      "[290]\teval-rmse:0.11962\n",
      "[291]\teval-rmse:0.11957\n",
      "[292]\teval-rmse:0.11952\n",
      "[293]\teval-rmse:0.11947\n",
      "[294]\teval-rmse:0.11942\n",
      "[295]\teval-rmse:0.11937\n",
      "[296]\teval-rmse:0.11932\n",
      "[297]\teval-rmse:0.11927\n",
      "[298]\teval-rmse:0.11923\n",
      "[299]\teval-rmse:0.11918\n",
      "[300]\teval-rmse:0.11913\n",
      "[301]\teval-rmse:0.11908\n",
      "[302]\teval-rmse:0.11904\n",
      "[303]\teval-rmse:0.11899\n",
      "[304]\teval-rmse:0.11894\n",
      "[305]\teval-rmse:0.11890\n",
      "[306]\teval-rmse:0.11885\n",
      "[307]\teval-rmse:0.11880\n",
      "[308]\teval-rmse:0.11876\n",
      "[309]\teval-rmse:0.11871\n",
      "[310]\teval-rmse:0.11866\n",
      "[311]\teval-rmse:0.11862\n",
      "[312]\teval-rmse:0.11857\n",
      "[313]\teval-rmse:0.11853\n",
      "[314]\teval-rmse:0.11848\n",
      "[315]\teval-rmse:0.11844\n",
      "[316]\teval-rmse:0.11839\n",
      "[317]\teval-rmse:0.11835\n",
      "[318]\teval-rmse:0.11831\n",
      "[319]\teval-rmse:0.11826\n",
      "[320]\teval-rmse:0.11822\n",
      "[321]\teval-rmse:0.11817\n",
      "[322]\teval-rmse:0.11813\n",
      "[323]\teval-rmse:0.11809\n",
      "[324]\teval-rmse:0.11804\n",
      "[325]\teval-rmse:0.11800\n",
      "[326]\teval-rmse:0.11796\n",
      "[327]\teval-rmse:0.11792\n",
      "[328]\teval-rmse:0.11787\n",
      "[329]\teval-rmse:0.11783\n",
      "[330]\teval-rmse:0.11779\n",
      "[331]\teval-rmse:0.11775\n",
      "[332]\teval-rmse:0.11770\n",
      "[333]\teval-rmse:0.11766\n",
      "[334]\teval-rmse:0.11762\n",
      "[335]\teval-rmse:0.11758\n",
      "[336]\teval-rmse:0.11754\n",
      "[337]\teval-rmse:0.11750\n",
      "[338]\teval-rmse:0.11746\n",
      "[339]\teval-rmse:0.11742\n",
      "[340]\teval-rmse:0.11738\n",
      "[341]\teval-rmse:0.11734\n",
      "[342]\teval-rmse:0.11730\n",
      "[343]\teval-rmse:0.11726\n",
      "[344]\teval-rmse:0.11722\n",
      "[345]\teval-rmse:0.11718\n",
      "[346]\teval-rmse:0.11714\n",
      "[347]\teval-rmse:0.11710\n",
      "[348]\teval-rmse:0.11706\n",
      "[349]\teval-rmse:0.11702\n",
      "[350]\teval-rmse:0.11698\n",
      "[351]\teval-rmse:0.11694\n",
      "[352]\teval-rmse:0.11691\n",
      "[353]\teval-rmse:0.11687\n",
      "[354]\teval-rmse:0.11683\n",
      "[355]\teval-rmse:0.11679\n",
      "[356]\teval-rmse:0.11675\n",
      "[357]\teval-rmse:0.11672\n",
      "[358]\teval-rmse:0.11668\n",
      "[359]\teval-rmse:0.11664\n",
      "[360]\teval-rmse:0.11661\n",
      "[361]\teval-rmse:0.11657\n",
      "[362]\teval-rmse:0.11653\n",
      "[363]\teval-rmse:0.11649\n",
      "[364]\teval-rmse:0.11646\n",
      "[365]\teval-rmse:0.11642\n",
      "[366]\teval-rmse:0.11638\n",
      "[367]\teval-rmse:0.11635\n",
      "[368]\teval-rmse:0.11631\n",
      "[369]\teval-rmse:0.11628\n",
      "[370]\teval-rmse:0.11624\n",
      "[371]\teval-rmse:0.11620\n",
      "[372]\teval-rmse:0.11617\n",
      "[373]\teval-rmse:0.11613\n",
      "[374]\teval-rmse:0.11610\n",
      "[375]\teval-rmse:0.11606\n",
      "[376]\teval-rmse:0.11603\n",
      "[377]\teval-rmse:0.11600\n",
      "[378]\teval-rmse:0.11596\n",
      "[379]\teval-rmse:0.11593\n",
      "[380]\teval-rmse:0.11589\n",
      "[381]\teval-rmse:0.11586\n",
      "[382]\teval-rmse:0.11582\n",
      "[383]\teval-rmse:0.11579\n",
      "[384]\teval-rmse:0.11576\n",
      "[385]\teval-rmse:0.11572\n",
      "[386]\teval-rmse:0.11569\n",
      "[387]\teval-rmse:0.11566\n",
      "[388]\teval-rmse:0.11563\n",
      "[389]\teval-rmse:0.11559\n",
      "[390]\teval-rmse:0.11556\n",
      "[391]\teval-rmse:0.11553\n",
      "[392]\teval-rmse:0.11550\n",
      "[393]\teval-rmse:0.11546\n",
      "[394]\teval-rmse:0.11543\n",
      "[395]\teval-rmse:0.11540\n",
      "[396]\teval-rmse:0.11537\n",
      "[397]\teval-rmse:0.11534\n",
      "[398]\teval-rmse:0.11531\n",
      "[399]\teval-rmse:0.11528\n",
      "[400]\teval-rmse:0.11525\n",
      "[401]\teval-rmse:0.11522\n",
      "[402]\teval-rmse:0.11519\n",
      "[403]\teval-rmse:0.11516\n",
      "[404]\teval-rmse:0.11512\n",
      "[405]\teval-rmse:0.11509\n",
      "[406]\teval-rmse:0.11507\n",
      "[407]\teval-rmse:0.11504\n",
      "[408]\teval-rmse:0.11501\n",
      "[409]\teval-rmse:0.11498\n",
      "[410]\teval-rmse:0.11495\n",
      "[411]\teval-rmse:0.11492\n",
      "[412]\teval-rmse:0.11489\n",
      "[413]\teval-rmse:0.11486\n",
      "[414]\teval-rmse:0.11483\n",
      "[415]\teval-rmse:0.11480\n",
      "[416]\teval-rmse:0.11478\n",
      "[417]\teval-rmse:0.11475\n",
      "[418]\teval-rmse:0.11472\n",
      "[419]\teval-rmse:0.11469\n",
      "[420]\teval-rmse:0.11466\n",
      "[421]\teval-rmse:0.11464\n",
      "[422]\teval-rmse:0.11461\n",
      "[423]\teval-rmse:0.11458\n",
      "[424]\teval-rmse:0.11456\n",
      "[425]\teval-rmse:0.11453\n",
      "[426]\teval-rmse:0.11450\n",
      "[427]\teval-rmse:0.11447\n",
      "[428]\teval-rmse:0.11445\n",
      "[429]\teval-rmse:0.11442\n",
      "[430]\teval-rmse:0.11440\n",
      "[431]\teval-rmse:0.11437\n",
      "[432]\teval-rmse:0.11434\n",
      "[433]\teval-rmse:0.11432\n",
      "[434]\teval-rmse:0.11429\n",
      "[435]\teval-rmse:0.11427\n",
      "[436]\teval-rmse:0.11424\n",
      "[437]\teval-rmse:0.11422\n",
      "[438]\teval-rmse:0.11419\n",
      "[439]\teval-rmse:0.11417\n",
      "[440]\teval-rmse:0.11414\n",
      "[441]\teval-rmse:0.11412\n",
      "[442]\teval-rmse:0.11409\n",
      "[443]\teval-rmse:0.11407\n",
      "[444]\teval-rmse:0.11405\n",
      "[445]\teval-rmse:0.11402\n",
      "[446]\teval-rmse:0.11400\n",
      "[447]\teval-rmse:0.11397\n",
      "[448]\teval-rmse:0.11395\n",
      "[449]\teval-rmse:0.11393\n",
      "[450]\teval-rmse:0.11390\n",
      "[451]\teval-rmse:0.11388\n",
      "[452]\teval-rmse:0.11386\n",
      "[453]\teval-rmse:0.11383\n",
      "[454]\teval-rmse:0.11381\n",
      "[455]\teval-rmse:0.11379\n",
      "[456]\teval-rmse:0.11377\n",
      "[457]\teval-rmse:0.11374\n",
      "[458]\teval-rmse:0.11372\n",
      "[459]\teval-rmse:0.11370\n",
      "[460]\teval-rmse:0.11368\n",
      "[461]\teval-rmse:0.11366\n",
      "[462]\teval-rmse:0.11363\n",
      "[463]\teval-rmse:0.11361\n",
      "[464]\teval-rmse:0.11359\n",
      "[465]\teval-rmse:0.11357\n",
      "[466]\teval-rmse:0.11355\n",
      "[467]\teval-rmse:0.11353\n",
      "[468]\teval-rmse:0.11351\n",
      "[469]\teval-rmse:0.11349\n",
      "[470]\teval-rmse:0.11347\n",
      "[471]\teval-rmse:0.11345\n",
      "[472]\teval-rmse:0.11343\n",
      "[473]\teval-rmse:0.11341\n",
      "[474]\teval-rmse:0.11339\n",
      "[475]\teval-rmse:0.11337\n",
      "[476]\teval-rmse:0.11335\n",
      "[477]\teval-rmse:0.11333\n",
      "[478]\teval-rmse:0.11331\n",
      "[479]\teval-rmse:0.11329\n",
      "[480]\teval-rmse:0.11327\n",
      "[481]\teval-rmse:0.11325\n",
      "[482]\teval-rmse:0.11323\n",
      "[483]\teval-rmse:0.11321\n",
      "[484]\teval-rmse:0.11319\n",
      "[485]\teval-rmse:0.11317\n",
      "[486]\teval-rmse:0.11315\n",
      "[487]\teval-rmse:0.11314\n",
      "[488]\teval-rmse:0.11312\n",
      "[489]\teval-rmse:0.11310\n",
      "[490]\teval-rmse:0.11308\n",
      "[491]\teval-rmse:0.11306\n",
      "[492]\teval-rmse:0.11305\n",
      "[493]\teval-rmse:0.11303\n",
      "[494]\teval-rmse:0.11301\n",
      "[495]\teval-rmse:0.11299\n",
      "[496]\teval-rmse:0.11298\n",
      "[497]\teval-rmse:0.11296\n",
      "[498]\teval-rmse:0.11294\n",
      "[499]\teval-rmse:0.11293\n",
      "[500]\teval-rmse:0.11291\n",
      "[501]\teval-rmse:0.11289\n",
      "[502]\teval-rmse:0.11288\n",
      "[503]\teval-rmse:0.11286\n",
      "[504]\teval-rmse:0.11284\n",
      "[505]\teval-rmse:0.11283\n",
      "[506]\teval-rmse:0.11281\n",
      "[507]\teval-rmse:0.11280\n",
      "[508]\teval-rmse:0.11278\n",
      "[509]\teval-rmse:0.11276\n",
      "[510]\teval-rmse:0.11275\n",
      "[511]\teval-rmse:0.11273\n",
      "[512]\teval-rmse:0.11272\n",
      "[513]\teval-rmse:0.11270\n",
      "[514]\teval-rmse:0.11269\n",
      "[515]\teval-rmse:0.11267\n",
      "[516]\teval-rmse:0.11266\n",
      "[517]\teval-rmse:0.11264\n",
      "[518]\teval-rmse:0.11263\n",
      "[519]\teval-rmse:0.11262\n",
      "[520]\teval-rmse:0.11260\n",
      "[521]\teval-rmse:0.11259\n",
      "[522]\teval-rmse:0.11257\n",
      "[523]\teval-rmse:0.11256\n",
      "[524]\teval-rmse:0.11255\n",
      "[525]\teval-rmse:0.11253\n",
      "[526]\teval-rmse:0.11252\n",
      "[527]\teval-rmse:0.11251\n",
      "[528]\teval-rmse:0.11249\n",
      "[529]\teval-rmse:0.11248\n",
      "[530]\teval-rmse:0.11247\n",
      "[531]\teval-rmse:0.11245\n",
      "[532]\teval-rmse:0.11244\n",
      "[533]\teval-rmse:0.11243\n",
      "[534]\teval-rmse:0.11242\n",
      "[535]\teval-rmse:0.11240\n",
      "[536]\teval-rmse:0.11239\n",
      "[537]\teval-rmse:0.11238\n",
      "[538]\teval-rmse:0.11237\n",
      "[539]\teval-rmse:0.11236\n",
      "[540]\teval-rmse:0.11234\n",
      "[541]\teval-rmse:0.11233\n",
      "[542]\teval-rmse:0.11232\n",
      "[543]\teval-rmse:0.11231\n",
      "[544]\teval-rmse:0.11230\n",
      "[545]\teval-rmse:0.11229\n",
      "[546]\teval-rmse:0.11228\n",
      "[547]\teval-rmse:0.11226\n",
      "[548]\teval-rmse:0.11225\n",
      "[549]\teval-rmse:0.11224\n",
      "[550]\teval-rmse:0.11223\n",
      "[551]\teval-rmse:0.11222\n",
      "[552]\teval-rmse:0.11221\n",
      "[553]\teval-rmse:0.11220\n",
      "[554]\teval-rmse:0.11219\n",
      "[555]\teval-rmse:0.11218\n",
      "[556]\teval-rmse:0.11217\n",
      "[557]\teval-rmse:0.11216\n",
      "[558]\teval-rmse:0.11215\n",
      "[559]\teval-rmse:0.11214\n",
      "[560]\teval-rmse:0.11213\n",
      "[561]\teval-rmse:0.11212\n",
      "[562]\teval-rmse:0.11211\n",
      "[563]\teval-rmse:0.11210\n",
      "[564]\teval-rmse:0.11210\n",
      "[565]\teval-rmse:0.11209\n",
      "[566]\teval-rmse:0.11208\n",
      "[567]\teval-rmse:0.11207\n",
      "[568]\teval-rmse:0.11206\n",
      "[569]\teval-rmse:0.11205\n",
      "[570]\teval-rmse:0.11204\n",
      "[571]\teval-rmse:0.11203\n",
      "[572]\teval-rmse:0.11203\n",
      "[573]\teval-rmse:0.11202\n",
      "[574]\teval-rmse:0.11201\n",
      "[575]\teval-rmse:0.11200\n",
      "[576]\teval-rmse:0.11199\n",
      "[577]\teval-rmse:0.11199\n",
      "[578]\teval-rmse:0.11198\n",
      "[579]\teval-rmse:0.11197\n",
      "[580]\teval-rmse:0.11196\n",
      "[581]\teval-rmse:0.11196\n",
      "[582]\teval-rmse:0.11195\n",
      "[583]\teval-rmse:0.11194\n",
      "[584]\teval-rmse:0.11193\n",
      "[585]\teval-rmse:0.11193\n",
      "[586]\teval-rmse:0.11192\n",
      "[587]\teval-rmse:0.11191\n",
      "[588]\teval-rmse:0.11191\n",
      "[589]\teval-rmse:0.11190\n",
      "[590]\teval-rmse:0.11189\n",
      "[591]\teval-rmse:0.11189\n",
      "[592]\teval-rmse:0.11188\n",
      "[593]\teval-rmse:0.11188\n",
      "[594]\teval-rmse:0.11187\n",
      "[595]\teval-rmse:0.11186\n",
      "[596]\teval-rmse:0.11186\n",
      "[597]\teval-rmse:0.11185\n",
      "[598]\teval-rmse:0.11185\n",
      "[599]\teval-rmse:0.11184\n",
      "[600]\teval-rmse:0.11184\n",
      "[601]\teval-rmse:0.11183\n",
      "[602]\teval-rmse:0.11182\n",
      "[603]\teval-rmse:0.11182\n",
      "[604]\teval-rmse:0.11181\n",
      "[605]\teval-rmse:0.11181\n",
      "[606]\teval-rmse:0.11180\n",
      "[607]\teval-rmse:0.11180\n",
      "[608]\teval-rmse:0.11179\n",
      "[609]\teval-rmse:0.11179\n",
      "[610]\teval-rmse:0.11179\n",
      "[611]\teval-rmse:0.11178\n",
      "[612]\teval-rmse:0.11178\n",
      "[613]\teval-rmse:0.11177\n",
      "[614]\teval-rmse:0.11177\n",
      "[615]\teval-rmse:0.11176\n",
      "[616]\teval-rmse:0.11176\n",
      "[617]\teval-rmse:0.11176\n",
      "[618]\teval-rmse:0.11175\n",
      "[619]\teval-rmse:0.11175\n",
      "[620]\teval-rmse:0.11175\n",
      "[621]\teval-rmse:0.11174\n",
      "[622]\teval-rmse:0.11174\n",
      "[623]\teval-rmse:0.11174\n",
      "[624]\teval-rmse:0.11173\n",
      "[625]\teval-rmse:0.11173\n",
      "[626]\teval-rmse:0.11173\n",
      "[627]\teval-rmse:0.11172\n",
      "[628]\teval-rmse:0.11172\n",
      "[629]\teval-rmse:0.11172\n",
      "[630]\teval-rmse:0.11172\n",
      "[631]\teval-rmse:0.11171\n",
      "[632]\teval-rmse:0.11171\n",
      "[633]\teval-rmse:0.11171\n",
      "[634]\teval-rmse:0.11171\n",
      "[635]\teval-rmse:0.11170\n",
      "[636]\teval-rmse:0.11170\n",
      "[637]\teval-rmse:0.11170\n",
      "[638]\teval-rmse:0.11170\n",
      "[639]\teval-rmse:0.11170\n",
      "[640]\teval-rmse:0.11169\n",
      "[641]\teval-rmse:0.11169\n",
      "[642]\teval-rmse:0.11169\n",
      "[643]\teval-rmse:0.11169\n",
      "[644]\teval-rmse:0.11169\n",
      "[645]\teval-rmse:0.11169\n",
      "[646]\teval-rmse:0.11169\n",
      "[647]\teval-rmse:0.11168\n",
      "[648]\teval-rmse:0.11168\n",
      "[649]\teval-rmse:0.11168\n",
      "[650]\teval-rmse:0.11168\n",
      "[651]\teval-rmse:0.11168\n",
      "[652]\teval-rmse:0.11168\n",
      "[653]\teval-rmse:0.11168\n",
      "[654]\teval-rmse:0.11168\n",
      "[655]\teval-rmse:0.11168\n",
      "[656]\teval-rmse:0.11168\n",
      "[657]\teval-rmse:0.11168\n",
      "[658]\teval-rmse:0.11168\n",
      "[659]\teval-rmse:0.11168\n",
      "[660]\teval-rmse:0.11168\n",
      "[661]\teval-rmse:0.11168\n",
      "[662]\teval-rmse:0.11168\n",
      "[663]\teval-rmse:0.11168\n",
      "[664]\teval-rmse:0.11168\n",
      "[665]\teval-rmse:0.11168\n",
      "[666]\teval-rmse:0.11168\n",
      "[667]\teval-rmse:0.11168\n",
      "[668]\teval-rmse:0.11168\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "\n",
    "# Erstellen eines DMatrix-Objekts; XGBoost optimiert die Leistung und Effizienz über seine eigene Datenstruktur\n",
    "dtrain = xgb.DMatrix(X_train_scaled, label=y_train_scaled)\n",
    "dval = xgb.DMatrix(X_test_scaled, label=y_test_scaled)\n",
    "\n",
    "# Parameter für XGBoost; diese können je nach Bedarf angepasst werden\n",
    "params = {\n",
    "    'max_depth': 10,  # Maximale Tiefe der Bäume\n",
    "    'objective': 'reg:squarederror',  # Regression mit quadratischem Fehler\n",
    "    'learning_rate': 0.001,\n",
    "    'n_estimators': 1000\n",
    "}\n",
    "\n",
    "# Training des Modells mit früherem Stopp, um Overfitting zu vermeiden\n",
    "model = xgb.train(params, dtrain, num_boost_round=1000, evals=[(dval, 'eval')],\n",
    "                  early_stopping_rounds=10)\n",
    "\n",
    "# Speichern des Modells\n",
    "model.save_model('xgb_model.json')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T21:13:33.153294500Z",
     "start_time": "2024-05-15T21:13:29.485470300Z"
    }
   },
   "id": "87e87fd5011da14b"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.012473166097423128\n",
      "Mean Absolute Error: 0.10028950277131032\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Vorhersagen machen\n",
    "preds = model.predict(dval)\n",
    "\n",
    "# Berechnen der Metriken\n",
    "mse = mean_squared_error(y_test_scaled, preds)\n",
    "mae = mean_absolute_error(y_test_scaled, preds)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T21:13:36.644012Z",
     "start_time": "2024-05-15T21:13:36.573970200Z"
    }
   },
   "id": "ec93e79ec153a757"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0476 - mae: 0.0996 - val_loss: 0.0151 - val_mae: 0.0194\n",
      "Epoch 2/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0140 - mae: 0.0138 - val_loss: 0.0131 - val_mae: 0.0090\n",
      "Epoch 3/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0127 - mae: 0.0105 - val_loss: 0.0123 - val_mae: 0.0113\n",
      "Epoch 4/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0118 - mae: 0.0099 - val_loss: 0.0113 - val_mae: 0.0090\n",
      "Epoch 5/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0110 - mae: 0.0094 - val_loss: 0.0105 - val_mae: 0.0068\n",
      "Epoch 6/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0102 - mae: 0.0089 - val_loss: 0.0098 - val_mae: 0.0094\n",
      "Epoch 7/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0095 - mae: 0.0084 - val_loss: 0.0092 - val_mae: 0.0089\n",
      "Epoch 8/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0089 - mae: 0.0079 - val_loss: 0.0085 - val_mae: 0.0051\n",
      "Epoch 9/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0082 - mae: 0.0073 - val_loss: 0.0081 - val_mae: 0.0122\n",
      "Epoch 10/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0077 - mae: 0.0066 - val_loss: 0.0074 - val_mae: 0.0051\n",
      "Epoch 11/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0072 - mae: 0.0072 - val_loss: 0.0069 - val_mae: 0.0033\n",
      "Epoch 12/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0068 - mae: 0.0061 - val_loss: 0.0065 - val_mae: 0.0052\n",
      "Epoch 13/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0064 - mae: 0.0065 - val_loss: 0.0063 - val_mae: 0.0101\n",
      "Epoch 14/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0060 - mae: 0.0058 - val_loss: 0.0059 - val_mae: 0.0084\n",
      "Epoch 15/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0057 - mae: 0.0056 - val_loss: 0.0055 - val_mae: 0.0038\n",
      "Epoch 16/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0054 - mae: 0.0054 - val_loss: 0.0052 - val_mae: 0.0049\n",
      "Epoch 17/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0051 - mae: 0.0045 - val_loss: 0.0049 - val_mae: 0.0037\n",
      "Epoch 18/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0048 - mae: 0.0052 - val_loss: 0.0046 - val_mae: 0.0031\n",
      "Epoch 19/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0045 - mae: 0.0055 - val_loss: 0.0044 - val_mae: 0.0037\n",
      "Epoch 20/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0043 - mae: 0.0047 - val_loss: 0.0041 - val_mae: 0.0034\n",
      "Epoch 21/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0041 - mae: 0.0043 - val_loss: 0.0039 - val_mae: 0.0040\n",
      "Epoch 22/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0039 - mae: 0.0045 - val_loss: 0.0037 - val_mae: 0.0056\n",
      "Epoch 23/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0036 - mae: 0.0043 - val_loss: 0.0035 - val_mae: 0.0022\n",
      "Epoch 24/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0035 - mae: 0.0047 - val_loss: 0.0033 - val_mae: 0.0028\n",
      "Epoch 25/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0033 - mae: 0.0038 - val_loss: 0.0031 - val_mae: 0.0027\n",
      "Epoch 26/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0031 - mae: 0.0039 - val_loss: 0.0030 - val_mae: 0.0048\n",
      "Epoch 27/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0029 - mae: 0.0042 - val_loss: 0.0028 - val_mae: 0.0020\n",
      "Epoch 28/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0028 - mae: 0.0039 - val_loss: 0.0027 - val_mae: 0.0025\n",
      "Epoch 29/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0027 - mae: 0.0039 - val_loss: 0.0026 - val_mae: 0.0035\n",
      "Epoch 30/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0025 - mae: 0.0033 - val_loss: 0.0024 - val_mae: 0.0025\n",
      "Epoch 31/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0024 - mae: 0.0035 - val_loss: 0.0023 - val_mae: 0.0042\n",
      "Epoch 32/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0023 - mae: 0.0037 - val_loss: 0.0022 - val_mae: 0.0052\n",
      "Epoch 33/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0022 - mae: 0.0038 - val_loss: 0.0021 - val_mae: 0.0024\n",
      "Epoch 34/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0021 - mae: 0.0035 - val_loss: 0.0020 - val_mae: 0.0027\n",
      "Epoch 35/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0020 - mae: 0.0037 - val_loss: 0.0019 - val_mae: 0.0037\n",
      "Epoch 36/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0019 - mae: 0.0033 - val_loss: 0.0018 - val_mae: 0.0045\n",
      "Epoch 37/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0018 - mae: 0.0037 - val_loss: 0.0017 - val_mae: 0.0036\n",
      "Epoch 38/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0017 - mae: 0.0035 - val_loss: 0.0017 - val_mae: 0.0027\n",
      "Epoch 39/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0017 - mae: 0.0032 - val_loss: 0.0016 - val_mae: 0.0051\n",
      "Epoch 40/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0016 - mae: 0.0032 - val_loss: 0.0015 - val_mae: 0.0024\n",
      "Epoch 41/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0015 - mae: 0.0034 - val_loss: 0.0015 - val_mae: 0.0027\n",
      "Epoch 42/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0014 - mae: 0.0032 - val_loss: 0.0014 - val_mae: 0.0027\n",
      "Epoch 43/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0014 - mae: 0.0033 - val_loss: 0.0013 - val_mae: 0.0029\n",
      "Epoch 44/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0013 - mae: 0.0031 - val_loss: 0.0013 - val_mae: 0.0049\n",
      "Epoch 45/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0013 - mae: 0.0031 - val_loss: 0.0012 - val_mae: 0.0020\n",
      "Epoch 46/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0012 - mae: 0.0032 - val_loss: 0.0012 - val_mae: 0.0023\n",
      "Epoch 47/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0012 - mae: 0.0029 - val_loss: 0.0011 - val_mae: 0.0023\n",
      "Epoch 48/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0011 - mae: 0.0032 - val_loss: 0.0011 - val_mae: 0.0021\n",
      "Epoch 49/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0011 - mae: 0.0035 - val_loss: 0.0010 - val_mae: 0.0031\n",
      "Epoch 50/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0010 - mae: 0.0029 - val_loss: 0.0010 - val_mae: 0.0022\n",
      "Epoch 51/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0010 - mae: 0.0030 - val_loss: 9.6845e-04 - val_mae: 0.0021\n",
      "Epoch 52/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 9.7411e-04 - mae: 0.0029 - val_loss: 9.3422e-04 - val_mae: 0.0018\n",
      "Epoch 53/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 9.3976e-04 - mae: 0.0030 - val_loss: 9.0180e-04 - val_mae: 0.0021\n",
      "Epoch 54/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 9.0587e-04 - mae: 0.0029 - val_loss: 8.7195e-04 - val_mae: 0.0021\n",
      "Epoch 55/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 8.7960e-04 - mae: 0.0032 - val_loss: 8.4266e-04 - val_mae: 0.0022\n",
      "Epoch 56/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 8.4775e-04 - mae: 0.0031 - val_loss: 8.1093e-04 - val_mae: 0.0018\n",
      "Epoch 57/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 8.1443e-04 - mae: 0.0027 - val_loss: 7.8849e-04 - val_mae: 0.0022\n",
      "Epoch 58/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.9279e-04 - mae: 0.0030 - val_loss: 0.0011 - val_mae: 0.0134\n",
      "Epoch 59/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.6210e-04 - mae: 0.0029 - val_loss: 7.3636e-04 - val_mae: 0.0023\n",
      "Epoch 60/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.3979e-04 - mae: 0.0028 - val_loss: 7.3761e-04 - val_mae: 0.0048\n",
      "Epoch 61/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.1884e-04 - mae: 0.0029 - val_loss: 7.1415e-04 - val_mae: 0.0047\n",
      "Epoch 62/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.9205e-04 - mae: 0.0026 - val_loss: 6.6995e-04 - val_mae: 0.0023\n",
      "Epoch 63/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.7820e-04 - mae: 0.0030 - val_loss: 6.4630e-04 - val_mae: 0.0017\n",
      "Epoch 64/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.5552e-04 - mae: 0.0029 - val_loss: 6.2780e-04 - val_mae: 0.0019\n",
      "Epoch 65/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.3595e-04 - mae: 0.0027 - val_loss: 6.1384e-04 - val_mae: 0.0027\n",
      "Epoch 66/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.1684e-04 - mae: 0.0027 - val_loss: 5.9335e-04 - val_mae: 0.0021\n",
      "Epoch 67/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.0347e-04 - mae: 0.0027 - val_loss: 5.7620e-04 - val_mae: 0.0020\n",
      "Epoch 68/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.8512e-04 - mae: 0.0026 - val_loss: 5.6277e-04 - val_mae: 0.0022\n",
      "Epoch 69/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.6966e-04 - mae: 0.0027 - val_loss: 5.4758e-04 - val_mae: 0.0021\n",
      "Epoch 70/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.5817e-04 - mae: 0.0028 - val_loss: 5.3203e-04 - val_mae: 0.0018\n",
      "Epoch 71/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.3850e-04 - mae: 0.0027 - val_loss: 5.1671e-04 - val_mae: 0.0017\n",
      "Epoch 72/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.3600e-04 - mae: 0.0029 - val_loss: 5.0758e-04 - val_mae: 0.0023\n",
      "Epoch 73/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.1326e-04 - mae: 0.0026 - val_loss: 4.9450e-04 - val_mae: 0.0020\n",
      "Epoch 74/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.0132e-04 - mae: 0.0026 - val_loss: 8.0750e-04 - val_mae: 0.0160\n",
      "Epoch 75/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.9100e-04 - mae: 0.0026 - val_loss: 4.6821e-04 - val_mae: 0.0017\n",
      "Epoch 76/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.7957e-04 - mae: 0.0026 - val_loss: 4.6144e-04 - val_mae: 0.0025\n",
      "Epoch 77/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.6960e-04 - mae: 0.0027 - val_loss: 4.4893e-04 - val_mae: 0.0020\n",
      "Epoch 78/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.5842e-04 - mae: 0.0027 - val_loss: 4.3665e-04 - val_mae: 0.0017\n",
      "Epoch 79/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.4781e-04 - mae: 0.0026 - val_loss: 4.5416e-04 - val_mae: 0.0053\n",
      "Epoch 80/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.3948e-04 - mae: 0.0029 - val_loss: 4.2155e-04 - val_mae: 0.0025\n",
      "Epoch 81/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.2934e-04 - mae: 0.0026 - val_loss: 4.1501e-04 - val_mae: 0.0030\n",
      "Epoch 82/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.1640e-04 - mae: 0.0025 - val_loss: 4.3974e-04 - val_mae: 0.0060\n",
      "Epoch 83/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.1144e-04 - mae: 0.0026 - val_loss: 3.9063e-04 - val_mae: 0.0017\n",
      "Epoch 84/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.0814e-04 - mae: 0.0028 - val_loss: 3.8327e-04 - val_mae: 0.0019\n",
      "Epoch 85/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.9324e-04 - mae: 0.0025 - val_loss: 3.7739e-04 - val_mae: 0.0021\n",
      "Epoch 86/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.8661e-04 - mae: 0.0025 - val_loss: 3.6820e-04 - val_mae: 0.0018\n",
      "Epoch 87/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.7816e-04 - mae: 0.0026 - val_loss: 3.9167e-04 - val_mae: 0.0045\n",
      "Epoch 88/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.7297e-04 - mae: 0.0027 - val_loss: 3.5346e-04 - val_mae: 0.0018\n",
      "Epoch 89/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.6662e-04 - mae: 0.0027 - val_loss: 3.4806e-04 - val_mae: 0.0020\n",
      "Epoch 90/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.6025e-04 - mae: 0.0026 - val_loss: 3.4368e-04 - val_mae: 0.0024\n",
      "Epoch 91/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.5354e-04 - mae: 0.0026 - val_loss: 3.3833e-04 - val_mae: 0.0025\n",
      "Epoch 92/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.4869e-04 - mae: 0.0026 - val_loss: 3.2798e-04 - val_mae: 0.0016\n",
      "Epoch 93/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.4317e-04 - mae: 0.0026 - val_loss: 3.2524e-04 - val_mae: 0.0021\n",
      "Epoch 94/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.3142e-04 - mae: 0.0024 - val_loss: 3.1717e-04 - val_mae: 0.0018\n",
      "Epoch 95/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.2881e-04 - mae: 0.0025 - val_loss: 3.1236e-04 - val_mae: 0.0018\n",
      "Epoch 96/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.2654e-04 - mae: 0.0027 - val_loss: 3.0685e-04 - val_mae: 0.0018\n",
      "Epoch 97/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.1945e-04 - mae: 0.0025 - val_loss: 3.0149e-04 - val_mae: 0.0016\n",
      "Epoch 98/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.1309e-04 - mae: 0.0025 - val_loss: 3.0033e-04 - val_mae: 0.0023\n",
      "Epoch 99/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.0970e-04 - mae: 0.0025 - val_loss: 2.9846e-04 - val_mae: 0.0026\n",
      "Epoch 100/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.0620e-04 - mae: 0.0026 - val_loss: 3.0450e-04 - val_mae: 0.0041\n",
      "Epoch 101/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.0192e-04 - mae: 0.0026 - val_loss: 2.8367e-04 - val_mae: 0.0017\n",
      "Epoch 102/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.9741e-04 - mae: 0.0026 - val_loss: 2.7956e-04 - val_mae: 0.0016\n",
      "Epoch 103/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.9645e-04 - mae: 0.0027 - val_loss: 2.7717e-04 - val_mae: 0.0018\n",
      "Epoch 104/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.8658e-04 - mae: 0.0024 - val_loss: 2.7429e-04 - val_mae: 0.0021\n",
      "Epoch 105/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.8379e-04 - mae: 0.0025 - val_loss: 2.7494e-04 - val_mae: 0.0026\n",
      "Epoch 106/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.8110e-04 - mae: 0.0026 - val_loss: 2.6748e-04 - val_mae: 0.0022\n",
      "Epoch 107/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.7829e-04 - mae: 0.0027 - val_loss: 2.6130e-04 - val_mae: 0.0017\n",
      "Epoch 108/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.7623e-04 - mae: 0.0026 - val_loss: 3.0734e-04 - val_mae: 0.0058\n",
      "Epoch 109/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.7166e-04 - mae: 0.0025 - val_loss: 2.5603e-04 - val_mae: 0.0018\n",
      "Epoch 110/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.6828e-04 - mae: 0.0024 - val_loss: 2.5437e-04 - val_mae: 0.0021\n",
      "Epoch 111/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.6382e-04 - mae: 0.0025 - val_loss: 2.5126e-04 - val_mae: 0.0020\n",
      "Epoch 112/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.6193e-04 - mae: 0.0024 - val_loss: 2.4605e-04 - val_mae: 0.0017\n",
      "Epoch 113/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.5655e-04 - mae: 0.0024 - val_loss: 2.4795e-04 - val_mae: 0.0025\n",
      "Epoch 114/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.6053e-04 - mae: 0.0028 - val_loss: 2.4187e-04 - val_mae: 0.0019\n",
      "Epoch 115/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.5197e-04 - mae: 0.0025 - val_loss: 2.4457e-04 - val_mae: 0.0028\n",
      "Epoch 116/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.5259e-04 - mae: 0.0026 - val_loss: 2.3565e-04 - val_mae: 0.0017\n",
      "Epoch 117/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.4649e-04 - mae: 0.0024 - val_loss: 2.3481e-04 - val_mae: 0.0021\n",
      "Epoch 118/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.4581e-04 - mae: 0.0025 - val_loss: 2.3527e-04 - val_mae: 0.0028\n",
      "Epoch 119/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.4331e-04 - mae: 0.0025 - val_loss: 2.2873e-04 - val_mae: 0.0018\n",
      "Epoch 120/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3991e-04 - mae: 0.0024 - val_loss: 2.2799e-04 - val_mae: 0.0022\n",
      "Epoch 121/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3636e-04 - mae: 0.0024 - val_loss: 2.2318e-04 - val_mae: 0.0017\n",
      "Epoch 122/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.4078e-04 - mae: 0.0027 - val_loss: 2.2172e-04 - val_mae: 0.0019\n",
      "Epoch 123/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3363e-04 - mae: 0.0025 - val_loss: 2.1946e-04 - val_mae: 0.0018\n",
      "Epoch 124/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3309e-04 - mae: 0.0026 - val_loss: 2.1831e-04 - val_mae: 0.0020\n",
      "Epoch 125/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2972e-04 - mae: 0.0024 - val_loss: 2.1484e-04 - val_mae: 0.0016\n",
      "Epoch 126/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2721e-04 - mae: 0.0025 - val_loss: 2.1271e-04 - val_mae: 0.0016\n",
      "Epoch 127/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2806e-04 - mae: 0.0026 - val_loss: 2.1104e-04 - val_mae: 0.0017\n",
      "Epoch 128/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2344e-04 - mae: 0.0024 - val_loss: 2.0939e-04 - val_mae: 0.0017\n",
      "Epoch 129/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2294e-04 - mae: 0.0025 - val_loss: 2.1578e-04 - val_mae: 0.0030\n",
      "Epoch 130/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2224e-04 - mae: 0.0025 - val_loss: 2.0511e-04 - val_mae: 0.0015\n",
      "Epoch 131/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1567e-04 - mae: 0.0023 - val_loss: 2.0600e-04 - val_mae: 0.0022\n",
      "Epoch 132/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1755e-04 - mae: 0.0025 - val_loss: 2.0734e-04 - val_mae: 0.0027\n",
      "Epoch 133/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1545e-04 - mae: 0.0025 - val_loss: 2.0644e-04 - val_mae: 0.0027\n",
      "Epoch 134/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1526e-04 - mae: 0.0026 - val_loss: 2.1107e-04 - val_mae: 0.0033\n",
      "Epoch 135/1000\n",
      "1417/1426 [============================>.] - ETA: 0s - loss: 2.1274e-04 - mae: 0.0026Restoring model weights from the end of the best epoch: 130.\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1431e-04 - mae: 0.0026 - val_loss: 2.1677e-04 - val_mae: 0.0044\n",
      "Epoch 135: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Netzwerkarchitektur\n",
    "model = Sequential([\n",
    "\n",
    "    Dense(136, activation='relu', input_shape=(4,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(216, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(104, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(328, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(8, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(120, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(1 , activation = 'linear')\n",
    "])\n",
    "\n",
    "# Optimierer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)  #0.0001\n",
    "\n",
    "# Modell kompilieren (Verwendung von mean_squared_error als Verlustfunktion für Regression)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])  # Metriken für Regression: Mean Absolute Error und Mean Squared Error\n",
    "\n",
    "# Early Stopping Callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "# Trainingsparameter\n",
    "batch_size = 25   #25\n",
    "epochs = 1000\n",
    "\n",
    "# Modell trainieren (Annahme: X_train, y_train, X_val, y_val sind vordefiniert)\n",
    "history = model.fit(X_train_scaled, y_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "model.save('D3_I_F_1.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T22:04:58.050954900Z",
     "start_time": "2024-04-02T21:58:11.072240100Z"
    }
   },
   "id": "8b52e1a9a6ff3aeb"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('Trainierte_Netze/D3_I_F_1.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T11:05:27.977393700Z",
     "start_time": "2024-04-19T11:05:27.651427100Z"
    }
   },
   "id": "696599f12f5114e9"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Initialisiere Listen, um Ergebnisse zu speichern\n",
    "val_loss_results = []\n",
    "val_mae_results = []\n",
    "\n",
    "# Funktion, um das Modell zu erstellen\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "            Dense(136, activation='relu', input_shape=(4,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "            Dense(216, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "            Dense(104, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "            Dense(328, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "            Dense(8, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "            Dense(120, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "            Dense(1 , activation = 'linear')\n",
    "\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# K-Fold Cross-Validation Konfiguration\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Leistungsüberwachung\n",
    "fold_no = 1\n",
    "for train_index, val_index in kf.split(X_train_scaled):\n",
    "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_scaled[train_index], y_train_scaled[val_index]\n",
    "\n",
    "    model = create_model()\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "    print(f'Training für Fold {fold_no}...')\n",
    "    history = model.fit(X_train_fold, y_train_fold, batch_size=25, epochs=1000, validation_data=(X_val_fold, y_val_fold), callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "    # Speichere die Ergebnisse des aktuellen Folds\n",
    "    val_loss_results.append(min(history.history['val_loss']))\n",
    "    val_mae_results.append(min(history.history['val_mae']))\n",
    "\n",
    "    fold_no += 1\n",
    "\n",
    "# Berechne den Durchschnitt über alle Folds\n",
    "average_val_loss = np.mean(val_loss_results)\n",
    "average_val_mae = np.mean(val_mae_results)\n",
    "# \n",
    "# Umwandeln der Listen in Pandas DataFrames\n",
    "val_loss_df = pd.DataFrame(val_loss_results, columns=['Validation Loss'])\n",
    "val_mae_df = pd.DataFrame(val_mae_results, columns=['Validation MAE'])\n",
    "\n",
    "# Speichern der DataFrames in CSV-Dateien\n",
    "val_loss_df.to_csv('val_loss_results_D3_I_F_1.csv', index=False)\n",
    "val_mae_df.to_csv('val_mae_results_D3_I_F_1.csv', index=False)\n",
    "\n",
    "# Gib die durchschnittlichen Ergebnisse aus\n",
    "print(f'Durchschnittlicher Validation Loss: {average_val_loss}')\n",
    "print(f'Durchschnittlicher Validation MAE: {average_val_mae}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T11:05:29.215395600Z",
     "start_time": "2024-04-19T11:05:29.181384Z"
    }
   },
   "id": "7ff728388210d66b"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "199/199 - 1s - loss: 2.0120e-04 - mae: 0.0029 - 514ms/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.00020120339468121529, 0.002875363687053323]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Auswertung auf dem Testdatensatz\n",
    "results = model.evaluate(X_test_scaled, y_test_scaled, verbose=2)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T11:05:30.299335400Z",
     "start_time": "2024-04-19T11:05:29.711151700Z"
    }
   },
   "id": "9050ab66ab36f169"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bsp. Predicted: [721.09924] Actual: [735.96] \n",
      "Durchschnittliche Abweichung (MAE): [7.41038792]\n",
      "0.5500216618740962\n"
     ]
    }
   ],
   "source": [
    "#Berechnung des MAE und MAPE\n",
    "scaled_predicted_values = model.predict(X_test_scaled, verbose = 0)\n",
    "\n",
    "# Rücktransformation der skalierten Werte \n",
    "original_predicted_values = scaler_target.inverse_transform(scaled_predicted_values)\n",
    "original_actual_values = scaler_target.inverse_transform(y_test_scaled)  # y_test sind die skalierten tatsächlichen Werte\n",
    "print(f' Bsp. Predicted: {original_predicted_values[100]} Actual: {original_actual_values[100]} ')\n",
    "\n",
    "def calculate_mae(list1, list2):\n",
    "    # Stelle sicher, dass beide Listen die gleiche Länge haben\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Listen müssen die gleiche Länge haben\")\n",
    "\n",
    "    # Berechne die absolute Differenz zwischen den Elementen der Listen\n",
    "    differences = [abs(x - y) for x, y in zip(list1, list2)]\n",
    "\n",
    "    # Berechne den Durchschnitt der absoluten Differenzen\n",
    "    mae = sum(differences) / len(differences)\n",
    "\n",
    "    return mae\n",
    "\n",
    "# Beispiel\n",
    "list1 = original_predicted_values\n",
    "list2 = original_actual_values\n",
    "\n",
    "mae = calculate_mae(list1, list2)\n",
    "print(f\"Durchschnittliche Abweichung (MAE): {mae}\")\n",
    "\n",
    "errors = np.abs((original_actual_values - original_predicted_values) / original_actual_values)\n",
    "mape = np.mean(errors) * 100\n",
    "print(mape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T11:05:31.968618600Z",
     "start_time": "2024-04-19T11:05:31.611293600Z"
    }
   },
   "id": "10cd79ca028075dd"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: [0.99918974]\n"
     ]
    }
   ],
   "source": [
    "# R^2 Berechnung\n",
    "def calculate_r_squared(predicted, actual):\n",
    "    # Berechnung des Mittelwerts der tatsächlichen Werte\n",
    "    mean_actual = sum(actual) / len(actual)\n",
    "    \n",
    "    # Berechnung der totalen Summe der Quadrate (SST)\n",
    "    sst = sum((x - mean_actual) ** 2 for x in actual)\n",
    "    \n",
    "    # Berechnung der Summe der Quadrate der Residuen (SSE)\n",
    "    sse = sum((actual[i] - predicted[i]) ** 2 for i in range(len(actual)))\n",
    "    \n",
    "    # Berechnung des R^2-Wertes\n",
    "    r_squared = 1 - (sse / sst)\n",
    "    \n",
    "    return r_squared\n",
    "\n",
    "# Berechnung von R^2 mit den bereitgestellten Listen\n",
    "r_squared = calculate_r_squared(list1, list2)\n",
    "\n",
    "print(f\"R^2: {r_squared}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T11:05:34.915096900Z",
     "start_time": "2024-04-19T11:05:34.848574400Z"
    }
   },
   "id": "d0505d16afcbef4a"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Werte die kleiner sind: 514\n"
     ]
    },
    {
     "data": {
      "text/plain": "        Echt   Temperatur  X-Koordinate  Y-Koordinate  Differenz\n1358  1981.0  1980.999390      0.209677          0.45   0.000610\n1431  1519.8  1519.797241      0.225806          0.17   0.002759\n3675  1858.6  1858.595947      0.580645          0.39   0.004053\n5739  1287.7  1287.704468      0.903226          0.83   0.004468\n661   1975.7  1975.707397      0.096774          0.55   0.007397\n...      ...          ...           ...           ...        ...\n6325  1613.1  1574.510498      1.000000          0.63  38.589502\n6295  1606.5  1567.853394      1.000000          0.33  38.646606\n6324  1623.3  1584.372925      1.000000          0.62  38.927075\n6297  1627.0  1588.036499      1.000000          0.35  38.963501\n6296  1617.1  1578.115234      1.000000          0.34  38.984766\n\n[6363 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Echt</th>\n      <th>Temperatur</th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Differenz</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1358</th>\n      <td>1981.0</td>\n      <td>1980.999390</td>\n      <td>0.209677</td>\n      <td>0.45</td>\n      <td>0.000610</td>\n    </tr>\n    <tr>\n      <th>1431</th>\n      <td>1519.8</td>\n      <td>1519.797241</td>\n      <td>0.225806</td>\n      <td>0.17</td>\n      <td>0.002759</td>\n    </tr>\n    <tr>\n      <th>3675</th>\n      <td>1858.6</td>\n      <td>1858.595947</td>\n      <td>0.580645</td>\n      <td>0.39</td>\n      <td>0.004053</td>\n    </tr>\n    <tr>\n      <th>5739</th>\n      <td>1287.7</td>\n      <td>1287.704468</td>\n      <td>0.903226</td>\n      <td>0.83</td>\n      <td>0.004468</td>\n    </tr>\n    <tr>\n      <th>661</th>\n      <td>1975.7</td>\n      <td>1975.707397</td>\n      <td>0.096774</td>\n      <td>0.55</td>\n      <td>0.007397</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6325</th>\n      <td>1613.1</td>\n      <td>1574.510498</td>\n      <td>1.000000</td>\n      <td>0.63</td>\n      <td>38.589502</td>\n    </tr>\n    <tr>\n      <th>6295</th>\n      <td>1606.5</td>\n      <td>1567.853394</td>\n      <td>1.000000</td>\n      <td>0.33</td>\n      <td>38.646606</td>\n    </tr>\n    <tr>\n      <th>6324</th>\n      <td>1623.3</td>\n      <td>1584.372925</td>\n      <td>1.000000</td>\n      <td>0.62</td>\n      <td>38.927075</td>\n    </tr>\n    <tr>\n      <th>6297</th>\n      <td>1627.0</td>\n      <td>1588.036499</td>\n      <td>1.000000</td>\n      <td>0.35</td>\n      <td>38.963501</td>\n    </tr>\n    <tr>\n      <th>6296</th>\n      <td>1617.1</td>\n      <td>1578.115234</td>\n      <td>1.000000</td>\n      <td>0.34</td>\n      <td>38.984766</td>\n    </tr>\n  </tbody>\n</table>\n<p>6363 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Überprüfung der maximalen Unterschiede zwischen Echt und Vorhergesagt\n",
    "df_result = pd.DataFrame({'Echt': [val[0] for val in list2], 'Temperatur': [val[0] for val in list1]})\n",
    "df_result['X-Koordinate'] = X_test_scaled[:, 0]\n",
    "df_result['Y-Koordinate'] = X_test_scaled[:, 1]\n",
    "df_result['Differenz'] = abs(df_result['Echt'] - df_result['Temperatur'])\n",
    "df_result['Differenz'].sort_values()\n",
    "sorted_df = df_result.sort_values(by= 'Differenz')\n",
    "Anzahl_Punkte = (sorted_df['Differenz'] > 20).sum()\n",
    "print(\"Anzahl der Werte die kleiner sind:\", Anzahl_Punkte)\n",
    "\n",
    "sorted_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T11:05:36.459809200Z",
     "start_time": "2024-04-19T11:05:36.425023400Z"
    }
   },
   "id": "47d4a39665ed1159"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "#Speichern der Vorhersage\n",
    "# df_test['Vorhergesagt'] = list1\n",
    "# df_test.to_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_I7000_F6000_D3_500_I_F_PKL_Prediction.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T11:57:37.051326700Z",
     "start_time": "2024-04-08T11:57:37.018612Z"
    }
   },
   "id": "73defb2e4e9a45da"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#Trainingsverlauf\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m mse \u001B[38;5;241m=\u001B[39m \u001B[43mhistory\u001B[49m\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      3\u001B[0m val_mse \u001B[38;5;241m=\u001B[39m history\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      5\u001B[0m epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mlen\u001B[39m(mse) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "#Trainingsverlauf\n",
    "mse = history.history['loss']\n",
    "val_mse = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(mse) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, mse, 'r', label='Training MSE')\n",
    "plt.plot(epochs, val_mse, 'b', label='Validation MSE')\n",
    "plt.title('Training and Validation MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T11:06:59.988163500Z",
     "start_time": "2024-04-19T11:06:59.896462700Z"
    }
   },
   "id": "3688dd7102e95baf"
  },
  {
   "cell_type": "markdown",
   "id": "553df6fa",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "def build_model(learning_rate=0.001, activation='relu', regularization=0.0001, dropout_rate=0.0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(136, activation=activation, input_shape=(4,), kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(216, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(104, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(328, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(8, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(120, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "model = KerasRegressor(model=build_model, verbose=2)\n",
    "\n",
    "# Anpassung der Parameter im param_grid\n",
    "param_grid = {\n",
    "    'model__learning_rate': [0.01, 0.001, 0.0001],\n",
    "    'model__regularization': [0.001, 0.0001, 0.00001],\n",
    "    'fit__batch_size': [25, 50, 75, 100],\n",
    "    'fit__epochs': [50],\n",
    "    'model__dropout_rate' : [0.0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=2)\n",
    "# Hinweis: Sicherstellen, dass Daten (X_train_scaled, y_train_scaled) korrekt definiert sind\n",
    "grid_result = grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "# Beste Parameter und Score ausgeben\n",
    "print(\"Beste Parameter:\", grid_search.best_params_)\n",
    "print(\"Beste Genauigkeit:\", grid_search.best_score_)\n",
    "\n",
    "with open(\"Gridsearch_D3_I_F_1.txt\", \"w\") as f:\n",
    "    f.write(f\"Beste Parameter: {grid_search.best_params_}\\n\")\n",
    "    f.write(f\"Beste Genauigkeit: {grid_search.best_score_}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:01:02.450167100Z",
     "start_time": "2024-03-15T10:01:02.439200700Z"
    }
   },
   "id": "578403f6e218787a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Search"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69b9aef262bcb2c3"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "492cf0ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T10:01:02.450167100Z",
     "start_time": "2024-03-15T10:01:02.443220200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Funktion zum Erstellen des Modells\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hp.Int('input_units', min_value=8, max_value=328, step=16), input_shape=(4,), activation='relu'))\n",
    "    for i in range(hp.Int('n_layers', 1, 10)):\n",
    "        model.add(Dense(hp.Int(f'units_{i}', min_value=8, max_value=328, step=16), activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Durchführung der Random Search dreimal\n",
    "for run in range(1, 4):\n",
    "    # Anpassen des Verzeichnisses und des Projektnamens für jeden Durchlauf\n",
    "    directory = 'random_search'\n",
    "    project_name = f'random_search_D3_I_F_1_{run}'\n",
    "\n",
    "    tuner = RandomSearch(\n",
    "        build_model, \n",
    "        objective='val_loss',\n",
    "        max_trials=100,\n",
    "        executions_per_trial=1,\n",
    "        directory=directory,\n",
    "        project_name=project_name\n",
    "    )\n",
    "\n",
    "    # Durchführung des Random Search\n",
    "    tuner.search(X_train_scaled, y_train_scaled, epochs=50, verbose =0, batch_size=50, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "\n",
    "    # Abrufen und Speichern des besten Modells\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "    model_path = os.path.join(directory, project_name, 'best_model.h5') \n",
    "    best_model.save(model_path)\n",
    "\n",
    "\n",
    "    # Optional: Abrufen und Ausgeben der besten Hyperparameter\n",
    "    best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "    # Konvertieren der Hyperparameter in ein DataFrame\n",
    "    df_hyperparameters = pd.DataFrame([best_hyperparameters.values])\n",
    "    # Speichern des DataFrame als CSV\n",
    "    df_hyperparameters.to_csv(f'random_search_D3_I_F_1_{run}.csv', index=False)\n",
    "\n",
    "    print(f\"Beste Hyperparameter für Lauf {run}: {best_hyperparameters.values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:01:02.450167100Z",
     "start_time": "2024-03-15T10:01:02.447649400Z"
    }
   },
   "id": "412f38f9b1e03d5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
