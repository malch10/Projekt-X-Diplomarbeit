{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94b0518e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T13:35:23.860641Z",
     "start_time": "2024-04-01T13:35:23.762298800Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense , Dropout\n",
    "from scikeras.wrappers import KerasRegressor \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4ff61b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T13:35:24.830539900Z",
     "start_time": "2024-04-01T13:35:24.666732400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n0             0.0000      -0.00200        100   6000   5000      449.80\n1             0.0000      -0.00192        100   6000   5000      479.76\n2             0.0000      -0.00184        100   6000   5000      506.60\n3             0.0000      -0.00176        100   6000   5000      530.80\n4             0.0000      -0.00168        100   6000   5000      552.15\n...              ...           ...        ...    ...    ...         ...\n351283        0.0024       0.00168        500   9000   5000     1365.50\n351284        0.0024       0.00176        500   9000   5000     1247.20\n351285        0.0024       0.00184        500   9000   5000     1114.10\n351286        0.0024       0.00192        500   9000   5000      983.97\n351287        0.0024       0.00200        500   9000   5000      942.84\n\n[351288 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>449.80</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0000</td>\n      <td>-0.00192</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>479.76</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0000</td>\n      <td>-0.00184</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>506.60</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0000</td>\n      <td>-0.00176</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>530.80</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0000</td>\n      <td>-0.00168</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>552.15</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>351283</th>\n      <td>0.0024</td>\n      <td>0.00168</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1365.50</td>\n    </tr>\n    <tr>\n      <th>351284</th>\n      <td>0.0024</td>\n      <td>0.00176</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1247.20</td>\n    </tr>\n    <tr>\n      <th>351285</th>\n      <td>0.0024</td>\n      <td>0.00184</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1114.10</td>\n    </tr>\n    <tr>\n      <th>351286</th>\n      <td>0.0024</td>\n      <td>0.00192</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>983.97</td>\n    </tr>\n    <tr>\n      <th>351287</th>\n      <td>0.0024</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>942.84</td>\n    </tr>\n  </tbody>\n</table>\n<p>351288 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/TPath_300_finish_data.pkl')\n",
    "data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_ALL_D3_500_I_F_PKL.pkl')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "966e3c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T11:41:41.938405100Z",
     "start_time": "2024-04-01T11:41:41.904939900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n",
      "1037169       0.00000      -0.00200        500   7000   6000      811.76\n",
      "1037170       0.00000      -0.00196        500   7000   6000      853.27\n",
      "1037171       0.00000      -0.00192        500   7000   6000      897.57\n",
      "1037172       0.00000      -0.00188        500   7000   6000      941.21\n",
      "1037173       0.00000      -0.00184        500   7000   6000      986.34\n",
      "...               ...           ...        ...    ...    ...         ...\n",
      "1043527       0.00248       0.00184        500   7000   6000      784.55\n",
      "1043528       0.00248       0.00188        500   7000   6000      745.87\n",
      "1043529       0.00248       0.00192        500   7000   6000      706.17\n",
      "1043530       0.00248       0.00196        500   7000   6000      693.28\n",
      "1043531       0.00248       0.00200        500   7000   6000      687.80\n",
      "\n",
      "[6363 rows x 6 columns]\n",
      "Empty DataFrame\n",
      "Columns: [X-Koordinate, Y-Koordinate, Zeitpunkt, Strom, Kraft, Temperatur]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/plain": "         X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n1037169       0.00000      -0.00200        500   7000   6000      811.76\n1037170       0.00000      -0.00196        500   7000   6000      853.27\n1037171       0.00000      -0.00192        500   7000   6000      897.57\n1037172       0.00000      -0.00188        500   7000   6000      941.21\n1037173       0.00000      -0.00184        500   7000   6000      986.34\n...               ...           ...        ...    ...    ...         ...\n1043527       0.00248       0.00184        500   7000   6000      784.55\n1043528       0.00248       0.00188        500   7000   6000      745.87\n1043529       0.00248       0.00192        500   7000   6000      706.17\n1043530       0.00248       0.00196        500   7000   6000      693.28\n1043531       0.00248       0.00200        500   7000   6000      687.80\n\n[6363 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1037169</th>\n      <td>0.00000</td>\n      <td>-0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>811.76</td>\n    </tr>\n    <tr>\n      <th>1037170</th>\n      <td>0.00000</td>\n      <td>-0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>853.27</td>\n    </tr>\n    <tr>\n      <th>1037171</th>\n      <td>0.00000</td>\n      <td>-0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>897.57</td>\n    </tr>\n    <tr>\n      <th>1037172</th>\n      <td>0.00000</td>\n      <td>-0.00188</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>941.21</td>\n    </tr>\n    <tr>\n      <th>1037173</th>\n      <td>0.00000</td>\n      <td>-0.00184</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>986.34</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1043527</th>\n      <td>0.00248</td>\n      <td>0.00184</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>784.55</td>\n    </tr>\n    <tr>\n      <th>1043528</th>\n      <td>0.00248</td>\n      <td>0.00188</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>745.87</td>\n    </tr>\n    <tr>\n      <th>1043529</th>\n      <td>0.00248</td>\n      <td>0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>706.17</td>\n    </tr>\n    <tr>\n      <th>1043530</th>\n      <td>0.00248</td>\n      <td>0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>693.28</td>\n    </tr>\n    <tr>\n      <th>1043531</th>\n      <td>0.00248</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>687.80</td>\n    </tr>\n  </tbody>\n</table>\n<p>6363 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedingung = (data['Kraft'] == 6000) & (data['Strom'] == 7000)\n",
    "df_test = data[bedingung].copy()\n",
    "print(df_test)\n",
    "#df_test.to_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_I7000_F6000_D3_500_I_F_PKL.pkl')\n",
    "data_all = data.drop(df_test.index)\n",
    "#print(data_all)\n",
    "print(data_all[(data_all['Kraft'] == 6000) & (data_all['Strom'] == 7000)])\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "         X-Koordinate  Y-Koordinate  Strom  Kraft    Temperatur\n254520        0.00000      -0.00200   6000   5000  7.535400e+02\n254521        0.00000      -0.00196   6000   5000  7.936300e+02\n254522        0.00000      -0.00192   6000   5000  8.356500e+02\n254523        0.00000      -0.00188   6000   5000  8.775000e+02\n254524        0.00000      -0.00184   6000   5000  9.199800e+02\n...               ...           ...    ...    ...           ...\n2087059       0.00248       0.00184   9000   5000  1.110600e+03\n2087060       0.00248       0.00188   9000   5000  1.046600e+03\n2087061       0.00248       0.00192   9000   5000  9.810900e+02\n2087062       0.00248       0.00196   9000   5000  7.888600e-31\n2087063       0.00248       0.00200   9000   5000  9.403500e+02\n\n[44541 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>254520</th>\n      <td>0.00000</td>\n      <td>-0.00200</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>7.535400e+02</td>\n    </tr>\n    <tr>\n      <th>254521</th>\n      <td>0.00000</td>\n      <td>-0.00196</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>7.936300e+02</td>\n    </tr>\n    <tr>\n      <th>254522</th>\n      <td>0.00000</td>\n      <td>-0.00192</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>8.356500e+02</td>\n    </tr>\n    <tr>\n      <th>254523</th>\n      <td>0.00000</td>\n      <td>-0.00188</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>8.775000e+02</td>\n    </tr>\n    <tr>\n      <th>254524</th>\n      <td>0.00000</td>\n      <td>-0.00184</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>9.199800e+02</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2087059</th>\n      <td>0.00248</td>\n      <td>0.00184</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1.110600e+03</td>\n    </tr>\n    <tr>\n      <th>2087060</th>\n      <td>0.00248</td>\n      <td>0.00188</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1.046600e+03</td>\n    </tr>\n    <tr>\n      <th>2087061</th>\n      <td>0.00248</td>\n      <td>0.00192</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>9.810900e+02</td>\n    </tr>\n    <tr>\n      <th>2087062</th>\n      <td>0.00248</td>\n      <td>0.00196</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>7.888600e-31</td>\n    </tr>\n    <tr>\n      <th>2087063</th>\n      <td>0.00248</td>\n      <td>0.00200</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>9.403500e+02</td>\n    </tr>\n  </tbody>\n</table>\n<p>44541 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all = data_all.drop('Zeitpunkt', axis = 1)\n",
    "data_all"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T11:41:41.958429500Z",
     "start_time": "2024-04-01T11:41:41.922469500Z"
    }
   },
   "id": "467c96c6df4a7dc9"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8783d1d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T11:41:42.018842800Z",
     "start_time": "2024-04-01T11:41:41.933405500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       X-Koordinate  Y-Koordinate  Strom  Kraft  Temperatur\n0           0.00112      -0.00064   6000   6000     1617.10\n1           0.00108      -0.00036   8000   7000     2058.20\n2           0.00136       0.00096   6000   6000     1420.30\n3           0.00064       0.00028   6000   5000     1829.90\n4           0.00048       0.00188   6000   6000      693.83\n...             ...           ...    ...    ...         ...\n44536       0.00248      -0.00188   6000   5000      842.80\n44537       0.00192       0.00092   6000   6000     1342.80\n44538       0.00248       0.00124   8000   7000     1434.90\n44539       0.00032       0.00008   6000   5000     1873.40\n44540       0.00120      -0.00044   7000   5000     2010.50\n\n[44541 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00112</td>\n      <td>-0.00064</td>\n      <td>6000</td>\n      <td>6000</td>\n      <td>1617.10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00108</td>\n      <td>-0.00036</td>\n      <td>8000</td>\n      <td>7000</td>\n      <td>2058.20</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00136</td>\n      <td>0.00096</td>\n      <td>6000</td>\n      <td>6000</td>\n      <td>1420.30</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00064</td>\n      <td>0.00028</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>1829.90</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00048</td>\n      <td>0.00188</td>\n      <td>6000</td>\n      <td>6000</td>\n      <td>693.83</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>44536</th>\n      <td>0.00248</td>\n      <td>-0.00188</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>842.80</td>\n    </tr>\n    <tr>\n      <th>44537</th>\n      <td>0.00192</td>\n      <td>0.00092</td>\n      <td>6000</td>\n      <td>6000</td>\n      <td>1342.80</td>\n    </tr>\n    <tr>\n      <th>44538</th>\n      <td>0.00248</td>\n      <td>0.00124</td>\n      <td>8000</td>\n      <td>7000</td>\n      <td>1434.90</td>\n    </tr>\n    <tr>\n      <th>44539</th>\n      <td>0.00032</td>\n      <td>0.00008</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>1873.40</td>\n    </tr>\n    <tr>\n      <th>44540</th>\n      <td>0.00120</td>\n      <td>-0.00044</td>\n      <td>7000</td>\n      <td>5000</td>\n      <td>2010.50</td>\n    </tr>\n  </tbody>\n</table>\n<p>44541 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all = data_all.sample(frac=1, random_state=42)  # Hier wird 42 als Random State verwendet, um die Ergebnisse reproduzierbar zu machen\n",
    "df_reset = data_all.reset_index(drop=True)\n",
    "df_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4e72a16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T11:41:42.018842800Z",
     "start_time": "2024-04-01T11:41:41.946886300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [X-Koordinate, Y-Koordinate, Strom, Kraft]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "y = df_reset[\"Temperatur\"]\n",
    "# Korrektur: Verwenden Sie den Spaltennamen direkt, ohne Indexierung der columns-Eigenschaft\n",
    "X = df_reset.drop(\"Temperatur\", axis=1)\n",
    "\n",
    "print(X[(X['Kraft'] == 6000) & (X['Strom'] == 7000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "label = df_test[\"Temperatur\"]\n",
    "# Korrektur: Verwenden Sie den Spaltennamen direkt, ohne Indexierung der columns-Eigenschaft\n",
    "X_2 = df_test.drop(\"Temperatur\", axis=1)\n",
    "X_2 = X_2.drop('Zeitpunkt',axis =1)\n",
    "X_2 = X_2.reset_index(drop=True)\n",
    "y_2 = label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T11:41:42.029842Z",
     "start_time": "2024-04-01T11:41:41.952304800Z"
    }
   },
   "id": "2920a35d3f81234d"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7fa289a50d87423"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e694a236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T11:41:42.082842500Z",
     "start_time": "2024-04-01T11:41:41.957428400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      X-Koordinate  Y-Koordinate  Strom  Kraft\n0          0.00000      -0.00200   7000   6000\n1          0.00000      -0.00196   7000   6000\n2          0.00000      -0.00192   7000   6000\n3          0.00000      -0.00188   7000   6000\n4          0.00000      -0.00184   7000   6000\n...            ...           ...    ...    ...\n6358       0.00248       0.00184   7000   6000\n6359       0.00248       0.00188   7000   6000\n6360       0.00248       0.00192   7000   6000\n6361       0.00248       0.00196   7000   6000\n6362       0.00248       0.00200   7000   6000\n\n[6363 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00000</td>\n      <td>-0.00200</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00000</td>\n      <td>-0.00196</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00000</td>\n      <td>-0.00192</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00000</td>\n      <td>-0.00188</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00000</td>\n      <td>-0.00184</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6358</th>\n      <td>0.00248</td>\n      <td>0.00184</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>6359</th>\n      <td>0.00248</td>\n      <td>0.00188</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>6360</th>\n      <td>0.00248</td>\n      <td>0.00192</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>6361</th>\n      <td>0.00248</td>\n      <td>0.00196</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>6362</th>\n      <td>0.00248</td>\n      <td>0.00200</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n  </tbody>\n</table>\n<p>6363 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f3303b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T11:41:42.083841900Z",
     "start_time": "2024-04-01T11:41:41.966142Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0        1617.10\n1        2058.20\n2        1420.30\n3        1829.90\n4         693.83\n          ...   \n44536     842.80\n44537    1342.80\n44538    1434.90\n44539    1873.40\n44540    2010.50\nName: Temperatur, Length: 44541, dtype: float64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3ad8da0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T11:41:42.083841900Z",
     "start_time": "2024-04-01T11:41:41.971294600Z"
    }
   },
   "outputs": [],
   "source": [
    " # train_df enthÃ¤lt 80% der Daten, test_df enthÃ¤lt 20% der Daten\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T11:41:42.083841900Z",
     "start_time": "2024-04-01T11:41:41.975718600Z"
    }
   },
   "id": "b78be1fe68aa0b4a"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c705edb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T11:41:42.083841900Z",
     "start_time": "2024-04-01T11:41:41.979730800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialisiere einen MinMaxScaler fÃ¼r die Features\n",
    "scaler_features = MinMaxScaler()\n",
    "scaler_features2 = MinMaxScaler()\n",
    "# Skaliere X_train und X_test\n",
    "X_train_scaled = scaler_features.fit_transform(X)\n",
    "#X_test_scaled = scaler_features.transform(X_test)  # Nutze gleiche Skalierungsparameter ohne das X_Test Informationen einflieÃŸen\n",
    "X_test_scaled_2 = scaler_features.transform(X_2)  # Nutze gleiche Skalierungsparameter ohne das X_Test Informationen einflieÃŸen\n",
    "\n",
    "# Initialisiere einen SEPARATEN MinMaxScaler fÃ¼r das Ziel, wenn nÃ¶tig\n",
    "scaler_target = MinMaxScaler()\n",
    "\n",
    "\n",
    "# Skaliere y_train und y_test. Beachte, dass y_train.reshape(-1, 1) verwendet wird, da MinMaxScaler \n",
    "# erwartet, dass die Eingaben als 2D-Arrays kommen, und Ziele normalerweise als 1D-Arrays vorliegen.\n",
    "y_train_scaled = scaler_target.fit_transform(y.values.reshape(-1, 1))\n",
    "#y_test_scaled = scaler_target.transform(y_test.values.reshape(-1, 1))\n",
    "y_test_scaled_2 = scaler_target.transform(y_2.values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbefe631e495b483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T11:41:42.083841900Z",
     "start_time": "2024-04-01T11:41:41.987570300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.        , 0.        , 0.33333333, 0.25      ],\n       [0.        , 0.01      , 0.33333333, 0.25      ],\n       [0.        , 0.02      , 0.33333333, 0.25      ],\n       ...,\n       [1.        , 0.98      , 0.33333333, 0.25      ],\n       [1.        , 0.99      , 0.33333333, 0.25      ],\n       [1.        , 1.        , 0.33333333, 0.25      ]])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_scaled.max()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T11:41:42.084842600Z",
     "start_time": "2024-04-01T11:41:41.993841900Z"
    }
   },
   "id": "ce04ce43aac2242f"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.1333 - mae: 0.2625 - val_loss: 0.0461 - val_mae: 0.1473\n",
      "Epoch 2/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0309 - mae: 0.0984 - val_loss: 0.0172 - val_mae: 0.0449\n",
      "Epoch 3/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0145 - mae: 0.0235 - val_loss: 0.0136 - val_mae: 0.0159\n",
      "Epoch 4/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0130 - mae: 0.0133 - val_loss: 0.0123 - val_mae: 0.0075\n",
      "Epoch 5/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0120 - mae: 0.0097 - val_loss: 0.0117 - val_mae: 0.0106\n",
      "Epoch 6/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0112 - mae: 0.0102 - val_loss: 0.0107 - val_mae: 0.0076\n",
      "Epoch 7/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0103 - mae: 0.0089 - val_loss: 0.0098 - val_mae: 0.0081\n",
      "Epoch 8/1000\n",
      "1426/1426 [==============================] - 2s 1ms/step - loss: 0.0094 - mae: 0.0069 - val_loss: 0.0090 - val_mae: 0.0051\n",
      "Epoch 9/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0087 - mae: 0.0079 - val_loss: 0.0082 - val_mae: 0.0057\n",
      "Epoch 10/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0079 - mae: 0.0070 - val_loss: 0.0077 - val_mae: 0.0109\n",
      "Epoch 11/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0072 - mae: 0.0064 - val_loss: 0.0069 - val_mae: 0.0045\n",
      "Epoch 12/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0066 - mae: 0.0059 - val_loss: 0.0063 - val_mae: 0.0052\n",
      "Epoch 13/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0061 - mae: 0.0055 - val_loss: 0.0058 - val_mae: 0.0030\n",
      "Epoch 14/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0056 - mae: 0.0060 - val_loss: 0.0055 - val_mae: 0.0096\n",
      "Epoch 15/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0052 - mae: 0.0048 - val_loss: 0.0049 - val_mae: 0.0032\n",
      "Epoch 16/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0048 - mae: 0.0050 - val_loss: 0.0045 - val_mae: 0.0034\n",
      "Epoch 17/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0044 - mae: 0.0051 - val_loss: 0.0042 - val_mae: 0.0035\n",
      "Epoch 18/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0041 - mae: 0.0046 - val_loss: 0.0039 - val_mae: 0.0029\n",
      "Epoch 19/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0038 - mae: 0.0044 - val_loss: 0.0037 - val_mae: 0.0087\n",
      "Epoch 20/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0035 - mae: 0.0041 - val_loss: 0.0040 - val_mae: 0.0167\n",
      "Epoch 21/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0032 - mae: 0.0043 - val_loss: 0.0031 - val_mae: 0.0045\n",
      "Epoch 22/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0030 - mae: 0.0043 - val_loss: 0.0029 - val_mae: 0.0051\n",
      "Epoch 23/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0028 - mae: 0.0039 - val_loss: 0.0027 - val_mae: 0.0056\n",
      "Epoch 24/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0026 - mae: 0.0039 - val_loss: 0.0024 - val_mae: 0.0025\n",
      "Epoch 25/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0024 - mae: 0.0041 - val_loss: 0.0023 - val_mae: 0.0028\n",
      "Epoch 26/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0022 - mae: 0.0038 - val_loss: 0.0024 - val_mae: 0.0129\n",
      "Epoch 27/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0021 - mae: 0.0037 - val_loss: 0.0020 - val_mae: 0.0032\n",
      "Epoch 28/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0019 - mae: 0.0037 - val_loss: 0.0019 - val_mae: 0.0030\n",
      "Epoch 29/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0018 - mae: 0.0037 - val_loss: 0.0017 - val_mae: 0.0026\n",
      "Epoch 30/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0017 - mae: 0.0037 - val_loss: 0.0016 - val_mae: 0.0026\n",
      "Epoch 31/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0016 - mae: 0.0034 - val_loss: 0.0016 - val_mae: 0.0048\n",
      "Epoch 32/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0015 - mae: 0.0035 - val_loss: 0.0014 - val_mae: 0.0023\n",
      "Epoch 33/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0014 - mae: 0.0035 - val_loss: 0.0014 - val_mae: 0.0035\n",
      "Epoch 34/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0013 - mae: 0.0035 - val_loss: 0.0013 - val_mae: 0.0029\n",
      "Epoch 35/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0013 - mae: 0.0038 - val_loss: 0.0012 - val_mae: 0.0026\n",
      "Epoch 36/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0012 - mae: 0.0035 - val_loss: 0.0012 - val_mae: 0.0052\n",
      "Epoch 37/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0033 - val_loss: 0.0013 - val_mae: 0.0103\n",
      "Epoch 38/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0011 - mae: 0.0034 - val_loss: 0.0010 - val_mae: 0.0020\n",
      "Epoch 39/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0010 - mae: 0.0035 - val_loss: 0.0010 - val_mae: 0.0029\n",
      "Epoch 40/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0010 - mae: 0.0034 - val_loss: 9.5431e-04 - val_mae: 0.0021\n",
      "Epoch 41/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 9.5556e-04 - mae: 0.0032 - val_loss: 0.0011 - val_mae: 0.0128\n",
      "Epoch 42/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 9.1879e-04 - mae: 0.0035 - val_loss: 8.7587e-04 - val_mae: 0.0022\n",
      "Epoch 43/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 8.8036e-04 - mae: 0.0034 - val_loss: 8.4123e-04 - val_mae: 0.0021\n",
      "Epoch 44/1000\n",
      "1426/1426 [==============================] - 2s 1ms/step - loss: 8.4808e-04 - mae: 0.0033 - val_loss: 8.1001e-04 - val_mae: 0.0024\n",
      "Epoch 45/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 8.1132e-04 - mae: 0.0031 - val_loss: 7.8269e-04 - val_mae: 0.0029\n",
      "Epoch 46/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 7.8401e-04 - mae: 0.0033 - val_loss: 7.4902e-04 - val_mae: 0.0023\n",
      "Epoch 47/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 7.5670e-04 - mae: 0.0033 - val_loss: 7.2294e-04 - val_mae: 0.0028\n",
      "Epoch 48/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 7.2342e-04 - mae: 0.0033 - val_loss: 7.0044e-04 - val_mae: 0.0031\n",
      "Epoch 49/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 7.0037e-04 - mae: 0.0032 - val_loss: 6.8275e-04 - val_mae: 0.0036\n",
      "Epoch 50/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 6.7461e-04 - mae: 0.0031 - val_loss: 6.4654e-04 - val_mae: 0.0024\n",
      "Epoch 51/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 6.5420e-04 - mae: 0.0032 - val_loss: 6.2530e-04 - val_mae: 0.0024\n",
      "Epoch 52/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 6.3167e-04 - mae: 0.0032 - val_loss: 6.0970e-04 - val_mae: 0.0032\n",
      "Epoch 53/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 6.0973e-04 - mae: 0.0030 - val_loss: 5.8403e-04 - val_mae: 0.0022\n",
      "Epoch 54/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 5.9140e-04 - mae: 0.0030 - val_loss: 5.6417e-04 - val_mae: 0.0020\n",
      "Epoch 55/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 5.7413e-04 - mae: 0.0030 - val_loss: 5.4869e-04 - val_mae: 0.0021\n",
      "Epoch 56/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 5.6081e-04 - mae: 0.0032 - val_loss: 5.3374e-04 - val_mae: 0.0025\n",
      "Epoch 57/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 5.4087e-04 - mae: 0.0029 - val_loss: 5.1950e-04 - val_mae: 0.0026\n",
      "Epoch 58/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 5.2939e-04 - mae: 0.0031 - val_loss: 5.0138e-04 - val_mae: 0.0019\n",
      "Epoch 59/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 5.1227e-04 - mae: 0.0029 - val_loss: 7.6553e-04 - val_mae: 0.0124\n",
      "Epoch 60/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 5.0070e-04 - mae: 0.0029 - val_loss: 6.3746e-04 - val_mae: 0.0099\n",
      "Epoch 61/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 4.8873e-04 - mae: 0.0030 - val_loss: 4.6595e-04 - val_mae: 0.0021\n",
      "Epoch 62/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 4.7851e-04 - mae: 0.0031 - val_loss: 4.5420e-04 - val_mae: 0.0022\n",
      "Epoch 63/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 4.6630e-04 - mae: 0.0029 - val_loss: 4.4457e-04 - val_mae: 0.0021\n",
      "Epoch 64/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 4.5765e-04 - mae: 0.0030 - val_loss: 4.3320e-04 - val_mae: 0.0020\n",
      "Epoch 65/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 4.4469e-04 - mae: 0.0029 - val_loss: 4.2551e-04 - val_mae: 0.0025\n",
      "Epoch 66/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 4.3501e-04 - mae: 0.0029 - val_loss: 4.2072e-04 - val_mae: 0.0030\n",
      "Epoch 67/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 4.2580e-04 - mae: 0.0029 - val_loss: 4.0356e-04 - val_mae: 0.0019\n",
      "Epoch 68/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 4.1792e-04 - mae: 0.0030 - val_loss: 3.9812e-04 - val_mae: 0.0024\n",
      "Epoch 69/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 4.0574e-04 - mae: 0.0028 - val_loss: 3.8828e-04 - val_mae: 0.0022\n",
      "Epoch 70/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 4.0172e-04 - mae: 0.0030 - val_loss: 3.7923e-04 - val_mae: 0.0020\n",
      "Epoch 71/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.9266e-04 - mae: 0.0029 - val_loss: 3.7158e-04 - val_mae: 0.0020\n",
      "Epoch 72/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.8304e-04 - mae: 0.0028 - val_loss: 3.6360e-04 - val_mae: 0.0020\n",
      "Epoch 73/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.7396e-04 - mae: 0.0027 - val_loss: 3.5655e-04 - val_mae: 0.0020\n",
      "Epoch 74/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.6748e-04 - mae: 0.0029 - val_loss: 3.6826e-04 - val_mae: 0.0044\n",
      "Epoch 75/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.6225e-04 - mae: 0.0029 - val_loss: 3.4268e-04 - val_mae: 0.0022\n",
      "Epoch 76/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.5500e-04 - mae: 0.0029 - val_loss: 3.4000e-04 - val_mae: 0.0027\n",
      "Epoch 77/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.5055e-04 - mae: 0.0029 - val_loss: 3.3191e-04 - val_mae: 0.0023\n",
      "Epoch 78/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.4379e-04 - mae: 0.0029 - val_loss: 3.3538e-04 - val_mae: 0.0036\n",
      "Epoch 79/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.3706e-04 - mae: 0.0028 - val_loss: 3.1967e-04 - val_mae: 0.0021\n",
      "Epoch 80/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.3183e-04 - mae: 0.0029 - val_loss: 3.1901e-04 - val_mae: 0.0028\n",
      "Epoch 81/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.2551e-04 - mae: 0.0027 - val_loss: 3.1264e-04 - val_mae: 0.0025\n",
      "Epoch 82/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.2304e-04 - mae: 0.0029 - val_loss: 3.0655e-04 - val_mae: 0.0023\n",
      "Epoch 83/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.1716e-04 - mae: 0.0028 - val_loss: 3.0356e-04 - val_mae: 0.0027\n",
      "Epoch 84/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.1143e-04 - mae: 0.0028 - val_loss: 2.9665e-04 - val_mae: 0.0022\n",
      "Epoch 85/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.0925e-04 - mae: 0.0028 - val_loss: 2.9002e-04 - val_mae: 0.0019\n",
      "Epoch 86/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.0360e-04 - mae: 0.0028 - val_loss: 2.8918e-04 - val_mae: 0.0024\n",
      "Epoch 87/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 3.0296e-04 - mae: 0.0029 - val_loss: 2.8228e-04 - val_mae: 0.0018\n",
      "Epoch 88/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.9611e-04 - mae: 0.0027 - val_loss: 2.7920e-04 - val_mae: 0.0019\n",
      "Epoch 89/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.9430e-04 - mae: 0.0029 - val_loss: 2.7687e-04 - val_mae: 0.0022\n",
      "Epoch 90/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.8714e-04 - mae: 0.0027 - val_loss: 2.7150e-04 - val_mae: 0.0019\n",
      "Epoch 91/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.8514e-04 - mae: 0.0028 - val_loss: 2.6824e-04 - val_mae: 0.0020\n",
      "Epoch 92/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.8231e-04 - mae: 0.0028 - val_loss: 3.0837e-04 - val_mae: 0.0058\n",
      "Epoch 93/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.7721e-04 - mae: 0.0028 - val_loss: 2.6766e-04 - val_mae: 0.0027\n",
      "Epoch 94/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.7619e-04 - mae: 0.0029 - val_loss: 2.5799e-04 - val_mae: 0.0018\n",
      "Epoch 95/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.7236e-04 - mae: 0.0027 - val_loss: 3.6924e-04 - val_mae: 0.0080\n",
      "Epoch 96/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.6879e-04 - mae: 0.0028 - val_loss: 2.5448e-04 - val_mae: 0.0024\n",
      "Epoch 97/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.6685e-04 - mae: 0.0028 - val_loss: 2.5107e-04 - val_mae: 0.0023\n",
      "Epoch 98/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.6423e-04 - mae: 0.0028 - val_loss: 2.4703e-04 - val_mae: 0.0019\n",
      "Epoch 99/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.5877e-04 - mae: 0.0026 - val_loss: 2.4473e-04 - val_mae: 0.0020\n",
      "Epoch 100/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.5785e-04 - mae: 0.0027 - val_loss: 2.4138e-04 - val_mae: 0.0018\n",
      "Epoch 101/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.5652e-04 - mae: 0.0028 - val_loss: 2.3880e-04 - val_mae: 0.0019\n",
      "Epoch 102/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.5242e-04 - mae: 0.0027 - val_loss: 2.3809e-04 - val_mae: 0.0022\n",
      "Epoch 103/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.5147e-04 - mae: 0.0028 - val_loss: 2.4925e-04 - val_mae: 0.0036\n",
      "Epoch 104/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.4822e-04 - mae: 0.0028 - val_loss: 2.3301e-04 - val_mae: 0.0021\n",
      "Epoch 105/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.4595e-04 - mae: 0.0027 - val_loss: 2.2955e-04 - val_mae: 0.0019\n",
      "Epoch 106/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.4347e-04 - mae: 0.0027 - val_loss: 2.3177e-04 - val_mae: 0.0025\n",
      "Epoch 107/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.3914e-04 - mae: 0.0026 - val_loss: 3.8117e-04 - val_mae: 0.0110\n",
      "Epoch 108/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.4048e-04 - mae: 0.0029 - val_loss: 2.2210e-04 - val_mae: 0.0017\n",
      "Epoch 109/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.3687e-04 - mae: 0.0027 - val_loss: 2.2108e-04 - val_mae: 0.0019\n",
      "Epoch 110/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.3510e-04 - mae: 0.0028 - val_loss: 2.3047e-04 - val_mae: 0.0034\n",
      "Epoch 111/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.3324e-04 - mae: 0.0027 - val_loss: 2.1661e-04 - val_mae: 0.0018\n",
      "Epoch 112/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.3171e-04 - mae: 0.0028 - val_loss: 2.1446e-04 - val_mae: 0.0017\n",
      "Epoch 113/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.2868e-04 - mae: 0.0027 - val_loss: 2.1533e-04 - val_mae: 0.0023\n",
      "Epoch 114/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.2663e-04 - mae: 0.0028 - val_loss: 2.1151e-04 - val_mae: 0.0019\n",
      "Epoch 115/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.2536e-04 - mae: 0.0027 - val_loss: 2.0960e-04 - val_mae: 0.0019\n",
      "Epoch 116/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.2352e-04 - mae: 0.0027 - val_loss: 2.0892e-04 - val_mae: 0.0021\n",
      "Epoch 117/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.2196e-04 - mae: 0.0027 - val_loss: 2.0911e-04 - val_mae: 0.0025\n",
      "Epoch 118/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.2093e-04 - mae: 0.0028 - val_loss: 2.0509e-04 - val_mae: 0.0019\n",
      "Epoch 119/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.1752e-04 - mae: 0.0027 - val_loss: 2.0414e-04 - val_mae: 0.0021\n",
      "Epoch 120/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.1799e-04 - mae: 0.0029 - val_loss: 2.0498e-04 - val_mae: 0.0024\n",
      "Epoch 121/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.1424e-04 - mae: 0.0026 - val_loss: 2.0064e-04 - val_mae: 0.0021\n",
      "Epoch 122/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.1324e-04 - mae: 0.0027 - val_loss: 1.9888e-04 - val_mae: 0.0020\n",
      "Epoch 123/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.0947e-04 - mae: 0.0025 - val_loss: 3.7288e-04 - val_mae: 0.0106\n",
      "Epoch 124/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.1341e-04 - mae: 0.0029 - val_loss: 1.9538e-04 - val_mae: 0.0019\n",
      "Epoch 125/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.0707e-04 - mae: 0.0026 - val_loss: 1.9560e-04 - val_mae: 0.0022\n",
      "Epoch 126/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.0857e-04 - mae: 0.0028 - val_loss: 2.0308e-04 - val_mae: 0.0031\n",
      "Epoch 127/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.0640e-04 - mae: 0.0027 - val_loss: 1.9933e-04 - val_mae: 0.0030\n",
      "Epoch 128/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.0483e-04 - mae: 0.0027 - val_loss: 2.0029e-04 - val_mae: 0.0031\n",
      "Epoch 129/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.0216e-04 - mae: 0.0027 - val_loss: 1.9172e-04 - val_mae: 0.0025\n",
      "Epoch 130/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.0453e-04 - mae: 0.0028 - val_loss: 1.8707e-04 - val_mae: 0.0018\n",
      "Epoch 131/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.0129e-04 - mae: 0.0027 - val_loss: 1.8700e-04 - val_mae: 0.0020\n",
      "Epoch 132/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.0073e-04 - mae: 0.0027 - val_loss: 1.8439e-04 - val_mae: 0.0018\n",
      "Epoch 133/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 2.0054e-04 - mae: 0.0027 - val_loss: 2.1111e-04 - val_mae: 0.0051\n",
      "Epoch 134/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.9843e-04 - mae: 0.0028 - val_loss: 1.9307e-04 - val_mae: 0.0030\n",
      "Epoch 135/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.9607e-04 - mae: 0.0026 - val_loss: 1.9512e-04 - val_mae: 0.0035\n",
      "Epoch 136/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.9706e-04 - mae: 0.0028 - val_loss: 1.8003e-04 - val_mae: 0.0018\n",
      "Epoch 137/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.9383e-04 - mae: 0.0026 - val_loss: 2.0924e-04 - val_mae: 0.0049\n",
      "Epoch 138/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.9353e-04 - mae: 0.0027 - val_loss: 1.7886e-04 - val_mae: 0.0020\n",
      "Epoch 139/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.9200e-04 - mae: 0.0027 - val_loss: 1.8696e-04 - val_mae: 0.0032\n",
      "Epoch 140/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.9230e-04 - mae: 0.0027 - val_loss: 1.9230e-04 - val_mae: 0.0039\n",
      "Epoch 141/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.8932e-04 - mae: 0.0027 - val_loss: 1.7730e-04 - val_mae: 0.0022\n",
      "Epoch 142/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.8889e-04 - mae: 0.0027 - val_loss: 1.8986e-04 - val_mae: 0.0040\n",
      "Epoch 143/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.8790e-04 - mae: 0.0027 - val_loss: 1.7235e-04 - val_mae: 0.0017\n",
      "Epoch 144/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.8897e-04 - mae: 0.0028 - val_loss: 1.7502e-04 - val_mae: 0.0023\n",
      "Epoch 145/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.8655e-04 - mae: 0.0027 - val_loss: 1.7221e-04 - val_mae: 0.0020\n",
      "Epoch 146/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.8390e-04 - mae: 0.0026 - val_loss: 3.0419e-04 - val_mae: 0.0106\n",
      "Epoch 147/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.8663e-04 - mae: 0.0029 - val_loss: 1.7197e-04 - val_mae: 0.0023\n",
      "Epoch 148/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.8335e-04 - mae: 0.0027 - val_loss: 1.6950e-04 - val_mae: 0.0019\n",
      "Epoch 149/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.8209e-04 - mae: 0.0027 - val_loss: 1.7396e-04 - val_mae: 0.0028\n",
      "Epoch 150/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.8123e-04 - mae: 0.0027 - val_loss: 1.6723e-04 - val_mae: 0.0018\n",
      "Epoch 151/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.8171e-04 - mae: 0.0027 - val_loss: 1.7275e-04 - val_mae: 0.0028\n",
      "Epoch 152/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.7927e-04 - mae: 0.0027 - val_loss: 1.6769e-04 - val_mae: 0.0021\n",
      "Epoch 153/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.8037e-04 - mae: 0.0027 - val_loss: 1.6521e-04 - val_mae: 0.0019\n",
      "Epoch 154/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.7902e-04 - mae: 0.0027 - val_loss: 1.6742e-04 - val_mae: 0.0024\n",
      "Epoch 155/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.7755e-04 - mae: 0.0027 - val_loss: 1.6300e-04 - val_mae: 0.0018\n",
      "Epoch 156/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.7739e-04 - mae: 0.0028 - val_loss: 1.6422e-04 - val_mae: 0.0020\n",
      "Epoch 157/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.7653e-04 - mae: 0.0027 - val_loss: 1.6261e-04 - val_mae: 0.0019\n",
      "Epoch 158/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.7490e-04 - mae: 0.0026 - val_loss: 1.6232e-04 - val_mae: 0.0021\n",
      "Epoch 159/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.7445e-04 - mae: 0.0026 - val_loss: 1.6157e-04 - val_mae: 0.0020\n",
      "Epoch 160/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.7457e-04 - mae: 0.0027 - val_loss: 2.2538e-04 - val_mae: 0.0072\n",
      "Epoch 161/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.7543e-04 - mae: 0.0028 - val_loss: 1.8191e-04 - val_mae: 0.0048\n",
      "Epoch 162/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.7095e-04 - mae: 0.0026 - val_loss: 1.6647e-04 - val_mae: 0.0031\n",
      "Epoch 163/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.7260e-04 - mae: 0.0027 - val_loss: 1.6089e-04 - val_mae: 0.0025\n",
      "Epoch 164/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.7144e-04 - mae: 0.0027 - val_loss: 1.6428e-04 - val_mae: 0.0028\n",
      "Epoch 165/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.6896e-04 - mae: 0.0026 - val_loss: 1.5758e-04 - val_mae: 0.0020\n",
      "Epoch 166/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.6939e-04 - mae: 0.0026 - val_loss: 1.7370e-04 - val_mae: 0.0043\n",
      "Epoch 167/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.6836e-04 - mae: 0.0027 - val_loss: 1.9109e-04 - val_mae: 0.0056\n",
      "Epoch 168/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.6833e-04 - mae: 0.0027 - val_loss: 1.5520e-04 - val_mae: 0.0020\n",
      "Epoch 169/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.6887e-04 - mae: 0.0027 - val_loss: 1.5682e-04 - val_mae: 0.0023\n",
      "Epoch 170/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.6761e-04 - mae: 0.0027 - val_loss: 1.7035e-04 - val_mae: 0.0043\n",
      "Epoch 171/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.6675e-04 - mae: 0.0026 - val_loss: 1.5814e-04 - val_mae: 0.0027\n",
      "Epoch 172/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.6658e-04 - mae: 0.0027 - val_loss: 1.5761e-04 - val_mae: 0.0027\n",
      "Epoch 173/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.6666e-04 - mae: 0.0027 - val_loss: 1.5223e-04 - val_mae: 0.0019\n",
      "Epoch 174/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.6507e-04 - mae: 0.0026 - val_loss: 1.5183e-04 - val_mae: 0.0019\n",
      "Epoch 175/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.6601e-04 - mae: 0.0027 - val_loss: 1.5486e-04 - val_mae: 0.0025\n",
      "Epoch 176/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.6288e-04 - mae: 0.0026 - val_loss: 1.5058e-04 - val_mae: 0.0020\n",
      "Epoch 177/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.6322e-04 - mae: 0.0027 - val_loss: 1.5053e-04 - val_mae: 0.0021\n",
      "Epoch 178/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.6306e-04 - mae: 0.0027 - val_loss: 1.4858e-04 - val_mae: 0.0018\n",
      "Epoch 179/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.6360e-04 - mae: 0.0027 - val_loss: 2.7936e-04 - val_mae: 0.0103\n",
      "Epoch 180/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.6376e-04 - mae: 0.0028 - val_loss: 1.5625e-04 - val_mae: 0.0031\n",
      "Epoch 181/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.6154e-04 - mae: 0.0027 - val_loss: 2.5495e-04 - val_mae: 0.0076\n",
      "Epoch 182/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.6357e-04 - mae: 0.0028 - val_loss: 1.4659e-04 - val_mae: 0.0017\n",
      "Epoch 183/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.6021e-04 - mae: 0.0026 - val_loss: 1.4781e-04 - val_mae: 0.0021\n",
      "Epoch 184/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.6067e-04 - mae: 0.0027 - val_loss: 1.4709e-04 - val_mae: 0.0020\n",
      "Epoch 185/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.5914e-04 - mae: 0.0026 - val_loss: 1.4802e-04 - val_mae: 0.0023\n",
      "Epoch 186/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 1.6134e-04 - mae: 0.0027 - val_loss: 1.4705e-04 - val_mae: 0.0022\n",
      "Epoch 187/1000\n",
      "1423/1426 [============================>.] - ETA: 0s - loss: 1.5789e-04 - mae: 0.0026Restoring model weights from the end of the best epoch: 182.\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5785e-04 - mae: 0.0026 - val_loss: 1.5518e-04 - val_mae: 0.0035\n",
      "Epoch 187: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Netzwerkarchitektur\n",
    "model = Sequential([\n",
    "\n",
    "    Dense(136, activation='relu', input_shape=(4,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(216, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(104, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(328, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(8, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(120, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(1 , activation = 'linear')\n",
    "])\n",
    "\n",
    "# Optimierer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)  #0.0001\n",
    "\n",
    "# Modell kompilieren (Verwendung von mean_squared_error als Verlustfunktion fÃ¼r Regression)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])  # Metriken fÃ¼r Regression: Mean Absolute Error und Mean Squared Error\n",
    "\n",
    "# Early Stopping Callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "# Trainingsparameter\n",
    "batch_size = 25   #25\n",
    "epochs = 1000\n",
    "\n",
    "# Modell trainieren (Annahme: X_train, y_train, X_val, y_val sind vordefiniert)\n",
    "history = model.fit(X_train_scaled, y_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:56:58.656466100Z",
     "start_time": "2024-03-31T20:50:00.023173100Z"
    }
   },
   "id": "8b52e1a9a6ff3aeb"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fÃ¼r Fold 1...\n",
      "Epoch 1/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0443 - mae: 0.0877 - val_loss: 0.0146 - val_mae: 0.0231\n",
      "Epoch 2/1000\n",
      "1426/1426 [==============================] - 2s 1ms/step - loss: 0.0135 - mae: 0.0155 - val_loss: 0.0126 - val_mae: 0.0091\n",
      "Epoch 3/1000\n",
      "1426/1426 [==============================] - 2s 1ms/step - loss: 0.0125 - mae: 0.0142 - val_loss: 0.0119 - val_mae: 0.0117\n",
      "Epoch 4/1000\n",
      "1426/1426 [==============================] - 2s 1ms/step - loss: 0.0116 - mae: 0.0113 - val_loss: 0.0111 - val_mae: 0.0071\n",
      "Epoch 5/1000\n",
      "1426/1426 [==============================] - 2s 1ms/step - loss: 0.0110 - mae: 0.0119 - val_loss: 0.0111 - val_mae: 0.0218\n",
      "Epoch 6/1000\n",
      "1426/1426 [==============================] - 2s 1ms/step - loss: 0.0103 - mae: 0.0097 - val_loss: 0.0099 - val_mae: 0.0065\n",
      "Epoch 7/1000\n",
      "1426/1426 [==============================] - 2s 1ms/step - loss: 0.0098 - mae: 0.0105 - val_loss: 0.0093 - val_mae: 0.0076\n",
      "Epoch 8/1000\n",
      "1426/1426 [==============================] - 2s 1ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0088 - val_mae: 0.0078\n",
      "Epoch 9/1000\n",
      "1426/1426 [==============================] - 2s 1ms/step - loss: 0.0087 - mae: 0.0096 - val_loss: 0.0083 - val_mae: 0.0044\n",
      "Epoch 10/1000\n",
      "1426/1426 [==============================] - 2s 1ms/step - loss: 0.0082 - mae: 0.0081 - val_loss: 0.0078 - val_mae: 0.0062\n",
      "Epoch 11/1000\n",
      "1426/1426 [==============================] - 2s 1ms/step - loss: 0.0078 - mae: 0.0087 - val_loss: 0.0074 - val_mae: 0.0057\n",
      "Epoch 12/1000\n",
      "1426/1426 [==============================] - 2s 1ms/step - loss: 0.0073 - mae: 0.0075 - val_loss: 0.0073 - val_mae: 0.0137\n",
      "Epoch 13/1000\n",
      "1426/1426 [==============================] - 2s 1ms/step - loss: 0.0070 - mae: 0.0079 - val_loss: 0.0067 - val_mae: 0.0061\n",
      "Epoch 14/1000\n",
      "1426/1426 [==============================] - 2s 1ms/step - loss: 0.0066 - mae: 0.0069 - val_loss: 0.0063 - val_mae: 0.0049\n",
      "Epoch 15/1000\n",
      "1426/1426 [==============================] - 2s 1ms/step - loss: 0.0063 - mae: 0.0071 - val_loss: 0.0061 - val_mae: 0.0094\n",
      "Epoch 16/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0060 - mae: 0.0065 - val_loss: 0.0057 - val_mae: 0.0048\n",
      "Epoch 17/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0057 - mae: 0.0064 - val_loss: 0.0054 - val_mae: 0.0032\n",
      "Epoch 18/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0054 - mae: 0.0058 - val_loss: 0.0052 - val_mae: 0.0046\n",
      "Epoch 19/1000\n",
      "1426/1426 [==============================] - 2s 2ms/step - loss: 0.0051 - mae: 0.0066 - val_loss: 0.0049 - val_mae: 0.0046\n",
      "Epoch 20/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0049 - mae: 0.0056 - val_loss: 0.0047 - val_mae: 0.0055\n",
      "Epoch 21/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0046 - mae: 0.0052 - val_loss: 0.0044 - val_mae: 0.0033\n",
      "Epoch 22/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0044 - mae: 0.0053 - val_loss: 0.0043 - val_mae: 0.0072\n",
      "Epoch 23/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0042 - mae: 0.0058 - val_loss: 0.0041 - val_mae: 0.0090\n",
      "Epoch 24/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0040 - mae: 0.0056 - val_loss: 0.0038 - val_mae: 0.0037\n",
      "Epoch 25/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0038 - mae: 0.0047 - val_loss: 0.0039 - val_mae: 0.0138\n",
      "Epoch 26/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0036 - mae: 0.0047 - val_loss: 0.0035 - val_mae: 0.0066\n",
      "Epoch 27/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0034 - mae: 0.0047 - val_loss: 0.0033 - val_mae: 0.0047\n",
      "Epoch 28/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0032 - mae: 0.0048 - val_loss: 0.0031 - val_mae: 0.0042\n",
      "Epoch 29/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0031 - mae: 0.0046 - val_loss: 0.0030 - val_mae: 0.0027\n",
      "Epoch 30/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0029 - mae: 0.0043 - val_loss: 0.0028 - val_mae: 0.0035\n",
      "Epoch 31/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0028 - mae: 0.0049 - val_loss: 0.0027 - val_mae: 0.0043\n",
      "Epoch 32/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0027 - mae: 0.0041 - val_loss: 0.0026 - val_mae: 0.0024\n",
      "Epoch 33/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0026 - mae: 0.0045 - val_loss: 0.0024 - val_mae: 0.0029\n",
      "Epoch 34/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0024 - mae: 0.0040 - val_loss: 0.0023 - val_mae: 0.0022\n",
      "Epoch 35/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0023 - mae: 0.0042 - val_loss: 0.0022 - val_mae: 0.0037\n",
      "Epoch 36/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0022 - mae: 0.0039 - val_loss: 0.0021 - val_mae: 0.0026\n",
      "Epoch 37/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0021 - mae: 0.0040 - val_loss: 0.0021 - val_mae: 0.0083\n",
      "Epoch 38/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0020 - mae: 0.0042 - val_loss: 0.0019 - val_mae: 0.0030\n",
      "Epoch 39/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0019 - mae: 0.0038 - val_loss: 0.0018 - val_mae: 0.0023\n",
      "Epoch 40/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0019 - mae: 0.0039 - val_loss: 0.0018 - val_mae: 0.0045\n",
      "Epoch 41/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0018 - mae: 0.0039 - val_loss: 0.0018 - val_mae: 0.0082\n",
      "Epoch 42/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0017 - mae: 0.0036 - val_loss: 0.0020 - val_mae: 0.0179\n",
      "Epoch 43/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0016 - mae: 0.0039 - val_loss: 0.0015 - val_mae: 0.0033\n",
      "Epoch 44/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0015 - mae: 0.0036 - val_loss: 0.0015 - val_mae: 0.0020\n",
      "Epoch 45/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0015 - mae: 0.0037 - val_loss: 0.0014 - val_mae: 0.0033\n",
      "Epoch 46/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0014 - mae: 0.0036 - val_loss: 0.0014 - val_mae: 0.0020\n",
      "Epoch 47/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0014 - mae: 0.0036 - val_loss: 0.0013 - val_mae: 0.0031\n",
      "Epoch 48/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0013 - mae: 0.0035 - val_loss: 0.0013 - val_mae: 0.0054\n",
      "Epoch 49/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0013 - mae: 0.0036 - val_loss: 0.0012 - val_mae: 0.0025\n",
      "Epoch 50/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0012 - mae: 0.0034 - val_loss: 0.0013 - val_mae: 0.0117\n",
      "Epoch 51/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0012 - mae: 0.0034 - val_loss: 0.0011 - val_mae: 0.0031\n",
      "Epoch 52/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0011 - mae: 0.0034 - val_loss: 0.0011 - val_mae: 0.0025\n",
      "Epoch 53/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0011 - mae: 0.0035 - val_loss: 0.0010 - val_mae: 0.0029\n",
      "Epoch 54/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0010 - mae: 0.0031 - val_loss: 9.7518e-04 - val_mae: 0.0022\n",
      "Epoch 55/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 9.9644e-04 - mae: 0.0034 - val_loss: 9.4118e-04 - val_mae: 0.0024\n",
      "Epoch 56/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 9.5803e-04 - mae: 0.0032 - val_loss: 9.1524e-04 - val_mae: 0.0033\n",
      "Epoch 57/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 9.2843e-04 - mae: 0.0033 - val_loss: 9.3554e-04 - val_mae: 0.0069\n",
      "Epoch 58/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 8.9506e-04 - mae: 0.0032 - val_loss: 8.4268e-04 - val_mae: 0.0022\n",
      "Epoch 59/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 8.6880e-04 - mae: 0.0033 - val_loss: 8.1790e-04 - val_mae: 0.0025\n",
      "Epoch 60/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 8.4031e-04 - mae: 0.0032 - val_loss: 7.8974e-04 - val_mae: 0.0024\n",
      "Epoch 61/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 8.1381e-04 - mae: 0.0032 - val_loss: 7.8586e-04 - val_mae: 0.0044\n",
      "Epoch 62/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.8858e-04 - mae: 0.0031 - val_loss: 7.4997e-04 - val_mae: 0.0036\n",
      "Epoch 63/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.6627e-04 - mae: 0.0031 - val_loss: 9.5636e-04 - val_mae: 0.0136\n",
      "Epoch 64/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.4592e-04 - mae: 0.0033 - val_loss: 6.9799e-04 - val_mae: 0.0023\n",
      "Epoch 65/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.2758e-04 - mae: 0.0032 - val_loss: 6.8002e-04 - val_mae: 0.0026\n",
      "Epoch 66/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.0467e-04 - mae: 0.0031 - val_loss: 6.6526e-04 - val_mae: 0.0033\n",
      "Epoch 67/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.8541e-04 - mae: 0.0031 - val_loss: 6.3861e-04 - val_mae: 0.0023\n",
      "Epoch 68/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.7411e-04 - mae: 0.0034 - val_loss: 6.2084e-04 - val_mae: 0.0020\n",
      "Epoch 69/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.5461e-04 - mae: 0.0032 - val_loss: 6.0715e-04 - val_mae: 0.0023\n",
      "Epoch 70/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.3353e-04 - mae: 0.0030 - val_loss: 5.9861e-04 - val_mae: 0.0031\n",
      "Epoch 71/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.1817e-04 - mae: 0.0031 - val_loss: 5.8400e-04 - val_mae: 0.0029\n",
      "Epoch 72/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.0469e-04 - mae: 0.0032 - val_loss: 5.5693e-04 - val_mae: 0.0019\n",
      "Epoch 73/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.8709e-04 - mae: 0.0031 - val_loss: 5.4358e-04 - val_mae: 0.0021\n",
      "Epoch 74/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.7556e-04 - mae: 0.0032 - val_loss: 5.3044e-04 - val_mae: 0.0023\n",
      "Epoch 75/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.6301e-04 - mae: 0.0032 - val_loss: 5.1630e-04 - val_mae: 0.0019\n",
      "Epoch 76/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.4475e-04 - mae: 0.0028 - val_loss: 5.0471e-04 - val_mae: 0.0022\n",
      "Epoch 77/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.3460e-04 - mae: 0.0030 - val_loss: 4.9238e-04 - val_mae: 0.0020\n",
      "Epoch 78/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.2395e-04 - mae: 0.0030 - val_loss: 4.9072e-04 - val_mae: 0.0030\n",
      "Epoch 79/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.0960e-04 - mae: 0.0029 - val_loss: 4.7375e-04 - val_mae: 0.0027\n",
      "Epoch 80/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.0221e-04 - mae: 0.0030 - val_loss: 4.7218e-04 - val_mae: 0.0036\n",
      "Epoch 81/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.8834e-04 - mae: 0.0028 - val_loss: 4.4944e-04 - val_mae: 0.0020\n",
      "Epoch 82/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.8324e-04 - mae: 0.0031 - val_loss: 4.3940e-04 - val_mae: 0.0020\n",
      "Epoch 83/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.6784e-04 - mae: 0.0028 - val_loss: 4.3462e-04 - val_mae: 0.0027\n",
      "Epoch 84/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.6281e-04 - mae: 0.0030 - val_loss: 4.2096e-04 - val_mae: 0.0019\n",
      "Epoch 85/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.5470e-04 - mae: 0.0030 - val_loss: 4.1140e-04 - val_mae: 0.0018\n",
      "Epoch 86/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.4294e-04 - mae: 0.0028 - val_loss: 4.0321e-04 - val_mae: 0.0017\n",
      "Epoch 87/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.3530e-04 - mae: 0.0027 - val_loss: 4.0291e-04 - val_mae: 0.0030\n",
      "Epoch 88/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.2740e-04 - mae: 0.0028 - val_loss: 3.8854e-04 - val_mae: 0.0020\n",
      "Epoch 89/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.1852e-04 - mae: 0.0028 - val_loss: 3.8095e-04 - val_mae: 0.0021\n",
      "Epoch 90/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.1348e-04 - mae: 0.0030 - val_loss: 3.7998e-04 - val_mae: 0.0029\n",
      "Epoch 91/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.0498e-04 - mae: 0.0028 - val_loss: 3.6501e-04 - val_mae: 0.0017\n",
      "Epoch 92/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.9714e-04 - mae: 0.0028 - val_loss: 3.5964e-04 - val_mae: 0.0022\n",
      "Epoch 93/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.8884e-04 - mae: 0.0028 - val_loss: 3.5420e-04 - val_mae: 0.0022\n",
      "Epoch 94/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.8449e-04 - mae: 0.0029 - val_loss: 3.4819e-04 - val_mae: 0.0022\n",
      "Epoch 95/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.7704e-04 - mae: 0.0027 - val_loss: 3.4092e-04 - val_mae: 0.0021\n",
      "Epoch 96/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.7146e-04 - mae: 0.0027 - val_loss: 7.8634e-04 - val_mae: 0.0127\n",
      "Epoch 97/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.6801e-04 - mae: 0.0028 - val_loss: 3.3750e-04 - val_mae: 0.0034\n",
      "Epoch 98/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.6288e-04 - mae: 0.0029 - val_loss: 3.2352e-04 - val_mae: 0.0019\n",
      "Epoch 99/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.5736e-04 - mae: 0.0029 - val_loss: 3.2004e-04 - val_mae: 0.0023\n",
      "Epoch 100/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.4853e-04 - mae: 0.0026 - val_loss: 3.5307e-04 - val_mae: 0.0060\n",
      "Epoch 101/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.4474e-04 - mae: 0.0028 - val_loss: 3.0897e-04 - val_mae: 0.0021\n",
      "Epoch 102/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.4343e-04 - mae: 0.0029 - val_loss: 3.0300e-04 - val_mae: 0.0018\n",
      "Epoch 103/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.3420e-04 - mae: 0.0027 - val_loss: 3.3159e-04 - val_mae: 0.0053\n",
      "Epoch 104/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.3194e-04 - mae: 0.0028 - val_loss: 3.0375e-04 - val_mae: 0.0031\n",
      "Epoch 105/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.2710e-04 - mae: 0.0026 - val_loss: 2.9069e-04 - val_mae: 0.0019\n",
      "Epoch 106/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.2362e-04 - mae: 0.0028 - val_loss: 2.9377e-04 - val_mae: 0.0028\n",
      "Epoch 107/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.2070e-04 - mae: 0.0028 - val_loss: 2.9629e-04 - val_mae: 0.0035\n",
      "Epoch 108/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.1485e-04 - mae: 0.0027 - val_loss: 2.7783e-04 - val_mae: 0.0017\n",
      "Epoch 109/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.0942e-04 - mae: 0.0027 - val_loss: 2.8154e-04 - val_mae: 0.0025\n",
      "Epoch 110/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.0570e-04 - mae: 0.0027 - val_loss: 2.7252e-04 - val_mae: 0.0021\n",
      "Epoch 111/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.0310e-04 - mae: 0.0027 - val_loss: 2.7787e-04 - val_mae: 0.0030\n",
      "Epoch 112/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.9908e-04 - mae: 0.0027 - val_loss: 2.7485e-04 - val_mae: 0.0032\n",
      "Epoch 113/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.9476e-04 - mae: 0.0026 - val_loss: 2.5946e-04 - val_mae: 0.0017\n",
      "Epoch 114/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.9372e-04 - mae: 0.0027 - val_loss: 2.6824e-04 - val_mae: 0.0035\n",
      "Epoch 115/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.8861e-04 - mae: 0.0027 - val_loss: 2.5249e-04 - val_mae: 0.0016\n",
      "Epoch 116/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.8915e-04 - mae: 0.0029 - val_loss: 2.5176e-04 - val_mae: 0.0021\n",
      "Epoch 117/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.8283e-04 - mae: 0.0027 - val_loss: 2.4700e-04 - val_mae: 0.0018\n",
      "Epoch 118/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.7770e-04 - mae: 0.0026 - val_loss: 3.0225e-04 - val_mae: 0.0075\n",
      "Epoch 119/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.7626e-04 - mae: 0.0027 - val_loss: 2.4200e-04 - val_mae: 0.0019\n",
      "Epoch 120/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.7290e-04 - mae: 0.0026 - val_loss: 2.4384e-04 - val_mae: 0.0026\n",
      "Epoch 121/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.7111e-04 - mae: 0.0027 - val_loss: 2.3568e-04 - val_mae: 0.0019\n",
      "Epoch 122/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.6791e-04 - mae: 0.0027 - val_loss: 2.3683e-04 - val_mae: 0.0026\n",
      "Epoch 123/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.6521e-04 - mae: 0.0027 - val_loss: 2.3720e-04 - val_mae: 0.0027\n",
      "Epoch 124/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.6151e-04 - mae: 0.0025 - val_loss: 2.3077e-04 - val_mae: 0.0022\n",
      "Epoch 125/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.6004e-04 - mae: 0.0027 - val_loss: 2.2568e-04 - val_mae: 0.0019\n",
      "Epoch 126/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.5990e-04 - mae: 0.0028 - val_loss: 2.2484e-04 - val_mae: 0.0021\n",
      "Epoch 127/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.5432e-04 - mae: 0.0026 - val_loss: 2.2026e-04 - val_mae: 0.0017\n",
      "Epoch 128/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.5130e-04 - mae: 0.0026 - val_loss: 2.7750e-04 - val_mae: 0.0067\n",
      "Epoch 129/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.5140e-04 - mae: 0.0027 - val_loss: 2.1727e-04 - val_mae: 0.0021\n",
      "Epoch 130/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.4639e-04 - mae: 0.0026 - val_loss: 2.1592e-04 - val_mae: 0.0021\n",
      "Epoch 131/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.4784e-04 - mae: 0.0027 - val_loss: 2.1484e-04 - val_mae: 0.0024\n",
      "Epoch 132/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.4246e-04 - mae: 0.0026 - val_loss: 2.0948e-04 - val_mae: 0.0018\n",
      "Epoch 133/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.4447e-04 - mae: 0.0028 - val_loss: 2.0784e-04 - val_mae: 0.0019\n",
      "Epoch 134/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.4049e-04 - mae: 0.0026 - val_loss: 2.2175e-04 - val_mae: 0.0039\n",
      "Epoch 135/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3754e-04 - mae: 0.0026 - val_loss: 2.0301e-04 - val_mae: 0.0017\n",
      "Epoch 136/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3619e-04 - mae: 0.0026 - val_loss: 2.0538e-04 - val_mae: 0.0023\n",
      "Epoch 137/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3398e-04 - mae: 0.0026 - val_loss: 2.0608e-04 - val_mae: 0.0024\n",
      "Epoch 138/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3146e-04 - mae: 0.0026 - val_loss: 1.9993e-04 - val_mae: 0.0020\n",
      "Epoch 139/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2914e-04 - mae: 0.0026 - val_loss: 1.9650e-04 - val_mae: 0.0019\n",
      "Epoch 140/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2779e-04 - mae: 0.0026 - val_loss: 1.9367e-04 - val_mae: 0.0016\n",
      "Epoch 141/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2800e-04 - mae: 0.0027 - val_loss: 2.0536e-04 - val_mae: 0.0034\n",
      "Epoch 142/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2447e-04 - mae: 0.0026 - val_loss: 2.2833e-04 - val_mae: 0.0053\n",
      "Epoch 143/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2194e-04 - mae: 0.0026 - val_loss: 1.9240e-04 - val_mae: 0.0020\n",
      "Epoch 144/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2076e-04 - mae: 0.0025 - val_loss: 1.8981e-04 - val_mae: 0.0022\n",
      "Epoch 145/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2069e-04 - mae: 0.0027 - val_loss: 1.8863e-04 - val_mae: 0.0022\n",
      "Epoch 146/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1992e-04 - mae: 0.0027 - val_loss: 1.8567e-04 - val_mae: 0.0018\n",
      "Epoch 147/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1679e-04 - mae: 0.0025 - val_loss: 1.8513e-04 - val_mae: 0.0020\n",
      "Epoch 148/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1375e-04 - mae: 0.0024 - val_loss: 1.8196e-04 - val_mae: 0.0018\n",
      "Epoch 149/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1406e-04 - mae: 0.0026 - val_loss: 2.1610e-04 - val_mae: 0.0051\n",
      "Epoch 150/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1303e-04 - mae: 0.0026 - val_loss: 1.7918e-04 - val_mae: 0.0017\n",
      "Epoch 151/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0972e-04 - mae: 0.0025 - val_loss: 1.7734e-04 - val_mae: 0.0017\n",
      "Epoch 152/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0822e-04 - mae: 0.0025 - val_loss: 1.7605e-04 - val_mae: 0.0017\n",
      "Epoch 153/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1008e-04 - mae: 0.0026 - val_loss: 2.5122e-04 - val_mae: 0.0081\n",
      "Epoch 154/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0957e-04 - mae: 0.0028 - val_loss: 1.7525e-04 - val_mae: 0.0020\n",
      "Epoch 155/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0489e-04 - mae: 0.0025 - val_loss: 1.7372e-04 - val_mae: 0.0020\n",
      "Epoch 156/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0404e-04 - mae: 0.0026 - val_loss: 1.7177e-04 - val_mae: 0.0018\n",
      "Epoch 157/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0351e-04 - mae: 0.0025 - val_loss: 1.7383e-04 - val_mae: 0.0024\n",
      "Epoch 158/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0320e-04 - mae: 0.0026 - val_loss: 1.6908e-04 - val_mae: 0.0016\n",
      "Epoch 159/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0377e-04 - mae: 0.0027 - val_loss: 1.6960e-04 - val_mae: 0.0019\n",
      "Epoch 160/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9962e-04 - mae: 0.0025 - val_loss: 1.6879e-04 - val_mae: 0.0021\n",
      "Epoch 161/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9972e-04 - mae: 0.0025 - val_loss: 1.6578e-04 - val_mae: 0.0017\n",
      "Epoch 162/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9692e-04 - mae: 0.0025 - val_loss: 1.6532e-04 - val_mae: 0.0018\n",
      "Epoch 163/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9821e-04 - mae: 0.0027 - val_loss: 1.7262e-04 - val_mae: 0.0027\n",
      "Epoch 164/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9589e-04 - mae: 0.0025 - val_loss: 1.6259e-04 - val_mae: 0.0016\n",
      "Epoch 165/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9507e-04 - mae: 0.0026 - val_loss: 1.6799e-04 - val_mae: 0.0028\n",
      "Epoch 166/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9463e-04 - mae: 0.0026 - val_loss: 1.6593e-04 - val_mae: 0.0026\n",
      "Epoch 167/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9235e-04 - mae: 0.0025 - val_loss: 1.6438e-04 - val_mae: 0.0022\n",
      "Epoch 168/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9168e-04 - mae: 0.0025 - val_loss: 1.6122e-04 - val_mae: 0.0021\n",
      "Epoch 169/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9018e-04 - mae: 0.0025 - val_loss: 5.3547e-04 - val_mae: 0.0144\n",
      "Epoch 170/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9306e-04 - mae: 0.0026 - val_loss: 1.5917e-04 - val_mae: 0.0021\n",
      "Epoch 171/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8981e-04 - mae: 0.0026 - val_loss: 1.7500e-04 - val_mae: 0.0043\n",
      "Epoch 172/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8740e-04 - mae: 0.0025 - val_loss: 1.5694e-04 - val_mae: 0.0020\n",
      "Epoch 173/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8739e-04 - mae: 0.0025 - val_loss: 1.5795e-04 - val_mae: 0.0021\n",
      "Epoch 174/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8482e-04 - mae: 0.0024 - val_loss: 1.5383e-04 - val_mae: 0.0017\n",
      "Epoch 175/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8636e-04 - mae: 0.0026 - val_loss: 1.6059e-04 - val_mae: 0.0029\n",
      "Epoch 176/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8322e-04 - mae: 0.0025 - val_loss: 3.2630e-04 - val_mae: 0.0120\n",
      "Epoch 177/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8450e-04 - mae: 0.0026 - val_loss: 1.5084e-04 - val_mae: 0.0017\n",
      "Epoch 178/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8236e-04 - mae: 0.0025 - val_loss: 1.6163e-04 - val_mae: 0.0030\n",
      "Epoch 179/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8135e-04 - mae: 0.0025 - val_loss: 1.5326e-04 - val_mae: 0.0022\n",
      "Epoch 180/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8070e-04 - mae: 0.0025 - val_loss: 1.5469e-04 - val_mae: 0.0025\n",
      "Epoch 181/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7978e-04 - mae: 0.0025 - val_loss: 1.7765e-04 - val_mae: 0.0045\n",
      "Epoch 182/1000\n",
      "1421/1426 [============================>.] - ETA: 0s - loss: 1.7858e-04 - mae: 0.0024Restoring model weights from the end of the best epoch: 177.\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7855e-04 - mae: 0.0024 - val_loss: 1.6488e-04 - val_mae: 0.0038\n",
      "Epoch 182: early stopping\n",
      "Training fÃ¼r Fold 2...\n",
      "Epoch 1/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0233 - mae: 0.0502 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 2/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0133 - mae: 0.0134 - val_loss: 0.0128 - val_mae: 0.0166\n",
      "Epoch 3/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0122 - mae: 0.0121 - val_loss: 0.0116 - val_mae: 0.0078\n",
      "Epoch 4/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0113 - mae: 0.0108 - val_loss: 0.0108 - val_mae: 0.0107\n",
      "Epoch 5/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0105 - mae: 0.0095 - val_loss: 0.0100 - val_mae: 0.0064\n",
      "Epoch 6/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0098 - mae: 0.0093 - val_loss: 0.0093 - val_mae: 0.0052\n",
      "Epoch 7/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0092 - mae: 0.0082 - val_loss: 0.0088 - val_mae: 0.0057\n",
      "Epoch 8/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0086 - mae: 0.0082 - val_loss: 0.0084 - val_mae: 0.0073\n",
      "Epoch 9/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0081 - mae: 0.0080 - val_loss: 0.0079 - val_mae: 0.0066\n",
      "Epoch 10/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0077 - mae: 0.0071 - val_loss: 0.0074 - val_mae: 0.0048\n",
      "Epoch 11/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0073 - mae: 0.0065 - val_loss: 0.0074 - val_mae: 0.0159\n",
      "Epoch 12/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0069 - mae: 0.0072 - val_loss: 0.0067 - val_mae: 0.0055\n",
      "Epoch 13/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0065 - mae: 0.0060 - val_loss: 0.0063 - val_mae: 0.0042\n",
      "Epoch 14/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0062 - mae: 0.0070 - val_loss: 0.0060 - val_mae: 0.0036\n",
      "Epoch 15/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0059 - mae: 0.0057 - val_loss: 0.0057 - val_mae: 0.0062\n",
      "Epoch 16/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0056 - mae: 0.0061 - val_loss: 0.0054 - val_mae: 0.0037\n",
      "Epoch 17/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0053 - mae: 0.0054 - val_loss: 0.0051 - val_mae: 0.0040\n",
      "Epoch 18/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0050 - mae: 0.0056 - val_loss: 0.0048 - val_mae: 0.0047\n",
      "Epoch 19/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0047 - mae: 0.0051 - val_loss: 0.0050 - val_mae: 0.0175\n",
      "Epoch 20/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0045 - mae: 0.0051 - val_loss: 0.0044 - val_mae: 0.0032\n",
      "Epoch 21/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0043 - mae: 0.0052 - val_loss: 0.0041 - val_mae: 0.0031\n",
      "Epoch 22/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0041 - mae: 0.0053 - val_loss: 0.0039 - val_mae: 0.0026\n",
      "Epoch 23/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0039 - mae: 0.0042 - val_loss: 0.0038 - val_mae: 0.0033\n",
      "Epoch 24/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0037 - mae: 0.0045 - val_loss: 0.0036 - val_mae: 0.0040\n",
      "Epoch 25/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0035 - mae: 0.0051 - val_loss: 0.0034 - val_mae: 0.0026\n",
      "Epoch 26/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0033 - mae: 0.0039 - val_loss: 0.0032 - val_mae: 0.0026\n",
      "Epoch 27/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0032 - mae: 0.0045 - val_loss: 0.0031 - val_mae: 0.0027\n",
      "Epoch 28/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0030 - mae: 0.0040 - val_loss: 0.0029 - val_mae: 0.0027\n",
      "Epoch 29/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0029 - mae: 0.0040 - val_loss: 0.0028 - val_mae: 0.0025\n",
      "Epoch 30/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0027 - mae: 0.0039 - val_loss: 0.0026 - val_mae: 0.0027\n",
      "Epoch 31/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0026 - mae: 0.0038 - val_loss: 0.0025 - val_mae: 0.0042\n",
      "Epoch 32/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0024 - mae: 0.0040 - val_loss: 0.0024 - val_mae: 0.0023\n",
      "Epoch 33/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0023 - mae: 0.0039 - val_loss: 0.0023 - val_mae: 0.0025\n",
      "Epoch 34/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0022 - mae: 0.0036 - val_loss: 0.0021 - val_mae: 0.0024\n",
      "Epoch 35/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0021 - mae: 0.0036 - val_loss: 0.0020 - val_mae: 0.0033\n",
      "Epoch 36/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0020 - mae: 0.0034 - val_loss: 0.0021 - val_mae: 0.0128\n",
      "Epoch 37/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0019 - mae: 0.0038 - val_loss: 0.0019 - val_mae: 0.0026\n",
      "Epoch 38/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0018 - mae: 0.0034 - val_loss: 0.0018 - val_mae: 0.0020\n",
      "Epoch 39/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0017 - mae: 0.0035 - val_loss: 0.0017 - val_mae: 0.0024\n",
      "Epoch 40/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0017 - mae: 0.0035 - val_loss: 0.0016 - val_mae: 0.0026\n",
      "Epoch 41/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0016 - mae: 0.0032 - val_loss: 0.0015 - val_mae: 0.0021\n",
      "Epoch 42/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0015 - mae: 0.0033 - val_loss: 0.0015 - val_mae: 0.0024\n",
      "Epoch 43/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0014 - mae: 0.0033 - val_loss: 0.0014 - val_mae: 0.0028\n",
      "Epoch 44/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0014 - mae: 0.0032 - val_loss: 0.0013 - val_mae: 0.0023\n",
      "Epoch 45/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0013 - mae: 0.0032 - val_loss: 0.0013 - val_mae: 0.0030\n",
      "Epoch 46/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0012 - mae: 0.0032 - val_loss: 0.0012 - val_mae: 0.0025\n",
      "Epoch 47/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0012 - mae: 0.0031 - val_loss: 0.0012 - val_mae: 0.0032\n",
      "Epoch 48/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0011 - mae: 0.0030 - val_loss: 0.0011 - val_mae: 0.0022\n",
      "Epoch 49/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0011 - mae: 0.0030 - val_loss: 0.0011 - val_mae: 0.0032\n",
      "Epoch 50/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0010 - mae: 0.0033 - val_loss: 0.0010 - val_mae: 0.0048\n",
      "Epoch 51/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 9.7886e-04 - mae: 0.0031 - val_loss: 9.8924e-04 - val_mae: 0.0053\n",
      "Epoch 52/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 9.4045e-04 - mae: 0.0030 - val_loss: 9.2412e-04 - val_mae: 0.0023\n",
      "Epoch 53/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 8.9990e-04 - mae: 0.0028 - val_loss: 8.8820e-04 - val_mae: 0.0025\n",
      "Epoch 54/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 8.7089e-04 - mae: 0.0030 - val_loss: 8.5343e-04 - val_mae: 0.0022\n",
      "Epoch 55/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 8.4036e-04 - mae: 0.0032 - val_loss: 8.2209e-04 - val_mae: 0.0021\n",
      "Epoch 56/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 8.0308e-04 - mae: 0.0030 - val_loss: 7.9596e-04 - val_mae: 0.0028\n",
      "Epoch 57/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.7247e-04 - mae: 0.0030 - val_loss: 7.5785e-04 - val_mae: 0.0019\n",
      "Epoch 58/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.4324e-04 - mae: 0.0030 - val_loss: 7.3164e-04 - val_mae: 0.0021\n",
      "Epoch 59/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 7.1282e-04 - mae: 0.0029 - val_loss: 7.0792e-04 - val_mae: 0.0025\n",
      "Epoch 60/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 6.9141e-04 - mae: 0.0030 - val_loss: 6.8415e-04 - val_mae: 0.0024\n",
      "Epoch 61/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 6.7470e-04 - mae: 0.0031 - val_loss: 6.6128e-04 - val_mae: 0.0021\n",
      "Epoch 62/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 6.4796e-04 - mae: 0.0029 - val_loss: 6.4798e-04 - val_mae: 0.0033\n",
      "Epoch 63/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 6.2902e-04 - mae: 0.0029 - val_loss: 6.2216e-04 - val_mae: 0.0020\n",
      "Epoch 64/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.0830e-04 - mae: 0.0029 - val_loss: 6.0187e-04 - val_mae: 0.0018\n",
      "Epoch 65/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.9299e-04 - mae: 0.0030 - val_loss: 5.8435e-04 - val_mae: 0.0019\n",
      "Epoch 66/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.7052e-04 - mae: 0.0027 - val_loss: 5.6881e-04 - val_mae: 0.0021\n",
      "Epoch 67/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.5606e-04 - mae: 0.0028 - val_loss: 5.5089e-04 - val_mae: 0.0019\n",
      "Epoch 68/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.4159e-04 - mae: 0.0029 - val_loss: 5.4998e-04 - val_mae: 0.0034\n",
      "Epoch 69/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.2831e-04 - mae: 0.0030 - val_loss: 5.2702e-04 - val_mae: 0.0027\n",
      "Epoch 70/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.0810e-04 - mae: 0.0027 - val_loss: 5.1164e-04 - val_mae: 0.0027\n",
      "Epoch 71/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.9885e-04 - mae: 0.0028 - val_loss: 4.9765e-04 - val_mae: 0.0025\n",
      "Epoch 72/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.8505e-04 - mae: 0.0029 - val_loss: 4.8547e-04 - val_mae: 0.0028\n",
      "Epoch 73/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.6809e-04 - mae: 0.0027 - val_loss: 5.4974e-04 - val_mae: 0.0071\n",
      "Epoch 74/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.5963e-04 - mae: 0.0028 - val_loss: 4.5723e-04 - val_mae: 0.0019\n",
      "Epoch 75/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.4764e-04 - mae: 0.0028 - val_loss: 4.4580e-04 - val_mae: 0.0018\n",
      "Epoch 76/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.3653e-04 - mae: 0.0028 - val_loss: 4.7084e-04 - val_mae: 0.0053\n",
      "Epoch 77/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.2579e-04 - mae: 0.0027 - val_loss: 4.2597e-04 - val_mae: 0.0019\n",
      "Epoch 78/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.2194e-04 - mae: 0.0030 - val_loss: 4.1941e-04 - val_mae: 0.0023\n",
      "Epoch 79/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.0914e-04 - mae: 0.0027 - val_loss: 4.0895e-04 - val_mae: 0.0021\n",
      "Epoch 80/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.9882e-04 - mae: 0.0027 - val_loss: 4.0160e-04 - val_mae: 0.0021\n",
      "Epoch 81/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.8857e-04 - mae: 0.0026 - val_loss: 3.9185e-04 - val_mae: 0.0021\n",
      "Epoch 82/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.8282e-04 - mae: 0.0028 - val_loss: 3.8646e-04 - val_mae: 0.0027\n",
      "Epoch 83/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.7429e-04 - mae: 0.0027 - val_loss: 3.7551e-04 - val_mae: 0.0019\n",
      "Epoch 84/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.6832e-04 - mae: 0.0028 - val_loss: 3.8202e-04 - val_mae: 0.0031\n",
      "Epoch 85/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.5866e-04 - mae: 0.0026 - val_loss: 3.6850e-04 - val_mae: 0.0031\n",
      "Epoch 86/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.5283e-04 - mae: 0.0026 - val_loss: 3.5713e-04 - val_mae: 0.0024\n",
      "Epoch 87/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.4880e-04 - mae: 0.0028 - val_loss: 3.5072e-04 - val_mae: 0.0021\n",
      "Epoch 88/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.3890e-04 - mae: 0.0025 - val_loss: 3.4508e-04 - val_mae: 0.0022\n",
      "Epoch 89/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.3442e-04 - mae: 0.0026 - val_loss: 3.5641e-04 - val_mae: 0.0041\n",
      "Epoch 90/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.2844e-04 - mae: 0.0026 - val_loss: 3.3355e-04 - val_mae: 0.0022\n",
      "Epoch 91/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.2964e-04 - mae: 0.0030 - val_loss: 3.2962e-04 - val_mae: 0.0023\n",
      "Epoch 92/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.1757e-04 - mae: 0.0026 - val_loss: 3.4062e-04 - val_mae: 0.0045\n",
      "Epoch 93/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.1295e-04 - mae: 0.0026 - val_loss: 3.2584e-04 - val_mae: 0.0034\n",
      "Epoch 94/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.1032e-04 - mae: 0.0028 - val_loss: 3.4042e-04 - val_mae: 0.0053\n",
      "Epoch 95/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.0375e-04 - mae: 0.0026 - val_loss: 3.0854e-04 - val_mae: 0.0022\n",
      "Epoch 96/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.0321e-04 - mae: 0.0028 - val_loss: 3.0524e-04 - val_mae: 0.0022\n",
      "Epoch 97/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.9485e-04 - mae: 0.0026 - val_loss: 2.9918e-04 - val_mae: 0.0020\n",
      "Epoch 98/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.9391e-04 - mae: 0.0027 - val_loss: 2.9566e-04 - val_mae: 0.0019\n",
      "Epoch 99/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.8665e-04 - mae: 0.0026 - val_loss: 2.9450e-04 - val_mae: 0.0027\n",
      "Epoch 100/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.8563e-04 - mae: 0.0028 - val_loss: 2.9155e-04 - val_mae: 0.0027\n",
      "Epoch 101/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.7988e-04 - mae: 0.0026 - val_loss: 2.9014e-04 - val_mae: 0.0030\n",
      "Epoch 102/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.7550e-04 - mae: 0.0027 - val_loss: 2.8121e-04 - val_mae: 0.0020\n",
      "Epoch 103/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.7356e-04 - mae: 0.0028 - val_loss: 2.7987e-04 - val_mae: 0.0023\n",
      "Epoch 104/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.7186e-04 - mae: 0.0028 - val_loss: 2.7286e-04 - val_mae: 0.0018\n",
      "Epoch 105/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.6546e-04 - mae: 0.0026 - val_loss: 2.7785e-04 - val_mae: 0.0031\n",
      "Epoch 106/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.6375e-04 - mae: 0.0027 - val_loss: 2.8271e-04 - val_mae: 0.0042\n",
      "Epoch 107/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.5871e-04 - mae: 0.0025 - val_loss: 2.8535e-04 - val_mae: 0.0043\n",
      "Epoch 108/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 2.5626e-04 - mae: 0.0027 - val_loss: 2.6127e-04 - val_mae: 0.0020\n",
      "Epoch 109/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.5118e-04 - mae: 0.0025 - val_loss: 2.6432e-04 - val_mae: 0.0030\n",
      "Epoch 110/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.5253e-04 - mae: 0.0027 - val_loss: 2.5524e-04 - val_mae: 0.0021\n",
      "Epoch 111/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.4711e-04 - mae: 0.0026 - val_loss: 2.5386e-04 - val_mae: 0.0022\n",
      "Epoch 112/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.4553e-04 - mae: 0.0027 - val_loss: 2.6484e-04 - val_mae: 0.0037\n",
      "Epoch 113/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.4129e-04 - mae: 0.0026 - val_loss: 2.5429e-04 - val_mae: 0.0030\n",
      "Epoch 114/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3888e-04 - mae: 0.0026 - val_loss: 2.4588e-04 - val_mae: 0.0020\n",
      "Epoch 115/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3835e-04 - mae: 0.0026 - val_loss: 2.4442e-04 - val_mae: 0.0024\n",
      "Epoch 116/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3570e-04 - mae: 0.0027 - val_loss: 2.4043e-04 - val_mae: 0.0021\n",
      "Epoch 117/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3198e-04 - mae: 0.0026 - val_loss: 2.3674e-04 - val_mae: 0.0017\n",
      "Epoch 118/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2993e-04 - mae: 0.0026 - val_loss: 2.3721e-04 - val_mae: 0.0021\n",
      "Epoch 119/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2810e-04 - mae: 0.0027 - val_loss: 2.3450e-04 - val_mae: 0.0021\n",
      "Epoch 120/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2321e-04 - mae: 0.0025 - val_loss: 2.3017e-04 - val_mae: 0.0017\n",
      "Epoch 121/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2437e-04 - mae: 0.0027 - val_loss: 2.2909e-04 - val_mae: 0.0019\n",
      "Epoch 122/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2107e-04 - mae: 0.0025 - val_loss: 2.2798e-04 - val_mae: 0.0021\n",
      "Epoch 123/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1826e-04 - mae: 0.0025 - val_loss: 2.2491e-04 - val_mae: 0.0019\n",
      "Epoch 124/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1926e-04 - mae: 0.0027 - val_loss: 2.2346e-04 - val_mae: 0.0021\n",
      "Epoch 125/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 2.1575e-04 - mae: 0.0026 - val_loss: 2.2514e-04 - val_mae: 0.0024\n",
      "Epoch 126/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1553e-04 - mae: 0.0027 - val_loss: 2.2289e-04 - val_mae: 0.0024\n",
      "Epoch 127/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1143e-04 - mae: 0.0025 - val_loss: 2.1944e-04 - val_mae: 0.0023\n",
      "Epoch 128/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0865e-04 - mae: 0.0024 - val_loss: 2.1821e-04 - val_mae: 0.0021\n",
      "Epoch 129/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0739e-04 - mae: 0.0025 - val_loss: 2.1463e-04 - val_mae: 0.0019\n",
      "Epoch 130/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0394e-04 - mae: 0.0024 - val_loss: 2.1242e-04 - val_mae: 0.0018\n",
      "Epoch 131/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0761e-04 - mae: 0.0027 - val_loss: 2.1129e-04 - val_mae: 0.0019\n",
      "Epoch 132/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0182e-04 - mae: 0.0024 - val_loss: 2.0927e-04 - val_mae: 0.0018\n",
      "Epoch 133/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0030e-04 - mae: 0.0024 - val_loss: 2.0727e-04 - val_mae: 0.0019\n",
      "Epoch 134/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0095e-04 - mae: 0.0026 - val_loss: 2.3801e-04 - val_mae: 0.0050\n",
      "Epoch 135/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9939e-04 - mae: 0.0026 - val_loss: 2.0732e-04 - val_mae: 0.0025\n",
      "Epoch 136/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9708e-04 - mae: 0.0025 - val_loss: 2.0478e-04 - val_mae: 0.0021\n",
      "Epoch 137/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9430e-04 - mae: 0.0024 - val_loss: 2.0877e-04 - val_mae: 0.0029\n",
      "Epoch 138/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9311e-04 - mae: 0.0025 - val_loss: 2.4332e-04 - val_mae: 0.0064\n",
      "Epoch 139/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9453e-04 - mae: 0.0026 - val_loss: 1.9981e-04 - val_mae: 0.0020\n",
      "Epoch 140/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9065e-04 - mae: 0.0025 - val_loss: 1.9719e-04 - val_mae: 0.0017\n",
      "Epoch 141/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9011e-04 - mae: 0.0025 - val_loss: 2.0091e-04 - val_mae: 0.0025\n",
      "Epoch 142/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9024e-04 - mae: 0.0026 - val_loss: 1.9721e-04 - val_mae: 0.0023\n",
      "Epoch 143/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8721e-04 - mae: 0.0025 - val_loss: 1.9393e-04 - val_mae: 0.0018\n",
      "Epoch 144/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.8559e-04 - mae: 0.0025 - val_loss: 1.9343e-04 - val_mae: 0.0019\n",
      "Epoch 145/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8495e-04 - mae: 0.0025 - val_loss: 1.9240e-04 - val_mae: 0.0019\n",
      "Epoch 146/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8405e-04 - mae: 0.0024 - val_loss: 1.9142e-04 - val_mae: 0.0021\n",
      "Epoch 147/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8466e-04 - mae: 0.0026 - val_loss: 1.9074e-04 - val_mae: 0.0021\n",
      "Epoch 148/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8156e-04 - mae: 0.0025 - val_loss: 1.8875e-04 - val_mae: 0.0018\n",
      "Epoch 149/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7990e-04 - mae: 0.0024 - val_loss: 1.9007e-04 - val_mae: 0.0021\n",
      "Epoch 150/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7962e-04 - mae: 0.0025 - val_loss: 1.8795e-04 - val_mae: 0.0021\n",
      "Epoch 151/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7881e-04 - mae: 0.0025 - val_loss: 1.8852e-04 - val_mae: 0.0022\n",
      "Epoch 152/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7794e-04 - mae: 0.0025 - val_loss: 1.8412e-04 - val_mae: 0.0018\n",
      "Epoch 153/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7556e-04 - mae: 0.0024 - val_loss: 1.8498e-04 - val_mae: 0.0020\n",
      "Epoch 154/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7762e-04 - mae: 0.0026 - val_loss: 1.8713e-04 - val_mae: 0.0025\n",
      "Epoch 155/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7228e-04 - mae: 0.0023 - val_loss: 1.8172e-04 - val_mae: 0.0018\n",
      "Epoch 156/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7324e-04 - mae: 0.0025 - val_loss: 1.8068e-04 - val_mae: 0.0018\n",
      "Epoch 157/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7398e-04 - mae: 0.0025 - val_loss: 1.8252e-04 - val_mae: 0.0023\n",
      "Epoch 158/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7430e-04 - mae: 0.0025 - val_loss: 1.7898e-04 - val_mae: 0.0018\n",
      "Epoch 159/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7163e-04 - mae: 0.0025 - val_loss: 1.7882e-04 - val_mae: 0.0019\n",
      "Epoch 160/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6871e-04 - mae: 0.0023 - val_loss: 1.7769e-04 - val_mae: 0.0018\n",
      "Epoch 161/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7063e-04 - mae: 0.0025 - val_loss: 1.7641e-04 - val_mae: 0.0018\n",
      "Epoch 162/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6740e-04 - mae: 0.0024 - val_loss: 1.7585e-04 - val_mae: 0.0018\n",
      "Epoch 163/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6707e-04 - mae: 0.0023 - val_loss: 1.7546e-04 - val_mae: 0.0020\n",
      "Epoch 164/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6602e-04 - mae: 0.0024 - val_loss: 1.7440e-04 - val_mae: 0.0019\n",
      "Epoch 165/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6558e-04 - mae: 0.0024 - val_loss: 1.8367e-04 - val_mae: 0.0033\n",
      "Epoch 166/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6516e-04 - mae: 0.0024 - val_loss: 1.7364e-04 - val_mae: 0.0019\n",
      "Epoch 167/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6404e-04 - mae: 0.0024 - val_loss: 1.7412e-04 - val_mae: 0.0023\n",
      "Epoch 168/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6246e-04 - mae: 0.0024 - val_loss: 1.7114e-04 - val_mae: 0.0019\n",
      "Epoch 169/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6065e-04 - mae: 0.0024 - val_loss: 1.7163e-04 - val_mae: 0.0020\n",
      "Epoch 170/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6325e-04 - mae: 0.0025 - val_loss: 1.6990e-04 - val_mae: 0.0019\n",
      "Epoch 171/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6036e-04 - mae: 0.0024 - val_loss: 1.6939e-04 - val_mae: 0.0018\n",
      "Epoch 172/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5872e-04 - mae: 0.0023 - val_loss: 1.6775e-04 - val_mae: 0.0017\n",
      "Epoch 173/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6010e-04 - mae: 0.0025 - val_loss: 1.6815e-04 - val_mae: 0.0019\n",
      "Epoch 174/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5991e-04 - mae: 0.0024 - val_loss: 1.7062e-04 - val_mae: 0.0023\n",
      "Epoch 175/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5927e-04 - mae: 0.0025 - val_loss: 1.6720e-04 - val_mae: 0.0019\n",
      "Epoch 176/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5648e-04 - mae: 0.0023 - val_loss: 1.6645e-04 - val_mae: 0.0021\n",
      "Epoch 177/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5529e-04 - mae: 0.0023 - val_loss: 8.5853e-04 - val_mae: 0.0238\n",
      "Epoch 178/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6473e-04 - mae: 0.0027 - val_loss: 1.6685e-04 - val_mae: 0.0021\n",
      "Epoch 179/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.5509e-04 - mae: 0.0024 - val_loss: 1.6540e-04 - val_mae: 0.0021\n",
      "Epoch 180/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5673e-04 - mae: 0.0024 - val_loss: 1.6399e-04 - val_mae: 0.0019\n",
      "Epoch 181/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5431e-04 - mae: 0.0024 - val_loss: 2.9242e-04 - val_mae: 0.0099\n",
      "Epoch 182/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5487e-04 - mae: 0.0024 - val_loss: 1.6216e-04 - val_mae: 0.0018\n",
      "Epoch 183/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5540e-04 - mae: 0.0025 - val_loss: 1.6950e-04 - val_mae: 0.0029\n",
      "Epoch 184/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5479e-04 - mae: 0.0026 - val_loss: 1.6106e-04 - val_mae: 0.0018\n",
      "Epoch 185/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5289e-04 - mae: 0.0024 - val_loss: 1.6080e-04 - val_mae: 0.0019\n",
      "Epoch 186/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5299e-04 - mae: 0.0025 - val_loss: 1.6247e-04 - val_mae: 0.0020\n",
      "Epoch 187/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5068e-04 - mae: 0.0024 - val_loss: 1.5931e-04 - val_mae: 0.0017\n",
      "Epoch 188/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5144e-04 - mae: 0.0024 - val_loss: 1.5986e-04 - val_mae: 0.0020\n",
      "Epoch 189/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5049e-04 - mae: 0.0024 - val_loss: 1.6492e-04 - val_mae: 0.0030\n",
      "Epoch 190/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4943e-04 - mae: 0.0023 - val_loss: 1.5893e-04 - val_mae: 0.0020\n",
      "Epoch 191/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4932e-04 - mae: 0.0024 - val_loss: 1.6056e-04 - val_mae: 0.0023\n",
      "Epoch 192/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4773e-04 - mae: 0.0023 - val_loss: 2.3772e-04 - val_mae: 0.0079\n",
      "Epoch 193/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4758e-04 - mae: 0.0024 - val_loss: 1.6384e-04 - val_mae: 0.0032\n",
      "Epoch 194/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4935e-04 - mae: 0.0025 - val_loss: 1.7624e-04 - val_mae: 0.0039\n",
      "Epoch 195/1000\n",
      "1418/1426 [============================>.] - ETA: 0s - loss: 1.4736e-04 - mae: 0.0024Restoring model weights from the end of the best epoch: 190.\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4725e-04 - mae: 0.0024 - val_loss: 1.6024e-04 - val_mae: 0.0026\n",
      "Epoch 195: early stopping\n",
      "Training fÃ¼r Fold 3...\n",
      "Epoch 1/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.1182 - mae: 0.2442 - val_loss: 0.0386 - val_mae: 0.1200\n",
      "Epoch 2/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0279 - mae: 0.0854 - val_loss: 0.0192 - val_mae: 0.0600\n",
      "Epoch 3/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0165 - mae: 0.0364 - val_loss: 0.0156 - val_mae: 0.0286\n",
      "Epoch 4/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0153 - mae: 0.0292 - val_loss: 0.0150 - val_mae: 0.0305\n",
      "Epoch 5/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0145 - mae: 0.0263 - val_loss: 0.0141 - val_mae: 0.0257\n",
      "Epoch 6/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0137 - mae: 0.0253 - val_loss: 0.0134 - val_mae: 0.0266\n",
      "Epoch 7/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0130 - mae: 0.0241 - val_loss: 0.0127 - val_mae: 0.0245\n",
      "Epoch 8/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0123 - mae: 0.0231 - val_loss: 0.0120 - val_mae: 0.0217\n",
      "Epoch 9/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0109 - mae: 0.0214 - val_loss: 0.0083 - val_mae: 0.0085\n",
      "Epoch 10/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0080 - mae: 0.0082 - val_loss: 0.0077 - val_mae: 0.0045\n",
      "Epoch 11/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0076 - mae: 0.0075 - val_loss: 0.0073 - val_mae: 0.0090\n",
      "Epoch 12/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0071 - mae: 0.0063 - val_loss: 0.0068 - val_mae: 0.0062\n",
      "Epoch 13/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0066 - mae: 0.0067 - val_loss: 0.0064 - val_mae: 0.0092\n",
      "Epoch 14/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0062 - mae: 0.0068 - val_loss: 0.0060 - val_mae: 0.0054\n",
      "Epoch 15/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0058 - mae: 0.0058 - val_loss: 0.0057 - val_mae: 0.0073\n",
      "Epoch 16/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0055 - mae: 0.0052 - val_loss: 0.0053 - val_mae: 0.0045\n",
      "Epoch 17/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0052 - mae: 0.0052 - val_loss: 0.0049 - val_mae: 0.0038\n",
      "Epoch 18/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0049 - mae: 0.0057 - val_loss: 0.0047 - val_mae: 0.0046\n",
      "Epoch 19/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0046 - mae: 0.0051 - val_loss: 0.0044 - val_mae: 0.0047\n",
      "Epoch 20/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0043 - mae: 0.0050 - val_loss: 0.0044 - val_mae: 0.0153\n",
      "Epoch 21/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0040 - mae: 0.0043 - val_loss: 0.0039 - val_mae: 0.0032\n",
      "Epoch 22/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0038 - mae: 0.0049 - val_loss: 0.0037 - val_mae: 0.0053\n",
      "Epoch 23/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0036 - mae: 0.0044 - val_loss: 0.0036 - val_mae: 0.0101\n",
      "Epoch 24/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0033 - mae: 0.0041 - val_loss: 0.0032 - val_mae: 0.0034\n",
      "Epoch 25/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0031 - mae: 0.0042 - val_loss: 0.0030 - val_mae: 0.0041\n",
      "Epoch 26/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0030 - mae: 0.0039 - val_loss: 0.0028 - val_mae: 0.0029\n",
      "Epoch 27/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0028 - mae: 0.0039 - val_loss: 0.0027 - val_mae: 0.0037\n",
      "Epoch 28/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0026 - mae: 0.0041 - val_loss: 0.0026 - val_mae: 0.0070\n",
      "Epoch 29/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0025 - mae: 0.0041 - val_loss: 0.0024 - val_mae: 0.0025\n",
      "Epoch 30/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0023 - mae: 0.0035 - val_loss: 0.0022 - val_mae: 0.0036\n",
      "Epoch 31/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0022 - mae: 0.0040 - val_loss: 0.0021 - val_mae: 0.0022\n",
      "Epoch 32/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0021 - mae: 0.0036 - val_loss: 0.0020 - val_mae: 0.0022\n",
      "Epoch 33/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0020 - mae: 0.0036 - val_loss: 0.0019 - val_mae: 0.0028\n",
      "Epoch 34/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0018 - mae: 0.0039 - val_loss: 0.0020 - val_mae: 0.0117\n",
      "Epoch 35/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0017 - mae: 0.0037 - val_loss: 0.0017 - val_mae: 0.0031\n",
      "Epoch 36/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0017 - mae: 0.0036 - val_loss: 0.0016 - val_mae: 0.0023\n",
      "Epoch 37/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0016 - mae: 0.0035 - val_loss: 0.0015 - val_mae: 0.0030\n",
      "Epoch 38/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0015 - mae: 0.0038 - val_loss: 0.0015 - val_mae: 0.0061\n",
      "Epoch 39/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0014 - mae: 0.0034 - val_loss: 0.0014 - val_mae: 0.0025\n",
      "Epoch 40/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0013 - mae: 0.0035 - val_loss: 0.0014 - val_mae: 0.0085\n",
      "Epoch 41/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0013 - mae: 0.0035 - val_loss: 0.0012 - val_mae: 0.0021\n",
      "Epoch 42/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0012 - mae: 0.0034 - val_loss: 0.0012 - val_mae: 0.0066\n",
      "Epoch 43/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0012 - mae: 0.0035 - val_loss: 0.0011 - val_mae: 0.0054\n",
      "Epoch 44/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0011 - mae: 0.0030 - val_loss: 0.0011 - val_mae: 0.0027\n",
      "Epoch 45/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0011 - mae: 0.0033 - val_loss: 0.0010 - val_mae: 0.0026\n",
      "Epoch 46/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0010 - mae: 0.0036 - val_loss: 9.6821e-04 - val_mae: 0.0021\n",
      "Epoch 47/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 9.6641e-04 - mae: 0.0031 - val_loss: 9.3858e-04 - val_mae: 0.0031\n",
      "Epoch 48/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 9.3146e-04 - mae: 0.0032 - val_loss: 8.9212e-04 - val_mae: 0.0026\n",
      "Epoch 49/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 8.9170e-04 - mae: 0.0031 - val_loss: 8.6328e-04 - val_mae: 0.0034\n",
      "Epoch 50/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 8.6217e-04 - mae: 0.0032 - val_loss: 8.1989e-04 - val_mae: 0.0020\n",
      "Epoch 51/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 8.2847e-04 - mae: 0.0034 - val_loss: 7.9390e-04 - val_mae: 0.0028\n",
      "Epoch 52/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.9226e-04 - mae: 0.0030 - val_loss: 7.5721e-04 - val_mae: 0.0019\n",
      "Epoch 53/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.6920e-04 - mae: 0.0033 - val_loss: 8.2571e-04 - val_mae: 0.0081\n",
      "Epoch 54/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.3819e-04 - mae: 0.0031 - val_loss: 7.1011e-04 - val_mae: 0.0028\n",
      "Epoch 55/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.1890e-04 - mae: 0.0033 - val_loss: 6.9076e-04 - val_mae: 0.0029\n",
      "Epoch 56/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.9043e-04 - mae: 0.0031 - val_loss: 6.6395e-04 - val_mae: 0.0025\n",
      "Epoch 57/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.7238e-04 - mae: 0.0032 - val_loss: 6.3822e-04 - val_mae: 0.0019\n",
      "Epoch 58/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.5073e-04 - mae: 0.0031 - val_loss: 6.4688e-04 - val_mae: 0.0042\n",
      "Epoch 59/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 6.2835e-04 - mae: 0.0031 - val_loss: 5.9982e-04 - val_mae: 0.0020\n",
      "Epoch 60/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.1233e-04 - mae: 0.0031 - val_loss: 5.8183e-04 - val_mae: 0.0021\n",
      "Epoch 61/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.9660e-04 - mae: 0.0031 - val_loss: 5.6410e-04 - val_mae: 0.0019\n",
      "Epoch 62/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.7373e-04 - mae: 0.0030 - val_loss: 5.5159e-04 - val_mae: 0.0024\n",
      "Epoch 63/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.6574e-04 - mae: 0.0033 - val_loss: 5.3543e-04 - val_mae: 0.0022\n",
      "Epoch 64/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.4688e-04 - mae: 0.0031 - val_loss: 5.7218e-04 - val_mae: 0.0058\n",
      "Epoch 65/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.3099e-04 - mae: 0.0030 - val_loss: 5.0728e-04 - val_mae: 0.0022\n",
      "Epoch 66/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.1766e-04 - mae: 0.0030 - val_loss: 4.9250e-04 - val_mae: 0.0020\n",
      "Epoch 67/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.0649e-04 - mae: 0.0032 - val_loss: 4.8173e-04 - val_mae: 0.0022\n",
      "Epoch 68/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.9042e-04 - mae: 0.0030 - val_loss: 6.1289e-04 - val_mae: 0.0099\n",
      "Epoch 69/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.8253e-04 - mae: 0.0032 - val_loss: 4.5740e-04 - val_mae: 0.0021\n",
      "Epoch 70/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.7318e-04 - mae: 0.0032 - val_loss: 4.4741e-04 - val_mae: 0.0022\n",
      "Epoch 71/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.5876e-04 - mae: 0.0029 - val_loss: 4.3832e-04 - val_mae: 0.0024\n",
      "Epoch 72/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.5353e-04 - mae: 0.0032 - val_loss: 4.3170e-04 - val_mae: 0.0026\n",
      "Epoch 73/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.3847e-04 - mae: 0.0029 - val_loss: 4.1823e-04 - val_mae: 0.0020\n",
      "Epoch 74/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.3173e-04 - mae: 0.0030 - val_loss: 4.0969e-04 - val_mae: 0.0021\n",
      "Epoch 75/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.2287e-04 - mae: 0.0031 - val_loss: 4.0152e-04 - val_mae: 0.0021\n",
      "Epoch 76/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.1619e-04 - mae: 0.0031 - val_loss: 3.9337e-04 - val_mae: 0.0022\n",
      "Epoch 77/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.0448e-04 - mae: 0.0029 - val_loss: 3.8736e-04 - val_mae: 0.0025\n",
      "Epoch 78/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.0152e-04 - mae: 0.0032 - val_loss: 3.7974e-04 - val_mae: 0.0024\n",
      "Epoch 79/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.9133e-04 - mae: 0.0030 - val_loss: 3.6911e-04 - val_mae: 0.0019\n",
      "Epoch 80/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.8598e-04 - mae: 0.0031 - val_loss: 3.9373e-04 - val_mae: 0.0051\n",
      "Epoch 81/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.7601e-04 - mae: 0.0029 - val_loss: 3.6224e-04 - val_mae: 0.0028\n",
      "Epoch 82/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.7142e-04 - mae: 0.0031 - val_loss: 3.5067e-04 - val_mae: 0.0020\n",
      "Epoch 83/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.6568e-04 - mae: 0.0031 - val_loss: 3.4499e-04 - val_mae: 0.0020\n",
      "Epoch 84/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.6080e-04 - mae: 0.0030 - val_loss: 3.4073e-04 - val_mae: 0.0023\n",
      "Epoch 85/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.5165e-04 - mae: 0.0029 - val_loss: 3.3408e-04 - val_mae: 0.0020\n",
      "Epoch 86/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.4778e-04 - mae: 0.0030 - val_loss: 4.4271e-04 - val_mae: 0.0091\n",
      "Epoch 87/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.4473e-04 - mae: 0.0031 - val_loss: 3.2720e-04 - val_mae: 0.0025\n",
      "Epoch 88/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.3557e-04 - mae: 0.0029 - val_loss: 3.2327e-04 - val_mae: 0.0031\n",
      "Epoch 89/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.3192e-04 - mae: 0.0029 - val_loss: 3.1341e-04 - val_mae: 0.0021\n",
      "Epoch 90/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.2781e-04 - mae: 0.0030 - val_loss: 3.1357e-04 - val_mae: 0.0024\n",
      "Epoch 91/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.2216e-04 - mae: 0.0029 - val_loss: 3.0659e-04 - val_mae: 0.0024\n",
      "Epoch 92/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.1995e-04 - mae: 0.0031 - val_loss: 3.1556e-04 - val_mae: 0.0041\n",
      "Epoch 93/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.1354e-04 - mae: 0.0029 - val_loss: 3.0231e-04 - val_mae: 0.0031\n",
      "Epoch 94/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.1346e-04 - mae: 0.0030 - val_loss: 3.0810e-04 - val_mae: 0.0040\n",
      "Epoch 95/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.0465e-04 - mae: 0.0028 - val_loss: 2.8857e-04 - val_mae: 0.0020\n",
      "Epoch 96/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.0249e-04 - mae: 0.0029 - val_loss: 2.9426e-04 - val_mae: 0.0033\n",
      "Epoch 97/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.9864e-04 - mae: 0.0029 - val_loss: 2.8473e-04 - val_mae: 0.0027\n",
      "Epoch 98/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.9341e-04 - mae: 0.0028 - val_loss: 0.0012 - val_mae: 0.0246\n",
      "Epoch 99/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.0105e-04 - mae: 0.0032 - val_loss: 2.7689e-04 - val_mae: 0.0025\n",
      "Epoch 100/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.9094e-04 - mae: 0.0030 - val_loss: 2.7429e-04 - val_mae: 0.0024\n",
      "Epoch 101/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.8404e-04 - mae: 0.0028 - val_loss: 2.7548e-04 - val_mae: 0.0030\n",
      "Epoch 102/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.8134e-04 - mae: 0.0029 - val_loss: 2.7111e-04 - val_mae: 0.0030\n",
      "Epoch 103/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.7980e-04 - mae: 0.0030 - val_loss: 2.6236e-04 - val_mae: 0.0021\n",
      "Epoch 104/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.7818e-04 - mae: 0.0030 - val_loss: 2.6825e-04 - val_mae: 0.0033\n",
      "Epoch 105/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.7319e-04 - mae: 0.0029 - val_loss: 2.7751e-04 - val_mae: 0.0043\n",
      "Epoch 106/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.7305e-04 - mae: 0.0031 - val_loss: 3.2646e-04 - val_mae: 0.0083\n",
      "Epoch 107/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.7040e-04 - mae: 0.0030 - val_loss: 2.5194e-04 - val_mae: 0.0022\n",
      "Epoch 108/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.6500e-04 - mae: 0.0029 - val_loss: 2.4730e-04 - val_mae: 0.0019\n",
      "Epoch 109/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.6096e-04 - mae: 0.0028 - val_loss: 2.4555e-04 - val_mae: 0.0021\n",
      "Epoch 110/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.6037e-04 - mae: 0.0029 - val_loss: 2.4456e-04 - val_mae: 0.0024\n",
      "Epoch 111/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.5708e-04 - mae: 0.0029 - val_loss: 2.4068e-04 - val_mae: 0.0021\n",
      "Epoch 112/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.5589e-04 - mae: 0.0029 - val_loss: 2.3879e-04 - val_mae: 0.0022\n",
      "Epoch 113/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.5610e-04 - mae: 0.0031 - val_loss: 2.3618e-04 - val_mae: 0.0022\n",
      "Epoch 114/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.4874e-04 - mae: 0.0028 - val_loss: 2.3612e-04 - val_mae: 0.0025\n",
      "Epoch 115/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.4835e-04 - mae: 0.0029 - val_loss: 2.3195e-04 - val_mae: 0.0022\n",
      "Epoch 116/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.4499e-04 - mae: 0.0028 - val_loss: 2.7291e-04 - val_mae: 0.0059\n",
      "Epoch 117/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.4543e-04 - mae: 0.0030 - val_loss: 2.3083e-04 - val_mae: 0.0026\n",
      "Epoch 118/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.4628e-04 - mae: 0.0031 - val_loss: 2.2842e-04 - val_mae: 0.0027\n",
      "Epoch 119/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3735e-04 - mae: 0.0027 - val_loss: 2.2691e-04 - val_mae: 0.0025\n",
      "Epoch 120/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3686e-04 - mae: 0.0028 - val_loss: 2.2434e-04 - val_mae: 0.0027\n",
      "Epoch 121/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3687e-04 - mae: 0.0029 - val_loss: 2.2035e-04 - val_mae: 0.0023\n",
      "Epoch 122/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3374e-04 - mae: 0.0029 - val_loss: 2.1746e-04 - val_mae: 0.0020\n",
      "Epoch 123/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3127e-04 - mae: 0.0029 - val_loss: 2.1799e-04 - val_mae: 0.0025\n",
      "Epoch 124/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2739e-04 - mae: 0.0028 - val_loss: 2.1254e-04 - val_mae: 0.0018\n",
      "Epoch 125/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2889e-04 - mae: 0.0029 - val_loss: 2.1860e-04 - val_mae: 0.0029\n",
      "Epoch 126/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2430e-04 - mae: 0.0028 - val_loss: 2.2424e-04 - val_mae: 0.0040\n",
      "Epoch 127/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2703e-04 - mae: 0.0030 - val_loss: 2.2003e-04 - val_mae: 0.0035\n",
      "Epoch 128/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2207e-04 - mae: 0.0028 - val_loss: 2.1222e-04 - val_mae: 0.0030\n",
      "Epoch 129/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2029e-04 - mae: 0.0028 - val_loss: 2.0574e-04 - val_mae: 0.0021\n",
      "Epoch 130/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1814e-04 - mae: 0.0028 - val_loss: 2.1583e-04 - val_mae: 0.0033\n",
      "Epoch 131/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1903e-04 - mae: 0.0030 - val_loss: 2.0131e-04 - val_mae: 0.0020\n",
      "Epoch 132/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1791e-04 - mae: 0.0029 - val_loss: 1.9978e-04 - val_mae: 0.0019\n",
      "Epoch 133/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1616e-04 - mae: 0.0029 - val_loss: 1.9984e-04 - val_mae: 0.0022\n",
      "Epoch 134/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1540e-04 - mae: 0.0028 - val_loss: 1.9925e-04 - val_mae: 0.0023\n",
      "Epoch 135/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1033e-04 - mae: 0.0027 - val_loss: 2.0144e-04 - val_mae: 0.0028\n",
      "Epoch 136/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1148e-04 - mae: 0.0028 - val_loss: 1.9728e-04 - val_mae: 0.0024\n",
      "Epoch 137/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1016e-04 - mae: 0.0029 - val_loss: 1.9324e-04 - val_mae: 0.0020\n",
      "Epoch 138/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0951e-04 - mae: 0.0029 - val_loss: 1.9325e-04 - val_mae: 0.0022\n",
      "Epoch 139/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0591e-04 - mae: 0.0028 - val_loss: 1.9677e-04 - val_mae: 0.0028\n",
      "Epoch 140/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0817e-04 - mae: 0.0029 - val_loss: 1.9006e-04 - val_mae: 0.0020\n",
      "Epoch 141/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0505e-04 - mae: 0.0029 - val_loss: 1.9517e-04 - val_mae: 0.0027\n",
      "Epoch 142/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0293e-04 - mae: 0.0028 - val_loss: 1.8667e-04 - val_mae: 0.0018\n",
      "Epoch 143/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0299e-04 - mae: 0.0028 - val_loss: 1.8798e-04 - val_mae: 0.0022\n",
      "Epoch 144/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0122e-04 - mae: 0.0029 - val_loss: 2.0813e-04 - val_mae: 0.0049\n",
      "Epoch 145/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0070e-04 - mae: 0.0029 - val_loss: 1.8758e-04 - val_mae: 0.0026\n",
      "Epoch 146/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9883e-04 - mae: 0.0028 - val_loss: 1.8320e-04 - val_mae: 0.0020\n",
      "Epoch 147/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9671e-04 - mae: 0.0027 - val_loss: 1.9602e-04 - val_mae: 0.0038\n",
      "Epoch 148/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9980e-04 - mae: 0.0029 - val_loss: 1.7992e-04 - val_mae: 0.0018\n",
      "Epoch 149/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9625e-04 - mae: 0.0028 - val_loss: 1.8587e-04 - val_mae: 0.0026\n",
      "Epoch 150/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9420e-04 - mae: 0.0028 - val_loss: 1.7829e-04 - val_mae: 0.0018\n",
      "Epoch 151/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9356e-04 - mae: 0.0028 - val_loss: 1.7844e-04 - val_mae: 0.0020\n",
      "Epoch 152/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9139e-04 - mae: 0.0028 - val_loss: 1.7763e-04 - val_mae: 0.0021\n",
      "Epoch 153/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9209e-04 - mae: 0.0028 - val_loss: 1.8029e-04 - val_mae: 0.0028\n",
      "Epoch 154/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9060e-04 - mae: 0.0029 - val_loss: 1.8002e-04 - val_mae: 0.0027\n",
      "Epoch 155/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8930e-04 - mae: 0.0028 - val_loss: 1.7581e-04 - val_mae: 0.0023\n",
      "Epoch 156/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8849e-04 - mae: 0.0027 - val_loss: 1.7454e-04 - val_mae: 0.0023\n",
      "Epoch 157/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8745e-04 - mae: 0.0028 - val_loss: 1.7123e-04 - val_mae: 0.0018\n",
      "Epoch 158/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8712e-04 - mae: 0.0028 - val_loss: 1.7713e-04 - val_mae: 0.0028\n",
      "Epoch 159/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8745e-04 - mae: 0.0028 - val_loss: 1.7908e-04 - val_mae: 0.0032\n",
      "Epoch 160/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8735e-04 - mae: 0.0029 - val_loss: 1.7006e-04 - val_mae: 0.0020\n",
      "Epoch 161/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8247e-04 - mae: 0.0026 - val_loss: 1.7062e-04 - val_mae: 0.0022\n",
      "Epoch 162/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8331e-04 - mae: 0.0028 - val_loss: 1.6975e-04 - val_mae: 0.0023\n",
      "Epoch 163/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8111e-04 - mae: 0.0027 - val_loss: 1.7365e-04 - val_mae: 0.0030\n",
      "Epoch 164/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8101e-04 - mae: 0.0027 - val_loss: 1.7015e-04 - val_mae: 0.0024\n",
      "Epoch 165/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8170e-04 - mae: 0.0028 - val_loss: 1.6894e-04 - val_mae: 0.0026\n",
      "Epoch 166/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8011e-04 - mae: 0.0028 - val_loss: 1.6622e-04 - val_mae: 0.0022\n",
      "Epoch 167/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7842e-04 - mae: 0.0027 - val_loss: 1.6396e-04 - val_mae: 0.0019\n",
      "Epoch 168/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7920e-04 - mae: 0.0028 - val_loss: 1.6368e-04 - val_mae: 0.0020\n",
      "Epoch 169/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7649e-04 - mae: 0.0027 - val_loss: 1.6381e-04 - val_mae: 0.0022\n",
      "Epoch 170/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7663e-04 - mae: 0.0027 - val_loss: 1.6618e-04 - val_mae: 0.0028\n",
      "Epoch 171/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7703e-04 - mae: 0.0028 - val_loss: 1.7067e-04 - val_mae: 0.0033\n",
      "Epoch 172/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7538e-04 - mae: 0.0028 - val_loss: 1.6414e-04 - val_mae: 0.0024\n",
      "Epoch 173/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7535e-04 - mae: 0.0028 - val_loss: 1.6211e-04 - val_mae: 0.0023\n",
      "Epoch 174/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7414e-04 - mae: 0.0028 - val_loss: 1.5925e-04 - val_mae: 0.0022\n",
      "Epoch 175/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7388e-04 - mae: 0.0027 - val_loss: 1.6798e-04 - val_mae: 0.0033\n",
      "Epoch 176/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7101e-04 - mae: 0.0026 - val_loss: 1.5814e-04 - val_mae: 0.0020\n",
      "Epoch 177/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7141e-04 - mae: 0.0027 - val_loss: 1.5672e-04 - val_mae: 0.0020\n",
      "Epoch 178/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7391e-04 - mae: 0.0028 - val_loss: 1.5642e-04 - val_mae: 0.0018\n",
      "Epoch 179/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7031e-04 - mae: 0.0027 - val_loss: 1.5975e-04 - val_mae: 0.0024\n",
      "Epoch 180/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6941e-04 - mae: 0.0027 - val_loss: 1.5521e-04 - val_mae: 0.0020\n",
      "Epoch 181/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6956e-04 - mae: 0.0027 - val_loss: 1.5480e-04 - val_mae: 0.0020\n",
      "Epoch 182/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7233e-04 - mae: 0.0029 - val_loss: 1.5668e-04 - val_mae: 0.0025\n",
      "Epoch 183/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6559e-04 - mae: 0.0025 - val_loss: 1.5716e-04 - val_mae: 0.0025\n",
      "Epoch 184/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6655e-04 - mae: 0.0027 - val_loss: 1.5570e-04 - val_mae: 0.0025\n",
      "Epoch 185/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6785e-04 - mae: 0.0028 - val_loss: 1.5246e-04 - val_mae: 0.0020\n",
      "Epoch 186/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6681e-04 - mae: 0.0027 - val_loss: 1.6120e-04 - val_mae: 0.0031\n",
      "Epoch 187/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6745e-04 - mae: 0.0029 - val_loss: 1.5122e-04 - val_mae: 0.0019\n",
      "Epoch 188/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6428e-04 - mae: 0.0027 - val_loss: 1.5235e-04 - val_mae: 0.0022\n",
      "Epoch 189/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6637e-04 - mae: 0.0028 - val_loss: 1.5155e-04 - val_mae: 0.0023\n",
      "Epoch 190/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6313e-04 - mae: 0.0026 - val_loss: 1.5888e-04 - val_mae: 0.0033\n",
      "Epoch 191/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6398e-04 - mae: 0.0028 - val_loss: 1.4827e-04 - val_mae: 0.0018\n",
      "Epoch 192/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6315e-04 - mae: 0.0027 - val_loss: 1.4776e-04 - val_mae: 0.0018\n",
      "Epoch 193/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6301e-04 - mae: 0.0027 - val_loss: 1.5469e-04 - val_mae: 0.0028\n",
      "Epoch 194/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5980e-04 - mae: 0.0026 - val_loss: 1.4808e-04 - val_mae: 0.0020\n",
      "Epoch 195/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6279e-04 - mae: 0.0027 - val_loss: 1.4659e-04 - val_mae: 0.0019\n",
      "Epoch 196/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6006e-04 - mae: 0.0026 - val_loss: 1.4960e-04 - val_mae: 0.0024\n",
      "Epoch 197/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6004e-04 - mae: 0.0027 - val_loss: 1.4736e-04 - val_mae: 0.0022\n",
      "Epoch 198/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5925e-04 - mae: 0.0026 - val_loss: 1.5867e-04 - val_mae: 0.0037\n",
      "Epoch 199/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5854e-04 - mae: 0.0026 - val_loss: 1.4500e-04 - val_mae: 0.0020\n",
      "Epoch 200/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5961e-04 - mae: 0.0028 - val_loss: 1.5196e-04 - val_mae: 0.0033\n",
      "Epoch 201/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5762e-04 - mae: 0.0026 - val_loss: 1.4464e-04 - val_mae: 0.0021\n",
      "Epoch 202/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5795e-04 - mae: 0.0027 - val_loss: 1.4390e-04 - val_mae: 0.0020\n",
      "Epoch 203/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5655e-04 - mae: 0.0026 - val_loss: 1.5041e-04 - val_mae: 0.0028\n",
      "Epoch 204/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5684e-04 - mae: 0.0027 - val_loss: 1.4284e-04 - val_mae: 0.0020\n",
      "Epoch 205/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5726e-04 - mae: 0.0026 - val_loss: 1.4443e-04 - val_mae: 0.0024\n",
      "Epoch 206/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5563e-04 - mae: 0.0027 - val_loss: 1.4316e-04 - val_mae: 0.0021\n",
      "Epoch 207/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5425e-04 - mae: 0.0026 - val_loss: 1.4014e-04 - val_mae: 0.0018\n",
      "Epoch 208/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5318e-04 - mae: 0.0026 - val_loss: 1.4152e-04 - val_mae: 0.0021\n",
      "Epoch 209/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5626e-04 - mae: 0.0028 - val_loss: 1.4370e-04 - val_mae: 0.0026\n",
      "Epoch 210/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5264e-04 - mae: 0.0026 - val_loss: 1.4521e-04 - val_mae: 0.0027\n",
      "Epoch 211/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5312e-04 - mae: 0.0027 - val_loss: 1.4507e-04 - val_mae: 0.0030\n",
      "Epoch 212/1000\n",
      "1416/1426 [============================>.] - ETA: 0s - loss: 1.5223e-04 - mae: 0.0026Restoring model weights from the end of the best epoch: 207.\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5247e-04 - mae: 0.0026 - val_loss: 1.6195e-04 - val_mae: 0.0046\n",
      "Epoch 212: early stopping\n",
      "Training fÃ¼r Fold 4...\n",
      "Epoch 1/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0279 - mae: 0.0604 - val_loss: 0.0142 - val_mae: 0.0202\n",
      "Epoch 2/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0128 - mae: 0.0115 - val_loss: 0.0119 - val_mae: 0.0077\n",
      "Epoch 3/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0114 - mae: 0.0097 - val_loss: 0.0112 - val_mae: 0.0165\n",
      "Epoch 4/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0104 - mae: 0.0096 - val_loss: 0.0098 - val_mae: 0.0076\n",
      "Epoch 5/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0094 - mae: 0.0078 - val_loss: 0.0103 - val_mae: 0.0292\n",
      "Epoch 6/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0087 - mae: 0.0080 - val_loss: 0.0085 - val_mae: 0.0124\n",
      "Epoch 7/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0081 - mae: 0.0074 - val_loss: 0.0077 - val_mae: 0.0048\n",
      "Epoch 8/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0075 - mae: 0.0072 - val_loss: 0.0072 - val_mae: 0.0049\n",
      "Epoch 9/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0070 - mae: 0.0065 - val_loss: 0.0067 - val_mae: 0.0059\n",
      "Epoch 10/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0065 - mae: 0.0067 - val_loss: 0.0063 - val_mae: 0.0067\n",
      "Epoch 11/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0061 - mae: 0.0060 - val_loss: 0.0076 - val_mae: 0.0248\n",
      "Epoch 12/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0058 - mae: 0.0065 - val_loss: 0.0057 - val_mae: 0.0110\n",
      "Epoch 13/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0055 - mae: 0.0058 - val_loss: 0.0053 - val_mae: 0.0079\n",
      "Epoch 14/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0052 - mae: 0.0055 - val_loss: 0.0050 - val_mae: 0.0030\n",
      "Epoch 15/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0049 - mae: 0.0052 - val_loss: 0.0048 - val_mae: 0.0097\n",
      "Epoch 16/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0046 - mae: 0.0059 - val_loss: 0.0045 - val_mae: 0.0036\n",
      "Epoch 17/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0044 - mae: 0.0050 - val_loss: 0.0042 - val_mae: 0.0029\n",
      "Epoch 18/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0042 - mae: 0.0051 - val_loss: 0.0041 - val_mae: 0.0094\n",
      "Epoch 19/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0040 - mae: 0.0056 - val_loss: 0.0038 - val_mae: 0.0034\n",
      "Epoch 20/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0038 - mae: 0.0047 - val_loss: 0.0037 - val_mae: 0.0078\n",
      "Epoch 21/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0036 - mae: 0.0050 - val_loss: 0.0035 - val_mae: 0.0043\n",
      "Epoch 22/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0034 - mae: 0.0045 - val_loss: 0.0033 - val_mae: 0.0039\n",
      "Epoch 23/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0032 - mae: 0.0045 - val_loss: 0.0032 - val_mae: 0.0061\n",
      "Epoch 24/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0031 - mae: 0.0043 - val_loss: 0.0030 - val_mae: 0.0026\n",
      "Epoch 25/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0029 - mae: 0.0042 - val_loss: 0.0028 - val_mae: 0.0032\n",
      "Epoch 26/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0028 - mae: 0.0042 - val_loss: 0.0027 - val_mae: 0.0028\n",
      "Epoch 27/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0027 - mae: 0.0043 - val_loss: 0.0026 - val_mae: 0.0036\n",
      "Epoch 28/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0025 - mae: 0.0039 - val_loss: 0.0024 - val_mae: 0.0029\n",
      "Epoch 29/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0024 - mae: 0.0043 - val_loss: 0.0024 - val_mae: 0.0054\n",
      "Epoch 30/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0023 - mae: 0.0042 - val_loss: 0.0022 - val_mae: 0.0034\n",
      "Epoch 31/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0022 - mae: 0.0042 - val_loss: 0.0021 - val_mae: 0.0022\n",
      "Epoch 32/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0021 - mae: 0.0038 - val_loss: 0.0020 - val_mae: 0.0027\n",
      "Epoch 33/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0020 - mae: 0.0040 - val_loss: 0.0019 - val_mae: 0.0035\n",
      "Epoch 34/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0019 - mae: 0.0038 - val_loss: 0.0019 - val_mae: 0.0025\n",
      "Epoch 35/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0018 - mae: 0.0040 - val_loss: 0.0018 - val_mae: 0.0021\n",
      "Epoch 36/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0018 - mae: 0.0039 - val_loss: 0.0017 - val_mae: 0.0030\n",
      "Epoch 37/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0017 - mae: 0.0037 - val_loss: 0.0016 - val_mae: 0.0023\n",
      "Epoch 38/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0016 - mae: 0.0036 - val_loss: 0.0016 - val_mae: 0.0058\n",
      "Epoch 39/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0016 - mae: 0.0039 - val_loss: 0.0015 - val_mae: 0.0034\n",
      "Epoch 40/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0015 - mae: 0.0038 - val_loss: 0.0014 - val_mae: 0.0027\n",
      "Epoch 41/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0014 - mae: 0.0033 - val_loss: 0.0014 - val_mae: 0.0049\n",
      "Epoch 42/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0014 - mae: 0.0036 - val_loss: 0.0013 - val_mae: 0.0032\n",
      "Epoch 43/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0013 - mae: 0.0035 - val_loss: 0.0014 - val_mae: 0.0077\n",
      "Epoch 44/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0013 - mae: 0.0038 - val_loss: 0.0012 - val_mae: 0.0021\n",
      "Epoch 45/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0012 - mae: 0.0033 - val_loss: 0.0012 - val_mae: 0.0021\n",
      "Epoch 46/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0012 - mae: 0.0032 - val_loss: 0.0011 - val_mae: 0.0025\n",
      "Epoch 47/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0011 - mae: 0.0035 - val_loss: 0.0011 - val_mae: 0.0029\n",
      "Epoch 48/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0011 - mae: 0.0036 - val_loss: 0.0011 - val_mae: 0.0026\n",
      "Epoch 49/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0011 - mae: 0.0032 - val_loss: 0.0010 - val_mae: 0.0021\n",
      "Epoch 50/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0010 - mae: 0.0033 - val_loss: 9.9040e-04 - val_mae: 0.0030\n",
      "Epoch 51/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 9.9402e-04 - mae: 0.0032 - val_loss: 9.8614e-04 - val_mae: 0.0047\n",
      "Epoch 52/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 9.6214e-04 - mae: 0.0034 - val_loss: 9.2286e-04 - val_mae: 0.0024\n",
      "Epoch 53/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 9.2850e-04 - mae: 0.0032 - val_loss: 8.9199e-04 - val_mae: 0.0025\n",
      "Epoch 54/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 8.9321e-04 - mae: 0.0031 - val_loss: 8.6132e-04 - val_mae: 0.0025\n",
      "Epoch 55/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 8.6917e-04 - mae: 0.0033 - val_loss: 8.4027e-04 - val_mae: 0.0030\n",
      "Epoch 56/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 8.3945e-04 - mae: 0.0032 - val_loss: 8.1187e-04 - val_mae: 0.0031\n",
      "Epoch 57/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 8.1748e-04 - mae: 0.0034 - val_loss: 7.8230e-04 - val_mae: 0.0026\n",
      "Epoch 58/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.9107e-04 - mae: 0.0032 - val_loss: 7.5692e-04 - val_mae: 0.0020\n",
      "Epoch 59/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.6396e-04 - mae: 0.0030 - val_loss: 7.3849e-04 - val_mae: 0.0028\n",
      "Epoch 60/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.4981e-04 - mae: 0.0034 - val_loss: 7.1456e-04 - val_mae: 0.0023\n",
      "Epoch 61/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.2223e-04 - mae: 0.0031 - val_loss: 6.9428e-04 - val_mae: 0.0025\n",
      "Epoch 62/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.0122e-04 - mae: 0.0030 - val_loss: 6.7276e-04 - val_mae: 0.0024\n",
      "Epoch 63/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.8159e-04 - mae: 0.0030 - val_loss: 6.5728e-04 - val_mae: 0.0029\n",
      "Epoch 64/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.6212e-04 - mae: 0.0029 - val_loss: 6.6318e-04 - val_mae: 0.0048\n",
      "Epoch 65/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.4598e-04 - mae: 0.0030 - val_loss: 6.1467e-04 - val_mae: 0.0017\n",
      "Epoch 66/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.2941e-04 - mae: 0.0030 - val_loss: 6.0174e-04 - val_mae: 0.0023\n",
      "Epoch 67/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.1391e-04 - mae: 0.0029 - val_loss: 5.8680e-04 - val_mae: 0.0024\n",
      "Epoch 68/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.9448e-04 - mae: 0.0028 - val_loss: 5.7499e-04 - val_mae: 0.0027\n",
      "Epoch 69/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.8466e-04 - mae: 0.0030 - val_loss: 5.5435e-04 - val_mae: 0.0018\n",
      "Epoch 70/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.6671e-04 - mae: 0.0029 - val_loss: 5.4132e-04 - val_mae: 0.0018\n",
      "Epoch 71/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.5952e-04 - mae: 0.0031 - val_loss: 5.2915e-04 - val_mae: 0.0020\n",
      "Epoch 72/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.3988e-04 - mae: 0.0028 - val_loss: 5.2004e-04 - val_mae: 0.0024\n",
      "Epoch 73/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.3025e-04 - mae: 0.0029 - val_loss: 5.1757e-04 - val_mae: 0.0035\n",
      "Epoch 74/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.1477e-04 - mae: 0.0028 - val_loss: 4.9174e-04 - val_mae: 0.0018\n",
      "Epoch 75/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.0711e-04 - mae: 0.0029 - val_loss: 4.8255e-04 - val_mae: 0.0023\n",
      "Epoch 76/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.9529e-04 - mae: 0.0029 - val_loss: 4.8061e-04 - val_mae: 0.0032\n",
      "Epoch 77/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.8611e-04 - mae: 0.0030 - val_loss: 4.6350e-04 - val_mae: 0.0026\n",
      "Epoch 78/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.7503e-04 - mae: 0.0028 - val_loss: 5.3164e-04 - val_mae: 0.0075\n",
      "Epoch 79/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.6512e-04 - mae: 0.0029 - val_loss: 4.4181e-04 - val_mae: 0.0020\n",
      "Epoch 80/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.5700e-04 - mae: 0.0028 - val_loss: 4.4770e-04 - val_mae: 0.0038\n",
      "Epoch 81/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.4315e-04 - mae: 0.0026 - val_loss: 4.2351e-04 - val_mae: 0.0020\n",
      "Epoch 82/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.3854e-04 - mae: 0.0028 - val_loss: 4.1487e-04 - val_mae: 0.0020\n",
      "Epoch 83/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.3055e-04 - mae: 0.0029 - val_loss: 4.0548e-04 - val_mae: 0.0018\n",
      "Epoch 84/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.2123e-04 - mae: 0.0027 - val_loss: 4.2263e-04 - val_mae: 0.0044\n",
      "Epoch 85/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.1273e-04 - mae: 0.0027 - val_loss: 4.2770e-04 - val_mae: 0.0057\n",
      "Epoch 86/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.0630e-04 - mae: 0.0028 - val_loss: 3.8999e-04 - val_mae: 0.0030\n",
      "Epoch 87/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.9607e-04 - mae: 0.0027 - val_loss: 3.7646e-04 - val_mae: 0.0019\n",
      "Epoch 88/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.8991e-04 - mae: 0.0028 - val_loss: 3.8475e-04 - val_mae: 0.0038\n",
      "Epoch 89/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.8204e-04 - mae: 0.0027 - val_loss: 3.6974e-04 - val_mae: 0.0030\n",
      "Epoch 90/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.7383e-04 - mae: 0.0026 - val_loss: 3.5776e-04 - val_mae: 0.0024\n",
      "Epoch 91/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.6989e-04 - mae: 0.0028 - val_loss: 3.5478e-04 - val_mae: 0.0029\n",
      "Epoch 92/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.6625e-04 - mae: 0.0028 - val_loss: 3.4754e-04 - val_mae: 0.0025\n",
      "Epoch 93/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.5721e-04 - mae: 0.0027 - val_loss: 3.4151e-04 - val_mae: 0.0026\n",
      "Epoch 94/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.5396e-04 - mae: 0.0028 - val_loss: 3.3149e-04 - val_mae: 0.0017\n",
      "Epoch 95/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.4894e-04 - mae: 0.0027 - val_loss: 3.2859e-04 - val_mae: 0.0022\n",
      "Epoch 96/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.4050e-04 - mae: 0.0026 - val_loss: 3.2199e-04 - val_mae: 0.0018\n",
      "Epoch 97/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.3634e-04 - mae: 0.0027 - val_loss: 3.1701e-04 - val_mae: 0.0018\n",
      "Epoch 98/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.3355e-04 - mae: 0.0027 - val_loss: 3.1160e-04 - val_mae: 0.0017\n",
      "Epoch 99/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.2476e-04 - mae: 0.0025 - val_loss: 3.1195e-04 - val_mae: 0.0025\n",
      "Epoch 100/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.2439e-04 - mae: 0.0027 - val_loss: 3.0257e-04 - val_mae: 0.0017\n",
      "Epoch 101/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.1999e-04 - mae: 0.0027 - val_loss: 3.0143e-04 - val_mae: 0.0023\n",
      "Epoch 102/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.1367e-04 - mae: 0.0027 - val_loss: 2.9446e-04 - val_mae: 0.0018\n",
      "Epoch 103/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.1043e-04 - mae: 0.0028 - val_loss: 2.9017e-04 - val_mae: 0.0017\n",
      "Epoch 104/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.0637e-04 - mae: 0.0026 - val_loss: 3.0161e-04 - val_mae: 0.0039\n",
      "Epoch 105/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.0232e-04 - mae: 0.0027 - val_loss: 2.8239e-04 - val_mae: 0.0017\n",
      "Epoch 106/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.9934e-04 - mae: 0.0027 - val_loss: 2.8115e-04 - val_mae: 0.0020\n",
      "Epoch 107/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.9509e-04 - mae: 0.0026 - val_loss: 2.8252e-04 - val_mae: 0.0028\n",
      "Epoch 108/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.9037e-04 - mae: 0.0026 - val_loss: 2.7186e-04 - val_mae: 0.0017\n",
      "Epoch 109/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.8704e-04 - mae: 0.0026 - val_loss: 2.7088e-04 - val_mae: 0.0022\n",
      "Epoch 110/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.8539e-04 - mae: 0.0028 - val_loss: 2.6964e-04 - val_mae: 0.0024\n",
      "Epoch 111/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.7967e-04 - mae: 0.0026 - val_loss: 2.6985e-04 - val_mae: 0.0027\n",
      "Epoch 112/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.8180e-04 - mae: 0.0029 - val_loss: 2.6417e-04 - val_mae: 0.0026\n",
      "Epoch 113/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.7470e-04 - mae: 0.0026 - val_loss: 2.5758e-04 - val_mae: 0.0019\n",
      "Epoch 114/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.7203e-04 - mae: 0.0026 - val_loss: 2.5375e-04 - val_mae: 0.0018\n",
      "Epoch 115/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.6799e-04 - mae: 0.0026 - val_loss: 2.5275e-04 - val_mae: 0.0022\n",
      "Epoch 116/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.6841e-04 - mae: 0.0027 - val_loss: 2.5124e-04 - val_mae: 0.0022\n",
      "Epoch 117/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.6271e-04 - mae: 0.0025 - val_loss: 2.4638e-04 - val_mae: 0.0019\n",
      "Epoch 118/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.6088e-04 - mae: 0.0026 - val_loss: 2.4403e-04 - val_mae: 0.0020\n",
      "Epoch 119/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.5981e-04 - mae: 0.0027 - val_loss: 2.5242e-04 - val_mae: 0.0031\n",
      "Epoch 120/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.5524e-04 - mae: 0.0025 - val_loss: 2.4010e-04 - val_mae: 0.0022\n",
      "Epoch 121/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.5385e-04 - mae: 0.0026 - val_loss: 2.3557e-04 - val_mae: 0.0017\n",
      "Epoch 122/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.5159e-04 - mae: 0.0026 - val_loss: 2.3311e-04 - val_mae: 0.0017\n",
      "Epoch 123/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.4911e-04 - mae: 0.0026 - val_loss: 2.3154e-04 - val_mae: 0.0018\n",
      "Epoch 124/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.4656e-04 - mae: 0.0026 - val_loss: 2.3001e-04 - val_mae: 0.0019\n",
      "Epoch 125/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.4360e-04 - mae: 0.0025 - val_loss: 2.2907e-04 - val_mae: 0.0021\n",
      "Epoch 126/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.4225e-04 - mae: 0.0026 - val_loss: 2.2429e-04 - val_mae: 0.0017\n",
      "Epoch 127/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3935e-04 - mae: 0.0025 - val_loss: 2.2165e-04 - val_mae: 0.0016\n",
      "Epoch 128/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3933e-04 - mae: 0.0026 - val_loss: 2.3441e-04 - val_mae: 0.0034\n",
      "Epoch 129/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3486e-04 - mae: 0.0026 - val_loss: 2.1846e-04 - val_mae: 0.0018\n",
      "Epoch 130/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3448e-04 - mae: 0.0026 - val_loss: 2.1657e-04 - val_mae: 0.0017\n",
      "Epoch 131/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3117e-04 - mae: 0.0025 - val_loss: 2.1550e-04 - val_mae: 0.0019\n",
      "Epoch 132/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2907e-04 - mae: 0.0025 - val_loss: 2.4189e-04 - val_mae: 0.0049\n",
      "Epoch 133/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3172e-04 - mae: 0.0027 - val_loss: 2.6619e-04 - val_mae: 0.0071\n",
      "Epoch 134/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2741e-04 - mae: 0.0026 - val_loss: 2.1295e-04 - val_mae: 0.0025\n",
      "Epoch 135/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2405e-04 - mae: 0.0025 - val_loss: 2.0892e-04 - val_mae: 0.0019\n",
      "Epoch 136/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2122e-04 - mae: 0.0024 - val_loss: 2.1520e-04 - val_mae: 0.0034\n",
      "Epoch 137/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2093e-04 - mae: 0.0026 - val_loss: 2.0596e-04 - val_mae: 0.0019\n",
      "Epoch 138/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1825e-04 - mae: 0.0024 - val_loss: 2.0229e-04 - val_mae: 0.0016\n",
      "Epoch 139/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1757e-04 - mae: 0.0025 - val_loss: 2.0263e-04 - val_mae: 0.0020\n",
      "Epoch 140/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1455e-04 - mae: 0.0024 - val_loss: 1.9986e-04 - val_mae: 0.0018\n",
      "Epoch 141/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1660e-04 - mae: 0.0026 - val_loss: 4.3138e-04 - val_mae: 0.0142\n",
      "Epoch 142/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1151e-04 - mae: 0.0024 - val_loss: 2.0148e-04 - val_mae: 0.0025\n",
      "Epoch 143/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1119e-04 - mae: 0.0025 - val_loss: 1.9588e-04 - val_mae: 0.0019\n",
      "Epoch 144/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1039e-04 - mae: 0.0026 - val_loss: 2.5822e-04 - val_mae: 0.0072\n",
      "Epoch 145/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0751e-04 - mae: 0.0025 - val_loss: 1.9494e-04 - val_mae: 0.0023\n",
      "Epoch 146/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1041e-04 - mae: 0.0026 - val_loss: 2.4607e-04 - val_mae: 0.0068\n",
      "Epoch 147/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0407e-04 - mae: 0.0024 - val_loss: 1.9181e-04 - val_mae: 0.0021\n",
      "Epoch 148/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0492e-04 - mae: 0.0026 - val_loss: 3.1219e-04 - val_mae: 0.0098\n",
      "Epoch 149/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0164e-04 - mae: 0.0024 - val_loss: 1.8830e-04 - val_mae: 0.0021\n",
      "Epoch 150/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0092e-04 - mae: 0.0024 - val_loss: 2.2033e-04 - val_mae: 0.0047\n",
      "Epoch 151/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0049e-04 - mae: 0.0026 - val_loss: 1.9008e-04 - val_mae: 0.0027\n",
      "Epoch 152/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9825e-04 - mae: 0.0025 - val_loss: 1.8890e-04 - val_mae: 0.0028\n",
      "Epoch 153/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9761e-04 - mae: 0.0025 - val_loss: 1.8206e-04 - val_mae: 0.0018\n",
      "Epoch 154/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9605e-04 - mae: 0.0025 - val_loss: 2.1080e-04 - val_mae: 0.0045\n",
      "Epoch 155/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9514e-04 - mae: 0.0025 - val_loss: 1.7998e-04 - val_mae: 0.0019\n",
      "Epoch 156/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9355e-04 - mae: 0.0025 - val_loss: 1.8093e-04 - val_mae: 0.0022\n",
      "Epoch 157/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9446e-04 - mae: 0.0026 - val_loss: 1.7734e-04 - val_mae: 0.0019\n",
      "Epoch 158/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9264e-04 - mae: 0.0026 - val_loss: 1.7778e-04 - val_mae: 0.0023\n",
      "Epoch 159/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8996e-04 - mae: 0.0025 - val_loss: 1.7635e-04 - val_mae: 0.0021\n",
      "Epoch 160/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9213e-04 - mae: 0.0026 - val_loss: 1.7268e-04 - val_mae: 0.0016\n",
      "Epoch 161/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8769e-04 - mae: 0.0025 - val_loss: 1.7174e-04 - val_mae: 0.0016\n",
      "Epoch 162/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8601e-04 - mae: 0.0024 - val_loss: 1.7229e-04 - val_mae: 0.0019\n",
      "Epoch 163/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8404e-04 - mae: 0.0024 - val_loss: 1.7315e-04 - val_mae: 0.0023\n",
      "Epoch 164/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8414e-04 - mae: 0.0025 - val_loss: 1.6849e-04 - val_mae: 0.0016\n",
      "Epoch 165/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8222e-04 - mae: 0.0025 - val_loss: 1.6811e-04 - val_mae: 0.0018\n",
      "Epoch 166/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8100e-04 - mae: 0.0024 - val_loss: 1.8927e-04 - val_mae: 0.0039\n",
      "Epoch 167/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8167e-04 - mae: 0.0026 - val_loss: 1.6661e-04 - val_mae: 0.0019\n",
      "Epoch 168/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8084e-04 - mae: 0.0025 - val_loss: 1.6487e-04 - val_mae: 0.0017\n",
      "Epoch 169/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7995e-04 - mae: 0.0026 - val_loss: 1.6470e-04 - val_mae: 0.0019\n",
      "Epoch 170/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7765e-04 - mae: 0.0025 - val_loss: 1.6641e-04 - val_mae: 0.0022\n",
      "Epoch 171/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7799e-04 - mae: 0.0026 - val_loss: 1.6344e-04 - val_mae: 0.0020\n",
      "Epoch 172/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7553e-04 - mae: 0.0024 - val_loss: 1.6095e-04 - val_mae: 0.0017\n",
      "Epoch 173/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7568e-04 - mae: 0.0025 - val_loss: 1.7573e-04 - val_mae: 0.0039\n",
      "Epoch 174/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7445e-04 - mae: 0.0025 - val_loss: 1.6009e-04 - val_mae: 0.0019\n",
      "Epoch 175/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7416e-04 - mae: 0.0025 - val_loss: 1.5829e-04 - val_mae: 0.0017\n",
      "Epoch 176/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7234e-04 - mae: 0.0025 - val_loss: 1.6254e-04 - val_mae: 0.0025\n",
      "Epoch 177/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7342e-04 - mae: 0.0026 - val_loss: 1.6298e-04 - val_mae: 0.0027\n",
      "Epoch 178/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6922e-04 - mae: 0.0024 - val_loss: 1.5621e-04 - val_mae: 0.0018\n",
      "Epoch 179/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7012e-04 - mae: 0.0025 - val_loss: 1.6163e-04 - val_mae: 0.0027\n",
      "Epoch 180/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6856e-04 - mae: 0.0025 - val_loss: 1.5633e-04 - val_mae: 0.0022\n",
      "Epoch 181/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6841e-04 - mae: 0.0025 - val_loss: 1.5326e-04 - val_mae: 0.0017\n",
      "Epoch 182/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6767e-04 - mae: 0.0025 - val_loss: 1.5652e-04 - val_mae: 0.0023\n",
      "Epoch 183/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6588e-04 - mae: 0.0024 - val_loss: 2.0082e-04 - val_mae: 0.0065\n",
      "Epoch 184/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6465e-04 - mae: 0.0024 - val_loss: 3.3522e-04 - val_mae: 0.0098\n",
      "Epoch 185/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6613e-04 - mae: 0.0026 - val_loss: 1.5269e-04 - val_mae: 0.0020\n",
      "Epoch 186/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6319e-04 - mae: 0.0024 - val_loss: 1.5606e-04 - val_mae: 0.0030\n",
      "Epoch 187/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6372e-04 - mae: 0.0025 - val_loss: 1.5117e-04 - val_mae: 0.0022\n",
      "Epoch 188/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6391e-04 - mae: 0.0026 - val_loss: 1.5510e-04 - val_mae: 0.0028\n",
      "Epoch 189/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6431e-04 - mae: 0.0025 - val_loss: 1.4807e-04 - val_mae: 0.0017\n",
      "Epoch 190/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6077e-04 - mae: 0.0024 - val_loss: 1.5682e-04 - val_mae: 0.0033\n",
      "Epoch 191/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6232e-04 - mae: 0.0026 - val_loss: 1.5362e-04 - val_mae: 0.0030\n",
      "Epoch 192/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6071e-04 - mae: 0.0025 - val_loss: 1.5126e-04 - val_mae: 0.0028\n",
      "Epoch 193/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5890e-04 - mae: 0.0024 - val_loss: 1.4591e-04 - val_mae: 0.0019\n",
      "Epoch 194/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5919e-04 - mae: 0.0025 - val_loss: 1.4776e-04 - val_mae: 0.0022\n",
      "Epoch 195/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5786e-04 - mae: 0.0024 - val_loss: 1.4458e-04 - val_mae: 0.0019\n",
      "Epoch 196/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5633e-04 - mae: 0.0024 - val_loss: 1.4441e-04 - val_mae: 0.0019\n",
      "Epoch 197/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6011e-04 - mae: 0.0026 - val_loss: 1.4300e-04 - val_mae: 0.0018\n",
      "Epoch 198/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5645e-04 - mae: 0.0024 - val_loss: 1.4276e-04 - val_mae: 0.0018\n",
      "Epoch 199/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5436e-04 - mae: 0.0023 - val_loss: 1.4127e-04 - val_mae: 0.0017\n",
      "Epoch 200/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5522e-04 - mae: 0.0025 - val_loss: 2.1336e-04 - val_mae: 0.0074\n",
      "Epoch 201/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5514e-04 - mae: 0.0025 - val_loss: 1.4206e-04 - val_mae: 0.0020\n",
      "Epoch 202/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5431e-04 - mae: 0.0025 - val_loss: 1.3963e-04 - val_mae: 0.0016\n",
      "Epoch 203/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5477e-04 - mae: 0.0025 - val_loss: 1.3900e-04 - val_mae: 0.0016\n",
      "Epoch 204/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5240e-04 - mae: 0.0024 - val_loss: 3.2415e-04 - val_mae: 0.0130\n",
      "Epoch 205/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5379e-04 - mae: 0.0026 - val_loss: 1.4449e-04 - val_mae: 0.0026\n",
      "Epoch 206/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5179e-04 - mae: 0.0025 - val_loss: 1.4016e-04 - val_mae: 0.0020\n",
      "Epoch 207/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5245e-04 - mae: 0.0026 - val_loss: 1.4647e-04 - val_mae: 0.0032\n",
      "Epoch 208/1000\n",
      "1421/1426 [============================>.] - ETA: 0s - loss: 1.5265e-04 - mae: 0.0026Restoring model weights from the end of the best epoch: 203.\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5258e-04 - mae: 0.0026 - val_loss: 1.3907e-04 - val_mae: 0.0021\n",
      "Epoch 208: early stopping\n",
      "Training fÃ¼r Fold 5...\n",
      "Epoch 1/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0458 - mae: 0.0908 - val_loss: 0.0165 - val_mae: 0.0330\n",
      "Epoch 2/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0146 - mae: 0.0187 - val_loss: 0.0137 - val_mae: 0.0111\n",
      "Epoch 3/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0134 - mae: 0.0128 - val_loss: 0.0129 - val_mae: 0.0089\n",
      "Epoch 4/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0126 - mae: 0.0120 - val_loss: 0.0123 - val_mae: 0.0124\n",
      "Epoch 5/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0121 - val_mae: 0.0189\n",
      "Epoch 6/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 0.0113 - mae: 0.0111 - val_loss: 0.0109 - val_mae: 0.0104\n",
      "Epoch 7/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 0.0106 - mae: 0.0093 - val_loss: 0.0102 - val_mae: 0.0057\n",
      "Epoch 8/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0100 - mae: 0.0097 - val_loss: 0.0099 - val_mae: 0.0142\n",
      "Epoch 9/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0093 - mae: 0.0080 - val_loss: 0.0091 - val_mae: 0.0101\n",
      "Epoch 10/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0088 - mae: 0.0091 - val_loss: 0.0085 - val_mae: 0.0075\n",
      "Epoch 11/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0082 - mae: 0.0070 - val_loss: 0.0079 - val_mae: 0.0075\n",
      "Epoch 12/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0077 - mae: 0.0073 - val_loss: 0.0074 - val_mae: 0.0062\n",
      "Epoch 13/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0072 - mae: 0.0074 - val_loss: 0.0070 - val_mae: 0.0056\n",
      "Epoch 14/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0067 - mae: 0.0061 - val_loss: 0.0065 - val_mae: 0.0038\n",
      "Epoch 15/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0064 - mae: 0.0073 - val_loss: 0.0063 - val_mae: 0.0087\n",
      "Epoch 16/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0060 - mae: 0.0059 - val_loss: 0.0058 - val_mae: 0.0042\n",
      "Epoch 17/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0057 - mae: 0.0060 - val_loss: 0.0055 - val_mae: 0.0043\n",
      "Epoch 18/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0054 - mae: 0.0054 - val_loss: 0.0052 - val_mae: 0.0032\n",
      "Epoch 19/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0051 - mae: 0.0054 - val_loss: 0.0049 - val_mae: 0.0036\n",
      "Epoch 20/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0048 - mae: 0.0057 - val_loss: 0.0046 - val_mae: 0.0039\n",
      "Epoch 21/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0045 - mae: 0.0049 - val_loss: 0.0044 - val_mae: 0.0042\n",
      "Epoch 22/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0043 - mae: 0.0050 - val_loss: 0.0042 - val_mae: 0.0030\n",
      "Epoch 23/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0041 - mae: 0.0049 - val_loss: 0.0039 - val_mae: 0.0051\n",
      "Epoch 24/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0038 - mae: 0.0042 - val_loss: 0.0037 - val_mae: 0.0043\n",
      "Epoch 25/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0036 - mae: 0.0045 - val_loss: 0.0035 - val_mae: 0.0037\n",
      "Epoch 26/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0034 - mae: 0.0046 - val_loss: 0.0033 - val_mae: 0.0026\n",
      "Epoch 27/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0032 - mae: 0.0038 - val_loss: 0.0032 - val_mae: 0.0074\n",
      "Epoch 28/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0031 - mae: 0.0037 - val_loss: 0.0030 - val_mae: 0.0030\n",
      "Epoch 29/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0029 - mae: 0.0043 - val_loss: 0.0028 - val_mae: 0.0029\n",
      "Epoch 30/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0028 - mae: 0.0042 - val_loss: 0.0027 - val_mae: 0.0054\n",
      "Epoch 31/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0026 - mae: 0.0037 - val_loss: 0.0025 - val_mae: 0.0032\n",
      "Epoch 32/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0025 - mae: 0.0038 - val_loss: 0.0024 - val_mae: 0.0026\n",
      "Epoch 33/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0023 - mae: 0.0039 - val_loss: 0.0023 - val_mae: 0.0024\n",
      "Epoch 34/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0022 - mae: 0.0035 - val_loss: 0.0022 - val_mae: 0.0031\n",
      "Epoch 35/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0021 - mae: 0.0039 - val_loss: 0.0021 - val_mae: 0.0035\n",
      "Epoch 36/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0020 - mae: 0.0036 - val_loss: 0.0020 - val_mae: 0.0050\n",
      "Epoch 37/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0019 - mae: 0.0036 - val_loss: 0.0019 - val_mae: 0.0019\n",
      "Epoch 38/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0018 - mae: 0.0038 - val_loss: 0.0018 - val_mae: 0.0022\n",
      "Epoch 39/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0017 - mae: 0.0033 - val_loss: 0.0017 - val_mae: 0.0035\n",
      "Epoch 40/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0016 - mae: 0.0036 - val_loss: 0.0016 - val_mae: 0.0031\n",
      "Epoch 41/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0016 - mae: 0.0035 - val_loss: 0.0015 - val_mae: 0.0024\n",
      "Epoch 42/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0015 - mae: 0.0033 - val_loss: 0.0015 - val_mae: 0.0027\n",
      "Epoch 43/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0014 - mae: 0.0036 - val_loss: 0.0014 - val_mae: 0.0029\n",
      "Epoch 44/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0014 - mae: 0.0035 - val_loss: 0.0013 - val_mae: 0.0023\n",
      "Epoch 45/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0013 - mae: 0.0035 - val_loss: 0.0013 - val_mae: 0.0021\n",
      "Epoch 46/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0013 - mae: 0.0035 - val_loss: 0.0013 - val_mae: 0.0045\n",
      "Epoch 47/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0012 - mae: 0.0034 - val_loss: 0.0012 - val_mae: 0.0026\n",
      "Epoch 48/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0012 - mae: 0.0036 - val_loss: 0.0012 - val_mae: 0.0052\n",
      "Epoch 49/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0011 - mae: 0.0031 - val_loss: 0.0011 - val_mae: 0.0045\n",
      "Epoch 50/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0011 - mae: 0.0033 - val_loss: 0.0011 - val_mae: 0.0023\n",
      "Epoch 51/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.0010 - mae: 0.0031 - val_loss: 0.0010 - val_mae: 0.0025\n",
      "Epoch 52/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 9.7998e-04 - mae: 0.0029 - val_loss: 9.7377e-04 - val_mae: 0.0022\n",
      "Epoch 53/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 9.4081e-04 - mae: 0.0031 - val_loss: 9.3214e-04 - val_mae: 0.0020\n",
      "Epoch 54/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 9.0827e-04 - mae: 0.0032 - val_loss: 9.0434e-04 - val_mae: 0.0027\n",
      "Epoch 55/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 8.7511e-04 - mae: 0.0032 - val_loss: 8.6780e-04 - val_mae: 0.0022\n",
      "Epoch 56/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 8.4687e-04 - mae: 0.0032 - val_loss: 8.4777e-04 - val_mae: 0.0030\n",
      "Epoch 57/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 8.0909e-04 - mae: 0.0029 - val_loss: 8.1127e-04 - val_mae: 0.0023\n",
      "Epoch 58/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.8320e-04 - mae: 0.0030 - val_loss: 7.8062e-04 - val_mae: 0.0020\n",
      "Epoch 59/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.5904e-04 - mae: 0.0031 - val_loss: 7.6392e-04 - val_mae: 0.0031\n",
      "Epoch 60/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.3959e-04 - mae: 0.0031 - val_loss: 7.3839e-04 - val_mae: 0.0029\n",
      "Epoch 61/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 7.1067e-04 - mae: 0.0030 - val_loss: 7.1913e-04 - val_mae: 0.0030\n",
      "Epoch 62/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.8684e-04 - mae: 0.0030 - val_loss: 7.0816e-04 - val_mae: 0.0045\n",
      "Epoch 63/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.6162e-04 - mae: 0.0028 - val_loss: 6.6533e-04 - val_mae: 0.0021\n",
      "Epoch 64/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.4450e-04 - mae: 0.0031 - val_loss: 6.4992e-04 - val_mae: 0.0031\n",
      "Epoch 65/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.2115e-04 - mae: 0.0028 - val_loss: 6.7250e-04 - val_mae: 0.0055\n",
      "Epoch 66/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 6.0326e-04 - mae: 0.0029 - val_loss: 6.1317e-04 - val_mae: 0.0030\n",
      "Epoch 67/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.8630e-04 - mae: 0.0030 - val_loss: 6.0139e-04 - val_mae: 0.0038\n",
      "Epoch 68/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.6977e-04 - mae: 0.0030 - val_loss: 5.7206e-04 - val_mae: 0.0019\n",
      "Epoch 69/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.5151e-04 - mae: 0.0028 - val_loss: 5.5909e-04 - val_mae: 0.0024\n",
      "Epoch 70/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.3714e-04 - mae: 0.0029 - val_loss: 7.1288e-04 - val_mae: 0.0105\n",
      "Epoch 71/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.2412e-04 - mae: 0.0029 - val_loss: 5.2958e-04 - val_mae: 0.0021\n",
      "Epoch 72/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 5.0982e-04 - mae: 0.0028 - val_loss: 5.2693e-04 - val_mae: 0.0029\n",
      "Epoch 73/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.9840e-04 - mae: 0.0029 - val_loss: 5.1024e-04 - val_mae: 0.0031\n",
      "Epoch 74/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.8319e-04 - mae: 0.0028 - val_loss: 5.0423e-04 - val_mae: 0.0037\n",
      "Epoch 75/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.7100e-04 - mae: 0.0028 - val_loss: 4.9413e-04 - val_mae: 0.0039\n",
      "Epoch 76/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.5785e-04 - mae: 0.0028 - val_loss: 4.6912e-04 - val_mae: 0.0025\n",
      "Epoch 77/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.4706e-04 - mae: 0.0029 - val_loss: 4.6029e-04 - val_mae: 0.0027\n",
      "Epoch 78/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.3750e-04 - mae: 0.0029 - val_loss: 4.6957e-04 - val_mae: 0.0047\n",
      "Epoch 79/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.2638e-04 - mae: 0.0028 - val_loss: 4.5904e-04 - val_mae: 0.0048\n",
      "Epoch 80/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.1617e-04 - mae: 0.0028 - val_loss: 4.2542e-04 - val_mae: 0.0019\n",
      "Epoch 81/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 4.0910e-04 - mae: 0.0029 - val_loss: 4.1898e-04 - val_mae: 0.0023\n",
      "Epoch 82/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.9783e-04 - mae: 0.0028 - val_loss: 4.4548e-04 - val_mae: 0.0051\n",
      "Epoch 83/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.9082e-04 - mae: 0.0029 - val_loss: 4.0360e-04 - val_mae: 0.0023\n",
      "Epoch 84/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.7976e-04 - mae: 0.0026 - val_loss: 3.9470e-04 - val_mae: 0.0023\n",
      "Epoch 85/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.7882e-04 - mae: 0.0029 - val_loss: 4.0296e-04 - val_mae: 0.0041\n",
      "Epoch 86/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.6746e-04 - mae: 0.0029 - val_loss: 3.8355e-04 - val_mae: 0.0028\n",
      "Epoch 87/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.6159e-04 - mae: 0.0029 - val_loss: 3.7244e-04 - val_mae: 0.0024\n",
      "Epoch 88/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.5463e-04 - mae: 0.0027 - val_loss: 3.9154e-04 - val_mae: 0.0044\n",
      "Epoch 89/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.4969e-04 - mae: 0.0029 - val_loss: 3.5932e-04 - val_mae: 0.0021\n",
      "Epoch 90/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.4002e-04 - mae: 0.0027 - val_loss: 3.6187e-04 - val_mae: 0.0033\n",
      "Epoch 91/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.3657e-04 - mae: 0.0027 - val_loss: 3.4982e-04 - val_mae: 0.0023\n",
      "Epoch 92/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.3092e-04 - mae: 0.0028 - val_loss: 3.4216e-04 - val_mae: 0.0020\n",
      "Epoch 93/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.2666e-04 - mae: 0.0028 - val_loss: 3.3653e-04 - val_mae: 0.0021\n",
      "Epoch 94/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.1911e-04 - mae: 0.0028 - val_loss: 3.3077e-04 - val_mae: 0.0020\n",
      "Epoch 95/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.1414e-04 - mae: 0.0027 - val_loss: 3.2781e-04 - val_mae: 0.0022\n",
      "Epoch 96/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.0810e-04 - mae: 0.0027 - val_loss: 3.2432e-04 - val_mae: 0.0026\n",
      "Epoch 97/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 3.0713e-04 - mae: 0.0028 - val_loss: 3.1658e-04 - val_mae: 0.0020\n",
      "Epoch 98/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.9883e-04 - mae: 0.0026 - val_loss: 3.6706e-04 - val_mae: 0.0061\n",
      "Epoch 99/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.9785e-04 - mae: 0.0029 - val_loss: 3.0898e-04 - val_mae: 0.0021\n",
      "Epoch 100/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.9163e-04 - mae: 0.0027 - val_loss: 3.0602e-04 - val_mae: 0.0024\n",
      "Epoch 101/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.8898e-04 - mae: 0.0027 - val_loss: 3.0032e-04 - val_mae: 0.0020\n",
      "Epoch 102/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.8204e-04 - mae: 0.0026 - val_loss: 2.9902e-04 - val_mae: 0.0025\n",
      "Epoch 103/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.7970e-04 - mae: 0.0027 - val_loss: 2.9350e-04 - val_mae: 0.0020\n",
      "Epoch 104/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.7590e-04 - mae: 0.0028 - val_loss: 3.5907e-04 - val_mae: 0.0073\n",
      "Epoch 105/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.7329e-04 - mae: 0.0028 - val_loss: 2.8550e-04 - val_mae: 0.0020\n",
      "Epoch 106/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.7046e-04 - mae: 0.0027 - val_loss: 2.9525e-04 - val_mae: 0.0036\n",
      "Epoch 107/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.6601e-04 - mae: 0.0028 - val_loss: 2.7986e-04 - val_mae: 0.0021\n",
      "Epoch 108/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.6320e-04 - mae: 0.0027 - val_loss: 2.7836e-04 - val_mae: 0.0022\n",
      "Epoch 109/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.5965e-04 - mae: 0.0027 - val_loss: 2.7809e-04 - val_mae: 0.0029\n",
      "Epoch 110/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.5686e-04 - mae: 0.0027 - val_loss: 2.7108e-04 - val_mae: 0.0021\n",
      "Epoch 111/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.5357e-04 - mae: 0.0027 - val_loss: 2.6835e-04 - val_mae: 0.0022\n",
      "Epoch 112/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.5032e-04 - mae: 0.0027 - val_loss: 2.6501e-04 - val_mae: 0.0023\n",
      "Epoch 113/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.4980e-04 - mae: 0.0028 - val_loss: 2.6249e-04 - val_mae: 0.0022\n",
      "Epoch 114/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.4410e-04 - mae: 0.0026 - val_loss: 2.6117e-04 - val_mae: 0.0022\n",
      "Epoch 115/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.4351e-04 - mae: 0.0027 - val_loss: 2.5615e-04 - val_mae: 0.0019\n",
      "Epoch 116/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.4067e-04 - mae: 0.0027 - val_loss: 2.5647e-04 - val_mae: 0.0025\n",
      "Epoch 117/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3760e-04 - mae: 0.0027 - val_loss: 2.5255e-04 - val_mae: 0.0021\n",
      "Epoch 118/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3548e-04 - mae: 0.0027 - val_loss: 2.4998e-04 - val_mae: 0.0021\n",
      "Epoch 119/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3283e-04 - mae: 0.0026 - val_loss: 2.5511e-04 - val_mae: 0.0030\n",
      "Epoch 120/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.3070e-04 - mae: 0.0026 - val_loss: 2.5334e-04 - val_mae: 0.0030\n",
      "Epoch 121/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2927e-04 - mae: 0.0027 - val_loss: 4.4172e-04 - val_mae: 0.0130\n",
      "Epoch 122/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2753e-04 - mae: 0.0028 - val_loss: 2.3967e-04 - val_mae: 0.0019\n",
      "Epoch 123/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2538e-04 - mae: 0.0026 - val_loss: 2.4498e-04 - val_mae: 0.0027\n",
      "Epoch 124/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2229e-04 - mae: 0.0026 - val_loss: 3.2745e-04 - val_mae: 0.0082\n",
      "Epoch 125/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.2249e-04 - mae: 0.0027 - val_loss: 2.3909e-04 - val_mae: 0.0024\n",
      "Epoch 126/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1763e-04 - mae: 0.0026 - val_loss: 2.3493e-04 - val_mae: 0.0022\n",
      "Epoch 127/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1589e-04 - mae: 0.0026 - val_loss: 2.3265e-04 - val_mae: 0.0021\n",
      "Epoch 128/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1681e-04 - mae: 0.0028 - val_loss: 2.3232e-04 - val_mae: 0.0025\n",
      "Epoch 129/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1310e-04 - mae: 0.0026 - val_loss: 2.2648e-04 - val_mae: 0.0018\n",
      "Epoch 130/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0906e-04 - mae: 0.0025 - val_loss: 2.2603e-04 - val_mae: 0.0019\n",
      "Epoch 131/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.1082e-04 - mae: 0.0027 - val_loss: 2.2501e-04 - val_mae: 0.0020\n",
      "Epoch 132/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0727e-04 - mae: 0.0026 - val_loss: 2.5224e-04 - val_mae: 0.0055\n",
      "Epoch 133/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0675e-04 - mae: 0.0027 - val_loss: 2.2157e-04 - val_mae: 0.0019\n",
      "Epoch 134/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0540e-04 - mae: 0.0027 - val_loss: 2.2263e-04 - val_mae: 0.0024\n",
      "Epoch 135/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0251e-04 - mae: 0.0026 - val_loss: 2.1843e-04 - val_mae: 0.0022\n",
      "Epoch 136/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 2.0471e-04 - mae: 0.0027 - val_loss: 2.2993e-04 - val_mae: 0.0035\n",
      "Epoch 137/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9972e-04 - mae: 0.0026 - val_loss: 2.1771e-04 - val_mae: 0.0025\n",
      "Epoch 138/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9902e-04 - mae: 0.0027 - val_loss: 2.1304e-04 - val_mae: 0.0019\n",
      "Epoch 139/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9500e-04 - mae: 0.0025 - val_loss: 2.1277e-04 - val_mae: 0.0022\n",
      "Epoch 140/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9665e-04 - mae: 0.0027 - val_loss: 2.1276e-04 - val_mae: 0.0024\n",
      "Epoch 141/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9310e-04 - mae: 0.0026 - val_loss: 2.1030e-04 - val_mae: 0.0020\n",
      "Epoch 142/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9225e-04 - mae: 0.0026 - val_loss: 2.0933e-04 - val_mae: 0.0021\n",
      "Epoch 143/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.9169e-04 - mae: 0.0027 - val_loss: 2.1696e-04 - val_mae: 0.0032\n",
      "Epoch 144/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.9021e-04 - mae: 0.0026 - val_loss: 2.0977e-04 - val_mae: 0.0024\n",
      "Epoch 145/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8873e-04 - mae: 0.0026 - val_loss: 2.2394e-04 - val_mae: 0.0044\n",
      "Epoch 146/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8768e-04 - mae: 0.0026 - val_loss: 2.1116e-04 - val_mae: 0.0033\n",
      "Epoch 147/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8700e-04 - mae: 0.0027 - val_loss: 2.0412e-04 - val_mae: 0.0027\n",
      "Epoch 148/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8348e-04 - mae: 0.0025 - val_loss: 2.0029e-04 - val_mae: 0.0019\n",
      "Epoch 149/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8483e-04 - mae: 0.0027 - val_loss: 2.0434e-04 - val_mae: 0.0025\n",
      "Epoch 150/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8265e-04 - mae: 0.0026 - val_loss: 1.9818e-04 - val_mae: 0.0018\n",
      "Epoch 151/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8161e-04 - mae: 0.0026 - val_loss: 1.9708e-04 - val_mae: 0.0018\n",
      "Epoch 152/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.8100e-04 - mae: 0.0026 - val_loss: 1.9734e-04 - val_mae: 0.0020\n",
      "Epoch 153/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7803e-04 - mae: 0.0025 - val_loss: 2.0337e-04 - val_mae: 0.0029\n",
      "Epoch 154/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7800e-04 - mae: 0.0026 - val_loss: 1.9583e-04 - val_mae: 0.0024\n",
      "Epoch 155/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7622e-04 - mae: 0.0025 - val_loss: 1.9489e-04 - val_mae: 0.0022\n",
      "Epoch 156/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7640e-04 - mae: 0.0026 - val_loss: 2.0105e-04 - val_mae: 0.0033\n",
      "Epoch 157/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7392e-04 - mae: 0.0024 - val_loss: 2.8448e-04 - val_mae: 0.0084\n",
      "Epoch 158/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7289e-04 - mae: 0.0025 - val_loss: 1.9007e-04 - val_mae: 0.0021\n",
      "Epoch 159/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7392e-04 - mae: 0.0027 - val_loss: 1.8881e-04 - val_mae: 0.0019\n",
      "Epoch 160/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7165e-04 - mae: 0.0026 - val_loss: 1.8863e-04 - val_mae: 0.0021\n",
      "Epoch 161/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.7086e-04 - mae: 0.0026 - val_loss: 1.8503e-04 - val_mae: 0.0017\n",
      "Epoch 162/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6978e-04 - mae: 0.0026 - val_loss: 2.3182e-04 - val_mae: 0.0063\n",
      "Epoch 163/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6969e-04 - mae: 0.0026 - val_loss: 1.8892e-04 - val_mae: 0.0026\n",
      "Epoch 164/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6776e-04 - mae: 0.0024 - val_loss: 1.8747e-04 - val_mae: 0.0025\n",
      "Epoch 165/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6791e-04 - mae: 0.0026 - val_loss: 1.8258e-04 - val_mae: 0.0017\n",
      "Epoch 166/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6700e-04 - mae: 0.0026 - val_loss: 1.8303e-04 - val_mae: 0.0020\n",
      "Epoch 167/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6481e-04 - mae: 0.0026 - val_loss: 1.9806e-04 - val_mae: 0.0044\n",
      "Epoch 168/1000\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 1.6318e-04 - mae: 0.0025 - val_loss: 1.8063e-04 - val_mae: 0.0019\n",
      "Epoch 169/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6368e-04 - mae: 0.0026 - val_loss: 1.7882e-04 - val_mae: 0.0018\n",
      "Epoch 170/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6269e-04 - mae: 0.0025 - val_loss: 2.8894e-04 - val_mae: 0.0099\n",
      "Epoch 171/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6187e-04 - mae: 0.0026 - val_loss: 1.7744e-04 - val_mae: 0.0019\n",
      "Epoch 172/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6140e-04 - mae: 0.0026 - val_loss: 1.7942e-04 - val_mae: 0.0024\n",
      "Epoch 173/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.6005e-04 - mae: 0.0026 - val_loss: 1.7593e-04 - val_mae: 0.0019\n",
      "Epoch 174/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5872e-04 - mae: 0.0025 - val_loss: 1.7638e-04 - val_mae: 0.0022\n",
      "Epoch 175/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5884e-04 - mae: 0.0025 - val_loss: 1.7454e-04 - val_mae: 0.0019\n",
      "Epoch 176/1000\n",
      "1426/1426 [==============================] - 4s 2ms/step - loss: 1.5843e-04 - mae: 0.0026 - val_loss: 1.7436e-04 - val_mae: 0.0020\n",
      "Epoch 177/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5753e-04 - mae: 0.0026 - val_loss: 1.7557e-04 - val_mae: 0.0023\n",
      "Epoch 178/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5555e-04 - mae: 0.0025 - val_loss: 1.8534e-04 - val_mae: 0.0038\n",
      "Epoch 179/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5573e-04 - mae: 0.0026 - val_loss: 1.7196e-04 - val_mae: 0.0017\n",
      "Epoch 180/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5657e-04 - mae: 0.0026 - val_loss: 1.7242e-04 - val_mae: 0.0021\n",
      "Epoch 181/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5411e-04 - mae: 0.0025 - val_loss: 1.7243e-04 - val_mae: 0.0020\n",
      "Epoch 182/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5438e-04 - mae: 0.0026 - val_loss: 2.4187e-04 - val_mae: 0.0076\n",
      "Epoch 183/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5347e-04 - mae: 0.0026 - val_loss: 1.7039e-04 - val_mae: 0.0021\n",
      "Epoch 184/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5164e-04 - mae: 0.0025 - val_loss: 1.7098e-04 - val_mae: 0.0022\n",
      "Epoch 185/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5220e-04 - mae: 0.0026 - val_loss: 1.7197e-04 - val_mae: 0.0026\n",
      "Epoch 186/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5200e-04 - mae: 0.0026 - val_loss: 1.7120e-04 - val_mae: 0.0026\n",
      "Epoch 187/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5027e-04 - mae: 0.0025 - val_loss: 1.6763e-04 - val_mae: 0.0020\n",
      "Epoch 188/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4987e-04 - mae: 0.0025 - val_loss: 1.7182e-04 - val_mae: 0.0026\n",
      "Epoch 189/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.5053e-04 - mae: 0.0026 - val_loss: 1.6998e-04 - val_mae: 0.0024\n",
      "Epoch 190/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4893e-04 - mae: 0.0025 - val_loss: 1.8895e-04 - val_mae: 0.0048\n",
      "Epoch 191/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4815e-04 - mae: 0.0025 - val_loss: 1.6471e-04 - val_mae: 0.0020\n",
      "Epoch 192/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4899e-04 - mae: 0.0025 - val_loss: 1.6390e-04 - val_mae: 0.0019\n",
      "Epoch 193/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4687e-04 - mae: 0.0026 - val_loss: 1.6764e-04 - val_mae: 0.0027\n",
      "Epoch 194/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4660e-04 - mae: 0.0025 - val_loss: 1.6238e-04 - val_mae: 0.0018\n",
      "Epoch 195/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4525e-04 - mae: 0.0025 - val_loss: 1.7108e-04 - val_mae: 0.0031\n",
      "Epoch 196/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4511e-04 - mae: 0.0025 - val_loss: 1.7906e-04 - val_mae: 0.0041\n",
      "Epoch 197/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4455e-04 - mae: 0.0025 - val_loss: 1.6307e-04 - val_mae: 0.0021\n",
      "Epoch 198/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4552e-04 - mae: 0.0026 - val_loss: 1.7996e-04 - val_mae: 0.0041\n",
      "Epoch 199/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4294e-04 - mae: 0.0025 - val_loss: 1.5986e-04 - val_mae: 0.0018\n",
      "Epoch 200/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4287e-04 - mae: 0.0025 - val_loss: 1.6042e-04 - val_mae: 0.0020\n",
      "Epoch 201/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4268e-04 - mae: 0.0025 - val_loss: 1.6129e-04 - val_mae: 0.0022\n",
      "Epoch 202/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4051e-04 - mae: 0.0024 - val_loss: 1.6142e-04 - val_mae: 0.0023\n",
      "Epoch 203/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4168e-04 - mae: 0.0025 - val_loss: 3.4587e-04 - val_mae: 0.0121\n",
      "Epoch 204/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4322e-04 - mae: 0.0026 - val_loss: 1.5816e-04 - val_mae: 0.0020\n",
      "Epoch 205/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3873e-04 - mae: 0.0023 - val_loss: 1.5973e-04 - val_mae: 0.0023\n",
      "Epoch 206/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.4103e-04 - mae: 0.0026 - val_loss: 1.5936e-04 - val_mae: 0.0021\n",
      "Epoch 207/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3943e-04 - mae: 0.0024 - val_loss: 1.5756e-04 - val_mae: 0.0020\n",
      "Epoch 208/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3838e-04 - mae: 0.0025 - val_loss: 1.5549e-04 - val_mae: 0.0020\n",
      "Epoch 209/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3826e-04 - mae: 0.0024 - val_loss: 1.7306e-04 - val_mae: 0.0043\n",
      "Epoch 210/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3867e-04 - mae: 0.0025 - val_loss: 1.5970e-04 - val_mae: 0.0028\n",
      "Epoch 211/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3775e-04 - mae: 0.0025 - val_loss: 1.5578e-04 - val_mae: 0.0022\n",
      "Epoch 212/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3883e-04 - mae: 0.0026 - val_loss: 1.5514e-04 - val_mae: 0.0020\n",
      "Epoch 213/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3685e-04 - mae: 0.0024 - val_loss: 1.5342e-04 - val_mae: 0.0018\n",
      "Epoch 214/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3712e-04 - mae: 0.0025 - val_loss: 1.5389e-04 - val_mae: 0.0018\n",
      "Epoch 215/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3740e-04 - mae: 0.0025 - val_loss: 1.5369e-04 - val_mae: 0.0019\n",
      "Epoch 216/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3517e-04 - mae: 0.0024 - val_loss: 1.5631e-04 - val_mae: 0.0026\n",
      "Epoch 217/1000\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3650e-04 - mae: 0.0025 - val_loss: 1.5359e-04 - val_mae: 0.0021\n",
      "Epoch 218/1000\n",
      "1424/1426 [============================>.] - ETA: 0s - loss: 1.3303e-04 - mae: 0.0025Restoring model weights from the end of the best epoch: 213.\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 1.3480e-04 - mae: 0.0025 - val_loss: 2.0857e-04 - val_mae: 0.0067\n",
      "Epoch 218: early stopping\n",
      "Durchschnittlicher Validation Loss: 0.00014846545236650853\n",
      "Durchschnittlicher Validation MAE: 0.0016695292899385095\n"
     ]
    }
   ],
   "source": [
    "# Initialisiere Listen, um Ergebnisse zu speichern\n",
    "val_loss_results = []\n",
    "val_mae_results = []\n",
    "\n",
    "# Funktion, um das Modell zu erstellen\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "            Dense(136, activation='relu', input_shape=(4,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "            Dense(216, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "            \n",
    "            Dense(104, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "            \n",
    "            Dense(328, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "            \n",
    "            Dense(8, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "            \n",
    "            Dense(120, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "            \n",
    "            Dense(1 , activation = 'linear')\n",
    "\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# K-Fold Cross-Validation Konfiguration\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# LeistungsÃ¼berwachung\n",
    "fold_no = 1\n",
    "for train_index, val_index in kf.split(X_train_scaled):\n",
    "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_scaled[train_index], y_train_scaled[val_index]\n",
    "\n",
    "    model = create_model()\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "    print(f'Training fÃ¼r Fold {fold_no}...')\n",
    "    history = model.fit(X_train_fold, y_train_fold, batch_size=25, epochs=1000, validation_data=(X_val_fold, y_val_fold), callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "    # Speichere die Ergebnisse des aktuellen Folds\n",
    "    val_loss_results.append(min(history.history['val_loss']))\n",
    "    val_mae_results.append(min(history.history['val_mae']))\n",
    "\n",
    "    fold_no += 1\n",
    "\n",
    "# Berechne den Durchschnitt Ã¼ber alle Folds\n",
    "average_val_loss = np.mean(val_loss_results)\n",
    "average_val_mae = np.mean(val_mae_results)\n",
    "# \n",
    "# Umwandeln der Listen in Pandas DataFrames\n",
    "val_loss_df = pd.DataFrame(val_loss_results, columns=['Validation Loss'])\n",
    "val_mae_df = pd.DataFrame(val_mae_results, columns=['Validation MAE'])\n",
    "\n",
    "# Speichern der DataFrames in CSV-Dateien\n",
    "val_loss_df.to_csv('val_loss_results_D3_I_F_1.csv', index=False)\n",
    "val_mae_df.to_csv('val_mae_results_D3_I_F_1.csv', index=False)\n",
    "\n",
    "# Gib die durchschnittlichen Ergebnisse aus\n",
    "print(f'Durchschnittlicher Validation Loss: {average_val_loss}')\n",
    "print(f'Durchschnittlicher Validation MAE: {average_val_mae}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T12:34:34.939681700Z",
     "start_time": "2024-04-01T11:43:22.056248300Z"
    }
   },
   "id": "7ff728388210d66b"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 - 0s - loss: 1.2498e-04 - mae: 0.0032 - 344ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.00012498479918576777, 0.003247056854888797]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test_scaled_2, y_test_scaled_2, verbose=2)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T12:43:03.027083300Z",
     "start_time": "2024-04-01T12:43:02.496740100Z"
    }
   },
   "id": "9050ab66ab36f169"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bsp. Predicted: [711.159] Actual: [735.96] \n",
      "Durchschnittliche Abweichung (MAE): [8.36831373]\n",
      "0.6024003836854117\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scaled_predicted_values = model.predict(X_test_scaled_2, verbose = 0)\n",
    "\n",
    "# FÃ¼hren Sie die RÃ¼cktransformation der skalierten Werte durch\n",
    "original_predicted_values = scaler_target.inverse_transform(scaled_predicted_values)\n",
    "original_actual_values = scaler_target.inverse_transform(y_test_scaled_2)  # y_test sind die skalierten tatsÃ¤chlichen Werte\n",
    "print(f' Bsp. Predicted: {original_predicted_values[100]} Actual: {original_actual_values[100]} ')\n",
    "\n",
    "def calculate_mae(list1, list2):\n",
    "    # Stelle sicher, dass beide Listen die gleiche LÃ¤nge haben\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Listen mÃ¼ssen die gleiche LÃ¤nge haben\")\n",
    "\n",
    "    # Berechne die absolute Differenz zwischen den Elementen der Listen\n",
    "    differences = [abs(x - y) for x, y in zip(list1, list2)]\n",
    "\n",
    "    # Berechne den Durchschnitt der absoluten Differenzen\n",
    "    mae = sum(differences) / len(differences)\n",
    "\n",
    "    return mae\n",
    "\n",
    "# Beispiel\n",
    "list1 = original_predicted_values\n",
    "list2 = original_actual_values\n",
    "\n",
    "mae = calculate_mae(list1, list2)\n",
    "print(f\"Durchschnittliche Abweichung (MAE): {mae}\")\n",
    "\n",
    "errors = np.abs((original_actual_values - original_predicted_values) / original_actual_values)\n",
    "mape = np.mean(errors) * 100\n",
    "print(mape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T12:43:06.812322800Z",
     "start_time": "2024-04-01T12:43:05.988842300Z"
    }
   },
   "id": "10cd79ca028075dd"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: [0.99873581]\n"
     ]
    }
   ],
   "source": [
    "def calculate_r_squared(predicted, actual):\n",
    "    # Berechnung des Mittelwerts der tatsÃ¤chlichen Werte\n",
    "    mean_actual = sum(actual) / len(actual)\n",
    "    \n",
    "    # Berechnung der totalen Summe der Quadrate (SST)\n",
    "    sst = sum((x - mean_actual) ** 2 for x in actual)\n",
    "    \n",
    "    # Berechnung der Summe der Quadrate der Residuen (SSE)\n",
    "    sse = sum((actual[i] - predicted[i]) ** 2 for i in range(len(actual)))\n",
    "    \n",
    "    # Berechnung des R^2-Wertes\n",
    "    r_squared = 1 - (sse / sst)\n",
    "    \n",
    "    return r_squared\n",
    "\n",
    "# Berechnung von R^2 mit den bereitgestellten Listen\n",
    "r_squared = calculate_r_squared(list1, list2)\n",
    "\n",
    "print(f\"R^2: {r_squared}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:42:57.572139200Z",
     "start_time": "2024-03-31T20:42:57.496717700Z"
    }
   },
   "id": "d0505d16afcbef4a"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Werte die kleiner sind: 183\n"
     ]
    },
    {
     "data": {
      "text/plain": "         Echt   Temperatur  X-Koordinate  Y-Koordinate  Differenz\n21    1644.20  1667.433105      0.000000          0.21 -23.233105\n423   1588.10  1611.326660      0.064516          0.19 -23.226660\n322   1588.40  1611.395996      0.048387          0.19 -22.995996\n424   1616.30  1639.162109      0.064516          0.20 -22.862109\n425   1643.40  1666.239624      0.064516          0.21 -22.839624\n...       ...          ...           ...           ...        ...\n5958   693.10   656.139709      0.935484          1.00  36.960291\n6059   691.77   654.232788      0.951613          1.00  37.537212\n6160   690.48   652.304260      0.967742          1.00  38.175740\n6261   689.09   650.375732      0.983871          1.00  38.714268\n6362   687.80   648.447144      1.000000          1.00  39.352856\n\n[6363 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Echt</th>\n      <th>Temperatur</th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Differenz</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>21</th>\n      <td>1644.20</td>\n      <td>1667.433105</td>\n      <td>0.000000</td>\n      <td>0.21</td>\n      <td>-23.233105</td>\n    </tr>\n    <tr>\n      <th>423</th>\n      <td>1588.10</td>\n      <td>1611.326660</td>\n      <td>0.064516</td>\n      <td>0.19</td>\n      <td>-23.226660</td>\n    </tr>\n    <tr>\n      <th>322</th>\n      <td>1588.40</td>\n      <td>1611.395996</td>\n      <td>0.048387</td>\n      <td>0.19</td>\n      <td>-22.995996</td>\n    </tr>\n    <tr>\n      <th>424</th>\n      <td>1616.30</td>\n      <td>1639.162109</td>\n      <td>0.064516</td>\n      <td>0.20</td>\n      <td>-22.862109</td>\n    </tr>\n    <tr>\n      <th>425</th>\n      <td>1643.40</td>\n      <td>1666.239624</td>\n      <td>0.064516</td>\n      <td>0.21</td>\n      <td>-22.839624</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5958</th>\n      <td>693.10</td>\n      <td>656.139709</td>\n      <td>0.935484</td>\n      <td>1.00</td>\n      <td>36.960291</td>\n    </tr>\n    <tr>\n      <th>6059</th>\n      <td>691.77</td>\n      <td>654.232788</td>\n      <td>0.951613</td>\n      <td>1.00</td>\n      <td>37.537212</td>\n    </tr>\n    <tr>\n      <th>6160</th>\n      <td>690.48</td>\n      <td>652.304260</td>\n      <td>0.967742</td>\n      <td>1.00</td>\n      <td>38.175740</td>\n    </tr>\n    <tr>\n      <th>6261</th>\n      <td>689.09</td>\n      <td>650.375732</td>\n      <td>0.983871</td>\n      <td>1.00</td>\n      <td>38.714268</td>\n    </tr>\n    <tr>\n      <th>6362</th>\n      <td>687.80</td>\n      <td>648.447144</td>\n      <td>1.000000</td>\n      <td>1.00</td>\n      <td>39.352856</td>\n    </tr>\n  </tbody>\n</table>\n<p>6363 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame({'Echt': [val[0] for val in list2], 'Temperatur': [val[0] for val in list1]})\n",
    "df_result['X-Koordinate'] = X_test_scaled_2[:, 0]\n",
    "df_result['Y-Koordinate'] = X_test_scaled_2[:, 1]\n",
    "\n",
    "df_result['Differenz'] = df_result['Echt'] - df_result['Temperatur']\n",
    "df_result['Differenz'].sort_values()\n",
    "sorted_df = df_result.sort_values(by= 'Differenz')\n",
    "Anzahl_Punkte = (sorted_df['Differenz'] > 20).sum()\n",
    "print(\"Anzahl der Werte die kleiner sind:\", Anzahl_Punkte)\n",
    "\n",
    "sorted_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T12:45:08.684811600Z",
     "start_time": "2024-04-01T12:45:08.480994700Z"
    }
   },
   "id": "47d4a39665ed1159"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "df_test['Vorhergesagt'] = list1\n",
    "df_test.to_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_I7000_F6000_D3_500_I_F_PKL_Prediction.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T19:30:16.479589900Z",
     "start_time": "2024-03-31T19:30:16.461404300Z"
    }
   },
   "id": "73defb2e4e9a45da"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mae = history.history['loss']\n",
    "val_mae = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(mae) + 1)\n",
    "\n",
    "# MAE Diagramm\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, mae, 'r', label='Training MSE')\n",
    "plt.plot(epochs, val_mae, 'b', label='Validation MSE')\n",
    "plt.title('Training and Validation MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.savefig('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Bilder Diplomarbeit/MSE_NeuroNetz/MSE_NeuroNetz_D3_2')\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T14:43:33.453659500Z",
     "start_time": "2024-03-29T14:43:33.154886700Z"
    }
   },
   "id": "3688dd7102e95baf"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f6f672a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T10:01:02.439200700Z",
     "start_time": "2024-03-15T10:01:02.436683600Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "553df6fa",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# def build_model(learning_rate=0.001, activation='relu', regularization=0.0001, dropout_rate=0.0):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(200, activation=activation, input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(448, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(352, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(320, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(256, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(416, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(128, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(96, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))    \n",
    "# \n",
    "#     model.add(Dense(32, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mae'])\n",
    "#     return model\n",
    "# \n",
    "# # Verwenden Sie eine Funktion, um das Modell zu instanziieren, fÃ¼r scikit-learn Wrapper\n",
    "# model = KerasRegressor(model=build_model, verbose=2)\n",
    "# \n",
    "# # Anpassung der Parameter im param_grid\n",
    "# param_grid = {\n",
    "#     'model__learning_rate': [0.01, 0.001, 0.0001],\n",
    "#     'model__regularization': [0.001, 0.0001, 0.00001],\n",
    "#     'fit__batch_size': [25, 50, 75, 100],\n",
    "#     'fit__epochs': [50],\n",
    "#     'model__dropout_rate' : [0.0, 0.1, 0.2]\n",
    "# }\n",
    "# \n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=2)\n",
    "# # Hinweis: Stellen Sie sicher, dass Ihre Daten (X_train_scaled, y_train_scaled) korrekt definiert sind\n",
    "# grid_result = grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "# # Beste Parameter und Score ausgeben\n",
    "# print(\"Beste Parameter:\", grid_search.best_params_)\n",
    "# print(\"Beste Genauigkeit:\", grid_search.best_score_)\n",
    "# \n",
    "# with open(\"Gridsearch_D3.txt\", \"w\") as f:\n",
    "#     f.write(f\"Beste Parameter: {grid_search.best_params_}\\n\")\n",
    "#     f.write(f\"Beste Genauigkeit: {grid_search.best_score_}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:01:02.450167100Z",
     "start_time": "2024-03-15T10:01:02.439200700Z"
    }
   },
   "id": "578403f6e218787a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Search"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69b9aef262bcb2c3"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "492cf0ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T10:01:02.450167100Z",
     "start_time": "2024-03-15T10:01:02.443220200Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Funktion zum Erstellen des Modells\n",
    "# def build_model(hp):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(hp.Int('input_units', min_value=8, max_value=328, step=16), input_shape=(2,), activation='relu'))\n",
    "#     for i in range(hp.Int('n_layers', 1, 10)):\n",
    "#         model.add(Dense(hp.Int(f'units_{i}', min_value=8, max_value=328, step=16), activation='relu'))\n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     return model\n",
    "# \n",
    "# # DurchfÃ¼hrung der Random Search dreimal\n",
    "# for run in range(1, 4):\n",
    "#     # Anpassen des Verzeichnisses und des Projektnamens fÃ¼r jeden Durchlauf\n",
    "#     directory = 'random_search'\n",
    "#     project_name = f'random_search_D3_{run}'\n",
    "#     \n",
    "#     tuner = RandomSearch(\n",
    "#         build_model,\n",
    "#         objective='val_loss',\n",
    "#         max_trials=100,\n",
    "#         executions_per_trial=1,\n",
    "#         directory=directory,\n",
    "#         project_name=project_name\n",
    "#     )\n",
    "#     \n",
    "#     # DurchfÃ¼hrung des Random Search\n",
    "#     tuner.search(X_train_scaled, y_train_scaled, epochs=50, verbose =0, batch_size=50, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "#     \n",
    "#     # Abrufen und Speichern des besten Modells\n",
    "#     best_model = tuner.get_best_models(num_models=1)[0]\n",
    "#     model_path = os.path.join(directory, project_name, 'best_model.h5') \n",
    "#     best_model.save(model_path)\n",
    "#     \n",
    "# \n",
    "#     # Optional: Abrufen und Ausgeben der besten Hyperparameter\n",
    "#     best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "#     \n",
    "#     # Konvertieren der Hyperparameter in ein DataFrame\n",
    "#     df_hyperparameters = pd.DataFrame([best_hyperparameters.values])\n",
    "#     # Speichern des DataFrame als CSV\n",
    "#     df_hyperparameters.to_csv(f'random_search_D3_{run}.csv', index=False)\n",
    "#     \n",
    "#     print(f\"Beste Hyperparameter fÃ¼r Lauf {run}: {best_hyperparameters.values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:01:02.450167100Z",
     "start_time": "2024-03-15T10:01:02.447649400Z"
    }
   },
   "id": "412f38f9b1e03d5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
