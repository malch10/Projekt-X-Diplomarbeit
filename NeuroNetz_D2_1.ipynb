{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94b0518e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T14:55:08.168450700Z",
     "start_time": "2024-04-15T14:55:03.226884100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense , Dropout\n",
    "from scikeras.wrappers import KerasRegressor \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Datenvorverarbeitung"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca9719455b328a93"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ff61b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T14:55:10.680457600Z",
     "start_time": "2024-04-15T14:55:10.612823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n0            0.0000      -0.00200        500   7000   9000      669.05\n1            0.0000      -0.00198        500   7000   9000      682.81\n2            0.0000      -0.00196        500   7000   9000      696.80\n3            0.0000      -0.00194        500   7000   9000      710.67\n4            0.0000      -0.00192        500   7000   9000      724.42\n...             ...           ...        ...    ...    ...         ...\n25321        0.0025       0.00192        500   7000   9000      584.84\n25322        0.0025       0.00194        500   7000   9000      581.64\n25323        0.0025       0.00196        500   7000   9000      578.47\n25324        0.0025       0.00198        500   7000   9000      575.32\n25325        0.0025       0.00200        500   7000   9000      572.20\n\n[25326 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>669.05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0000</td>\n      <td>-0.00198</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>682.81</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0000</td>\n      <td>-0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>696.80</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0000</td>\n      <td>-0.00194</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>710.67</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0000</td>\n      <td>-0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>724.42</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25321</th>\n      <td>0.0025</td>\n      <td>0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>584.84</td>\n    </tr>\n    <tr>\n      <th>25322</th>\n      <td>0.0025</td>\n      <td>0.00194</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>581.64</td>\n    </tr>\n    <tr>\n      <th>25323</th>\n      <td>0.0025</td>\n      <td>0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>578.47</td>\n    </tr>\n    <tr>\n      <th>25324</th>\n      <td>0.0025</td>\n      <td>0.00198</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>575.32</td>\n    </tr>\n    <tr>\n      <th>25325</th>\n      <td>0.0025</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>572.20</td>\n    </tr>\n  </tbody>\n</table>\n<p>25326 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/TPath_300_finish_data.pkl')\n",
    "data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_D2_I7000_F9000/TPath_500_finish_data_D2.pkl')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "966e3c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T14:55:11.405253700Z",
     "start_time": "2024-04-15T14:55:11.347362400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       X-Koordinate  Y-Koordinate  Temperatur\n0            0.0000      -0.00200      669.05\n1            0.0000      -0.00198      682.81\n2            0.0000      -0.00196      696.80\n3            0.0000      -0.00194      710.67\n4            0.0000      -0.00192      724.42\n...             ...           ...         ...\n25321        0.0025       0.00192      584.84\n25322        0.0025       0.00194      581.64\n25323        0.0025       0.00196      578.47\n25324        0.0025       0.00198      575.32\n25325        0.0025       0.00200      572.20\n\n[25326 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>669.05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0000</td>\n      <td>-0.00198</td>\n      <td>682.81</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0000</td>\n      <td>-0.00196</td>\n      <td>696.80</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0000</td>\n      <td>-0.00194</td>\n      <td>710.67</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0000</td>\n      <td>-0.00192</td>\n      <td>724.42</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25321</th>\n      <td>0.0025</td>\n      <td>0.00192</td>\n      <td>584.84</td>\n    </tr>\n    <tr>\n      <th>25322</th>\n      <td>0.0025</td>\n      <td>0.00194</td>\n      <td>581.64</td>\n    </tr>\n    <tr>\n      <th>25323</th>\n      <td>0.0025</td>\n      <td>0.00196</td>\n      <td>578.47</td>\n    </tr>\n    <tr>\n      <th>25324</th>\n      <td>0.0025</td>\n      <td>0.00198</td>\n      <td>575.32</td>\n    </tr>\n    <tr>\n      <th>25325</th>\n      <td>0.0025</td>\n      <td>0.00200</td>\n      <td>572.20</td>\n    </tr>\n  </tbody>\n</table>\n<p>25326 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Droppen unnötiger Spalten\n",
    "df = data.drop(data.columns[2:5], axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8783d1d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T09:44:04.611926800Z",
     "start_time": "2024-04-08T09:44:04.378511Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       X-Koordinate  Y-Koordinate  Temperatur\n",
      "5099        0.00050      -0.00052     1471.00\n",
      "12799       0.00126       0.00072     1319.30\n",
      "15071       0.00148       0.00194      595.19\n",
      "24620       0.00244      -0.00004     1249.00\n",
      "11071       0.00110      -0.00168      884.35\n",
      "...             ...           ...         ...\n",
      "21575       0.00214      -0.00064     1263.60\n",
      "5390        0.00052       0.00128     1035.40\n",
      "860         0.00008      -0.00088     1376.50\n",
      "15795       0.00156       0.00034     1383.80\n",
      "23654       0.00234       0.00074     1149.60\n",
      "\n",
      "[25326 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": "       X-Koordinate  Y-Koordinate  Temperatur\n0           0.00050      -0.00052     1471.00\n1           0.00126       0.00072     1319.30\n2           0.00148       0.00194      595.19\n3           0.00244      -0.00004     1249.00\n4           0.00110      -0.00168      884.35\n...             ...           ...         ...\n25321       0.00214      -0.00064     1263.60\n25322       0.00052       0.00128     1035.40\n25323       0.00008      -0.00088     1376.50\n25324       0.00156       0.00034     1383.80\n25325       0.00234       0.00074     1149.60\n\n[25326 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00050</td>\n      <td>-0.00052</td>\n      <td>1471.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00126</td>\n      <td>0.00072</td>\n      <td>1319.30</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00148</td>\n      <td>0.00194</td>\n      <td>595.19</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00244</td>\n      <td>-0.00004</td>\n      <td>1249.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00110</td>\n      <td>-0.00168</td>\n      <td>884.35</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25321</th>\n      <td>0.00214</td>\n      <td>-0.00064</td>\n      <td>1263.60</td>\n    </tr>\n    <tr>\n      <th>25322</th>\n      <td>0.00052</td>\n      <td>0.00128</td>\n      <td>1035.40</td>\n    </tr>\n    <tr>\n      <th>25323</th>\n      <td>0.00008</td>\n      <td>-0.00088</td>\n      <td>1376.50</td>\n    </tr>\n    <tr>\n      <th>25324</th>\n      <td>0.00156</td>\n      <td>0.00034</td>\n      <td>1383.80</td>\n    </tr>\n    <tr>\n      <th>25325</th>\n      <td>0.00234</td>\n      <td>0.00074</td>\n      <td>1149.60</td>\n    </tr>\n  </tbody>\n</table>\n<p>25326 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomisieren der Anordnung\n",
    "df1 = df.sample(frac=1, random_state=42)  # Hier wird 42 als Random State verwendet, um die Ergebnisse reproduzierbar zu machen\n",
    "print(df1)\n",
    "df_reset = df1.reset_index(drop=True)\n",
    "df_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4e72a16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T09:44:04.752389300Z",
     "start_time": "2024-04-08T09:44:04.558383Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gesamtdaten festlegen\n",
    "\n",
    "label = df_reset[\"Temperatur\"]\n",
    "df1 = df_reset.drop(\"Temperatur\", axis=1)\n",
    "X = df1\n",
    "y = label"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7fa289a50d87423"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e694a236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T09:44:05.252668900Z",
     "start_time": "2024-04-08T09:44:05.188379800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       X-Koordinate  Y-Koordinate\n0           0.00050      -0.00052\n1           0.00126       0.00072\n2           0.00148       0.00194\n3           0.00244      -0.00004\n4           0.00110      -0.00168\n...             ...           ...\n25321       0.00214      -0.00064\n25322       0.00052       0.00128\n25323       0.00008      -0.00088\n25324       0.00156       0.00034\n25325       0.00234       0.00074\n\n[25326 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00050</td>\n      <td>-0.00052</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00126</td>\n      <td>0.00072</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00148</td>\n      <td>0.00194</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00244</td>\n      <td>-0.00004</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00110</td>\n      <td>-0.00168</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25321</th>\n      <td>0.00214</td>\n      <td>-0.00064</td>\n    </tr>\n    <tr>\n      <th>25322</th>\n      <td>0.00052</td>\n      <td>0.00128</td>\n    </tr>\n    <tr>\n      <th>25323</th>\n      <td>0.00008</td>\n      <td>-0.00088</td>\n    </tr>\n    <tr>\n      <th>25324</th>\n      <td>0.00156</td>\n      <td>0.00034</td>\n    </tr>\n    <tr>\n      <th>25325</th>\n      <td>0.00234</td>\n      <td>0.00074</td>\n    </tr>\n  </tbody>\n</table>\n<p>25326 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f3303b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T09:44:05.452518600Z",
     "start_time": "2024-04-08T09:44:05.417583500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0        1471.00\n1        1319.30\n2         595.19\n3        1249.00\n4         884.35\n          ...   \n25321    1263.60\n25322    1035.40\n25323    1376.50\n25324    1383.80\n25325    1149.60\nName: Temperatur, Length: 25326, dtype: float64"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3ad8da0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T09:44:05.626388400Z",
     "start_time": "2024-04-08T09:44:05.589585400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Unterteilung in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c705edb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T09:44:06.116368300Z",
     "start_time": "2024-04-08T09:44:06.084190300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialisiere einen MinMaxScaler für die Features\n",
    "scaler_features = MinMaxScaler()\n",
    "# Skaliere X_train und X_test\n",
    "X_train_scaled = scaler_features.fit_transform(X_train)\n",
    "X_test_scaled = scaler_features.transform(X_test) \n",
    "\n",
    "# Initialisiere einen SEPARATEN MinMaxScaler für das Ziel\n",
    "scaler_target = MinMaxScaler()\n",
    "# erwartet, dass die Eingaben als 2D-Arrays kommen, und Ziele normalerweise als 1D-Arrays vorliegen.\n",
    "y_train_scaled = scaler_target.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test_scaled = scaler_target.transform(y_test.values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bbefe631e495b483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T09:44:06.577497400Z",
     "start_time": "2024-04-08T09:44:06.543044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.   , 0.15 ],\n       [0.984, 0.49 ],\n       [0.224, 0.905],\n       ...,\n       [0.04 , 0.585],\n       [0.976, 0.815],\n       [0.744, 0.785]])"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Netzwerkarchitektur"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d664797f8dcbd88c"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "109/109 [==============================] - 1s 4ms/step - loss: 0.1610 - mae: 0.3004 - val_loss: 0.1207 - val_mae: 0.2514\n",
      "Epoch 2/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0935 - mae: 0.2162 - val_loss: 0.0683 - val_mae: 0.1772\n",
      "Epoch 3/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0467 - mae: 0.1322 - val_loss: 0.0303 - val_mae: 0.0865\n",
      "Epoch 4/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0240 - mae: 0.0631 - val_loss: 0.0193 - val_mae: 0.0416\n",
      "Epoch 5/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0177 - mae: 0.0333 - val_loss: 0.0164 - val_mae: 0.0253\n",
      "Epoch 6/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0158 - mae: 0.0220 - val_loss: 0.0154 - val_mae: 0.0213\n",
      "Epoch 7/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0181 - val_loss: 0.0149 - val_mae: 0.0189\n",
      "Epoch 8/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0144 - mae: 0.0151 - val_loss: 0.0142 - val_mae: 0.0163\n",
      "Epoch 9/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0140 - mae: 0.0131 - val_loss: 0.0138 - val_mae: 0.0134\n",
      "Epoch 10/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0119 - val_loss: 0.0135 - val_mae: 0.0123\n",
      "Epoch 11/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0133 - mae: 0.0112 - val_loss: 0.0131 - val_mae: 0.0104\n",
      "Epoch 12/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0130 - mae: 0.0105 - val_loss: 0.0130 - val_mae: 0.0110\n",
      "Epoch 13/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0128 - mae: 0.0101 - val_loss: 0.0127 - val_mae: 0.0090\n",
      "Epoch 14/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0126 - mae: 0.0101 - val_loss: 0.0128 - val_mae: 0.0160\n",
      "Epoch 15/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0125 - mae: 0.0101 - val_loss: 0.0135 - val_mae: 0.0268\n",
      "Epoch 16/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0124 - mae: 0.0110 - val_loss: 0.0124 - val_mae: 0.0138\n",
      "Epoch 17/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0121 - mae: 0.0089 - val_loss: 0.0122 - val_mae: 0.0138\n",
      "Epoch 18/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0120 - mae: 0.0098 - val_loss: 0.0121 - val_mae: 0.0132\n",
      "Epoch 19/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0119 - mae: 0.0086 - val_loss: 0.0121 - val_mae: 0.0146\n",
      "Epoch 20/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0118 - mae: 0.0096 - val_loss: 0.0118 - val_mae: 0.0081\n",
      "Epoch 21/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0117 - mae: 0.0083 - val_loss: 0.0116 - val_mae: 0.0066\n",
      "Epoch 22/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0116 - mae: 0.0077 - val_loss: 0.0116 - val_mae: 0.0083\n",
      "Epoch 23/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0115 - mae: 0.0080 - val_loss: 0.0115 - val_mae: 0.0077\n",
      "Epoch 24/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0117 - mae: 0.0129 - val_loss: 0.0115 - val_mae: 0.0090\n",
      "Epoch 25/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0114 - mae: 0.0077 - val_loss: 0.0114 - val_mae: 0.0078\n",
      "Epoch 26/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0113 - mae: 0.0069 - val_loss: 0.0113 - val_mae: 0.0082\n",
      "Epoch 27/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0113 - mae: 0.0076 - val_loss: 0.0112 - val_mae: 0.0063\n",
      "Epoch 28/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0112 - mae: 0.0065 - val_loss: 0.0112 - val_mae: 0.0077\n",
      "Epoch 29/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0112 - mae: 0.0077 - val_loss: 0.0112 - val_mae: 0.0087\n",
      "Epoch 30/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0111 - mae: 0.0080 - val_loss: 0.0112 - val_mae: 0.0125\n",
      "Epoch 31/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0111 - mae: 0.0093 - val_loss: 0.0110 - val_mae: 0.0069\n",
      "Epoch 32/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0110 - mae: 0.0082 - val_loss: 0.0110 - val_mae: 0.0091\n",
      "Epoch 33/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0110 - mae: 0.0088 - val_loss: 0.0111 - val_mae: 0.0110\n",
      "Epoch 34/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0110 - mae: 0.0084 - val_loss: 0.0108 - val_mae: 0.0048\n",
      "Epoch 35/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0109 - mae: 0.0069 - val_loss: 0.0108 - val_mae: 0.0056\n",
      "Epoch 36/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0108 - mae: 0.0066 - val_loss: 0.0108 - val_mae: 0.0056\n",
      "Epoch 37/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0108 - mae: 0.0083 - val_loss: 0.0110 - val_mae: 0.0141\n",
      "Epoch 38/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0108 - mae: 0.0099 - val_loss: 0.0108 - val_mae: 0.0108\n",
      "Epoch 39/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0107 - mae: 0.0063 - val_loss: 0.0109 - val_mae: 0.0131\n",
      "Epoch 40/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0107 - mae: 0.0087 - val_loss: 0.0108 - val_mae: 0.0116\n",
      "Epoch 41/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0108 - mae: 0.0122 - val_loss: 0.0106 - val_mae: 0.0058\n",
      "Epoch 42/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0105 - mae: 0.0065 - val_loss: 0.0105 - val_mae: 0.0075\n",
      "Epoch 43/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0105 - mae: 0.0073 - val_loss: 0.0105 - val_mae: 0.0055\n",
      "Epoch 44/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0058 - val_loss: 0.0104 - val_mae: 0.0048\n",
      "Epoch 45/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0069 - val_loss: 0.0104 - val_mae: 0.0073\n",
      "Epoch 46/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0061 - val_loss: 0.0105 - val_mae: 0.0097\n",
      "Epoch 47/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0073 - val_loss: 0.0103 - val_mae: 0.0074\n",
      "Epoch 48/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0073 - val_loss: 0.0104 - val_mae: 0.0119\n",
      "Epoch 49/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0076 - val_loss: 0.0102 - val_mae: 0.0070\n",
      "Epoch 50/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0087 - val_loss: 0.0104 - val_mae: 0.0127\n",
      "Epoch 51/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0105 - mae: 0.0129 - val_loss: 0.0101 - val_mae: 0.0044\n",
      "Epoch 52/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0054 - val_loss: 0.0101 - val_mae: 0.0051\n",
      "Epoch 53/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0045 - val_loss: 0.0101 - val_mae: 0.0065\n",
      "Epoch 54/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0055 - val_loss: 0.0105 - val_mae: 0.0160\n",
      "Epoch 55/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0106 - val_loss: 0.0100 - val_mae: 0.0063\n",
      "Epoch 56/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0058 - val_loss: 0.0100 - val_mae: 0.0065\n",
      "Epoch 57/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0068 - val_loss: 0.0100 - val_mae: 0.0086\n",
      "Epoch 58/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0066 - val_loss: 0.0099 - val_mae: 0.0065\n",
      "Epoch 59/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0098 - val_loss: 0.0098 - val_mae: 0.0063\n",
      "Epoch 60/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0049 - val_loss: 0.0098 - val_mae: 0.0064\n",
      "Epoch 61/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0051 - val_loss: 0.0098 - val_mae: 0.0062\n",
      "Epoch 62/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0070 - val_loss: 0.0099 - val_mae: 0.0115\n",
      "Epoch 63/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0088 - val_loss: 0.0098 - val_mae: 0.0093\n",
      "Epoch 64/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0097 - mae: 0.0075 - val_loss: 0.0097 - val_mae: 0.0087\n",
      "Epoch 65/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0096 - mae: 0.0052 - val_loss: 0.0096 - val_mae: 0.0064\n",
      "Epoch 66/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0096 - mae: 0.0061 - val_loss: 0.0096 - val_mae: 0.0061\n",
      "Epoch 67/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0096 - mae: 0.0070 - val_loss: 0.0097 - val_mae: 0.0108\n",
      "Epoch 68/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0096 - mae: 0.0067 - val_loss: 0.0096 - val_mae: 0.0079\n",
      "Epoch 69/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0095 - mae: 0.0052 - val_loss: 0.0096 - val_mae: 0.0115\n",
      "Epoch 70/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0095 - mae: 0.0072 - val_loss: 0.0094 - val_mae: 0.0066\n",
      "Epoch 71/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0094 - mae: 0.0047 - val_loss: 0.0097 - val_mae: 0.0147\n",
      "Epoch 72/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0094 - mae: 0.0081 - val_loss: 0.0095 - val_mae: 0.0110\n",
      "Epoch 73/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0095 - val_mae: 0.0115\n",
      "Epoch 74/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0093 - mae: 0.0061 - val_loss: 0.0095 - val_mae: 0.0117\n",
      "Epoch 75/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0094 - mae: 0.0088 - val_loss: 0.0092 - val_mae: 0.0036\n",
      "Epoch 76/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0092 - mae: 0.0045 - val_loss: 0.0092 - val_mae: 0.0043\n",
      "Epoch 77/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0092 - mae: 0.0043 - val_loss: 0.0093 - val_mae: 0.0106\n",
      "Epoch 78/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0092 - mae: 0.0060 - val_loss: 0.0091 - val_mae: 0.0044\n",
      "Epoch 79/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0091 - mae: 0.0039 - val_loss: 0.0091 - val_mae: 0.0035\n",
      "Epoch 80/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0091 - mae: 0.0051 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 81/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0091 - mae: 0.0050 - val_loss: 0.0090 - val_mae: 0.0040\n",
      "Epoch 82/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0091 - mae: 0.0064 - val_loss: 0.0097 - val_mae: 0.0214\n",
      "Epoch 83/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0090 - mae: 0.0074 - val_loss: 0.0090 - val_mae: 0.0060\n",
      "Epoch 84/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0090 - mae: 0.0057 - val_loss: 0.0091 - val_mae: 0.0105\n",
      "Epoch 85/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0093 - mae: 0.0135 - val_loss: 0.0089 - val_mae: 0.0049\n",
      "Epoch 86/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0089 - mae: 0.0036 - val_loss: 0.0091 - val_mae: 0.0121\n",
      "Epoch 87/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0089 - mae: 0.0049 - val_loss: 0.0088 - val_mae: 0.0037\n",
      "Epoch 88/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0088 - mae: 0.0045 - val_loss: 0.0088 - val_mae: 0.0030\n",
      "Epoch 89/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0075 - val_loss: 0.0088 - val_mae: 0.0074\n",
      "Epoch 90/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0088 - mae: 0.0074 - val_loss: 0.0088 - val_mae: 0.0063\n",
      "Epoch 91/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0088 - mae: 0.0064 - val_loss: 0.0087 - val_mae: 0.0043\n",
      "Epoch 92/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0087 - mae: 0.0045 - val_loss: 0.0094 - val_mae: 0.0193\n",
      "Epoch 93/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0088 - mae: 0.0076 - val_loss: 0.0088 - val_mae: 0.0111\n",
      "Epoch 94/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0087 - mae: 0.0047 - val_loss: 0.0086 - val_mae: 0.0038\n",
      "Epoch 95/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0086 - mae: 0.0045 - val_loss: 0.0111 - val_mae: 0.0393\n",
      "Epoch 96/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0089 - mae: 0.0123 - val_loss: 0.0086 - val_mae: 0.0040\n",
      "Epoch 97/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0086 - mae: 0.0034 - val_loss: 0.0085 - val_mae: 0.0034\n",
      "Epoch 98/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0085 - mae: 0.0036 - val_loss: 0.0085 - val_mae: 0.0042\n",
      "Epoch 99/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0085 - mae: 0.0051 - val_loss: 0.0085 - val_mae: 0.0069\n",
      "Epoch 100/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0085 - mae: 0.0042 - val_loss: 0.0085 - val_mae: 0.0043\n",
      "Epoch 101/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0085 - mae: 0.0041 - val_loss: 0.0086 - val_mae: 0.0090\n",
      "Epoch 102/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0084 - mae: 0.0036 - val_loss: 0.0084 - val_mae: 0.0030\n",
      "Epoch 103/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0084 - mae: 0.0043 - val_loss: 0.0084 - val_mae: 0.0035\n",
      "Epoch 104/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0084 - mae: 0.0053 - val_loss: 0.0088 - val_mae: 0.0145\n",
      "Epoch 105/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0090 - mae: 0.0143 - val_loss: 0.0083 - val_mae: 0.0040\n",
      "Epoch 106/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0083 - mae: 0.0043 - val_loss: 0.0084 - val_mae: 0.0095\n",
      "Epoch 107/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0083 - mae: 0.0040 - val_loss: 0.0083 - val_mae: 0.0028\n",
      "Epoch 108/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0083 - mae: 0.0037 - val_loss: 0.0089 - val_mae: 0.0189\n",
      "Epoch 109/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0083 - mae: 0.0065 - val_loss: 0.0083 - val_mae: 0.0049\n",
      "Epoch 110/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0082 - mae: 0.0038 - val_loss: 0.0082 - val_mae: 0.0044\n",
      "Epoch 111/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0082 - mae: 0.0044 - val_loss: 0.0082 - val_mae: 0.0031\n",
      "Epoch 112/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0082 - mae: 0.0034 - val_loss: 0.0082 - val_mae: 0.0041\n",
      "Epoch 113/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0082 - mae: 0.0045 - val_loss: 0.0082 - val_mae: 0.0078\n",
      "Epoch 114/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0083 - mae: 0.0098 - val_loss: 0.0082 - val_mae: 0.0076\n",
      "Epoch 115/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0081 - mae: 0.0048 - val_loss: 0.0083 - val_mae: 0.0104\n",
      "Epoch 116/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0081 - mae: 0.0040 - val_loss: 0.0081 - val_mae: 0.0040\n",
      "Epoch 117/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0081 - mae: 0.0067 - val_loss: 0.0086 - val_mae: 0.0173\n",
      "Epoch 118/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0081 - mae: 0.0059 - val_loss: 0.0080 - val_mae: 0.0033\n",
      "Epoch 119/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0080 - mae: 0.0040 - val_loss: 0.0081 - val_mae: 0.0066\n",
      "Epoch 120/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0080 - mae: 0.0056 - val_loss: 0.0081 - val_mae: 0.0079\n",
      "Epoch 121/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0080 - mae: 0.0066 - val_loss: 0.0081 - val_mae: 0.0090\n",
      "Epoch 122/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0080 - mae: 0.0039 - val_loss: 0.0079 - val_mae: 0.0048\n",
      "Epoch 123/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0080 - mae: 0.0054 - val_loss: 0.0079 - val_mae: 0.0027\n",
      "Epoch 124/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0079 - mae: 0.0048 - val_loss: 0.0080 - val_mae: 0.0078\n",
      "Epoch 125/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0079 - mae: 0.0053 - val_loss: 0.0079 - val_mae: 0.0028\n",
      "Epoch 126/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0079 - mae: 0.0046 - val_loss: 0.0078 - val_mae: 0.0039\n",
      "Epoch 127/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0079 - mae: 0.0073 - val_loss: 0.0080 - val_mae: 0.0093\n",
      "Epoch 128/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0070 - val_loss: 0.0083 - val_mae: 0.0186\n",
      "Epoch 129/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0075 - val_loss: 0.0078 - val_mae: 0.0041\n",
      "Epoch 130/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0078 - mae: 0.0045 - val_loss: 0.0078 - val_mae: 0.0050\n",
      "Epoch 131/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0063 - val_loss: 0.0077 - val_mae: 0.0041\n",
      "Epoch 132/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0077 - mae: 0.0034 - val_loss: 0.0077 - val_mae: 0.0028\n",
      "Epoch 133/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0078 - mae: 0.0061 - val_loss: 0.0090 - val_mae: 0.0289\n",
      "Epoch 134/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0078 - mae: 0.0071 - val_loss: 0.0077 - val_mae: 0.0030\n",
      "Epoch 135/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0077 - mae: 0.0029 - val_loss: 0.0077 - val_mae: 0.0036\n",
      "Epoch 136/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0076 - mae: 0.0036 - val_loss: 0.0076 - val_mae: 0.0030\n",
      "Epoch 137/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0052 - val_loss: 0.0076 - val_mae: 0.0036\n",
      "Epoch 138/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0076 - mae: 0.0054 - val_loss: 0.0076 - val_mae: 0.0037\n",
      "Epoch 139/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0076 - mae: 0.0050 - val_loss: 0.0076 - val_mae: 0.0079\n",
      "Epoch 140/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0066 - val_loss: 0.0077 - val_mae: 0.0107\n",
      "Epoch 141/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0075 - mae: 0.0044 - val_loss: 0.0077 - val_mae: 0.0096\n",
      "Epoch 142/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0075 - mae: 0.0042 - val_loss: 0.0075 - val_mae: 0.0033\n",
      "Epoch 143/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0075 - mae: 0.0037 - val_loss: 0.0076 - val_mae: 0.0071\n",
      "Epoch 144/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0077 - mae: 0.0106 - val_loss: 0.0076 - val_mae: 0.0089\n",
      "Epoch 145/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0076 - mae: 0.0071 - val_loss: 0.0074 - val_mae: 0.0031\n",
      "Epoch 146/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0074 - mae: 0.0036 - val_loss: 0.0076 - val_mae: 0.0104\n",
      "Epoch 147/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0074 - mae: 0.0048 - val_loss: 0.0075 - val_mae: 0.0072\n",
      "Epoch 148/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0074 - mae: 0.0040 - val_loss: 0.0074 - val_mae: 0.0038\n",
      "Epoch 149/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0074 - mae: 0.0036 - val_loss: 0.0074 - val_mae: 0.0061\n",
      "Epoch 150/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0074 - mae: 0.0040 - val_loss: 0.0074 - val_mae: 0.0049\n",
      "Epoch 151/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0073 - mae: 0.0034 - val_loss: 0.0073 - val_mae: 0.0035\n",
      "Epoch 152/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0074 - mae: 0.0057 - val_loss: 0.0073 - val_mae: 0.0047\n",
      "Epoch 153/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0073 - mae: 0.0048 - val_loss: 0.0073 - val_mae: 0.0057\n",
      "Epoch 154/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0076 - mae: 0.0128 - val_loss: 0.0073 - val_mae: 0.0046\n",
      "Epoch 155/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0073 - mae: 0.0035 - val_loss: 0.0072 - val_mae: 0.0025\n",
      "Epoch 156/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0073 - mae: 0.0040 - val_loss: 0.0073 - val_mae: 0.0064\n",
      "Epoch 157/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0072 - mae: 0.0042 - val_loss: 0.0073 - val_mae: 0.0070\n",
      "Epoch 158/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0072 - mae: 0.0028 - val_loss: 0.0072 - val_mae: 0.0026\n",
      "Epoch 159/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0072 - mae: 0.0035 - val_loss: 0.0072 - val_mae: 0.0039\n",
      "Epoch 160/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0072 - mae: 0.0031 - val_loss: 0.0072 - val_mae: 0.0044\n",
      "Epoch 161/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0072 - mae: 0.0035 - val_loss: 0.0072 - val_mae: 0.0057\n",
      "Epoch 162/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0071 - mae: 0.0040 - val_loss: 0.0071 - val_mae: 0.0043\n",
      "Epoch 163/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0072 - mae: 0.0072 - val_loss: 0.0071 - val_mae: 0.0038\n",
      "Epoch 164/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0071 - mae: 0.0031 - val_loss: 0.0071 - val_mae: 0.0028\n",
      "Epoch 165/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0071 - mae: 0.0028 - val_loss: 0.0071 - val_mae: 0.0034\n",
      "Epoch 166/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0071 - mae: 0.0049 - val_loss: 0.0071 - val_mae: 0.0077\n",
      "Epoch 167/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0070 - mae: 0.0032 - val_loss: 0.0070 - val_mae: 0.0048\n",
      "Epoch 168/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0071 - mae: 0.0072 - val_loss: 0.0071 - val_mae: 0.0068\n",
      "Epoch 169/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0070 - mae: 0.0038 - val_loss: 0.0070 - val_mae: 0.0032\n",
      "Epoch 170/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0070 - mae: 0.0049 - val_loss: 0.0070 - val_mae: 0.0038\n",
      "Epoch 171/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0070 - mae: 0.0051 - val_loss: 0.0069 - val_mae: 0.0025\n",
      "Epoch 172/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0070 - mae: 0.0034 - val_loss: 0.0070 - val_mae: 0.0076\n",
      "Epoch 173/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0069 - mae: 0.0036 - val_loss: 0.0069 - val_mae: 0.0024\n",
      "Epoch 174/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0070 - mae: 0.0053 - val_loss: 0.0069 - val_mae: 0.0064\n",
      "Epoch 175/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0070 - mae: 0.0069 - val_loss: 0.0069 - val_mae: 0.0026\n",
      "Epoch 176/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0069 - mae: 0.0036 - val_loss: 0.0069 - val_mae: 0.0060\n",
      "Epoch 177/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0070 - mae: 0.0069 - val_loss: 0.0069 - val_mae: 0.0062\n",
      "Epoch 178/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0068 - mae: 0.0032 - val_loss: 0.0068 - val_mae: 0.0040\n",
      "Epoch 179/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0068 - mae: 0.0039 - val_loss: 0.0068 - val_mae: 0.0039\n",
      "Epoch 180/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0068 - mae: 0.0059 - val_loss: 0.0069 - val_mae: 0.0080\n",
      "Epoch 181/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0068 - mae: 0.0034 - val_loss: 0.0071 - val_mae: 0.0147\n",
      "Epoch 182/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0068 - mae: 0.0050 - val_loss: 0.0068 - val_mae: 0.0038\n",
      "Epoch 183/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0068 - mae: 0.0050 - val_loss: 0.0068 - val_mae: 0.0065\n",
      "Epoch 184/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0067 - mae: 0.0030 - val_loss: 0.0069 - val_mae: 0.0103\n",
      "Epoch 185/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0068 - mae: 0.0066 - val_loss: 0.0067 - val_mae: 0.0027\n",
      "Epoch 186/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0067 - mae: 0.0040 - val_loss: 0.0067 - val_mae: 0.0047\n",
      "Epoch 187/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0067 - mae: 0.0047 - val_loss: 0.0067 - val_mae: 0.0064\n",
      "Epoch 188/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0067 - mae: 0.0030 - val_loss: 0.0067 - val_mae: 0.0021\n",
      "Epoch 189/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0067 - mae: 0.0027 - val_loss: 0.0067 - val_mae: 0.0053\n",
      "Epoch 190/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0067 - mae: 0.0062 - val_loss: 0.0067 - val_mae: 0.0077\n",
      "Epoch 191/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0067 - mae: 0.0052 - val_loss: 0.0066 - val_mae: 0.0056\n",
      "Epoch 192/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0067 - mae: 0.0059 - val_loss: 0.0067 - val_mae: 0.0086\n",
      "Epoch 193/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0066 - mae: 0.0054 - val_loss: 0.0066 - val_mae: 0.0026\n",
      "Epoch 194/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0066 - mae: 0.0026 - val_loss: 0.0066 - val_mae: 0.0023\n",
      "Epoch 195/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0066 - mae: 0.0031 - val_loss: 0.0066 - val_mae: 0.0054\n",
      "Epoch 196/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0066 - mae: 0.0045 - val_loss: 0.0065 - val_mae: 0.0032\n",
      "Epoch 197/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0065 - mae: 0.0039 - val_loss: 0.0065 - val_mae: 0.0034\n",
      "Epoch 198/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0065 - mae: 0.0046 - val_loss: 0.0070 - val_mae: 0.0174\n",
      "Epoch 199/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0066 - mae: 0.0063 - val_loss: 0.0065 - val_mae: 0.0028\n",
      "Epoch 200/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0065 - mae: 0.0036 - val_loss: 0.0065 - val_mae: 0.0028\n",
      "Epoch 201/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0065 - mae: 0.0056 - val_loss: 0.0065 - val_mae: 0.0059\n",
      "Epoch 202/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0065 - mae: 0.0034 - val_loss: 0.0064 - val_mae: 0.0025\n",
      "Epoch 203/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0064 - mae: 0.0024 - val_loss: 0.0064 - val_mae: 0.0027\n",
      "Epoch 204/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0064 - mae: 0.0029 - val_loss: 0.0064 - val_mae: 0.0045\n",
      "Epoch 205/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0064 - mae: 0.0040 - val_loss: 0.0067 - val_mae: 0.0131\n",
      "Epoch 206/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0064 - mae: 0.0053 - val_loss: 0.0064 - val_mae: 0.0047\n",
      "Epoch 207/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0064 - mae: 0.0039 - val_loss: 0.0072 - val_mae: 0.0204\n",
      "Epoch 208/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0065 - mae: 0.0082 - val_loss: 0.0063 - val_mae: 0.0028\n",
      "Epoch 209/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0066 - mae: 0.0107 - val_loss: 0.0070 - val_mae: 0.0207\n",
      "Epoch 210/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0063 - mae: 0.0038 - val_loss: 0.0063 - val_mae: 0.0023\n",
      "Epoch 211/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0063 - mae: 0.0023 - val_loss: 0.0063 - val_mae: 0.0039\n",
      "Epoch 212/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0063 - mae: 0.0024 - val_loss: 0.0063 - val_mae: 0.0023\n",
      "Epoch 213/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0063 - mae: 0.0023 - val_loss: 0.0063 - val_mae: 0.0030\n",
      "Epoch 214/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0063 - mae: 0.0026 - val_loss: 0.0062 - val_mae: 0.0024\n",
      "Epoch 215/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0062 - mae: 0.0027 - val_loss: 0.0062 - val_mae: 0.0035\n",
      "Epoch 216/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0062 - mae: 0.0032 - val_loss: 0.0063 - val_mae: 0.0060\n",
      "Epoch 217/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0062 - mae: 0.0030 - val_loss: 0.0063 - val_mae: 0.0062\n",
      "Epoch 218/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0063 - mae: 0.0069 - val_loss: 0.0062 - val_mae: 0.0034\n",
      "Epoch 219/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0062 - mae: 0.0024 - val_loss: 0.0062 - val_mae: 0.0036\n",
      "Epoch 220/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0062 - mae: 0.0032 - val_loss: 0.0062 - val_mae: 0.0053\n",
      "Epoch 221/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0062 - mae: 0.0038 - val_loss: 0.0062 - val_mae: 0.0055\n",
      "Epoch 222/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0061 - mae: 0.0030 - val_loss: 0.0063 - val_mae: 0.0092\n",
      "Epoch 223/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0061 - mae: 0.0039 - val_loss: 0.0061 - val_mae: 0.0028\n",
      "Epoch 224/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0061 - mae: 0.0026 - val_loss: 0.0061 - val_mae: 0.0054\n",
      "Epoch 225/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0061 - mae: 0.0056 - val_loss: 0.0061 - val_mae: 0.0050\n",
      "Epoch 226/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0061 - mae: 0.0037 - val_loss: 0.0061 - val_mae: 0.0033\n",
      "Epoch 227/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0061 - mae: 0.0041 - val_loss: 0.0076 - val_mae: 0.0284\n",
      "Epoch 228/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0061 - mae: 0.0051 - val_loss: 0.0061 - val_mae: 0.0051\n",
      "Epoch 229/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0061 - mae: 0.0067 - val_loss: 0.0060 - val_mae: 0.0043\n",
      "Epoch 230/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0060 - mae: 0.0038 - val_loss: 0.0060 - val_mae: 0.0038\n",
      "Epoch 231/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0060 - mae: 0.0024 - val_loss: 0.0060 - val_mae: 0.0036\n",
      "Epoch 232/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0060 - mae: 0.0039 - val_loss: 0.0060 - val_mae: 0.0028\n",
      "Epoch 233/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0060 - mae: 0.0025 - val_loss: 0.0060 - val_mae: 0.0049\n",
      "Epoch 234/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0060 - mae: 0.0034 - val_loss: 0.0060 - val_mae: 0.0068\n",
      "Epoch 235/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0061 - mae: 0.0065 - val_loss: 0.0060 - val_mae: 0.0063\n",
      "Epoch 236/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0059 - mae: 0.0030 - val_loss: 0.0059 - val_mae: 0.0031\n",
      "Epoch 237/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0059 - mae: 0.0036 - val_loss: 0.0060 - val_mae: 0.0067\n",
      "Epoch 238/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0059 - mae: 0.0026 - val_loss: 0.0059 - val_mae: 0.0070\n",
      "Epoch 239/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0059 - mae: 0.0047 - val_loss: 0.0065 - val_mae: 0.0191\n",
      "Epoch 240/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0060 - mae: 0.0062 - val_loss: 0.0059 - val_mae: 0.0024\n",
      "Epoch 241/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0059 - mae: 0.0030 - val_loss: 0.0058 - val_mae: 0.0028\n",
      "Epoch 242/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0058 - mae: 0.0025 - val_loss: 0.0058 - val_mae: 0.0038\n",
      "Epoch 243/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0058 - mae: 0.0035 - val_loss: 0.0059 - val_mae: 0.0079\n",
      "Epoch 244/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0058 - mae: 0.0034 - val_loss: 0.0058 - val_mae: 0.0050\n",
      "Epoch 245/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0058 - mae: 0.0055 - val_loss: 0.0059 - val_mae: 0.0066\n",
      "Epoch 246/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0058 - mae: 0.0028 - val_loss: 0.0058 - val_mae: 0.0069\n",
      "Epoch 247/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0060 - mae: 0.0083 - val_loss: 0.0058 - val_mae: 0.0027\n",
      "Epoch 248/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0058 - mae: 0.0026 - val_loss: 0.0058 - val_mae: 0.0044\n",
      "Epoch 249/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0057 - mae: 0.0027 - val_loss: 0.0057 - val_mae: 0.0029\n",
      "Epoch 250/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0057 - mae: 0.0021 - val_loss: 0.0058 - val_mae: 0.0054\n",
      "Epoch 251/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0057 - mae: 0.0026 - val_loss: 0.0057 - val_mae: 0.0033\n",
      "Epoch 252/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0057 - mae: 0.0047 - val_loss: 0.0059 - val_mae: 0.0113\n",
      "Epoch 253/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0057 - mae: 0.0051 - val_loss: 0.0057 - val_mae: 0.0049\n",
      "Epoch 254/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0057 - mae: 0.0028 - val_loss: 0.0057 - val_mae: 0.0050\n",
      "Epoch 255/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0057 - mae: 0.0026 - val_loss: 0.0057 - val_mae: 0.0043\n",
      "Epoch 256/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0056 - mae: 0.0023 - val_loss: 0.0057 - val_mae: 0.0053\n",
      "Epoch 257/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0056 - mae: 0.0039 - val_loss: 0.0057 - val_mae: 0.0051\n",
      "Epoch 258/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0056 - mae: 0.0030 - val_loss: 0.0056 - val_mae: 0.0038\n",
      "Epoch 259/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0057 - mae: 0.0057 - val_loss: 0.0057 - val_mae: 0.0095\n",
      "Epoch 260/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0057 - mae: 0.0063 - val_loss: 0.0056 - val_mae: 0.0028\n",
      "Epoch 261/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0056 - mae: 0.0024 - val_loss: 0.0056 - val_mae: 0.0033\n",
      "Epoch 262/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0056 - mae: 0.0028 - val_loss: 0.0055 - val_mae: 0.0021\n",
      "Epoch 263/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0028 - val_loss: 0.0056 - val_mae: 0.0053\n",
      "Epoch 264/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0056 - mae: 0.0041 - val_loss: 0.0056 - val_mae: 0.0059\n",
      "Epoch 265/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0046 - val_loss: 0.0055 - val_mae: 0.0041\n",
      "Epoch 266/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0033 - val_loss: 0.0056 - val_mae: 0.0090\n",
      "Epoch 267/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0031 - val_loss: 0.0055 - val_mae: 0.0022\n",
      "Epoch 268/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0036 - val_loss: 0.0055 - val_mae: 0.0026\n",
      "Epoch 269/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0027 - val_loss: 0.0055 - val_mae: 0.0069\n",
      "Epoch 270/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0054 - mae: 0.0031 - val_loss: 0.0055 - val_mae: 0.0050\n",
      "Epoch 271/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0054 - mae: 0.0034 - val_loss: 0.0054 - val_mae: 0.0027\n",
      "Epoch 272/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0048 - val_loss: 0.0054 - val_mae: 0.0032\n",
      "Epoch 273/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0054 - mae: 0.0044 - val_loss: 0.0054 - val_mae: 0.0033\n",
      "Epoch 274/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0054 - mae: 0.0058 - val_loss: 0.0055 - val_mae: 0.0092\n",
      "Epoch 275/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0054 - mae: 0.0038 - val_loss: 0.0055 - val_mae: 0.0100\n",
      "Epoch 276/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0054 - mae: 0.0034 - val_loss: 0.0054 - val_mae: 0.0056\n",
      "Epoch 277/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0053 - mae: 0.0026 - val_loss: 0.0054 - val_mae: 0.0062\n",
      "Epoch 278/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0053 - mae: 0.0032 - val_loss: 0.0053 - val_mae: 0.0020\n",
      "Epoch 279/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0053 - mae: 0.0032 - val_loss: 0.0055 - val_mae: 0.0103\n",
      "Epoch 280/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0079 - val_loss: 0.0053 - val_mae: 0.0043\n",
      "Epoch 281/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0053 - mae: 0.0031 - val_loss: 0.0053 - val_mae: 0.0026\n",
      "Epoch 282/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0053 - mae: 0.0023 - val_loss: 0.0053 - val_mae: 0.0020\n",
      "Epoch 283/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0053 - mae: 0.0018 - val_loss: 0.0053 - val_mae: 0.0023\n",
      "Epoch 284/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0053 - mae: 0.0024 - val_loss: 0.0053 - val_mae: 0.0042\n",
      "Epoch 285/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0032 - val_loss: 0.0052 - val_mae: 0.0021\n",
      "Epoch 286/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0028 - val_loss: 0.0053 - val_mae: 0.0054\n",
      "Epoch 287/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0031 - val_loss: 0.0052 - val_mae: 0.0046\n",
      "Epoch 288/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0052 - mae: 0.0038 - val_loss: 0.0052 - val_mae: 0.0023\n",
      "Epoch 289/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0052 - mae: 0.0032 - val_loss: 0.0052 - val_mae: 0.0067\n",
      "Epoch 290/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0052 - mae: 0.0064 - val_loss: 0.0052 - val_mae: 0.0048\n",
      "Epoch 291/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0052 - mae: 0.0035 - val_loss: 0.0052 - val_mae: 0.0023\n",
      "Epoch 292/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0051 - mae: 0.0025 - val_loss: 0.0052 - val_mae: 0.0050\n",
      "Epoch 293/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0051 - mae: 0.0025 - val_loss: 0.0051 - val_mae: 0.0048\n",
      "Epoch 294/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0051 - mae: 0.0037 - val_loss: 0.0051 - val_mae: 0.0050\n",
      "Epoch 295/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0051 - mae: 0.0033 - val_loss: 0.0051 - val_mae: 0.0028\n",
      "Epoch 296/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0051 - mae: 0.0025 - val_loss: 0.0052 - val_mae: 0.0082\n",
      "Epoch 297/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0051 - mae: 0.0035 - val_loss: 0.0051 - val_mae: 0.0061\n",
      "Epoch 298/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0051 - mae: 0.0044 - val_loss: 0.0051 - val_mae: 0.0040\n",
      "Epoch 299/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0051 - mae: 0.0037 - val_loss: 0.0051 - val_mae: 0.0037\n",
      "Epoch 300/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0050 - mae: 0.0028 - val_loss: 0.0050 - val_mae: 0.0028\n",
      "Epoch 301/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0026 - val_loss: 0.0050 - val_mae: 0.0037\n",
      "Epoch 302/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0050 - mae: 0.0028 - val_loss: 0.0050 - val_mae: 0.0037\n",
      "Epoch 303/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0030 - val_loss: 0.0050 - val_mae: 0.0022\n",
      "Epoch 304/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0044 - val_loss: 0.0050 - val_mae: 0.0023\n",
      "Epoch 305/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0050 - mae: 0.0037 - val_loss: 0.0050 - val_mae: 0.0031\n",
      "Epoch 306/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0036 - val_loss: 0.0050 - val_mae: 0.0027\n",
      "Epoch 307/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0050 - mae: 0.0033 - val_loss: 0.0050 - val_mae: 0.0052\n",
      "Epoch 308/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0049 - mae: 0.0035 - val_loss: 0.0049 - val_mae: 0.0031\n",
      "Epoch 309/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0049 - mae: 0.0028 - val_loss: 0.0049 - val_mae: 0.0039\n",
      "Epoch 310/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0042 - val_loss: 0.0049 - val_mae: 0.0032\n",
      "Epoch 311/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0033 - val_loss: 0.0049 - val_mae: 0.0060\n",
      "Epoch 312/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0049 - mae: 0.0028 - val_loss: 0.0049 - val_mae: 0.0019\n",
      "Epoch 313/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0050 - val_loss: 0.0049 - val_mae: 0.0031\n",
      "Epoch 314/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0031 - val_loss: 0.0049 - val_mae: 0.0030\n",
      "Epoch 315/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0026 - val_loss: 0.0049 - val_mae: 0.0047\n",
      "Epoch 316/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0032 - val_loss: 0.0048 - val_mae: 0.0040\n",
      "Epoch 317/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0026 - val_loss: 0.0048 - val_mae: 0.0030\n",
      "Epoch 318/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0051 - val_loss: 0.0048 - val_mae: 0.0036\n",
      "Epoch 319/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0048 - mae: 0.0023 - val_loss: 0.0048 - val_mae: 0.0016\n",
      "Epoch 320/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0027 - val_loss: 0.0049 - val_mae: 0.0104\n",
      "Epoch 321/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0050 - val_loss: 0.0048 - val_mae: 0.0027\n",
      "Epoch 322/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0047 - mae: 0.0022 - val_loss: 0.0047 - val_mae: 0.0023\n",
      "Epoch 323/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0047 - mae: 0.0028 - val_loss: 0.0048 - val_mae: 0.0048\n",
      "Epoch 324/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0047 - mae: 0.0032 - val_loss: 0.0047 - val_mae: 0.0028\n",
      "Epoch 325/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0047 - mae: 0.0038 - val_loss: 0.0049 - val_mae: 0.0105\n",
      "Epoch 326/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0047 - mae: 0.0047 - val_loss: 0.0047 - val_mae: 0.0033\n",
      "Epoch 327/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0047 - mae: 0.0021 - val_loss: 0.0047 - val_mae: 0.0021\n",
      "Epoch 328/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0047 - mae: 0.0020 - val_loss: 0.0047 - val_mae: 0.0018\n",
      "Epoch 329/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0047 - mae: 0.0027 - val_loss: 0.0047 - val_mae: 0.0025\n",
      "Epoch 330/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0047 - mae: 0.0029 - val_loss: 0.0047 - val_mae: 0.0051\n",
      "Epoch 331/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0026 - val_loss: 0.0046 - val_mae: 0.0027\n",
      "Epoch 332/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0034 - val_loss: 0.0046 - val_mae: 0.0024\n",
      "Epoch 333/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0026 - val_loss: 0.0046 - val_mae: 0.0018\n",
      "Epoch 334/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0031 - val_loss: 0.0046 - val_mae: 0.0023\n",
      "Epoch 335/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0030 - val_loss: 0.0046 - val_mae: 0.0025\n",
      "Epoch 336/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0024 - val_loss: 0.0046 - val_mae: 0.0018\n",
      "Epoch 337/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0038 - val_loss: 0.0046 - val_mae: 0.0027\n",
      "Epoch 338/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0031 - val_loss: 0.0045 - val_mae: 0.0023\n",
      "Epoch 339/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0033 - val_loss: 0.0054 - val_mae: 0.0221\n",
      "Epoch 340/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0047 - mae: 0.0079 - val_loss: 0.0045 - val_mae: 0.0019\n",
      "Epoch 341/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0018 - val_loss: 0.0045 - val_mae: 0.0025\n",
      "Epoch 342/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0018 - val_loss: 0.0045 - val_mae: 0.0050\n",
      "Epoch 343/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0024 - val_loss: 0.0045 - val_mae: 0.0029\n",
      "Epoch 344/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0020 - val_loss: 0.0045 - val_mae: 0.0021\n",
      "Epoch 345/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0023 - val_loss: 0.0045 - val_mae: 0.0017\n",
      "Epoch 346/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0030 - val_loss: 0.0045 - val_mae: 0.0025\n",
      "Epoch 347/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0046 - val_loss: 0.0044 - val_mae: 0.0021\n",
      "Epoch 348/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0022 - val_loss: 0.0044 - val_mae: 0.0021\n",
      "Epoch 349/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0023 - val_loss: 0.0044 - val_mae: 0.0023\n",
      "Epoch 350/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0025 - val_loss: 0.0044 - val_mae: 0.0026\n",
      "Epoch 351/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0027 - val_loss: 0.0044 - val_mae: 0.0019\n",
      "Epoch 352/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0022 - val_loss: 0.0044 - val_mae: 0.0018\n",
      "Epoch 353/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0023 - val_loss: 0.0044 - val_mae: 0.0036\n",
      "Epoch 354/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0065 - val_loss: 0.0044 - val_mae: 0.0024\n",
      "Epoch 355/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0022 - val_loss: 0.0044 - val_mae: 0.0027\n",
      "Epoch 356/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0027 - val_loss: 0.0043 - val_mae: 0.0018\n",
      "Epoch 357/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0025 - val_loss: 0.0043 - val_mae: 0.0034\n",
      "Epoch 358/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0017 - val_loss: 0.0043 - val_mae: 0.0025\n",
      "Epoch 359/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0019 - val_loss: 0.0051 - val_mae: 0.0191\n",
      "Epoch 360/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0072 - val_loss: 0.0043 - val_mae: 0.0024\n",
      "Epoch 361/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0019 - val_loss: 0.0043 - val_mae: 0.0020\n",
      "Epoch 362/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0017 - val_loss: 0.0043 - val_mae: 0.0015\n",
      "Epoch 363/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0019 - val_loss: 0.0043 - val_mae: 0.0030\n",
      "Epoch 364/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0027 - val_loss: 0.0043 - val_mae: 0.0029\n",
      "Epoch 365/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0032 - val_loss: 0.0042 - val_mae: 0.0019\n",
      "Epoch 366/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0020 - val_loss: 0.0042 - val_mae: 0.0019\n",
      "Epoch 367/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0030 - val_loss: 0.0042 - val_mae: 0.0032\n",
      "Epoch 368/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0031 - val_loss: 0.0042 - val_mae: 0.0019\n",
      "Epoch 369/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0021 - val_loss: 0.0042 - val_mae: 0.0028\n",
      "Epoch 370/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0040 - val_loss: 0.0042 - val_mae: 0.0042\n",
      "Epoch 371/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0024 - val_loss: 0.0042 - val_mae: 0.0018\n",
      "Epoch 372/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0021 - val_loss: 0.0042 - val_mae: 0.0040\n",
      "Epoch 373/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0027 - val_loss: 0.0042 - val_mae: 0.0068\n",
      "Epoch 374/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0033 - val_loss: 0.0042 - val_mae: 0.0027\n",
      "Epoch 375/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0040 - val_loss: 0.0042 - val_mae: 0.0043\n",
      "Epoch 376/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0030 - val_loss: 0.0042 - val_mae: 0.0060\n",
      "Epoch 377/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0024 - val_loss: 0.0041 - val_mae: 0.0028\n",
      "Epoch 378/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0032 - val_loss: 0.0041 - val_mae: 0.0017\n",
      "Epoch 379/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0025 - val_loss: 0.0041 - val_mae: 0.0027\n",
      "Epoch 380/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0045 - val_loss: 0.0041 - val_mae: 0.0060\n",
      "Epoch 381/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0026 - val_loss: 0.0041 - val_mae: 0.0033\n",
      "Epoch 382/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0019 - val_loss: 0.0041 - val_mae: 0.0032\n",
      "Epoch 383/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0025 - val_loss: 0.0041 - val_mae: 0.0024\n",
      "Epoch 384/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0028 - val_loss: 0.0040 - val_mae: 0.0018\n",
      "Epoch 385/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0037 - val_loss: 0.0040 - val_mae: 0.0024\n",
      "Epoch 386/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0030 - val_loss: 0.0040 - val_mae: 0.0022\n",
      "Epoch 387/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0032 - val_loss: 0.0040 - val_mae: 0.0042\n",
      "Epoch 388/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0023 - val_loss: 0.0041 - val_mae: 0.0066\n",
      "Epoch 389/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0026 - val_loss: 0.0040 - val_mae: 0.0019\n",
      "Epoch 390/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0021 - val_loss: 0.0040 - val_mae: 0.0039\n",
      "Epoch 391/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0033 - val_loss: 0.0040 - val_mae: 0.0050\n",
      "Epoch 392/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0034 - val_loss: 0.0041 - val_mae: 0.0074\n",
      "Epoch 393/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0072 - val_loss: 0.0040 - val_mae: 0.0030\n",
      "Epoch 394/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0022 - val_loss: 0.0039 - val_mae: 0.0029\n",
      "Epoch 395/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0017 - val_loss: 0.0039 - val_mae: 0.0034\n",
      "Epoch 396/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0020 - val_loss: 0.0039 - val_mae: 0.0017\n",
      "Epoch 397/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0017 - val_loss: 0.0039 - val_mae: 0.0015\n",
      "Epoch 398/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0016 - val_loss: 0.0039 - val_mae: 0.0018\n",
      "Epoch 399/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0020 - val_loss: 0.0039 - val_mae: 0.0018\n",
      "Epoch 400/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0021 - val_loss: 0.0039 - val_mae: 0.0048\n",
      "Epoch 401/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0032 - val_loss: 0.0040 - val_mae: 0.0082\n",
      "Epoch 402/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0053 - val_loss: 0.0039 - val_mae: 0.0030\n",
      "Epoch 403/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0039 - mae: 0.0019 - val_loss: 0.0039 - val_mae: 0.0032\n",
      "Epoch 404/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0019 - val_loss: 0.0038 - val_mae: 0.0027\n",
      "Epoch 405/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0026 - val_loss: 0.0038 - val_mae: 0.0026\n",
      "Epoch 406/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0031 - val_loss: 0.0038 - val_mae: 0.0036\n",
      "Epoch 407/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0024 - val_loss: 0.0038 - val_mae: 0.0021\n",
      "Epoch 408/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0026 - val_loss: 0.0039 - val_mae: 0.0067\n",
      "Epoch 409/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0029 - val_loss: 0.0038 - val_mae: 0.0023\n",
      "Epoch 410/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0019 - val_loss: 0.0038 - val_mae: 0.0030\n",
      "Epoch 411/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0032 - val_loss: 0.0038 - val_mae: 0.0024\n",
      "Epoch 412/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0036 - val_loss: 0.0038 - val_mae: 0.0018\n",
      "Epoch 413/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0018 - val_loss: 0.0038 - val_mae: 0.0033\n",
      "Epoch 414/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0027 - val_loss: 0.0037 - val_mae: 0.0032\n",
      "Epoch 415/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0044 - val_loss: 0.0038 - val_mae: 0.0047\n",
      "Epoch 416/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0026 - val_loss: 0.0037 - val_mae: 0.0015\n",
      "Epoch 417/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0026 - val_loss: 0.0037 - val_mae: 0.0024\n",
      "Epoch 418/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0027 - val_loss: 0.0037 - val_mae: 0.0029\n",
      "Epoch 419/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0023 - val_loss: 0.0037 - val_mae: 0.0021\n",
      "Epoch 420/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0019 - val_loss: 0.0037 - val_mae: 0.0014\n",
      "Epoch 421/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0033 - val_loss: 0.0037 - val_mae: 0.0020\n",
      "Epoch 422/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0032 - val_loss: 0.0037 - val_mae: 0.0028\n",
      "Epoch 423/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0022 - val_loss: 0.0037 - val_mae: 0.0019\n",
      "Epoch 424/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0020 - val_loss: 0.0038 - val_mae: 0.0083\n",
      "Epoch 425/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0030 - val_loss: 0.0037 - val_mae: 0.0040\n",
      "Epoch 426/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0021 - val_loss: 0.0036 - val_mae: 0.0021\n",
      "Epoch 427/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0021 - val_loss: 0.0036 - val_mae: 0.0034\n",
      "Epoch 428/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0040 - val_loss: 0.0036 - val_mae: 0.0015\n",
      "Epoch 429/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0031 - val_loss: 0.0036 - val_mae: 0.0028\n",
      "Epoch 430/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0027 - val_loss: 0.0036 - val_mae: 0.0027\n",
      "Epoch 431/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0016 - val_loss: 0.0036 - val_mae: 0.0027\n",
      "Epoch 432/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0028 - val_loss: 0.0037 - val_mae: 0.0088\n",
      "Epoch 433/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0040 - val_loss: 0.0036 - val_mae: 0.0014\n",
      "Epoch 434/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0019 - val_loss: 0.0035 - val_mae: 0.0018\n",
      "Epoch 435/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0021 - val_loss: 0.0035 - val_mae: 0.0027\n",
      "Epoch 436/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0023 - val_loss: 0.0035 - val_mae: 0.0017\n",
      "Epoch 437/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0022 - val_loss: 0.0038 - val_mae: 0.0137\n",
      "Epoch 438/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0046 - val_loss: 0.0035 - val_mae: 0.0035\n",
      "Epoch 439/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0021 - val_loss: 0.0035 - val_mae: 0.0018\n",
      "Epoch 440/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0022 - val_loss: 0.0035 - val_mae: 0.0016\n",
      "Epoch 441/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0026 - val_loss: 0.0035 - val_mae: 0.0042\n",
      "Epoch 442/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0032 - val_loss: 0.0035 - val_mae: 0.0018\n",
      "Epoch 443/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0027 - val_loss: 0.0035 - val_mae: 0.0065\n",
      "Epoch 444/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0030 - val_loss: 0.0035 - val_mae: 0.0027\n",
      "Epoch 445/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0020 - val_loss: 0.0034 - val_mae: 0.0018\n",
      "Epoch 446/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0020 - val_loss: 0.0034 - val_mae: 0.0017\n",
      "Epoch 447/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0018 - val_loss: 0.0034 - val_mae: 0.0019\n",
      "Epoch 448/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0026 - val_loss: 0.0034 - val_mae: 0.0018\n",
      "Epoch 449/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0050 - val_loss: 0.0034 - val_mae: 0.0029\n",
      "Epoch 450/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0019 - val_loss: 0.0034 - val_mae: 0.0036\n",
      "Epoch 451/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0024 - val_loss: 0.0035 - val_mae: 0.0067\n",
      "Epoch 452/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0037 - val_loss: 0.0034 - val_mae: 0.0013\n",
      "Epoch 453/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0021 - val_loss: 0.0034 - val_mae: 0.0031\n",
      "Epoch 454/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0019 - val_loss: 0.0034 - val_mae: 0.0013\n",
      "Epoch 455/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0024 - val_loss: 0.0034 - val_mae: 0.0050\n",
      "Epoch 456/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0031 - val_loss: 0.0033 - val_mae: 0.0016\n",
      "Epoch 457/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0020 - val_loss: 0.0033 - val_mae: 0.0029\n",
      "Epoch 458/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0023 - val_loss: 0.0033 - val_mae: 0.0025\n",
      "Epoch 459/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0022 - val_loss: 0.0033 - val_mae: 0.0025\n",
      "Epoch 460/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0023 - val_loss: 0.0033 - val_mae: 0.0026\n",
      "Epoch 461/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0022 - val_loss: 0.0033 - val_mae: 0.0020\n",
      "Epoch 462/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0022 - val_loss: 0.0033 - val_mae: 0.0020\n",
      "Epoch 463/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0029 - val_loss: 0.0033 - val_mae: 0.0034\n",
      "Epoch 464/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0023 - val_loss: 0.0033 - val_mae: 0.0015\n",
      "Epoch 465/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0040 - val_loss: 0.0033 - val_mae: 0.0025\n",
      "Epoch 466/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0026 - val_loss: 0.0033 - val_mae: 0.0028\n",
      "Epoch 467/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0023 - val_loss: 0.0033 - val_mae: 0.0019\n",
      "Epoch 468/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0023 - val_loss: 0.0033 - val_mae: 0.0073\n",
      "Epoch 469/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0043 - val_loss: 0.0032 - val_mae: 0.0029\n",
      "Epoch 470/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0021 - val_loss: 0.0032 - val_mae: 0.0019\n",
      "Epoch 471/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0018 - val_loss: 0.0032 - val_mae: 0.0042\n",
      "Epoch 472/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0034 - val_loss: 0.0032 - val_mae: 0.0025\n",
      "Epoch 473/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0028 - val_loss: 0.0032 - val_mae: 0.0016\n",
      "Epoch 474/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0018 - val_loss: 0.0032 - val_mae: 0.0017\n",
      "Epoch 475/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0019 - val_loss: 0.0032 - val_mae: 0.0035\n",
      "Epoch 476/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0034 - val_loss: 0.0032 - val_mae: 0.0017\n",
      "Epoch 477/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0022 - val_loss: 0.0032 - val_mae: 0.0044\n",
      "Epoch 478/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0028 - val_loss: 0.0032 - val_mae: 0.0020\n",
      "Epoch 479/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0026 - val_loss: 0.0031 - val_mae: 0.0014\n",
      "Epoch 480/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0016 - val_loss: 0.0031 - val_mae: 0.0021\n",
      "Epoch 481/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0024 - val_loss: 0.0031 - val_mae: 0.0027\n",
      "Epoch 482/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0026 - val_loss: 0.0031 - val_mae: 0.0016\n",
      "Epoch 483/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0029 - val_loss: 0.0031 - val_mae: 0.0015\n",
      "Epoch 484/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0021 - val_loss: 0.0031 - val_mae: 0.0026\n",
      "Epoch 485/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0016 - val_loss: 0.0031 - val_mae: 0.0019\n",
      "Epoch 486/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0031 - val_loss: 0.0031 - val_mae: 0.0017\n",
      "Epoch 487/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0029 - val_loss: 0.0031 - val_mae: 0.0014\n",
      "Epoch 488/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0027 - val_loss: 0.0032 - val_mae: 0.0068\n",
      "Epoch 489/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0025 - val_loss: 0.0031 - val_mae: 0.0028\n",
      "Epoch 490/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0018 - val_loss: 0.0031 - val_mae: 0.0030\n",
      "Epoch 491/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0019 - val_loss: 0.0031 - val_mae: 0.0058\n",
      "Epoch 492/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0042 - val_loss: 0.0030 - val_mae: 0.0023\n",
      "Epoch 493/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0017 - val_loss: 0.0030 - val_mae: 0.0016\n",
      "Epoch 494/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0019 - val_loss: 0.0030 - val_mae: 0.0011\n",
      "Epoch 495/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0017 - val_loss: 0.0030 - val_mae: 0.0013\n",
      "Epoch 496/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0026 - val_loss: 0.0030 - val_mae: 0.0036\n",
      "Epoch 497/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0026 - val_loss: 0.0030 - val_mae: 0.0014\n",
      "Epoch 498/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0023 - val_loss: 0.0030 - val_mae: 0.0025\n",
      "Epoch 499/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0018 - val_loss: 0.0030 - val_mae: 0.0015\n",
      "Epoch 500/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0020 - val_loss: 0.0030 - val_mae: 0.0031\n",
      "Epoch 501/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0033 - val_loss: 0.0030 - val_mae: 0.0029\n",
      "Epoch 502/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0018 - val_loss: 0.0030 - val_mae: 0.0026\n",
      "Epoch 503/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0024 - val_loss: 0.0030 - val_mae: 0.0038\n",
      "Epoch 504/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0036 - val_loss: 0.0029 - val_mae: 0.0015\n",
      "Epoch 505/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0015 - val_loss: 0.0029 - val_mae: 0.0018\n",
      "Epoch 506/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0019 - val_loss: 0.0029 - val_mae: 0.0029\n",
      "Epoch 507/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0036 - val_loss: 0.0029 - val_mae: 0.0021\n",
      "Epoch 508/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0016 - val_loss: 0.0029 - val_mae: 0.0015\n",
      "Epoch 509/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0023 - val_loss: 0.0029 - val_mae: 0.0028\n",
      "Epoch 510/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0019 - val_loss: 0.0029 - val_mae: 0.0013\n",
      "Epoch 511/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0033 - val_loss: 0.0029 - val_mae: 0.0017\n",
      "Epoch 512/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0019 - val_loss: 0.0029 - val_mae: 0.0047\n",
      "Epoch 513/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0023 - val_loss: 0.0029 - val_mae: 0.0013\n",
      "Epoch 514/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0023 - val_loss: 0.0029 - val_mae: 0.0030\n",
      "Epoch 515/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0025 - val_loss: 0.0029 - val_mae: 0.0088\n",
      "Epoch 516/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0023 - val_loss: 0.0028 - val_mae: 0.0026\n",
      "Epoch 517/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0019 - val_loss: 0.0030 - val_mae: 0.0084\n",
      "Epoch 518/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0028 - val_loss: 0.0028 - val_mae: 0.0021\n",
      "Epoch 519/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0020 - val_loss: 0.0028 - val_mae: 0.0016\n",
      "Epoch 520/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0023 - val_loss: 0.0028 - val_mae: 0.0016\n",
      "Epoch 521/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0019 - val_loss: 0.0028 - val_mae: 0.0019\n",
      "Epoch 522/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0019 - val_loss: 0.0028 - val_mae: 0.0013\n",
      "Epoch 523/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0035 - val_loss: 0.0035 - val_mae: 0.0208\n",
      "Epoch 524/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0052 - val_loss: 0.0028 - val_mae: 0.0013\n",
      "Epoch 525/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0015 - val_loss: 0.0028 - val_mae: 0.0018\n",
      "Epoch 526/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0016 - val_loss: 0.0028 - val_mae: 0.0014\n",
      "Epoch 527/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0018 - val_loss: 0.0028 - val_mae: 0.0014\n",
      "Epoch 528/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0014 - val_loss: 0.0028 - val_mae: 0.0024\n",
      "Epoch 529/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0015 - val_loss: 0.0027 - val_mae: 0.0013\n",
      "Epoch 530/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0017 - val_loss: 0.0027 - val_mae: 0.0017\n",
      "Epoch 531/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0021 - val_loss: 0.0027 - val_mae: 0.0020\n",
      "Epoch 532/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0017 - val_loss: 0.0027 - val_mae: 0.0018\n",
      "Epoch 533/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0016 - val_loss: 0.0027 - val_mae: 0.0041\n",
      "Epoch 534/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0023 - val_loss: 0.0027 - val_mae: 0.0021\n",
      "Epoch 535/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0020 - val_loss: 0.0027 - val_mae: 0.0025\n",
      "Epoch 536/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0025 - val_loss: 0.0027 - val_mae: 0.0021\n",
      "Epoch 537/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0023 - val_loss: 0.0027 - val_mae: 0.0011\n",
      "Epoch 538/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0027 - mae: 0.0022 - val_loss: 0.0027 - val_mae: 0.0037\n",
      "Epoch 539/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0027 - mae: 0.0026 - val_loss: 0.0027 - val_mae: 0.0050\n",
      "Epoch 540/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0027 - mae: 0.0018 - val_loss: 0.0028 - val_mae: 0.0089\n",
      "Epoch 541/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0027 - mae: 0.0030 - val_loss: 0.0027 - val_mae: 0.0020\n",
      "Epoch 542/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0017 - val_loss: 0.0026 - val_mae: 0.0013\n",
      "Epoch 543/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0017 - val_loss: 0.0026 - val_mae: 0.0015\n",
      "Epoch 544/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0032 - val_loss: 0.0026 - val_mae: 0.0017\n",
      "Epoch 545/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0015 - val_loss: 0.0026 - val_mae: 0.0027\n",
      "Epoch 546/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0024 - val_loss: 0.0028 - val_mae: 0.0106\n",
      "Epoch 547/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0035 - val_loss: 0.0026 - val_mae: 0.0041\n",
      "Epoch 548/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0022 - val_loss: 0.0027 - val_mae: 0.0062\n",
      "Epoch 549/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0024 - val_loss: 0.0026 - val_mae: 0.0038\n",
      "Epoch 550/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0031 - val_loss: 0.0026 - val_mae: 0.0033\n",
      "Epoch 551/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0024 - val_loss: 0.0026 - val_mae: 0.0018\n",
      "Epoch 552/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0018 - val_loss: 0.0026 - val_mae: 0.0016\n",
      "Epoch 553/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0019 - val_loss: 0.0026 - val_mae: 0.0030\n",
      "Epoch 554/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0037 - val_loss: 0.0026 - val_mae: 0.0021\n",
      "Epoch 555/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0020 - val_loss: 0.0026 - val_mae: 0.0029\n",
      "Epoch 556/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0027 - val_loss: 0.0025 - val_mae: 0.0013\n",
      "Epoch 557/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0024 - val_loss: 0.0026 - val_mae: 0.0050\n",
      "Epoch 558/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0019 - val_loss: 0.0025 - val_mae: 0.0027\n",
      "Epoch 559/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0016 - val_loss: 0.0026 - val_mae: 0.0053\n",
      "Epoch 560/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0022 - val_loss: 0.0025 - val_mae: 0.0029\n",
      "Epoch 561/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0027 - val_loss: 0.0025 - val_mae: 0.0017\n",
      "Epoch 562/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0022 - val_loss: 0.0025 - val_mae: 0.0037\n",
      "Epoch 563/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0021 - val_loss: 0.0025 - val_mae: 0.0017\n",
      "Epoch 564/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0014 - val_loss: 0.0026 - val_mae: 0.0084\n",
      "Epoch 565/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0033 - val_loss: 0.0025 - val_mae: 0.0056\n",
      "Epoch 566/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0026 - val_loss: 0.0025 - val_mae: 0.0014\n",
      "Epoch 567/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0019 - val_loss: 0.0025 - val_mae: 0.0012\n",
      "Epoch 568/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0018 - val_loss: 0.0025 - val_mae: 0.0017\n",
      "Epoch 569/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0016 - val_loss: 0.0025 - val_mae: 0.0014\n",
      "Epoch 570/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0015 - val_loss: 0.0025 - val_mae: 0.0034\n",
      "Epoch 571/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0027 - val_loss: 0.0024 - val_mae: 0.0025\n",
      "Epoch 572/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0020 - val_loss: 0.0024 - val_mae: 0.0017\n",
      "Epoch 573/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0016 - val_loss: 0.0024 - val_mae: 0.0022\n",
      "Epoch 574/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0021 - val_loss: 0.0024 - val_mae: 0.0013\n",
      "Epoch 575/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0024 - val_loss: 0.0024 - val_mae: 0.0028\n",
      "Epoch 576/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0027 - val_loss: 0.0024 - val_mae: 0.0031\n",
      "Epoch 577/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0019 - val_loss: 0.0024 - val_mae: 0.0032\n",
      "Epoch 578/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0022 - val_loss: 0.0024 - val_mae: 0.0024\n",
      "Epoch 579/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0026 - val_loss: 0.0024 - val_mae: 0.0060\n",
      "Epoch 580/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0037 - val_loss: 0.0024 - val_mae: 0.0015\n",
      "Epoch 581/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0014 - val_loss: 0.0024 - val_mae: 0.0014\n",
      "Epoch 582/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0023 - val_loss: 0.0024 - val_mae: 0.0068\n",
      "Epoch 583/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0030 - val_loss: 0.0024 - val_mae: 0.0012\n",
      "Epoch 584/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0017 - val_loss: 0.0024 - val_mae: 0.0042\n",
      "Epoch 585/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0018 - val_loss: 0.0023 - val_mae: 0.0014\n",
      "Epoch 586/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0014 - val_loss: 0.0023 - val_mae: 0.0013\n",
      "Epoch 587/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0025 - val_loss: 0.0023 - val_mae: 0.0012\n",
      "Epoch 588/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0018 - val_loss: 0.0023 - val_mae: 0.0033\n",
      "Epoch 589/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0030 - val_loss: 0.0023 - val_mae: 0.0026\n",
      "Epoch 590/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0021 - val_loss: 0.0023 - val_mae: 0.0019\n",
      "Epoch 591/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0017 - val_loss: 0.0024 - val_mae: 0.0067\n",
      "Epoch 592/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0022 - val_loss: 0.0023 - val_mae: 0.0012\n",
      "Epoch 593/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0017 - val_loss: 0.0023 - val_mae: 0.0020\n",
      "Epoch 594/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0021 - val_loss: 0.0023 - val_mae: 0.0056\n",
      "Epoch 595/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0027 - val_loss: 0.0025 - val_mae: 0.0110\n",
      "Epoch 596/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0041 - val_loss: 0.0023 - val_mae: 0.0020\n",
      "Epoch 597/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0016 - val_loss: 0.0023 - val_mae: 0.0011\n",
      "Epoch 598/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0014 - val_loss: 0.0023 - val_mae: 0.0023\n",
      "Epoch 599/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0018 - val_loss: 0.0023 - val_mae: 0.0019\n",
      "Epoch 600/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0017 - val_loss: 0.0023 - val_mae: 0.0015\n",
      "Epoch 601/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0026 - val_loss: 0.0022 - val_mae: 0.0018\n",
      "Epoch 602/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0015 - val_loss: 0.0023 - val_mae: 0.0049\n",
      "Epoch 603/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0019 - val_loss: 0.0022 - val_mae: 0.0014\n",
      "Epoch 604/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0022 - mae: 0.0020 - val_loss: 0.0022 - val_mae: 0.0026\n",
      "Epoch 605/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0022 - mae: 0.0018 - val_loss: 0.0022 - val_mae: 0.0029\n",
      "Epoch 606/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0022 - mae: 0.0016 - val_loss: 0.0022 - val_mae: 0.0028\n",
      "Epoch 607/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0022 - mae: 0.0040 - val_loss: 0.0022 - val_mae: 0.0046\n",
      "Epoch 608/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0022 - mae: 0.0017 - val_loss: 0.0022 - val_mae: 0.0015\n",
      "Epoch 609/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0022 - mae: 0.0016 - val_loss: 0.0022 - val_mae: 0.0017\n",
      "Epoch 610/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0022 - mae: 0.0016 - val_loss: 0.0022 - val_mae: 0.0015\n",
      "Epoch 611/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0015 - val_loss: 0.0022 - val_mae: 0.0018\n",
      "Epoch 612/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0021 - val_loss: 0.0022 - val_mae: 0.0015\n",
      "Epoch 613/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0017 - val_loss: 0.0022 - val_mae: 0.0040\n",
      "Epoch 614/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0023 - val_loss: 0.0022 - val_mae: 0.0034\n",
      "Epoch 615/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0019 - val_loss: 0.0022 - val_mae: 0.0014\n",
      "Epoch 616/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0031 - val_loss: 0.0022 - val_mae: 0.0052\n",
      "Epoch 617/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0016 - val_loss: 0.0021 - val_mae: 0.0012\n",
      "Epoch 618/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0018 - val_loss: 0.0022 - val_mae: 0.0070\n",
      "Epoch 619/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0029 - val_loss: 0.0021 - val_mae: 0.0024\n",
      "Epoch 620/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0015 - val_loss: 0.0021 - val_mae: 0.0020\n",
      "Epoch 621/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0029 - val_loss: 0.0021 - val_mae: 0.0045\n",
      "Epoch 622/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0015 - val_loss: 0.0021 - val_mae: 0.0012\n",
      "Epoch 623/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0014 - val_loss: 0.0021 - val_mae: 0.0018\n",
      "Epoch 624/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0021 - val_loss: 0.0021 - val_mae: 0.0016\n",
      "Epoch 625/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0019 - val_loss: 0.0021 - val_mae: 0.0027\n",
      "Epoch 626/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0019 - val_loss: 0.0021 - val_mae: 0.0025\n",
      "Epoch 627/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0018 - val_loss: 0.0021 - val_mae: 0.0016\n",
      "Epoch 628/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0017 - val_loss: 0.0021 - val_mae: 0.0020\n",
      "Epoch 629/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0019 - val_loss: 0.0021 - val_mae: 0.0042\n",
      "Epoch 630/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0022 - val_loss: 0.0021 - val_mae: 0.0012\n",
      "Epoch 631/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0047 - val_loss: 0.0021 - val_mae: 0.0021\n",
      "Epoch 632/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0019 - val_loss: 0.0021 - val_mae: 0.0076\n",
      "Epoch 633/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0021 - val_loss: 0.0020 - val_mae: 0.0011\n",
      "Epoch 634/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0013 - val_loss: 0.0020 - val_mae: 0.0026\n",
      "Epoch 635/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0013 - val_loss: 0.0020 - val_mae: 0.0018\n",
      "Epoch 636/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0018 - val_loss: 0.0020 - val_mae: 0.0027\n",
      "Epoch 637/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0021 - val_loss: 0.0020 - val_mae: 0.0044\n",
      "Epoch 638/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0014 - val_loss: 0.0020 - val_mae: 0.0010\n",
      "Epoch 639/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0014 - val_loss: 0.0020 - val_mae: 0.0014\n",
      "Epoch 640/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0017 - val_loss: 0.0020 - val_mae: 0.0013\n",
      "Epoch 641/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0015 - val_loss: 0.0020 - val_mae: 0.0036\n",
      "Epoch 642/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0023 - val_loss: 0.0020 - val_mae: 0.0028\n",
      "Epoch 643/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0026 - val_loss: 0.0020 - val_mae: 0.0014\n",
      "Epoch 644/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0019 - val_loss: 0.0020 - val_mae: 0.0014\n",
      "Epoch 645/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0016 - val_loss: 0.0020 - val_mae: 0.0046\n",
      "Epoch 646/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0028 - val_loss: 0.0020 - val_mae: 0.0023\n",
      "Epoch 647/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0025 - val_loss: 0.0020 - val_mae: 0.0022\n",
      "Epoch 648/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0016 - val_loss: 0.0020 - val_mae: 0.0015\n",
      "Epoch 649/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0020 - val_loss: 0.0020 - val_mae: 0.0034\n",
      "Epoch 650/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0025 - val_loss: 0.0020 - val_mae: 0.0023\n",
      "Epoch 651/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0015 - val_loss: 0.0020 - val_mae: 0.0044\n",
      "Epoch 652/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0023 - val_loss: 0.0019 - val_mae: 0.0026\n",
      "Epoch 653/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0015 - val_loss: 0.0019 - val_mae: 0.0017\n",
      "Epoch 654/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0017 - val_loss: 0.0019 - val_mae: 0.0023\n",
      "Epoch 655/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0018 - val_loss: 0.0019 - val_mae: 0.0013\n",
      "Epoch 656/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0023 - val_loss: 0.0019 - val_mae: 0.0027\n",
      "Epoch 657/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0018 - val_loss: 0.0020 - val_mae: 0.0056\n",
      "Epoch 658/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0023 - val_loss: 0.0020 - val_mae: 0.0089\n",
      "Epoch 659/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0051 - val_loss: 0.0019 - val_mae: 0.0016\n",
      "Epoch 660/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0014 - val_loss: 0.0019 - val_mae: 0.0019\n",
      "Epoch 661/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0012 - val_loss: 0.0019 - val_mae: 0.0012\n",
      "Epoch 662/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0014 - val_loss: 0.0019 - val_mae: 0.0012\n",
      "Epoch 663/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0012 - val_loss: 0.0019 - val_mae: 0.0037\n",
      "Epoch 664/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0013 - val_loss: 0.0019 - val_mae: 0.0015\n",
      "Epoch 665/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0016 - val_loss: 0.0019 - val_mae: 0.0030\n",
      "Epoch 666/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0014 - val_loss: 0.0019 - val_mae: 0.0012\n",
      "Epoch 667/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0017 - val_loss: 0.0019 - val_mae: 0.0021\n",
      "Epoch 668/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0016 - val_loss: 0.0019 - val_mae: 0.0026\n",
      "Epoch 669/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0017 - val_loss: 0.0019 - val_mae: 0.0017\n",
      "Epoch 670/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0016 - val_loss: 0.0018 - val_mae: 0.0015\n",
      "Epoch 671/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0032 - val_loss: 0.0018 - val_mae: 0.0021\n",
      "Epoch 672/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0014 - val_loss: 0.0019 - val_mae: 0.0056\n",
      "Epoch 673/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0030 - val_loss: 0.0018 - val_mae: 0.0030\n",
      "Epoch 674/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0015 - val_loss: 0.0018 - val_mae: 0.0015\n",
      "Epoch 675/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0017 - val_loss: 0.0018 - val_mae: 0.0011\n",
      "Epoch 676/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0014 - val_loss: 0.0018 - val_mae: 0.0044\n",
      "Epoch 677/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0031 - val_loss: 0.0018 - val_mae: 0.0039\n",
      "Epoch 678/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0019 - val_loss: 0.0018 - val_mae: 0.0011\n",
      "Epoch 679/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0014 - val_loss: 0.0018 - val_mae: 0.0012\n",
      "Epoch 680/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0017 - val_loss: 0.0018 - val_mae: 0.0015\n",
      "Epoch 681/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0028 - val_loss: 0.0018 - val_mae: 0.0023\n",
      "Epoch 682/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0015 - val_loss: 0.0018 - val_mae: 0.0020\n",
      "Epoch 683/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0015 - val_loss: 0.0018 - val_mae: 0.0033\n",
      "Epoch 684/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0024 - val_loss: 0.0018 - val_mae: 0.0023\n",
      "Epoch 685/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0028 - val_loss: 0.0018 - val_mae: 0.0031\n",
      "Epoch 686/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0019 - val_loss: 0.0018 - val_mae: 0.0058\n",
      "Epoch 687/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0018 - val_loss: 0.0018 - val_mae: 0.0018\n",
      "Epoch 688/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0016 - val_loss: 0.0018 - val_mae: 0.0024\n",
      "Epoch 689/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0017 - val_loss: 0.0018 - val_mae: 0.0026\n",
      "Epoch 690/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0020 - val_loss: 0.0017 - val_mae: 0.0019\n",
      "Epoch 691/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0023 - val_loss: 0.0018 - val_mae: 0.0038\n",
      "Epoch 692/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0020 - val_loss: 0.0017 - val_mae: 0.0011\n",
      "Epoch 693/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0024 - val_loss: 0.0017 - val_mae: 0.0032\n",
      "Epoch 694/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0026 - val_loss: 0.0017 - val_mae: 0.0020\n",
      "Epoch 695/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0017 - val_loss: 0.0017 - val_mae: 0.0012\n",
      "Epoch 696/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0015 - val_loss: 0.0017 - val_mae: 0.0019\n",
      "Epoch 697/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0016 - val_loss: 0.0017 - val_mae: 0.0011\n",
      "Epoch 698/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0016 - val_loss: 0.0017 - val_mae: 0.0019\n",
      "Epoch 699/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0020 - val_loss: 0.0017 - val_mae: 0.0030\n",
      "Epoch 700/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0024 - val_loss: 0.0018 - val_mae: 0.0066\n",
      "Epoch 701/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0028 - val_loss: 0.0017 - val_mae: 0.0021\n",
      "Epoch 702/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0015 - val_loss: 0.0017 - val_mae: 0.0016\n",
      "Epoch 703/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0017 - val_loss: 0.0017 - val_mae: 0.0048\n",
      "Epoch 704/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0018 - val_loss: 0.0017 - val_mae: 0.0034\n",
      "Epoch 705/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0021 - val_loss: 0.0017 - val_mae: 0.0039\n",
      "Epoch 706/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0025 - val_loss: 0.0017 - val_mae: 0.0036\n",
      "Epoch 707/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0020 - val_loss: 0.0017 - val_mae: 0.0017\n",
      "Epoch 708/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0017 - val_loss: 0.0017 - val_mae: 0.0023\n",
      "Epoch 709/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0019 - val_loss: 0.0016 - val_mae: 0.0015\n",
      "Epoch 710/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0017 - val_loss: 0.0016 - val_mae: 0.0015\n",
      "Epoch 711/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0033 - val_loss: 0.0017 - val_mae: 0.0070\n",
      "Epoch 712/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0028 - val_loss: 0.0016 - val_mae: 0.0013\n",
      "Epoch 713/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0016 - val_loss: 0.0016 - val_mae: 0.0013\n",
      "Epoch 714/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0015 - val_loss: 0.0016 - val_mae: 0.0024\n",
      "Epoch 715/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0015 - val_loss: 0.0016 - val_mae: 0.0039\n",
      "Epoch 716/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0016 - val_loss: 0.0016 - val_mae: 0.0015\n",
      "Epoch 717/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0018 - val_loss: 0.0016 - val_mae: 0.0013\n",
      "Epoch 718/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0022 - val_loss: 0.0016 - val_mae: 0.0046\n",
      "Epoch 719/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0020 - val_loss: 0.0017 - val_mae: 0.0092\n",
      "Epoch 720/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0023 - val_loss: 0.0016 - val_mae: 0.0012\n",
      "Epoch 721/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0015 - val_loss: 0.0016 - val_mae: 0.0018\n",
      "Epoch 722/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0017 - val_loss: 0.0016 - val_mae: 0.0024\n",
      "Epoch 723/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0024 - val_loss: 0.0017 - val_mae: 0.0071\n",
      "Epoch 724/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0024 - val_loss: 0.0016 - val_mae: 0.0012\n",
      "Epoch 725/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0018 - val_loss: 0.0016 - val_mae: 0.0033\n",
      "Epoch 726/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0015 - val_loss: 0.0016 - val_mae: 0.0016\n",
      "Epoch 727/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0015 - val_loss: 0.0016 - val_mae: 0.0021\n",
      "Epoch 728/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0023 - val_loss: 0.0016 - val_mae: 0.0047\n",
      "Epoch 729/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0033 - val_loss: 0.0016 - val_mae: 0.0029\n",
      "Epoch 730/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0015 - val_loss: 0.0016 - val_mae: 0.0011\n",
      "Epoch 731/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0017 - val_loss: 0.0016 - val_mae: 0.0022\n",
      "Epoch 732/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0020 - val_loss: 0.0015 - val_mae: 0.0018\n",
      "Epoch 733/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0019 - val_loss: 0.0015 - val_mae: 0.0013\n",
      "Epoch 734/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0013 - val_loss: 0.0015 - val_mae: 0.0018\n",
      "Epoch 735/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0022 - val_loss: 0.0015 - val_mae: 0.0011\n",
      "Epoch 736/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0014 - val_loss: 0.0016 - val_mae: 0.0081\n",
      "Epoch 737/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0027 - val_loss: 0.0015 - val_mae: 0.0040\n",
      "Epoch 738/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0015 - val_loss: 0.0015 - val_mae: 0.0012\n",
      "Epoch 739/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0016 - val_loss: 0.0015 - val_mae: 0.0013\n",
      "Epoch 740/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0016 - val_loss: 0.0015 - val_mae: 0.0015\n",
      "Epoch 741/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0018 - val_loss: 0.0015 - val_mae: 0.0012\n",
      "Epoch 742/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0019 - val_loss: 0.0015 - val_mae: 0.0023\n",
      "Epoch 743/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0019 - val_loss: 0.0015 - val_mae: 0.0030\n",
      "Epoch 744/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0017 - val_loss: 0.0015 - val_mae: 0.0034\n",
      "Epoch 745/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0019 - val_loss: 0.0015 - val_mae: 0.0026\n",
      "Epoch 746/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0018 - val_loss: 0.0015 - val_mae: 0.0013\n",
      "Epoch 747/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0017 - val_loss: 0.0015 - val_mae: 0.0039\n",
      "Epoch 748/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0020 - val_loss: 0.0015 - val_mae: 0.0026\n",
      "Epoch 749/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0019 - val_loss: 0.0015 - val_mae: 0.0063\n",
      "Epoch 750/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0029 - val_loss: 0.0015 - val_mae: 0.0024\n",
      "Epoch 751/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0016 - val_loss: 0.0015 - val_mae: 0.0058\n",
      "Epoch 752/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0025 - val_loss: 0.0015 - val_mae: 0.0085\n",
      "Epoch 753/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0025 - val_loss: 0.0015 - val_mae: 0.0014\n",
      "Epoch 754/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0018 - val_loss: 0.0015 - val_mae: 0.0021\n",
      "Epoch 755/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0016 - val_loss: 0.0015 - val_mae: 0.0029\n",
      "Epoch 756/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0015 - val_loss: 0.0015 - val_mae: 0.0052\n",
      "Epoch 757/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0017 - val_loss: 0.0014 - val_mae: 0.0024\n",
      "Epoch 758/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0022 - val_loss: 0.0014 - val_mae: 0.0014\n",
      "Epoch 759/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0015 - val_loss: 0.0014 - val_mae: 0.0031\n",
      "Epoch 760/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0019 - val_loss: 0.0015 - val_mae: 0.0054\n",
      "Epoch 761/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0019 - val_loss: 0.0014 - val_mae: 0.0018\n",
      "Epoch 762/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0018 - val_loss: 0.0014 - val_mae: 0.0013\n",
      "Epoch 763/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0017 - val_loss: 0.0014 - val_mae: 0.0040\n",
      "Epoch 764/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0016 - val_loss: 0.0014 - val_mae: 0.0048\n",
      "Epoch 765/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0031 - val_loss: 0.0014 - val_mae: 0.0013\n",
      "Epoch 766/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0019 - val_loss: 0.0014 - val_mae: 0.0023\n",
      "Epoch 767/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0016 - val_loss: 0.0014 - val_mae: 0.0038\n",
      "Epoch 768/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0017 - val_loss: 0.0014 - val_mae: 0.0039\n",
      "Epoch 769/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0022 - val_loss: 0.0014 - val_mae: 0.0020\n",
      "Epoch 770/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0020 - val_loss: 0.0014 - val_mae: 0.0019\n",
      "Epoch 771/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0014 - val_loss: 0.0014 - val_mae: 0.0036\n",
      "Epoch 772/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0029 - val_loss: 0.0014 - val_mae: 0.0051\n",
      "Epoch 773/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0016 - val_loss: 0.0014 - val_mae: 0.0018\n",
      "Epoch 774/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0014 - val_loss: 0.0014 - val_mae: 0.0017\n",
      "Epoch 775/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0019 - val_loss: 0.0014 - val_mae: 0.0024\n",
      "Epoch 776/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0016 - val_loss: 0.0014 - val_mae: 0.0014\n",
      "Epoch 777/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0019 - val_loss: 0.0014 - val_mae: 0.0020\n",
      "Epoch 778/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0016 - val_loss: 0.0014 - val_mae: 0.0023\n",
      "Epoch 779/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0019 - val_loss: 0.0014 - val_mae: 0.0028\n",
      "Epoch 780/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0022 - val_loss: 0.0014 - val_mae: 0.0074\n",
      "Epoch 781/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0024 - val_loss: 0.0013 - val_mae: 0.0015\n",
      "Epoch 782/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0019 - val_loss: 0.0013 - val_mae: 0.0017\n",
      "Epoch 783/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0014 - val_loss: 0.0013 - val_mae: 0.0014\n",
      "Epoch 784/2000\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 0.0013 - mae: 0.0015 - val_loss: 0.0013 - val_mae: 0.0017\n",
      "Epoch 785/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0017 - val_loss: 0.0013 - val_mae: 0.0022\n",
      "Epoch 786/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0018 - val_loss: 0.0013 - val_mae: 0.0015\n",
      "Epoch 787/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0015 - val_loss: 0.0013 - val_mae: 0.0012\n",
      "Epoch 788/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0020 - val_loss: 0.0013 - val_mae: 0.0024\n",
      "Epoch 789/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0020 - val_loss: 0.0013 - val_mae: 0.0027\n",
      "Epoch 790/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0017 - val_loss: 0.0013 - val_mae: 0.0014\n",
      "Epoch 791/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0016 - val_loss: 0.0013 - val_mae: 0.0016\n",
      "Epoch 792/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0019 - val_loss: 0.0013 - val_mae: 0.0017\n",
      "Epoch 793/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0019 - val_loss: 0.0014 - val_mae: 0.0061\n",
      "Epoch 794/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0025 - val_loss: 0.0013 - val_mae: 0.0021\n",
      "Epoch 795/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0020 - val_loss: 0.0013 - val_mae: 0.0028\n",
      "Epoch 796/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0016 - val_loss: 0.0013 - val_mae: 0.0021\n",
      "Epoch 797/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0017 - val_loss: 0.0013 - val_mae: 0.0040\n",
      "Epoch 798/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0015 - val_loss: 0.0013 - val_mae: 0.0063\n",
      "Epoch 799/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0019 - val_loss: 0.0013 - val_mae: 0.0017\n",
      "Epoch 800/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0017 - val_loss: 0.0013 - val_mae: 0.0018\n",
      "Epoch 801/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0017 - val_loss: 0.0013 - val_mae: 0.0037\n",
      "Epoch 802/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0016 - val_loss: 0.0013 - val_mae: 0.0028\n",
      "Epoch 803/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0019 - val_loss: 0.0013 - val_mae: 0.0020\n",
      "Epoch 804/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0020 - val_loss: 0.0013 - val_mae: 0.0021\n",
      "Epoch 805/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0016 - val_loss: 0.0012 - val_mae: 0.0011\n",
      "Epoch 806/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0024 - val_loss: 0.0013 - val_mae: 0.0030\n",
      "Epoch 807/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0018 - val_loss: 0.0012 - val_mae: 0.0025\n",
      "Epoch 808/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0020 - val_loss: 0.0012 - val_mae: 0.0012\n",
      "Epoch 809/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0014 - val_loss: 0.0012 - val_mae: 0.0013\n",
      "Epoch 810/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0014 - val_loss: 0.0012 - val_mae: 0.0034\n",
      "Epoch 811/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0024 - val_loss: 0.0013 - val_mae: 0.0049\n",
      "Epoch 812/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0020 - val_loss: 0.0012 - val_mae: 0.0024\n",
      "Epoch 813/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0019 - val_loss: 0.0012 - val_mae: 0.0019\n",
      "Epoch 814/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0018 - val_loss: 0.0012 - val_mae: 0.0021\n",
      "Epoch 815/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0018 - val_loss: 0.0012 - val_mae: 0.0020\n",
      "Epoch 816/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0018 - val_loss: 0.0012 - val_mae: 0.0038\n",
      "Epoch 817/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0019 - val_loss: 0.0012 - val_mae: 0.0023\n",
      "Epoch 818/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0025 - val_loss: 0.0012 - val_mae: 0.0016\n",
      "Epoch 819/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0017 - val_loss: 0.0012 - val_mae: 0.0021\n",
      "Epoch 820/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0015 - val_loss: 0.0012 - val_mae: 0.0013\n",
      "Epoch 821/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0019 - val_loss: 0.0012 - val_mae: 0.0020\n",
      "Epoch 822/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0016 - val_loss: 0.0012 - val_mae: 0.0018\n",
      "Epoch 823/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0017 - val_loss: 0.0012 - val_mae: 0.0021\n",
      "Epoch 824/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0017 - val_loss: 0.0012 - val_mae: 0.0022\n",
      "Epoch 825/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0025 - val_loss: 0.0012 - val_mae: 0.0027\n",
      "Epoch 826/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0019 - val_loss: 0.0012 - val_mae: 0.0014\n",
      "Epoch 827/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0019 - val_loss: 0.0012 - val_mae: 0.0022\n",
      "Epoch 828/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0021 - val_loss: 0.0012 - val_mae: 0.0018\n",
      "Epoch 829/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0016 - val_loss: 0.0012 - val_mae: 0.0016\n",
      "Epoch 830/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0016 - val_loss: 0.0012 - val_mae: 0.0013\n",
      "Epoch 831/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0024 - val_loss: 0.0012 - val_mae: 0.0018\n",
      "Epoch 832/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0018 - val_loss: 0.0013 - val_mae: 0.0086\n",
      "Epoch 833/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0020 - val_loss: 0.0012 - val_mae: 0.0018\n",
      "Epoch 834/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0016 - val_loss: 0.0012 - val_mae: 0.0026\n",
      "Epoch 835/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0018 - val_loss: 0.0012 - val_mae: 0.0068\n",
      "Epoch 836/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0019 - val_loss: 0.0011 - val_mae: 0.0014\n",
      "Epoch 837/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0016 - val_loss: 0.0011 - val_mae: 0.0020\n",
      "Epoch 838/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0015 - val_loss: 0.0012 - val_mae: 0.0047\n",
      "Epoch 839/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0019 - val_loss: 0.0012 - val_mae: 0.0037\n",
      "Epoch 840/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0016 - val_loss: 0.0011 - val_mae: 0.0020\n",
      "Epoch 841/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0015 - val_loss: 0.0011 - val_mae: 0.0019\n",
      "Epoch 842/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0021 - val_loss: 0.0012 - val_mae: 0.0060\n",
      "Epoch 843/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0017 - val_loss: 0.0011 - val_mae: 0.0027\n",
      "Epoch 844/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0016 - val_loss: 0.0011 - val_mae: 0.0036\n",
      "Epoch 845/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0020 - val_loss: 0.0011 - val_mae: 0.0045\n",
      "Epoch 846/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0028 - val_loss: 0.0011 - val_mae: 0.0013\n",
      "Epoch 847/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0013 - val_loss: 0.0011 - val_mae: 0.0013\n",
      "Epoch 848/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0015 - val_loss: 0.0011 - val_mae: 0.0016\n",
      "Epoch 849/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0018 - val_loss: 0.0011 - val_mae: 0.0015\n",
      "Epoch 850/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0019 - val_loss: 0.0011 - val_mae: 0.0027\n",
      "Epoch 851/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0017 - val_loss: 0.0011 - val_mae: 0.0027\n",
      "Epoch 852/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0019 - val_loss: 0.0011 - val_mae: 0.0021\n",
      "Epoch 853/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0020 - val_loss: 0.0011 - val_mae: 0.0050\n",
      "Epoch 854/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0018 - val_loss: 0.0011 - val_mae: 0.0021\n",
      "Epoch 855/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0013 - val_loss: 0.0011 - val_mae: 0.0016\n",
      "Epoch 856/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0013 - val_loss: 0.0011 - val_mae: 0.0018\n",
      "Epoch 857/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0015 - val_loss: 0.0011 - val_mae: 0.0018\n",
      "Epoch 858/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0015 - val_loss: 0.0011 - val_mae: 0.0070\n",
      "Epoch 859/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0019 - val_loss: 0.0011 - val_mae: 0.0018\n",
      "Epoch 860/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0019 - val_loss: 0.0011 - val_mae: 0.0059\n",
      "Epoch 861/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0020 - val_loss: 0.0011 - val_mae: 0.0016\n",
      "Epoch 862/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0014 - val_loss: 0.0011 - val_mae: 0.0029\n",
      "Epoch 863/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0019 - val_loss: 0.0011 - val_mae: 0.0013\n",
      "Epoch 864/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0016 - val_loss: 0.0012 - val_mae: 0.0091\n",
      "Epoch 865/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0025 - val_loss: 0.0011 - val_mae: 0.0019\n",
      "Epoch 866/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0015 - val_loss: 0.0011 - val_mae: 0.0017\n",
      "Epoch 867/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0014 - val_loss: 0.0011 - val_mae: 0.0023\n",
      "Epoch 868/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0014 - val_loss: 0.0010 - val_mae: 0.0012\n",
      "Epoch 869/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0017 - val_loss: 0.0010 - val_mae: 0.0023\n",
      "Epoch 870/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0016 - val_loss: 0.0010 - val_mae: 0.0019\n",
      "Epoch 871/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0021 - val_loss: 0.0010 - val_mae: 0.0014\n",
      "Epoch 872/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0018 - val_loss: 0.0010 - val_mae: 0.0027\n",
      "Epoch 873/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0018 - val_loss: 0.0010 - val_mae: 0.0021\n",
      "Epoch 874/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0019 - val_loss: 0.0011 - val_mae: 0.0052\n",
      "Epoch 875/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0020 - val_loss: 0.0010 - val_mae: 0.0014\n",
      "Epoch 876/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0018 - val_loss: 0.0010 - val_mae: 0.0022\n",
      "Epoch 877/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0019 - val_loss: 0.0010 - val_mae: 0.0028\n",
      "Epoch 878/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0018 - val_loss: 0.0010 - val_mae: 0.0014\n",
      "Epoch 879/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0015 - val_loss: 0.0010 - val_mae: 0.0014\n",
      "Epoch 880/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0015 - val_loss: 0.0010 - val_mae: 0.0029\n",
      "Epoch 881/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0016 - val_loss: 0.0010 - val_mae: 0.0036\n",
      "Epoch 882/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0023 - val_loss: 0.0010 - val_mae: 0.0056\n",
      "Epoch 883/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0022 - val_loss: 0.0010 - val_mae: 0.0016\n",
      "Epoch 884/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0016 - val_loss: 9.9926e-04 - val_mae: 0.0013\n",
      "Epoch 885/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 9.9888e-04 - mae: 0.0016 - val_loss: 0.0010 - val_mae: 0.0032\n",
      "Epoch 886/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.9654e-04 - mae: 0.0016 - val_loss: 0.0010 - val_mae: 0.0035\n",
      "Epoch 887/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 9.9485e-04 - mae: 0.0018 - val_loss: 9.9705e-04 - val_mae: 0.0027\n",
      "Epoch 888/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.9522e-04 - mae: 0.0022 - val_loss: 0.0011 - val_mae: 0.0065\n",
      "Epoch 889/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0042 - val_loss: 9.8641e-04 - val_mae: 0.0014\n",
      "Epoch 890/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.8426e-04 - mae: 0.0012 - val_loss: 9.8404e-04 - val_mae: 0.0013\n",
      "Epoch 891/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.8398e-04 - mae: 0.0016 - val_loss: 9.8513e-04 - val_mae: 0.0018\n",
      "Epoch 892/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.8007e-04 - mae: 0.0013 - val_loss: 9.8296e-04 - val_mae: 0.0021\n",
      "Epoch 893/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.7828e-04 - mae: 0.0014 - val_loss: 9.8312e-04 - val_mae: 0.0022\n",
      "Epoch 894/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.7603e-04 - mae: 0.0014 - val_loss: 9.8314e-04 - val_mae: 0.0027\n",
      "Epoch 895/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.7438e-04 - mae: 0.0015 - val_loss: 9.7233e-04 - val_mae: 0.0012\n",
      "Epoch 896/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 9.7114e-04 - mae: 0.0014 - val_loss: 9.6982e-04 - val_mae: 0.0012\n",
      "Epoch 897/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 9.6825e-04 - mae: 0.0013 - val_loss: 9.6930e-04 - val_mae: 0.0019\n",
      "Epoch 898/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.6602e-04 - mae: 0.0014 - val_loss: 9.7081e-04 - val_mae: 0.0024\n",
      "Epoch 899/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.6627e-04 - mae: 0.0019 - val_loss: 9.6265e-04 - val_mae: 0.0014\n",
      "Epoch 900/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.6089e-04 - mae: 0.0015 - val_loss: 9.6076e-04 - val_mae: 0.0017\n",
      "Epoch 901/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.5945e-04 - mae: 0.0017 - val_loss: 0.0011 - val_mae: 0.0070\n",
      "Epoch 902/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.6608e-04 - mae: 0.0027 - val_loss: 9.5681e-04 - val_mae: 0.0017\n",
      "Epoch 903/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.5292e-04 - mae: 0.0015 - val_loss: 9.5219e-04 - val_mae: 0.0015\n",
      "Epoch 904/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.5127e-04 - mae: 0.0016 - val_loss: 9.6767e-04 - val_mae: 0.0036\n",
      "Epoch 905/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.5036e-04 - mae: 0.0018 - val_loss: 0.0010 - val_mae: 0.0069\n",
      "Epoch 906/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.4914e-04 - mae: 0.0020 - val_loss: 9.5695e-04 - val_mae: 0.0029\n",
      "Epoch 907/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.4415e-04 - mae: 0.0017 - val_loss: 9.5641e-04 - val_mae: 0.0031\n",
      "Epoch 908/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.4101e-04 - mae: 0.0016 - val_loss: 9.3929e-04 - val_mae: 0.0015\n",
      "Epoch 909/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.3900e-04 - mae: 0.0017 - val_loss: 0.0011 - val_mae: 0.0101\n",
      "Epoch 910/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.5104e-04 - mae: 0.0029 - val_loss: 9.3331e-04 - val_mae: 0.0012\n",
      "Epoch 911/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.3240e-04 - mae: 0.0013 - val_loss: 9.3119e-04 - val_mae: 0.0012\n",
      "Epoch 912/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.2981e-04 - mae: 0.0013 - val_loss: 9.2860e-04 - val_mae: 0.0011\n",
      "Epoch 913/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 9.2840e-04 - mae: 0.0015 - val_loss: 9.2917e-04 - val_mae: 0.0019\n",
      "Epoch 914/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.3096e-04 - mae: 0.0022 - val_loss: 9.2506e-04 - val_mae: 0.0016\n",
      "Epoch 915/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.2318e-04 - mae: 0.0014 - val_loss: 9.2923e-04 - val_mae: 0.0026\n",
      "Epoch 916/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.2104e-04 - mae: 0.0015 - val_loss: 9.2761e-04 - val_mae: 0.0029\n",
      "Epoch 917/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 9.1789e-04 - mae: 0.0014 - val_loss: 9.2208e-04 - val_mae: 0.0021\n",
      "Epoch 918/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.1586e-04 - mae: 0.0015 - val_loss: 9.1721e-04 - val_mae: 0.0019\n",
      "Epoch 919/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.2494e-04 - mae: 0.0026 - val_loss: 9.1281e-04 - val_mae: 0.0015\n",
      "Epoch 920/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.1067e-04 - mae: 0.0014 - val_loss: 9.1029e-04 - val_mae: 0.0015\n",
      "Epoch 921/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.0838e-04 - mae: 0.0015 - val_loss: 9.1653e-04 - val_mae: 0.0033\n",
      "Epoch 922/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.0755e-04 - mae: 0.0017 - val_loss: 9.0858e-04 - val_mae: 0.0023\n",
      "Epoch 923/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.0340e-04 - mae: 0.0014 - val_loss: 9.0219e-04 - val_mae: 0.0013\n",
      "Epoch 924/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.0165e-04 - mae: 0.0015 - val_loss: 9.0384e-04 - val_mae: 0.0021\n",
      "Epoch 925/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.0069e-04 - mae: 0.0019 - val_loss: 9.1517e-04 - val_mae: 0.0039\n",
      "Epoch 926/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 8.9704e-04 - mae: 0.0016 - val_loss: 8.9399e-04 - val_mae: 0.0012\n",
      "Epoch 927/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 8.9511e-04 - mae: 0.0018 - val_loss: 9.1196e-04 - val_mae: 0.0045\n",
      "Epoch 928/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 8.9262e-04 - mae: 0.0017 - val_loss: 9.7547e-04 - val_mae: 0.0080\n",
      "Epoch 929/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 9.0065e-04 - mae: 0.0029 - val_loss: 9.5720e-04 - val_mae: 0.0065\n",
      "Epoch 930/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 8.9609e-04 - mae: 0.0024 - val_loss: 8.8630e-04 - val_mae: 0.0016\n",
      "Epoch 931/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 8.8451e-04 - mae: 0.0015 - val_loss: 8.8376e-04 - val_mae: 0.0014\n",
      "Epoch 932/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 8.8110e-04 - mae: 0.0013 - val_loss: 8.8118e-04 - val_mae: 0.0015\n",
      "Epoch 933/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 8.7999e-04 - mae: 0.0015 - val_loss: 9.0709e-04 - val_mae: 0.0041\n",
      "Epoch 934/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 8.8180e-04 - mae: 0.0021 - val_loss: 8.7622e-04 - val_mae: 0.0014\n",
      "Epoch 935/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 8.7555e-04 - mae: 0.0015 - val_loss: 8.9377e-04 - val_mae: 0.0036\n",
      "Epoch 936/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 8.7388e-04 - mae: 0.0016 - val_loss: 8.7787e-04 - val_mae: 0.0024\n",
      "Epoch 937/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 8.7066e-04 - mae: 0.0015 - val_loss: 8.7571e-04 - val_mae: 0.0025\n",
      "Epoch 938/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 8.6909e-04 - mae: 0.0016 - val_loss: 8.7138e-04 - val_mae: 0.0023\n",
      "Epoch 939/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 8.6550e-04 - mae: 0.0014 - val_loss: 8.6639e-04 - val_mae: 0.0018\n",
      "Epoch 940/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 8.6561e-04 - mae: 0.0018 - val_loss: 8.7306e-04 - val_mae: 0.0030\n",
      "Epoch 941/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 8.6856e-04 - mae: 0.0024 - val_loss: 8.7066e-04 - val_mae: 0.0035\n",
      "Epoch 942/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 8.5835e-04 - mae: 0.0014 - val_loss: 8.6090e-04 - val_mae: 0.0019\n",
      "Epoch 943/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 8.5658e-04 - mae: 0.0015 - val_loss: 8.5803e-04 - val_mae: 0.0021\n",
      "Epoch 944/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 8.5519e-04 - mae: 0.0017 - val_loss: 8.5445e-04 - val_mae: 0.0018\n",
      "Epoch 945/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 8.5575e-04 - mae: 0.0021 - val_loss: 8.6544e-04 - val_mae: 0.0030\n",
      "Epoch 946/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 8.5063e-04 - mae: 0.0017 - val_loss: 8.4919e-04 - val_mae: 0.0016\n",
      "Epoch 947/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 8.4651e-04 - mae: 0.0014 - val_loss: 8.4689e-04 - val_mae: 0.0017\n",
      "Epoch 948/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 8.4585e-04 - mae: 0.0017 - val_loss: 8.4261e-04 - val_mae: 0.0012\n",
      "Epoch 949/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 8.4523e-04 - mae: 0.0020 - val_loss: 8.4733e-04 - val_mae: 0.0026\n",
      "Epoch 950/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 8.4233e-04 - mae: 0.0019 - val_loss: 8.4645e-04 - val_mae: 0.0026\n",
      "Epoch 951/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 8.3687e-04 - mae: 0.0013 - val_loss: 8.5228e-04 - val_mae: 0.0039\n",
      "Epoch 952/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 8.3701e-04 - mae: 0.0018 - val_loss: 8.3373e-04 - val_mae: 0.0013\n",
      "Epoch 953/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 8.3328e-04 - mae: 0.0016 - val_loss: 8.3066e-04 - val_mae: 0.0012\n",
      "Epoch 954/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 8.3363e-04 - mae: 0.0020 - val_loss: 8.3621e-04 - val_mae: 0.0025\n",
      "Epoch 955/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 8.2924e-04 - mae: 0.0017 - val_loss: 8.2924e-04 - val_mae: 0.0019\n",
      "Epoch 956/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 8.2538e-04 - mae: 0.0014 - val_loss: 8.3435e-04 - val_mae: 0.0028\n",
      "Epoch 957/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 8.2538e-04 - mae: 0.0018 - val_loss: 8.2440e-04 - val_mae: 0.0019\n",
      "Epoch 958/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 8.2280e-04 - mae: 0.0018 - val_loss: 8.2503e-04 - val_mae: 0.0024\n",
      "Epoch 959/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 8.1907e-04 - mae: 0.0016 - val_loss: 8.1901e-04 - val_mae: 0.0018\n",
      "Epoch 960/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 8.1659e-04 - mae: 0.0016 - val_loss: 8.1804e-04 - val_mae: 0.0020\n",
      "Epoch 961/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 8.1437e-04 - mae: 0.0016 - val_loss: 8.1411e-04 - val_mae: 0.0017\n",
      "Epoch 962/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 8.1231e-04 - mae: 0.0017 - val_loss: 8.1306e-04 - val_mae: 0.0019\n",
      "Epoch 963/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 8.1000e-04 - mae: 0.0017 - val_loss: 8.1081e-04 - val_mae: 0.0021\n",
      "Epoch 964/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 8.1126e-04 - mae: 0.0021 - val_loss: 8.1000e-04 - val_mae: 0.0021\n",
      "Epoch 965/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 8.0481e-04 - mae: 0.0016 - val_loss: 8.7869e-04 - val_mae: 0.0066\n",
      "Epoch 966/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 8.0542e-04 - mae: 0.0018 - val_loss: 8.0222e-04 - val_mae: 0.0017\n",
      "Epoch 967/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 8.0062e-04 - mae: 0.0016 - val_loss: 7.9918e-04 - val_mae: 0.0016\n",
      "Epoch 968/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 7.9730e-04 - mae: 0.0014 - val_loss: 7.9871e-04 - val_mae: 0.0020\n",
      "Epoch 969/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 7.9645e-04 - mae: 0.0017 - val_loss: 8.1664e-04 - val_mae: 0.0043\n",
      "Epoch 970/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 7.9486e-04 - mae: 0.0018 - val_loss: 7.9423e-04 - val_mae: 0.0020\n",
      "Epoch 971/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 7.9225e-04 - mae: 0.0018 - val_loss: 8.0092e-04 - val_mae: 0.0031\n",
      "Epoch 972/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 7.9067e-04 - mae: 0.0019 - val_loss: 7.8716e-04 - val_mae: 0.0014\n",
      "Epoch 973/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 7.8671e-04 - mae: 0.0016 - val_loss: 7.8617e-04 - val_mae: 0.0016\n",
      "Epoch 974/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 7.9028e-04 - mae: 0.0023 - val_loss: 7.8750e-04 - val_mae: 0.0023\n",
      "Epoch 975/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 7.8200e-04 - mae: 0.0015 - val_loss: 7.8634e-04 - val_mae: 0.0027\n",
      "Epoch 976/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 7.8073e-04 - mae: 0.0016 - val_loss: 7.8212e-04 - val_mae: 0.0020\n",
      "Epoch 977/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 7.7723e-04 - mae: 0.0014 - val_loss: 7.9379e-04 - val_mae: 0.0033\n",
      "Epoch 978/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 7.7555e-04 - mae: 0.0015 - val_loss: 7.7386e-04 - val_mae: 0.0013\n",
      "Epoch 979/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 7.7241e-04 - mae: 0.0013 - val_loss: 8.0429e-04 - val_mae: 0.0044\n",
      "Epoch 980/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 7.7368e-04 - mae: 0.0019 - val_loss: 7.6874e-04 - val_mae: 0.0012\n",
      "Epoch 981/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 7.6839e-04 - mae: 0.0015 - val_loss: 8.2890e-04 - val_mae: 0.0065\n",
      "Epoch 982/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 7.7670e-04 - mae: 0.0029 - val_loss: 7.6826e-04 - val_mae: 0.0022\n",
      "Epoch 983/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 7.6845e-04 - mae: 0.0021 - val_loss: 7.6568e-04 - val_mae: 0.0019\n",
      "Epoch 984/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 7.6200e-04 - mae: 0.0014 - val_loss: 7.9132e-04 - val_mae: 0.0050\n",
      "Epoch 985/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 7.6370e-04 - mae: 0.0020 - val_loss: 7.6220e-04 - val_mae: 0.0019\n",
      "Epoch 986/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 7.5875e-04 - mae: 0.0015 - val_loss: 7.5693e-04 - val_mae: 0.0012\n",
      "Epoch 987/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 7.5717e-04 - mae: 0.0016 - val_loss: 7.6233e-04 - val_mae: 0.0024\n",
      "Epoch 988/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 7.5418e-04 - mae: 0.0014 - val_loss: 7.5369e-04 - val_mae: 0.0016\n",
      "Epoch 989/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 7.5261e-04 - mae: 0.0015 - val_loss: 7.9151e-04 - val_mae: 0.0050\n",
      "Epoch 990/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 7.5296e-04 - mae: 0.0019 - val_loss: 7.5415e-04 - val_mae: 0.0026\n",
      "Epoch 991/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 7.4934e-04 - mae: 0.0017 - val_loss: 7.5870e-04 - val_mae: 0.0030\n",
      "Epoch 992/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 7.4996e-04 - mae: 0.0021 - val_loss: 7.4553e-04 - val_mae: 0.0015\n",
      "Epoch 993/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 7.4394e-04 - mae: 0.0014 - val_loss: 7.4186e-04 - val_mae: 0.0011\n",
      "Epoch 994/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 7.4407e-04 - mae: 0.0017 - val_loss: 7.5984e-04 - val_mae: 0.0042\n",
      "Epoch 995/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 7.4135e-04 - mae: 0.0017 - val_loss: 7.6091e-04 - val_mae: 0.0043\n",
      "Epoch 996/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 7.4058e-04 - mae: 0.0019 - val_loss: 7.4827e-04 - val_mae: 0.0033\n",
      "Epoch 997/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 7.4240e-04 - mae: 0.0024 - val_loss: 7.3478e-04 - val_mae: 0.0013\n",
      "Epoch 998/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 7.3366e-04 - mae: 0.0014 - val_loss: 7.3564e-04 - val_mae: 0.0019\n",
      "Epoch 999/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 7.3280e-04 - mae: 0.0016 - val_loss: 7.8123e-04 - val_mae: 0.0055\n",
      "Epoch 1000/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 7.3530e-04 - mae: 0.0021 - val_loss: 7.3436e-04 - val_mae: 0.0023\n",
      "Epoch 1001/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 7.2918e-04 - mae: 0.0016 - val_loss: 7.2682e-04 - val_mae: 0.0012\n",
      "Epoch 1002/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 7.2792e-04 - mae: 0.0017 - val_loss: 7.2528e-04 - val_mae: 0.0014\n",
      "Epoch 1003/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 7.2371e-04 - mae: 0.0013 - val_loss: 7.2412e-04 - val_mae: 0.0016\n",
      "Epoch 1004/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 7.2189e-04 - mae: 0.0014 - val_loss: 7.2057e-04 - val_mae: 0.0012\n",
      "Epoch 1005/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 7.2054e-04 - mae: 0.0015 - val_loss: 7.2705e-04 - val_mae: 0.0027\n",
      "Epoch 1006/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 7.2014e-04 - mae: 0.0018 - val_loss: 7.1657e-04 - val_mae: 0.0012\n",
      "Epoch 1007/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 7.1654e-04 - mae: 0.0015 - val_loss: 7.1715e-04 - val_mae: 0.0018\n",
      "Epoch 1008/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 7.1472e-04 - mae: 0.0016 - val_loss: 7.1390e-04 - val_mae: 0.0015\n",
      "Epoch 1009/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 7.1195e-04 - mae: 0.0014 - val_loss: 7.1067e-04 - val_mae: 0.0013\n",
      "Epoch 1010/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 7.1106e-04 - mae: 0.0017 - val_loss: 7.0876e-04 - val_mae: 0.0013\n",
      "Epoch 1011/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 7.0797e-04 - mae: 0.0015 - val_loss: 7.1268e-04 - val_mae: 0.0026\n",
      "Epoch 1012/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 7.0621e-04 - mae: 0.0016 - val_loss: 7.0525e-04 - val_mae: 0.0015\n",
      "Epoch 1013/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 7.0422e-04 - mae: 0.0016 - val_loss: 7.0588e-04 - val_mae: 0.0021\n",
      "Epoch 1014/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 7.0563e-04 - mae: 0.0020 - val_loss: 7.0005e-04 - val_mae: 0.0014\n",
      "Epoch 1015/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 7.0016e-04 - mae: 0.0016 - val_loss: 7.4011e-04 - val_mae: 0.0051\n",
      "Epoch 1016/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 6.9853e-04 - mae: 0.0016 - val_loss: 6.9536e-04 - val_mae: 0.0011\n",
      "Epoch 1017/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 7.0086e-04 - mae: 0.0022 - val_loss: 7.3080e-04 - val_mae: 0.0044\n",
      "Epoch 1018/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 6.9777e-04 - mae: 0.0020 - val_loss: 6.9714e-04 - val_mae: 0.0025\n",
      "Epoch 1019/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 6.9134e-04 - mae: 0.0014 - val_loss: 6.9010e-04 - val_mae: 0.0012\n",
      "Epoch 1020/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 6.8939e-04 - mae: 0.0014 - val_loss: 6.9493e-04 - val_mae: 0.0028\n",
      "Epoch 1021/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 6.8837e-04 - mae: 0.0016 - val_loss: 7.5416e-04 - val_mae: 0.0062\n",
      "Epoch 1022/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 6.9156e-04 - mae: 0.0021 - val_loss: 7.0061e-04 - val_mae: 0.0031\n",
      "Epoch 1023/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 6.8671e-04 - mae: 0.0018 - val_loss: 6.8381e-04 - val_mae: 0.0016\n",
      "Epoch 1024/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 6.8308e-04 - mae: 0.0016 - val_loss: 7.0778e-04 - val_mae: 0.0039\n",
      "Epoch 1025/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 6.8552e-04 - mae: 0.0021 - val_loss: 6.7931e-04 - val_mae: 0.0013\n",
      "Epoch 1026/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 6.7848e-04 - mae: 0.0014 - val_loss: 6.8060e-04 - val_mae: 0.0021\n",
      "Epoch 1027/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 6.7955e-04 - mae: 0.0019 - val_loss: 6.7719e-04 - val_mae: 0.0017\n",
      "Epoch 1028/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 6.7442e-04 - mae: 0.0013 - val_loss: 6.7315e-04 - val_mae: 0.0011\n",
      "Epoch 1029/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 6.7535e-04 - mae: 0.0018 - val_loss: 6.7368e-04 - val_mae: 0.0017\n",
      "Epoch 1030/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 6.7136e-04 - mae: 0.0015 - val_loss: 6.7187e-04 - val_mae: 0.0016\n",
      "Epoch 1031/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 6.7141e-04 - mae: 0.0018 - val_loss: 6.6766e-04 - val_mae: 0.0011\n",
      "Epoch 1032/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 6.6962e-04 - mae: 0.0018 - val_loss: 6.7918e-04 - val_mae: 0.0033\n",
      "Epoch 1033/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 6.6714e-04 - mae: 0.0017 - val_loss: 6.6579e-04 - val_mae: 0.0016\n",
      "Epoch 1034/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 6.6506e-04 - mae: 0.0016 - val_loss: 6.9477e-04 - val_mae: 0.0054\n",
      "Epoch 1035/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 6.6497e-04 - mae: 0.0019 - val_loss: 6.6168e-04 - val_mae: 0.0015\n",
      "Epoch 1036/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 6.6068e-04 - mae: 0.0015 - val_loss: 6.6071e-04 - val_mae: 0.0018\n",
      "Epoch 1037/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 6.6012e-04 - mae: 0.0017 - val_loss: 6.6303e-04 - val_mae: 0.0020\n",
      "Epoch 1038/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 6.5921e-04 - mae: 0.0019 - val_loss: 6.5580e-04 - val_mae: 0.0014\n",
      "Epoch 1039/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 6.5595e-04 - mae: 0.0016 - val_loss: 6.6341e-04 - val_mae: 0.0030\n",
      "Epoch 1040/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 6.5404e-04 - mae: 0.0016 - val_loss: 6.6038e-04 - val_mae: 0.0029\n",
      "Epoch 1041/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 6.5169e-04 - mae: 0.0015 - val_loss: 6.5211e-04 - val_mae: 0.0018\n",
      "Epoch 1042/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 6.4999e-04 - mae: 0.0015 - val_loss: 6.4784e-04 - val_mae: 0.0011\n",
      "Epoch 1043/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 6.4871e-04 - mae: 0.0016 - val_loss: 6.4882e-04 - val_mae: 0.0019\n",
      "Epoch 1044/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 6.4616e-04 - mae: 0.0015 - val_loss: 6.6588e-04 - val_mae: 0.0038\n",
      "Epoch 1045/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 6.5339e-04 - mae: 0.0025 - val_loss: 6.4875e-04 - val_mae: 0.0024\n",
      "Epoch 1046/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 6.4345e-04 - mae: 0.0016 - val_loss: 6.4123e-04 - val_mae: 0.0013\n",
      "Epoch 1047/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 6.4087e-04 - mae: 0.0014 - val_loss: 6.4425e-04 - val_mae: 0.0022\n",
      "Epoch 1048/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 6.4036e-04 - mae: 0.0017 - val_loss: 6.5676e-04 - val_mae: 0.0036\n",
      "Epoch 1049/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 6.3986e-04 - mae: 0.0017 - val_loss: 6.3938e-04 - val_mae: 0.0019\n",
      "Epoch 1050/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 6.3755e-04 - mae: 0.0017 - val_loss: 6.4034e-04 - val_mae: 0.0024\n",
      "Epoch 1051/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 6.3447e-04 - mae: 0.0015 - val_loss: 6.3356e-04 - val_mae: 0.0014\n",
      "Epoch 1052/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 6.3248e-04 - mae: 0.0014 - val_loss: 6.3456e-04 - val_mae: 0.0020\n",
      "Epoch 1053/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 6.3096e-04 - mae: 0.0015 - val_loss: 6.2961e-04 - val_mae: 0.0013\n",
      "Epoch 1054/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 6.2841e-04 - mae: 0.0013 - val_loss: 6.3322e-04 - val_mae: 0.0025\n",
      "Epoch 1055/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 6.2850e-04 - mae: 0.0016 - val_loss: 6.2791e-04 - val_mae: 0.0018\n",
      "Epoch 1056/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 6.2565e-04 - mae: 0.0015 - val_loss: 6.2432e-04 - val_mae: 0.0013\n",
      "Epoch 1057/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 6.2814e-04 - mae: 0.0021 - val_loss: 6.2344e-04 - val_mae: 0.0016\n",
      "Epoch 1058/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 6.2274e-04 - mae: 0.0016 - val_loss: 6.2955e-04 - val_mae: 0.0027\n",
      "Epoch 1059/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 6.2193e-04 - mae: 0.0018 - val_loss: 6.2944e-04 - val_mae: 0.0027\n",
      "Epoch 1060/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 6.2069e-04 - mae: 0.0018 - val_loss: 6.1757e-04 - val_mae: 0.0014\n",
      "Epoch 1061/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 6.1652e-04 - mae: 0.0014 - val_loss: 6.1639e-04 - val_mae: 0.0014\n",
      "Epoch 1062/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 6.1676e-04 - mae: 0.0017 - val_loss: 6.1555e-04 - val_mae: 0.0018\n",
      "Epoch 1063/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 6.1501e-04 - mae: 0.0017 - val_loss: 6.1638e-04 - val_mae: 0.0020\n",
      "Epoch 1064/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 6.1437e-04 - mae: 0.0019 - val_loss: 6.1292e-04 - val_mae: 0.0019\n",
      "Epoch 1065/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 6.0981e-04 - mae: 0.0014 - val_loss: 6.1089e-04 - val_mae: 0.0019\n",
      "Epoch 1066/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 6.1211e-04 - mae: 0.0021 - val_loss: 6.2021e-04 - val_mae: 0.0029\n",
      "Epoch 1067/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 6.0642e-04 - mae: 0.0014 - val_loss: 6.0556e-04 - val_mae: 0.0012\n",
      "Epoch 1068/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 6.0952e-04 - mae: 0.0020 - val_loss: 6.0371e-04 - val_mae: 0.0012\n",
      "Epoch 1069/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 6.0419e-04 - mae: 0.0015 - val_loss: 6.0541e-04 - val_mae: 0.0020\n",
      "Epoch 1070/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 6.0159e-04 - mae: 0.0013 - val_loss: 6.0474e-04 - val_mae: 0.0022\n",
      "Epoch 1071/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 5.9993e-04 - mae: 0.0013 - val_loss: 6.2975e-04 - val_mae: 0.0041\n",
      "Epoch 1072/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 6.0001e-04 - mae: 0.0016 - val_loss: 5.9893e-04 - val_mae: 0.0016\n",
      "Epoch 1073/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 5.9733e-04 - mae: 0.0015 - val_loss: 6.0764e-04 - val_mae: 0.0030\n",
      "Epoch 1074/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 5.9625e-04 - mae: 0.0016 - val_loss: 5.9409e-04 - val_mae: 0.0013\n",
      "Epoch 1075/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 5.9531e-04 - mae: 0.0017 - val_loss: 5.9716e-04 - val_mae: 0.0024\n",
      "Epoch 1076/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 5.9178e-04 - mae: 0.0014 - val_loss: 5.9372e-04 - val_mae: 0.0019\n",
      "Epoch 1077/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 5.9123e-04 - mae: 0.0016 - val_loss: 5.9464e-04 - val_mae: 0.0023\n",
      "Epoch 1078/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 5.9323e-04 - mae: 0.0022 - val_loss: 5.8995e-04 - val_mae: 0.0020\n",
      "Epoch 1079/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 5.8726e-04 - mae: 0.0015 - val_loss: 5.9332e-04 - val_mae: 0.0027\n",
      "Epoch 1080/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 5.8597e-04 - mae: 0.0015 - val_loss: 5.8902e-04 - val_mae: 0.0023\n",
      "Epoch 1081/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 5.8761e-04 - mae: 0.0021 - val_loss: 5.9177e-04 - val_mae: 0.0027\n",
      "Epoch 1082/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 5.8324e-04 - mae: 0.0016 - val_loss: 6.3726e-04 - val_mae: 0.0060\n",
      "Epoch 1083/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 5.8314e-04 - mae: 0.0017 - val_loss: 5.8029e-04 - val_mae: 0.0015\n",
      "Epoch 1084/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 5.7982e-04 - mae: 0.0016 - val_loss: 5.7847e-04 - val_mae: 0.0014\n",
      "Epoch 1085/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 5.7721e-04 - mae: 0.0013 - val_loss: 5.8036e-04 - val_mae: 0.0020\n",
      "Epoch 1086/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 5.7871e-04 - mae: 0.0019 - val_loss: 5.7809e-04 - val_mae: 0.0021\n",
      "Epoch 1087/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 5.7398e-04 - mae: 0.0013 - val_loss: 5.7354e-04 - val_mae: 0.0013\n",
      "Epoch 1088/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 5.7249e-04 - mae: 0.0013 - val_loss: 5.7155e-04 - val_mae: 0.0012\n",
      "Epoch 1089/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 5.7254e-04 - mae: 0.0017 - val_loss: 5.7647e-04 - val_mae: 0.0025\n",
      "Epoch 1090/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 5.7361e-04 - mae: 0.0021 - val_loss: 5.6987e-04 - val_mae: 0.0015\n",
      "Epoch 1091/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 5.6985e-04 - mae: 0.0016 - val_loss: 5.6995e-04 - val_mae: 0.0018\n",
      "Epoch 1092/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 5.6713e-04 - mae: 0.0015 - val_loss: 5.7422e-04 - val_mae: 0.0024\n",
      "Epoch 1093/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 5.6546e-04 - mae: 0.0014 - val_loss: 5.6795e-04 - val_mae: 0.0020\n",
      "Epoch 1094/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 5.6397e-04 - mae: 0.0015 - val_loss: 5.6248e-04 - val_mae: 0.0012\n",
      "Epoch 1095/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 5.6368e-04 - mae: 0.0017 - val_loss: 5.6243e-04 - val_mae: 0.0016\n",
      "Epoch 1096/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 5.6101e-04 - mae: 0.0015 - val_loss: 5.6940e-04 - val_mae: 0.0032\n",
      "Epoch 1097/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 5.6136e-04 - mae: 0.0018 - val_loss: 5.6523e-04 - val_mae: 0.0025\n",
      "Epoch 1098/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 5.5826e-04 - mae: 0.0016 - val_loss: 5.5822e-04 - val_mae: 0.0018\n",
      "Epoch 1099/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 5.6403e-04 - mae: 0.0025 - val_loss: 5.6033e-04 - val_mae: 0.0023\n",
      "Epoch 1100/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 5.5425e-04 - mae: 0.0013 - val_loss: 5.5356e-04 - val_mae: 0.0012\n",
      "Epoch 1101/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 5.5408e-04 - mae: 0.0016 - val_loss: 5.9569e-04 - val_mae: 0.0051\n",
      "Epoch 1102/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 5.6050e-04 - mae: 0.0025 - val_loss: 5.5290e-04 - val_mae: 0.0017\n",
      "Epoch 1103/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 5.5041e-04 - mae: 0.0014 - val_loss: 5.4892e-04 - val_mae: 0.0011\n",
      "Epoch 1104/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 5.4983e-04 - mae: 0.0015 - val_loss: 5.5083e-04 - val_mae: 0.0020\n",
      "Epoch 1105/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 5.4777e-04 - mae: 0.0014 - val_loss: 5.4700e-04 - val_mae: 0.0013\n",
      "Epoch 1106/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 5.4629e-04 - mae: 0.0014 - val_loss: 5.4644e-04 - val_mae: 0.0014\n",
      "Epoch 1107/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 5.4554e-04 - mae: 0.0015 - val_loss: 5.5196e-04 - val_mae: 0.0026\n",
      "Epoch 1108/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 5.4309e-04 - mae: 0.0013 - val_loss: 5.6384e-04 - val_mae: 0.0042\n",
      "Epoch 1109/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 5.4568e-04 - mae: 0.0019 - val_loss: 5.4254e-04 - val_mae: 0.0017\n",
      "Epoch 1110/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 5.4007e-04 - mae: 0.0012 - val_loss: 5.4185e-04 - val_mae: 0.0018\n",
      "Epoch 1111/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 5.4014e-04 - mae: 0.0015 - val_loss: 5.4020e-04 - val_mae: 0.0016\n",
      "Epoch 1112/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 5.4276e-04 - mae: 0.0021 - val_loss: 5.3771e-04 - val_mae: 0.0015\n",
      "Epoch 1113/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 5.3630e-04 - mae: 0.0014 - val_loss: 5.3526e-04 - val_mae: 0.0012\n",
      "Epoch 1114/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 5.3554e-04 - mae: 0.0015 - val_loss: 5.4186e-04 - val_mae: 0.0025\n",
      "Epoch 1115/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 5.3562e-04 - mae: 0.0018 - val_loss: 5.3676e-04 - val_mae: 0.0022\n",
      "Epoch 1116/2000\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 5.3247e-04 - mae: 0.0015 - val_loss: 5.4054e-04 - val_mae: 0.0030\n",
      "Epoch 1117/2000\n",
      "109/109 [==============================] - 0s 3ms/step - loss: 5.3208e-04 - mae: 0.0016 - val_loss: 5.3680e-04 - val_mae: 0.0023\n",
      "Epoch 1118/2000\n",
      "105/109 [===========================>..] - ETA: 0s - loss: 5.2971e-04 - mae: 0.0014Restoring model weights from the end of the best epoch: 1113.\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 5.2981e-04 - mae: 0.0015 - val_loss: 5.9424e-04 - val_mae: 0.0065\n",
      "Epoch 1118: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Netzwerkarchitektur\n",
    "model = Sequential([\n",
    "\n",
    "    Dense(136, activation='relu', input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(216, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(104, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(328, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(8, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(120, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(1 , activation = 'linear')\n",
    "])\n",
    "\n",
    "# Optimierer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "# Modell kompilieren (Verwendung von mean_squared_error als Verlustfunktion für Regression)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])  # Metriken für Regression: Mean Absolute Error und Mean Squared Error\n",
    "\n",
    "# Early Stopping Callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "# Trainingsparameter\n",
    "batch_size = 150\n",
    "epochs = 2000\n",
    "\n",
    "# Modell trainieren (Annahme: X_train, y_train, X_val, y_val sind vordefiniert)\n",
    "history = model.fit(X_train_scaled, y_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])\n",
    "model.save('D2_1.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T09:49:10.079292900Z",
     "start_time": "2024-04-08T09:44:07.731823100Z"
    }
   },
   "id": "8b52e1a9a6ff3aeb"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    " # Initialisiere Listen, um Ergebnisse zu speichern\n",
    "val_loss_results = []\n",
    "val_mae_results = []\n",
    "\n",
    "# Funktion, um das Modell zu erstellen\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "                Dense(136, activation='relu', input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "                Dense(216, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "                Dense(104, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "                Dense(328, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "                Dense(8, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "                Dense(120, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "                Dense(1 , activation = 'linear')\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# K-Fold Cross-Validation Konfiguration\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Leistungsüberwachung\n",
    "fold_no = 1\n",
    "for train_index, val_index in kf.split(X_train_scaled):\n",
    "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_scaled[train_index], y_train_scaled[val_index]\n",
    "\n",
    "    model = create_model()\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "    print(f'Training für Fold {fold_no}...')\n",
    "    history = model.fit(X_train_fold, y_train_fold, batch_size=150, epochs=1000, validation_data=(X_val_fold, y_val_fold), callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "    # Speichere die Ergebnisse des aktuellen Folds\n",
    "    val_loss_results.append(min(history.history['val_loss']))\n",
    "    val_mae_results.append(min(history.history['val_mae']))\n",
    "\n",
    "    fold_no += 1\n",
    "\n",
    "# Berechne den Durchschnitt über alle Folds\n",
    "average_val_loss = np.mean(val_loss_results)\n",
    "average_val_mae = np.mean(val_mae_results)\n",
    "\n",
    "# Gib die durchschnittlichen Ergebnisse aus\n",
    "print(f'Durchschnittlicher Validation Loss: {average_val_loss}')\n",
    "print(f'Durchschnittlicher Validation MAE: {average_val_mae}')\n",
    "\n",
    "# Umwandeln der Listen in Pandas DataFrames\n",
    "val_loss_df = pd.DataFrame(val_loss_results, columns=['Validation Loss'])\n",
    "val_mae_df = pd.DataFrame(val_mae_results, columns=['Validation MAE'])\n",
    "\n",
    "# Speichern der DataFrames in CSV-Dateien\n",
    "val_loss_df.to_csv('val_loss_results_D2_1.csv', index=False)\n",
    "val_mae_df.to_csv('val_mae_results_D2_1.csv', index=False)\n",
    "\n",
    "# Gib die durchschnittlichen Ergebnisse aus\n",
    "print(f'Durchschnittlicher Validation Loss: {average_val_loss}')\n",
    "print(f'Durchschnittlicher Validation MAE: {average_val_mae}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T11:32:04.334836900Z",
     "start_time": "2024-03-18T11:32:04.330877800Z"
    }
   },
   "id": "d5ecf98837da6e96"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 - 0s - loss: 5.3508e-04 - mae: 0.0012 - 167ms/epoch - 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.000535078754182905, 0.0012097759172320366]"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Auswertung des Modells auf den Testdaten\n",
    "results = model.evaluate(X_test_scaled, y_test_scaled, verbose=2)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T09:49:22.758616100Z",
     "start_time": "2024-04-08T09:49:22.545296400Z"
    }
   },
   "id": "f27ef8e901869c23"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bsp. Predicted: [1287.6149] Actual: [1286.9] \n",
      "Durchschnittliche Abweichung (MAE): [1.14663258]\n"
     ]
    }
   ],
   "source": [
    "#Rückrechnung des skalierten MAE zum unskalierten MAE für eines bessere Einschätzung des Ergebnisses\n",
    "scaled_predicted_values = model.predict(X_test_scaled, verbose = 0)\n",
    "\n",
    "# Führen Sie die Rücktransformation der skalierten Werte durch\n",
    "original_predicted_values = scaler_target.inverse_transform(scaled_predicted_values)\n",
    "original_actual_values = scaler_target.inverse_transform(y_test_scaled)  # y_test sind die skalierten tatsächlichen Werte\n",
    "print(f' Bsp. Predicted: {original_predicted_values[100]} Actual: {original_actual_values[100]} ')\n",
    "\n",
    "def calculate_mae(list1, list2):\n",
    "    # Stelle sicher, dass beide Listen die gleiche Länge haben\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Listen müssen die gleiche Länge haben\")\n",
    "\n",
    "    # Berechne die absolute Differenz zwischen den Elementen der Listen\n",
    "    differences = [abs(x - y) for x, y in zip(list1, list2)]\n",
    "\n",
    "    # Berechne den Durchschnitt der absoluten Differenzen\n",
    "    mae = sum(differences) / len(differences)\n",
    "\n",
    "    return mae\n",
    "\n",
    "# Beispiel\n",
    "list1 = original_predicted_values\n",
    "list2 = original_actual_values\n",
    "\n",
    "mae = calculate_mae(list1, list2)\n",
    "print(f\"Durchschnittliche Abweichung (MAE): {mae}\")\n",
    "\n",
    "# Berechnung MAPE\n",
    "errors = np.abs((original_actual_values - original_predicted_values) / original_actual_values)\n",
    "mape = np.mean(errors) * 100\n",
    "print(mape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T09:49:26.859215900Z",
     "start_time": "2024-04-08T09:49:26.572630400Z"
    }
   },
   "id": "b1e271125bed3df7"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: [0.99966131]\n"
     ]
    }
   ],
   "source": [
    "# Berechnung der Auswertungsgröße R^2\n",
    "def calculate_r_squared(predicted, actual):\n",
    "    # Berechnung des Mittelwerts der tatsächlichen Werte\n",
    "    mean_actual = sum(actual) / len(actual)\n",
    "    \n",
    "    # Berechnung der totalen Summe der Quadrate (SST)\n",
    "    sst = sum((x - mean_actual) ** 2 for x in actual)\n",
    "    \n",
    "    # Berechnung der Summe der Quadrate der Residuen (SSE)\n",
    "    sse = sum((actual[i] - predicted[i]) ** 2 for i in range(len(actual)))\n",
    "    \n",
    "    # Berechnung des R^2-Wertes\n",
    "    r_squared = 1 - (sse / sst)\n",
    "    \n",
    "    return r_squared\n",
    "\n",
    "# Berechnung von R^2 mit den bereitgestellten Listen\n",
    "r_squared = calculate_r_squared(list1, list2)\n",
    "\n",
    "print(f\"R^2: {r_squared}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T11:32:30.188269500Z",
     "start_time": "2024-03-18T11:32:30.142936200Z"
    }
   },
   "id": "79a9ed0f6e7bf14e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plotten des Trainingsprozesses"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "460cff4a63ca2dd1"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mse = history.history['loss']\n",
    "val_mse = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(mae) + 1)\n",
    "\n",
    "# MAE Diagramm\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, mse, 'r', label='Training MSE')\n",
    "plt.plot(epochs, val_mse, 'b', label='Validation MSE')\n",
    "plt.title('Training and Validation MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.savefig('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Bilder Diplomarbeit/MSE_NeuroNetz/MSE_NeuroNetz_D2_2')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T11:32:04.961807300Z",
     "start_time": "2024-03-18T11:32:04.771797600Z"
    }
   },
   "id": "3688dd7102e95baf"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9f6f672a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T11:32:04.961807300Z",
     "start_time": "2024-03-18T11:32:04.958877400Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Werte die kleiner sind: 4933\n"
     ]
    },
    {
     "data": {
      "text/plain": "            Echt  Vorhergesagt  X-Koordinate  Y-Koordinate  Differenz\n2493  811.525146        836.38         0.992         0.900 -24.854854\n2316  732.671204        755.11         0.992         0.930 -22.438796\n2187  772.044312        793.93         0.976         0.915 -21.885688\n2696  798.328857        820.06         0.976         0.905 -21.731143\n914   811.471313        832.31         0.976         0.900 -20.838687\n...          ...           ...           ...           ...        ...\n4223  692.116394        670.60         0.960         0.000  21.516394\n1631  685.484131        663.16         0.888         0.000  22.324131\n1499  688.454651        665.99         0.920         0.000  22.464651\n2686  691.384094        668.83         0.952         0.000  22.554094\n3794  613.878479        591.24         0.840         0.975  22.638479\n\n[5066 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Echt</th>\n      <th>Vorhergesagt</th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Differenz</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2493</th>\n      <td>811.525146</td>\n      <td>836.38</td>\n      <td>0.992</td>\n      <td>0.900</td>\n      <td>-24.854854</td>\n    </tr>\n    <tr>\n      <th>2316</th>\n      <td>732.671204</td>\n      <td>755.11</td>\n      <td>0.992</td>\n      <td>0.930</td>\n      <td>-22.438796</td>\n    </tr>\n    <tr>\n      <th>2187</th>\n      <td>772.044312</td>\n      <td>793.93</td>\n      <td>0.976</td>\n      <td>0.915</td>\n      <td>-21.885688</td>\n    </tr>\n    <tr>\n      <th>2696</th>\n      <td>798.328857</td>\n      <td>820.06</td>\n      <td>0.976</td>\n      <td>0.905</td>\n      <td>-21.731143</td>\n    </tr>\n    <tr>\n      <th>914</th>\n      <td>811.471313</td>\n      <td>832.31</td>\n      <td>0.976</td>\n      <td>0.900</td>\n      <td>-20.838687</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4223</th>\n      <td>692.116394</td>\n      <td>670.60</td>\n      <td>0.960</td>\n      <td>0.000</td>\n      <td>21.516394</td>\n    </tr>\n    <tr>\n      <th>1631</th>\n      <td>685.484131</td>\n      <td>663.16</td>\n      <td>0.888</td>\n      <td>0.000</td>\n      <td>22.324131</td>\n    </tr>\n    <tr>\n      <th>1499</th>\n      <td>688.454651</td>\n      <td>665.99</td>\n      <td>0.920</td>\n      <td>0.000</td>\n      <td>22.464651</td>\n    </tr>\n    <tr>\n      <th>2686</th>\n      <td>691.384094</td>\n      <td>668.83</td>\n      <td>0.952</td>\n      <td>0.000</td>\n      <td>22.554094</td>\n    </tr>\n    <tr>\n      <th>3794</th>\n      <td>613.878479</td>\n      <td>591.24</td>\n      <td>0.840</td>\n      <td>0.975</td>\n      <td>22.638479</td>\n    </tr>\n  </tbody>\n</table>\n<p>5066 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Zeigt die größten Differenzen von vorhergesagten Wert und echten Wert an\n",
    "df_result = pd.DataFrame({'Echt': [val[0] for val in list2], 'Vorhergesagt': [val[0] for val in list1]})\n",
    "df_result['X-Koordinate'] = X_test_scaled[:, 0]\n",
    "df_result['Y-Koordinate'] = X_test_scaled[:, 1]\n",
    "\n",
    "df_result['Differenz'] = abs(df_result['Echt'] - df_result['Vorhergesagt'])\n",
    "df_result['Differenz'].sort_values()\n",
    "sorted_df = df_result.sort_values(by= 'Differenz')\n",
    "Anzahl_Punkte = (sorted_df['Differenz'] > -10).sum()\n",
    "print(\"Anzahl der Werte die kleiner sind:\", Anzahl_Punkte)\n",
    "\n",
    "sorted_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T11:32:04.981071Z",
     "start_time": "2024-03-18T11:32:04.961807300Z"
    }
   },
   "id": "6a9d8a95f5e95b9"
  },
  {
   "cell_type": "markdown",
   "id": "553df6fa",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1dca80c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T11:32:04.981071Z",
     "start_time": "2024-03-18T11:32:04.981071Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(learning_rate=0.001, activation='relu', regularization=0.0001, dropout_rate=0.0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(136, activation=activation, input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(216, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(104, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(328, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(8, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(120, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Verwenden Sie eine Funktion, um das Modell zu instanziieren, für scikit-learn Wrapper\n",
    "model = KerasRegressor(model=build_model, verbose=2)\n",
    "\n",
    "# Anpassung der Parameter im param_grid\n",
    "param_grid = {\n",
    "    'model__learning_rate': [0.01, 0.001, 0.0001],\n",
    "    'model__regularization': [0.001, 0.0001],\n",
    "    'fit__batch_size': [50, 100, 150, 200],\n",
    "    'fit__epochs': [50],\n",
    "    'model__dropout_rate' : [0.0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=2)\n",
    "# Hinweis: Stellen Sie sicher, dass Ihre Daten (X_train_scaled, y_train_scaled) korrekt definiert sind\n",
    "grid_result = grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "# Beste Parameter und Score ausgeben\n",
    "print(\"Beste Parameter:\", grid_search.best_params_)\n",
    "print(\"Beste Genauigkeit:\", grid_search.best_score_)\n",
    "\n",
    "with open(\"Gridsearch_D2_1.txt\", \"w\") as f:\n",
    "    f.write(f\"Beste Parameter: {grid_search.best_params_}\\n\")\n",
    "    f.write(f\"Beste Genauigkeit: {grid_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Search Architektur"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "315c4a978449b8a5"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "# Funktion zum Erstellen des Modells\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hp.Int('input_units', min_value=8, max_value=328, step=16), input_shape=(2,), activation='relu'))\n",
    "    for i in range(hp.Int('n_layers', 1, 10)):\n",
    "        model.add(Dense(hp.Int(f'units_{i}', min_value=8, max_value=328, step=16), activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Durchführung der Random Search dreimal\n",
    "for run in range(1, 4):\n",
    "    # Anpassen des Verzeichnisses und des Projektnamens für jeden Durchlauf\n",
    "    directory = 'random_search'\n",
    "    project_name = f'random_search_D2_{run}'\n",
    "\n",
    "    tuner = RandomSearch(\n",
    "        build_model,\n",
    "        objective='val_loss',\n",
    "        max_trials=100,\n",
    "        executions_per_trial=1,\n",
    "        directory=directory,\n",
    "        project_name=project_name\n",
    "    )\n",
    "\n",
    "    # Durchführung des Random Search\n",
    "    tuner.search(X_train_scaled, y_train_scaled, epochs=200, verbose =0, batch_size=50, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "\n",
    "    # Abrufen und Speichern des besten Modells\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "    model_path = os.path.join(directory, project_name, 'best_model.h5') \n",
    "    best_model.save(model_path)\n",
    "\n",
    "\n",
    "    # Optional: Abrufen und Ausgeben der besten Hyperparameter\n",
    "    best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "    # Konvertieren der Hyperparameter in ein DataFrame\n",
    "    df_hyperparameters = pd.DataFrame([best_hyperparameters.values])\n",
    "    # Speichern des DataFrame als CSV\n",
    "    df_hyperparameters.to_csv(f'random_search_D2_{run}.csv', index=False)\n",
    "\n",
    "    print(f\"Beste Hyperparameter für Lauf {run}: {best_hyperparameters.values}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T11:32:04.989541800Z",
     "start_time": "2024-03-18T11:32:04.981071Z"
    }
   },
   "id": "611306fcc5b8bde8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
