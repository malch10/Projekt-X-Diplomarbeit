{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94b0518e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T16:12:04.594399200Z",
     "start_time": "2024-04-02T16:11:58.172860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense , Dropout\n",
    "from scikeras.wrappers import KerasRegressor \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14809ab5e1b4d1d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T16:12:04.636961600Z",
     "start_time": "2024-04-02T16:12:04.595400400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft    Temperatur\n0             0.00000      -0.00200        100   6000   5000  4.498000e+02\n1             0.00000      -0.00196        100   6000   5000  4.652100e+02\n2             0.00000      -0.00192        100   6000   5000  4.797600e+02\n3             0.00000      -0.00188        100   6000   5000  4.935200e+02\n4             0.00000      -0.00184        100   6000   5000  5.066000e+02\n...               ...           ...        ...    ...    ...           ...\n2087059       0.00248       0.00184        500   9000   5000  1.110600e+03\n2087060       0.00248       0.00188        500   9000   5000  1.046600e+03\n2087061       0.00248       0.00192        500   9000   5000  9.810900e+02\n2087062       0.00248       0.00196        500   9000   5000  7.888600e-31\n2087063       0.00248       0.00200        500   9000   5000  9.403500e+02\n\n[1068984 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00000</td>\n      <td>-0.00200</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>4.498000e+02</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00000</td>\n      <td>-0.00196</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>4.652100e+02</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00000</td>\n      <td>-0.00192</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>4.797600e+02</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00000</td>\n      <td>-0.00188</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>4.935200e+02</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00000</td>\n      <td>-0.00184</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>5.066000e+02</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2087059</th>\n      <td>0.00248</td>\n      <td>0.00184</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1.110600e+03</td>\n    </tr>\n    <tr>\n      <th>2087060</th>\n      <td>0.00248</td>\n      <td>0.00188</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1.046600e+03</td>\n    </tr>\n    <tr>\n      <th>2087061</th>\n      <td>0.00248</td>\n      <td>0.00192</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>9.810900e+02</td>\n    </tr>\n    <tr>\n      <th>2087062</th>\n      <td>0.00248</td>\n      <td>0.00196</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>7.888600e-31</td>\n    </tr>\n    <tr>\n      <th>2087063</th>\n      <td>0.00248</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>9.403500e+02</td>\n    </tr>\n  </tbody>\n</table>\n<p>1068984 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_ALL_D3_t_21_I_F_PKL.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "966e3c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T16:12:04.744066500Z",
     "start_time": "2024-04-02T16:12:04.635962500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n",
      "782649        0.00000      -0.00200        100   7000   6000      478.13\n",
      "782650        0.00000      -0.00196        100   7000   6000      495.01\n",
      "782651        0.00000      -0.00192        100   7000   6000      511.16\n",
      "782652        0.00000      -0.00188        100   7000   6000      526.58\n",
      "782653        0.00000      -0.00184        100   7000   6000      541.43\n",
      "...               ...           ...        ...    ...    ...         ...\n",
      "1043527       0.00248       0.00184        500   7000   6000      784.55\n",
      "1043528       0.00248       0.00188        500   7000   6000      745.87\n",
      "1043529       0.00248       0.00192        500   7000   6000      706.17\n",
      "1043530       0.00248       0.00196        500   7000   6000      693.28\n",
      "1043531       0.00248       0.00200        500   7000   6000      687.80\n",
      "\n",
      "[133623 rows x 6 columns]\n",
      "Empty DataFrame\n",
      "Columns: [X-Koordinate, Y-Koordinate, Zeitpunkt, Strom, Kraft, Temperatur]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/plain": "         X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n1037169       0.00000      -0.00200        500   7000   6000      811.76\n1037170       0.00000      -0.00196        500   7000   6000      853.27\n1037171       0.00000      -0.00192        500   7000   6000      897.57\n1037172       0.00000      -0.00188        500   7000   6000      941.21\n1037173       0.00000      -0.00184        500   7000   6000      986.34\n...               ...           ...        ...    ...    ...         ...\n1043527       0.00248       0.00184        500   7000   6000      784.55\n1043528       0.00248       0.00188        500   7000   6000      745.87\n1043529       0.00248       0.00192        500   7000   6000      706.17\n1043530       0.00248       0.00196        500   7000   6000      693.28\n1043531       0.00248       0.00200        500   7000   6000      687.80\n\n[6363 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1037169</th>\n      <td>0.00000</td>\n      <td>-0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>811.76</td>\n    </tr>\n    <tr>\n      <th>1037170</th>\n      <td>0.00000</td>\n      <td>-0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>853.27</td>\n    </tr>\n    <tr>\n      <th>1037171</th>\n      <td>0.00000</td>\n      <td>-0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>897.57</td>\n    </tr>\n    <tr>\n      <th>1037172</th>\n      <td>0.00000</td>\n      <td>-0.00188</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>941.21</td>\n    </tr>\n    <tr>\n      <th>1037173</th>\n      <td>0.00000</td>\n      <td>-0.00184</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>986.34</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1043527</th>\n      <td>0.00248</td>\n      <td>0.00184</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>784.55</td>\n    </tr>\n    <tr>\n      <th>1043528</th>\n      <td>0.00248</td>\n      <td>0.00188</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>745.87</td>\n    </tr>\n    <tr>\n      <th>1043529</th>\n      <td>0.00248</td>\n      <td>0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>706.17</td>\n    </tr>\n    <tr>\n      <th>1043530</th>\n      <td>0.00248</td>\n      <td>0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>693.28</td>\n    </tr>\n    <tr>\n      <th>1043531</th>\n      <td>0.00248</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n      <td>687.80</td>\n    </tr>\n  </tbody>\n</table>\n<p>6363 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedingung = (data['Kraft'] == 6000) & (data['Strom'] == 7000)\n",
    "df_test = data[bedingung].copy()\n",
    "print(df_test)\n",
    "#df_test.to_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_I7000_F6000_D3_500_I_F_PKL.pkl')\n",
    "data_all = data.drop(df_test.index)\n",
    "#print(data_all)\n",
    "print(data_all[(data_all['Kraft'] == 6000) & (data_all['Strom'] == 7000)])\n",
    "df_test_500 = df_test[(df_test['Zeitpunkt'] == 500)]\n",
    "df_test_500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "         X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft    Temperatur\n0             0.00000      -0.00200        100   6000   5000  4.498000e+02\n1             0.00000      -0.00196        100   6000   5000  4.652100e+02\n2             0.00000      -0.00192        100   6000   5000  4.797600e+02\n3             0.00000      -0.00188        100   6000   5000  4.935200e+02\n4             0.00000      -0.00184        100   6000   5000  5.066000e+02\n...               ...           ...        ...    ...    ...           ...\n2087059       0.00248       0.00184        500   9000   5000  1.110600e+03\n2087060       0.00248       0.00188        500   9000   5000  1.046600e+03\n2087061       0.00248       0.00192        500   9000   5000  9.810900e+02\n2087062       0.00248       0.00196        500   9000   5000  7.888600e-31\n2087063       0.00248       0.00200        500   9000   5000  9.403500e+02\n\n[935361 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00000</td>\n      <td>-0.00200</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>4.498000e+02</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00000</td>\n      <td>-0.00196</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>4.652100e+02</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00000</td>\n      <td>-0.00192</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>4.797600e+02</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00000</td>\n      <td>-0.00188</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>4.935200e+02</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00000</td>\n      <td>-0.00184</td>\n      <td>100</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>5.066000e+02</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2087059</th>\n      <td>0.00248</td>\n      <td>0.00184</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1.110600e+03</td>\n    </tr>\n    <tr>\n      <th>2087060</th>\n      <td>0.00248</td>\n      <td>0.00188</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>1.046600e+03</td>\n    </tr>\n    <tr>\n      <th>2087061</th>\n      <td>0.00248</td>\n      <td>0.00192</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>9.810900e+02</td>\n    </tr>\n    <tr>\n      <th>2087062</th>\n      <td>0.00248</td>\n      <td>0.00196</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>7.888600e-31</td>\n    </tr>\n    <tr>\n      <th>2087063</th>\n      <td>0.00248</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>9000</td>\n      <td>5000</td>\n      <td>9.403500e+02</td>\n    </tr>\n  </tbody>\n</table>\n<p>935361 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T16:12:04.781584200Z",
     "start_time": "2024-04-02T16:12:04.737481700Z"
    }
   },
   "id": "5285bb0b0f14baf5"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8783d1d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T16:12:04.949098200Z",
     "start_time": "2024-04-02T16:12:04.746585Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n0            0.00092 -3.200000e-04        380   8000   7000     1966.20\n1            0.00228 -1.480000e-03        420   8000   6000     1413.60\n2            0.00200  5.200000e-04        340   7000   9000      863.16\n3            0.00036 -1.920000e-03        140   7000   9000      454.08\n4            0.00068  4.529900e-18        140   8000   7000      916.13\n...              ...           ...        ...    ...    ...         ...\n935356       0.00184 -1.520000e-03        480   6000   6000     1077.10\n935357       0.00124 -1.360000e-03        400   7000   5000     1510.90\n935358       0.00184 -9.600000e-04        500   6000   5000     1544.50\n935359       0.00120 -1.600000e-03        100   8000   7000      673.61\n935360       0.00040  4.000000e-05        480   6000   5000     1859.40\n\n[935361 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00092</td>\n      <td>-3.200000e-04</td>\n      <td>380</td>\n      <td>8000</td>\n      <td>7000</td>\n      <td>1966.20</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00228</td>\n      <td>-1.480000e-03</td>\n      <td>420</td>\n      <td>8000</td>\n      <td>6000</td>\n      <td>1413.60</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00200</td>\n      <td>5.200000e-04</td>\n      <td>340</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>863.16</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00036</td>\n      <td>-1.920000e-03</td>\n      <td>140</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>454.08</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00068</td>\n      <td>4.529900e-18</td>\n      <td>140</td>\n      <td>8000</td>\n      <td>7000</td>\n      <td>916.13</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>935356</th>\n      <td>0.00184</td>\n      <td>-1.520000e-03</td>\n      <td>480</td>\n      <td>6000</td>\n      <td>6000</td>\n      <td>1077.10</td>\n    </tr>\n    <tr>\n      <th>935357</th>\n      <td>0.00124</td>\n      <td>-1.360000e-03</td>\n      <td>400</td>\n      <td>7000</td>\n      <td>5000</td>\n      <td>1510.90</td>\n    </tr>\n    <tr>\n      <th>935358</th>\n      <td>0.00184</td>\n      <td>-9.600000e-04</td>\n      <td>500</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>1544.50</td>\n    </tr>\n    <tr>\n      <th>935359</th>\n      <td>0.00120</td>\n      <td>-1.600000e-03</td>\n      <td>100</td>\n      <td>8000</td>\n      <td>7000</td>\n      <td>673.61</td>\n    </tr>\n    <tr>\n      <th>935360</th>\n      <td>0.00040</td>\n      <td>4.000000e-05</td>\n      <td>480</td>\n      <td>6000</td>\n      <td>5000</td>\n      <td>1859.40</td>\n    </tr>\n  </tbody>\n</table>\n<p>935361 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all = data_all.sample(frac=1, random_state=42)  # Hier wird 42 als Random State verwendet, um die Ergebnisse reproduzierbar zu machen\n",
    "df_reset = data_all.reset_index(drop=True)\n",
    "df_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4e72a16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T16:12:04.951617Z",
     "start_time": "2024-04-02T16:12:04.918152500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [X-Koordinate, Y-Koordinate, Zeitpunkt, Strom, Kraft]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "y = df_reset[\"Temperatur\"]\n",
    "# Korrektur: Verwenden Sie den Spaltennamen direkt, ohne Indexierung der columns-Eigenschaft\n",
    "X = df_reset.drop(\"Temperatur\", axis=1)\n",
    "\n",
    "print(X[(X['Kraft'] == 6000) & (X['Strom'] == 7000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "label = df_test[\"Temperatur\"]\n",
    "# Korrektur: Verwenden Sie den Spaltennamen direkt, ohne Indexierung der columns-Eigenschaft\n",
    "X_2 = df_test.drop(\"Temperatur\", axis=1)\n",
    "\n",
    "X_2 = X_2.reset_index(drop=True)\n",
    "y_2 = label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T21:43:17.978773400Z",
     "start_time": "2024-04-02T21:43:17.923233400Z"
    }
   },
   "id": "2920a35d3f81234d"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7fa289a50d87423"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e694a236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T21:43:18.857438600Z",
     "start_time": "2024-04-02T21:43:18.812704700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft\n0            0.00000      -0.00200        100   7000   6000\n1            0.00000      -0.00196        100   7000   6000\n2            0.00000      -0.00192        100   7000   6000\n3            0.00000      -0.00188        100   7000   6000\n4            0.00000      -0.00184        100   7000   6000\n...              ...           ...        ...    ...    ...\n133618       0.00248       0.00184        500   7000   6000\n133619       0.00248       0.00188        500   7000   6000\n133620       0.00248       0.00192        500   7000   6000\n133621       0.00248       0.00196        500   7000   6000\n133622       0.00248       0.00200        500   7000   6000\n\n[133623 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00000</td>\n      <td>-0.00200</td>\n      <td>100</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00000</td>\n      <td>-0.00196</td>\n      <td>100</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00000</td>\n      <td>-0.00192</td>\n      <td>100</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00000</td>\n      <td>-0.00188</td>\n      <td>100</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00000</td>\n      <td>-0.00184</td>\n      <td>100</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>133618</th>\n      <td>0.00248</td>\n      <td>0.00184</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>133619</th>\n      <td>0.00248</td>\n      <td>0.00188</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>133620</th>\n      <td>0.00248</td>\n      <td>0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>133621</th>\n      <td>0.00248</td>\n      <td>0.00196</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>133622</th>\n      <td>0.00248</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>6000</td>\n    </tr>\n  </tbody>\n</table>\n<p>133623 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f3303b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T21:43:19.295071100Z",
     "start_time": "2024-04-02T21:43:19.256679800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "782649     478.13\n782650     495.01\n782651     511.16\n782652     526.58\n782653     541.43\n            ...  \n1043527    784.55\n1043528    745.87\n1043529    706.17\n1043530    693.28\n1043531    687.80\nName: Temperatur, Length: 133623, dtype: float64"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e3ad8da0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T21:43:19.707983500Z",
     "start_time": "2024-04-02T21:43:19.695424100Z"
    }
   },
   "outputs": [],
   "source": [
    " # train_df enthält 80% der Daten, test_df enthält 20% der Daten\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T21:43:20.588041100Z",
     "start_time": "2024-04-02T21:43:20.550523900Z"
    }
   },
   "id": "b78be1fe68aa0b4a"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9c705edb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T21:43:20.902734600Z",
     "start_time": "2024-04-02T21:43:20.821750300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialisiere einen MinMaxScaler für die Features\n",
    "scaler_features = MinMaxScaler()\n",
    "scaler_features2 = MinMaxScaler()\n",
    "# Skaliere X_train und X_test\n",
    "X_train_scaled = scaler_features.fit_transform(X)\n",
    "#X_test_scaled = scaler_features.transform(X_test)  # Nutze gleiche Skalierungsparameter ohne das X_Test Informationen einfließen\n",
    "X_test_scaled = scaler_features.transform(X_2)  # Nutze gleiche Skalierungsparameter ohne das X_Test Informationen einfließen\n",
    "\n",
    "# Initialisiere einen SEPARATEN MinMaxScaler für das Ziel, wenn nötig\n",
    "scaler_target = MinMaxScaler()\n",
    "\n",
    "\n",
    "# Skaliere y_train und y_test. Beachte, dass y_train.reshape(-1, 1) verwendet wird, da MinMaxScaler \n",
    "# erwartet, dass die Eingaben als 2D-Arrays kommen, und Ziele normalerweise als 1D-Arrays vorliegen.\n",
    "y_train_scaled = scaler_target.fit_transform(y.values.reshape(-1, 1))\n",
    "#y_test_scaled = scaler_target.transform(y_test.values.reshape(-1, 1))\n",
    "y_test_scaled = scaler_target.transform(y_2.values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbefe631e495b483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T21:42:14.202662900Z",
     "start_time": "2024-04-02T21:42:14.190025300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.        , 0.        , 1.        , 0.33333333, 0.25      ],\n       [0.        , 0.01      , 1.        , 0.33333333, 0.25      ],\n       [0.        , 0.02      , 1.        , 0.33333333, 0.25      ],\n       ...,\n       [1.        , 0.98      , 1.        , 0.33333333, 0.25      ],\n       [1.        , 0.99      , 1.        , 0.33333333, 0.25      ],\n       [1.        , 1.        , 1.        , 0.33333333, 0.25      ]])"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.37096774, 0.42      , 0.7       , 0.66666667, 0.5       ],\n       [0.91935484, 0.13      , 0.8       , 0.66666667, 0.25      ],\n       [0.80645161, 0.63      , 0.6       , 0.33333333, 1.        ],\n       ...,\n       [0.74193548, 0.26      , 1.        , 0.        , 0.        ],\n       [0.48387097, 0.1       , 0.        , 0.66666667, 0.5       ],\n       [0.16129032, 0.51      , 0.95      , 0.        , 0.        ]])"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T21:42:14.397755900Z",
     "start_time": "2024-04-02T21:42:14.383274Z"
    }
   },
   "id": "ce04ce43aac2242f"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "3742/3742 [==============================] - 26s 6ms/step - loss: 0.0233 - mae: 0.0187 - val_loss: 0.0172 - val_mae: 0.0078\n",
      "Epoch 2/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 0.0151 - mae: 0.0086 - val_loss: 0.0132 - val_mae: 0.0085\n",
      "Epoch 3/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 0.0118 - mae: 0.0073 - val_loss: 0.0106 - val_mae: 0.0104\n",
      "Epoch 4/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 0.0095 - mae: 0.0067 - val_loss: 0.0085 - val_mae: 0.0051\n",
      "Epoch 5/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 0.0077 - mae: 0.0060 - val_loss: 0.0069 - val_mae: 0.0052\n",
      "Epoch 6/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 0.0063 - mae: 0.0057 - val_loss: 0.0056 - val_mae: 0.0050\n",
      "Epoch 7/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 0.0052 - mae: 0.0055 - val_loss: 0.0047 - val_mae: 0.0050\n",
      "Epoch 8/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 0.0043 - mae: 0.0053 - val_loss: 0.0039 - val_mae: 0.0060\n",
      "Epoch 9/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 0.0036 - mae: 0.0052 - val_loss: 0.0033 - val_mae: 0.0044\n",
      "Epoch 10/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 0.0030 - mae: 0.0051 - val_loss: 0.0028 - val_mae: 0.0047\n",
      "Epoch 11/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 0.0026 - mae: 0.0050 - val_loss: 0.0024 - val_mae: 0.0080\n",
      "Epoch 12/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 0.0022 - mae: 0.0049 - val_loss: 0.0021 - val_mae: 0.0042\n",
      "Epoch 13/500\n",
      "3742/3742 [==============================] - 25s 7ms/step - loss: 0.0020 - mae: 0.0048 - val_loss: 0.0018 - val_mae: 0.0052\n",
      "Epoch 14/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 0.0017 - mae: 0.0048 - val_loss: 0.0016 - val_mae: 0.0039\n",
      "Epoch 15/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 0.0015 - mae: 0.0047 - val_loss: 0.0015 - val_mae: 0.0048\n",
      "Epoch 16/500\n",
      "3742/3742 [==============================] - 24s 7ms/step - loss: 0.0014 - mae: 0.0047 - val_loss: 0.0014 - val_mae: 0.0086\n",
      "Epoch 17/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 0.0013 - mae: 0.0047 - val_loss: 0.0012 - val_mae: 0.0059\n",
      "Epoch 18/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 0.0012 - mae: 0.0046 - val_loss: 0.0011 - val_mae: 0.0039\n",
      "Epoch 19/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 0.0011 - mae: 0.0046 - val_loss: 0.0010 - val_mae: 0.0041\n",
      "Epoch 20/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 9.7643e-04 - mae: 0.0046 - val_loss: 9.3929e-04 - val_mae: 0.0047\n",
      "Epoch 21/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 9.0598e-04 - mae: 0.0046 - val_loss: 8.6892e-04 - val_mae: 0.0041\n",
      "Epoch 22/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 8.4354e-04 - mae: 0.0045 - val_loss: 8.3928e-04 - val_mae: 0.0065\n",
      "Epoch 23/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 7.9003e-04 - mae: 0.0045 - val_loss: 8.3786e-04 - val_mae: 0.0088\n",
      "Epoch 24/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 7.4199e-04 - mae: 0.0044 - val_loss: 7.1035e-04 - val_mae: 0.0036\n",
      "Epoch 25/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 7.0089e-04 - mae: 0.0045 - val_loss: 6.7853e-04 - val_mae: 0.0042\n",
      "Epoch 26/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 6.6358e-04 - mae: 0.0044 - val_loss: 6.4521e-04 - val_mae: 0.0044\n",
      "Epoch 27/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 6.3113e-04 - mae: 0.0044 - val_loss: 6.0708e-04 - val_mae: 0.0037\n",
      "Epoch 28/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 6.0191e-04 - mae: 0.0044 - val_loss: 5.7857e-04 - val_mae: 0.0036\n",
      "Epoch 29/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 5.7503e-04 - mae: 0.0044 - val_loss: 5.7256e-04 - val_mae: 0.0054\n",
      "Epoch 30/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 5.5056e-04 - mae: 0.0043 - val_loss: 5.5376e-04 - val_mae: 0.0056\n",
      "Epoch 31/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 5.2884e-04 - mae: 0.0043 - val_loss: 5.1219e-04 - val_mae: 0.0039\n",
      "Epoch 32/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 5.0911e-04 - mae: 0.0043 - val_loss: 4.9063e-04 - val_mae: 0.0035\n",
      "Epoch 33/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 4.9136e-04 - mae: 0.0043 - val_loss: 4.7374e-04 - val_mae: 0.0035\n",
      "Epoch 34/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 4.7484e-04 - mae: 0.0043 - val_loss: 4.6261e-04 - val_mae: 0.0038\n",
      "Epoch 35/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 4.5964e-04 - mae: 0.0042 - val_loss: 4.4771e-04 - val_mae: 0.0038\n",
      "Epoch 36/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 4.4607e-04 - mae: 0.0042 - val_loss: 4.3156e-04 - val_mae: 0.0035\n",
      "Epoch 37/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 4.3345e-04 - mae: 0.0042 - val_loss: 4.2151e-04 - val_mae: 0.0037\n",
      "Epoch 38/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 4.2168e-04 - mae: 0.0042 - val_loss: 4.2205e-04 - val_mae: 0.0047\n",
      "Epoch 39/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 4.1069e-04 - mae: 0.0042 - val_loss: 3.9869e-04 - val_mae: 0.0036\n",
      "Epoch 40/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 4.0087e-04 - mae: 0.0042 - val_loss: 3.8740e-04 - val_mae: 0.0034\n",
      "Epoch 41/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 3.9100e-04 - mae: 0.0042 - val_loss: 3.7840e-04 - val_mae: 0.0035\n",
      "Epoch 42/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 3.8325e-04 - mae: 0.0042 - val_loss: 3.6988e-04 - val_mae: 0.0034\n",
      "Epoch 43/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 3.7495e-04 - mae: 0.0042 - val_loss: 3.6529e-04 - val_mae: 0.0038\n",
      "Epoch 44/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 3.6712e-04 - mae: 0.0042 - val_loss: 3.6008e-04 - val_mae: 0.0039\n",
      "Epoch 45/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 3.5976e-04 - mae: 0.0041 - val_loss: 3.5088e-04 - val_mae: 0.0037\n",
      "Epoch 46/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 3.5305e-04 - mae: 0.0041 - val_loss: 3.4415e-04 - val_mae: 0.0036\n",
      "Epoch 47/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 3.4583e-04 - mae: 0.0041 - val_loss: 3.4375e-04 - val_mae: 0.0042\n",
      "Epoch 48/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 3.4042e-04 - mae: 0.0041 - val_loss: 3.2834e-04 - val_mae: 0.0032\n",
      "Epoch 49/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 3.3484e-04 - mae: 0.0041 - val_loss: 3.2621e-04 - val_mae: 0.0036\n",
      "Epoch 50/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 3.2946e-04 - mae: 0.0041 - val_loss: 3.2485e-04 - val_mae: 0.0038\n",
      "Epoch 51/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 3.2439e-04 - mae: 0.0040 - val_loss: 3.1489e-04 - val_mae: 0.0034\n",
      "Epoch 52/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 3.2046e-04 - mae: 0.0041 - val_loss: 3.1491e-04 - val_mae: 0.0039\n",
      "Epoch 53/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 3.1531e-04 - mae: 0.0040 - val_loss: 3.0758e-04 - val_mae: 0.0035\n",
      "Epoch 54/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 3.1164e-04 - mae: 0.0041 - val_loss: 3.1273e-04 - val_mae: 0.0045\n",
      "Epoch 55/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 3.0759e-04 - mae: 0.0040 - val_loss: 2.9843e-04 - val_mae: 0.0034\n",
      "Epoch 56/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 3.0323e-04 - mae: 0.0040 - val_loss: 3.0876e-04 - val_mae: 0.0044\n",
      "Epoch 57/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 3.0027e-04 - mae: 0.0040 - val_loss: 2.9917e-04 - val_mae: 0.0041\n",
      "Epoch 58/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 2.9656e-04 - mae: 0.0040 - val_loss: 2.9542e-04 - val_mae: 0.0040\n",
      "Epoch 59/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 2.9312e-04 - mae: 0.0039 - val_loss: 3.8284e-04 - val_mae: 0.0097\n",
      "Epoch 60/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 2.9023e-04 - mae: 0.0039 - val_loss: 2.8511e-04 - val_mae: 0.0036\n",
      "Epoch 61/500\n",
      "3742/3742 [==============================] - 24s 6ms/step - loss: 2.8758e-04 - mae: 0.0039 - val_loss: 3.1138e-04 - val_mae: 0.0061\n",
      "Epoch 62/500\n",
      "3742/3742 [==============================] - 21s 5ms/step - loss: 2.8505e-04 - mae: 0.0039 - val_loss: 2.7873e-04 - val_mae: 0.0035\n",
      "Epoch 63/500\n",
      "3742/3742 [==============================] - 20s 5ms/step - loss: 2.8186e-04 - mae: 0.0039 - val_loss: 2.8075e-04 - val_mae: 0.0040\n",
      "Epoch 64/500\n",
      "3742/3742 [==============================] - 20s 5ms/step - loss: 2.7990e-04 - mae: 0.0039 - val_loss: 2.7852e-04 - val_mae: 0.0041\n",
      "Epoch 65/500\n",
      "3742/3742 [==============================] - 18s 5ms/step - loss: 2.7734e-04 - mae: 0.0039 - val_loss: 2.7384e-04 - val_mae: 0.0037\n",
      "Epoch 66/500\n",
      "3742/3742 [==============================] - 18s 5ms/step - loss: 2.7493e-04 - mae: 0.0039 - val_loss: 2.8962e-04 - val_mae: 0.0055\n",
      "Epoch 67/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.7295e-04 - mae: 0.0039 - val_loss: 2.6826e-04 - val_mae: 0.0036\n",
      "Epoch 68/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.7101e-04 - mae: 0.0039 - val_loss: 2.6257e-04 - val_mae: 0.0032\n",
      "Epoch 69/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.6877e-04 - mae: 0.0039 - val_loss: 2.6509e-04 - val_mae: 0.0037\n",
      "Epoch 70/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.6695e-04 - mae: 0.0039 - val_loss: 2.7352e-04 - val_mae: 0.0047\n",
      "Epoch 71/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.6481e-04 - mae: 0.0039 - val_loss: 3.2947e-04 - val_mae: 0.0087\n",
      "Epoch 72/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.6312e-04 - mae: 0.0038 - val_loss: 2.6074e-04 - val_mae: 0.0039\n",
      "Epoch 73/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.6140e-04 - mae: 0.0038 - val_loss: 2.5513e-04 - val_mae: 0.0034\n",
      "Epoch 74/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.5939e-04 - mae: 0.0038 - val_loss: 2.5296e-04 - val_mae: 0.0033\n",
      "Epoch 75/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.5795e-04 - mae: 0.0038 - val_loss: 2.5313e-04 - val_mae: 0.0034\n",
      "Epoch 76/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.5669e-04 - mae: 0.0038 - val_loss: 2.6857e-04 - val_mae: 0.0052\n",
      "Epoch 77/500\n",
      "3742/3742 [==============================] - 18s 5ms/step - loss: 2.5485e-04 - mae: 0.0038 - val_loss: 2.7100e-04 - val_mae: 0.0054\n",
      "Epoch 78/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.5310e-04 - mae: 0.0038 - val_loss: 2.5009e-04 - val_mae: 0.0037\n",
      "Epoch 79/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.5200e-04 - mae: 0.0038 - val_loss: 3.2171e-04 - val_mae: 0.0085\n",
      "Epoch 80/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.5062e-04 - mae: 0.0038 - val_loss: 2.4325e-04 - val_mae: 0.0031\n",
      "Epoch 81/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.5001e-04 - mae: 0.0038 - val_loss: 2.5608e-04 - val_mae: 0.0046\n",
      "Epoch 82/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.4841e-04 - mae: 0.0038 - val_loss: 2.4222e-04 - val_mae: 0.0032\n",
      "Epoch 83/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.4727e-04 - mae: 0.0038 - val_loss: 2.3987e-04 - val_mae: 0.0031\n",
      "Epoch 84/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.4575e-04 - mae: 0.0037 - val_loss: 2.3981e-04 - val_mae: 0.0032\n",
      "Epoch 85/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.4473e-04 - mae: 0.0037 - val_loss: 2.5273e-04 - val_mae: 0.0047\n",
      "Epoch 86/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.4386e-04 - mae: 0.0038 - val_loss: 2.3822e-04 - val_mae: 0.0034\n",
      "Epoch 87/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.4294e-04 - mae: 0.0038 - val_loss: 2.3789e-04 - val_mae: 0.0033\n",
      "Epoch 88/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.4159e-04 - mae: 0.0037 - val_loss: 2.4552e-04 - val_mae: 0.0043\n",
      "Epoch 89/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.4042e-04 - mae: 0.0037 - val_loss: 2.4541e-04 - val_mae: 0.0043\n",
      "Epoch 90/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.3972e-04 - mae: 0.0037 - val_loss: 2.3512e-04 - val_mae: 0.0033\n",
      "Epoch 91/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.3885e-04 - mae: 0.0037 - val_loss: 2.3167e-04 - val_mae: 0.0030\n",
      "Epoch 92/500\n",
      "3742/3742 [==============================] - 18s 5ms/step - loss: 2.3781e-04 - mae: 0.0037 - val_loss: 2.4080e-04 - val_mae: 0.0041\n",
      "Epoch 93/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.3710e-04 - mae: 0.0037 - val_loss: 2.2927e-04 - val_mae: 0.0030\n",
      "Epoch 94/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.3615e-04 - mae: 0.0037 - val_loss: 2.3641e-04 - val_mae: 0.0040\n",
      "Epoch 95/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.3509e-04 - mae: 0.0037 - val_loss: 2.2957e-04 - val_mae: 0.0032\n",
      "Epoch 96/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.3430e-04 - mae: 0.0037 - val_loss: 2.3112e-04 - val_mae: 0.0036\n",
      "Epoch 97/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.3338e-04 - mae: 0.0037 - val_loss: 2.3373e-04 - val_mae: 0.0036\n",
      "Epoch 98/500\n",
      "3742/3742 [==============================] - 18s 5ms/step - loss: 2.3316e-04 - mae: 0.0037 - val_loss: 2.2794e-04 - val_mae: 0.0033\n",
      "Epoch 99/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.3184e-04 - mae: 0.0037 - val_loss: 2.2544e-04 - val_mae: 0.0031\n",
      "Epoch 100/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.3120e-04 - mae: 0.0037 - val_loss: 2.2908e-04 - val_mae: 0.0035\n",
      "Epoch 101/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.3051e-04 - mae: 0.0037 - val_loss: 2.2409e-04 - val_mae: 0.0031\n",
      "Epoch 102/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.2949e-04 - mae: 0.0036 - val_loss: 2.3489e-04 - val_mae: 0.0044\n",
      "Epoch 103/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.2949e-04 - mae: 0.0037 - val_loss: 3.5660e-04 - val_mae: 0.0114\n",
      "Epoch 104/500\n",
      "3742/3742 [==============================] - 18s 5ms/step - loss: 2.2863e-04 - mae: 0.0037 - val_loss: 2.4138e-04 - val_mae: 0.0050\n",
      "Epoch 105/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.2777e-04 - mae: 0.0037 - val_loss: 2.2209e-04 - val_mae: 0.0031\n",
      "Epoch 106/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.2750e-04 - mae: 0.0037 - val_loss: 2.3097e-04 - val_mae: 0.0041\n",
      "Epoch 107/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.2706e-04 - mae: 0.0037 - val_loss: 2.4642e-04 - val_mae: 0.0057\n",
      "Epoch 108/500\n",
      "3742/3742 [==============================] - 18s 5ms/step - loss: 2.2619e-04 - mae: 0.0036 - val_loss: 2.2533e-04 - val_mae: 0.0037\n",
      "Epoch 109/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.2578e-04 - mae: 0.0037 - val_loss: 2.1904e-04 - val_mae: 0.0030\n",
      "Epoch 110/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.2517e-04 - mae: 0.0037 - val_loss: 2.2387e-04 - val_mae: 0.0036\n",
      "Epoch 111/500\n",
      "3742/3742 [==============================] - 18s 5ms/step - loss: 2.2462e-04 - mae: 0.0037 - val_loss: 2.2007e-04 - val_mae: 0.0033\n",
      "Epoch 112/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.2363e-04 - mae: 0.0036 - val_loss: 2.2128e-04 - val_mae: 0.0035\n",
      "Epoch 113/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.2339e-04 - mae: 0.0037 - val_loss: 2.1762e-04 - val_mae: 0.0032\n",
      "Epoch 114/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.2297e-04 - mae: 0.0037 - val_loss: 2.3683e-04 - val_mae: 0.0050\n",
      "Epoch 115/500\n",
      "3742/3742 [==============================] - 18s 5ms/step - loss: 2.2229e-04 - mae: 0.0036 - val_loss: 2.2113e-04 - val_mae: 0.0037\n",
      "Epoch 116/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.2169e-04 - mae: 0.0036 - val_loss: 2.4297e-04 - val_mae: 0.0056\n",
      "Epoch 117/500\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.2153e-04 - mae: 0.0036 - val_loss: 2.2185e-04 - val_mae: 0.0039\n",
      "Epoch 118/500\n",
      "3731/3742 [============================>.] - ETA: 0s - loss: 2.2085e-04 - mae: 0.0036Restoring model weights from the end of the best epoch: 113.\n",
      "3742/3742 [==============================] - 17s 5ms/step - loss: 2.2086e-04 - mae: 0.0036 - val_loss: 2.2392e-04 - val_mae: 0.0039\n",
      "Epoch 118: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erikm\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Netzwerkarchitektur\n",
    "model = Sequential([\n",
    "\n",
    "    Dense(168, activation='relu', input_shape=(5,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "\n",
    "    Dense(56, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(184, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(88, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(152, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(40, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(296, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(136, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(264, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(296, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(40, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "    \n",
    "    Dense(1 , activation = 'linear')\n",
    "])\n",
    "\n",
    "# Optimierer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "# Modell kompilieren (Verwendung von mean_squared_error als Verlustfunktion für Regression)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])  # Metriken für Regression: Mean Absolute Error und Mean Squared Error\n",
    "\n",
    "# Early Stopping Callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "# Trainingsparameter\n",
    "batch_size = 200 \n",
    "epochs = 500\n",
    "\n",
    "# Modell trainieren (Annahme: X_train, y_train, X_val, y_val sind vordefiniert)\n",
    "history = model.fit(X_train_scaled, y_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "model.save('D3_t_21_I_F_2.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T18:17:54.820629200Z",
     "start_time": "2024-04-02T17:36:37.118744Z"
    }
   },
   "id": "8b52e1a9a6ff3aeb"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training für Fold 1...\n",
      "Epoch 1/1000\n",
      "3742/3742 [==============================] - 22s 5ms/step - loss: 0.0272 - mae: 0.0238 - val_loss: 0.0199 - val_mae: 0.0115\n",
      "Epoch 2/1000\n",
      "3742/3742 [==============================] - 20s 5ms/step - loss: 0.0173 - mae: 0.0088 - val_loss: 0.0150 - val_mae: 0.0083\n",
      "Epoch 3/1000\n",
      "3742/3742 [==============================] - 21s 5ms/step - loss: 0.0130 - mae: 0.0072 - val_loss: 0.0113 - val_mae: 0.0066\n",
      "Epoch 4/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 0.0099 - mae: 0.0064 - val_loss: 0.0086 - val_mae: 0.0062\n",
      "Epoch 5/1000\n",
      "3742/3742 [==============================] - 21s 5ms/step - loss: 0.0076 - mae: 0.0059 - val_loss: 0.0067 - val_mae: 0.0053\n",
      "Epoch 6/1000\n",
      "3742/3742 [==============================] - 21s 5ms/step - loss: 0.0059 - mae: 0.0055 - val_loss: 0.0052 - val_mae: 0.0052\n",
      "Epoch 7/1000\n",
      "3742/3742 [==============================] - 20s 5ms/step - loss: 0.0047 - mae: 0.0053 - val_loss: 0.0041 - val_mae: 0.0053\n",
      "Epoch 8/1000\n",
      "3742/3742 [==============================] - 20s 5ms/step - loss: 0.0037 - mae: 0.0051 - val_loss: 0.0034 - val_mae: 0.0052\n",
      "Epoch 9/1000\n",
      "3742/3742 [==============================] - 20s 5ms/step - loss: 0.0030 - mae: 0.0050 - val_loss: 0.0028 - val_mae: 0.0065\n",
      "Epoch 10/1000\n",
      "3742/3742 [==============================] - 20s 5ms/step - loss: 0.0025 - mae: 0.0048 - val_loss: 0.0024 - val_mae: 0.0075\n",
      "Epoch 11/1000\n",
      "3742/3742 [==============================] - 20s 5ms/step - loss: 0.0022 - mae: 0.0047 - val_loss: 0.0020 - val_mae: 0.0042\n",
      "Epoch 12/1000\n",
      "3742/3742 [==============================] - 20s 5ms/step - loss: 0.0018 - mae: 0.0046 - val_loss: 0.0017 - val_mae: 0.0036\n",
      "Epoch 13/1000\n",
      "3742/3742 [==============================] - 20s 5ms/step - loss: 0.0016 - mae: 0.0045 - val_loss: 0.0015 - val_mae: 0.0046\n",
      "Epoch 14/1000\n",
      "3742/3742 [==============================] - 21s 5ms/step - loss: 0.0014 - mae: 0.0045 - val_loss: 0.0013 - val_mae: 0.0038\n",
      "Epoch 15/1000\n",
      "3742/3742 [==============================] - 20s 5ms/step - loss: 0.0013 - mae: 0.0045 - val_loss: 0.0012 - val_mae: 0.0037\n",
      "Epoch 16/1000\n",
      "3742/3742 [==============================] - 20s 5ms/step - loss: 0.0012 - mae: 0.0044 - val_loss: 0.0011 - val_mae: 0.0042\n",
      "Epoch 17/1000\n",
      "3742/3742 [==============================] - 20s 5ms/step - loss: 0.0011 - mae: 0.0044 - val_loss: 0.0010 - val_mae: 0.0058\n",
      "Epoch 18/1000\n",
      "3742/3742 [==============================] - 20s 5ms/step - loss: 9.6728e-04 - mae: 0.0043 - val_loss: 9.5266e-04 - val_mae: 0.0060\n",
      "Epoch 19/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 8.9365e-04 - mae: 0.0043 - val_loss: 8.9431e-04 - val_mae: 0.0066\n",
      "Epoch 20/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 8.2971e-04 - mae: 0.0043 - val_loss: 7.9402e-04 - val_mae: 0.0037\n",
      "Epoch 21/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 7.7434e-04 - mae: 0.0043 - val_loss: 7.4539e-04 - val_mae: 0.0041\n",
      "Epoch 22/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 7.2605e-04 - mae: 0.0043 - val_loss: 7.1211e-04 - val_mae: 0.0049\n",
      "Epoch 23/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 6.8412e-04 - mae: 0.0043 - val_loss: 6.6882e-04 - val_mae: 0.0045\n",
      "Epoch 24/1000\n",
      "3742/3742 [==============================] - 20s 5ms/step - loss: 6.4606e-04 - mae: 0.0042 - val_loss: 6.3056e-04 - val_mae: 0.0045\n",
      "Epoch 25/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 6.1215e-04 - mae: 0.0042 - val_loss: 5.8909e-04 - val_mae: 0.0035\n",
      "Epoch 26/1000\n",
      "3742/3742 [==============================] - 20s 5ms/step - loss: 5.8160e-04 - mae: 0.0042 - val_loss: 5.6048e-04 - val_mae: 0.0036\n",
      "Epoch 27/1000\n",
      "3742/3742 [==============================] - 20s 5ms/step - loss: 5.5409e-04 - mae: 0.0042 - val_loss: 5.4138e-04 - val_mae: 0.0043\n",
      "Epoch 28/1000\n",
      "3742/3742 [==============================] - 20s 5ms/step - loss: 5.2883e-04 - mae: 0.0041 - val_loss: 5.1039e-04 - val_mae: 0.0035\n",
      "Epoch 29/1000\n",
      "3742/3742 [==============================] - 21s 5ms/step - loss: 5.0569e-04 - mae: 0.0041 - val_loss: 5.0435e-04 - val_mae: 0.0051\n",
      "Epoch 30/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 4.8535e-04 - mae: 0.0041 - val_loss: 4.6834e-04 - val_mae: 0.0034\n",
      "Epoch 31/1000\n",
      "3742/3742 [==============================] - 20s 5ms/step - loss: 4.6638e-04 - mae: 0.0041 - val_loss: 4.6168e-04 - val_mae: 0.0045\n",
      "Epoch 32/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 4.5012e-04 - mae: 0.0041 - val_loss: 4.3698e-04 - val_mae: 0.0036\n",
      "Epoch 33/1000\n",
      "3742/3742 [==============================] - 20s 5ms/step - loss: 4.3528e-04 - mae: 0.0041 - val_loss: 4.2253e-04 - val_mae: 0.0035\n",
      "Epoch 34/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 4.2079e-04 - mae: 0.0040 - val_loss: 4.2074e-04 - val_mae: 0.0046\n",
      "Epoch 35/1000\n",
      "3742/3742 [==============================] - 20s 5ms/step - loss: 4.0863e-04 - mae: 0.0040 - val_loss: 3.9650e-04 - val_mae: 0.0033\n",
      "Epoch 36/1000\n",
      "3742/3742 [==============================] - 20s 5ms/step - loss: 3.9715e-04 - mae: 0.0040 - val_loss: 4.0531e-04 - val_mae: 0.0052\n",
      "Epoch 37/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 3.8667e-04 - mae: 0.0040 - val_loss: 3.8576e-04 - val_mae: 0.0043\n",
      "Epoch 38/1000\n",
      "3742/3742 [==============================] - 20s 5ms/step - loss: 3.7698e-04 - mae: 0.0039 - val_loss: 3.7715e-04 - val_mae: 0.0041\n",
      "Epoch 39/1000\n",
      "3742/3742 [==============================] - 20s 5ms/step - loss: 3.6770e-04 - mae: 0.0039 - val_loss: 3.6116e-04 - val_mae: 0.0037\n",
      "Epoch 40/1000\n",
      "3742/3742 [==============================] - 20s 5ms/step - loss: 3.5949e-04 - mae: 0.0039 - val_loss: 3.5473e-04 - val_mae: 0.0038\n",
      "Epoch 41/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 3.5226e-04 - mae: 0.0039 - val_loss: 3.4228e-04 - val_mae: 0.0033\n",
      "Epoch 42/1000\n",
      "3742/3742 [==============================] - 20s 5ms/step - loss: 3.4504e-04 - mae: 0.0039 - val_loss: 3.3654e-04 - val_mae: 0.0034\n",
      "Epoch 43/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 3.3835e-04 - mae: 0.0038 - val_loss: 3.2907e-04 - val_mae: 0.0032\n",
      "Epoch 44/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 3.3306e-04 - mae: 0.0039 - val_loss: 3.2181e-04 - val_mae: 0.0030\n",
      "Epoch 45/1000\n",
      "3742/3742 [==============================] - 21s 5ms/step - loss: 3.2736e-04 - mae: 0.0039 - val_loss: 3.1821e-04 - val_mae: 0.0032\n",
      "Epoch 46/1000\n",
      "3742/3742 [==============================] - 20s 5ms/step - loss: 3.2223e-04 - mae: 0.0039 - val_loss: 3.1314e-04 - val_mae: 0.0032\n",
      "Epoch 47/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 3.1657e-04 - mae: 0.0038 - val_loss: 3.0878e-04 - val_mae: 0.0033\n",
      "Epoch 48/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 3.1253e-04 - mae: 0.0038 - val_loss: 3.0524e-04 - val_mae: 0.0033\n",
      "Epoch 49/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 3.0863e-04 - mae: 0.0039 - val_loss: 2.9942e-04 - val_mae: 0.0031\n",
      "Epoch 50/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 3.0423e-04 - mae: 0.0038 - val_loss: 3.0281e-04 - val_mae: 0.0037\n",
      "Epoch 51/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 3.0045e-04 - mae: 0.0038 - val_loss: 2.9356e-04 - val_mae: 0.0033\n",
      "Epoch 52/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.9700e-04 - mae: 0.0038 - val_loss: 2.9162e-04 - val_mae: 0.0035\n",
      "Epoch 53/1000\n",
      "3742/3742 [==============================] - 21s 5ms/step - loss: 2.9344e-04 - mae: 0.0038 - val_loss: 2.8692e-04 - val_mae: 0.0033\n",
      "Epoch 54/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.9099e-04 - mae: 0.0038 - val_loss: 2.8609e-04 - val_mae: 0.0036\n",
      "Epoch 55/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.8741e-04 - mae: 0.0038 - val_loss: 2.7908e-04 - val_mae: 0.0031\n",
      "Epoch 56/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.8471e-04 - mae: 0.0038 - val_loss: 2.9129e-04 - val_mae: 0.0047\n",
      "Epoch 57/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.8141e-04 - mae: 0.0037 - val_loss: 2.8121e-04 - val_mae: 0.0039\n",
      "Epoch 58/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.7964e-04 - mae: 0.0038 - val_loss: 2.9366e-04 - val_mae: 0.0050\n",
      "Epoch 59/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.7683e-04 - mae: 0.0038 - val_loss: 2.7516e-04 - val_mae: 0.0038\n",
      "Epoch 60/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.7444e-04 - mae: 0.0038 - val_loss: 2.6936e-04 - val_mae: 0.0034\n",
      "Epoch 61/1000\n",
      "3742/3742 [==============================] - 20s 5ms/step - loss: 2.7278e-04 - mae: 0.0038 - val_loss: 2.6453e-04 - val_mae: 0.0031\n",
      "Epoch 62/1000\n",
      "3742/3742 [==============================] - 20s 5ms/step - loss: 2.6946e-04 - mae: 0.0037 - val_loss: 2.7027e-04 - val_mae: 0.0039\n",
      "Epoch 63/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.6848e-04 - mae: 0.0038 - val_loss: 2.6255e-04 - val_mae: 0.0032\n",
      "Epoch 64/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.6601e-04 - mae: 0.0037 - val_loss: 3.2966e-04 - val_mae: 0.0086\n",
      "Epoch 65/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.6445e-04 - mae: 0.0038 - val_loss: 2.6067e-04 - val_mae: 0.0034\n",
      "Epoch 66/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.6270e-04 - mae: 0.0038 - val_loss: 2.6329e-04 - val_mae: 0.0040\n",
      "Epoch 67/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.6090e-04 - mae: 0.0038 - val_loss: 2.8486e-04 - val_mae: 0.0060\n",
      "Epoch 68/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.5860e-04 - mae: 0.0037 - val_loss: 2.5543e-04 - val_mae: 0.0035\n",
      "Epoch 69/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.5753e-04 - mae: 0.0037 - val_loss: 2.6190e-04 - val_mae: 0.0043\n",
      "Epoch 70/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.5638e-04 - mae: 0.0037 - val_loss: 2.5031e-04 - val_mae: 0.0031\n",
      "Epoch 71/1000\n",
      "3742/3742 [==============================] - 21s 5ms/step - loss: 2.5476e-04 - mae: 0.0037 - val_loss: 2.5080e-04 - val_mae: 0.0034\n",
      "Epoch 72/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.5338e-04 - mae: 0.0037 - val_loss: 2.7393e-04 - val_mae: 0.0057\n",
      "Epoch 73/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.5161e-04 - mae: 0.0037 - val_loss: 2.5551e-04 - val_mae: 0.0042\n",
      "Epoch 74/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.5088e-04 - mae: 0.0038 - val_loss: 2.4761e-04 - val_mae: 0.0033\n",
      "Epoch 75/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.4988e-04 - mae: 0.0038 - val_loss: 2.4321e-04 - val_mae: 0.0031\n",
      "Epoch 76/1000\n",
      "3742/3742 [==============================] - 22s 6ms/step - loss: 2.4749e-04 - mae: 0.0037 - val_loss: 2.4633e-04 - val_mae: 0.0036\n",
      "Epoch 77/1000\n",
      "3742/3742 [==============================] - 22s 6ms/step - loss: 2.4687e-04 - mae: 0.0037 - val_loss: 2.4467e-04 - val_mae: 0.0035\n",
      "Epoch 78/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.4535e-04 - mae: 0.0037 - val_loss: 2.3835e-04 - val_mae: 0.0030\n",
      "Epoch 79/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.4397e-04 - mae: 0.0037 - val_loss: 2.4544e-04 - val_mae: 0.0039\n",
      "Epoch 80/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.4324e-04 - mae: 0.0037 - val_loss: 2.7381e-04 - val_mae: 0.0065\n",
      "Epoch 81/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.4155e-04 - mae: 0.0037 - val_loss: 2.3615e-04 - val_mae: 0.0032\n",
      "Epoch 82/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.4066e-04 - mae: 0.0037 - val_loss: 2.3609e-04 - val_mae: 0.0033\n",
      "Epoch 83/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.3963e-04 - mae: 0.0037 - val_loss: 2.4099e-04 - val_mae: 0.0038\n",
      "Epoch 84/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.3880e-04 - mae: 0.0037 - val_loss: 2.7932e-04 - val_mae: 0.0066\n",
      "Epoch 85/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.3752e-04 - mae: 0.0037 - val_loss: 2.4357e-04 - val_mae: 0.0045\n",
      "Epoch 86/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.3652e-04 - mae: 0.0037 - val_loss: 2.3297e-04 - val_mae: 0.0033\n",
      "Epoch 87/1000\n",
      "3742/3742 [==============================] - 21s 5ms/step - loss: 2.3568e-04 - mae: 0.0036 - val_loss: 2.3668e-04 - val_mae: 0.0039\n",
      "Epoch 88/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.3508e-04 - mae: 0.0037 - val_loss: 2.3604e-04 - val_mae: 0.0038\n",
      "Epoch 89/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.3386e-04 - mae: 0.0036 - val_loss: 2.2693e-04 - val_mae: 0.0029\n",
      "Epoch 90/1000\n",
      "3742/3742 [==============================] - 19s 5ms/step - loss: 2.3357e-04 - mae: 0.0036 - val_loss: 2.2980e-04 - val_mae: 0.0033\n",
      "Epoch 91/1000\n",
      "3742/3742 [==============================] - 18s 5ms/step - loss: 2.3249e-04 - mae: 0.0036 - val_loss: 2.2955e-04 - val_mae: 0.0034\n",
      "Epoch 92/1000\n",
      "3742/3742 [==============================] - 20s 5ms/step - loss: 2.3178e-04 - mae: 0.0036 - val_loss: 2.2663e-04 - val_mae: 0.0031\n",
      "Epoch 93/1000\n",
      "3742/3742 [==============================] - 19s 5ms/step - loss: 2.3082e-04 - mae: 0.0036 - val_loss: 2.2608e-04 - val_mae: 0.0032\n",
      "Epoch 94/1000\n",
      "3742/3742 [==============================] - 21s 6ms/step - loss: 2.3036e-04 - mae: 0.0036 - val_loss: 2.3503e-04 - val_mae: 0.0039\n",
      "Epoch 95/1000\n",
      "3742/3742 [==============================] - 19s 5ms/step - loss: 2.2933e-04 - mae: 0.0036 - val_loss: 2.2512e-04 - val_mae: 0.0032\n",
      "Epoch 96/1000\n",
      "1566/3742 [===========>..................] - ETA: 9s - loss: 2.3139e-04 - mae: 0.0037"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 52\u001B[0m\n\u001B[0;32m     49\u001B[0m early_stopping \u001B[38;5;241m=\u001B[39m EarlyStopping(monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m, patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmin\u001B[39m\u001B[38;5;124m'\u001B[39m, restore_best_weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTraining für Fold \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfold_no\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m...\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 52\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_fold\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train_fold\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m200\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX_val_fold\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_val_fold\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mearly_stopping\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;66;03m# Speichere die Ergebnisse des aktuellen Folds\u001B[39;00m\n\u001B[0;32m     55\u001B[0m val_loss_results\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mmin\u001B[39m(history\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m]))\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:1807\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1799\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1800\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1801\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1804\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1805\u001B[0m ):\n\u001B[0;32m   1806\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1807\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1808\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1809\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    829\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    831\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 832\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    834\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    835\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:868\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    865\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    866\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    867\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 868\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    869\u001B[0m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_config\u001B[49m\n\u001B[0;32m    870\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    871\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    872\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    873\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    874\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[1;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[0;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[1;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[0;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[0;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[0;32m   1319\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1320\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1321\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1322\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1323\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1324\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1325\u001B[0m     args,\n\u001B[0;32m   1326\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1327\u001B[0m     executing_eagerly)\n\u001B[0;32m   1328\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[1;34m(self, args)\u001B[0m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[0;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[1;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[0;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[0;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[0;32m    261\u001B[0m     )\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001B[0m, in \u001B[0;36mContext.call_function\u001B[1;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[0;32m   1484\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[0;32m   1485\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1486\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1487\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1488\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1489\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1490\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1491\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1492\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1493\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1494\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m   1495\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1496\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1500\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[0;32m   1501\u001B[0m   )\n",
      "File \u001B[1;32m~\\Desktop\\Diplomarbeit Erik Marr\\Projekt X\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# # Initialisiere Listen, um Ergebnisse zu speichern\n",
    "# val_loss_results = []\n",
    "# val_mae_results = []\n",
    "# \n",
    "# # Funktion, um das Modell zu erstellen\n",
    "# def create_model():\n",
    "#     model = Sequential([\n",
    "#             Dense(168, activation='relu', input_shape=(5,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "#         \n",
    "#             Dense(56, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "#             \n",
    "#             Dense(184, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "#             \n",
    "#             Dense(88, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "#             \n",
    "#             Dense(152, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "#             \n",
    "#             Dense(40, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "#             \n",
    "#             Dense(296, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "#             \n",
    "#             Dense(136, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "#             \n",
    "#             Dense(264, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "#             \n",
    "#             Dense(296, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "#             \n",
    "#             Dense(40, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n",
    "#             \n",
    "#             Dense(1 , activation = 'linear')\n",
    "# \n",
    "#     ])\n",
    "#     optimizer = Adam(learning_rate=0.0001)\n",
    "#     model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "#     return model\n",
    "# \n",
    "# # K-Fold Cross-Validation Konfiguration\n",
    "# n_splits = 5\n",
    "# kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "# \n",
    "# # Leistungsüberwachung\n",
    "# fold_no = 1\n",
    "# for train_index, val_index in kf.split(X_train_scaled):\n",
    "#     X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "#     y_train_fold, y_val_fold = y_train_scaled[train_index], y_train_scaled[val_index]\n",
    "# \n",
    "#     model = create_model()\n",
    "# \n",
    "#     early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "# \n",
    "#     print(f'Training für Fold {fold_no}...')\n",
    "#     history = model.fit(X_train_fold, y_train_fold, batch_size=200, epochs=1000, validation_data=(X_val_fold, y_val_fold), callbacks=[early_stopping], verbose=1)\n",
    "# \n",
    "#     # Speichere die Ergebnisse des aktuellen Folds\n",
    "#     val_loss_results.append(min(history.history['val_loss']))\n",
    "#     val_mae_results.append(min(history.history['val_mae']))\n",
    "# \n",
    "#     fold_no += 1\n",
    "# \n",
    "# # Berechne den Durchschnitt über alle Folds\n",
    "# average_val_loss = np.mean(val_loss_results)\n",
    "# average_val_mae = np.mean(val_mae_results)\n",
    "# \n",
    "# #Umwandeln der Listen in Pandas DataFrames\n",
    "# val_loss_df = pd.DataFrame(val_loss_results, columns=['Validation Loss'])\n",
    "# val_mae_df = pd.DataFrame(val_mae_results, columns=['Validation MAE'])\n",
    "# \n",
    "# # Speichern der DataFrames in CSV-Dateien\n",
    "# val_loss_df.to_csv('val_loss_results_D3_t_21_I_F_2.csv', index=False)\n",
    "# val_mae_df.to_csv('val_mae_results_D3_t_21_I_F_2.csv', index=False)\n",
    "# \n",
    "# # Gib die durchschnittlichen Ergebnisse aus\n",
    "# print(f'Durchschnittlicher Validation Loss: {average_val_loss}')\n",
    "# print(f'Durchschnittlicher Validation MAE: {average_val_mae}')\n",
    "# \n",
    "# \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T17:29:01.234522600Z",
     "start_time": "2024-04-02T16:56:13.204232400Z"
    }
   },
   "id": "7ff728388210d66b"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4176/4176 - 4s - loss: 2.8168e-04 - mae: 0.0081 - 4s/epoch - 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.00028167665004730225, 0.008136036805808544]"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test_scaled, y_test_scaled, verbose=2)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T21:43:34.741227200Z",
     "start_time": "2024-04-02T21:43:30.294472700Z"
    }
   },
   "id": "9050ab66ab36f169"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bsp. Predicted: [448.20505] Actual: [444.2] \n",
      "Durchschnittliche Abweichung (MAE): [20.96821777]\n",
      "1.9209720506069525\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scaled_predicted_values = model.predict(X_test_scaled, verbose = 0)\n",
    "\n",
    "# Führen Sie die Rücktransformation der skalierten Werte durch\n",
    "original_predicted_values = scaler_target.inverse_transform(scaled_predicted_values)\n",
    "original_actual_values = scaler_target.inverse_transform(y_test_scaled)  # y_test sind die skalierten tatsächlichen Werte\n",
    "print(f' Bsp. Predicted: {original_predicted_values[100]} Actual: {original_actual_values[100]} ')\n",
    "\n",
    "def calculate_mae(list1, list2):\n",
    "    # Stelle sicher, dass beide Listen die gleiche Länge haben\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Listen müssen die gleiche Länge haben\")\n",
    "\n",
    "    # Berechne die absolute Differenz zwischen den Elementen der Listen\n",
    "    differences = [abs(x - y) for x, y in zip(list1, list2)]\n",
    "\n",
    "    # Berechne den Durchschnitt der absoluten Differenzen\n",
    "    mae = sum(differences) / len(differences)\n",
    "\n",
    "    return mae\n",
    "\n",
    "# Beispiel\n",
    "list1 = original_predicted_values\n",
    "list2 = original_actual_values\n",
    "\n",
    "mae = calculate_mae(list1, list2)\n",
    "print(f\"Durchschnittliche Abweichung (MAE): {mae}\")\n",
    "\n",
    "errors = np.abs((original_actual_values - original_predicted_values) / original_actual_values)\n",
    "mape = np.mean(errors) * 100\n",
    "print(mape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T21:40:26.182815700Z",
     "start_time": "2024-04-02T21:40:20.706440600Z"
    }
   },
   "id": "10cd79ca028075dd"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: [0.99945157]\n"
     ]
    }
   ],
   "source": [
    "def calculate_r_squared(predicted, actual):\n",
    "    # Berechnung des Mittelwerts der tatsächlichen Werte\n",
    "    mean_actual = sum(actual) / len(actual)\n",
    "    \n",
    "    # Berechnung der totalen Summe der Quadrate (SST)\n",
    "    sst = sum((x - mean_actual) ** 2 for x in actual)\n",
    "    \n",
    "    # Berechnung der Summe der Quadrate der Residuen (SSE)\n",
    "    sse = sum((actual[i] - predicted[i]) ** 2 for i in range(len(actual)))\n",
    "    \n",
    "    # Berechnung des R^2-Wertes\n",
    "    r_squared = 1 - (sse / sst)\n",
    "    \n",
    "    return r_squared\n",
    "\n",
    "# Berechnung von R^2 mit den bereitgestellten Listen\n",
    "r_squared = calculate_r_squared(list1, list2)\n",
    "\n",
    "print(f\"R^2: {r_squared}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T21:33:50.536528800Z",
     "start_time": "2024-04-02T21:33:50.481948800Z"
    }
   },
   "id": "d0505d16afcbef4a"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Werte die kleiner sind: 31\n"
     ]
    },
    {
     "data": {
      "text/plain": "         Echt   Temperatur  X-Koordinate  Y-Koordinate  Differenz\n6268   991.21  1029.766602      1.000000          0.06 -38.556602\n6167   992.96  1030.098022      0.983871          0.06 -37.138022\n6269  1028.90  1064.723877      1.000000          0.07 -35.823877\n6066   994.91  1030.432861      0.967742          0.06 -35.522861\n6168  1031.10  1066.558228      0.983871          0.07 -35.458228\n...       ...          ...           ...           ...        ...\n1005   836.92   812.107910      0.145161          0.96  24.812090\n904    837.19   812.355164      0.129032          0.96  24.834836\n6160   690.48   664.262695      0.967742          1.00  26.217305\n6261   689.09   661.521362      0.983871          1.00  27.568638\n6362   687.80   658.809814      1.000000          1.00  28.990186\n\n[6363 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Echt</th>\n      <th>Temperatur</th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Differenz</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6268</th>\n      <td>991.21</td>\n      <td>1029.766602</td>\n      <td>1.000000</td>\n      <td>0.06</td>\n      <td>-38.556602</td>\n    </tr>\n    <tr>\n      <th>6167</th>\n      <td>992.96</td>\n      <td>1030.098022</td>\n      <td>0.983871</td>\n      <td>0.06</td>\n      <td>-37.138022</td>\n    </tr>\n    <tr>\n      <th>6269</th>\n      <td>1028.90</td>\n      <td>1064.723877</td>\n      <td>1.000000</td>\n      <td>0.07</td>\n      <td>-35.823877</td>\n    </tr>\n    <tr>\n      <th>6066</th>\n      <td>994.91</td>\n      <td>1030.432861</td>\n      <td>0.967742</td>\n      <td>0.06</td>\n      <td>-35.522861</td>\n    </tr>\n    <tr>\n      <th>6168</th>\n      <td>1031.10</td>\n      <td>1066.558228</td>\n      <td>0.983871</td>\n      <td>0.07</td>\n      <td>-35.458228</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1005</th>\n      <td>836.92</td>\n      <td>812.107910</td>\n      <td>0.145161</td>\n      <td>0.96</td>\n      <td>24.812090</td>\n    </tr>\n    <tr>\n      <th>904</th>\n      <td>837.19</td>\n      <td>812.355164</td>\n      <td>0.129032</td>\n      <td>0.96</td>\n      <td>24.834836</td>\n    </tr>\n    <tr>\n      <th>6160</th>\n      <td>690.48</td>\n      <td>664.262695</td>\n      <td>0.967742</td>\n      <td>1.00</td>\n      <td>26.217305</td>\n    </tr>\n    <tr>\n      <th>6261</th>\n      <td>689.09</td>\n      <td>661.521362</td>\n      <td>0.983871</td>\n      <td>1.00</td>\n      <td>27.568638</td>\n    </tr>\n    <tr>\n      <th>6362</th>\n      <td>687.80</td>\n      <td>658.809814</td>\n      <td>1.000000</td>\n      <td>1.00</td>\n      <td>28.990186</td>\n    </tr>\n  </tbody>\n</table>\n<p>6363 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame({'Echt': [val[0] for val in list2], 'Temperatur': [val[0] for val in list1]})\n",
    "df_result['X-Koordinate'] = X_test_scaled[:, 0]\n",
    "df_result['Y-Koordinate'] = X_test_scaled[:, 1]\n",
    "\n",
    "df_result['Differenz'] = df_result['Echt'] - df_result['Temperatur']\n",
    "df_result['Differenz'].sort_values()\n",
    "sorted_df = df_result.sort_values(by= 'Differenz')\n",
    "Anzahl_Punkte = (sorted_df['Differenz'] > 20).sum()\n",
    "print(\"Anzahl der Werte die kleiner sind:\", Anzahl_Punkte)\n",
    "\n",
    "sorted_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T13:21:48.837963Z",
     "start_time": "2024-04-01T13:21:48.801951300Z"
    }
   },
   "id": "47d4a39665ed1159"
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "df_test['Vorhergesagt'] = list1\n",
    "#df_test.to_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_I7000_F6000_D3_500_I_F_PKL_Prediction.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T15:32:21.241594100Z",
     "start_time": "2024-03-29T15:32:21.192942700Z"
    }
   },
   "id": "73defb2e4e9a45da"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mae = history.history['loss']\n",
    "val_mae = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(mae) + 1)\n",
    "\n",
    "# MAE Diagramm\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, mae, 'r', label='Training MSE')\n",
    "plt.plot(epochs, val_mae, 'b', label='Validation MSE')\n",
    "plt.title('Training and Validation MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.savefig('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Bilder Diplomarbeit/MSE_NeuroNetz/MSE_NeuroNetz_D3_2')\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T14:43:33.453659500Z",
     "start_time": "2024-03-29T14:43:33.154886700Z"
    }
   },
   "id": "3688dd7102e95baf"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f6f672a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T10:01:02.439200700Z",
     "start_time": "2024-03-15T10:01:02.436683600Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "553df6fa",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# def build_model(learning_rate=0.001, activation='relu', regularization=0.0001, dropout_rate=0.0):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(200, activation=activation, input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(448, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(352, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(320, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(256, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(416, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(128, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(96, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))    \n",
    "# \n",
    "#     model.add(Dense(32, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mae'])\n",
    "#     return model\n",
    "# \n",
    "# # Verwenden Sie eine Funktion, um das Modell zu instanziieren, für scikit-learn Wrapper\n",
    "# model = KerasRegressor(model=build_model, verbose=2)\n",
    "# \n",
    "# # Anpassung der Parameter im param_grid\n",
    "# param_grid = {\n",
    "#     'model__learning_rate': [0.01, 0.001, 0.0001],\n",
    "#     'model__regularization': [0.001, 0.0001, 0.00001],\n",
    "#     'fit__batch_size': [25, 50, 75, 100],\n",
    "#     'fit__epochs': [50],\n",
    "#     'model__dropout_rate' : [0.0, 0.1, 0.2]\n",
    "# }\n",
    "# \n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=2)\n",
    "# # Hinweis: Stellen Sie sicher, dass Ihre Daten (X_train_scaled, y_train_scaled) korrekt definiert sind\n",
    "# grid_result = grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "# # Beste Parameter und Score ausgeben\n",
    "# print(\"Beste Parameter:\", grid_search.best_params_)\n",
    "# print(\"Beste Genauigkeit:\", grid_search.best_score_)\n",
    "# \n",
    "# with open(\"Gridsearch_D3.txt\", \"w\") as f:\n",
    "#     f.write(f\"Beste Parameter: {grid_search.best_params_}\\n\")\n",
    "#     f.write(f\"Beste Genauigkeit: {grid_search.best_score_}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:01:02.450167100Z",
     "start_time": "2024-03-15T10:01:02.439200700Z"
    }
   },
   "id": "578403f6e218787a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
