{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "94b0518e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T10:01:59.883781100Z",
     "start_time": "2024-03-15T10:01:59.803433200Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense , Dropout\n",
    "from scikeras.wrappers import KerasRegressor \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e4ff61b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T10:01:59.953742400Z",
     "start_time": "2024-03-15T10:01:59.813504400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      X-Koordinate  Y-Koordinate  Zeitpunkt  Strom  Kraft  Temperatur\n0           0.0000      -0.00200        500   7000   9000      669.05\n1           0.0000      -0.00192        500   7000   9000      724.42\n2           0.0000      -0.00184        500   7000   9000      779.83\n3           0.0000      -0.00176        500   7000   9000      835.21\n4           0.0000      -0.00168        500   7000   9000      890.44\n...            ...           ...        ...    ...    ...         ...\n1066        0.0024       0.00168        500   7000   9000      775.40\n1067        0.0024       0.00176        500   7000   9000      715.43\n1068        0.0024       0.00184        500   7000   9000      645.85\n1069        0.0024       0.00192        500   7000   9000      585.87\n1070        0.0024       0.00200        500   7000   9000      574.64\n\n[1071 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Zeitpunkt</th>\n      <th>Strom</th>\n      <th>Kraft</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>669.05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0000</td>\n      <td>-0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>724.42</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0000</td>\n      <td>-0.00184</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>779.83</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0000</td>\n      <td>-0.00176</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>835.21</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0000</td>\n      <td>-0.00168</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>890.44</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1066</th>\n      <td>0.0024</td>\n      <td>0.00168</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>775.40</td>\n    </tr>\n    <tr>\n      <th>1067</th>\n      <td>0.0024</td>\n      <td>0.00176</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>715.43</td>\n    </tr>\n    <tr>\n      <th>1068</th>\n      <td>0.0024</td>\n      <td>0.00184</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>645.85</td>\n    </tr>\n    <tr>\n      <th>1069</th>\n      <td>0.0024</td>\n      <td>0.00192</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>585.87</td>\n    </tr>\n    <tr>\n      <th>1070</th>\n      <td>0.0024</td>\n      <td>0.00200</td>\n      <td>500</td>\n      <td>7000</td>\n      <td>9000</td>\n      <td>574.64</td>\n    </tr>\n  </tbody>\n</table>\n<p>1071 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/TPath_300_finish_data.pkl')\n",
    "data = pd.read_pickle('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Daten/Finish/Finish_D4_I7000_F9000/TPath_500_finish_data_D4.pkl')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "966e3c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T10:01:59.983780800Z",
     "start_time": "2024-03-15T10:01:59.820518600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      X-Koordinate  Y-Koordinate  Temperatur\n0           0.0000      -0.00200      669.05\n1           0.0000      -0.00192      724.42\n2           0.0000      -0.00184      779.83\n3           0.0000      -0.00176      835.21\n4           0.0000      -0.00168      890.44\n...            ...           ...         ...\n1066        0.0024       0.00168      775.40\n1067        0.0024       0.00176      715.43\n1068        0.0024       0.00184      645.85\n1069        0.0024       0.00192      585.87\n1070        0.0024       0.00200      574.64\n\n[1071 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0000</td>\n      <td>-0.00200</td>\n      <td>669.05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0000</td>\n      <td>-0.00192</td>\n      <td>724.42</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0000</td>\n      <td>-0.00184</td>\n      <td>779.83</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0000</td>\n      <td>-0.00176</td>\n      <td>835.21</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0000</td>\n      <td>-0.00168</td>\n      <td>890.44</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1066</th>\n      <td>0.0024</td>\n      <td>0.00168</td>\n      <td>775.40</td>\n    </tr>\n    <tr>\n      <th>1067</th>\n      <td>0.0024</td>\n      <td>0.00176</td>\n      <td>715.43</td>\n    </tr>\n    <tr>\n      <th>1068</th>\n      <td>0.0024</td>\n      <td>0.00184</td>\n      <td>645.85</td>\n    </tr>\n    <tr>\n      <th>1069</th>\n      <td>0.0024</td>\n      <td>0.00192</td>\n      <td>585.87</td>\n    </tr>\n    <tr>\n      <th>1070</th>\n      <td>0.0024</td>\n      <td>0.00200</td>\n      <td>574.64</td>\n    </tr>\n  </tbody>\n</table>\n<p>1071 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.drop(data.columns[2:5], axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8783d1d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T10:01:59.983780800Z",
     "start_time": "2024-03-15T10:01:59.828609100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      X-Koordinate  Y-Koordinate  Temperatur\n",
      "184        0.00036       0.00048     1441.10\n",
      "572        0.00132      -0.00112     1225.70\n",
      "309        0.00072      -0.00176      832.88\n",
      "930        0.00216      -0.00104     1158.00\n",
      "711        0.00156       0.00184      642.96\n",
      "...            ...           ...         ...\n",
      "330        0.00072      -0.00008     1500.20\n",
      "466        0.00108      -0.00144     1045.00\n",
      "121        0.00024      -0.00048     1484.90\n",
      "1044       0.00240      -0.00008     1259.10\n",
      "860        0.00192       0.00152      861.75\n",
      "\n",
      "[1071 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": "      X-Koordinate  Y-Koordinate  Temperatur\n0          0.00036       0.00048     1441.10\n1          0.00132      -0.00112     1225.70\n2          0.00072      -0.00176      832.88\n3          0.00216      -0.00104     1158.00\n4          0.00156       0.00184      642.96\n...            ...           ...         ...\n1066       0.00072      -0.00008     1500.20\n1067       0.00108      -0.00144     1045.00\n1068       0.00024      -0.00048     1484.90\n1069       0.00240      -0.00008     1259.10\n1070       0.00192       0.00152      861.75\n\n[1071 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n      <th>Temperatur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00036</td>\n      <td>0.00048</td>\n      <td>1441.10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00132</td>\n      <td>-0.00112</td>\n      <td>1225.70</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00072</td>\n      <td>-0.00176</td>\n      <td>832.88</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00216</td>\n      <td>-0.00104</td>\n      <td>1158.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00156</td>\n      <td>0.00184</td>\n      <td>642.96</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1066</th>\n      <td>0.00072</td>\n      <td>-0.00008</td>\n      <td>1500.20</td>\n    </tr>\n    <tr>\n      <th>1067</th>\n      <td>0.00108</td>\n      <td>-0.00144</td>\n      <td>1045.00</td>\n    </tr>\n    <tr>\n      <th>1068</th>\n      <td>0.00024</td>\n      <td>-0.00048</td>\n      <td>1484.90</td>\n    </tr>\n    <tr>\n      <th>1069</th>\n      <td>0.00240</td>\n      <td>-0.00008</td>\n      <td>1259.10</td>\n    </tr>\n    <tr>\n      <th>1070</th>\n      <td>0.00192</td>\n      <td>0.00152</td>\n      <td>861.75</td>\n    </tr>\n  </tbody>\n</table>\n<p>1071 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.sample(frac=1, random_state=42)  # Hier wird 42 als Random State verwendet, um die Ergebnisse reproduzierbar zu machen\n",
    "\n",
    "print(df1)\n",
    "df_reset = df1.reset_index(drop=True)\n",
    "df_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a4e72a16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T10:01:59.983780800Z",
     "start_time": "2024-03-15T10:01:59.838712800Z"
    }
   },
   "outputs": [],
   "source": [
    "label = df_reset[\"Temperatur\"]\n",
    "# Korrektur: Verwenden Sie den Spaltennamen direkt, ohne Indexierung der columns-Eigenschaft\n",
    "df1 = df_reset.drop(\"Temperatur\", axis=1)\n",
    "X = df1\n",
    "y = label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7fa289a50d87423"
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e694a236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T10:01:59.983780800Z",
     "start_time": "2024-03-15T10:01:59.843829800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      X-Koordinate  Y-Koordinate\n0          0.00036       0.00048\n1          0.00132      -0.00112\n2          0.00072      -0.00176\n3          0.00216      -0.00104\n4          0.00156       0.00184\n...            ...           ...\n1066       0.00072      -0.00008\n1067       0.00108      -0.00144\n1068       0.00024      -0.00048\n1069       0.00240      -0.00008\n1070       0.00192       0.00152\n\n[1071 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X-Koordinate</th>\n      <th>Y-Koordinate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00036</td>\n      <td>0.00048</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00132</td>\n      <td>-0.00112</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00072</td>\n      <td>-0.00176</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00216</td>\n      <td>-0.00104</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00156</td>\n      <td>0.00184</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1066</th>\n      <td>0.00072</td>\n      <td>-0.00008</td>\n    </tr>\n    <tr>\n      <th>1067</th>\n      <td>0.00108</td>\n      <td>-0.00144</td>\n    </tr>\n    <tr>\n      <th>1068</th>\n      <td>0.00024</td>\n      <td>-0.00048</td>\n    </tr>\n    <tr>\n      <th>1069</th>\n      <td>0.00240</td>\n      <td>-0.00008</td>\n    </tr>\n    <tr>\n      <th>1070</th>\n      <td>0.00192</td>\n      <td>0.00152</td>\n    </tr>\n  </tbody>\n</table>\n<p>1071 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3f3303b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T10:01:59.983780800Z",
     "start_time": "2024-03-15T10:01:59.850321500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0       1441.10\n1       1225.70\n2        832.88\n3       1158.00\n4        642.96\n         ...   \n1066    1500.20\n1067    1045.00\n1068    1484.90\n1069    1259.10\n1070     861.75\nName: Temperatur, Length: 1071, dtype: float64"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e3ad8da0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T10:01:59.983780800Z",
     "start_time": "2024-03-15T10:01:59.855443700Z"
    }
   },
   "outputs": [],
   "source": [
    " # train_df enthält 80% der Daten, test_df enthält 20% der Daten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9c705edb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T10:01:59.983780800Z",
     "start_time": "2024-03-15T10:01:59.860035500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialisiere einen MinMaxScaler für die Features\n",
    "scaler_features = MinMaxScaler()\n",
    "scaler_features2 = MinMaxScaler()\n",
    "# Skaliere X_train und X_test\n",
    "X_train_scaled = scaler_features.fit_transform(X_train)\n",
    "X_test_scaled = scaler_features.transform(X_test)  # Nutze unterschiedliche Skalierungsparameter\n",
    "\n",
    "# Initialisiere einen SEPARATEN MinMaxScaler für das Ziel, wenn nötig\n",
    "scaler_target = MinMaxScaler()\n",
    "\n",
    "\n",
    "# Skaliere y_train und y_test. Beachte, dass y_train.reshape(-1, 1) verwendet wird, da MinMaxScaler \n",
    "# erwartet, dass die Eingaben als 2D-Arrays kommen, und Ziele normalerweise als 1D-Arrays vorliegen.\n",
    "y_train_scaled = scaler_target.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test_scaled = scaler_target.transform(y_test.values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bbefe631e495b483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T10:01:59.983780800Z",
     "start_time": "2024-03-15T10:01:59.867119800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.35, 0.88],\n       [0.75, 0.88],\n       [0.85, 0.02],\n       ...,\n       [0.2 , 0.86],\n       [1.  , 0.52],\n       [0.8 , 0.04]])"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_scaled.max()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:01:59.983780800Z",
     "start_time": "2024-03-15T10:01:59.870971800Z"
    }
   },
   "id": "ce04ce43aac2242f"
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "10/10 [==============================] - 2s 26ms/step - loss: 1.0211 - mae: 0.5810 - val_loss: 0.5033 - val_mae: 0.3183\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5119 - mae: 0.3404 - val_loss: 0.4583 - val_mae: 0.2824\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4715 - mae: 0.3153 - val_loss: 0.4265 - val_mae: 0.2615\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4498 - mae: 0.3064 - val_loss: 0.4492 - val_mae: 0.3275\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4357 - mae: 0.3123 - val_loss: 0.3918 - val_mae: 0.2680\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3928 - mae: 0.2744 - val_loss: 0.3566 - val_mae: 0.2290\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3622 - mae: 0.2502 - val_loss: 0.3324 - val_mae: 0.2085\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3338 - mae: 0.2267 - val_loss: 0.2991 - val_mae: 0.1757\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3007 - mae: 0.1915 - val_loss: 0.2771 - val_mae: 0.1343\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2838 - mae: 0.1688 - val_loss: 0.2739 - val_mae: 0.1418\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2539 - mae: 0.1184 - val_loss: 0.2388 - val_mae: 0.0808\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2355 - mae: 0.0751 - val_loss: 0.2316 - val_mae: 0.0749\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2284 - mae: 0.0653 - val_loss: 0.2523 - val_mae: 0.1523\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2311 - mae: 0.0849 - val_loss: 0.2579 - val_mae: 0.1629\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2334 - mae: 0.0993 - val_loss: 0.2259 - val_mae: 0.0951\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2185 - mae: 0.0669 - val_loss: 0.2148 - val_mae: 0.0570\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2110 - mae: 0.0452 - val_loss: 0.2120 - val_mae: 0.0597\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2076 - mae: 0.0400 - val_loss: 0.2084 - val_mae: 0.0527\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2074 - mae: 0.0524 - val_loss: 0.2327 - val_mae: 0.1363\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2138 - mae: 0.0852 - val_loss: 0.2201 - val_mae: 0.1122\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2075 - mae: 0.0726 - val_loss: 0.2036 - val_mae: 0.0659\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2014 - mae: 0.0528 - val_loss: 0.1975 - val_mae: 0.0402\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1966 - mae: 0.0359 - val_loss: 0.1964 - val_mae: 0.0436\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1944 - mae: 0.0303 - val_loss: 0.1930 - val_mae: 0.0254\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1920 - mae: 0.0198 - val_loss: 0.1914 - val_mae: 0.0255\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1903 - mae: 0.0154 - val_loss: 0.1897 - val_mae: 0.0176\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1888 - mae: 0.0130 - val_loss: 0.1880 - val_mae: 0.0124\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1873 - mae: 0.0098 - val_loss: 0.1866 - val_mae: 0.0106\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1860 - mae: 0.0094 - val_loss: 0.1855 - val_mae: 0.0143\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1849 - mae: 0.0106 - val_loss: 0.1844 - val_mae: 0.0165\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1837 - mae: 0.0111 - val_loss: 0.1831 - val_mae: 0.0125\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1825 - mae: 0.0094 - val_loss: 0.1818 - val_mae: 0.0086\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1814 - mae: 0.0073 - val_loss: 0.1807 - val_mae: 0.0069\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1803 - mae: 0.0081 - val_loss: 0.1798 - val_mae: 0.0101\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1793 - mae: 0.0073 - val_loss: 0.1787 - val_mae: 0.0092\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1783 - mae: 0.0080 - val_loss: 0.1777 - val_mae: 0.0085\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1774 - mae: 0.0094 - val_loss: 0.1768 - val_mae: 0.0104\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1764 - mae: 0.0081 - val_loss: 0.1758 - val_mae: 0.0077\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1754 - mae: 0.0075 - val_loss: 0.1752 - val_mae: 0.0161\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1746 - mae: 0.0111 - val_loss: 0.1740 - val_mae: 0.0090\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1738 - mae: 0.0127 - val_loss: 0.1734 - val_mae: 0.0167\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1728 - mae: 0.0121 - val_loss: 0.1722 - val_mae: 0.0085\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1718 - mae: 0.0079 - val_loss: 0.1715 - val_mae: 0.0146\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1710 - mae: 0.0110 - val_loss: 0.1707 - val_mae: 0.0165\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1702 - mae: 0.0103 - val_loss: 0.1696 - val_mae: 0.0081\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1694 - mae: 0.0126 - val_loss: 0.1700 - val_mae: 0.0286\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1690 - mae: 0.0191 - val_loss: 0.1704 - val_mae: 0.0353\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1689 - mae: 0.0275 - val_loss: 0.1677 - val_mae: 0.0212\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1682 - mae: 0.0283 - val_loss: 0.1669 - val_mae: 0.0182\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1664 - mae: 0.0167 - val_loss: 0.1657 - val_mae: 0.0134\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1654 - mae: 0.0142 - val_loss: 0.1649 - val_mae: 0.0122\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1645 - mae: 0.0104 - val_loss: 0.1659 - val_mae: 0.0357\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1642 - mae: 0.0186 - val_loss: 0.1647 - val_mae: 0.0309\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1638 - mae: 0.0236 - val_loss: 0.1635 - val_mae: 0.0269\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1634 - mae: 0.0264 - val_loss: 0.1681 - val_mae: 0.0659\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1669 - mae: 0.0564 - val_loss: 0.1627 - val_mae: 0.0371\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1621 - mae: 0.0286 - val_loss: 0.1609 - val_mae: 0.0232\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1606 - mae: 0.0210 - val_loss: 0.1597 - val_mae: 0.0128\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1594 - mae: 0.0125 - val_loss: 0.1590 - val_mae: 0.0144\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1585 - mae: 0.0102 - val_loss: 0.1581 - val_mae: 0.0105\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1580 - mae: 0.0138 - val_loss: 0.1580 - val_mae: 0.0204\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1574 - mae: 0.0150 - val_loss: 0.1567 - val_mae: 0.0090\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1564 - mae: 0.0096 - val_loss: 0.1561 - val_mae: 0.0133\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1557 - mae: 0.0108 - val_loss: 0.1556 - val_mae: 0.0166\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1550 - mae: 0.0095 - val_loss: 0.1545 - val_mae: 0.0063\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1543 - mae: 0.0077 - val_loss: 0.1540 - val_mae: 0.0125\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1536 - mae: 0.0094 - val_loss: 0.1533 - val_mae: 0.0110\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1529 - mae: 0.0070 - val_loss: 0.1525 - val_mae: 0.0091\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1522 - mae: 0.0072 - val_loss: 0.1519 - val_mae: 0.0099\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1516 - mae: 0.0074 - val_loss: 0.1511 - val_mae: 0.0061\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1509 - mae: 0.0065 - val_loss: 0.1506 - val_mae: 0.0125\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1503 - mae: 0.0109 - val_loss: 0.1500 - val_mae: 0.0140\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1498 - mae: 0.0149 - val_loss: 0.1494 - val_mae: 0.0111\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1490 - mae: 0.0104 - val_loss: 0.1485 - val_mae: 0.0073\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1483 - mae: 0.0069 - val_loss: 0.1479 - val_mae: 0.0061\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1476 - mae: 0.0068 - val_loss: 0.1476 - val_mae: 0.0178\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1471 - mae: 0.0102 - val_loss: 0.1467 - val_mae: 0.0101\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1464 - mae: 0.0089 - val_loss: 0.1462 - val_mae: 0.0115\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1458 - mae: 0.0102 - val_loss: 0.1458 - val_mae: 0.0168\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1453 - mae: 0.0122 - val_loss: 0.1450 - val_mae: 0.0169\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1448 - mae: 0.0149 - val_loss: 0.1445 - val_mae: 0.0184\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1456 - mae: 0.0298 - val_loss: 0.1645 - val_mae: 0.1133\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1538 - mae: 0.0786 - val_loss: 0.1440 - val_mae: 0.0229\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1519 - mae: 0.0653 - val_loss: 0.1557 - val_mae: 0.0885\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1476 - mae: 0.0551 - val_loss: 0.1495 - val_mae: 0.0756\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1447 - mae: 0.0443 - val_loss: 0.1428 - val_mae: 0.0336\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1421 - mae: 0.0280 - val_loss: 0.1414 - val_mae: 0.0214\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1412 - mae: 0.0231 - val_loss: 0.1411 - val_mae: 0.0265\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1404 - mae: 0.0193 - val_loss: 0.1411 - val_mae: 0.0319\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1400 - mae: 0.0220 - val_loss: 0.1399 - val_mae: 0.0286\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1390 - mae: 0.0156 - val_loss: 0.1385 - val_mae: 0.0145\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1382 - mae: 0.0117 - val_loss: 0.1379 - val_mae: 0.0139\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1376 - mae: 0.0121 - val_loss: 0.1372 - val_mae: 0.0098\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1369 - mae: 0.0077 - val_loss: 0.1367 - val_mae: 0.0136\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1365 - mae: 0.0115 - val_loss: 0.1362 - val_mae: 0.0157\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1360 - mae: 0.0154 - val_loss: 0.1357 - val_mae: 0.0148\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1353 - mae: 0.0097 - val_loss: 0.1349 - val_mae: 0.0088\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1346 - mae: 0.0065 - val_loss: 0.1343 - val_mae: 0.0053\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1341 - mae: 0.0052 - val_loss: 0.1338 - val_mae: 0.0062\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1335 - mae: 0.0055 - val_loss: 0.1332 - val_mae: 0.0063\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1330 - mae: 0.0056 - val_loss: 0.1327 - val_mae: 0.0061\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1325 - mae: 0.0074 - val_loss: 0.1323 - val_mae: 0.0121\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1320 - mae: 0.0093 - val_loss: 0.1316 - val_mae: 0.0078\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1314 - mae: 0.0076 - val_loss: 0.1311 - val_mae: 0.0065\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1308 - mae: 0.0058 - val_loss: 0.1305 - val_mae: 0.0060\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1303 - mae: 0.0053 - val_loss: 0.1300 - val_mae: 0.0049\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1298 - mae: 0.0056 - val_loss: 0.1296 - val_mae: 0.0113\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1293 - mae: 0.0085 - val_loss: 0.1289 - val_mae: 0.0048\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1287 - mae: 0.0052 - val_loss: 0.1284 - val_mae: 0.0075\n",
      "Epoch 110/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1282 - mae: 0.0068 - val_loss: 0.1280 - val_mae: 0.0125\n",
      "Epoch 111/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1278 - mae: 0.0100 - val_loss: 0.1274 - val_mae: 0.0054\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1272 - mae: 0.0067 - val_loss: 0.1269 - val_mae: 0.0089\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1267 - mae: 0.0085 - val_loss: 0.1264 - val_mae: 0.0076\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1262 - mae: 0.0077 - val_loss: 0.1258 - val_mae: 0.0051\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1257 - mae: 0.0091 - val_loss: 0.1253 - val_mae: 0.0050\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1251 - mae: 0.0061 - val_loss: 0.1249 - val_mae: 0.0074\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1246 - mae: 0.0060 - val_loss: 0.1243 - val_mae: 0.0078\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1241 - mae: 0.0062 - val_loss: 0.1240 - val_mae: 0.0125\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1237 - mae: 0.0087 - val_loss: 0.1238 - val_mae: 0.0176\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1233 - mae: 0.0117 - val_loss: 0.1250 - val_mae: 0.0400\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1234 - mae: 0.0217 - val_loss: 0.1240 - val_mae: 0.0338\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1235 - mae: 0.0280 - val_loss: 0.1225 - val_mae: 0.0229\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1221 - mae: 0.0174 - val_loss: 0.1235 - val_mae: 0.0387\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1221 - mae: 0.0242 - val_loss: 0.1221 - val_mae: 0.0277\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1215 - mae: 0.0227 - val_loss: 0.1296 - val_mae: 0.0780\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1264 - mae: 0.0595 - val_loss: 0.1268 - val_mae: 0.0725\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1222 - mae: 0.0377 - val_loss: 0.1213 - val_mae: 0.0402\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1201 - mae: 0.0237 - val_loss: 0.1193 - val_mae: 0.0169\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1191 - mae: 0.0141 - val_loss: 0.1186 - val_mae: 0.0086\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1184 - mae: 0.0089 - val_loss: 0.1181 - val_mae: 0.0066\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1179 - mae: 0.0071 - val_loss: 0.1176 - val_mae: 0.0060\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1174 - mae: 0.0072 - val_loss: 0.1172 - val_mae: 0.0103\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1169 - mae: 0.0063 - val_loss: 0.1166 - val_mae: 0.0055\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1164 - mae: 0.0048 - val_loss: 0.1163 - val_mae: 0.0094\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1161 - mae: 0.0078 - val_loss: 0.1158 - val_mae: 0.0085\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1155 - mae: 0.0060 - val_loss: 0.1154 - val_mae: 0.0122\n",
      "Epoch 137/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.1151 - mae: 0.0070 - val_loss: 0.1149 - val_mae: 0.0102\n",
      "Epoch 138/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1147 - mae: 0.0085 - val_loss: 0.1144 - val_mae: 0.0080\n",
      "Epoch 139/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1143 - mae: 0.0107 - val_loss: 0.1145 - val_mae: 0.0198\n",
      "Epoch 140/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1141 - mae: 0.0152 - val_loss: 0.1135 - val_mae: 0.0064\n",
      "Epoch 141/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1138 - mae: 0.0181 - val_loss: 0.1137 - val_mae: 0.0215\n",
      "Epoch 142/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1133 - mae: 0.0169 - val_loss: 0.1126 - val_mae: 0.0102\n",
      "Epoch 143/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1125 - mae: 0.0111 - val_loss: 0.1122 - val_mae: 0.0087\n",
      "Epoch 144/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1120 - mae: 0.0083 - val_loss: 0.1119 - val_mae: 0.0121\n",
      "Epoch 145/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1116 - mae: 0.0097 - val_loss: 0.1114 - val_mae: 0.0128\n",
      "Epoch 146/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1111 - mae: 0.0082 - val_loss: 0.1110 - val_mae: 0.0122\n",
      "Epoch 147/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1107 - mae: 0.0087 - val_loss: 0.1103 - val_mae: 0.0052\n",
      "Epoch 148/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1102 - mae: 0.0074 - val_loss: 0.1100 - val_mae: 0.0096\n",
      "Epoch 149/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1098 - mae: 0.0069 - val_loss: 0.1095 - val_mae: 0.0062\n",
      "Epoch 150/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1093 - mae: 0.0070 - val_loss: 0.1090 - val_mae: 0.0049\n",
      "Epoch 151/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1089 - mae: 0.0045 - val_loss: 0.1086 - val_mae: 0.0043\n",
      "Epoch 152/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1084 - mae: 0.0039 - val_loss: 0.1084 - val_mae: 0.0122\n",
      "Epoch 153/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1081 - mae: 0.0105 - val_loss: 0.1078 - val_mae: 0.0079\n",
      "Epoch 154/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1076 - mae: 0.0063 - val_loss: 0.1075 - val_mae: 0.0115\n",
      "Epoch 155/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1072 - mae: 0.0076 - val_loss: 0.1069 - val_mae: 0.0057\n",
      "Epoch 156/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1068 - mae: 0.0070 - val_loss: 0.1066 - val_mae: 0.0086\n",
      "Epoch 157/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1064 - mae: 0.0085 - val_loss: 0.1062 - val_mae: 0.0122\n",
      "Epoch 158/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1060 - mae: 0.0078 - val_loss: 0.1057 - val_mae: 0.0057\n",
      "Epoch 159/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1055 - mae: 0.0060 - val_loss: 0.1052 - val_mae: 0.0056\n",
      "Epoch 160/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1051 - mae: 0.0063 - val_loss: 0.1050 - val_mae: 0.0133\n",
      "Epoch 161/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1048 - mae: 0.0113 - val_loss: 0.1048 - val_mae: 0.0175\n",
      "Epoch 162/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1044 - mae: 0.0108 - val_loss: 0.1044 - val_mae: 0.0179\n",
      "Epoch 163/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1043 - mae: 0.0175 - val_loss: 0.1045 - val_mae: 0.0244\n",
      "Epoch 164/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1040 - mae: 0.0186 - val_loss: 0.1051 - val_mae: 0.0339\n",
      "Epoch 165/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1038 - mae: 0.0220 - val_loss: 0.1033 - val_mae: 0.0208\n",
      "Epoch 166/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1033 - mae: 0.0199 - val_loss: 0.1044 - val_mae: 0.0363\n",
      "Epoch 167/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1031 - mae: 0.0222 - val_loss: 0.1039 - val_mae: 0.0369\n",
      "Epoch 168/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1027 - mae: 0.0229 - val_loss: 0.1035 - val_mae: 0.0332\n",
      "Epoch 169/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1034 - mae: 0.0365 - val_loss: 0.1150 - val_mae: 0.0916\n",
      "Epoch 170/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1070 - mae: 0.0609 - val_loss: 0.1079 - val_mae: 0.0629\n",
      "Epoch 171/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1029 - mae: 0.0348 - val_loss: 0.1013 - val_mae: 0.0214\n",
      "Epoch 172/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1014 - mae: 0.0271 - val_loss: 0.1023 - val_mae: 0.0354\n",
      "Epoch 173/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1014 - mae: 0.0292 - val_loss: 0.1005 - val_mae: 0.0194\n",
      "Epoch 174/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1005 - mae: 0.0245 - val_loss: 0.0996 - val_mae: 0.0145\n",
      "Epoch 175/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1000 - mae: 0.0229 - val_loss: 0.1010 - val_mae: 0.0337\n",
      "Epoch 176/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0998 - mae: 0.0260 - val_loss: 0.0993 - val_mae: 0.0242\n",
      "Epoch 177/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0987 - mae: 0.0163 - val_loss: 0.0983 - val_mae: 0.0135\n",
      "Epoch 178/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0981 - mae: 0.0107 - val_loss: 0.0978 - val_mae: 0.0083\n",
      "Epoch 179/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0976 - mae: 0.0077 - val_loss: 0.0975 - val_mae: 0.0118\n",
      "Epoch 180/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0972 - mae: 0.0088 - val_loss: 0.0970 - val_mae: 0.0085\n",
      "Epoch 181/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0970 - mae: 0.0129 - val_loss: 0.0976 - val_mae: 0.0223\n",
      "Epoch 182/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0976 - mae: 0.0266 - val_loss: 0.0987 - val_mae: 0.0376\n",
      "Epoch 183/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0976 - mae: 0.0296 - val_loss: 0.0961 - val_mae: 0.0172\n",
      "Epoch 184/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0962 - mae: 0.0195 - val_loss: 0.0963 - val_mae: 0.0257\n",
      "Epoch 185/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0956 - mae: 0.0141 - val_loss: 0.0954 - val_mae: 0.0143\n",
      "Epoch 186/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0950 - mae: 0.0098 - val_loss: 0.0947 - val_mae: 0.0064\n",
      "Epoch 187/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0946 - mae: 0.0067 - val_loss: 0.0943 - val_mae: 0.0050\n",
      "Epoch 188/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0942 - mae: 0.0057 - val_loss: 0.0939 - val_mae: 0.0057\n",
      "Epoch 189/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0938 - mae: 0.0058 - val_loss: 0.0936 - val_mae: 0.0068\n",
      "Epoch 190/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0935 - mae: 0.0086 - val_loss: 0.0934 - val_mae: 0.0153\n",
      "Epoch 191/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0931 - mae: 0.0086 - val_loss: 0.0929 - val_mae: 0.0112\n",
      "Epoch 192/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0927 - mae: 0.0076 - val_loss: 0.0925 - val_mae: 0.0096\n",
      "Epoch 193/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0923 - mae: 0.0066 - val_loss: 0.0922 - val_mae: 0.0119\n",
      "Epoch 194/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0920 - mae: 0.0076 - val_loss: 0.0919 - val_mae: 0.0126\n",
      "Epoch 195/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0917 - mae: 0.0092 - val_loss: 0.0914 - val_mae: 0.0065\n",
      "Epoch 196/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0913 - mae: 0.0064 - val_loss: 0.0911 - val_mae: 0.0098\n",
      "Epoch 197/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0909 - mae: 0.0078 - val_loss: 0.0907 - val_mae: 0.0067\n",
      "Epoch 198/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0906 - mae: 0.0101 - val_loss: 0.0903 - val_mae: 0.0062\n",
      "Epoch 199/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0902 - mae: 0.0076 - val_loss: 0.0900 - val_mae: 0.0088\n",
      "Epoch 200/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0898 - mae: 0.0068 - val_loss: 0.0896 - val_mae: 0.0057\n",
      "Epoch 201/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0895 - mae: 0.0053 - val_loss: 0.0892 - val_mae: 0.0046\n",
      "Epoch 202/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0891 - mae: 0.0046 - val_loss: 0.0889 - val_mae: 0.0059\n",
      "Epoch 203/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0887 - mae: 0.0052 - val_loss: 0.0885 - val_mae: 0.0040\n",
      "Epoch 204/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0884 - mae: 0.0061 - val_loss: 0.0884 - val_mae: 0.0131\n",
      "Epoch 205/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0881 - mae: 0.0083 - val_loss: 0.0878 - val_mae: 0.0044\n",
      "Epoch 206/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0877 - mae: 0.0051 - val_loss: 0.0875 - val_mae: 0.0090\n",
      "Epoch 207/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0874 - mae: 0.0071 - val_loss: 0.0871 - val_mae: 0.0056\n",
      "Epoch 208/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0870 - mae: 0.0051 - val_loss: 0.0868 - val_mae: 0.0041\n",
      "Epoch 209/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0867 - mae: 0.0049 - val_loss: 0.0865 - val_mae: 0.0080\n",
      "Epoch 210/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0864 - mae: 0.0075 - val_loss: 0.0866 - val_mae: 0.0201\n",
      "Epoch 211/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0861 - mae: 0.0118 - val_loss: 0.0863 - val_mae: 0.0205\n",
      "Epoch 212/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0860 - mae: 0.0143 - val_loss: 0.0860 - val_mae: 0.0195\n",
      "Epoch 213/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0858 - mae: 0.0188 - val_loss: 0.0871 - val_mae: 0.0336\n",
      "Epoch 214/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0857 - mae: 0.0219 - val_loss: 0.0860 - val_mae: 0.0258\n",
      "Epoch 215/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0851 - mae: 0.0180 - val_loss: 0.0849 - val_mae: 0.0184\n",
      "Epoch 216/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0847 - mae: 0.0162 - val_loss: 0.0844 - val_mae: 0.0125\n",
      "Epoch 217/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0843 - mae: 0.0141 - val_loss: 0.0839 - val_mae: 0.0134\n",
      "Epoch 218/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0837 - mae: 0.0080 - val_loss: 0.0834 - val_mae: 0.0058\n",
      "Epoch 219/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0833 - mae: 0.0061 - val_loss: 0.0832 - val_mae: 0.0093\n",
      "Epoch 220/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0830 - mae: 0.0080 - val_loss: 0.0828 - val_mae: 0.0095\n",
      "Epoch 221/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0828 - mae: 0.0110 - val_loss: 0.0827 - val_mae: 0.0131\n",
      "Epoch 222/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0827 - mae: 0.0166 - val_loss: 0.0825 - val_mae: 0.0169\n",
      "Epoch 223/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0823 - mae: 0.0138 - val_loss: 0.0818 - val_mae: 0.0094\n",
      "Epoch 224/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0817 - mae: 0.0078 - val_loss: 0.0814 - val_mae: 0.0052\n",
      "Epoch 225/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0813 - mae: 0.0060 - val_loss: 0.0812 - val_mae: 0.0113\n",
      "Epoch 226/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0811 - mae: 0.0097 - val_loss: 0.0811 - val_mae: 0.0163\n",
      "Epoch 227/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0808 - mae: 0.0119 - val_loss: 0.0806 - val_mae: 0.0102\n",
      "Epoch 228/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0805 - mae: 0.0111 - val_loss: 0.0804 - val_mae: 0.0155\n",
      "Epoch 229/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0801 - mae: 0.0108 - val_loss: 0.0818 - val_mae: 0.0335\n",
      "Epoch 230/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0811 - mae: 0.0304 - val_loss: 0.0797 - val_mae: 0.0122\n",
      "Epoch 231/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0809 - mae: 0.0306 - val_loss: 0.0851 - val_mae: 0.0641\n",
      "Epoch 232/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0821 - mae: 0.0426 - val_loss: 0.0792 - val_mae: 0.0126\n",
      "Epoch 233/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0793 - mae: 0.0189 - val_loss: 0.0790 - val_mae: 0.0195\n",
      "Epoch 234/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0787 - mae: 0.0128 - val_loss: 0.0785 - val_mae: 0.0141\n",
      "Epoch 235/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0783 - mae: 0.0114 - val_loss: 0.0780 - val_mae: 0.0078\n",
      "Epoch 236/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0779 - mae: 0.0081 - val_loss: 0.0776 - val_mae: 0.0053\n",
      "Epoch 237/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0775 - mae: 0.0066 - val_loss: 0.0775 - val_mae: 0.0105\n",
      "Epoch 238/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0772 - mae: 0.0070 - val_loss: 0.0770 - val_mae: 0.0073\n",
      "Epoch 239/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0769 - mae: 0.0063 - val_loss: 0.0771 - val_mae: 0.0159\n",
      "Epoch 240/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0768 - mae: 0.0141 - val_loss: 0.0769 - val_mae: 0.0188\n",
      "Epoch 241/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0765 - mae: 0.0135 - val_loss: 0.0761 - val_mae: 0.0087\n",
      "Epoch 242/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0760 - mae: 0.0096 - val_loss: 0.0762 - val_mae: 0.0192\n",
      "Epoch 243/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0760 - mae: 0.0168 - val_loss: 0.0761 - val_mae: 0.0182\n",
      "Epoch 244/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0758 - mae: 0.0184 - val_loss: 0.0756 - val_mae: 0.0160\n",
      "Epoch 245/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0754 - mae: 0.0161 - val_loss: 0.0749 - val_mae: 0.0100\n",
      "Epoch 246/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0749 - mae: 0.0108 - val_loss: 0.0746 - val_mae: 0.0060\n",
      "Epoch 247/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0744 - mae: 0.0057 - val_loss: 0.0743 - val_mae: 0.0070\n",
      "Epoch 248/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0741 - mae: 0.0053 - val_loss: 0.0739 - val_mae: 0.0057\n",
      "Epoch 249/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0738 - mae: 0.0056 - val_loss: 0.0736 - val_mae: 0.0056\n",
      "Epoch 250/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0735 - mae: 0.0047 - val_loss: 0.0733 - val_mae: 0.0064\n",
      "Epoch 251/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0732 - mae: 0.0051 - val_loss: 0.0730 - val_mae: 0.0042\n",
      "Epoch 252/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0729 - mae: 0.0047 - val_loss: 0.0727 - val_mae: 0.0049\n",
      "Epoch 253/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0726 - mae: 0.0052 - val_loss: 0.0724 - val_mae: 0.0060\n",
      "Epoch 254/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0723 - mae: 0.0047 - val_loss: 0.0725 - val_mae: 0.0153\n",
      "Epoch 255/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0721 - mae: 0.0084 - val_loss: 0.0718 - val_mae: 0.0049\n",
      "Epoch 256/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0717 - mae: 0.0055 - val_loss: 0.0717 - val_mae: 0.0092\n",
      "Epoch 257/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0715 - mae: 0.0071 - val_loss: 0.0713 - val_mae: 0.0061\n",
      "Epoch 258/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0711 - mae: 0.0058 - val_loss: 0.0710 - val_mae: 0.0060\n",
      "Epoch 259/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0708 - mae: 0.0061 - val_loss: 0.0707 - val_mae: 0.0047\n",
      "Epoch 260/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0705 - mae: 0.0058 - val_loss: 0.0704 - val_mae: 0.0086\n",
      "Epoch 261/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0704 - mae: 0.0112 - val_loss: 0.0705 - val_mae: 0.0159\n",
      "Epoch 262/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0701 - mae: 0.0105 - val_loss: 0.0702 - val_mae: 0.0174\n",
      "Epoch 263/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0698 - mae: 0.0109 - val_loss: 0.0695 - val_mae: 0.0059\n",
      "Epoch 264/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0694 - mae: 0.0054 - val_loss: 0.0692 - val_mae: 0.0064\n",
      "Epoch 265/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0691 - mae: 0.0051 - val_loss: 0.0689 - val_mae: 0.0040\n",
      "Epoch 266/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0688 - mae: 0.0050 - val_loss: 0.0686 - val_mae: 0.0057\n",
      "Epoch 267/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0685 - mae: 0.0043 - val_loss: 0.0685 - val_mae: 0.0103\n",
      "Epoch 268/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0683 - mae: 0.0063 - val_loss: 0.0681 - val_mae: 0.0063\n",
      "Epoch 269/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0680 - mae: 0.0066 - val_loss: 0.0680 - val_mae: 0.0120\n",
      "Epoch 270/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0681 - mae: 0.0168 - val_loss: 0.0681 - val_mae: 0.0192\n",
      "Epoch 271/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0677 - mae: 0.0157 - val_loss: 0.0699 - val_mae: 0.0429\n",
      "Epoch 272/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0688 - mae: 0.0320 - val_loss: 0.0735 - val_mae: 0.0606\n",
      "Epoch 273/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0727 - mae: 0.0583 - val_loss: 0.0693 - val_mae: 0.0365\n",
      "Epoch 274/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0712 - mae: 0.0520 - val_loss: 0.0744 - val_mae: 0.0659\n",
      "Epoch 275/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0700 - mae: 0.0493 - val_loss: 0.0698 - val_mae: 0.0451\n",
      "Epoch 276/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0695 - mae: 0.0426Restoring model weights from the end of the best epoch: 271.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0683 - mae: 0.0349 - val_loss: 0.0669 - val_mae: 0.0259\n",
      "Epoch 276: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Netzwerkarchitektur\n",
    "model = Sequential([\n",
    "\n",
    "    Dense(136, activation='relu', input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "\n",
    "    Dense(72, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(200, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    Dense(296, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    Dense(248, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    Dense(72, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    Dense(328, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    Dense(296, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    Dense(264, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    Dense(8, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n",
    "    \n",
    "    Dense(1 , activation = 'linear')\n",
    "])\n",
    "\n",
    "# Optimierer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# Modell kompilieren (Verwendung von mean_squared_error als Verlustfunktion für Regression)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])  # Metriken für Regression: Mean Absolute Error und Mean Squared Error\n",
    "\n",
    "# Early Stopping Callback\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "# Trainingsparameter\n",
    "batch_size = 75\n",
    "epochs = 1000\n",
    "\n",
    "# Modell trainieren (Annahme: X_train, y_train, X_val, y_val sind vordefiniert)\n",
    "history = model.fit(X_train_scaled, y_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:02:19.991927200Z",
     "start_time": "2024-03-15T10:01:59.874759400Z"
    }
   },
   "id": "8b52e1a9a6ff3aeb"
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 - 0s - loss: 0.0696 - mae: 0.0401 - 29ms/epoch - 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.06964200735092163, 0.04013713076710701]"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test_scaled, y_test_scaled, verbose=2)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:02:20.057091900Z",
     "start_time": "2024-03-15T10:02:19.985926900Z"
    }
   },
   "id": "4b02697cbcecd185"
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bsp. Predicted: [1129.0691] Actual: [1148.8] \n",
      "Durchschnittliche Abweichung (MAE): [37.94001992]\n"
     ]
    }
   ],
   "source": [
    "scaled_predicted_values = model.predict(X_test_scaled, verbose = 0)\n",
    "\n",
    "# Führen Sie die Rücktransformation der skalierten Werte durch\n",
    "original_predicted_values = scaler_target.inverse_transform(scaled_predicted_values)\n",
    "original_actual_values = scaler_target.inverse_transform(y_test_scaled)  # y_test sind die skalierten tatsächlichen Werte\n",
    "print(f' Bsp. Predicted: {original_predicted_values[100]} Actual: {original_actual_values[100]} ')\n",
    "\n",
    "def calculate_mae(list1, list2):\n",
    "    # Stelle sicher, dass beide Listen die gleiche Länge haben\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Listen müssen die gleiche Länge haben\")\n",
    "\n",
    "    # Berechne die absolute Differenz zwischen den Elementen der Listen\n",
    "    differences = [abs(x - y) for x, y in zip(list1, list2)]\n",
    "\n",
    "    # Berechne den Durchschnitt der absoluten Differenzen\n",
    "    mae = sum(differences) / len(differences)\n",
    "\n",
    "    return mae\n",
    "\n",
    "# Beispiel\n",
    "list1 = original_predicted_values\n",
    "list2 = original_actual_values\n",
    "\n",
    "mae = calculate_mae(list1, list2)\n",
    "print(f\"Durchschnittliche Abweichung (MAE): {mae}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:02:20.180042100Z",
     "start_time": "2024-03-15T10:02:20.055092300Z"
    }
   },
   "id": "a402d28abbd82f60"
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: [0.96905492]\n"
     ]
    }
   ],
   "source": [
    "def calculate_r_squared(predicted, actual):\n",
    "    # Berechnung des Mittelwerts der tatsächlichen Werte\n",
    "    mean_actual = sum(actual) / len(actual)\n",
    "    \n",
    "    # Berechnung der totalen Summe der Quadrate (SST)\n",
    "    sst = sum((x - mean_actual) ** 2 for x in actual)\n",
    "    \n",
    "    # Berechnung der Summe der Quadrate der Residuen (SSE)\n",
    "    sse = sum((actual[i] - predicted[i]) ** 2 for i in range(len(actual)))\n",
    "    \n",
    "    # Berechnung des R^2-Wertes\n",
    "    r_squared = 1 - (sse / sst)\n",
    "    \n",
    "    return r_squared\n",
    "\n",
    "# Berechnung von R^2 mit den bereitgestellten Listen\n",
    "r_squared = calculate_r_squared(list1, list2)\n",
    "\n",
    "print(f\"R^2: {r_squared}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:02:20.189042300Z",
     "start_time": "2024-03-15T10:02:20.180042100Z"
    }
   },
   "id": "2820df0b9f03b675"
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIjCAYAAAA0vUuxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABvx0lEQVR4nO3dd3wUdf7H8fduyqb3kAKBQOgtIE1AbKAUD3tDFBBPBLHLnR2wnHhnOX6K/RS88wDLiV0UEKzYQHqREnoKCek9u/P7Y8nqmpAiSWaTvJ6Pxz52Z/Y7M5/NLDFvv9/5jsUwDEMAAAAAgBOyml0AAAAAAHg6ghMAAAAA1ILgBAAAAAC1IDgBAAAAQC0ITgAAAABQC4ITAAAAANSC4AQAAAAAtSA4AQAAAEAtCE4AAAAAUAuCEwB4qClTpigxMfEPbTt37lxZLJaGLcjD7Nu3TxaLRYsWLWryY1ssFs2dO9e1vGjRIlksFu3bt6/WbRMTEzVlypQGredkvisAgLohOAFAPVksljo91qxZY3aprd4tt9wii8Wi3bt3n7DNfffdJ4vFok2bNjVhZfV35MgRzZ07Vxs2bDC7FJfK8GqxWPTII49U22bixImyWCwKCgpyW+9wOPTvf/9bQ4YMUUREhIKDg9W1a1dNmjRJ3333navdmjVravx3tnTp0kb9jABQydvsAgCgufnPf/7jtvzvf/9bK1asqLK+R48eJ3Wcl19+WQ6H4w9te//99+vuu+8+qeO3BBMnTtQzzzyjxYsXa/bs2dW2WbJkifr06aO+ffv+4eNcc801uvLKK2Wz2f7wPmpz5MgRPfjgg0pMTFS/fv3c3juZ70pD8PPz05IlS3T//fe7rS8sLNR7770nPz+/KtvccsstevbZZ3XBBRdo4sSJ8vb21s6dO/XJJ5+oU6dOOvXUU6u0HzRoUJX9DB06tGE/DACcAMEJAOrp6quvdlv+7rvvtGLFiirrf6+oqEgBAQF1Po6Pj88fqk+SvL295e3Nr/ghQ4aoc+fOWrJkSbXBae3atUpJSdFjjz12Usfx8vKSl5fXSe3jZJzMd6UhjBs3Tu+88442btyo5ORk1/r33ntPZWVlGjNmjD7//HPX+vT0dD333HO6/vrr9dJLL7nta/78+Tp69GiVY4wYMUKXXnpp430IAKgFQ/UAoBGceeaZ6t27t9atW6fTTz9dAQEBuvfeeyU5/5g877zzFB8fL5vNpqSkJD388MOy2+1u+/j9dSuVw6KeeOIJvfTSS0pKSpLNZtOgQYP0448/um1b3TVOFotFN910k95991317t1bNptNvXr10vLly6vUv2bNGg0cOFB+fn5KSkrSiy++WOfrpr766itddtllat++vWw2mxISEnT77beruLi4yucLCgrS4cOHdeGFFyooKEjR0dGaNWtWlZ9FTk6OpkyZotDQUIWFhWny5MnKycmptRbJ2eu0Y8cOrV+/vsp7ixcvlsVi0YQJE1RWVqbZs2drwIABCg0NVWBgoEaMGKHVq1fXeozqrnEyDEOPPPKI2rVrp4CAAJ111lnaunVrlW2PHTumWbNmqU+fPgoKClJISIjGjh2rjRs3utqsWbPG1dty7bXXuoapVV7fVd01ToWFhbrzzjuVkJAgm82mbt266YknnpBhGG7t6vO9OJGhQ4eqY8eOWrx4sdv6//73vxozZowiIiLc1qekpMgwDA0fPrzKviwWi9q0aVPnYwNAU+F/RwJAI8nKytLYsWN15ZVX6uqrr1ZMTIwk5x/ZQUFBuuOOOxQUFKTPP/9cs2fPVl5enh5//PFa97t48WLl5+frhhtukMVi0T/+8Q9dfPHF2rt3b609D19//bXeeecd3XjjjQoODtbTTz+tSy65RAcOHFBkZKQk6eeff9aYMWMUFxenBx98UHa7XQ899JCio6Pr9LnfeustFRUVacaMGYqMjNQPP/ygZ555RocOHdJbb73l1tZut2v06NEaMmSInnjiCa1cuVJPPvmkkpKSNGPGDEnOAHLBBRfo66+/1vTp09WjRw8tW7ZMkydPrlM9EydO1IMPPqjFixfrlFNOcTv2m2++qREjRqh9+/bKzMzUv/71L02YMEHXX3+98vPz9corr2j06NH64YcfqgyPq83s2bP1yCOPaNy4cRo3bpzWr1+vc889V2VlZW7t9u7dq3fffVeXXXaZOnbsqPT0dL344os644wztG3bNsXHx6tHjx566KGHNHv2bE2bNk0jRoyQJA0bNqzaYxuGofPPP1+rV6/Wddddp379+unTTz/VX/7yFx0+fFj//Oc/3drX5XtRmwkTJuj111/XY489JovFoszMTH322Wf6z3/+UyWEdejQQZLzu3LZZZfVqSc2Pz9fmZmZVdZHRka2+IlQAHgIAwBwUmbOnGn8/tfpGWecYUgyXnjhhSrti4qKqqy74YYbjICAAKOkpMS1bvLkyUaHDh1cyykpKYYkIzIy0jh27Jhr/XvvvWdIMj744APXujlz5lSpSZLh6+tr7N6927Vu48aNhiTjmWeeca0bP368ERAQYBw+fNi1bteuXYa3t3eVfVanus83b948w2KxGPv373f7fJKMhx56yK1t//79jQEDBriW3333XUOS8Y9//MO1rqKiwhgxYoQhyVi4cGGtNQ0aNMho166dYbfbXeuWL19uSDJefPFF1z5LS0vdtsvOzjZiYmKMqVOnuq2XZMyZM8e1vHDhQkOSkZKSYhiGYWRkZBi+vr7GeeedZzgcDle7e++915BkTJ482bWupKTErS7DcJ5rm83m9rP58ccfT/h5f/9dqfyZPfLII27tLr30UsNisbh9B+r6vahO5Xfy8ccfN7Zs2WJIMr766ivDMAzj2WefNYKCgozCwkJj8uTJRmBgoNu2kyZNMiQZ4eHhxkUXXWQ88cQTxvbt26scY/Xq1YakEz5SU1NrrBEAGgpD9QCgkdhsNl177bVV1vv7+7teV/5f9BEjRqioqEg7duyodb9XXHGFwsPDXcuVvQ979+6tddtRo0YpKSnJtdy3b1+FhIS4trXb7Vq5cqUuvPBCxcfHu9p17txZY8eOrXX/kvvnKywsVGZmpoYNGybDMPTzzz9XaT99+nS35REjRrh9lo8//lje3t6uHijJeU3RzTffXKd6JOd1aYcOHdKXX37pWrd48WL5+vrqsssuc+3T19dXknPGt2PHjqmiokIDBw6sdphfTVauXKmysjLdfPPNbr0ht912W5W2NptNVqvzP8d2u11ZWVkKCgpSt27d6n3cSh9//LG8vLx0yy23uK2/8847ZRiGPvnkE7f1tX0v6qJXr17q27evlixZIsn5873gggtO2Ju0cOFCLViwQB07dtSyZcs0a9Ys9ejRQyNHjtThw4ertJ89e7ZWrFhR5fH7YYAA0FgITgDQSNq2bev6Q/y3tm7dqosuukihoaEKCQlRdHS0a2KJ3NzcWvfbvn17t+XKEJWdnV3vbSu3r9w2IyNDxcXF6ty5c5V21a2rzoEDBzRlyhRFRES4rls644wzJFX9fH5+flWGAP62Hknav3+/4uLiqkxn3a1btzrVI0lXXnmlvLy8XNfglJSUaNmyZRo7dqxbCH3ttdfUt29f+fn5KTIyUtHR0froo4/qdF5+a//+/ZKkLl26uK2Pjo52O57kDGn//Oc/1aVLF9lsNkVFRSk6OlqbNm2q93F/e/z4+HgFBwe7ra+c6bGyvkq1fS/q6qqrrtJbb72l3bt369tvv9VVV111wrZWq1UzZ87UunXrlJmZqffee09jx47V559/riuvvLJK+z59+mjUqFFVHtX9GwOAxkBwAoBG8tuel0o5OTk644wztHHjRj300EP64IMPtGLFCv3973+XpDpNKX2i2duM313039Db1oXdbtc555yjjz76SHfddZfeffddrVixwjWJwe8/X1PNRNemTRudc845+t///qfy8nJ98MEHys/P18SJE11tXn/9dU2ZMkVJSUl65ZVXtHz5cq1YsUJnn312o071/eijj+qOO+7Q6aefrtdff12ffvqpVqxYoV69ejXZFOMN9b2YMGGCMjMzdf311ysyMlLnnntunbaLjIzU+eefr48//lhnnHGGvv766yrhDgDMxuQQANCE1qxZo6ysLL3zzjs6/fTTXetTUlJMrOpXbdq0kZ+fX7U3jK3pJrKVNm/erF9++UWvvfaaJk2a5Fq/YsWKP1xThw4dtGrVKhUUFLj1Ou3cubNe+5k4caKWL1+uTz75RIsXL1ZISIjGjx/vev/tt99Wp06d9M4777gNr5szZ84fqlmSdu3apU6dOrnWHz16tEovzttvv62zzjpLr7zyitv6nJwcRUVFuZbrMwFChw4dtHLlSuXn57v1OlUOBa2sr6G1b99ew4cP15o1azRjxow/NCX+wIED9cUXXyg1NbXR6gSAP4IeJwBoQpX/Z/+3/ye/rKxMzz33nFklufHy8tKoUaP07rvv6siRI671u3fvrnJdzIm2l9w/n2EY+r//+78/XNO4ceNUUVGh559/3rXObrfrmWeeqdd+LrzwQgUEBOi5557TJ598oosvvtjtxqzV1f79999r7dq19a551KhR8vHx0TPPPOO2v/nz51dp6+XlVaVn56233qpynU9gYKAk1Wka9nHjxslut2vBggVu6//5z3/KYrHU+Xq1P+KRRx7RnDlzarwGLS0tTdu2bauyvqysTKtWrZLVaq3z0FAAaCr0OAFAExo2bJjCw8M1efJk3XLLLbJYLPrPf/7TYEPlGsLcuXP12Wefafjw4ZoxY4brD/DevXtrw4YNNW7bvXt3JSUladasWTp8+LBCQkL0v//9r97XyvzW+PHjNXz4cN19993at2+fevbsqXfeeafe1/8EBQXpwgsvdF3n9NthepL0pz/9Se+8844uuuginXfeeUpJSdELL7ygnj17qqCgoF7Hqrwf1bx58/SnP/1J48aN088//6xPPvnErRep8rgPPfSQrr32Wg0bNkybN2/Wf//7X7eeKklKSkpSWFiYXnjhBQUHByswMFBDhgxRx44dqxx//PjxOuuss3Tfffdp3759Sk5O1meffab33ntPt912m9tEEA3tjDPOcF3TdiKHDh3S4MGDdfbZZ2vkyJGKjY1VRkaGlixZoo0bN+q2226r8nP66quvVFJSUmVfffv2Vd++fRv0MwBAdQhOANCEIiMj9eGHH+rOO+/U/fffr/DwcF199dUaOXKkRo8ebXZ5kqQBAwbok08+0axZs/TAAw8oISFBDz30kLZv317rrH8+Pj764IMPdMstt2jevHny8/PTRRddpJtuuknJycl/qB6r1ar3339ft912m15//XVZLBadf/75evLJJ9W/f/967WvixIlavHix4uLidPbZZ7u9N2XKFKWlpenFF1/Up59+qp49e+r111/XW2+9pTVr1tS77kceeUR+fn564YUXtHr1ag0ZMkSfffaZzjvvPLd29957rwoLC7V48WK98cYbOuWUU/TRRx/p7rvvdmvn4+Oj1157Tffcc4+mT5+uiooKLVy4sNrgVPkzmz17tt544w0tXLhQiYmJevzxx3XnnXfW+7M0tG7dumn+/Pn6+OOP9dxzzyk9PV1+fn7q3bu3Xn75ZV133XVVtnn66aer3decOXMITgCahMXwpP/NCQDwWBdeeKG2bt2qXbt2mV0KAABNjmucAABVFBcXuy3v2rVLH3/8sc4880xzCgIAwGT0OAEAqoiLi9OUKVPUqVMn7d+/X88//7xKS0v1888/V7k3EQAArQHXOAEAqhgzZoyWLFmitLQ02Ww2DR06VI8++iihCQDQatHjBAAAAAC14BonAAAAAKgFwQkAAAAAatHqrnFyOBw6cuSIgoODZbFYzC4HAAAAgEkMw1B+fr7i4+Nltdbcp9TqgtORI0eUkJBgdhkAAAAAPMTBgwfVrl27Gtu0uuAUHBwsyfnDCQkJMbkaAAAAAGbJy8tTQkKCKyPUpNUFp8rheSEhIQQnAAAAAHW6hIfJIQAAAACgFgQnAAAAAKgFwQkAAAAAatHqrnECAACAZ7Lb7SovLze7DLQwPj4+8vLyOun9EJwAAABguoKCAh06dEiGYZhdCloYi8Widu3aKSgo6KT2Q3ACAACAqex2uw4dOqSAgABFR0fXaYYzoC4Mw9DRo0d16NAhdenS5aR6nghOAAAAMFV5ebkMw1B0dLT8/f3NLgctTHR0tPbt26fy8vKTCk5MDgEAAACPQE8TGkNDfa8ITgAAAABQC4ITAAAAANSC4AQAAAB4iMTERM2fP7/O7desWSOLxaKcnJxGqwlOBCcAAACgniwWS42PuXPn/qH9/vjjj5o2bVqd2w8bNkypqakKDQ39Q8erq8qAFh4erpKSErf3fvzxR9fn/q2XX35ZycnJCgoKUlhYmPr376958+a53p87d261P7vu3bs36mf5o5hVDwAAAKin1NRU1+s33nhDs2fP1s6dO13rfnvPIMMwZLfb5e1d+5/e0dHR9arD19dXsbGx9drmZAQHB2vZsmWaMGGCa90rr7yi9u3b68CBA651r776qm677TY9/fTTOuOMM1RaWqpNmzZpy5Ytbvvr1auXVq5c6bauLj8nM9DjBAAAAM9iGFJhoTmPOt6ANzY21vUIDQ2VxWJxLe/YsUPBwcH65JNPNGDAANlsNn399dfas2ePLrjgAsXExCgoKEiDBg2qEhp+P1TPYrHoX//6ly666CIFBASoS5cuev/9913v/36o3qJFixQWFqZPP/1UPXr0UFBQkMaMGeMW9CoqKnTLLbcoLCxMkZGRuuuuuzR58mRdeOGFtX7uyZMn69VXX3UtFxcXa+nSpZo8ebJbu/fff1+XX365rrvuOnXu3Fm9evXShAkT9Le//c2tnbe3t9vPMjY2VlFRUbXWYQaCEwAAADxLUZEUFGTOo6iowT7G3Xffrccee0zbt29X3759VVBQoHHjxmnVqlX6+eefNWbMGI0fP96tp6Y6Dz74oC6//HJt2rRJ48aN08SJE3Xs2LEafnxFeuKJJ/Sf//xHX375pQ4cOKBZs2a53v/73/+u//73v1q4cKG++eYb5eXl6d13363TZ7rmmmv01VdfuWr+3//+p8TERJ1yyilu7WJjY/Xdd99p//79ddpvc0BwAgAAABrBQw89pHPOOUdJSUmKiIhQcnKybrjhBvXu3VtdunTRww8/rKSkJLcepOpMmTJFEyZMUOfOnfXoo4+qoKBAP/zwwwnbl5eX64UXXtDAgQN1yimn6KabbtKqVatc7z/zzDO65557dNFFF6l79+5asGCBwsLC6vSZ2rRpo7Fjx2rRokWSnEPypk6dWqXdnDlzFBYWpsTERHXr1k1TpkzRm2++KYfD4dZu8+bNCgoKcntMnz69TrU0Nc8cQNhabNki7dwpdeki9e1rdjUAAACeISBAKigw79gNZODAgW7LBQUFmjt3rj766COlpqaqoqJCxcXFtfY49f3N34mBgYEKCQlRRkbGCdsHBAQoKSnJtRwXF+dqn5ubq/T0dA0ePNj1vpeXlwYMGFAl1JzI1KlTdeutt+rqq6/W2rVr9dZbb+mrr75yaxMXF6e1a9dqy5Yt+vLLL/Xtt99q8uTJ+te//qXly5fLanX233Tr1q1KcAwJCalTHU2N4GSm116TnnhCmjVLevxxs6sBAADwDBaLFBhodhUnLfB3n2HWrFlasWKFnnjiCXXu3Fn+/v669NJLVVZWVuN+fHx83JYtFkuNIae69kYdr92qi7Fjx2ratGm67rrrNH78eEVGRp6wbe/evdW7d2/deOONmj59ukaMGKEvvvhCZ511liTn5BadO3dusNoaE0P1zOTl5Xy2282tAwAAAI3um2++0ZQpU3TRRRepT58+io2N1b59+5q0htDQUMXExOjHH390rbPb7Vq/fn2d9+Ht7a1JkyZpzZo11Q7TO5GePXtKkgoLC+tesAehx8lMBCcAAIBWo0uXLnrnnXc0fvx4WSwWPfDAA3UeHteQbr75Zs2bN0+dO3dW9+7d9cwzzyg7O7vKfZhq8vDDD+svf/nLCXubZsyYofj4eJ199tlq166dUlNT9cgjjyg6OlpDhw51tauoqFBaWprbthaLRTExMX/swzUigpOZCE4AAACtxlNPPaWpU6dq2LBhioqK0l133aW8vLwmr+Ouu+5SWlqaJk2aJC8vL02bNk2jR4+WV+XfpnXg6+tb47Tho0aN0quvvqrnn39eWVlZioqK0tChQ7Vq1Sq3sLV161bFxcW5bWuz2arcZNcTWIyGHPDYDOTl5Sk0NFS5ubnmX3j24IPS3LnS9OnS88+bWwsAAIBJSkpKlJKSoo4dO8rPz8/sclodh8OhHj166PLLL9fDDz9sdjkNrqbvV32yAT1OZqLHCQAAAE1s//79+uyzz3TGGWeotLRUCxYsUEpKiq666iqzS/Nopk4O8eWXX2r8+PGKj4+XxWKp04231qxZo1NOOUU2m02dO3d2zSHfLBGcAAAA0MSsVqsWLVqkQYMGafjw4dq8ebNWrlypHj16mF2aRzO1x6mwsFDJycmaOnWqLr744lrbp6Sk6LzzztP06dP13//+V6tWrdKf//xnxcXFafTo0U1QcQMjOAEAAKCJJSQk6JtvvjG7jGbH1OA0duxYjR07ts7tX3jhBXXs2FFPPvmkJKlHjx76+uuv9c9//pPgBAAAAKDRNKv7OK1du1ajRo1yWzd69GitXbv2hNuUlpYqLy/P7eExCE4AAABAs9CsglNaWlqVOd1jYmKUl5en4uLiareZN2+eQkNDXY+EhISmKLVuCE4AAABAs9CsgtMfcc899yg3N9f1OHjwoNkl/YrgBAAAADQLzWo68tjYWKWnp7utS09PV0hIiPz9/avdxmazyWazNUV59UdwAgAAAJqFZtXjVHm34d9asWKFhg4dalJFJ8l6/MfvcJhbBwAAAIAamRqcCgoKtGHDBm3YsEGSc7rxDRs26MCBA5Kcw+wmTZrkaj99+nTt3btXf/3rX7Vjxw4999xzevPNN3X77bebUf7Jo8cJAACgVTvzzDN12223uZYTExM1f/78Grep6/1Pa9NQ+2ktTA1OP/30k/r376/+/ftLku644w71799fs2fPliSlpqa6QpQkdezYUR999JFWrFih5ORkPfnkk/rXv/7VPKcilwhOAAAAzdT48eM1ZsyYat/76quvZLFYtGnTpnrv98cff9S0adNOtjw3c+fOVb9+/aqsT01Nrdetgf6IRYsWyWKxVHtz3bfeeksWi0WJiYmudXa7XY899pi6d+8uf39/RUREaMiQIfrXv/7lajNlyhRZLJYqjxOdj4Zi6jVOZ555pgzDOOH7ixYtqnabn3/+uRGrakIEJwAAgGbpuuuu0yWXXKJDhw6pXbt2bu8tXLhQAwcOVN++feu93+jo6IYqsVaxsbFNcpzAwEBlZGRo7dq1bpfYvPLKK2rfvr1b2wcffFAvvviiFixYoIEDByovL08//fSTsrOz3dqNGTNGCxcudFvX2PMaNKtrnFocghMAAEAVhiEVFprzqOH/6bv505/+pOjo6Cr/o7+goEBvvfWWrrvuOmVlZWnChAlq27atAgIC1KdPHy1ZsqTG/f5+qN6uXbt0+umny8/PTz179tSKFSuqbHPXXXepa9euCggIUKdOnfTAAw+ovLxckrMj4sEHH9TGjRtdPTOVNf9+qN7mzZt19tlny9/fX5GRkZo2bZoKCgpc70+ZMkUXXnihnnjiCcXFxSkyMlIzZ850HetEvL29ddVVV+nVV191rTt06JDWrFmjq666yq3t+++/rxtvvFGXXXaZOnbsqOTkZF133XWaNWuWWzubzabY2Fi3R3h4eI11nKxmNatei0NwAgAAqKKoSAoKMufYBQVSYGDt7by9vTVp0iQtWrRI9913nywWiyTn8DO73a4JEyaooKBAAwYM0F133aWQkBB99NFHuuaaa5SUlKTBgwfXegyHw6GLL75YMTEx+v7775Wbm+t2PVSl4OBgLVq0SPHx8dq8ebOuv/56BQcH669//auuuOIKbdmyRcuXL9fKlSslSaGhoVX2UVhYqNGjR2vo0KH68ccflZGRoT//+c+66aab3MLh6tWrFRcXp9WrV2v37t264oor1K9fP11//fU1fpapU6fqzDPP1P/93/8pICBAixYt0pgxY6rcozU2Nlaff/65brzxxibtfasLepzMRHACAABotqZOnao9e/boiy++cK1buHChLrnkEoWGhqpt27aaNWuW+vXrp06dOunmm2/WmDFj9Oabb9Zp/ytXrtSOHTv073//W8nJyTr99NP16KOPVml3//33a9iwYUpMTNT48eM1a9Ys1zH8/f0VFBQkb29vV89MdbfxWbx4sUpKSvTvf/9bvXv31tlnn60FCxboP//5j9vtgMLDw7VgwQJ1795df/rTn3TeeedVmfW6Ov3791enTp309ttvyzAMLVq0SFOnTq3S7qmnntLRo0cVGxurvn37avr06frkk0+qtPvwww8VFBTk9qjuZ9OQ6HEyE8EJAACgioAAZ8+PWceuq+7du2vYsGF69dVXdeaZZ2r37t366quv9NBDD0lyTnTw6KOP6s0339Thw4dVVlam0tJSBdTxINu3b1dCQoLi4+Nd66q7Dc8bb7yhp59+Wnv27FFBQYEqKioUEhJS9w9y/FjJyckK/E132/Dhw+VwOLRz505Xz1CvXr3kVfk3rKS4uDht3ry5TseYOnWqFi5cqPbt26uwsFDjxo3TggUL3Nr07NlTW7Zs0bp16/TNN9/oyy+/1Pjx4zVlyhS3CSLOOussPf/8827bRkRE1Osz1xfByUwEJwAAgCoslroNl/ME1113nW6++WY9++yzWrhwoZKSknTGGWdIkh5//HH93//9n+bPn68+ffooMDBQt912m8rKyhrs+GvXrtXEiRP14IMPavTo0QoNDdXSpUv15JNPNtgxfsvHx8dt2WKxyFHHe5JOnDhRf/3rXzV37lxdc8018vauPopYrVYNGjRIgwYN0m233abXX39d11xzje677z517NhRknPCic6dO5/ch6knhuqZieAEAADQrF1++eWyWq1avHix/v3vf2vq1Kmu652++eYbXXDBBbr66quVnJysTp066Zdffqnzvnv06KGDBw8qNTXVte67775za/Ptt9+qQ4cOuu+++zRw4EB16dJF+/fvd2vj6+srey1/b/bo0UMbN25UYWGha90333wjq9Wqbt261bnmmkREROj888/XF198Ue0wvRPp2bOnJLnVZgaCk5kITgAAAM1aUFCQrrjiCt1zzz1KTU3VlClTXO916dJFK1as0Lfffqvt27frhhtucLteqDajRo1S165dNXnyZG3cuFFfffWV7rvvPrc2Xbp00YEDB7R06VLt2bNHTz/9tJYtW+bWJjExUSkpKdqwYYMyMzNVWlpa5VgTJ06Un5+fJk+erC1btmj16tW6+eabdc0111SZwOFkLFq0SJmZmerevXu171966aX65z//qe+//1779+/XmjVrNHPmTHXt2tVtm9LSUqWlpbk9MjMzG6zO6hCczERwAgAAaPauu+46ZWdna/To0W7XI91///065ZRTNHr0aJ155pmKjY3VhRdeWOf9Wq1WLVu2TMXFxRo8eLD+/Oc/629/+5tbm/PPP1+33367brrpJvXr10/ffvutHnjgAbc2l1xyicaMGaOzzjpL0dHR1U6JHhAQoE8//VTHjh3ToEGDdOmll2rkyJFVrkE6WZVTnZ/I6NGj9cEHH2j8+PGu0Ni9e3d99tlnbkP7li9frri4OLfHaaed1qC1/p7FqOkOtC1QXl6eQkNDlZubW++L5hrc6tXS2WdLPXtKW7eaWwsAAIBJSkpKlJKSoo4dO8rPz8/sctDC1PT9qk82oMfJTNbjP356nAAAAACPRnAyU+VQvTrORAIAAADAHAQnM3GNEwAAANAsEJzMRHACAAAAmgWCk5kITgAAAC6tbM4yNJGG+l4RnMxEcAIAAJDX8b+JysrKTK4ELVHl96rye/ZHedfeBI2G4AQAACBvb28FBATo6NGj8vHxkdXK/9tHw3A4HDp69KgCAgLc7gP1RxCczERwAgAAkMViUVxcnFJSUrR//36zy0ELY7Va1b59e1kslpPaD8HJTAQnAAAASZKvr6+6dOnCcD00OF9f3wbpxSQ4mYngBAAA4GK1WuXn52d2GUC1GEBqJoITAAAA0CwQnMxEcAIAAACaBYKTmQhOAAAAQLNAcDITwQkAAABoFghOZqqc3cMwnA8AAAAAHongZKbf3r3Y4TCvDgAAAAA1IjiZ6bfBieF6AAAAgMciOJmJ4AQAAAA0CwQnMxGcAAAAgGaB4GQmghMAAADQLBCczERwAgAAAJoFgpOZCE4AAABAs0BwMpPF4nxIBCcAAADAgxGczFbZ60RwAgAAADwWwclsBCcAAADA4xGczEZwAgAAADwewclsBCcAAADA4xGczEZwAgAAADwewcls1uOnwOEwtw4AAAAAJ0RwMhs9TgAAAIDHIziZjeAEAAAAeDyCk9kITgAAAIDHIziZjeAEAAAAeDyCk9kITgAAAIDHIziZjeAEAAAAeDyCk9kITgAAAIDHIziZjeAEAAAAeDyCk9kITgAAAIDHIziZjeAEAAAAeDyCk9kITgAAAIDHIziZjeAEAAAAeDyCk9msx08BwQkAAADwWAQns1X2ODkc5tYBAAAA4IQITmZjqB4AAADg8QhOZiM4AQAAAB6P4GQ2ghMAAADg8QhOZiM4AQAAAB6P4GQ2ghMAAADg8QhOZiM4AQAAAB6P4GQ2ghMAAADg8QhOZiM4AQAAAB6P4GQ2ghMAAADg8QhOZiM4AQAAAB6P4GQ2ghMAAADg8QhOZiM4AQAAAB6P4GQ26/FTQHACAAAAPBbByWyVPU4Oh7l1AAAAADghgpPZGKoHAAAAeDyCk9kITgAAAIDHIziZjeAEAAAAeDyCk9kITgAAAIDHIziZjeAEAAAAeDyCk9kITgAAAIDHIziZjeAEAAAAeDyCk9kITgAAAIDHIziZjeAEAAAAeDyCk9kITgAAAIDHIziZjeAEAAAAeDzTg9Ozzz6rxMRE+fn5aciQIfrhhx9qbD9//nx169ZN/v7+SkhI0O23366SkpImqrYREJwAAAAAj2dqcHrjjTd0xx13aM6cOVq/fr2Sk5M1evRoZWRkVNt+8eLFuvvuuzVnzhxt375dr7zyit544w3de++9TVx5A7IePwUEJwAAAMBjmRqcnnrqKV1//fW69tpr1bNnT73wwgsKCAjQq6++Wm37b7/9VsOHD9dVV12lxMREnXvuuZowYUKtvVQerbLHyeEwtw4AAAAAJ2RacCorK9O6des0atSoX4uxWjVq1CitXbu22m2GDRumdevWuYLS3r179fHHH2vcuHEnPE5paany8vLcHh6FoXoAAACAx/M268CZmZmy2+2KiYlxWx8TE6MdO3ZUu81VV12lzMxMnXbaaTIMQxUVFZo+fXqNQ/XmzZunBx98sEFrb1AEJwAAAMDjmT45RH2sWbNGjz76qJ577jmtX79e77zzjj766CM9/PDDJ9zmnnvuUW5urutx8ODBJqy4DghOAAAAgMczrccpKipKXl5eSk9Pd1ufnp6u2NjYard54IEHdM011+jPf/6zJKlPnz4qLCzUtGnTdN9998lqrZoDbTabbDZbw3+AhkJwAgAAADyeaT1Ovr6+GjBggFatWuVa53A4tGrVKg0dOrTabYqKiqqEI6/jwcMwjMYrtjERnAAAAACPZ1qPkyTdcccdmjx5sgYOHKjBgwdr/vz5Kiws1LXXXitJmjRpktq2bat58+ZJksaPH6+nnnpK/fv315AhQ7R792498MADGj9+vCtANTsEJwAAAMDjmRqcrrjiCh09elSzZ89WWlqa+vXrp+XLl7smjDhw4IBbD9P9998vi8Wi+++/X4cPH1Z0dLTGjx+vv/3tb2Z9hJNHcAIAAAA8nsVotmPc/pi8vDyFhoYqNzdXISEhZpcjLV4sTZwojRwprVxpdjUAAABAq1GfbNCsZtVrkehxAgAAADwewclsBCcAAADA4xGczEZwAgAAADwewclslZNfEJwAAAAAj0VwMhs9TgAAAIDHIziZrTI4ORzm1gEAAADghAhOZqPHCQAAAPB4BCezEZwAAAAAj0dwMhvBCQAAAPB4BCezEZwAAAAAj0dwMhvBCQAAAPB4BCezEZwAAAAAj0dwMhvBCQAAAPB4BCezEZwAAAAAj0dwMhvBCQAAAPB4BCezEZwAAAAAj0dwMhvBCQAAAPB4BCezWY+fAoITAAAA4LEITmar7HFyOMytAwAAAMAJEZzMxlA9AAAAwOMRnMxGcAIAAAA8HsHJbAQnAAAAwOMRnMxGcAIAAAA8HsHJbJXBSWKCCAAAAMBDEZzM9tvgRK8TAAAA4JEITmYjOAEAAAAej+BkNoITAAAA4PEITmYjOAEAAAAej+BkNoITAAAA4PEITmYjOAEAAAAej+BkNutvTgHBCQAAAPBIBCdPUBmeCE4AAACARyI4eYLK4XrcABcAAADwSAQnT1AZnOhxAgAAADwSwckTEJwAAAAAj0Zw8gQEJwAAAMCjEZw8AcEJAAAA8GgEJ09AcAIAAAA8GsHJExCcAAAAAI9GcPIEBCcAAADAoxGcPAHBCQAAAPBoBCdPQHACAAAAPBrByRMQnAAAAACPRnDyBAQnAAAAwKMRnDyB9fhpIDgBAAAAHong5AnocQIAAAA8GsHJE1QGJ4fD3DoAAAAAVIvg5AnocQIAAAA8GsHJExCcAAAAAI9GcPIEBCcAAADAoxGcPAHBCQAAAPBoBCdPQHACAAAAPBrByRMQnAAAAACPRnDyBAQnAAAAwKMRnDwBwQkAAADwaAQnT0BwAgAAADwawckTEJwAAAAAj0Zw8gQEJwAAAMCjEZw8gfX4aSA4AQAAAB6J4OQJ6HECAAAAPBrByRNUBieHw9w6AAAAAFSL4OQJ6HECAAAAPBrByRMQnAAAAACPRnDyBAQnAAAAwKMRnDwBwQkAAADwaAQnT0BwAgAAADwawckTEJwAAAAAj0Zw8gQEJwAAAMCjEZw8AcEJAAAA8GgEJ09AcAIAAAA8GsHJExCcAAAAAI9GcPIE1uOngeAEAAAAeCSCkyegxwkAAADwaAQnT0BwAgAAADwawckTVAYnh8PcOgAAAABUi+DkCehxAgAAADwawckTEJwAAAAAj2Z6cHr22WeVmJgoPz8/DRkyRD/88EON7XNycjRz5kzFxcXJZrOpa9eu+vjjj5uo2kZCcAIAAAA8mreZB3/jjTd0xx136IUXXtCQIUM0f/58jR49Wjt37lSbNm2qtC8rK9M555yjNm3a6O2331bbtm21f/9+hYWFNX3xDYngBAAAAHg0U4PTU089peuvv17XXnutJOmFF17QRx99pFdffVV33313lfavvvqqjh07pm+//VY+Pj6SpMTExKYsuXEQnAAAAACPZtpQvbKyMq1bt06jRo36tRirVaNGjdLatWur3eb999/X0KFDNXPmTMXExKh379569NFHZa8hcJSWliovL8/t4XEITgAAAIBHMy04ZWZmym63KyYmxm19TEyM0tLSqt1m7969evvtt2W32/Xxxx/rgQce0JNPPqlHHnnkhMeZN2+eQkNDXY+EhIQG/RwNguAEAAAAeDTTJ4eoD4fDoTZt2uill17SgAEDdMUVV+i+++7TCy+8cMJt7rnnHuXm5roeBw8ebMKK64jgBAAAAHg0065xioqKkpeXl9LT093Wp6enKzY2ttpt4uLi5OPjI6/KoCGpR48eSktLU1lZmXx9fatsY7PZZLPZGrb4hkZwAgAAADyaaT1Ovr6+GjBggFatWuVa53A4tGrVKg0dOrTabYYPH67du3fL4XC41v3yyy+Ki4urNjQ1GwQnAAAAwKOZOlTvjjvu0Msvv6zXXntN27dv14wZM1RYWOiaZW/SpEm65557XO1nzJihY8eO6dZbb9Uvv/yijz76SI8++qhmzpxp1kdoGNbjp4HgBAAAAHgkU6cjv+KKK3T06FHNnj1baWlp6tevn5YvX+6aMOLAgQOyWn/NdgkJCfr00091++23q2/fvmrbtq1uvfVW3XXXXWZ9hIZBjxMAAADg0SyGYRhmF9GU8vLyFBoaqtzcXIWEhJhdjtOSJdJVV0lnny39ZugiAAAAgMZTn2zQrGbVa7HocQIAAAA8GsHJExCcAAAAAI9GcPIEBCcAAADAoxGcPAHBCQAAAPBoBCdPQHACAAAAPBrByRMQnAAAAACPVq/g9MMPP8hewx/3paWlevPNN0+6qFaH4AQAAAB4tHoFp6FDhyorK8u1HBISor1797qWc3JyNGHChIarrrUgOAEAAAAerV7B6ff3yq3u3rmt7H66DYPgBAAAAHi0Br/GyWKxNPQuWz6CEwAAAODRmBzCExCcAAAAAI/mXd8Ntm3bprS0NEnOYXk7duxQQUGBJCkzM7Nhq2strMfzK8EJAAAA8Ej1Dk4jR450u47pT3/6kyTnED3DMBiq90fQ4wQAAAB4tHoFp5SUlMaqo3WrDE4Oh7l1AAAAAKhWvYJThw4dam2zZcuWP1xMq0WPEwAAAODRGmRyiPz8fL300ksaPHiwkpOTG2KXrQvBCQAAAPBoJxWcvvzyS02ePFlxcXF64okndPbZZ+u7775rqNpaD4ITAAAA4NHqPTlEWlqaFi1apFdeeUV5eXm6/PLLVVpaqnfffVc9e/ZsjBpbPoITAAAA4NHq1eM0fvx4devWTZs2bdL8+fN15MgRPfPMM41VW+tBcAIAAAA8Wr16nD755BPdcsstmjFjhrp06dJYNbU+BCcAAADAo9Wrx+nrr79Wfn6+BgwYoCFDhmjBggXc9LYhEJwAAAAAj1av4HTqqafq5ZdfVmpqqm644QYtXbpU8fHxcjgcWrFihfLz8xurzpaN4AQAAAB4NIthGMbJ7GDnzp165ZVX9J///Ec5OTk655xz9P777zdUfQ0uLy9PoaGhys3NVUhIiNnlOB09KrVp43ztcEgWi7n1AAAAAK1AfbLBSd/HqVu3bvrHP/6hQ4cOaenSpbLwR3/9VfY4SfQ6AQAAAB6oXpNDTJ06tdY2kZGRf7iYVsv6m/xqt0ve9Z4lHgAAAEAjqtdf6IsWLVKHDh3Uv39/nWiEHz1OfwA9TgAAAIBHq1dwmjFjhpYsWaKUlBRde+21uvrqqxUREdFYtbUeBCcAAADAo9XrGqdnn31Wqamp+utf/6oPPvhACQkJuvzyy/Xpp5+esAcKdfDb4ORwmFcHAAAAgGrVe3IIm82mCRMmaMWKFdq2bZt69eqlG2+8UYmJiSooKGiMGls+epwAAAAAj3ZSs+pZrVZZLBYZhiE7f/D/cQQnAAAAwKPVOziVlpZqyZIlOuecc9S1a1dt3rxZCxYs0IEDBxQUFNQYNbZ8Fsuv924iOAEAAAAep16TQ9x4441aunSpEhISNHXqVC1ZskRRUVGNVVvr4uUlVVQ4HwAAAAA8isWox6wOVqtV7du3V//+/Wucdvydd95pkOIaQ33uDtyk2raVjhyRvvtOGjLE7GoAAACAFq8+2aBePU6TJk3iPk2NpXNnZ3DatYvgBAAAAHiYet8AFw1n3TpnB1P//tKwLl2kL790BicAAAAAHuWkZtXDyfn3v6WbbpLefVdSly7Olbt3m1kSAAAAgGoQnEzUsaPzOSVFvwYnepwAAAAAj0NwMtEJg1Pd5+sAAAAA0AQITibq1Mn5nJIiKSnJuZCTI2VlmVUSAAAAgGoQnExU2eN07JiUWx7gnJJcYrgeAAAA4GEITiYKCpIq7x/MdU4AAACA5yI4maza65yYWQ8AAADwKAQnkzGzHgAAAOD5CE4mIzgBAAAAno/gZDKmJAcAAAA8H8HJZG7BKSlJslikvDzp6FFT6wIAAADwK4KTySqD0759kmHzk9q1c65guB4AAADgMQhOJmvf3tnJVFQkZWSImfUAAAAAD0RwMpnN9msnExNEAAAAAJ6J4OQB3K5z6trVubBtm2n1AAAAAHBHcPIAbsFp6FDnwpo1kt1uVkkAAAAAfoPg5AHcgtOgQVJIiJSdLa1fb2pdAAAAAJwITh6gMjjt3SvJ21s66yznipUrTasJAAAAwK8ITh7ArcdJks45x/m8YoUp9QAAAABwR3DyAJXB6cABqaJCvwanb75xzlMOAAAAwFQEJw8QH++cltxud94IV126OG/wVFYmffml2eUBAAAArR7ByQNYrVKvXs7XmzfLeUfcUaOcKxiuBwAAAJiO4OQh+vZ1Pm/ceHxF5XA9JogAAAAATEdw8hDJyc5nV3AaOVI/aYAWbjpFSkszrS4AAAAABCeP8fvgZERF61Lf9zVVC/XTY/Q6AQAAAGYiOHmIyuCUkiLl5Um7dkn7y+IlSXuW/iA5HCZWBwAAALRuBCcPEREhtWvnfL1pk/T557++dyTdi2udAAAAABMRnDxI5QQRmzZJq1f/uv6I4qXnnjOnKAAAAAAEJ09SOVxvw4ZqgtMHH0gHD5pSFwAAANDaEZw8SGVweucd6ejRX9cfCevpvMbppZfMKQwAAABo5QhOHqQyOGVlOZ9DQ53PR/yTnC/ef7/piwIAAABAcPIkXbpI/v6/Ll96qfP5SG6Q88WePZJhNH1hAAAAQCtHcPIgXl5S796/Lk+c6HwuKLIqX8FSYaGUkWFOcQAAAEArRnDyMJUz64WGSiNGSCEhzuUjcQOcL/bsMacwAAAAoBUjOHmYU091Po8aJXl7S/HOe+DqSJt+zhcEJwAAAKDJeZtdANxNmSJZrdK4cc7l+Hhpxw4pNbyHc8XevabVBgAAALRWBCcP4+0tTZ3667Krx6lyZj16nAAAAIAmx1A9DxcX53w+Ym3nfEFwAgAAAJocwcnDuXqcyqKdLxiqBwAAADQ5gpOHcwWngmDni7Q057TkAAAAAJoMwcnDuYJTho8UHu5coNcJAAAAaFIEJw/nCk5HJKNjJ+cC1zkBAAAATcojgtOzzz6rxMRE+fn5aciQIfrhhx/qtN3SpUtlsVh04YUXNm6BJqqcHKK4WMpt38e5QI8TAAAA0KRMD05vvPGG7rjjDs2ZM0fr169XcnKyRo8erYyMjBq327dvn2bNmqURI0Y0UaXm8Pf/dYTekehk5wt6nAAAAIAmZXpweuqpp3T99dfr2muvVc+ePfXCCy8oICBAr7766gm3sdvtmjhxoh588EF16tSpCas1h2u4XnA35wuCEwAAANCkTA1OZWVlWrdunUaNGuVaZ7VaNWrUKK1du/aE2z300ENq06aNrrvuulqPUVpaqry8PLdHc+MKTr4dnC8ITgAAAECTMjU4ZWZmym63KyYmxm19TEyM0tLSqt3m66+/1iuvvKKXX365TseYN2+eQkNDXY+EhISTrrupuYKTcfzFvn2S3W5aPQAAAEBrY/pQvfrIz8/XNddco5dffllRUVF12uaee+5Rbm6u63Hw4MFGrrLhuYJTYYjk6ytVVEjN8HMAAAAAzZW3mQePioqSl5eX0tPT3danp6crNja2Svs9e/Zo3759Gj9+vGudw+GQJHl7e2vnzp1KSkpy28Zms8lmszVC9U3HFZxSrVJiovTLL87heomJZpYFAAAAtBqm9jj5+vpqwIABWrVqlWudw+HQqlWrNHTo0Crtu3fvrs2bN2vDhg2ux/nnn6+zzjpLGzZsaJbD8OqiMjgdOiSpa1fnwvbtptUDAAAAtDam9jhJ0h133KHJkydr4MCBGjx4sObPn6/CwkJde+21kqRJkyapbdu2mjdvnvz8/NS7d2+37cPCwiSpyvqWpHNn5/POnZIxMlmWDz+UNmwwtSYAAACgNTE9OF1xxRU6evSoZs+erbS0NPXr10/Lly93TRhx4MABWa3N6lKsBte1q2S1Sjk5UlriqYqTCE4AAABAE7IYhmGYXURTysvLU2hoqHJzcxUSEmJ2OXXWrZvz0qYVrx3RqMltnZNEFBRIPj5mlwYAAAA0S/XJBq27K6cZ6dnT+bwtO1YKCZHKyrjOCQAAAGgiBKdmojI4bd1mlfr1cy4wXA8AAABoEgSnZqJXL+fztm36NTj9/LNZ5QAAAACtCsGpmXD1OG2VjH79nQsEJwAAAKBJEJyaiW7dnDPrZWdL6e0HOVdu2CC1rrk9AAAAAFMQnJoJf3+pUyfn620VXZ2z6uXmSvv2mVoXAAAA0BoQnJqRyuuctv7i8+sCw/UAAACARkdwakZcU5Jvk9T/+HVOzKwHAAAANDqCUzNSbXCixwkAAABodASnZsQ1VG+rZCT3cy4QnAAAAIBGR3BqRrp1kywWKStLOtquv3OavcOHpbQ0s0sDAAAAWjSCUzMSEPDrzHpb9wVKPXo4F376ybyiAAAAgFaA4NTM9OnjfP7pJ0kDBzoXfvzRtHoAAACA1oDg1Mycdprz+auvJA06fiNcepwAAACARkVwamZOP935/PXXkuOU3/Q4GYZ5RQEAAAAtHMGpmenfXwoMlLKzpa0+/SRvb+noUengQbNLAwAAAFosglMz4+0tDR3qfP3l97bfXfQEAAAAoDEQnJqhyuF6X30lJogAAAAAmgDBqRkaMcL5/NVXkjGQCSIAAACAxkZwaoaGDJF8fKQjR6S9scOcK3/6iQkiAAAAgEZCcGqG/P1/nYn8q6PdJJtNysmR9uwxtS4AAACgpSI4NVOVw/W+/MZb6tfPucBwPQAAAKBREJyaKbcJIgYMcC6sX29aPQAAAEBLRnBqpgYPdj7v3i3ldz0enDZvNq8gAAAAoAUjODVTUVFSbKzz9Vb/41OSE5wAAACARkFwasYq7327uaSL88Xhw1J2tnkFAQAAAC0UwakZqwxOW/b4Sx06OBfodQIAAAAaHMGpGXP1OG3+/QIAAACAhkRwasZ693Y+b94sGb0JTgAAAEBjITg1Yz17ShaLlJkppbc/fkdcghMAAADQ4AhOzVhAgNS5s/P1Fu9+x19skQzDtJoAAACAlojg1My5Lm3KbS/5+Eh5edKBA+YWBQAAALQwBKdmzhWctnlJ3bsfX2C4HgAAANCQCE7NHDPrAQAAAI2P4NTMVWalrVslRy+CEwAAANAYCE7NXFKS5OcnFRdLe6OHOFcSnAAAAIAGRXBq5ry8nNOSS9Jm4/iNnXbskIqKzCsKAAAAaGEITi1A377O53X7o6TERKmiQvroI1NrAgAAAFoSglMLMGKE8/nz1RbpyiudC0uXmlcQAAAA0MIQnFqAUaOczz/8IOWed5Vz4aOPpNxc84oCAAAAWhCCUwvQvr3UpYtkt0tfZPWWevSQSkul994zuzQAAACgRSA4tRAjRzqfV33+m+F6S5aYVxAAAADQghCcWojK4XorV+rX4LRihZSZaVpNAAAAQEtBcGohzjpLslikbdukI0FdpVNOcY7de/tts0sDAAAAmj2CUwsREeHMSpK0apWkSy91LqxYYVpNAAAAQEtBcGpB3IbrDRniXPj5Z9PqAQAAAFoKglMLUhmcli+XNtsGOBdSUqTsbPOKAgAAAFoAglMLMny4FB8vZWRI/U4P1XVBbyhPwdKGDWaXBgAAADRrBKcWxN9f+uor6bLLJIdDerXgcj2k2dL69WaXBgAAADRrBKcWplMn6c03pWefdS5/p1MJTgAAAMBJIji1UMOHO5+3qaeMdQQnAAAA4GQQnFqobt0kq9VQtiKUtjNXKiw0uyQAAACg2SI4tVB+flJSkkWStE09pI0bTa4IAAAAaL4ITi1Yz57O523qyXVOAAAAwEkgOLVgvXo5n7eqV43B6ZtvpMOHm6goAAAAoBkiOLVgtfU4GYb0wAPSaadJF13UxMUBAAAAzQjBqQX7bY+TsWWrVFrqes8wpFmzpEcecS6vWycVF5tQJAAAANAMEJxasG7dJIvF0DFFKsMeIX33neu9OXOkp55yvvbxcd4wd+tWkwoFAAAAPBzBqQXz95c6dXLOrLdVvaT33pMk2e3SggXONs8+K40Y4Xy9aZMZVQIAAACej+DUwlUO19umntKyZZJh6McfpexsKTRUmjZNSk52tmHGcgAAAKB6BKcWrnKCiK1eydK+fdLGjVq+3LnunHMkb2+pb1/nMsEJAAAAqB7BqYVz9TiFDXO+WLbMFZzGjHE+V/Y4bdrknDQCAAAAgDuCUwvnmpK8LEmSlPX2av3wg3Pd6NG/tvHycg7fO3TIhCIBAAAAD0dwauG6d5csFikz308p1iSt3BYnw5B695batXO2sdmc7SSG6wEAAADVITi1cAEB0tChztdXBb2v93SBpF+H6VX67XA9AAAAAO4ITq3Aa69JYWHSd3k9tURXSZLGDMx0a5Pcxy5J2vjfLVJhYY37MwznDXPLyhqlXAAAAMDjEJxagc6dpaVLJavVOfNDgAp12t/HS0VFUmam9Nhj6vvkFEnSpm1e0qOP1ri///1PGjhQuv76xq4cAAAA8AwEp1Zi9Gjp73933gz3fN9PZfv5O2nIECkhQbrnHiVnrpQk/aKuKl64VKqoOOG+3n/f+fz669LevY1eOgAAAGA6glMrMmuWtGGD9PJ7bZw3cNqyRSopkU45RbGL/q6oSIcc8tKW1Ai55iyvxldfOZ8dDunJJ5umdgAAAMBMBKdWJjlZChpzmvTOO9KMGdI330g//STL5ElK7uf8Onyp06V//ava7Q8dct5Ht9Krr0pHjzZB4QAAAICJCE6t1fjx0nPPScOGOecrl3Tppc63HtdfVPjB51JqapXNKnubBgyQBg1ydlg980xTFQ0AAACYg+AEl6lTpcREKV2xWuCYIS1aVKXNl186n08/XfrrX52vFyyodSI+AAAAoFkjOMHF11d68EHn67/rLuU8v0QqKHBrU9njNGKEdNFFUqdOUna2c+QfAAAA0FIRnOBm4kSpRzeHshWhfxy8Upo2zXnjJklZWdLWrc52p50meXlJkyY5lxcvNqlgAAAAoAkQnODGy0t6+G/Or8U83avTl0zXpzd9IMNwziMhSd27S9HRksrLNWGDc7zeihWGMjJMKhoAAABoZAQnVHHxxdKdd0o+XnZ9pdM15rnzNaZfmpYscfY8nX66nL1QN9ygru8+roH6UXa7RW89n2lu4QAAAEAjITihCotFeuIJaW+KVbd1/lA2leizTbFautQ5+96IdinSXXdJCxdKXl6aGOG859Pix/ZXOxMfAAAA0Nx5RHB69tlnlZiYKD8/Pw0ZMkQ//PDDCdu+/PLLGjFihMLDwxUeHq5Ro0bV2B5/XLsEi/65eZQ2z3xRo6yrJEkWOXT67DOkxx93NnrxRV2x8npZ5NC3JQOUctZU6dgxE6sGAAAAGp7pwemNN97QHXfcoTlz5mj9+vVKTk7W6NGjlXGCC2bWrFmjCRMmaPXq1Vq7dq0SEhJ07rnn6vDhw01ceSvh56cuC27VZ7uT9O4Z/9RbcbeqfVuHFB8vPf20dN11iusfq7OHlUiSluzsL513XpXZ+AAAAIDmzGIYx6dMM8mQIUM0aNAgLViwQJLkcDiUkJCgm2++WXfffXet29vtdoWHh2vBggWaVDnFWw3y8vIUGhqq3NxchYSEnHT9cHr1Vem666RQS64+N87SKaMipfffl/z9zS4NAAAAqFZ9soGpPU5lZWVat26dRo0a5VpntVo1atQorV27tk77KCoqUnl5uSIiIqp9v7S0VHl5eW4PNLyJE533dso1QnWuVmjryiPOWSQOHTK7NAAAAOCkmRqcMjMzZbfbFRMT47Y+JiZGaWlpddrHXXfdpfj4eLfw9Vvz5s1TaGio65GQkHDSdaMqm0368ENp0CApS5E6y7JGM36aqpd6zteB/3zhuhcUAAAA0ByZfo3TyXjssce0dOlSLVu2TH5+ftW2ueeee5Sbm+t6HDx4sImrbD1CQqTly6W+faWjRrRe0AzdkP+Euk4aogeinlfRo/Olo0fNLhMAAACoN1ODU1RUlLy8vJSenu62Pj09XbGxsTVu+8QTT+ixxx7TZ599pr59+56wnc1mU0hIiNsDjSciQlq7VnrjDemu28s0JCZFpfLTI8duVLf7LtFdsa9pzZlzVbbsI6moyOxyAQAAgDrxiMkhBg8erGeeeUaSc3KI9u3b66abbjrh5BD/+Mc/9Le//U2ffvqpTj311Hodj8khmpZhSMsWF+uOWyu0PyvYtT5YeRppXa0xXVM07tIAJVw5XOrZ03kTKQAAAKAJ1CcbmB6c3njjDU2ePFkvvviiBg8erPnz5+vNN9/Ujh07FBMTo0mTJqlt27aaN2+eJOnvf/+7Zs+ercWLF2v48OGu/QQFBSkoKKjW4xGczFFcLL37rvTJ4mNavspHR4uD3d7vo00aE/i1Tu+fr+F/Clf46MFSnz6Sl5c5BQMAAKDFa1bBSZIWLFigxx9/XGlpaerXr5+efvppDRkyRJJ05plnKjExUYsWLZIkJSYmav/+/VX2MWfOHM2dO7fWYxGczOdwSD+vN7T89Ux9/H65vkuJkUPuAamzdqmf9xb165Cj5P5W9RsZqbYju8uS1EmyNutL8wAAAOAhml1wakoEJ8+TlSUtf79Mq/+Xpa++99UvmZHVtotRmk71/klDEw7p1AEVGnhuhAKH9pW6d5e8vZu4agAAADR3BKcaEJw8X2amtGGdXRs+TdfGbwu0YVegth+LkV3u4chLFeqpbepr3ao+8Vnq21fqe3qY4s/uLkuf3tIJZloEAAAAJIJTjQhOzVNJibT+hwqtff+ovvuyVGu3h+lwQVi1bcN1TH21WX0iD6t3p2L17u+jXqdHKmxwV6lTJ66bAgAAgCSCU40ITi3HoUPShvUObfoiW5u/K9SmX2zamRUlu1F9MGqrQ+pl3a7ekWnqlVSsHsk2JQyKVezwJHl36UigAgAAaGUITjUgOLVspaXS9m2GNn+ZrU1fHNPWrRZtORSqg0VRJ9zGKruStFcDQ3bqlISjSujoo9huoep8apTaDusgxcUxTToAAEALRHCqAcGpdcrNlbZttmvrl1na8l2+tm636pcjwTpSFKoK+Zxwu3gd1iCv9eoWlaWOCXZ17OGnjv3D1OG0BNl6dJLqMAU+AAAAPBPBqQYEJ/yWwyGlH7Fr8+dH9dPqfG3aJKWmWXQkx197i2KrTJNeySKHumiXkm071SGyQLkBcTrmE6Mse5iOlQZKXl66ZnSGpl2YoZCEUCkxUfL3b9oPBwAAgBoRnGpAcEJdFRZKP/9QrnUrsrR3U6FS9jq0N9VfKXmRKnLULQSFKFcX6l111S/qGp6pAWcEqePEYbKce45Ux+/fL79IN9/snHX9idl58tn4k3T66UzBDgAAcJIITjUgOOFkGYaUni5tXlugn1fnKG1vocJL0hRZdFARJUcUUXxYB3JC9NSxydpe1rnK9pHKVD9tUOfANLWLsyvF1l2bCjqpUAHq37NUgwY4NGiYr/oPD9CqL7x19dVSXp5z2/G2T/VG6YXyHzlceustKTy8iT+958jKcvYYRkebXQkAAGiuCE41IDihqTgc0ooV0o8/GNq1tUzbN5Zq464Aldnr1lPkpQrXvatOsW3RttIklchfZ2iNntId6t+lUJZ3/if17t2YH8MjlZZKXbtKZWXOHrngYLMrAgAAzRHBqQYEJ5iprEzatEna9kOBdv+YrQM7i9XekaLkkh8UkHVQP+V01o/FvfSj/RSlKU6SNFML9JTu0FqfMzTe+qHyS22SpAQd0Ln6TIMi9mrAYC91H91BQaNOlXr2lKxWMz9mo1u5UjrnHOfrd9+VLrjA1HIAAEAzRXCqAcEJzYFRVq7DO/JVnpmrjgHpznFpycnadKydHnxQWv6JoaLiqlOkxyhNSdYUdQ49qqTYIoVE2+QXEaCItv4adKqXEk+JkKVjYrOfqOL226X5852vb7hBeuEFU8sBAADNFMGpBgQntATFxdLnn0vfrC7VT6sL9PMOP2UWBda6XYzS1FW/KCawULHRFYqJkWLa+qhzd28lDw9SRK84KT5e8jnxFO2eoGtXadcu5+v27aV9+5y32kpJkY4ckYYPN7U8AADQTBCcakBwQkuVkyPt2VmhPd8d1e6f85TyS4UKcspVWlihwzmB+jmvs8pruGeVJLXTQXXQfrX1O6Z24QVq26ZcbdtZ1aGzjzr0CVFM72hZOyRIbdqYNhxw1y5ncPLxcZZQWiptveVFdTw1Rl1mna/DR6z6v/+TbrnFlPIAAEAzUp9swHzGQAsRFiYNGOKtAUPipOPXR/1WSYn083pDB7fkKn1zhtJ2Fyg91aHUTG/tyIrW3pK2OqQEHVKCVCIp9fhj46/7sKlE7XVAHSxblRiUqQ6RBWofX664Dr6KTQpSbI9wRfaMkTWxvRQa6uwGamAff+x8Pv10ycvL0GefWfTJ07/I++ltOqwLJUm33uq8N/HUqQ1+eAAA0EoRnIBWws9PGjrMoqHDwiSFVXk/N1fatsWhQ9vydHh7ng7tKdHhg4YOZfho/7EQHS4OV6n8tEtdtcvoKuXL+dgn6dtf9+OlCsUoXe2su5QQeEztwovULrZCCR0satfZX+16hyk+OVo+nRL+0LVWH33kfB43TrKu/VafabiWWS7WHmsXyS4N1I/6SYN0/fWGgoMtuuyyeh8CAACgCobqAaiT8nLp0CFp/54K7d+Yo33bCrV/T4UOHvZS2jFfpRUEKrMstE77ssihWKWpnXeaEgKz1S7ieLhK9FK7Lv6KSgpVaMcIhXeNll+bEFfPVUGBFBnpnJ1wx8d7pYsuUvfSX7vEOsSWamfYEN20Y6b+pevl61WhVf/L1WkXRDbKzwQAADRvXONUA4IT0HjKy6WMDOnI3hId2pilQzsKdGhvmQ4elA4dtelQXrAOFUeqXL513mecUpVkO6SEoGyV24L09pFh6uR3RLsD+krHspTkf0Qpxc6hiS+9JF0/sUj2mbfoskXjtEwXK0JZ+nbSi+r28NXOmSQAAACOIzjVgOAEmMvhkI5mGDq0PV8HNx5zhquUMh08ZNWhTJsO5YXoWFmQ8hxBcsir2n3crKf1tG6V2rXTzJE79NxrgerQwXkzXN/jmazo/ZU6e2Ksvi/orQ7apxmWFzVipI+6XTNEof06yrtbkmSzNeEnBwAAnobgVAOCE9A8GIZ07FCR9q7L1p5NhTqSUqr0wxUqKyzXXVfsU+wp8VK/ftqdFqRp06R775VGjXLfR0a6oaH9i7U3NaDK/gNUKFksslu8FRuQp1PbHtTQpKMaOlTqNyZWvr26NPv7XQEAgJoRnGpAcAJal6NHpddfl776MEffrLUqo7j2f/d+KlZPbVO8f47iosoUF21XXJwU195HcZ0DFdctRLF9ouXTto3kVX2vGAAA8HwEpxoQnIDWrbxcysk2lJeSJeu+vbLu26s9Oyu0dleU1u6L1XdpicqqCKvTvqJ0VPHeGYoLyFVcSKHiosoVFyvFJXgrLilAcd1CFNc7Uv6JMZI3k5gCAOBpCE41IDgBqIlhSLt+MfTLT3lK3ZCu1F/ylHrY0JFMH6XmBCi1KERp5ZGqqOVmwr8VpmzFeWUozj/HGbAiyhQX61BcO2/FJdoU1zlQ8T1CFdwputHufwUAAKoiONWA4ATgZDkcUlaGXalbjyl1e45SdxfqyP5ypR4xlHrUW6k5/kotDFFqWaRK5Ffn/QaqQHFKU5xvlrMXK7RIcZFliotxOHuxEm2K6xKk8E7hssa2kaKjJZ+6BzgAAOCO4FQDghOApmIYUu4xu1K3ZevINmfASt1fqtTDDqVmeCs1x0+pBSFKLY1QvhFU5/1a5FCYchSlTMV6ZyrOP1exIYWKiyhVTLShiBgfhcf7K6ZjgOK6Biu4Y5QsMW2koCBTe7MMQ/rrX6XVq6UbbpAmTWJiQwCAuQhONSA4AfBEBQVSakqJUnfkKnVXgVL3lSj1kEOpaRalZvnoSG6gUgtDlF1R/99bASpUvI4ozpKuWP8ctQkqUkxYmdpEOdQmxqKYBF+16eCvmM7BCko8HrKiohp84osXXpBmzPh1uW14oZ66K0OX39WxQY8DAEBdEZxqQHAC0JyVlkrZ2dKxTIcy9+Yp9Zd8paaUKO1QuVJTLcrI8lJ2vreOFdmUXhKqPHvde7Ik54yCbZShGKWrjW+O2gQUKizYruAQi4LDvRQcaVNglL92FcTp+/0xSkkPUOeEMvVOKtaAbgU6IzlHMVF2VXTtqd1HAmS1Sl26SD/9JJ12mlRWJl1+Qam+/iRPR8qiJUlPj1uum98/hxkKAQBNjuBUA4ITgNaksFBKTZVS9xbryM58pacUKeNQmdLTHMo4alVGjo/S8wOUURKiQnvD3LeqvfYrTbEqk3McXqx/ruyGRUdLQnRR3936X+FYle05oL9an9DTjpslSQ8m/Ev3Ph0r7/NGc90WAKDJEJxqQHACgOoVFkoZGVL64Qpl7MlXRkqh0veXKC+zVPnHKpSf61B+vqH8Qi+11SENcXynLiWbtUdJ2mz01rcVg7WxopdrfwEqlENWlcgZyDprl37SQIUqT+rQQcb7H+ihuQ7NXZYsSWqjdF3m96HOHFSohH4Raje4rWKTY+SVEM9sgwCARkFwqgHBCQAaT1aWtGWzofbWQ+qwe5XKDqTp+0Ntte5QjC6O+UaJBVukyEjpkUekNm0kSc8/kqUH/mZTVknVYYVeqlCcUhVryVC0f76iAksUFVKmqHC7oqIMRcV4KSrOV1EJ/opKDFJEx1B5x0Y5g5bV2tQfHwDQzBCcakBwAgDPU14urfrMrreeSdWO7YYOZfrpcFG47Kr/jYPDdUxRylSUd66i/PIVFVis6JDS42HLoqgYq8Jj/WQNC5EjJEyhcQHq2tNbtohAKSBA8vOjd6sGn33mzKVDhphdCQCcPIJTDQhOANA82O3OoYMHd5UofUe2MlPylXmwWJkZdmVmWZSZ7a3MfJsyiwKUWRqkY/awP3wsq+zqpL2yyqFCBcrXWqE+/nvUL/KA2keXKLKNlyLjfBWZEKCojsGKSAqXd9sYKSbGGbZaie+/l0491XkZ2urV0vDhZlcEACeH4FQDghMAtEwVFc4ZBzMPlypzb54y9xcq81CJMo+UKfOowxm2cpxh61ixv2S3y2KvUIY9UrlGaL2PF6ocRSpLkdYcRfoVKCqwWJEhFYqMMBQZKVfYimrnp8gOQYrsGKKAdhHN+nqtMWOkTz91vo6Oln78UerQwdyaAOBkEJxqQHACAPyWYThnHvxlu11e5SUKtBYrP61QG38q18YtVqWlW5WV46WsAl9lFQcouzz4Dx/LT8XOsOWVqyhbniL9ixUZVKrIMLszcEVZFBnro6i2NkUmBCgyMVihieGyRkeaPtvgt986e5i8vKSuXaXt26W+faVvvnHeWxkAmiOCUw0ITgCAk1HZs5WVaSjrYJGy9uQo64Czdysrvdy5PsfbGbSK/JVZGqysilBV6I8FH6vsitAxRVqyFeWTq0i/AkUGlCgyuEyRYRWKDDcUGW1VVKy3wuNsCmwTpIDYEAXGhSigbbi8woKr7eEyDOeNl7286jba8JxzpJUrpeuuk2b/pViDB1QovTBYf+q+W8s2dJS3jftwAWh+CE41IDgBAJqaYUj5+VLWkVJl7c1V1v4CZ9BKLVNWhv142PJSVp6PMgv9lVUSoKzyEBUagSd9bD8VK9yaqwjvPPl6OVQiPxUbfsooD1OR3U8+1gqdFf+LxnbaqRyFaX1We6UWhigyzKHoaEPRbazyDrLp8RdD5e3l0K55/1Pis3/Rd/tjdZZWq0T+mh77rp77uq8sSZ0a4KcFAE2H4FQDghMAoLkoLZUzWO0vUOa+AmUdKnaGr/QKZ9jKtigrx1uZBTZlFfkruzRQRXZfFRmNM2HFNL2oFzXdudC+vZYNnqdL3r5Shqy6RG8rLyhee61d1L9tui7utk3jkg8rNDlR6t5dRrsE7U4LUmqqNHBgq5pTA4AHIzjVgOAEAGjpDEMqKZEKM4tVcDhX2QcLlHWgUBWFpbI5iuXnKFIbW45ifLJ1ON1bH2xO1Oo97dXGJ1v9A39RovbpWK6XjubZdLQoQEeLg2RxOPT3mKcUnRQijRwp3XWXFBiop2dn6taHo05YS1sdUkelaJe6KF2xkiQ/S4nOCP5ZpyXsU69kH/UcHq52fSMU2LGN8/5eNVzPVV7uvL6qtNQZwJrpPBsAPATBqQYEJwAA6skwJIfDeUFUNV58Udr2U5F6W7epQ9Z6rdmXqP/tSdYvOTFu7XxVqggdU5riqt1PiHIVraMK8ypQmF+xwmwlCvMvkeHjq/SKSB0pidS2YzEqdfhKknra9ui2Nos1sGueSnudIkvPHuoyLFoRPWIk7/rfAwxA60NwqgHBCQCApnHsmPTLL9LePYYSooo1qF2qbHlHtWO7oU+/CdLPG63akhKgHTmxKnL413m/IcqVXV4qVPXT+bVRupJ8DighKFttw4sVGWZXWJgUFumlsGgfhcXYFBYfoLB2QQpuGyJbdIh8o0Jk8WaCC6C1ITjVgOAEAIBnqZw848ghh7L25irnQK5yDhUoN7NCOdkOOUrKFOOTrRjvLPXsXKZOvQOU799Gryxvq1eWxysnR7JVFKqs1NBhe/W9WXURphxFeWcr0idfUf4FigooVkRQmcJCHM7gFW5RWJS3wtr4KizWzxm+2gYqqG2orOGhpk8ZD6D+CE41IDgBANByFeQ5tHPtMe3blKeDO4t05ECFsrOlnDyLcgq8lVPkq5wSf2WXByrHHiy7Tn5In1V2hSpXYZZchXvnK8ynSGF+JQoPKFVYUIUreIVHHA9e0T4Kj/NTaFyAQuMDFRgfKktYqOTnd/I/AAD1QnCqAcEJAABIv06iUZpXqpKj+co5VKDMg8XKPFyqrPRyHc0wlJNtKCfHopx8L+UU+iin2Fc5pf7KKQ9UdkWwymQ76Tq8VKEQ5SlUeQr1LlCoT5FCbSUK9S9TaECFQoPsCg2VQsMsCo3wUmikt0Lb2BQa6+8MX3EBCooNkiU4SLLVXE95ubRvnxQbKwX/8Xs5Ay1GfbIBV04CAIBWyWKR/P0lf3+bFGNTbO8Tzw54IiUlUk5mhbIPFijncKFyUouVk16q7Ixy5WRVKOeYoexcq3Lyrc7gVWRTdqm/ssuDlGsPkl3esstb2YpQtiKkCjkfxZJy6l6HVXYFqlAOlatC3vKxVCjEq1Ah3sUK8SlSsE+JcuzB2pLfwTW5RlJIhvpFH1FyYq769ShVYhcftekcosjO4fKODpdCQyWrtd4/k8ZgGNJPP0lJSVJEhNnVoLWixwkAAMAEhiEVFUm52Q7lHil0PlKLlJteotzMcuVmVSg3267cXCk3z6qcAm/lFvkot8Sm3HJ/5ZYHKNdR/+GGNpWoVCceFmiRQxE6pjbKUBuvY4q25SkqoEhBAQ4FBFoUEGRVQIi3/EN9FBBmU0CETQGhvgrwcyggQIpt76vYLsGyRkVIYWEnnI2xPj+nv/xFevJJqV076csvpY4dT2qXgAtD9WpAcAIAAC2FK3xlVajwaJG8igvkXVqo8twi5R0tVV5mmfLypPwCi/xUouTYdHUMzlRWjpc27g/Txv1h2nAgQpsyYnWkOExZFaEydPK9TL4qVbyOKFS5CvYuVrBvqUL8yhTk75CPv7d8/L0VGmIoJqpCbaIMBYT5yi/EV4eKIvT1jiht2huo5PhMTej0vRZ/00GvbBrk2ncH70P6MvhPan/tSOnOO6X4+JOuF60XwakGBCcAAIDqVVRIWVnS0cNlythboIz9xTp6qFRH0+wqyitXcX6FigocKio0VFRkUVGJVUWlXiqq8FGxw6YCu7/SKyLlUMNO7W6VXf/QX/WibtAudVVbHdJg/SCbtVyhcYGKCrcrOtpQVIy3otr5KTrBT1Ht/BTVPkD+MSGyhIdJgYHcMRlVcI0TAAAA6s3bW4qJkWJifKVT/tjFROXl0uHDUurBCuWnFigvtVD5GcXKP1qi/GPlKi8oVXlBqXLyrErP81NGQaCKy71UWm5VqPI03Os79XVs0GrbaL1dMEYlDl/999x/6+KEAl0R9qnO+E877U1tp2VqJzkkHT7+qIGPyhSoHEVasxXhnS+bj11Wb6usXlZ5WQ1ZrYai/QvVOfKYOkQWyjvAVxY/m6z+Nln8bPIKsCkqxktt2vmqTXs/RXUIlFd4CGGslaHHCQAAAB6prEwqLnbOU1EpO1v66COpoEAq+eWAclOO6WiGQ5lZFmXm+iizwF9HS4OVWR7aILMeVscih6KUqRhlqI1vtqJsBQoOsCso0FBwsBQcalVQqJfzOcxbwRE+Co70VVCkTcFt/BUU7a/g2ED5RARLvr6NUqMZDh6UIiOlgADnst0uPfecc0KPq67yzIzJUL0aEJwAAABaPsOQCgul4iJDpTnFyk8t0LGDhTqWWqryvGLZ84vkKC6VwyFVVBg6kmnTnrQAHcwKlKPCLqPCIcPufC4vl7LKgpReHqEsR3iDXAcmOa8FC1a+gq2FCvIqVrBPiYJ8yhRsK1Owf7mC/B0KDnQoKEjugSzCR0ERvgqOsikoyk/BbZxBzC86WBbfpr8Rc3a2dPfd0ksvSe3aGVo89nUN2LxIE9Oe1Lv7+kmSrr5aevHFX0OVpyA41YDgBAAAgD+qokLKyjSUvr9YGXsLlZ5SpKwjpSrIKlV+doUKcu3KzzOUX2hRQYm38kt9VVDmq/xyf+Xb/VXgCKhxVsOT4aUKBalAQdYiBXsVKdi72BXEgvwqFBxQoaAAh4KPB7GgEKuCw7wUFO7j7BWrDGIxAQpqE6CguGBZfU98Zc/u3dKyZdITT0gZGb+ut8quJO3RLnWVr0pll5fs8la/qIN6ddZ29Z+S7BwT6gEITjUgOAEAAMBM5eVSQXa58tMLlZ9erIKjzmvACo6VKf9YufJzHa4AVlAg5RdalV/kdTyI+RwPYn7KtweowB6gQgU2Wq2BKlCQxRnEgrxL5OtVoXKHl3IrArW3vL2rXQ/rTj3luFVLNEH/1mRJUritUO8l3Cz77hRdrjd0VG0kSefpQ92XuFhDP7pf6tmz0WqvC4JTDQhOAAAAaEnsdqkot1z5qQXKTy9SQWaJ8jOP94IdK1dBToXycx2/CWIWFRR5Kb/YPYgVVPgp3xGofCOoTjMjeqtcZ+gLXaq3NVWvytfbkC6+WEvOfFEffh2m+++XevSQdOyYDr7zo+5+IlJLd/Z37XvNx0U6Y6y5Y/cITjUgOAEAAAAnZhhSSV6Z8tMKVZBR5JwV8XgQKyuxy9fPSzY/i/rFpSu8PMO5Qd++zt4jW80TcuzeLT02t0Trvy/XTzuDZW2Yy8X+MIJTDQhOAAAAgLnKyyWfpp/Hoor6ZAOTMx4AAACA1sYTQlN9EZwAAAAAoBYEJwAAAACoBcEJAAAAAGpBcAIAAACAWhCcAAAAAKAWBCcAAAAAqAXBCQAAAABqQXACAAAAgFoQnAAAAACgFgQnAAAAAKgFwQkAAAAAakFwAgAAAIBaEJwAAAAAoBYEJwAAAACoBcEJAAAAAGpBcAIAAACAWhCcAAAAAKAW3mYX0NQMw5Ak5eXlmVwJAAAAADNVZoLKjFCTVhec8vPzJUkJCQkmVwIAAADAE+Tn5ys0NLTGNhajLvGqBXE4HDpy5IiCg4NlsVhMqSEvL08JCQk6ePCgQkJCTKkB5uH8t26c/9aN89+6cf5bN86/ZzIMQ/n5+YqPj5fVWvNVTK2ux8lqtapdu3ZmlyFJCgkJ4R9OK8b5b904/60b57914/y3bpx/z1NbT1MlJocAAAAAgFoQnAAAAACgFgQnE9hsNs2ZM0c2m83sUmACzn/rxvlv3Tj/rRvnv3Xj/Dd/rW5yCAAAAACoL3qcAAAAAKAWBCcAAAAAqAXBCQAAAABqQXACAAAAgFoQnJrYs88+q8TERPn5+WnIkCH64YcfzC4JjWDu3LmyWCxuj+7du7veLykp0cyZMxUZGamgoCBdcsklSk9PN7FinKwvv/xS48ePV3x8vCwWi95991239w3D0OzZsxUXFyd/f3+NGjVKu3btcmtz7NgxTZw4USEhIQoLC9N1112ngoKCJvwU+KNqO/9Tpkyp8jthzJgxbm04/83TvHnzNGjQIAUHB6tNmza68MILtXPnTrc2dfmdf+DAAZ133nkKCAhQmzZt9Je//EUVFRVN+VHwB9Tl/J955plV/v1Pnz7drQ3nv3kgODWhN954Q3fccYfmzJmj9evXKzk5WaNHj1ZGRobZpaER9OrVS6mpqa7H119/7Xrv9ttv1wcffKC33npLX3zxhY4cOaKLL77YxGpxsgoLC5WcnKxnn3222vf/8Y9/6Omnn9YLL7yg77//XoGBgRo9erRKSkpcbSZOnKitW7dqxYoV+vDDD/Xll19q2rRpTfURcBJqO/+SNGbMGLffCUuWLHF7n/PfPH3xxReaOXOmvvvuO61YsULl5eU699xzVVhY6GpT2+98u92u8847T2VlZfr222/12muvadGiRZo9e7YZHwn1UJfzL0nXX3+927//f/zjH673OP/NiIEmM3jwYGPmzJmuZbvdbsTHxxvz5s0zsSo0hjlz5hjJycnVvpeTk2P4+PgYb731lmvd9u3bDUnG2rVrm6hCNCZJxrJly1zLDofDiI2NNR5//HHXupycHMNmsxlLliwxDMMwtm3bZkgyfvzxR1ebTz75xLBYLMbhw4ebrHacvN+ff8MwjMmTJxsXXHDBCbfh/LccGRkZhiTjiy++MAyjbr/zP/74Y8NqtRppaWmuNs8//7wREhJilJaWNu0HwEn5/fk3DMM444wzjFtvvfWE23D+mw96nJpIWVmZ1q1bp1GjRrnWWa1WjRo1SmvXrjWxMjSWXbt2KT4+Xp06ddLEiRN14MABSdK6detUXl7u9l3o3r272rdvz3ehhUpJSVFaWprbOQ8NDdWQIUNc53zt2rUKCwvTwIEDXW1GjRolq9Wq77//vslrRsNbs2aN2rRpo27dumnGjBnKyspyvcf5bzlyc3MlSREREZLq9jt/7dq16tOnj2JiYlxtRo8erby8PG3durUJq8fJ+v35r/Tf//5XUVFR6t27t+655x4VFRW53uP8Nx/eZhfQWmRmZsput7v9o5CkmJgY7dixw6Sq0FiGDBmiRYsWqVu3bkpNTdWDDz6oESNGaMuWLUpLS5Ovr6/CwsLctomJiVFaWpo5BaNRVZ7X6v79V76XlpamNm3auL3v7e2tiIgIvhctwJgxY3TxxRerY8eO2rNnj+69916NHTtWa9eulZeXF+e/hXA4HLrttts0fPhw9e7dW5Lq9Ds/LS2t2t8Ple+heaju/EvSVVddpQ4dOig+Pl6bNm3SXXfdpZ07d+qdd96RxPlvTghOQCMYO3as63Xfvn01ZMgQdejQQW+++ab8/f1NrAyAGa688krX6z59+qhv375KSkrSmjVrNHLkSBMrQ0OaOXOmtmzZ4nZNK1qPE53/316r2KdPH8XFxWnkyJHas2ePkpKSmrpMnASG6jWRqKgoeXl5VZlFJz09XbGxsSZVhaYSFhamrl27avfu3YqNjVVZWZlycnLc2vBdaLkqz2tN//5jY2OrTBRTUVGhY8eO8b1ogTp16qSoqCjt3r1bEue/Jbjpppv04YcfavXq1WrXrp1rfV1+58fGxlb7+6HyPXi+E53/6gwZMkSS3P79c/6bB4JTE/H19dWAAQO0atUq1zqHw6FVq1Zp6NChJlaGplBQUKA9e/YoLi5OAwYMkI+Pj9t3YefOnTpw4ADfhRaqY8eOio2NdTvneXl5+v77713nfOjQocrJydG6detcbT7//HM5HA7Xf2TRchw6dEhZWVmKi4uTxPlvzgzD0E033aRly5bp888/V8eOHd3er8vv/KFDh2rz5s1u4XnFihUKCQlRz549m+aD4A+p7fxXZ8OGDZLk9u+f899MmD07RWuydOlSw2azGYsWLTK2bdtmTJs2zQgLC3ObRQUtw5133mmsWbPGSElJMb755htj1KhRRlRUlJGRkWEYhmFMnz7daN++vfH5558bP/30kzF06FBj6NChJleNk5Gfn2/8/PPPxs8//2xIMp566inj559/Nvbv328YhmE89thjRlhYmPHee+8ZmzZtMi644AKjY8eORnFxsWsfY8aMMfr37298//33xtdff2106dLFmDBhglkfCfVQ0/nPz883Zs2aZaxdu9ZISUkxVq5caZxyyilGly5djJKSEtc+OP/N04wZM4zQ0FBjzZo1RmpqqutRVFTkalPb7/yKigqjd+/exrnnnmts2LDBWL58uREdHW3cc889Znwk1ENt53/37t3GQw89ZPz0009GSkqK8d577xmdOnUyTj/9dNc+OP/NB8GpiT3zzDNG+/btDV9fX2Pw4MHGd999Z3ZJaARXXHGFERcXZ/j6+hpt27Y1rrjiCmP37t2u94uLi40bb7zRCA8PNwICAoyLLrrISE1NNbFinKzVq1cbkqo8Jk+ebBiGc0ryBx54wIiJiTFsNpsxcuRIY+fOnW77yMrKMiZMmGAEBQUZISEhxrXXXmvk5+eb8GlQXzWd/6KiIuPcc881oqOjDR8fH6NDhw7G9ddfX+V/mnH+m6fqzrskY+HCha42dfmdv2/fPmPs2LGGv7+/ERUVZdx5551GeXl5E38a1Fdt5//AgQPG6aefbkRERBg2m83o3Lmz8Ze//MXIzc112w/nv3mwGIZhNF3/FgAAAAA0P1zjBAAAAAC1IDgBAAAAQC0ITgAAAABQC4ITAAAAANSC4AQAAAAAtSA4AQAAAEAtCE4AAAAAUAuCEwAAAADUguAEAEANLBaL3n33XbPLAACYjOAEAPBYU6ZMkcViqfIYM2aM2aUBAFoZb7MLAACgJmPGjNHChQvd1tlsNpOqAQC0VvQ4AQA8ms1mU2xsrNsjPDxcknMY3fPPP6+xY8fK399fnTp10ttvv+22/ebNm3X22WfL399fkZGRmjZtmgoKCtzavPrqq+rVq5dsNpvi4uJ00003ub2fmZmpiy66SAEBAerSpYvef/9913vZ2dmaOHGioqOj5e/vry5dulQJegCA5o/gBABo1h544AFdcskl2rhxoyZOnKgrr7xS27dvlyQVFhZq9OjRCg8P148//qi33npLK1eudAtGzz//vGbOnKlp06Zp8+bNev/999W5c2e3Yzz44IO6/PLLtWnTJo0bN04TJ07UsWPHXMfftm2bPvnkE23fvl3PP/+8oqKimu4HAABoEhbDMAyziwAAoDpTpkzR66+/Lj8/P7f19957r+69915ZLBZNnz5dzz//vOu9U089Vaeccoqee+45vfzyy7rrrrt08OBBBQYGSpI+/vhjjR8/XkeOHFFMTIzatm2ra6+9Vo888ki1NVgsFt1///16+OGHJTnDWFBQkD755BONGTNG559/vqKiovTqq6820k8BAOAJuMYJAODRzjrrLLdgJEkRERGu10OHDnV7b+jQodqwYYMkafv27UpOTnaFJkkaPny4HA6Hdu7cKYvFoiNHjmjkyJE11tC3b1/X68DAQIWEhCgjI0OSNGPGDF1yySVav369zj33XF144YUaNmzYH/qsAADPRXACAHi0wMDAKkPnGoq/v3+d2vn4+LgtWywWORwOSdLYsWO1f/9+ffzxx1qxYoVGjhypmTNn6oknnmjwegEA5uEaJwBAs/bdd99VWe7Ro4ckqUePHtq4caMKCwtd73/zzTeyWq3q1q2bgoODlZiYqFWrVp1UDdHR0Zo8ebJef/11zZ8/Xy+99NJJ7Q8A4HnocQIAeLTS0lKlpaW5rfP29nZNwPDWW29p4MCBOu200/Tf//5XP/zwg1555RVJ0sSJEzVnzhxNnjxZc+fO1dGjR3XzzTfrmmuuUUxMjCRp7ty5mj59utq0aaOxY8cqPz9f33zzjW6++eY61Td79mwNGDBAvXr1UmlpqT788ENXcAMAtBwEJwCAR1u+fLni4uLc1nXr1k07duyQ5JzxbunSpbrxxhsVFxenJUuWqGfPnpKkgIAAffrpp7r11ls1aNAgBQQE6JJLLtFTTz3l2tfkyZNVUlKif/7zn5o1a5aioqJ06aWX1rk+X19f3XPPPdq3b5/8/f01YsQILV26tAE+OQDAkzCrHgCg2bJYLFq2bJkuvPBCs0sBALRwXOMEAAAAALUgOAEAAABALbjGCQDQbDHaHADQVOhxAgAAAIBaEJwAAAAAoBYEJwAAAACoBcEJAAAAAGpBcAIAAACAWhCcAAAAAKAWBCcAAAAAqAXBCQAAAABq8f9dNxWryDxWNQAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mae = history.history['loss']\n",
    "val_mae = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(mae) + 1)\n",
    "\n",
    "# MAE Diagramm\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, mae, 'r', label='Training MSE')\n",
    "plt.plot(epochs, val_mae, 'b', label='Validation MSE')\n",
    "plt.title('Training and Validation MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.savefig('C:/Users/erikm/Desktop/Diplomarbeit Erik Marr/Bilder Diplomarbeit/MSE_NeuroNetz/MSE_NeuroNetz_D4_2')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:02:20.376734500Z",
     "start_time": "2024-03-15T10:02:20.187042100Z"
    }
   },
   "id": "3688dd7102e95baf"
  },
  {
   "cell_type": "markdown",
   "id": "553df6fa",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "# def build_model(learning_rate=0.001, activation='relu', regularization=0.0001, dropout_rate=0.0):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(448, activation=activation, input_shape=(2,), kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(384, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(96, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(128, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(320, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "# \n",
    "#     model.add(Dense(416, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "#     \n",
    "#     model.add(Dense(416, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "#     \n",
    "#     model.add(Dense(256, activation=activation, kernel_initializer='he_uniform', kernel_regularizer=l2(regularization)))\n",
    "#     model.add(Dropout(dropout_rate))    \n",
    "#     \n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mae'])\n",
    "#     return model\n",
    "# \n",
    "# # Verwenden Sie eine Funktion, um das Modell zu instanziieren, für scikit-learn Wrapper\n",
    "# model = KerasRegressor(model=build_model, verbose=2)\n",
    "# \n",
    "# # Anpassung der Parameter im param_grid\n",
    "# param_grid = {\n",
    "#     'model__learning_rate': [0.01, 0.001, 0.0001],\n",
    "#     'model__regularization': [0.001, 0.0001],\n",
    "#     'fit__batch_size': [10, 25, 50, 75],\n",
    "#     'fit__epochs': [50],\n",
    "#     'model__dropout_rate' : [0.0, 0.1, 0.2]\n",
    "# }\n",
    "# \n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=2)\n",
    "# # Hinweis: Stellen Sie sicher, dass Ihre Daten (X_train_scaled, y_train_scaled) korrekt definiert sind\n",
    "# grid_result = grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "# # Beste Parameter und Score ausgeben\n",
    "# print(\"Beste Parameter:\", grid_search.best_params_)\n",
    "# print(\"Beste Genauigkeit:\", grid_search.best_score_)\n",
    "# \n",
    "# with open(\"Gridsearch_D4.txt\", \"w\") as f:\n",
    "#     f.write(f\"Beste Parameter: {grid_search.best_params_}\\n\")\n",
    "#     f.write(f\"Beste Genauigkeit: {grid_search.best_score_}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:02:20.390737300Z",
     "start_time": "2024-03-15T10:02:20.377735Z"
    }
   },
   "id": "7464a951f44a07ee"
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "# # Funktion zum Erstellen des Modells\n",
    "# def build_model(hp):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(hp.Int('input_units', min_value=8, max_value=328, step=16), input_shape=(2,), activation='relu'))\n",
    "#     for i in range(hp.Int('n_layers', 1, 10)):\n",
    "#         model.add(Dense(hp.Int(f'units_{i}', min_value=8, max_value=328, step=16), activation='relu'))\n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     return model\n",
    "# \n",
    "# # Durchführung der Random Search dreimal\n",
    "# for run in range(1, 4):\n",
    "#     # Anpassen des Verzeichnisses und des Projektnamens für jeden Durchlauf\n",
    "#     directory = 'random_search'\n",
    "#     project_name = f'random_search_D4_{run}'\n",
    "#     \n",
    "#     tuner = RandomSearch(\n",
    "#         build_model,\n",
    "#         objective='val_loss',\n",
    "#         max_trials=100,\n",
    "#         executions_per_trial=1,\n",
    "#         directory=directory,\n",
    "#         project_name=project_name\n",
    "#     )\n",
    "#     \n",
    "#     # Durchführung des Random Search\n",
    "#     tuner.search(X_train_scaled, y_train_scaled, epochs=50, verbose =0, batch_size=20, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "#     \n",
    "#     # Abrufen und Speichern des besten Modells\n",
    "#     best_model = tuner.get_best_models(num_models=1)[0]\n",
    "#     model_path = os.path.join(directory, project_name, 'best_model.h5') \n",
    "#     best_model.save(model_path)\n",
    "#     \n",
    "# \n",
    "#     # Optional: Abrufen und Ausgeben der besten Hyperparameter\n",
    "#     best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "#     \n",
    "#     # Konvertieren der Hyperparameter in ein DataFrame\n",
    "#     df_hyperparameters = pd.DataFrame([best_hyperparameters.values])\n",
    "#     # Speichern des DataFrame als CSV\n",
    "#     df_hyperparameters.to_csv(f'random_search_D4_{run}.csv', index=False)\n",
    "#     \n",
    "#     print(f\"Beste Hyperparameter für Lauf {run}: {best_hyperparameters.values}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:02:20.390737300Z",
     "start_time": "2024-03-15T10:02:20.382300800Z"
    }
   },
   "id": "d0f02feb42b652f5"
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:02:20.390737300Z",
     "start_time": "2024-03-15T10:02:20.387187Z"
    }
   },
   "id": "3e35d5ebef369658"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
